--- ../../benchmarkAnalysis/Ring::Switch.testObjConstSwitch/linuxX64/baseline/bitcode/bitcode.ll	2023-07-19 02:48:43.160627700 +0200
+++ ../../benchmarkAnalysis/Ring::Switch.testObjConstSwitch/linuxX64/unordered/bitcode/bitcode.ll	2023-07-19 03:00:30.890405846 +0200
@@ -1,4 +1,4 @@
-; ModuleID = '../../benchmarkAnalysis/Ring::Switch.testObjConstSwitch/linuxX64/baseline/main.kt.bc'
+; ModuleID = '../../benchmarkAnalysis/Ring::Switch.testObjConstSwitch/linuxX64/unordered/main.kt.bc'
 source_filename = "out"
 target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
 target triple = "x86_64-unknown-linux-gnu"
@@ -171,6 +171,8 @@
 %"kclassbody:kotlin.native.internal.KClassImpl#internal" = type { %struct.ObjHeader, i8* }
 %"kclassbody:kotlin.Throwable.ExceptionTraceBuilder#internal" = type { %struct.ObjHeader, %struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader*, i1 }
 %"kclassbody:kotlin.collections.HashMap#internal" = type { %struct.ObjHeader, %struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader*, i32, i32, i32, i32, i1 }
+%"class.kotlin::NativeOrUnregisteredThreadGuard" = type { [8 x i8], %"class.kotlin::CalledFromNativeGuard" }
+%"class.kotlin::CalledFromNativeGuard" = type <{ %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, i32, i8, [3 x i8] }>
 %class.SourceInfo = type { %"class.std::__cxx11::basic_string", i32, i32 }
 %"class.std::__cxx11::basic_string" = type { %"struct.std::__cxx11::basic_string<char, std::char_traits<char>, kotlin::std_support::allocator<char>>::_Alloc_hider", i64, %union.anon.108 }
 %"struct.std::__cxx11::basic_string<char, std::char_traits<char>, kotlin::std_support::allocator<char>>::_Alloc_hider" = type { i8* }
@@ -862,8 +864,8 @@
 @init_node.112 = internal global %struct.InitNode { void (i32, %struct.MemoryState*)* @256, %struct.InitNode* null }
 @158 = internal unnamed_addr constant { %struct.ArrayHeader, [20 x i32] } { %struct.ArrayHeader { %struct.TypeInfo* bitcast (i8* getelementptr (i8, i8* bitcast ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.IntArray#internal" to i8*), i32 1) to %struct.TypeInfo*), i32 20 }, [20 x i32] [i32 11, i32 29, i32 47, i32 71, i32 103, i32 149, i32 175, i32 227, i32 263, i32 307, i32 361, i32 487, i32 563, i32 617, i32 677, i32 751, i32 823, i32 883, i32 967, i32 1031] }
 @init_node.113 = internal global %struct.InitNode { void (i32, %struct.MemoryState*)* @257, %struct.InitNode* null }
-@_Konan_init_stdlib_guard = internal unnamed_addr global i1 false
-@_Konan_init_main_guard = internal unnamed_addr global i1 false
+@_Konan_init_stdlib_guard = private unnamed_addr global i32 0
+@_Konan_init_main_guard = private unnamed_addr global i32 0
 @llvm.global_ctors = appending global [6 x { i32, void ()*, i8* }] [{ i32, void ()*, i8* } { i32 1, void ()* @_Konan_constructors, i8* null }, { i32, void ()*, i8* } { i32 65535, void ()* @_GLOBAL__sub_I_GlobalData.cpp, i8* null }, { i32, void ()*, i8* } { i32 65535, void ()* @_GLOBAL__sub_I_CallsChecker.cpp, i8* null }, { i32, void ()*, i8* } { i32 65535, void ()* @_GLOBAL__sub_I_ThreadSuspension.cpp, i8* null }, { i32, void ()*, i8* } { i32 65535, void ()* @_GLOBAL__sub_I_ConcurrentMarkAndSweep.cpp, i8* null }, { i32, void ()*, i8* } { i32 65535, void ()* @_mi_process_init, i8* null }]
 @llvm.global.annotations = appending global [23 x { i8*, i8*, i8*, i32 }] [{ i8*, i8*, i8*, i32 } { i8* bitcast (void ()* @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.30, i32 0, i32 0), i8* getelementptr inbounds ([75 x i8], [75 x i8]* @.str.31, i32 0, i32 0), i32 53 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void (%"class.kotlin::mm::ThreadSuspensionData.37"*)* @_ZN6kotlin2mm20ThreadSuspensionData18suspendIfRequestedEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.13.129, i32 0, i32 0), i8* getelementptr inbounds ([84 x i8], [84 x i8]* @.str.14.130, i32 0, i32 0), i32 47 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void ()* @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.4.31, i32 0, i32 0), i8* getelementptr inbounds ([75 x i8], [75 x i8]* @.str.5.32, i32 0, i32 0), i32 53 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void ()* @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.2.38, i32 0, i32 0), i8* getelementptr inbounds ([75 x i8], [75 x i8]* @.str.3.39, i32 0, i32 0), i32 53 }, { i8*, i8*, i8*, i32 } { i8* bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to i8*), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.2.259, i32 0, i32 0), i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.3.260, i32 0, i32 0), i32 51 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void ()* @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.14.261, i32 0, i32 0), i8* getelementptr inbounds ([75 x i8], [75 x i8]* @.str.15.262, i32 0, i32 0), i32 53 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void (%"class.kotlin::mm::ThreadSuspensionData.37"*)* @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.4.293, i32 0, i32 0), i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.5.294, i32 0, i32 0), i32 53 }, { i8*, i8*, i8*, i32 } { i8* bitcast (i1 ()* @_ZN6kotlin2mm24RequestThreadsSuspensionEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.4.293, i32 0, i32 0), i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.5.294, i32 0, i32 0), i32 68 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void ()* @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.4.310, i32 0, i32 0), i8* getelementptr inbounds ([75 x i8], [75 x i8]* @.str.5.311, i32 0, i32 0), i32 53 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void ()* @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.4.325, i32 0, i32 0), i8* getelementptr inbounds ([75 x i8], [75 x i8]* @.str.5.326, i32 0, i32 0), i32 53 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void (%"class.kotlin::mm::ThreadSuspensionData.37"*)* @_ZN6kotlin2mm20ThreadSuspensionData18suspendIfRequestedEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.24.338, i32 0, i32 0), i8* getelementptr inbounds ([84 x i8], [84 x i8]* @.str.25.339, i32 0, i32 0), i32 47 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void (%"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData"*)* @_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData14OnSuspendForGCEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.3.306, i32 0, i32 0), i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.4.307, i32 0, i32 0), i32 79 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void (%"class.kotlin::gc::ConcurrentMarkAndSweep"*, i64)* @_ZN6kotlin2gc22ConcurrentMarkAndSweep29CollectRootSetAndStartMarkingENS0_8GCHandleE to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.3.306, i32 0, i32 0), i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.4.307, i32 0, i32 0), i32 227 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void ()* @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.3.306, i32 0, i32 0), i8* getelementptr inbounds ([75 x i8], [75 x i8]* @.str.19.308, i32 0, i32 0), i32 53 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void ()* @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.10.35.309, i32 0, i32 0), i8* getelementptr inbounds ([75 x i8], [75 x i8]* @.str.11.36, i32 0, i32 0), i32 53 }, { i8*, i8*, i8*, i32 } { i8* bitcast (i64 ()* @_mi_os_numa_node_count_get to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.3.55, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.4.56, i32 0, i32 0), i32 1208 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void (%"class.kotlin::gc::internal::GCEmptySchedulerData"*, i32, i8**, i64, i64, i8*)* @_ZNK12_GLOBAL__N_112StderrLogger3LogEN6kotlin7logging5LevelENS1_11std_support4spanIKPKcLm18446744073709551615EEESt17basic_string_viewIcSt11char_traitsIcEE to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.15.123, i32 0, i32 0), i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.16.124, i32 0, i32 0), i32 108 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void (i8*, i32)* @_ZN5konan16consoleErrorUtf8EPKcj to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.212.532, i32 0, i32 0), i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.1.213, i32 0, i32 0), i32 79 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void (i8*, ...)* @_ZN5konan13consolePrintfEPKcz to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.212.532, i32 0, i32 0), i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.1.213, i32 0, i32 0), i32 163 }, { i8*, i8*, i8*, i32 } { i8* bitcast (void (i8*, ...)* @_ZN5konan13consoleErrorfEPKcz to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.212.532, i32 0, i32 0), i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.1.213, i32 0, i32 0), i32 175 }, { i8*, i8*, i8*, i32 } { i8* bitcast (i1 ()* @_ZN5konan36isOnThreadExitNotSetOrAlreadyStartedEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.212.532, i32 0, i32 0), i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.1.213, i32 0, i32 0), i32 216 }, { i8*, i8*, i8*, i32 } { i8* bitcast (i32 ()* @_ZN5konan6gettidEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.212.532, i32 0, i32 0), i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.1.213, i32 0, i32 0), i32 265 }, { i8*, i8*, i8*, i32 } { i8* bitcast (i32 ()* @_ZN5konan15currentThreadIdEv to i8*), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.212.532, i32 0, i32 0), i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.1.213, i32 0, i32 0), i32 270 }], section "llvm.metadata"
 @.str.30 = private unnamed_addr constant [24 x i8] c"no_external_calls_check\00", section "llvm.metadata"
@@ -886,7 +888,7 @@
 @_ZN6kotlin2mm10GlobalData9instance_E = internal global %"class.kotlin::mm::GlobalData" zeroinitializer, align 8
 @_ZN12_GLOBAL__N_118gSuspensionCondVarE = internal global %"class.std::condition_variable" zeroinitializer, align 8
 @_ZN12_GLOBAL__N_17checkerE = internal global %"class.(anonymous namespace)::KnownFunctionChecker" zeroinitializer, align 8
-@Kotlin_callsCheckerGoodFunctionNames = internal unnamed_addr constant [236 x i8*] [i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.9.117, i32 0, i32 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.1.10, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.2.11, i32 0, i32 0), i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.3.12, i32 0, i32 0), i8* getelementptr inbounds ([58 x i8], [58 x i8]* @.str.4.13, i32 0, i32 0), i8* getelementptr inbounds ([58 x i8], [58 x i8]* @.str.5.14, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.6.15, i32 0, i32 0), i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.7.16, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.8.17, i32 0, i32 0), i8* getelementptr inbounds ([46 x i8], [46 x i8]* @.str.9.18, i32 0, i32 0), i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.10.118, i32 0, i32 0), i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.11.19, i32 0, i32 0), i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.12.20, i32 0, i32 0), i8* getelementptr inbounds ([68 x i8], [68 x i8]* @.str.13.21, i32 0, i32 0), i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.14.22, i32 0, i32 0), i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.15.119, i32 0, i32 0), i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.16.23, i32 0, i32 0), i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.17.24, i32 0, i32 0), i8* getelementptr inbounds ([44 x i8], [44 x i8]* @.str.18.120, i32 0, i32 0), i8* getelementptr inbounds ([53 x i8], [53 x i8]* @.str.19.25, i32 0, i32 0), i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.20.26, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.21.121, i32 0, i32 0), i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.22.27, i32 0, i32 0), i8* getelementptr inbounds ([66 x i8], [66 x i8]* @.str.23.28, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.24.122, i32 0, i32 0), i8* getelementptr inbounds ([58 x i8], [58 x i8]* @.str.25.123, i32 0, i32 0), i8* getelementptr inbounds ([60 x i8], [60 x i8]* @.str.26, i32 0, i32 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.27, i32 0, i32 0), i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.28.124, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.29.125, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.30.126, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.31.127, i32 0, i32 0), i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.32, i32 0, i32 0), i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.33, i32 0, i32 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.34, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.35, i32 0, i32 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.36, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.37, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.38, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.39, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.40, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.41, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.42, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.43, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.44, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.45, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.46, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.47, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.48, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.49, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.50, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.51, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.52, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.53, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.51, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.54, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.55, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.56, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.57, i32 0, i32 0), i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.58, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.59, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.60, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.60, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.61, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.61, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.62, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.63, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.64, i32 0, i32 0), i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.65, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.66, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.67, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.68, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.69, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.70, i32 0, i32 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.71, i32 0, i32 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.72, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.73, i32 0, i32 0), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.74, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.75, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.76, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.77, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.78, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.79, i32 0, i32 0), i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.80, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.81, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.82, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.83, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.84, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.85, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.86, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.87, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.88, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.89, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.90, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.91, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.92, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.93, i32 0, i32 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.94, i32 0, i32 0), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.95, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.96, i32 0, i32 0), i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.97, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.98, i32 0, i32 0), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.99, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.100, i32 0, i32 0), i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.101, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.102, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.103, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.104, i32 0, i32 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.105, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.106, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.107, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.108, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.109, i32 0, i32 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.110, i32 0, i32 0), i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.111, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.112, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.113, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.114, i32 0, i32 0), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.115, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.116, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.117, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.118, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.119, i32 0, i32 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.120, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.121, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.122, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.123, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.124, i32 0, i32 0), i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.125, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.126, i32 0, i32 0), i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.127, i32 0, i32 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.128, i32 0, i32 0), i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.129, i32 0, i32 0), i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.130, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.131, i32 0, i32 0), i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.132, i32 0, i32 0), i8* getelementptr inbounds ([34 x i8], [34 x i8]* @.str.133, i32 0, i32 0), i8* getelementptr inbounds ([46 x i8], [46 x i8]* @.str.134, i32 0, i32 0), i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.135, i32 0, i32 0), i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.136, i32 0, i32 0), i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.137, i32 0, i32 0), i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.138, i32 0, i32 0), i8* getelementptr inbounds ([39 x i8], [39 x i8]* @.str.139, i32 0, i32 0), i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.140, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.141, i32 0, i32 0), i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.142, i32 0, i32 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.143, i32 0, i32 0), i8* getelementptr inbounds ([54 x i8], [54 x i8]* @.str.144, i32 0, i32 0), i8* getelementptr inbounds ([73 x i8], [73 x i8]* @.str.145, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.146, i32 0, i32 0), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.147, i32 0, i32 0), i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.148, i32 0, i32 0), i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.149, i32 0, i32 0), i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.150, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.151, i32 0, i32 0), i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.152, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.153, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.154, i32 0, i32 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.155, i32 0, i32 0), i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.156, i32 0, i32 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.157, i32 0, i32 0), i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.158, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.159, i32 0, i32 0), i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.160, i32 0, i32 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.161, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.162, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.163, i32 0, i32 0), i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.164, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.165, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.166, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.167, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.168, i32 0, i32 0), i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.169, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.170, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.171, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.172, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.173, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.174, i32 0, i32 0), i8* getelementptr inbounds ([34 x i8], [34 x i8]* @.str.175, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.176, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.177, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.178, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.179, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.180, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.181, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.182, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.183, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.184, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.185, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.186, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.187, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.188, i32 0, i32 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.189, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.190, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.191, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.191, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.192, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.193, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.194, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.195, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.196, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.197, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.198, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.199, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.200, i32 0, i32 0), i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.201, i32 0, i32 0), i8* getelementptr inbounds ([33 x i8], [33 x i8]* @.str.202, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.203, i32 0, i32 0), i8* getelementptr inbounds ([40 x i8], [40 x i8]* @.str.204, i32 0, i32 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.205, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.206, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.207, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.208, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.209, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.210, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.211, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.212, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.213, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.214, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.215, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.216, i32 0, i32 0), i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.217, i32 0, i32 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.218, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.219, i32 0, i32 0), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.220, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.221, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.222, i32 0, i32 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.223, i32 0, i32 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.224, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.225, i32 0, i32 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.226, i32 0, i32 0), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.227, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.228, i32 0, i32 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.229, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.230, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.231, i32 0, i32 0)], align 16
+@Kotlin_callsCheckerGoodFunctionNames = internal unnamed_addr global [236 x i8*] [i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.9.117, i32 0, i32 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.1.10, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.2.11, i32 0, i32 0), i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.3.12, i32 0, i32 0), i8* getelementptr inbounds ([58 x i8], [58 x i8]* @.str.4.13, i32 0, i32 0), i8* getelementptr inbounds ([58 x i8], [58 x i8]* @.str.5.14, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.6.15, i32 0, i32 0), i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.7.16, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.8.17, i32 0, i32 0), i8* getelementptr inbounds ([46 x i8], [46 x i8]* @.str.9.18, i32 0, i32 0), i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.10.118, i32 0, i32 0), i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.11.19, i32 0, i32 0), i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.12.20, i32 0, i32 0), i8* getelementptr inbounds ([68 x i8], [68 x i8]* @.str.13.21, i32 0, i32 0), i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.14.22, i32 0, i32 0), i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.15.119, i32 0, i32 0), i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.16.23, i32 0, i32 0), i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.17.24, i32 0, i32 0), i8* getelementptr inbounds ([44 x i8], [44 x i8]* @.str.18.120, i32 0, i32 0), i8* getelementptr inbounds ([53 x i8], [53 x i8]* @.str.19.25, i32 0, i32 0), i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.20.26, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.21.121, i32 0, i32 0), i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.22.27, i32 0, i32 0), i8* getelementptr inbounds ([66 x i8], [66 x i8]* @.str.23.28, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.24.122, i32 0, i32 0), i8* getelementptr inbounds ([58 x i8], [58 x i8]* @.str.25.123, i32 0, i32 0), i8* getelementptr inbounds ([60 x i8], [60 x i8]* @.str.26, i32 0, i32 0), i8* getelementptr inbounds ([61 x i8], [61 x i8]* @.str.27, i32 0, i32 0), i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.28.124, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.29.125, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.30.126, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.31.127, i32 0, i32 0), i8* getelementptr inbounds ([41 x i8], [41 x i8]* @.str.32, i32 0, i32 0), i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.33, i32 0, i32 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.34, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.35, i32 0, i32 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.36, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.37, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.38, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.39, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.40, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.41, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.42, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.43, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.44, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.45, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.46, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.47, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.48, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.49, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.50, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.51, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.52, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.53, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.51, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.54, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.55, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.56, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.57, i32 0, i32 0), i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.58, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.59, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.60, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.60, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.61, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.61, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.62, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.63, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.64, i32 0, i32 0), i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.65, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.66, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.67, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.68, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.69, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.70, i32 0, i32 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.71, i32 0, i32 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.72, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.73, i32 0, i32 0), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.74, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.75, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.76, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.77, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.78, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.79, i32 0, i32 0), i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.80, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.81, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.82, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.83, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.84, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.85, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.86, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.87, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.88, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.89, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.90, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.91, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.92, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.93, i32 0, i32 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.94, i32 0, i32 0), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.95, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.96, i32 0, i32 0), i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.97, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.98, i32 0, i32 0), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.99, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.100, i32 0, i32 0), i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.101, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.102, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.103, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.104, i32 0, i32 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.105, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.106, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.107, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.108, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.109, i32 0, i32 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.110, i32 0, i32 0), i8* getelementptr inbounds ([4 x i8], [4 x i8]* @.str.111, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.112, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.113, i32 0, i32 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.114, i32 0, i32 0), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.115, i32 0, i32 0), i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.116, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.117, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.118, i32 0, i32 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.119, i32 0, i32 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.120, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.121, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.122, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.123, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.124, i32 0, i32 0), i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.125, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.126, i32 0, i32 0), i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.127, i32 0, i32 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.128, i32 0, i32 0), i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.129, i32 0, i32 0), i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.130, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.131, i32 0, i32 0), i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.132, i32 0, i32 0), i8* getelementptr inbounds ([34 x i8], [34 x i8]* @.str.133, i32 0, i32 0), i8* getelementptr inbounds ([46 x i8], [46 x i8]* @.str.134, i32 0, i32 0), i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.135, i32 0, i32 0), i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.136, i32 0, i32 0), i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.137, i32 0, i32 0), i8* getelementptr inbounds ([38 x i8], [38 x i8]* @.str.138, i32 0, i32 0), i8* getelementptr inbounds ([39 x i8], [39 x i8]* @.str.139, i32 0, i32 0), i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.140, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.141, i32 0, i32 0), i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.142, i32 0, i32 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.143, i32 0, i32 0), i8* getelementptr inbounds ([54 x i8], [54 x i8]* @.str.144, i32 0, i32 0), i8* getelementptr inbounds ([73 x i8], [73 x i8]* @.str.145, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.146, i32 0, i32 0), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.147, i32 0, i32 0), i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.148, i32 0, i32 0), i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.149, i32 0, i32 0), i8* getelementptr inbounds ([27 x i8], [27 x i8]* @.str.150, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.151, i32 0, i32 0), i8* getelementptr inbounds ([30 x i8], [30 x i8]* @.str.152, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.153, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.154, i32 0, i32 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.155, i32 0, i32 0), i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.156, i32 0, i32 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.157, i32 0, i32 0), i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.158, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.159, i32 0, i32 0), i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.160, i32 0, i32 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.161, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.162, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.163, i32 0, i32 0), i8* getelementptr inbounds ([23 x i8], [23 x i8]* @.str.164, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.165, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.166, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.167, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.168, i32 0, i32 0), i8* getelementptr inbounds ([28 x i8], [28 x i8]* @.str.169, i32 0, i32 0), i8* getelementptr inbounds ([25 x i8], [25 x i8]* @.str.170, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.171, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.172, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.173, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.174, i32 0, i32 0), i8* getelementptr inbounds ([34 x i8], [34 x i8]* @.str.175, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.176, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.177, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.178, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.179, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.180, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.181, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.182, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.183, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.184, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.185, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.186, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.187, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.188, i32 0, i32 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.189, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.190, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.191, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.191, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.192, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.193, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.194, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.195, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.196, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.197, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.198, i32 0, i32 0), i8* getelementptr inbounds ([15 x i8], [15 x i8]* @.str.199, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.200, i32 0, i32 0), i8* getelementptr inbounds ([22 x i8], [22 x i8]* @.str.201, i32 0, i32 0), i8* getelementptr inbounds ([33 x i8], [33 x i8]* @.str.202, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.203, i32 0, i32 0), i8* getelementptr inbounds ([40 x i8], [40 x i8]* @.str.204, i32 0, i32 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.205, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.206, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.207, i32 0, i32 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.208, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.209, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.210, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.211, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.212, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.213, i32 0, i32 0), i8* getelementptr inbounds ([17 x i8], [17 x i8]* @.str.214, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.215, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.216, i32 0, i32 0), i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.217, i32 0, i32 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.218, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.219, i32 0, i32 0), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.220, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.221, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.222, i32 0, i32 0), i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.223, i32 0, i32 0), i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.224, i32 0, i32 0), i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.225, i32 0, i32 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.226, i32 0, i32 0), i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.227, i32 0, i32 0), i8* getelementptr inbounds ([12 x i8], [12 x i8]* @.str.228, i32 0, i32 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.229, i32 0, i32 0), i8* getelementptr inbounds ([14 x i8], [14 x i8]* @.str.230, i32 0, i32 0), i8* getelementptr inbounds ([16 x i8], [16 x i8]* @.str.231, i32 0, i32 0)], align 16
 @.str.9.117 = private unnamed_addr constant [11 x i8] c"\01_mprotect\00", align 1
 @.str.1.10 = private unnamed_addr constant [9 x i8] c"mprotect\00", align 1
 @.str.2.11 = private unnamed_addr constant [15 x i8] c"posix_memalign\00", align 1
@@ -1180,7 +1182,7 @@
 @_mi_heap_default = internal thread_local(initialexec) unnamed_addr global %struct.mi_heap_s* @_mi_heap_empty, align 8
 @_mi_heap_main = internal global { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 } { %struct.mi_tld_s* @tld_main, [129 x %struct.mi_page_s*] [%struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* @_mi_page_empty], [75 x %struct.mi_page_queue_s] [%struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 8 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 8 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 16 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 24 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 32 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 40 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 48 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 56 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 64 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 80 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 96 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 112 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 128 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 160 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 192 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 224 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 256 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 320 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 384 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 448 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 512 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 640 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 768 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 896 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 1024 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 1280 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 1536 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 1792 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 2048 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 2560 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 3072 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 3584 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 4096 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 5120 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 6144 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 7168 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 8192 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 10240 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 12288 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 14336 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 16384 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 20480 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 24576 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 28672 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 32768 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 40960 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 49152 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 57344 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 65536 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 81920 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 98304 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 114688 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 131072 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 163840 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 196608 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 229376 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 262144 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 327680 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 393216 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 458752 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 524288 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 655360 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 786432 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 917504 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 1048576 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 1310720 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 1572864 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 1835008 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 2097152 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 2621440 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 3145728 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 3670016 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 4194304 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 2097160 }, %struct.mi_page_queue_s { %struct.mi_page_s* null, %struct.mi_page_s* null, i64 2097168 }], %"class.kotlin::gc::GCHandle"* null, i64 0, i64 0, [2 x i64] zeroinitializer, { <{ i32, [15 x i32] }>, [16 x i32], i32 } { <{ i32, [15 x i32] }> <{ i32 -2073254261, [15 x i32] zeroinitializer }>, [16 x i32] zeroinitializer, i32 0 }, i64 0, i64 74, i64 0, %struct.mi_heap_s* null, i8 0 }, align 8
 @tld_main = internal global %struct.mi_tld_s { i64 0, i8 0, %struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*), %struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*), %struct.mi_segments_tld_s { %struct.mi_segment_queue_s zeroinitializer, %struct.mi_segment_queue_s zeroinitializer, %struct.mi_page_queue_s zeroinitializer, i64 0, i64 0, i64 0, i64 0, i64 0, i64 0, %struct.mi_segment_s* null, %struct.mi_stats_s* bitcast (i8* getelementptr (i8, i8* bitcast (%struct.mi_tld_s* @tld_main to i8*), i64 176) to %struct.mi_stats_s*), %struct.mi_os_tld_s* bitcast (i8* getelementptr (i8, i8* bitcast (%struct.mi_tld_s* @tld_main to i8*), i64 160) to %struct.mi_os_tld_s*) }, %struct.mi_os_tld_s { i64 0, %struct.mi_stats_s* bitcast (i8* getelementptr (i8, i8* bitcast (%struct.mi_tld_s* @tld_main to i8*), i64 176) to %struct.mi_stats_s*) }, %struct.mi_stats_s zeroinitializer }, align 8
-@_mi_process_is_initialized = internal unnamed_addr global i1 false, align 1
+@_mi_process_is_initialized = internal unnamed_addr global i8 0, align 1
 @_mi_stats_main = internal global %struct.mi_stats_s zeroinitializer, align 64
 @_mi_heap_default_key = internal global i32 -1, align 4
 @os_preloading = internal unnamed_addr global i1 false, align 1
@@ -1395,11 +1397,11 @@
   %objHeader = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %5, i64 0, i32 0
   %typeInfoOrMeta_ = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %5, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_, align 8
-  %8 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %8 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %9 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
   %10 = bitcast [12 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %11 = bitcast %"class.kotlin::mm::ShadowStack"* %9 to i64*
-  %12 = load i64, i64* %11, align 8, !tbaa !7
+  %12 = load atomic i64, i64* %11 unordered, align 8, !tbaa !7
   %13 = getelementptr inbounds [12 x %struct.ObjHeader*], [12 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %14 = bitcast %struct.ObjHeader** %13 to i64*
   store i64 %12, i64* %14, align 8, !tbaa !9
@@ -1438,7 +1440,7 @@
   %33 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#toString(){}kotlin.String"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader** nonnull %25)
   %34 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 6
   %35 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %34 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %36 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %35, align 8, !tbaa !3
+  %36 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %35 unordered, align 8, !tbaa !3
   %37 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %36, i64 0, i32 2, i32 1
   %38 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %37, i64 56) #37
   %39 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %38, i64 1
@@ -1458,7 +1460,7 @@
   %45 = getelementptr inbounds [12 x %struct.ObjHeader*], [12 x %struct.ObjHeader*]* %3, i64 0, i64 10
   %46 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 6
   %47 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %46 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %48 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %47, align 8, !tbaa !3
+  %48 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %47 unordered, align 8, !tbaa !3
   %49 = zext i32 %1 to i64
   %50 = shl nuw nsw i64 %49, 3
   %51 = add nuw nsw i64 %50, 31
@@ -1479,7 +1481,7 @@
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %56, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %62, align 8, !tbaa !3
   %63 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %64 = bitcast %struct.ObjHeader* %63 to i32*
-  %65 = load i32, i32* %64, align 8, !tbaa !18
+  %65 = load atomic i32, i32* %64 unordered, align 8, !tbaa !18
   %66 = icmp slt i32 %65, %1
   %spec.select = select i1 %66, i32 %65, i32 %1
   %67 = bitcast %struct.ObjHeader* %0 to i64*
@@ -1489,7 +1491,7 @@
   %71 = load atomic volatile i64, i64* %70 monotonic, align 8
   %72 = inttoptr i64 %71 to %struct.TypeInfo*
   %73 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %72, i64 0, i32 14
-  %74 = load i32, i32* %73, align 4, !tbaa !19
+  %74 = load atomic i32, i32* %73 unordered, align 4, !tbaa !19
   %75 = icmp eq i32 %74, 72
   br i1 %75, label %label_.i, label %label_1.i
 
@@ -1505,7 +1507,7 @@
   %80 = load atomic volatile i64, i64* %79 monotonic, align 8
   %81 = inttoptr i64 %80 to %struct.TypeInfo*
   %82 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %81, i64 0, i32 14
-  %83 = load i32, i32* %82, align 4, !tbaa !19
+  %83 = load atomic i32, i32* %82 unordered, align 4, !tbaa !19
   %84 = icmp eq i32 %83, 72
   br i1 %84, label %label_2.i, label %label_3.i
 
@@ -1518,12 +1520,12 @@
   br i1 %85, label %86, label %92
 
 86:                                               ; preds = %label_2.i
-  %87 = load i32, i32* %64, align 8, !tbaa !18
+  %87 = load atomic i32, i32* %64 unordered, align 8, !tbaa !18
   %88 = icmp ult i32 %87, %spec.select
   br i1 %88, label %92, label %89
 
 89:                                               ; preds = %86
-  %90 = load i32, i32* %60, align 8, !tbaa !18
+  %90 = load atomic i32, i32* %60 unordered, align 8, !tbaa !18
   %91 = icmp ult i32 %90, %spec.select
   br i1 %91, label %92, label %93
 
@@ -1540,140 +1542,107 @@
   %97 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %54, i64 4
   %98 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %99 = zext i32 %spec.select to i64
-  %min.iters.check = icmp eq i32 %spec.select, 1
-  br i1 %min.iters.check, label %scalar.ph, label %vector.memcheck
-
-vector.memcheck:                                  ; preds = %96
-  %100 = add nuw nsw i64 %99, 4
-  %scevgep = getelementptr %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %54, i64 %100
-  %101 = add nuw nsw i64 %99, 2
-  %scevgep2 = getelementptr %struct.ObjHeader, %struct.ObjHeader* %0, i64 %101
-  %102 = bitcast %struct.ObjHeader* %scevgep2 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
-  %bound0 = icmp ult %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, %102
-  %103 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %scevgep to %struct.ObjHeader*
-  %bound1 = icmp ult %struct.ObjHeader* %98, %103
-  %found.conflict = and i1 %bound0, %bound1
-  br i1 %found.conflict, label %scalar.ph, label %vector.ph
-
-vector.ph:                                        ; preds = %vector.memcheck
-  %n.vec = and i64 %99, 4294967294
-  br label %vector.body
+  %100 = add nsw i64 %99, -1
+  %xtraiter = and i64 %99, 7
+  %101 = icmp ult i64 %100, 7
+  br i1 %101, label %epilogue.loopexit.unr-lcssa, label %.new
 
-vector.body:                                      ; preds = %vector.body, %vector.ph
-  %index = phi i64 [ 0, %vector.ph ], [ %index.next, %vector.body ]
-  %104 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %index
-  %105 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %index
-  %106 = bitcast %struct.ObjHeader* %105 to <2 x i64>*
-  %wide.load = load <2 x i64>, <2 x i64>* %106, align 8, !tbaa !3, !alias.scope !21
-  %107 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %104 to <2 x i64>*
-  store <2 x i64> %wide.load, <2 x i64>* %107, align 8, !tbaa !3, !alias.scope !24, !noalias !21
-  %index.next = add i64 %index, 2
-  %108 = icmp eq i64 %index.next, %n.vec
-  br i1 %108, label %middle.block, label %vector.body, !llvm.loop !26
+.new:                                             ; preds = %96
+  %unroll_iter = and i64 %99, 4294967288
+  br label %102
 
-middle.block:                                     ; preds = %vector.body
-  %cmp.n = icmp eq i64 %n.vec, %99
-  br i1 %cmp.n, label %epilogue, label %scalar.ph
+102:                                              ; preds = %102, %.new
+  %103 = phi i64 [ 0, %.new ], [ %151, %102 ]
+  %niter = phi i64 [ %unroll_iter, %.new ], [ %niter.nsub.7, %102 ]
+  %104 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %103
+  %105 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %103
+  %106 = bitcast %struct.ObjHeader* %105 to i64*
+  %107 = load atomic i64, i64* %106 unordered, align 8, !tbaa !3
+  %108 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %104 to i64*
+  store i64 %107, i64* %108, align 8, !tbaa !3
+  %109 = or i64 %103, 1
+  %110 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %109
+  %111 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %109
+  %112 = bitcast %struct.ObjHeader* %111 to i64*
+  %113 = load atomic i64, i64* %112 unordered, align 8, !tbaa !3
+  %114 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %110 to i64*
+  store i64 %113, i64* %114, align 8, !tbaa !3
+  %115 = or i64 %103, 2
+  %116 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %115
+  %117 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %115
+  %118 = bitcast %struct.ObjHeader* %117 to i64*
+  %119 = load atomic i64, i64* %118 unordered, align 8, !tbaa !3
+  %120 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %116 to i64*
+  store i64 %119, i64* %120, align 8, !tbaa !3
+  %121 = or i64 %103, 3
+  %122 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %121
+  %123 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %121
+  %124 = bitcast %struct.ObjHeader* %123 to i64*
+  %125 = load atomic i64, i64* %124 unordered, align 8, !tbaa !3
+  %126 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %122 to i64*
+  store i64 %125, i64* %126, align 8, !tbaa !3
+  %127 = or i64 %103, 4
+  %128 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %127
+  %129 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %127
+  %130 = bitcast %struct.ObjHeader* %129 to i64*
+  %131 = load atomic i64, i64* %130 unordered, align 8, !tbaa !3
+  %132 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %128 to i64*
+  store i64 %131, i64* %132, align 8, !tbaa !3
+  %133 = or i64 %103, 5
+  %134 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %133
+  %135 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %133
+  %136 = bitcast %struct.ObjHeader* %135 to i64*
+  %137 = load atomic i64, i64* %136 unordered, align 8, !tbaa !3
+  %138 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %134 to i64*
+  store i64 %137, i64* %138, align 8, !tbaa !3
+  %139 = or i64 %103, 6
+  %140 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %139
+  %141 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %139
+  %142 = bitcast %struct.ObjHeader* %141 to i64*
+  %143 = load atomic i64, i64* %142 unordered, align 8, !tbaa !3
+  %144 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %140 to i64*
+  store i64 %143, i64* %144, align 8, !tbaa !3
+  %145 = or i64 %103, 7
+  %146 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %145
+  %147 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %145
+  %148 = bitcast %struct.ObjHeader* %147 to i64*
+  %149 = load atomic i64, i64* %148 unordered, align 8, !tbaa !3
+  %150 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %146 to i64*
+  store i64 %149, i64* %150, align 8, !tbaa !3
+  %151 = add nuw nsw i64 %103, 8
+  %niter.nsub.7 = add i64 %niter, -8
+  %niter.ncmp.7 = icmp eq i64 %niter.nsub.7, 0
+  br i1 %niter.ncmp.7, label %epilogue.loopexit.unr-lcssa, label %102
 
-scalar.ph:                                        ; preds = %middle.block, %vector.memcheck, %96
-  %bc.resume.val = phi i64 [ %n.vec, %middle.block ], [ 0, %96 ], [ 0, %vector.memcheck ]
-  %109 = sub nsw i64 %99, %bc.resume.val
-  %110 = xor i64 %bc.resume.val, -1
-  %111 = add nsw i64 %110, %99
-  %xtraiter = and i64 %109, 7
+epilogue.loopexit.unr-lcssa:                      ; preds = %102, %96
+  %.unr = phi i64 [ 0, %96 ], [ %151, %102 ]
   %lcmp.mod.not = icmp eq i64 %xtraiter, 0
-  br i1 %lcmp.mod.not, label %.prol.loopexit, label %.prol.preheader
-
-.prol.preheader:                                  ; preds = %.prol.preheader, %scalar.ph
-  %112 = phi i64 [ %118, %.prol.preheader ], [ %bc.resume.val, %scalar.ph ]
-  %prol.iter = phi i64 [ %prol.iter.sub, %.prol.preheader ], [ %xtraiter, %scalar.ph ]
-  %113 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %112
-  %114 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %112
-  %115 = bitcast %struct.ObjHeader* %114 to i64*
-  %116 = load i64, i64* %115, align 8, !tbaa !3
-  %117 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %113 to i64*
-  store i64 %116, i64* %117, align 8, !tbaa !3
-  %118 = add nuw nsw i64 %112, 1
-  %prol.iter.sub = add i64 %prol.iter, -1
-  %prol.iter.cmp.not = icmp eq i64 %prol.iter.sub, 0
-  br i1 %prol.iter.cmp.not, label %.prol.loopexit, label %.prol.preheader, !llvm.loop !28
-
-.prol.loopexit:                                   ; preds = %.prol.preheader, %scalar.ph
-  %.unr = phi i64 [ %bc.resume.val, %scalar.ph ], [ %118, %.prol.preheader ]
-  %119 = icmp ult i64 %111, 7
-  br i1 %119, label %epilogue, label %scalar.ph.new
+  br i1 %lcmp.mod.not, label %epilogue, label %.epil.preheader
 
-scalar.ph.new:                                    ; preds = %scalar.ph.new, %.prol.loopexit
-  %120 = phi i64 [ %168, %scalar.ph.new ], [ %.unr, %.prol.loopexit ]
-  %121 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %120
-  %122 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %120
-  %123 = bitcast %struct.ObjHeader* %122 to i64*
-  %124 = load i64, i64* %123, align 8, !tbaa !3
-  %125 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %121 to i64*
-  store i64 %124, i64* %125, align 8, !tbaa !3
-  %126 = add nuw nsw i64 %120, 1
-  %127 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %126
-  %128 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %126
-  %129 = bitcast %struct.ObjHeader* %128 to i64*
-  %130 = load i64, i64* %129, align 8, !tbaa !3
-  %131 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %127 to i64*
-  store i64 %130, i64* %131, align 8, !tbaa !3
-  %132 = add nuw nsw i64 %120, 2
-  %133 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %132
-  %134 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %132
-  %135 = bitcast %struct.ObjHeader* %134 to i64*
-  %136 = load i64, i64* %135, align 8, !tbaa !3
-  %137 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %133 to i64*
-  store i64 %136, i64* %137, align 8, !tbaa !3
-  %138 = add nuw nsw i64 %120, 3
-  %139 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %138
-  %140 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %138
-  %141 = bitcast %struct.ObjHeader* %140 to i64*
-  %142 = load i64, i64* %141, align 8, !tbaa !3
-  %143 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %139 to i64*
-  store i64 %142, i64* %143, align 8, !tbaa !3
-  %144 = add nuw nsw i64 %120, 4
-  %145 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %144
-  %146 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %144
-  %147 = bitcast %struct.ObjHeader* %146 to i64*
-  %148 = load i64, i64* %147, align 8, !tbaa !3
-  %149 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %145 to i64*
-  store i64 %148, i64* %149, align 8, !tbaa !3
-  %150 = add nuw nsw i64 %120, 5
-  %151 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %150
-  %152 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %150
-  %153 = bitcast %struct.ObjHeader* %152 to i64*
-  %154 = load i64, i64* %153, align 8, !tbaa !3
-  %155 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %151 to i64*
-  store i64 %154, i64* %155, align 8, !tbaa !3
-  %156 = add nuw nsw i64 %120, 6
-  %157 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %156
-  %158 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %156
-  %159 = bitcast %struct.ObjHeader* %158 to i64*
-  %160 = load i64, i64* %159, align 8, !tbaa !3
-  %161 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %157 to i64*
-  store i64 %160, i64* %161, align 8, !tbaa !3
-  %162 = add nuw nsw i64 %120, 7
-  %163 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %162
-  %164 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %162
-  %165 = bitcast %struct.ObjHeader* %164 to i64*
-  %166 = load i64, i64* %165, align 8, !tbaa !3
-  %167 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %163 to i64*
-  store i64 %166, i64* %167, align 8, !tbaa !3
-  %168 = add nuw nsw i64 %120, 8
-  %169 = icmp eq i64 %168, %99
-  br i1 %169, label %epilogue, label %scalar.ph.new, !llvm.loop !30
+.epil.preheader:                                  ; preds = %.epil.preheader, %epilogue.loopexit.unr-lcssa
+  %152 = phi i64 [ %158, %.epil.preheader ], [ %.unr, %epilogue.loopexit.unr-lcssa ]
+  %epil.iter = phi i64 [ %epil.iter.sub, %.epil.preheader ], [ %xtraiter, %epilogue.loopexit.unr-lcssa ]
+  %153 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 %152
+  %154 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %152
+  %155 = bitcast %struct.ObjHeader* %154 to i64*
+  %156 = load atomic i64, i64* %155 unordered, align 8, !tbaa !3
+  %157 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %153 to i64*
+  store i64 %156, i64* %157, align 8, !tbaa !3
+  %158 = add nuw nsw i64 %152, 1
+  %epil.iter.sub = add i64 %epil.iter, -1
+  %epil.iter.cmp.not = icmp eq i64 %epil.iter.sub, 0
+  br i1 %epil.iter.cmp.not, label %epilogue, label %.epil.preheader, !llvm.loop !21
 
-epilogue:                                         ; preds = %scalar.ph.new, %.prol.loopexit, %middle.block, %93
-  %170 = getelementptr inbounds [12 x %struct.ObjHeader*], [12 x %struct.ObjHeader*]* %3, i64 0, i64 11
-  %171 = bitcast %struct.ObjHeader** %170 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %56, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %171, align 8, !tbaa !3
-  %172 = bitcast %struct.ObjHeader** %2 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %56, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %172, align 8, !tbaa !3
-  %173 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
-  %174 = load i64, i64* %14, align 8, !tbaa !9
-  %175 = bitcast %"class.kotlin::mm::ShadowStack"* %173 to i64*
-  store i64 %174, i64* %175, align 8, !tbaa !7
+epilogue:                                         ; preds = %.epil.preheader, %epilogue.loopexit.unr-lcssa, %93
+  %159 = getelementptr inbounds [12 x %struct.ObjHeader*], [12 x %struct.ObjHeader*]* %3, i64 0, i64 11
+  %160 = bitcast %struct.ObjHeader** %159 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %56, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %160, align 8, !tbaa !3
+  %161 = bitcast %struct.ObjHeader** %2 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %56, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %161, align 8, !tbaa !3
+  %162 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
+  %163 = load atomic i64, i64* %14 unordered, align 8, !tbaa !9
+  %164 = bitcast %"class.kotlin::mm::ShadowStack"* %162 to i64*
+  store i64 %163, i64* %164, align 8, !tbaa !7
   ret %struct.ObjHeader* %61
 }
 
@@ -1690,11 +1659,11 @@
   %objHeader = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %5, i64 0, i32 0
   %typeInfoOrMeta_ = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %5, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_, align 8
-  %8 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %8 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %9 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
   %10 = bitcast [11 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %11 = bitcast %"class.kotlin::mm::ShadowStack"* %9 to i64*
-  %12 = load i64, i64* %11, align 8, !tbaa !7
+  %12 = load atomic i64, i64* %11 unordered, align 8, !tbaa !7
   %13 = getelementptr inbounds [11 x %struct.ObjHeader*], [11 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %14 = bitcast %struct.ObjHeader** %13 to i64*
   store i64 %12, i64* %14, align 8, !tbaa !9
@@ -1733,7 +1702,7 @@
   %33 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#toString(){}kotlin.String"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader** nonnull %25)
   %34 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 6
   %35 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %34 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %36 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %35, align 8, !tbaa !3
+  %36 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %35 unordered, align 8, !tbaa !3
   %37 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %36, i64 0, i32 2, i32 1
   %38 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %37, i64 56) #37
   %39 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %38, i64 1
@@ -1753,7 +1722,7 @@
   %45 = getelementptr inbounds [11 x %struct.ObjHeader*], [11 x %struct.ObjHeader*]* %3, i64 0, i64 9
   %46 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 6
   %47 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %46 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %48 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %47, align 8, !tbaa !3
+  %48 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %47 unordered, align 8, !tbaa !3
   %49 = zext i32 %1 to i64
   %50 = shl nuw nsw i64 %49, 2
   %51 = add nuw nsw i64 %50, 31
@@ -1773,7 +1742,7 @@
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %56, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %61, align 8, !tbaa !3
   %62 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %63 = bitcast %struct.ObjHeader* %62 to i32*
-  %64 = load i32, i32* %63, align 8, !tbaa !18
+  %64 = load atomic i32, i32* %63 unordered, align 8, !tbaa !18
   %65 = icmp slt i32 %64, %1
   br i1 %65, label %call_success10, label %call_success10.thread
 
@@ -1783,12 +1752,12 @@
 
 call_success10.thread:                            ; preds = %call_success10, %call_success9
   %67 = phi i32 [ %64, %call_success10 ], [ %1, %call_success9 ]
-  %68 = load i32, i32* %63, align 8, !tbaa !18
+  %68 = load atomic i32, i32* %63 unordered, align 8, !tbaa !18
   %69 = icmp ult i32 %68, %67
   br i1 %69, label %73, label %70
 
 70:                                               ; preds = %call_success10.thread
-  %71 = load i32, i32* %60, align 8, !tbaa !18
+  %71 = load atomic i32, i32* %60 unordered, align 8, !tbaa !18
   %72 = icmp ult i32 %71, %67
   br i1 %72, label %73, label %epilogue
 
@@ -1813,7 +1782,7 @@
   %85 = bitcast %struct.ObjHeader** %2 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %56, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %85, align 8, !tbaa !3
   %86 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
-  %87 = load i64, i64* %14, align 8, !tbaa !9
+  %87 = load atomic i64, i64* %14 unordered, align 8, !tbaa !9
   %88 = bitcast %"class.kotlin::mm::ShadowStack"* %86 to i64*
   store i64 %87, i64* %88, align 8, !tbaa !7
   ret %struct.ObjHeader* %84
@@ -1832,11 +1801,11 @@
   %objHeader = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %5, i64 0, i32 0
   %typeInfoOrMeta_ = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %5, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_, align 8
-  %8 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %8 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %9 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
   %10 = bitcast [11 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %11 = bitcast %"class.kotlin::mm::ShadowStack"* %9 to i64*
-  %12 = load i64, i64* %11, align 8, !tbaa !7
+  %12 = load atomic i64, i64* %11 unordered, align 8, !tbaa !7
   %13 = getelementptr inbounds [11 x %struct.ObjHeader*], [11 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %14 = bitcast %struct.ObjHeader** %13 to i64*
   store i64 %12, i64* %14, align 8, !tbaa !9
@@ -1875,7 +1844,7 @@
   %33 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#toString(){}kotlin.String"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader** nonnull %25)
   %34 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 6
   %35 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %34 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %36 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %35, align 8, !tbaa !3
+  %36 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %35 unordered, align 8, !tbaa !3
   %37 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %36, i64 0, i32 2, i32 1
   %38 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %37, i64 56) #37
   %39 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %38, i64 1
@@ -1895,7 +1864,7 @@
   %45 = getelementptr inbounds [11 x %struct.ObjHeader*], [11 x %struct.ObjHeader*]* %3, i64 0, i64 9
   %46 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 6
   %47 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %46 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %48 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %47, align 8, !tbaa !3
+  %48 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %47 unordered, align 8, !tbaa !3
   %49 = zext i32 %1 to i64
   %50 = shl nuw nsw i64 %49, 1
   %51 = add nuw nsw i64 %50, 31
@@ -1915,7 +1884,7 @@
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %56, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %61, align 8, !tbaa !3
   %62 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %63 = bitcast %struct.ObjHeader* %62 to i32*
-  %64 = load i32, i32* %63, align 8, !tbaa !18
+  %64 = load atomic i32, i32* %63 unordered, align 8, !tbaa !18
   %65 = icmp slt i32 %64, %1
   br i1 %65, label %call_success10, label %call_success10.thread
 
@@ -1925,12 +1894,12 @@
 
 call_success10.thread:                            ; preds = %call_success10, %call_success9
   %67 = phi i32 [ %64, %call_success10 ], [ %1, %call_success9 ]
-  %68 = load i32, i32* %63, align 8, !tbaa !18
+  %68 = load atomic i32, i32* %63 unordered, align 8, !tbaa !18
   %69 = icmp ult i32 %68, %67
   br i1 %69, label %73, label %70
 
 70:                                               ; preds = %call_success10.thread
-  %71 = load i32, i32* %60, align 8, !tbaa !18
+  %71 = load atomic i32, i32* %60 unordered, align 8, !tbaa !18
   %72 = icmp ult i32 %71, %67
   br i1 %72, label %73, label %epilogue
 
@@ -1955,7 +1924,7 @@
   %85 = bitcast %struct.ObjHeader** %2 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %56, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %85, align 8, !tbaa !3
   %86 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
-  %87 = load i64, i64* %14, align 8, !tbaa !9
+  %87 = load atomic i64, i64* %14 unordered, align 8, !tbaa !9
   %88 = bitcast %"class.kotlin::mm::ShadowStack"* %86 to i64*
   store i64 %87, i64* %88, align 8, !tbaa !7
   ret %struct.ObjHeader* %84
@@ -2002,11 +1971,11 @@
   %objHeader6 = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %10, i64 0, i32 0
   %typeInfoOrMeta_7 = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %10, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_7, align 8
-  %13 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %13 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %14 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %13, i64 0, i32 1, i32 5
   %15 = bitcast [10 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %16 = bitcast %"class.kotlin::mm::ShadowStack"* %14 to i64*
-  %17 = load i64, i64* %16, align 8, !tbaa !7
+  %17 = load atomic i64, i64* %16 unordered, align 8, !tbaa !7
   %18 = getelementptr inbounds [10 x %struct.ObjHeader*], [10 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %19 = bitcast %struct.ObjHeader** %18 to i64*
   store i64 %17, i64* %19, align 8, !tbaa !9
@@ -2044,7 +2013,7 @@
   %40 = load atomic volatile i64, i64* %39 monotonic, align 8
   %41 = inttoptr i64 %40 to %struct.TypeInfo*
   %42 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %41, i64 0, i32 14
-  %43 = load i32, i32* %42, align 4, !tbaa !19
+  %43 = load atomic i32, i32* %42 unordered, align 4, !tbaa !19
   %44 = icmp eq i32 %43, 202
   br i1 %44, label %call_success2, label %call_success2.thread
 
@@ -2075,7 +2044,7 @@
   %59 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %58 monotonic, align 8
   %60 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %59, i64 1, i32 1
   %61 = bitcast %struct.ExtendedTypeInfo** %60 to i32 (%struct.ObjHeader*)**
-  %62 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %61, align 8
+  %62 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %61 unordered, align 8
   %63 = call i32 %62(%struct.ObjHeader* %0)
   %64 = bitcast [12 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.lifetime.start.p0i8(i64 96, i8* nonnull %64)
@@ -2084,7 +2053,7 @@
   %65 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %13, i64 0, i32 1, i32 5
   %66 = bitcast [12 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %67 = bitcast %"class.kotlin::mm::ShadowStack"* %65 to i64*
-  %68 = load i64, i64* %67, align 8, !tbaa !7
+  %68 = load atomic i64, i64* %67 unordered, align 8, !tbaa !7
   %69 = getelementptr inbounds [12 x %struct.ObjHeader*], [12 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %70 = bitcast %struct.ObjHeader** %69 to i64*
   store i64 %68, i64* %70, align 8, !tbaa !9
@@ -2096,7 +2065,7 @@
   %74 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %66, i64 0, i32 3
   store i32 12, i32* %74, align 4, !tbaa !13
   %75 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %13, i64 0, i32 1, i32 5
-  %76 = load i64, i64* %70, align 8, !tbaa !9
+  %76 = load atomic i64, i64* %70 unordered, align 8, !tbaa !9
   %77 = bitcast %"class.kotlin::mm::ShadowStack"* %75 to i64*
   store i64 %76, i64* %77, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 96, i8* nonnull %64)
@@ -2110,7 +2079,7 @@
   %83 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#toString(){}kotlin.String"(%struct.ObjHeader* nonnull %objHeader6, %struct.ObjHeader** %1)
   store %struct.ObjHeader* %83, %struct.ObjHeader** %1, align 8, !tbaa !3
   %84 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %13, i64 0, i32 1, i32 5
-  %85 = load i64, i64* %19, align 8, !tbaa !9
+  %85 = load atomic i64, i64* %19 unordered, align 8, !tbaa !9
   %86 = bitcast %"class.kotlin::mm::ShadowStack"* %84 to i64*
   store i64 %85, i64* %86, align 8, !tbaa !7
   ret %struct.ObjHeader* %83
@@ -2143,7 +2112,7 @@
   %14 = load atomic volatile i64, i64* %13 monotonic, align 8
   %15 = inttoptr i64 %14 to %struct.TypeInfo*
   %16 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %15, i64 0, i32 14
-  %17 = load i32, i32* %16, align 4, !tbaa !19
+  %17 = load atomic i32, i32* %16 unordered, align 4, !tbaa !19
   %18 = icmp eq i32 %17, 82
   br i1 %18, label %when_case.i, label %epilogue
 
@@ -2233,7 +2202,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %epilogue
   %5 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %6 = bitcast %struct.ObjHeader* %5 to i32*
-  %7 = load i32, i32* %6, align 4
+  %7 = load atomic i32, i32* %6 unordered, align 4
   ret i32 %7
 }
 
@@ -2252,7 +2221,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
   %6 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %7 = bitcast %struct.ObjHeader* %6 to %struct.ObjHeader**
-  %8 = load %struct.ObjHeader*, %struct.ObjHeader** %7, align 8
+  %8 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %7 unordered, align 8
   store %struct.ObjHeader* %8, %struct.ObjHeader** %1, align 8, !tbaa !3
   ret %struct.ObjHeader* %8
 }
@@ -2288,7 +2257,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %entry
   %6 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %7 = bitcast %struct.ObjHeader* %6 to i32*
-  %8 = load i32, i32* %7, align 4
+  %8 = load atomic i32, i32* %7 unordered, align 4
   %9 = icmp eq %struct.ObjHeader* %1, null
   br i1 %9, label %epilogue, label %instance_of_exit.i
 
@@ -2300,14 +2269,14 @@
   %14 = load atomic volatile i64, i64* %13 monotonic, align 8
   %15 = inttoptr i64 %14 to %struct.TypeInfo*
   %16 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %15, i64 0, i32 14
-  %17 = load i32, i32* %16, align 4, !tbaa !19
+  %17 = load atomic i32, i32* %16 unordered, align 4, !tbaa !19
   %18 = icmp eq i32 %17, 104
   br i1 %18, label %when_case.i, label %epilogue
 
 when_case.i:                                      ; preds = %instance_of_exit.i
   %19 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %1, i64 1
   %20 = bitcast %struct.ObjHeader* %19 to i32*
-  %21 = load i32, i32* %20, align 4
+  %21 = load atomic i32, i32* %20 unordered, align 4
   %22 = icmp eq i32 %21, %8
   br label %epilogue
 
@@ -2331,7 +2300,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %6, %epilogue
   %7 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %8 = bitcast %struct.ObjHeader* %7 to i32*
-  %9 = load i32, i32* %8, align 4
+  %9 = load atomic i32, i32* %8 unordered, align 4
   %10 = getelementptr inbounds [16 x i8], [16 x i8]* %2, i64 0, i64 0
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %10) #37
   call void (i8*, i64, i8*, ...) @_ZN5konan8snprintfEPcmPKcz(i8* nonnull %10, i64 16, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.157.845, i64 0, i64 0), i32 %9)
@@ -2356,7 +2325,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %epilogue
   %5 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %6 = bitcast %struct.ObjHeader* %5 to i32*
-  %7 = load i32, i32* %6, align 4
+  %7 = load atomic i32, i32* %6 unordered, align 4
   ret i32 %7
 }
 
@@ -2367,11 +2336,11 @@
   %.sub = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 0
   %3 = bitcast [4 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %3, i8 0, i32 32, i1 immarg false) #49
-  %4 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %4 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %5 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
   %6 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %7 = bitcast %"class.kotlin::mm::ShadowStack"* %5 to i64*
-  %8 = load i64, i64* %7, align 8, !tbaa !7
+  %8 = load atomic i64, i64* %7 unordered, align 8, !tbaa !7
   %9 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %10 = bitcast %struct.ObjHeader** %9 to i64*
   store i64 %8, i64* %10, align 8, !tbaa !9
@@ -2406,7 +2375,7 @@
   %22 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %23 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 6
   %24 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %23 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %25 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %24, align 8, !tbaa !3
+  %25 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %24 unordered, align 8, !tbaa !3
   %26 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %25, i64 0, i32 2, i32 1
   %27 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %26, i64 24) #37
   %28 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %27, i64 1
@@ -2427,7 +2396,7 @@
   %36 = phi %struct.ObjHeader* [ %21, %call_success1 ], [ %30, %when_exit ]
   store %struct.ObjHeader* %36, %struct.ObjHeader** %1, align 8, !tbaa !3
   %37 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %38 = load i64, i64* %10, align 8, !tbaa !9
+  %38 = load atomic i64, i64* %10 unordered, align 8, !tbaa !9
   %39 = bitcast %"class.kotlin::mm::ShadowStack"* %37 to i64*
   store i64 %38, i64* %39, align 8, !tbaa !7
   ret %struct.ObjHeader* %36
@@ -2465,7 +2434,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %epilogue
   %5 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %6 = bitcast %struct.ObjHeader* %5 to i32*
-  %7 = load i32, i32* %6, align 8, !tbaa !18
+  %7 = load atomic i32, i32* %6 unordered, align 8, !tbaa !18
   ret i32 %7
 }
 
@@ -2480,11 +2449,11 @@
   %6 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %4, i64 0, i64 3
   %7 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %4, i64 0, i64 4
   %8 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %4, i64 0, i64 5
-  %9 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %9 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %10 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
   %11 = bitcast [6 x %struct.ObjHeader*]* %4 to %struct.FrameOverlay.6*
   %12 = bitcast %"class.kotlin::mm::ShadowStack"* %10 to i64*
-  %13 = load i64, i64* %12, align 8, !tbaa !7
+  %13 = load atomic i64, i64* %12 unordered, align 8, !tbaa !7
   %14 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %4, i64 0, i64 1
   %15 = bitcast %struct.ObjHeader** %14 to i64*
   store i64 %13, i64* %15, align 8, !tbaa !9
@@ -2517,7 +2486,7 @@
   store %struct.ObjHeader* %28, %struct.ObjHeader** %30, align 8, !tbaa !3
   %31 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 6
   %32 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %31 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %33 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %32, align 8, !tbaa !3
+  %33 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %32 unordered, align 8, !tbaa !3
   %34 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %33, i64 0, i32 2, i32 1
   %35 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %34, i64 24) #37
   %36 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %35, i64 1
@@ -2533,7 +2502,7 @@
   store %struct.ObjHeader* %0, %struct.ObjHeader** %42, align 8, !tbaa !3
   %43 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 6
   %44 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %43 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %45 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %44, align 8, !tbaa !3
+  %45 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %44 unordered, align 8, !tbaa !3
   %46 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %45, i64 0, i32 2, i32 1
   %47 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %46, i64 40) #37
   %48 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %47, i64 1
@@ -2552,7 +2521,7 @@
   %55 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
   %56 = bitcast [6 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %57 = bitcast %"class.kotlin::mm::ShadowStack"* %55 to i64*
-  %58 = load i64, i64* %57, align 8, !tbaa !7
+  %58 = load atomic i64, i64* %57 unordered, align 8, !tbaa !7
   %59 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %60 = bitcast %struct.ObjHeader** %59 to i64*
   store i64 %58, i64* %60, align 8, !tbaa !9
@@ -2565,7 +2534,7 @@
   store i32 6, i32* %64, align 4, !tbaa !13
   %65 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 6
   %66 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %65 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %67 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %66, align 8, !tbaa !3
+  %67 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %66 unordered, align 8, !tbaa !3
   %68 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %67, i64 0, i32 2, i32 1
   %69 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %68, i64 32) #37
   %70 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %69, i64 1
@@ -2591,10 +2560,10 @@
 epilogue:                                         ; preds = %label_init.i.i, %Kotlin_mm_safePointFunctionPrologue.exit
   %79 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %3, i64 0, i64 5
   %80 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %3, i64 0, i64 4
-  %81 = load i64, i64* bitcast (%struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal" to i64*), align 8
+  %81 = load atomic i64, i64* bitcast (%struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal" to i64*) unordered, align 8
   %82 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 6
   %83 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %82 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %84 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %83, align 8, !tbaa !3
+  %84 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %83 unordered, align 8, !tbaa !3
   %85 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %84, i64 0, i32 2, i32 1
   %86 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %85, i64 32) #37
   %87 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %86, i64 1
@@ -2612,7 +2581,7 @@
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %88, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %94, align 8, !tbaa !3
   %95 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 6
   %96 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %95 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %97 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %96, align 8, !tbaa !3
+  %97 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %96 unordered, align 8, !tbaa !3
   %98 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %97, i64 0, i32 2, i32 1
   %99 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %98, i64 32) #37
   %100 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %99, i64 1
@@ -2632,7 +2601,7 @@
   %108 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
   %109 = bitcast [5 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %110 = bitcast %"class.kotlin::mm::ShadowStack"* %108 to i64*
-  %111 = load i64, i64* %110, align 8, !tbaa !7
+  %111 = load atomic i64, i64* %110 unordered, align 8, !tbaa !7
   %112 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %113 = bitcast %struct.ObjHeader** %112 to i64*
   store i64 %111, i64* %113, align 8, !tbaa !9
@@ -2645,7 +2614,7 @@
   store i32 5, i32* %117, align 4, !tbaa !13
   %118 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 6
   %119 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %118 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %120 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %119, align 8, !tbaa !3
+  %120 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %119 unordered, align 8, !tbaa !3
   %121 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %120, i64 0, i32 2, i32 1
   %122 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %121, i64 24) #37
   %123 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %122, i64 1
@@ -2663,7 +2632,7 @@
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %124, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %130, align 8, !tbaa !3
   %131 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 6
   %132 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %131 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %133 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %132, align 8, !tbaa !3
+  %133 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %132 unordered, align 8, !tbaa !3
   %134 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %133, i64 0, i32 2, i32 1
   %135 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %134, i64 24) #37
   %136 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %135, i64 1
@@ -2689,7 +2658,7 @@
   %147 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 4
   %148 = bitcast %struct.ObjHeader* %147 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %49, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %148, align 8, !tbaa !3
-  %149 = load i64, i64* %15, align 8, !tbaa !9
+  %149 = load atomic i64, i64* %15 unordered, align 8, !tbaa !9
   store i64 %149, i64* %145, align 8, !tbaa !7
   ret void
 }
@@ -2709,7 +2678,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
   %6 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %7 = bitcast %struct.ObjHeader* %6 to %struct.ObjHeader**
-  %8 = load %struct.ObjHeader*, %struct.ObjHeader** %7, align 8
+  %8 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %7 unordered, align 8
   store %struct.ObjHeader* %8, %struct.ObjHeader** %1, align 8, !tbaa !3
   ret %struct.ObjHeader* %8
 }
@@ -2729,7 +2698,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
   %6 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %7 = bitcast %struct.ObjHeader* %6 to %struct.ObjHeader**
-  %8 = load %struct.ObjHeader*, %struct.ObjHeader** %7, align 8
+  %8 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %7 unordered, align 8
   store %struct.ObjHeader* %8, %struct.ObjHeader** %1, align 8, !tbaa !3
   ret %struct.ObjHeader* %8
 }
@@ -2748,7 +2717,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %call_success
   %6 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 4
   %7 = bitcast %struct.ObjHeader* %6 to %struct.ObjHeader**
-  %8 = load %struct.ObjHeader*, %struct.ObjHeader** %7, align 8
+  %8 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %7 unordered, align 8
   %9 = bitcast %struct.ObjHeader* %8 to i64*
   %10 = load atomic volatile i64, i64* %9 monotonic, align 8
   %11 = and i64 %10, -4
@@ -2791,11 +2760,11 @@
   %objHeader = getelementptr inbounds %"kclassbody:kotlin.Throwable.ExceptionTraceBuilder#internal", %"kclassbody:kotlin.Throwable.ExceptionTraceBuilder#internal"* %9, i64 0, i32 0
   %typeInfoOrMeta_ = getelementptr inbounds %"kclassbody:kotlin.Throwable.ExceptionTraceBuilder#internal", %"kclassbody:kotlin.Throwable.ExceptionTraceBuilder#internal"* %9, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.Throwable.ExceptionTraceBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_, align 8
-  %12 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %12 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %13 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %14 = bitcast [4 x %struct.ObjHeader*]* %6 to %struct.FrameOverlay.6*
   %15 = bitcast %"class.kotlin::mm::ShadowStack"* %13 to i64*
-  %16 = load i64, i64* %15, align 8, !tbaa !7
+  %16 = load atomic i64, i64* %15 unordered, align 8, !tbaa !7
   %17 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %6, i64 0, i64 1
   %18 = bitcast %struct.ObjHeader** %17 to i64*
   store i64 %16, i64* %18, align 8, !tbaa !9
@@ -2826,7 +2795,7 @@
   %30 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %31 = bitcast [5 x %struct.ObjHeader*]* %4 to %struct.FrameOverlay.6*
   %32 = bitcast %"class.kotlin::mm::ShadowStack"* %30 to i64*
-  %33 = load i64, i64* %32, align 8, !tbaa !7
+  %33 = load atomic i64, i64* %32 unordered, align 8, !tbaa !7
   %34 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %4, i64 0, i64 1
   %35 = bitcast %struct.ObjHeader** %34 to i64*
   store i64 %33, i64* %35, align 8, !tbaa !9
@@ -2842,7 +2811,7 @@
   store %struct.ObjHeader* %0, %struct.ObjHeader** %41, align 8, !tbaa !3
   %42 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 6
   %43 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %42 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %44 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %43, align 8, !tbaa !3
+  %44 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %43 unordered, align 8, !tbaa !3
   %45 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %44, i64 0, i32 2, i32 1
   %46 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %45, i64 32) #37
   %47 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %46, i64 1
@@ -2860,7 +2829,7 @@
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %48, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %54, align 8, !tbaa !3
   %55 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 6
   %56 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %55 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %57 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %56, align 8, !tbaa !3
+  %57 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %56 unordered, align 8, !tbaa !3
   %58 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %57, i64 0, i32 2, i32 1
   %59 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %58, i64 24) #37
   %60 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %59, i64 1
@@ -2879,7 +2848,7 @@
   %67 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %68 = bitcast [4 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %69 = bitcast %"class.kotlin::mm::ShadowStack"* %67 to i64*
-  %70 = load i64, i64* %69, align 8, !tbaa !7
+  %70 = load atomic i64, i64* %69 unordered, align 8, !tbaa !7
   %71 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %72 = bitcast %struct.ObjHeader** %71 to i64*
   store i64 %70, i64* %72, align 8, !tbaa !9
@@ -2892,7 +2861,7 @@
   store i32 4, i32* %76, align 4, !tbaa !13
   %77 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 6
   %78 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %77 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %79 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %78, align 8, !tbaa !3
+  %79 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %78 unordered, align 8, !tbaa !3
   %80 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %79, i64 0, i32 2, i32 1
   %81 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %80, i64 96) #37
   %82 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %81, i64 1
@@ -2913,7 +2882,7 @@
   %91 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %92 = bitcast [7 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %93 = bitcast %"class.kotlin::mm::ShadowStack"* %91 to i64*
-  %94 = load i64, i64* %93, align 8, !tbaa !7
+  %94 = load atomic i64, i64* %93 unordered, align 8, !tbaa !7
   %95 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %96 = bitcast %struct.ObjHeader** %95 to i64*
   store i64 %94, i64* %96, align 8, !tbaa !9
@@ -2926,7 +2895,7 @@
   store i32 7, i32* %100, align 4, !tbaa !13
   %101 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 6
   %102 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %101 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %103 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %102, align 8, !tbaa !3
+  %103 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %102 unordered, align 8, !tbaa !3
   %104 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %103, i64 0, i32 2, i32 1
   %105 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %104, i64 88) #37
   %106 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %105, i64 1
@@ -2942,7 +2911,7 @@
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %107, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %112, align 8, !tbaa !3
   %113 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 6
   %114 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %113 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %115 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %114, align 8, !tbaa !3
+  %115 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %114 unordered, align 8, !tbaa !3
   %116 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %115, i64 0, i32 2, i32 1
   %117 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %116, i64 56) #37
   %118 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %117, i64 1
@@ -2958,7 +2927,7 @@
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %119, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %124, align 8, !tbaa !3
   %125 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 6
   %126 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %125 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %127 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %126, align 8, !tbaa !3
+  %127 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %126 unordered, align 8, !tbaa !3
   %128 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %127, i64 0, i32 2, i32 1
   %129 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %128, i64 88) #37
   %130 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %129, i64 1
@@ -2995,7 +2964,7 @@
   %148 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %149 = bitcast [4 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
   %150 = bitcast %"class.kotlin::mm::ShadowStack"* %148 to i64*
-  %151 = load i64, i64* %150, align 8, !tbaa !7
+  %151 = load atomic i64, i64* %150 unordered, align 8, !tbaa !7
   %152 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 1
   %153 = bitcast %struct.ObjHeader** %152 to i64*
   store i64 %151, i64* %153, align 8, !tbaa !9
@@ -3008,25 +2977,25 @@
   store i32 4, i32* %157, align 4, !tbaa !13
   %158 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %81, i64 6
   %159 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %158 to %struct.ObjHeader**
-  %160 = load %struct.ObjHeader*, %struct.ObjHeader** %159, align 8
+  %160 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %159 unordered, align 8
   store %struct.ObjHeader* %160, %struct.ObjHeader** %147, align 8, !tbaa !3
   %161 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %160, i64 1
   %162 = bitcast %struct.ObjHeader* %161 to i32*
-  %163 = load i32, i32* %162, align 8, !tbaa !18
+  %163 = load atomic i32, i32* %162 unordered, align 8, !tbaa !18
   %164 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %165 = load i64, i64* %153, align 8, !tbaa !9
+  %165 = load atomic i64, i64* %153 unordered, align 8, !tbaa !9
   %166 = bitcast %"class.kotlin::mm::ShadowStack"* %164 to i64*
   store i64 %165, i64* %166, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %146) #37
   %167 = icmp eq i32 %163, 0
-  %168 = call i32 @llvm.ctlz.i32(i32 %163, i1 true) #37, !range !31
+  %168 = call i32 @llvm.ctlz.i32(i32 %163, i1 true) #37, !range !23
   %phi.bo = add nuw nsw i32 %168, 1
   %169 = select i1 %167, i32 33, i32 %phi.bo
   %170 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %81, i64 11
   %171 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %170 to i32*
   store i32 %169, i32* %171, align 8
   %172 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %173 = load i64, i64* %96, align 8, !tbaa !9
+  %173 = load atomic i64, i64* %96 unordered, align 8, !tbaa !9
   %174 = bitcast %"class.kotlin::mm::ShadowStack"* %172 to i64*
   store i64 %173, i64* %174, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 56, i8* nonnull %87) #37
@@ -3038,13 +3007,13 @@
   %178 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %objHeader, i64 3
   %179 = bitcast %struct.ObjHeader* %178 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %61, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %179, align 8, !tbaa !3
-  %180 = load i64, i64* %35, align 8, !tbaa !9
+  %180 = load atomic i64, i64* %35 unordered, align 8, !tbaa !9
   store i64 %180, i64* %177, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %27)
   %181 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %objHeader, i64 4
   %182 = bitcast %struct.ObjHeader* %181 to i1*
   store i1 true, i1* %182, align 8
-  %183 = load %struct.ObjHeader*, %struct.ObjHeader** %41, align 8
+  %183 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %41 unordered, align 8
   %184 = bitcast [9 x %struct.ObjHeader*]* %5 to i8*
   call void @llvm.lifetime.start.p0i8(i64 72, i8* nonnull %184)
   %.sub.i.i = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %5, i64 0, i64 0
@@ -3053,7 +3022,7 @@
   %185 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %186 = bitcast [9 x %struct.ObjHeader*]* %5 to %struct.FrameOverlay.6*
   %187 = bitcast %"class.kotlin::mm::ShadowStack"* %185 to i64*
-  %188 = load i64, i64* %187, align 8, !tbaa !7
+  %188 = load atomic i64, i64* %187 unordered, align 8, !tbaa !7
   %189 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %5, i64 0, i64 1
   %190 = bitcast %struct.ObjHeader** %189 to i64*
   store i64 %188, i64* %190, align 8, !tbaa !9
@@ -3079,64 +3048,65 @@
   %204 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %203 monotonic, align 8
   %205 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %204, i64 1, i32 4
   %206 = bitcast %struct.TypeInfo** %205 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %207 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %206, align 8
+  %207 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %206 unordered, align 8
   %208 = call %struct.ObjHeader* %207(%struct.ObjHeader* %183, %struct.ObjHeader** nonnull %197)
   store %struct.ObjHeader* %208, %struct.ObjHeader** %cause.i.i, align 8, !tbaa !3
-  store %struct.ObjHeader* %208, %struct.ObjHeader** %196, align 8, !tbaa !3
-  %.not.i.i = icmp eq %struct.ObjHeader* %208, null
+  %209 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %cause.i.i unordered, align 8
+  store %struct.ObjHeader* %209, %struct.ObjHeader** %196, align 8, !tbaa !3
+  %.not.i.i = icmp eq %struct.ObjHeader* %209, null
   br i1 %.not.i.i, label %epilogue, label %while_loop.i.i
 
 while_loop.i.i:                                   ; preds = %when_case.i.i
-  %209 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %210 = and i8 %209, 1
-  %211 = icmp eq i8 %210, 0
-  br i1 %211, label %Kotlin_mm_safePointWhileLoopBody.exit.i.i, label %212
+  %210 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %211 = and i8 %210, 1
+  %212 = icmp eq i8 %211, 0
+  br i1 %212, label %Kotlin_mm_safePointWhileLoopBody.exit.i.i, label %213
 
-212:                                              ; preds = %while_loop.i.i
+213:                                              ; preds = %while_loop.i.i
   call fastcc void @_ZN6kotlin2mm26SuspendIfRequestedSlowPathEv() #37
   br label %Kotlin_mm_safePointWhileLoopBody.exit.i.i
 
-Kotlin_mm_safePointWhileLoopBody.exit.i.i:        ; preds = %212, %while_loop.i.i
-  %213 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %5, i64 0, i64 8
-  %214 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %5, i64 0, i64 7
-  %215 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %5, i64 0, i64 6
-  %216 = load %struct.ObjHeader*, %struct.ObjHeader** %cause.i.i, align 8
-  store %struct.ObjHeader* %216, %struct.ObjHeader** %215, align 8, !tbaa !3
-  %217 = call fastcc zeroext i1 @"kfun:kotlin.Throwable.ExceptionTraceBuilder.dumpSelfTrace#internal"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader* %216, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [11 x i16] }* @115 to %struct.ObjHeader*))
-  %218 = load %struct.ObjHeader*, %struct.ObjHeader** %cause.i.i, align 8
-  store %struct.ObjHeader* %218, %struct.ObjHeader** %214, align 8, !tbaa !3
-  %219 = bitcast %struct.ObjHeader* %218 to i64*
-  %220 = load atomic volatile i64, i64* %219 monotonic, align 8
-  %221 = and i64 %220, -4
-  %222 = inttoptr i64 %221 to i64*
-  %223 = load atomic volatile i64, i64* %222 monotonic, align 8
-  %224 = inttoptr i64 %223 to i8*
-  %225 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 6
-  %226 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %225 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %227 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %226, align 8, !tbaa !3
-  %228 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %227, i64 0, i32 2, i32 1
-  %229 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %228, i64 24) #37
-  %230 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %229, i64 1
-  %231 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %229, i64 2
-  %232 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %231 to %struct.ObjHeader*
-  %233 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %231 to %struct.TypeInfo**
-  %234 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %230 to i64*
-  store i64 0, i64* %234, align 8
-  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [3 x i8*] }, { %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.native.internal.KClassImpl#internal", i64 0, i32 0), %struct.TypeInfo** %233, align 8, !tbaa !14
-  %235 = bitcast %struct.ObjHeader** %213 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %231, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %235, align 8, !tbaa !3
-  %236 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %229, i64 3
-  %237 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %236 to i8**
-  store i8* %224, i8** %237, align 8
-  call fastcc void @ThrowInvalidReceiverTypeException(%struct.ObjHeader* nonnull %232) #50
+Kotlin_mm_safePointWhileLoopBody.exit.i.i:        ; preds = %213, %while_loop.i.i
+  %214 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %5, i64 0, i64 8
+  %215 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %5, i64 0, i64 7
+  %216 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %5, i64 0, i64 6
+  %217 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %cause.i.i unordered, align 8
+  store %struct.ObjHeader* %217, %struct.ObjHeader** %216, align 8, !tbaa !3
+  %218 = call fastcc zeroext i1 @"kfun:kotlin.Throwable.ExceptionTraceBuilder.dumpSelfTrace#internal"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader* %217, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [11 x i16] }* @115 to %struct.ObjHeader*))
+  %219 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %cause.i.i unordered, align 8
+  store %struct.ObjHeader* %219, %struct.ObjHeader** %215, align 8, !tbaa !3
+  %220 = bitcast %struct.ObjHeader* %219 to i64*
+  %221 = load atomic volatile i64, i64* %220 monotonic, align 8
+  %222 = and i64 %221, -4
+  %223 = inttoptr i64 %222 to i64*
+  %224 = load atomic volatile i64, i64* %223 monotonic, align 8
+  %225 = inttoptr i64 %224 to i8*
+  %226 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 6
+  %227 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %226 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
+  %228 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %227 unordered, align 8, !tbaa !3
+  %229 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %228, i64 0, i32 2, i32 1
+  %230 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %229, i64 24) #37
+  %231 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %230, i64 1
+  %232 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %230, i64 2
+  %233 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %232 to %struct.ObjHeader*
+  %234 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %232 to %struct.TypeInfo**
+  %235 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %231 to i64*
+  store i64 0, i64* %235, align 8
+  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [3 x i8*] }, { %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.native.internal.KClassImpl#internal", i64 0, i32 0), %struct.TypeInfo** %234, align 8, !tbaa !14
+  %236 = bitcast %struct.ObjHeader** %214 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %232, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %236, align 8, !tbaa !3
+  %237 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %230, i64 3
+  %238 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %237 to i8**
+  store i8* %225, i8** %238, align 8
+  call fastcc void @ThrowInvalidReceiverTypeException(%struct.ObjHeader* nonnull %233) #50
   unreachable
 
 epilogue:                                         ; preds = %when_case.i.i, %Kotlin_mm_safePointFunctionPrologue.exit
-  %238 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %239 = bitcast %"class.kotlin::mm::ShadowStack"* %238 to i64*
+  %239 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
+  %240 = bitcast %"class.kotlin::mm::ShadowStack"* %239 to i64*
   call void @llvm.lifetime.end.p0i8(i64 72, i8* nonnull %184)
-  %240 = load i64, i64* %18, align 8, !tbaa !9
-  store i64 %240, i64* %239, align 8, !tbaa !7
+  %241 = load atomic i64, i64* %18 unordered, align 8, !tbaa !9
+  store i64 %241, i64* %240, align 8, !tbaa !7
   ret void
 }
 
@@ -3149,11 +3119,11 @@
   %5 = bitcast [5 x %struct.ObjHeader*]* %4 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %5, i8 0, i32 40, i1 immarg false) #49
   %6 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %4, i64 0, i64 3
-  %7 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %7 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %8 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 5
   %9 = bitcast [5 x %struct.ObjHeader*]* %4 to %struct.FrameOverlay.6*
   %10 = bitcast %"class.kotlin::mm::ShadowStack"* %8 to i64*
-  %11 = load i64, i64* %10, align 8, !tbaa !7
+  %11 = load atomic i64, i64* %10 unordered, align 8, !tbaa !7
   %12 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %4, i64 0, i64 1
   %13 = bitcast %struct.ObjHeader** %12 to i64*
   store i64 %11, i64* %13, align 8, !tbaa !9
@@ -3187,7 +3157,7 @@
   %26 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 5
   %27 = bitcast [4 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %28 = bitcast %"class.kotlin::mm::ShadowStack"* %26 to i64*
-  %29 = load i64, i64* %28, align 8, !tbaa !7
+  %29 = load atomic i64, i64* %28 unordered, align 8, !tbaa !7
   %30 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %31 = bitcast %struct.ObjHeader** %30 to i64*
   store i64 %29, i64* %31, align 8, !tbaa !9
@@ -3212,7 +3182,7 @@
   %44 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %43 monotonic, align 8
   %45 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %44, i64 1, i32 2
   %46 = bitcast i32* %45 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %47 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %46, align 8
+  %47 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %46 unordered, align 8
   %48 = call %struct.ObjHeader* %47(%struct.ObjHeader* nonnull %1, %struct.ObjHeader** nonnull %37)
   br label %call_success
 
@@ -3221,7 +3191,7 @@
   %50 = bitcast %struct.ObjHeader* %49 to %struct.ArrayHeader*
   call fastcc void @Kotlin_io_Console_println(%struct.ArrayHeader* %50)
   %51 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 5
-  %52 = load i64, i64* %31, align 8, !tbaa !9
+  %52 = load atomic i64, i64* %31 unordered, align 8, !tbaa !9
   %53 = bitcast %"class.kotlin::mm::ShadowStack"* %51 to i64*
   store i64 %52, i64* %53, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %25)
@@ -3232,7 +3202,7 @@
   %55 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 5
   %56 = bitcast [11 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %57 = bitcast %"class.kotlin::mm::ShadowStack"* %55 to i64*
-  %58 = load i64, i64* %57, align 8, !tbaa !7
+  %58 = load atomic i64, i64* %57 unordered, align 8, !tbaa !7
   %59 = getelementptr inbounds [11 x %struct.ObjHeader*], [11 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %60 = bitcast %struct.ObjHeader** %59 to i64*
   store i64 %58, i64* %60, align 8, !tbaa !9
@@ -3245,7 +3215,7 @@
   store i32 11, i32* %64, align 4, !tbaa !13
   %65 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %1, i64 2
   %66 = bitcast %struct.ObjHeader* %65 to i32*
-  %67 = load i32, i32* %66, align 4
+  %67 = load atomic i32, i32* %66 unordered, align 4
   %68 = icmp slt i32 %67, 0
   br i1 %68, label %when_case7.i.i, label %call_success1
 
@@ -3254,15 +3224,15 @@
   %70 = getelementptr inbounds [11 x %struct.ObjHeader*], [11 x %struct.ObjHeader*]* %2, i64 0, i64 9
   %71 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %1, i64 1
   %72 = bitcast %struct.ObjHeader* %71 to %struct.ObjHeader**
-  %73 = load %struct.ObjHeader*, %struct.ObjHeader** %72, align 8
+  %73 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %72 unordered, align 8
   store %struct.ObjHeader* %73, %struct.ObjHeader** %70, align 8, !tbaa !3
   store %struct.ObjHeader* %73, %struct.ObjHeader** %69, align 8, !tbaa !3
   %74 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %73, i64 1
   %75 = bitcast %struct.ObjHeader* %74 to i32*
-  %76 = load i32, i32* %75, align 8, !tbaa !18
+  %76 = load atomic i32, i32* %75 unordered, align 8, !tbaa !18
   %77 = icmp slt i32 %76, 0
   %spec.select = select i1 %77, i32 %76, i32 0
-  %78 = load i32, i32* %75, align 8, !tbaa !18
+  %78 = load atomic i32, i32* %75 unordered, align 8, !tbaa !18
   call fastcc void @checkRangeIndexes(i32 %67, i32 %spec.select, i32 %78)
   %79 = bitcast %struct.ObjHeader* %73 to i64*
   %80 = load atomic volatile i64, i64* %79 monotonic, align 8
@@ -3334,7 +3304,7 @@
   %131 = icmp eq i64 %130, 0
   %132 = bitcast i16* %127 to i8*
   call void @llvm.memset.p0i8.i64(i8* nonnull align 2 dereferenceable(32) %132, i8 0, i64 32, i1 false)
-  br i1 %131, label %.loopexit3, label %104, !llvm.loop !32
+  br i1 %131, label %.loopexit3, label %104, !llvm.loop !24
 
 .loopexit3:                                       ; preds = %104, %92
   %133 = phi i64 [ 0, %92 ], [ %129, %104 ]
@@ -3350,7 +3320,7 @@
   %140 = icmp eq i64 %139, 0
   %141 = bitcast i16* %137 to i8*
   call void @llvm.memset.p0i8.i64(i8* nonnull align 2 dereferenceable(32) %141, i8 0, i64 32, i1 false)
-  br i1 %140, label %.loopexit, label %.preheader, !llvm.loop !33
+  br i1 %140, label %.loopexit, label %.preheader, !llvm.loop !26
 
 .loopexit:                                        ; preds = %.preheader, %.loopexit3
   %142 = icmp eq i64 %90, %93
@@ -3365,16 +3335,16 @@
   %147 = phi i32 [ %150, %146 ], [ %144, %143 ]
   %148 = phi i16* [ %149, %146 ], [ %145, %143 ]
   %149 = getelementptr inbounds i16, i16* %148, i64 1
-  store i16 0, i16* %148, align 2, !tbaa !34
+  store i16 0, i16* %148, align 2, !tbaa !27
   %150 = add nsw i32 %147, 1
   %151 = icmp eq i32 %150, %spec.select
-  br i1 %151, label %call_success1, label %146, !llvm.loop !36
+  br i1 %151, label %call_success1, label %146, !llvm.loop !29
 
 call_success1:                                    ; preds = %146, %.loopexit, %when_case7.i.i, %call_success
   call fastcc void @"kfun:kotlin.text.StringBuilder#ensureCapacity(kotlin.Int){}"(%struct.ObjHeader* %1, i32 0)
   store i32 0, i32* %66, align 4
   %152 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 5
-  %153 = load i64, i64* %60, align 8, !tbaa !9
+  %153 = load atomic i64, i64* %60 unordered, align 8, !tbaa !9
   %154 = bitcast %"class.kotlin::mm::ShadowStack"* %152 to i64*
   store i64 %153, i64* %154, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 88, i8* nonnull %54)
@@ -3389,7 +3359,7 @@
 epilogue:                                         ; preds = %returnable_block_exit, %call_success1
   %157 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %7, %call_success1 ], [ %7, %returnable_block_exit ]
   %158 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %157, i64 0, i32 1, i32 5
-  %159 = load i64, i64* %13, align 8, !tbaa !9
+  %159 = load atomic i64, i64* %13 unordered, align 8, !tbaa !9
   %160 = bitcast %"class.kotlin::mm::ShadowStack"* %158 to i64*
   store i64 %159, i64* %160, align 8, !tbaa !7
   ret void
@@ -3412,11 +3382,11 @@
   %13 = getelementptr inbounds [29 x %struct.ObjHeader*], [29 x %struct.ObjHeader*]* %3, i64 0, i64 21
   %14 = getelementptr inbounds [29 x %struct.ObjHeader*], [29 x %struct.ObjHeader*]* %3, i64 0, i64 22
   %15 = getelementptr inbounds [29 x %struct.ObjHeader*], [29 x %struct.ObjHeader*]* %3, i64 0, i64 23
-  %16 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %16 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %17 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %16, i64 0, i32 1, i32 5
   %18 = bitcast [29 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %19 = bitcast %"class.kotlin::mm::ShadowStack"* %17 to i64*
-  %20 = load i64, i64* %19, align 8, !tbaa !7
+  %20 = load atomic i64, i64* %19 unordered, align 8, !tbaa !7
   %21 = getelementptr inbounds [29 x %struct.ObjHeader*], [29 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %22 = bitcast %struct.ObjHeader** %21 to i64*
   store i64 %20, i64* %22, align 8, !tbaa !9
@@ -3439,10 +3409,10 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %30, %call_success
   %31 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 3
   %32 = bitcast %struct.ObjHeader* %31 to %struct.ObjHeader**
-  %33 = load %struct.ObjHeader*, %struct.ObjHeader** %32, align 8
+  %33 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %32 unordered, align 8
   %34 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %33, i64 1
   %35 = bitcast %struct.ObjHeader* %34 to %struct.ObjHeader**
-  %36 = load %struct.ObjHeader*, %struct.ObjHeader** %35, align 8
+  %36 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %35 unordered, align 8
   %37 = call fastcc i32 @"kfun:kotlin.collections.HashMap#addKey(1:0){}kotlin.Int"(%struct.ObjHeader* %36, %struct.ObjHeader* %1)
   %38 = icmp sgt i32 %37, -1
   br i1 %38, label %call_success12, label %call_success7
@@ -3456,7 +3426,7 @@
   %44 = getelementptr inbounds [29 x %struct.ObjHeader*], [29 x %struct.ObjHeader*]* %3, i64 0, i64 3
   %45 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %46 = bitcast %struct.ObjHeader* %45 to %struct.ObjHeader**
-  %47 = load %struct.ObjHeader*, %struct.ObjHeader** %46, align 8
+  %47 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %46 unordered, align 8
   %48 = call fastcc %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.String?){}kotlin.text.StringBuilder"(%struct.ObjHeader* %47, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [0 x i8] }* @102 to %struct.ObjHeader*), %struct.ObjHeader** nonnull %44)
   %49 = call fastcc %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.String?){}kotlin.text.StringBuilder"(%struct.ObjHeader* %47, %struct.ObjHeader* %2, %struct.ObjHeader** nonnull %43)
   %50 = call fastcc %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.String?){}kotlin.text.StringBuilder"(%struct.ObjHeader* %47, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [32 x i16] }* @116 to %struct.ObjHeader*), %struct.ObjHeader** nonnull %42)
@@ -3469,7 +3439,7 @@
   %57 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %56 monotonic, align 8
   %58 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %57, i64 1, i32 2
   %59 = bitcast i32* %58 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %60 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %59, align 8
+  %60 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %59 unordered, align 8
   %61 = call %struct.ObjHeader* %60(%struct.ObjHeader* %1, %struct.ObjHeader** nonnull %41)
   %62 = call fastcc %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.String?){}kotlin.text.StringBuilder"(%struct.ObjHeader* %47, %struct.ObjHeader* %61, %struct.ObjHeader** nonnull %40)
   %63 = call fastcc %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.String?){}kotlin.text.StringBuilder"(%struct.ObjHeader* %47, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [1 x i16] }* @108 to %struct.ObjHeader*), %struct.ObjHeader** nonnull %39)
@@ -3483,7 +3453,7 @@
   %67 = getelementptr inbounds [29 x %struct.ObjHeader*], [29 x %struct.ObjHeader*]* %3, i64 0, i64 9
   %68 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %69 = bitcast %struct.ObjHeader* %68 to %struct.ObjHeader**
-  %70 = load %struct.ObjHeader*, %struct.ObjHeader** %69, align 8
+  %70 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %69 unordered, align 8
   %71 = call fastcc %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.String?){}kotlin.text.StringBuilder"(%struct.ObjHeader* %70, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [0 x i8] }* @102 to %struct.ObjHeader*), %struct.ObjHeader** nonnull %67)
   %72 = call fastcc %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.String?){}kotlin.text.StringBuilder"(%struct.ObjHeader* %70, %struct.ObjHeader* %2, %struct.ObjHeader** nonnull %66)
   %73 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %1, i64 0, i32 0
@@ -3495,13 +3465,13 @@
   %79 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %78 monotonic, align 8
   %80 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %79, i64 1, i32 2
   %81 = bitcast i32* %80 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %82 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %81, align 8
+  %82 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %81 unordered, align 8
   %83 = call %struct.ObjHeader* %82(%struct.ObjHeader* %1, %struct.ObjHeader** nonnull %65)
   %84 = call fastcc %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.String?){}kotlin.text.StringBuilder"(%struct.ObjHeader* %70, %struct.ObjHeader* %83, %struct.ObjHeader** nonnull %64)
   call fastcc void @"kfun:kotlin.Throwable.ExceptionTraceBuilder.endln#internal"(%struct.ObjHeader* %0, %struct.ObjHeader* %70)
   %85 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %86 = bitcast %struct.ObjHeader* %85 to %struct.ObjHeader**
-  %87 = load %struct.ObjHeader*, %struct.ObjHeader** %86, align 8
+  %87 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %86 unordered, align 8
   %88 = icmp eq %struct.ObjHeader* %87, %1
   br i1 %88, label %call_success13.thread, label %when_exit.i
 
@@ -3511,16 +3481,16 @@
 when_exit.i:                                      ; preds = %call_success12
   %89 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %87, i64 3
   %90 = bitcast %struct.ObjHeader* %89 to %struct.ObjHeader**
-  %91 = load %struct.ObjHeader*, %struct.ObjHeader** %90, align 8
+  %91 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %90 unordered, align 8
   %92 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %91, i64 1
   %93 = bitcast %struct.ObjHeader* %92 to i32*
-  %94 = load i32, i32* %93, align 8, !tbaa !18
+  %94 = load atomic i32, i32* %93 unordered, align 8, !tbaa !18
   %95 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %1, i64 3
   %96 = bitcast %struct.ObjHeader* %95 to %struct.ObjHeader**
-  %97 = load %struct.ObjHeader*, %struct.ObjHeader** %96, align 8
+  %97 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %96 unordered, align 8
   %98 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %97, i64 1
   %99 = bitcast %struct.ObjHeader* %98 to i32*
-  %100 = load i32, i32* %99, align 8, !tbaa !18
+  %100 = load atomic i32, i32* %99 unordered, align 8, !tbaa !18
   %.not.i = icmp sgt i32 %94, %100
   %spec.select = select i1 %.not.i, i32 %100, i32 %94
   %101 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %97, i64 2
@@ -3544,7 +3514,7 @@
   %108 = xor i64 %indvars.iv6, -1
   %109 = trunc i64 %108 to i32
   %110 = add i32 %100, %109
-  %111 = load i32, i32* %99, align 8, !tbaa !18
+  %111 = load atomic i32, i32* %99 unordered, align 8, !tbaa !18
   %112 = icmp ugt i32 %111, %110
   br i1 %112, label %Kotlin_NativePtrArray_get.exit.i, label %113
 
@@ -3555,7 +3525,7 @@
 Kotlin_NativePtrArray_get.exit.i:                 ; preds = %Kotlin_mm_safePointWhileLoopBody.exit.i
   %114 = trunc i64 %108 to i32
   %115 = add i32 %94, %114
-  %116 = load i32, i32* %93, align 8, !tbaa !18
+  %116 = load atomic i32, i32* %93 unordered, align 8, !tbaa !18
   %117 = icmp ugt i32 %116, %115
   br i1 %117, label %Kotlin_NativePtrArray_get.exit11.i, label %118
 
@@ -3567,11 +3537,11 @@
   %119 = sext i32 %110 to i64
   %120 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %101, i64 %119
   %121 = bitcast %struct.ObjHeader* %120 to i8**
-  %122 = load i8*, i8** %121, align 8, !tbaa !3
+  %122 = load atomic i8*, i8** %121 unordered, align 8, !tbaa !3
   %123 = sext i32 %115 to i64
   %124 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %102, i64 %123
   %125 = bitcast %struct.ObjHeader* %124 to i8**
-  %126 = load i8*, i8** %125, align 8, !tbaa !3
+  %126 = load atomic i8*, i8** %125 unordered, align 8, !tbaa !3
   %.not10.i = icmp eq i8* %122, %126
   br i1 %.not10.i, label %when_exit7.i, label %call_success13
 
@@ -3597,7 +3567,7 @@
   %131 = call fastcc %struct.ObjHeader* @"kfun:kotlin.Throwable.<get-stackTraceStrings>#internal"(%struct.ObjHeader* %1, %struct.ObjHeader** nonnull %5)
   %132 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %131, i64 1
   %133 = bitcast %struct.ObjHeader* %132 to i32*
-  %134 = load i32, i32* %133, align 8, !tbaa !18
+  %134 = load atomic i32, i32* %133 unordered, align 8, !tbaa !18
   %135 = sub i32 %134, %130
   %136 = icmp sgt i32 %135, 0
   br i1 %136, label %when_case17, label %when_exit18
@@ -3622,7 +3592,7 @@
   %141 = call fastcc %struct.ObjHeader* @"kfun:kotlin.Throwable.<get-stackTraceStrings>#internal"(%struct.ObjHeader* %1, %struct.ObjHeader** nonnull %6)
   %142 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %141, i64 1
   %143 = bitcast %struct.ObjHeader* %142 to i32*
-  %144 = load i32, i32* %143, align 8, !tbaa !18
+  %144 = load atomic i32, i32* %143 unordered, align 8, !tbaa !18
   %145 = zext i32 %144 to i64
   %146 = icmp ult i64 %indvars.iv, %145
   br i1 %146, label %loop_check, label %147
@@ -3635,9 +3605,9 @@
   %148 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %141, i64 2
   %149 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %148, i64 %indvars.iv
   %150 = bitcast %struct.ObjHeader* %149 to %struct.ObjHeader**
-  %151 = load %struct.ObjHeader*, %struct.ObjHeader** %150, align 8, !tbaa !3
+  %151 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %150 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %151, %struct.ObjHeader** %7, align 8, !tbaa !3
-  %152 = load %struct.ObjHeader*, %struct.ObjHeader** %69, align 8
+  %152 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %69 unordered, align 8
   %153 = call fastcc %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.String?){}kotlin.text.StringBuilder"(%struct.ObjHeader* %152, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [0 x i8] }* @102 to %struct.ObjHeader*), %struct.ObjHeader** nonnull %8)
   %154 = call fastcc %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.String?){}kotlin.text.StringBuilder"(%struct.ObjHeader* %152, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [7 x i16] }* @117 to %struct.ObjHeader*), %struct.ObjHeader** nonnull %9)
   %155 = call fastcc %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.String?){}kotlin.text.StringBuilder"(%struct.ObjHeader* %152, %struct.ObjHeader* %151, %struct.ObjHeader** nonnull %10)
@@ -3650,7 +3620,7 @@
   br i1 %.not, label %returnable_block_exit, label %call_success31
 
 call_success31:                                   ; preds = %when_exit18
-  %156 = load %struct.ObjHeader*, %struct.ObjHeader** %69, align 8
+  %156 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %69 unordered, align 8
   %157 = call fastcc %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.String?){}kotlin.text.StringBuilder"(%struct.ObjHeader* %156, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [0 x i8] }* @102 to %struct.ObjHeader*), %struct.ObjHeader** nonnull %11)
   %158 = call fastcc %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.String?){}kotlin.text.StringBuilder"(%struct.ObjHeader* %156, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [12 x i16] }* @118 to %struct.ObjHeader*), %struct.ObjHeader** nonnull %12)
   %159 = call fastcc %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.Int){}kotlin.text.StringBuilder"(%struct.ObjHeader* %156, i32 %130, %struct.ObjHeader** nonnull %13)
@@ -3661,7 +3631,7 @@
 returnable_block_exit:                            ; preds = %call_success31, %when_exit18
   %161 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %1, i64 5
   %162 = bitcast %struct.ObjHeader* %161 to %struct.ObjHeader**
-  %163 = load %struct.ObjHeader*, %struct.ObjHeader** %162, align 8
+  %163 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %162 unordered, align 8
   store %struct.ObjHeader* %163, %struct.ObjHeader** %15, align 8, !tbaa !3
   %164 = icmp eq %struct.ObjHeader* %163, null
   br i1 %164, label %epilogue, label %call_success36
@@ -3676,7 +3646,7 @@
   %171 = inttoptr i64 %170 to i8*
   %172 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %16, i64 0, i32 1, i32 6
   %173 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %172 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %174 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %173, align 8, !tbaa !3
+  %174 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %173 unordered, align 8, !tbaa !3
   %175 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %174, i64 0, i32 2, i32 1
   %176 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %175, i64 24) #37
   %177 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %176, i64 1
@@ -3697,7 +3667,7 @@
 epilogue:                                         ; preds = %returnable_block_exit, %call_success7
   %185 = phi i1 [ false, %call_success7 ], [ true, %returnable_block_exit ]
   %186 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %16, i64 0, i32 1, i32 5
-  %187 = load i64, i64* %22, align 8, !tbaa !9
+  %187 = load atomic i64, i64* %22 unordered, align 8, !tbaa !9
   %188 = bitcast %"class.kotlin::mm::ShadowStack"* %186 to i64*
   store i64 %187, i64* %188, align 8, !tbaa !7
   ret i1 %185
@@ -3732,11 +3702,11 @@
   %objHeader10 = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %16, i64 0, i32 0
   %typeInfoOrMeta_11 = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %16, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_11, align 8
-  %19 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %19 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %20 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %19, i64 0, i32 1, i32 5
   %21 = bitcast [13 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %22 = bitcast %"class.kotlin::mm::ShadowStack"* %20 to i64*
-  %23 = load i64, i64* %22, align 8, !tbaa !7
+  %23 = load atomic i64, i64* %22 unordered, align 8, !tbaa !7
   %24 = getelementptr inbounds [13 x %struct.ObjHeader*], [13 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %25 = bitcast %struct.ObjHeader** %24 to i64*
   store i64 %23, i64* %25, align 8, !tbaa !9
@@ -3789,7 +3759,7 @@
   %54 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %53 monotonic, align 8
   %55 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %54, i64 1, i32 5
   %56 = bitcast i32** %55 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %57 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %56, align 8
+  %57 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %56 unordered, align 8
   %58 = call %struct.ObjHeader* %57(%struct.ObjHeader* %0, %struct.ObjHeader** nonnull %6)
   %.not = icmp eq %struct.ObjHeader* %58, null
   br i1 %.not, label %epilogue, label %call_success15
@@ -3807,7 +3777,7 @@
   %66 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %65 monotonic, align 8
   %67 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %66, i64 1, i32 5
   %68 = bitcast i32** %67 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %69 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %68, align 8
+  %69 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %68 unordered, align 8
   %70 = call %struct.ObjHeader* %69(%struct.ObjHeader* %0, %struct.ObjHeader** nonnull %10)
   %71 = icmp eq %struct.ObjHeader* %70, null
   br i1 %71, label %call_success21, label %call_success19
@@ -3822,7 +3792,7 @@
   %78 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %77 monotonic, align 8
   %79 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %78, i64 1, i32 2
   %80 = bitcast i32* %79 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %81 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %80, align 8
+  %81 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %80 unordered, align 8
   %82 = call %struct.ObjHeader* %81(%struct.ObjHeader* nonnull %70, %struct.ObjHeader** nonnull %11)
   br label %call_success21
 
@@ -3836,7 +3806,7 @@
   %86 = phi %struct.ObjHeader* [ %85, %call_success21 ], [ %47, %call_success9 ]
   store %struct.ObjHeader* %86, %struct.ObjHeader** %1, align 8, !tbaa !3
   %87 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %19, i64 0, i32 1, i32 5
-  %88 = load i64, i64* %25, align 8, !tbaa !9
+  %88 = load atomic i64, i64* %25 unordered, align 8, !tbaa !9
   %89 = bitcast %"class.kotlin::mm::ShadowStack"* %87 to i64*
   store i64 %88, i64* %89, align 8, !tbaa !7
   ret %struct.ObjHeader* %86
@@ -3844,975 +3814,1077 @@
 
 define internal nonnull %struct.ObjHeader* @"kfun:kotlin.Throwable.$<init>$lambda$0$FUNCTION_REFERENCE$1.invoke#internal"(%struct.ObjHeader* nocapture readonly %0, %struct.ObjHeader** nocapture %1) #3 personality i32 (...)* @__gxx_personality_v0 {
 entry:
-  %2 = alloca [10 x %class.SourceInfo], align 16
-  %3 = alloca [1024 x i8], align 16
-  %4 = alloca %"class.std::__cxx11::basic_string", align 8
-  %5 = alloca %"class.std::vector.1", align 8
-  %6 = alloca %class.ObjHolder, align 8
+  %2 = alloca %"class.kotlin::NativeOrUnregisteredThreadGuard", align 8
+  %3 = alloca [10 x %class.SourceInfo], align 16
+  %4 = alloca [1024 x i8], align 16
+  %5 = alloca %"class.std::__cxx11::basic_string", align 8
+  %6 = alloca %"class.std::vector.1", align 8
   %7 = alloca %class.ObjHolder, align 8
-  %8 = alloca [4 x %struct.ObjHeader*], align 8
-  %9 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %10 = and i8 %9, 1
-  %11 = icmp eq i8 %10, 0
-  br i1 %11, label %Kotlin_mm_safePointFunctionPrologue.exit, label %12
+  %8 = alloca %class.ObjHolder, align 8
+  %9 = alloca [4 x %struct.ObjHeader*], align 8
+  %10 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %11 = and i8 %10, 1
+  %12 = icmp eq i8 %11, 0
+  br i1 %12, label %Kotlin_mm_safePointFunctionPrologue.exit, label %13
 
-12:                                               ; preds = %entry
+13:                                               ; preds = %entry
   tail call fastcc void @_ZN6kotlin2mm26SuspendIfRequestedSlowPathEv() #37
   br label %Kotlin_mm_safePointFunctionPrologue.exit
 
-Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %12, %entry
-  %13 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
-  %14 = bitcast %struct.ObjHeader* %13 to %struct.ObjHeader**
-  %15 = load %struct.ObjHeader*, %struct.ObjHeader** %14, align 8
-  %16 = bitcast [4 x %struct.ObjHeader*]* %8 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %16)
-  %.sub.i = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %8, i64 0, i64 0
-  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %16, i8 0, i32 32, i1 immarg false) #49
-  %17 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %8, i64 0, i64 3
-  %18 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %19 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %18, i64 0, i32 1, i32 5
-  %20 = bitcast [4 x %struct.ObjHeader*]* %8 to %struct.FrameOverlay.6*
-  %21 = bitcast %"class.kotlin::mm::ShadowStack"* %19 to i64*
-  %22 = load i64, i64* %21, align 8, !tbaa !7
-  %23 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %8, i64 0, i64 1
-  %24 = bitcast %struct.ObjHeader** %23 to i64*
-  store i64 %22, i64* %24, align 8, !tbaa !9
-  %25 = bitcast %"class.kotlin::mm::ShadowStack"* %19 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %25, align 8, !tbaa !7
-  %26 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %8, i64 0, i64 2
-  %27 = bitcast %struct.ObjHeader** %26 to i32*
-  store i32 0, i32* %27, align 8, !tbaa !12
-  %28 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %20, i64 0, i32 3
-  store i32 4, i32* %28, align 4, !tbaa !13
-  %29 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %15, i64 3
-  %30 = bitcast %struct.ObjHeader* %29 to %struct.ObjHeader**
-  %31 = load %struct.ObjHeader*, %struct.ObjHeader** %30, align 8
-  %32 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %31, i64 2
-  %33 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %31, i64 1
-  %34 = bitcast %struct.ObjHeader* %33 to i32*
-  %35 = load i32, i32* %34, align 8, !tbaa !18
-  %36 = zext i32 %35 to i64
-  %37 = bitcast %"class.std::vector.1"* %5 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %37) #37
-  %38 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
-  %39 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %38, i64 328
-  %40 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %39 to i32*
-  %41 = atomicrmw xchg i32* %40, i32 1 seq_cst, align 4
-  %42 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3, !noalias !38
-  %.not = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %42, null
-  br i1 %.not, label %46, label %43
+Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %13, %entry
+  %14 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
+  %15 = bitcast %struct.ObjHeader* %14 to %struct.ObjHeader**
+  %16 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %15 unordered, align 8
+  %17 = bitcast [4 x %struct.ObjHeader*]* %9 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %17)
+  %.sub.i = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %9, i64 0, i64 0
+  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %17, i8 0, i32 32, i1 immarg false) #49
+  %18 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %9, i64 0, i64 3
+  %19 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %20 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %19, i64 0, i32 1, i32 5
+  %21 = bitcast [4 x %struct.ObjHeader*]* %9 to %struct.FrameOverlay.6*
+  %22 = bitcast %"class.kotlin::mm::ShadowStack"* %20 to i64*
+  %23 = load atomic i64, i64* %22 unordered, align 8, !tbaa !7
+  %24 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %9, i64 0, i64 1
+  %25 = bitcast %struct.ObjHeader** %24 to i64*
+  store i64 %23, i64* %25, align 8, !tbaa !9
+  %26 = bitcast %"class.kotlin::mm::ShadowStack"* %20 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %26, align 8, !tbaa !7
+  %27 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %9, i64 0, i64 2
+  %28 = bitcast %struct.ObjHeader** %27 to i32*
+  store i32 0, i32* %28, align 8, !tbaa !12
+  %29 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %21, i64 0, i32 3
+  store i32 4, i32* %29, align 4, !tbaa !13
+  %30 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %16, i64 3
+  %31 = bitcast %struct.ObjHeader* %30 to %struct.ObjHeader**
+  %32 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %31 unordered, align 8
+  %33 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %32, i64 2
+  %34 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %32, i64 1
+  %35 = bitcast %struct.ObjHeader* %34 to i32*
+  %36 = load atomic i32, i32* %35 unordered, align 8, !tbaa !18
+  %37 = zext i32 %36 to i64
+  %38 = bitcast %"class.std::vector.1"* %6 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %38) #37
+  %39 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
+  %40 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %39, i64 328
+  %41 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %40 to i32*
+  %42 = atomicrmw xchg i32* %41, i32 1 seq_cst, align 4
+  %43 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %2, i64 0, i32 0, i64 0
+  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %43) #37, !noalias !31
+  %44 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %2, i64 0, i32 1
+  %45 = getelementptr inbounds %"class.kotlin::CalledFromNativeGuard", %"class.kotlin::CalledFromNativeGuard"* %44, i64 0, i32 0
+  store %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* null, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %45, align 8, !tbaa !34, !noalias !31
+  %46 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %2, i64 0, i32 1, i32 1
+  store i32 1, i32* %46, align 8, !tbaa !38, !noalias !31
+  %47 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %2, i64 0, i32 1, i32 2
+  store i8 0, i8* %47, align 4, !tbaa !39, !noalias !31
+  %48 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3, !noalias !31
+  %.not = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %48, null
+  br i1 %.not, label %54, label %49
 
-43:                                               ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
-  %44 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %42, i64 0, i32 1, i32 8, i32 0, i32 0
-  %45 = atomicrmw xchg i32* %44, i32 1 seq_cst, align 4, !noalias !38
-  %phi.cast = bitcast %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %42 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*
-  br label %46
+49:                                               ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
+  %50 = ptrtoint %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %48 to i64
+  %51 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %48, i64 0, i32 1, i32 8, i32 0, i32 0
+  %52 = atomicrmw xchg i32* %51, i32 1 seq_cst, align 4, !noalias !31
+  %53 = bitcast %"class.kotlin::CalledFromNativeGuard"* %44 to i64*
+  store i64 %50, i64* %53, align 8, !tbaa !34, !noalias !31
+  store i32 %52, i32* %46, align 8, !tbaa !38, !noalias !31
+  store i8 1, i8* %47, align 4, !tbaa !39, !noalias !31
+  br label %54
 
-46:                                               ; preds = %43, %Kotlin_mm_safePointFunctionPrologue.exit
-  %.sroa.7.0 = phi i32 [ 1, %Kotlin_mm_safePointFunctionPrologue.exit ], [ %45, %43 ]
-  %.sroa.3.0 = phi %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* [ null, %Kotlin_mm_safePointFunctionPrologue.exit ], [ %phi.cast, %43 ]
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %37, i8 0, i64 24, i1 false) #37, !alias.scope !38
-  %47 = getelementptr inbounds %"class.std::vector.1", %"class.std::vector.1"* %5, i64 0, i32 0, i32 0, i32 2
-  %48 = bitcast %"class.std::vector.1"* %5 to i64*
-  %cond = icmp eq i32 %35, 0
-  br i1 %cond, label %286, label %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE7reserveEm.exit.i.i.i
+54:                                               ; preds = %49, %Kotlin_mm_safePointFunctionPrologue.exit
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %38, i8 0, i64 24, i1 false) #37, !alias.scope !31
+  %55 = getelementptr inbounds %"class.std::vector.1", %"class.std::vector.1"* %6, i64 0, i32 0, i32 0, i32 2
+  %56 = bitcast %"class.std::__cxx11::basic_string"** %55 to i64*
+  %57 = load atomic i64, i64* %56 unordered, align 8, !tbaa !40, !alias.scope !31
+  %58 = bitcast %"class.std::vector.1"* %6 to i64*
+  %59 = load atomic i64, i64* %58 unordered, align 8, !tbaa !43, !alias.scope !31
+  %60 = sub i64 %57, %59
+  %61 = ashr exact i64 %60, 5
+  %62 = icmp ult i64 %61, %37
+  %63 = inttoptr i64 %59 to %"class.std::__cxx11::basic_string"*
+  br i1 %62, label %64, label %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE7reserveEm.exit.i.i.i
 
-_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE7reserveEm.exit.i.i.i: ; preds = %46
-  %49 = getelementptr inbounds %"class.std::vector.1", %"class.std::vector.1"* %5, i64 0, i32 0, i32 0, i32 1
-  %50 = call noalias i8* @calloc(i64 %36, i64 32) #37, !noalias !38
-  %51 = bitcast i8* %50 to %"class.std::__cxx11::basic_string"*
-  %52 = bitcast %"class.std::vector.1"* %5 to i8**
-  store i8* %50, i8** %52, align 8, !tbaa !41, !alias.scope !38
-  %53 = bitcast %"class.std::__cxx11::basic_string"** %49 to i8**
-  store i8* %50, i8** %53, align 8, !tbaa !44, !alias.scope !38
-  %54 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %51, i64 %36
-  store %"class.std::__cxx11::basic_string"* %54, %"class.std::__cxx11::basic_string"** %47, align 8, !tbaa !45, !alias.scope !38
-  %55 = bitcast [10 x %class.SourceInfo]* %2 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 400, i8* nonnull %55) #37, !noalias !38
-  %56 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 0, i32 0, i32 2
-  %57 = bitcast [10 x %class.SourceInfo]* %2 to %union.anon.108**
-  store %union.anon.108* %56, %union.anon.108** %57, align 16, !tbaa !46, !noalias !38
-  %58 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 0, i32 0, i32 1
-  store i64 0, i64* %58, align 8, !tbaa !48, !noalias !38
-  %59 = bitcast %union.anon.108* %56 to i8*
-  store i8 0, i8* %59, align 16, !tbaa !51, !noalias !38
-  %60 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 0, i32 1
-  store i32 -1, i32* %60, align 16, !tbaa !52, !noalias !38
-  %61 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 0, i32 2
-  store i32 -1, i32* %61, align 4, !tbaa !54, !noalias !38
-  %62 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 1
-  %63 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 1, i32 0, i32 2
-  %64 = bitcast %class.SourceInfo* %62 to %union.anon.108**
-  store %union.anon.108* %63, %union.anon.108** %64, align 8, !tbaa !46, !noalias !38
-  %65 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 1, i32 0, i32 1
-  store i64 0, i64* %65, align 8, !tbaa !48, !noalias !38
-  %66 = bitcast %union.anon.108* %63 to i8*
-  store i8 0, i8* %66, align 8, !tbaa !51, !noalias !38
-  %67 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 1, i32 1
-  store i32 -1, i32* %67, align 8, !tbaa !52, !noalias !38
-  %68 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 1, i32 2
-  store i32 -1, i32* %68, align 4, !tbaa !54, !noalias !38
-  %69 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 2
-  %70 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 2, i32 0, i32 2
-  %71 = bitcast %class.SourceInfo* %69 to %union.anon.108**
-  store %union.anon.108* %70, %union.anon.108** %71, align 16, !tbaa !46, !noalias !38
-  %72 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 2, i32 0, i32 1
-  store i64 0, i64* %72, align 8, !tbaa !48, !noalias !38
-  %73 = bitcast %union.anon.108* %70 to i8*
-  store i8 0, i8* %73, align 16, !tbaa !51, !noalias !38
-  %74 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 2, i32 1
-  store i32 -1, i32* %74, align 16, !tbaa !52, !noalias !38
-  %75 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 2, i32 2
-  store i32 -1, i32* %75, align 4, !tbaa !54, !noalias !38
-  %76 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 3
-  %77 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 3, i32 0, i32 2
-  %78 = bitcast %class.SourceInfo* %76 to %union.anon.108**
-  store %union.anon.108* %77, %union.anon.108** %78, align 8, !tbaa !46, !noalias !38
-  %79 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 3, i32 0, i32 1
-  store i64 0, i64* %79, align 8, !tbaa !48, !noalias !38
-  %80 = bitcast %union.anon.108* %77 to i8*
-  store i8 0, i8* %80, align 8, !tbaa !51, !noalias !38
-  %81 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 3, i32 1
-  store i32 -1, i32* %81, align 8, !tbaa !52, !noalias !38
-  %82 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 3, i32 2
-  store i32 -1, i32* %82, align 4, !tbaa !54, !noalias !38
-  %83 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 4
-  %84 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 4, i32 0, i32 2
-  %85 = bitcast %class.SourceInfo* %83 to %union.anon.108**
-  store %union.anon.108* %84, %union.anon.108** %85, align 16, !tbaa !46, !noalias !38
-  %86 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 4, i32 0, i32 1
-  store i64 0, i64* %86, align 8, !tbaa !48, !noalias !38
-  %87 = bitcast %union.anon.108* %84 to i8*
-  store i8 0, i8* %87, align 16, !tbaa !51, !noalias !38
-  %88 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 4, i32 1
-  store i32 -1, i32* %88, align 16, !tbaa !52, !noalias !38
-  %89 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 4, i32 2
-  store i32 -1, i32* %89, align 4, !tbaa !54, !noalias !38
-  %90 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 5
-  %91 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 5, i32 0, i32 2
-  %92 = bitcast %class.SourceInfo* %90 to %union.anon.108**
-  store %union.anon.108* %91, %union.anon.108** %92, align 8, !tbaa !46, !noalias !38
-  %93 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 5, i32 0, i32 1
-  store i64 0, i64* %93, align 8, !tbaa !48, !noalias !38
-  %94 = bitcast %union.anon.108* %91 to i8*
-  store i8 0, i8* %94, align 8, !tbaa !51, !noalias !38
-  %95 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 5, i32 1
-  store i32 -1, i32* %95, align 8, !tbaa !52, !noalias !38
-  %96 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 5, i32 2
-  store i32 -1, i32* %96, align 4, !tbaa !54, !noalias !38
-  %97 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 6
-  %98 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 6, i32 0, i32 2
-  %99 = bitcast %class.SourceInfo* %97 to %union.anon.108**
-  store %union.anon.108* %98, %union.anon.108** %99, align 16, !tbaa !46, !noalias !38
-  %100 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 6, i32 0, i32 1
-  store i64 0, i64* %100, align 8, !tbaa !48, !noalias !38
-  %101 = bitcast %union.anon.108* %98 to i8*
-  store i8 0, i8* %101, align 16, !tbaa !51, !noalias !38
-  %102 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 6, i32 1
-  store i32 -1, i32* %102, align 16, !tbaa !52, !noalias !38
-  %103 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 6, i32 2
-  store i32 -1, i32* %103, align 4, !tbaa !54, !noalias !38
-  %104 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 7
-  %105 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 7, i32 0, i32 2
-  %106 = bitcast %class.SourceInfo* %104 to %union.anon.108**
-  store %union.anon.108* %105, %union.anon.108** %106, align 8, !tbaa !46, !noalias !38
-  %107 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 7, i32 0, i32 1
-  store i64 0, i64* %107, align 8, !tbaa !48, !noalias !38
-  %108 = bitcast %union.anon.108* %105 to i8*
-  store i8 0, i8* %108, align 8, !tbaa !51, !noalias !38
-  %109 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 7, i32 1
-  store i32 -1, i32* %109, align 8, !tbaa !52, !noalias !38
-  %110 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 7, i32 2
-  store i32 -1, i32* %110, align 4, !tbaa !54, !noalias !38
-  %111 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 8
-  %112 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 8, i32 0, i32 2
-  %113 = bitcast %class.SourceInfo* %111 to %union.anon.108**
-  store %union.anon.108* %112, %union.anon.108** %113, align 16, !tbaa !46, !noalias !38
-  %114 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 8, i32 0, i32 1
-  store i64 0, i64* %114, align 8, !tbaa !48, !noalias !38
-  %115 = bitcast %union.anon.108* %112 to i8*
-  store i8 0, i8* %115, align 16, !tbaa !51, !noalias !38
-  %116 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 8, i32 1
-  store i32 -1, i32* %116, align 16, !tbaa !52, !noalias !38
-  %117 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 8, i32 2
-  store i32 -1, i32* %117, align 4, !tbaa !54, !noalias !38
-  %118 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 9
-  %119 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 9, i32 0, i32 2
-  %120 = bitcast %class.SourceInfo* %118 to %union.anon.108**
-  store %union.anon.108* %119, %union.anon.108** %120, align 8, !tbaa !46, !noalias !38
-  %121 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 9, i32 0, i32 1
-  store i64 0, i64* %121, align 8, !tbaa !48, !noalias !38
-  %122 = bitcast %union.anon.108* %119 to i8*
-  store i8 0, i8* %122, align 8, !tbaa !51, !noalias !38
-  %123 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 9, i32 1
-  store i32 -1, i32* %123, align 8, !tbaa !52, !noalias !38
-  %124 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 9, i32 2
-  store i32 -1, i32* %124, align 4, !tbaa !54, !noalias !38
-  %125 = getelementptr inbounds [1024 x i8], [1024 x i8]* %3, i64 0, i64 0
-  %126 = getelementptr inbounds %"class.std::vector.1", %"class.std::vector.1"* %5, i64 0, i32 0, i32 0, i32 1
-  %127 = bitcast %"class.std::__cxx11::basic_string"** %126 to i64*
-  %128 = bitcast %"class.std::__cxx11::basic_string"* %4 to i8*
-  %129 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %4, i64 0, i32 2
-  %130 = bitcast %"class.std::__cxx11::basic_string"* %4 to %union.anon.108**
-  %131 = bitcast %union.anon.108* %129 to i8*
-  %132 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %4, i64 0, i32 0, i32 0
-  %133 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %4, i64 0, i32 2, i32 0
-  %134 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %4, i64 0, i32 1
-  %135 = getelementptr inbounds %"class.std::vector.1", %"class.std::vector.1"* %5, i64 0, i32 0, i32 0, i32 0
-  %.promoted = load %"class.std::__cxx11::basic_string"*, %"class.std::__cxx11::basic_string"** %47, align 8, !tbaa !45, !alias.scope !38
-  br label %140
+64:                                               ; preds = %54
+  %65 = getelementptr inbounds %"class.std::vector.1", %"class.std::vector.1"* %6, i64 0, i32 0, i32 0, i32 1
+  %66 = bitcast %"class.std::__cxx11::basic_string"** %65 to i64*
+  %67 = load atomic i64, i64* %66 unordered, align 8, !tbaa !44, !alias.scope !31
+  %68 = sub i64 %67, %59
+  %69 = ashr exact i64 %68, 5
+  %70 = inttoptr i64 %67 to %"class.std::__cxx11::basic_string"*
+  %71 = call noalias i8* @calloc(i64 %37, i64 32) #37, !noalias !31
+  %72 = bitcast i8* %71 to %"class.std::__cxx11::basic_string"*
+  %73 = icmp eq %"class.std::__cxx11::basic_string"* %63, %70
+  br i1 %73, label %.critedge, label %.preheader9
 
-136:                                              ; preds = %272
-  store %"class.std::__cxx11::basic_string"* %273, %"class.std::__cxx11::basic_string"** %47, align 8, !tbaa !45, !alias.scope !38
-  %137 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 9, i32 0, i32 0, i32 0
-  %138 = load i8*, i8** %137, align 8, !tbaa !55, !noalias !38
-  %139 = icmp eq i8* %138, %122
-  br i1 %139, label %277, label %276
+.preheader9:                                      ; preds = %90, %64
+  %74 = phi %"class.std::__cxx11::basic_string"* [ %96, %90 ], [ %72, %64 ]
+  %75 = phi %"class.std::__cxx11::basic_string"* [ %95, %90 ], [ %63, %64 ]
+  %76 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %74, i64 0, i32 2
+  %77 = bitcast %"class.std::__cxx11::basic_string"* %74 to %union.anon.108**
+  store %union.anon.108* %76, %union.anon.108** %77, align 8, !tbaa !45, !noalias !31
+  %78 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %75, i64 0, i32 0, i32 0
+  %79 = load atomic i8*, i8** %78 unordered, align 8, !tbaa !47, !noalias !31
+  %80 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %75, i64 0, i32 2
+  %81 = bitcast %union.anon.108* %80 to i8*
+  %82 = icmp eq i8* %79, %81
+  br i1 %82, label %83, label %85
 
-140:                                              ; preds = %272, %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE7reserveEm.exit.i.i.i
-  %141 = phi %"class.std::__cxx11::basic_string"* [ %.promoted, %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE7reserveEm.exit.i.i.i ], [ %273, %272 ]
-  %142 = phi i64 [ 0, %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE7reserveEm.exit.i.i.i ], [ %274, %272 ]
-  %143 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %32, i64 %142
-  %144 = bitcast %struct.ObjHeader* %143 to i64*
-  %145 = load i64, i64* %144, align 8, !tbaa !3, !noalias !38
-  %146 = icmp ult i64 %145, 2
-  br i1 %146, label %272, label %147
+83:                                               ; preds = %.preheader9
+  %84 = bitcast %union.anon.108* %76 to i8*
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(16) %84, i8* nonnull align 8 dereferenceable(16) %79, i64 16, i1 false) #37, !noalias !31
+  br label %90
 
-147:                                              ; preds = %140
-  %148 = add i64 %145, -1
-  %149 = inttoptr i64 %148 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %125) #37, !noalias !38
-  %150 = load i64, i64* %127, align 8, !tbaa !44, !alias.scope !38
-  %151 = load i64, i64* %48, align 8, !tbaa !41, !alias.scope !38
-  %152 = sub i64 %150, %151
-  %153 = ashr exact i64 %152, 5
-  %154 = inttoptr i64 %150 to %"class.std::__cxx11::basic_string"*
-  invoke void (i8*, i64, i64, i8*, i1, i8*, ...) @_ZL18snprintf_with_addrPcmmPKvbPKcz(i8* nonnull %125, i64 undef, i64 %153, i8* %149, i1 zeroext false, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.69.559, i64 0, i64 0), i8* getelementptr inbounds ([1 x i8], [1 x i8]* @.str.7.558, i64 0, i64 0))
-          to label %155 unwind label %267, !noalias !38
+85:                                               ; preds = %.preheader9
+  %86 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %74, i64 0, i32 0, i32 0
+  store i8* %79, i8** %86, align 8, !tbaa !47, !noalias !31
+  %87 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %75, i64 0, i32 2, i32 0
+  %88 = load atomic i64, i64* %87 unordered, align 8, !tbaa !50, !noalias !31
+  %89 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %74, i64 0, i32 2, i32 0
+  store i64 %88, i64* %89, align 8, !tbaa !50, !noalias !31
+  br label %90
 
-155:                                              ; preds = %147
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %128) #37, !noalias !38
-  store %union.anon.108* %129, %union.anon.108** %130, align 8, !tbaa !56, !noalias !38
-  %156 = call i64 @strlen(i8* nonnull dereferenceable(1) %125) #37, !noalias !38
-  %157 = icmp ugt i64 %156, 15
-  br i1 %157, label %158, label %164
+90:                                               ; preds = %85, %83
+  %91 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %75, i64 0, i32 1
+  %92 = load atomic i64, i64* %91 unordered, align 8, !tbaa !51, !noalias !31
+  %93 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %74, i64 0, i32 1
+  store i64 %92, i64* %93, align 8, !tbaa !51, !noalias !31
+  %94 = bitcast %"class.std::__cxx11::basic_string"* %75 to %union.anon.108**
+  store %union.anon.108* %80, %union.anon.108** %94, align 8, !tbaa !47, !noalias !31
+  store i64 0, i64* %91, align 8, !tbaa !51, !noalias !31
+  store i8 0, i8* %81, align 8, !tbaa !50, !noalias !31
+  %95 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %75, i64 1
+  %96 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %74, i64 1
+  %97 = icmp eq %"class.std::__cxx11::basic_string"* %95, %70
+  br i1 %97, label %.loopexit10, label %.preheader9
 
-158:                                              ; preds = %155
-  %159 = icmp slt i64 %156, 0
-  br i1 %159, label %160, label %161
+.loopexit10:                                      ; preds = %90
+  br i1 %73, label %.critedge, label %.preheader8
 
-160:                                              ; preds = %158
-  call fastcc void @_ZSt20__throw_length_errorPKc(i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.14.134.831, i64 0, i64 0)) #51, !noalias !38
+.preheader8:                                      ; preds = %105, %.loopexit10
+  %98 = phi %"class.std::__cxx11::basic_string"* [ %106, %105 ], [ %63, %.loopexit10 ]
+  %99 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %98, i64 0, i32 0, i32 0
+  %100 = load atomic i8*, i8** %99 unordered, align 8, !tbaa !47, !noalias !31
+  %101 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %98, i64 0, i32 2
+  %102 = bitcast %union.anon.108* %101 to i8*
+  %103 = icmp eq i8* %100, %102
+  br i1 %103, label %105, label %104
+
+104:                                              ; preds = %.preheader8
+  call void @free(i8* %100) #37, !noalias !31
+  br label %105
+
+105:                                              ; preds = %104, %.preheader8
+  %106 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %98, i64 1
+  %107 = icmp eq %"class.std::__cxx11::basic_string"* %106, %70
+  br i1 %107, label %.critedge, label %.preheader8
+
+.critedge:                                        ; preds = %105, %.loopexit10, %64
+  %108 = icmp eq i64 %59, 0
+  br i1 %108, label %111, label %109
+
+109:                                              ; preds = %.critedge
+  %110 = inttoptr i64 %59 to i8*
+  call void @free(i8* %110) #37, !noalias !31
+  br label %111
+
+111:                                              ; preds = %109, %.critedge
+  %112 = bitcast %"class.std::vector.1"* %6 to i8**
+  store i8* %71, i8** %112, align 8, !tbaa !43, !alias.scope !31
+  %113 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %72, i64 %69
+  store %"class.std::__cxx11::basic_string"* %113, %"class.std::__cxx11::basic_string"** %65, align 8, !tbaa !44, !alias.scope !31
+  %114 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %72, i64 %37
+  store %"class.std::__cxx11::basic_string"* %114, %"class.std::__cxx11::basic_string"** %55, align 8, !tbaa !40, !alias.scope !31
+  br label %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE7reserveEm.exit.i.i.i
+
+_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE7reserveEm.exit.i.i.i: ; preds = %111, %54
+  %115 = icmp eq i32 %36, 0
+  br i1 %115, label %344, label %116
+
+116:                                              ; preds = %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE7reserveEm.exit.i.i.i
+  %117 = bitcast [10 x %class.SourceInfo]* %3 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 400, i8* nonnull %117) #37, !noalias !31
+  %118 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 0, i32 0, i32 2
+  %119 = bitcast [10 x %class.SourceInfo]* %3 to %union.anon.108**
+  store %union.anon.108* %118, %union.anon.108** %119, align 16, !tbaa !52, !noalias !31
+  %120 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 0, i32 0, i32 1
+  store i64 0, i64* %120, align 8, !tbaa !54, !noalias !31
+  %121 = bitcast %union.anon.108* %118 to i8*
+  store i8 0, i8* %121, align 16, !tbaa !50, !noalias !31
+  %122 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 0, i32 1
+  store i32 -1, i32* %122, align 16, !tbaa !56, !noalias !31
+  %123 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 0, i32 2
+  store i32 -1, i32* %123, align 4, !tbaa !58, !noalias !31
+  %124 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 1
+  %125 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 1, i32 0, i32 2
+  %126 = bitcast %class.SourceInfo* %124 to %union.anon.108**
+  store %union.anon.108* %125, %union.anon.108** %126, align 8, !tbaa !52, !noalias !31
+  %127 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 1, i32 0, i32 1
+  store i64 0, i64* %127, align 8, !tbaa !54, !noalias !31
+  %128 = bitcast %union.anon.108* %125 to i8*
+  store i8 0, i8* %128, align 8, !tbaa !50, !noalias !31
+  %129 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 1, i32 1
+  store i32 -1, i32* %129, align 8, !tbaa !56, !noalias !31
+  %130 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 1, i32 2
+  store i32 -1, i32* %130, align 4, !tbaa !58, !noalias !31
+  %131 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 2
+  %132 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 2, i32 0, i32 2
+  %133 = bitcast %class.SourceInfo* %131 to %union.anon.108**
+  store %union.anon.108* %132, %union.anon.108** %133, align 16, !tbaa !52, !noalias !31
+  %134 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 2, i32 0, i32 1
+  store i64 0, i64* %134, align 8, !tbaa !54, !noalias !31
+  %135 = bitcast %union.anon.108* %132 to i8*
+  store i8 0, i8* %135, align 16, !tbaa !50, !noalias !31
+  %136 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 2, i32 1
+  store i32 -1, i32* %136, align 16, !tbaa !56, !noalias !31
+  %137 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 2, i32 2
+  store i32 -1, i32* %137, align 4, !tbaa !58, !noalias !31
+  %138 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 3
+  %139 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 3, i32 0, i32 2
+  %140 = bitcast %class.SourceInfo* %138 to %union.anon.108**
+  store %union.anon.108* %139, %union.anon.108** %140, align 8, !tbaa !52, !noalias !31
+  %141 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 3, i32 0, i32 1
+  store i64 0, i64* %141, align 8, !tbaa !54, !noalias !31
+  %142 = bitcast %union.anon.108* %139 to i8*
+  store i8 0, i8* %142, align 8, !tbaa !50, !noalias !31
+  %143 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 3, i32 1
+  store i32 -1, i32* %143, align 8, !tbaa !56, !noalias !31
+  %144 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 3, i32 2
+  store i32 -1, i32* %144, align 4, !tbaa !58, !noalias !31
+  %145 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 4
+  %146 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 4, i32 0, i32 2
+  %147 = bitcast %class.SourceInfo* %145 to %union.anon.108**
+  store %union.anon.108* %146, %union.anon.108** %147, align 16, !tbaa !52, !noalias !31
+  %148 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 4, i32 0, i32 1
+  store i64 0, i64* %148, align 8, !tbaa !54, !noalias !31
+  %149 = bitcast %union.anon.108* %146 to i8*
+  store i8 0, i8* %149, align 16, !tbaa !50, !noalias !31
+  %150 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 4, i32 1
+  store i32 -1, i32* %150, align 16, !tbaa !56, !noalias !31
+  %151 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 4, i32 2
+  store i32 -1, i32* %151, align 4, !tbaa !58, !noalias !31
+  %152 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 5
+  %153 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 5, i32 0, i32 2
+  %154 = bitcast %class.SourceInfo* %152 to %union.anon.108**
+  store %union.anon.108* %153, %union.anon.108** %154, align 8, !tbaa !52, !noalias !31
+  %155 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 5, i32 0, i32 1
+  store i64 0, i64* %155, align 8, !tbaa !54, !noalias !31
+  %156 = bitcast %union.anon.108* %153 to i8*
+  store i8 0, i8* %156, align 8, !tbaa !50, !noalias !31
+  %157 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 5, i32 1
+  store i32 -1, i32* %157, align 8, !tbaa !56, !noalias !31
+  %158 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 5, i32 2
+  store i32 -1, i32* %158, align 4, !tbaa !58, !noalias !31
+  %159 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 6
+  %160 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 6, i32 0, i32 2
+  %161 = bitcast %class.SourceInfo* %159 to %union.anon.108**
+  store %union.anon.108* %160, %union.anon.108** %161, align 16, !tbaa !52, !noalias !31
+  %162 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 6, i32 0, i32 1
+  store i64 0, i64* %162, align 8, !tbaa !54, !noalias !31
+  %163 = bitcast %union.anon.108* %160 to i8*
+  store i8 0, i8* %163, align 16, !tbaa !50, !noalias !31
+  %164 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 6, i32 1
+  store i32 -1, i32* %164, align 16, !tbaa !56, !noalias !31
+  %165 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 6, i32 2
+  store i32 -1, i32* %165, align 4, !tbaa !58, !noalias !31
+  %166 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 7
+  %167 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 7, i32 0, i32 2
+  %168 = bitcast %class.SourceInfo* %166 to %union.anon.108**
+  store %union.anon.108* %167, %union.anon.108** %168, align 8, !tbaa !52, !noalias !31
+  %169 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 7, i32 0, i32 1
+  store i64 0, i64* %169, align 8, !tbaa !54, !noalias !31
+  %170 = bitcast %union.anon.108* %167 to i8*
+  store i8 0, i8* %170, align 8, !tbaa !50, !noalias !31
+  %171 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 7, i32 1
+  store i32 -1, i32* %171, align 8, !tbaa !56, !noalias !31
+  %172 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 7, i32 2
+  store i32 -1, i32* %172, align 4, !tbaa !58, !noalias !31
+  %173 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 8
+  %174 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 8, i32 0, i32 2
+  %175 = bitcast %class.SourceInfo* %173 to %union.anon.108**
+  store %union.anon.108* %174, %union.anon.108** %175, align 16, !tbaa !52, !noalias !31
+  %176 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 8, i32 0, i32 1
+  store i64 0, i64* %176, align 8, !tbaa !54, !noalias !31
+  %177 = bitcast %union.anon.108* %174 to i8*
+  store i8 0, i8* %177, align 16, !tbaa !50, !noalias !31
+  %178 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 8, i32 1
+  store i32 -1, i32* %178, align 16, !tbaa !56, !noalias !31
+  %179 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 8, i32 2
+  store i32 -1, i32* %179, align 4, !tbaa !58, !noalias !31
+  %180 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 9
+  %181 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 9, i32 0, i32 2
+  %182 = bitcast %class.SourceInfo* %180 to %union.anon.108**
+  store %union.anon.108* %181, %union.anon.108** %182, align 8, !tbaa !52, !noalias !31
+  %183 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 9, i32 0, i32 1
+  store i64 0, i64* %183, align 8, !tbaa !54, !noalias !31
+  %184 = bitcast %union.anon.108* %181 to i8*
+  store i8 0, i8* %184, align 8, !tbaa !50, !noalias !31
+  %185 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 9, i32 1
+  store i32 -1, i32* %185, align 8, !tbaa !56, !noalias !31
+  %186 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 9, i32 2
+  store i32 -1, i32* %186, align 4, !tbaa !58, !noalias !31
+  %187 = getelementptr inbounds [1024 x i8], [1024 x i8]* %4, i64 0, i64 0
+  %188 = getelementptr inbounds %"class.std::vector.1", %"class.std::vector.1"* %6, i64 0, i32 0, i32 0, i32 1
+  %189 = bitcast %"class.std::__cxx11::basic_string"** %188 to i64*
+  %190 = bitcast %"class.std::__cxx11::basic_string"* %5 to i8*
+  %191 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %5, i64 0, i32 2
+  %192 = bitcast %"class.std::__cxx11::basic_string"* %5 to %union.anon.108**
+  %193 = bitcast %union.anon.108* %191 to i8*
+  %194 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %5, i64 0, i32 0, i32 0
+  %195 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %5, i64 0, i32 2, i32 0
+  %196 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %5, i64 0, i32 1
+  %197 = getelementptr inbounds %"class.std::vector.1", %"class.std::vector.1"* %6, i64 0, i32 0, i32 0, i32 0
+  br label %202
+
+198:                                              ; preds = %331
+  %199 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 9, i32 0, i32 0, i32 0
+  %200 = load atomic i8*, i8** %199 unordered, align 8, !tbaa !59, !noalias !31
+  %201 = icmp eq i8* %200, %184
+  br i1 %201, label %335, label %334
+
+202:                                              ; preds = %331, %116
+  %203 = phi i64 [ 0, %116 ], [ %332, %331 ]
+  %204 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %33, i64 %203
+  %205 = bitcast %struct.ObjHeader* %204 to i64*
+  %206 = load atomic i64, i64* %205 unordered, align 8, !tbaa !3, !noalias !31
+  %207 = icmp ult i64 %206, 2
+  br i1 %207, label %331, label %208
+
+208:                                              ; preds = %202
+  %209 = add i64 %206, -1
+  %210 = inttoptr i64 %209 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 1024, i8* nonnull %187) #37, !noalias !31
+  %211 = load atomic i64, i64* %189 unordered, align 8, !tbaa !44, !alias.scope !31
+  %212 = load atomic i64, i64* %58 unordered, align 8, !tbaa !43, !alias.scope !31
+  %213 = sub i64 %211, %212
+  %214 = ashr exact i64 %213, 5
+  %215 = inttoptr i64 %211 to %"class.std::__cxx11::basic_string"*
+  invoke void (i8*, i64, i64, i8*, i1, i8*, ...) @_ZL18snprintf_with_addrPcmmPKvbPKcz(i8* nonnull %187, i64 undef, i64 %214, i8* %210, i1 zeroext false, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.69.559, i64 0, i64 0), i8* getelementptr inbounds ([1 x i8], [1 x i8]* @.str.7.558, i64 0, i64 0))
+          to label %216 unwind label %326, !noalias !31
+
+216:                                              ; preds = %208
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %190) #37, !noalias !31
+  store %union.anon.108* %191, %union.anon.108** %192, align 8, !tbaa !45, !noalias !31
+  %217 = call i64 @strlen(i8* nonnull dereferenceable(1) %187) #37, !noalias !31
+  %218 = icmp ugt i64 %217, 15
+  br i1 %218, label %219, label %225
+
+219:                                              ; preds = %216
+  %220 = icmp slt i64 %217, 0
+  br i1 %220, label %221, label %222
+
+221:                                              ; preds = %219
+  call fastcc void @_ZSt20__throw_length_errorPKc(i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.14.134.831, i64 0, i64 0)) #51, !noalias !31
   unreachable
 
-161:                                              ; preds = %158
-  %162 = add nuw i64 %156, 1
-  %163 = call noalias i8* @calloc(i64 %162, i64 1) #37, !noalias !38
-  store i8* %163, i8** %132, align 8, !tbaa !58, !noalias !38
-  store i64 %156, i64* %133, align 8, !tbaa !51, !noalias !38
-  br label %164
+222:                                              ; preds = %219
+  %223 = add nuw i64 %217, 1
+  %224 = call noalias i8* @calloc(i64 %223, i64 1) #37, !noalias !31
+  store i8* %224, i8** %194, align 8, !tbaa !47, !noalias !31
+  store i64 %217, i64* %195, align 8, !tbaa !50, !noalias !31
+  br label %225
 
-164:                                              ; preds = %161, %155
-  %165 = phi i8* [ %163, %161 ], [ %131, %155 ]
-  switch i64 %156, label %168 [
-    i64 1, label %166
-    i64 0, label %169
+225:                                              ; preds = %222, %216
+  %226 = phi i8* [ %224, %222 ], [ %193, %216 ]
+  switch i64 %217, label %229 [
+    i64 1, label %227
+    i64 0, label %230
   ]
 
-166:                                              ; preds = %164
-  %167 = load i8, i8* %125, align 16, !tbaa !51, !noalias !38
-  store i8 %167, i8* %165, align 1, !tbaa !51, !noalias !38
-  br label %169
+227:                                              ; preds = %225
+  %228 = load atomic i8, i8* %187 unordered, align 16, !tbaa !50, !noalias !31
+  store i8 %228, i8* %226, align 1, !tbaa !50, !noalias !31
+  br label %230
 
-168:                                              ; preds = %164
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %165, i8* nonnull align 16 %125, i64 %156, i1 false) #37, !noalias !38
-  br label %169
+229:                                              ; preds = %225
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %226, i8* nonnull align 16 %187, i64 %217, i1 false) #37, !noalias !31
+  br label %230
 
-169:                                              ; preds = %168, %166, %164
-  store i64 %156, i64* %134, align 8, !tbaa !60, !noalias !38
-  %170 = getelementptr inbounds i8, i8* %165, i64 %156
-  store i8 0, i8* %170, align 1, !tbaa !51, !noalias !38
-  %171 = icmp eq %"class.std::__cxx11::basic_string"* %141, %154
-  br i1 %171, label %187, label %172
+230:                                              ; preds = %229, %227, %225
+  store i64 %217, i64* %196, align 8, !tbaa !51, !noalias !31
+  %231 = load atomic i8*, i8** %194 unordered, align 8, !tbaa !47, !noalias !31
+  %232 = getelementptr inbounds i8, i8* %231, i64 %217
+  store i8 0, i8* %232, align 1, !tbaa !50, !noalias !31
+  %233 = load atomic %"class.std::__cxx11::basic_string"*, %"class.std::__cxx11::basic_string"** %55 unordered, align 8, !tbaa !40, !alias.scope !31
+  %234 = icmp eq %"class.std::__cxx11::basic_string"* %233, %215
+  br i1 %234, label %250, label %235
 
-172:                                              ; preds = %169
-  %173 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %154, i64 0, i32 2
-  %174 = inttoptr i64 %150 to %union.anon.108**
-  store %union.anon.108* %173, %union.anon.108** %174, align 8, !tbaa !56, !noalias !38
-  %175 = load i8*, i8** %132, align 8, !tbaa !58, !noalias !38
-  %176 = icmp eq i8* %175, %131
-  br i1 %176, label %177, label %179
+235:                                              ; preds = %230
+  %236 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %215, i64 0, i32 2
+  %237 = inttoptr i64 %211 to %union.anon.108**
+  store %union.anon.108* %236, %union.anon.108** %237, align 8, !tbaa !45, !noalias !31
+  %238 = load atomic i8*, i8** %194 unordered, align 8, !tbaa !47, !noalias !31
+  %239 = icmp eq i8* %238, %193
+  br i1 %239, label %240, label %242
 
-177:                                              ; preds = %172
-  %178 = bitcast %union.anon.108* %173 to i8*
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(16) %178, i8* nonnull align 8 dereferenceable(16) %131, i64 16, i1 false) #37, !noalias !38
-  br label %183
+240:                                              ; preds = %235
+  %241 = bitcast %union.anon.108* %236 to i8*
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(16) %241, i8* nonnull align 8 dereferenceable(16) %193, i64 16, i1 false) #37, !noalias !31
+  br label %246
 
-179:                                              ; preds = %172
-  %180 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %154, i64 0, i32 0, i32 0
-  store i8* %175, i8** %180, align 8, !tbaa !58, !noalias !38
-  %181 = load i64, i64* %133, align 8, !tbaa !51, !noalias !38
-  %182 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %154, i64 0, i32 2, i32 0
-  store i64 %181, i64* %182, align 8, !tbaa !51, !noalias !38
-  br label %183
+242:                                              ; preds = %235
+  %243 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %215, i64 0, i32 0, i32 0
+  store i8* %238, i8** %243, align 8, !tbaa !47, !noalias !31
+  %244 = load atomic i64, i64* %195 unordered, align 8, !tbaa !50, !noalias !31
+  %245 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %215, i64 0, i32 2, i32 0
+  store i64 %244, i64* %245, align 8, !tbaa !50, !noalias !31
+  br label %246
 
-183:                                              ; preds = %179, %177
-  %184 = load i64, i64* %134, align 8, !tbaa !60, !noalias !38
-  %185 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %154, i64 0, i32 1
-  store i64 %184, i64* %185, align 8, !tbaa !60, !noalias !38
-  store %union.anon.108* %129, %union.anon.108** %130, align 8, !tbaa !58, !noalias !38
-  store i64 0, i64* %134, align 8, !tbaa !60, !noalias !38
-  store i8 0, i8* %131, align 8, !tbaa !51, !noalias !38
-  %186 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %154, i64 1
-  store %"class.std::__cxx11::basic_string"* %186, %"class.std::__cxx11::basic_string"** %126, align 8, !tbaa !44, !alias.scope !38
-  br label %265
+246:                                              ; preds = %242, %240
+  %247 = load atomic i64, i64* %196 unordered, align 8, !tbaa !51, !noalias !31
+  %248 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %215, i64 0, i32 1
+  store i64 %247, i64* %248, align 8, !tbaa !51, !noalias !31
+  store %union.anon.108* %191, %union.anon.108** %192, align 8, !tbaa !47, !noalias !31
+  store i64 0, i64* %196, align 8, !tbaa !51, !noalias !31
+  store i8 0, i8* %193, align 8, !tbaa !50, !noalias !31
+  %249 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %215, i64 1
+  store %"class.std::__cxx11::basic_string"* %249, %"class.std::__cxx11::basic_string"** %188, align 8, !tbaa !44, !alias.scope !31
+  br label %325
 
-187:                                              ; preds = %169
-  %188 = ptrtoint %"class.std::__cxx11::basic_string"* %141 to i64
-  %189 = icmp eq i64 %152, 0
-  %190 = select i1 %189, i64 1, i64 %153
-  %191 = add nsw i64 %190, %153
-  %192 = icmp ult i64 %191, %153
-  %193 = icmp ugt i64 %191, 576460752303423487
-  %194 = or i1 %192, %193
-  %195 = select i1 %194, i64 576460752303423487, i64 %191
-  %196 = inttoptr i64 %151 to %"class.std::__cxx11::basic_string"*
-  %197 = sub i64 %188, %151
-  %198 = ashr exact i64 %197, 5
-  %199 = icmp eq i64 %195, 0
-  br i1 %199, label %203, label %200
+250:                                              ; preds = %230
+  %251 = icmp eq i64 %213, 0
+  %252 = select i1 %251, i64 1, i64 %214
+  %253 = add nsw i64 %252, %214
+  %254 = icmp ult i64 %253, %214
+  %255 = icmp ugt i64 %253, 576460752303423487
+  %256 = or i1 %254, %255
+  %257 = select i1 %256, i64 576460752303423487, i64 %253
+  %258 = inttoptr i64 %212 to %"class.std::__cxx11::basic_string"*
+  %259 = icmp eq i64 %257, 0
+  br i1 %259, label %263, label %260
 
-200:                                              ; preds = %187
-  %201 = call noalias i8* @calloc(i64 %195, i64 32) #37, !noalias !38
-  %202 = bitcast i8* %201 to %"class.std::__cxx11::basic_string"*
-  br label %203
+260:                                              ; preds = %250
+  %261 = call noalias i8* @calloc(i64 %257, i64 32) #37, !noalias !31
+  %262 = bitcast i8* %261 to %"class.std::__cxx11::basic_string"*
+  br label %263
 
-203:                                              ; preds = %200, %187
-  %204 = phi %"class.std::__cxx11::basic_string"* [ %202, %200 ], [ null, %187 ]
-  %205 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %204, i64 %198
-  %206 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %204, i64 %198, i32 2
-  %207 = bitcast %"class.std::__cxx11::basic_string"* %205 to %union.anon.108**
-  store %union.anon.108* %206, %union.anon.108** %207, align 8, !tbaa !56, !noalias !38
-  %208 = load i8*, i8** %132, align 8, !tbaa !58, !noalias !38
-  %209 = icmp eq i8* %208, %131
-  br i1 %209, label %210, label %212
+263:                                              ; preds = %260, %250
+  %264 = phi %"class.std::__cxx11::basic_string"* [ %262, %260 ], [ null, %250 ]
+  %265 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %264, i64 %214
+  %266 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %264, i64 %214, i32 2
+  %267 = bitcast %"class.std::__cxx11::basic_string"* %265 to %union.anon.108**
+  store %union.anon.108* %266, %union.anon.108** %267, align 8, !tbaa !45, !noalias !31
+  %268 = load atomic i8*, i8** %194 unordered, align 8, !tbaa !47, !noalias !31
+  %269 = icmp eq i8* %268, %193
+  br i1 %269, label %270, label %272
 
-210:                                              ; preds = %203
-  %211 = bitcast %union.anon.108* %206 to i8*
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(16) %211, i8* nonnull align 8 dereferenceable(16) %131, i64 16, i1 false) #37, !noalias !38
-  br label %216
+270:                                              ; preds = %263
+  %271 = bitcast %union.anon.108* %266 to i8*
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(16) %271, i8* nonnull align 8 dereferenceable(16) %193, i64 16, i1 false) #37, !noalias !31
+  br label %276
 
-212:                                              ; preds = %203
-  %213 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %205, i64 0, i32 0, i32 0
-  store i8* %208, i8** %213, align 8, !tbaa !58, !noalias !38
-  %214 = load i64, i64* %133, align 8, !tbaa !51, !noalias !38
-  %215 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %204, i64 %198, i32 2, i32 0
-  store i64 %214, i64* %215, align 8, !tbaa !51, !noalias !38
-  br label %216
+272:                                              ; preds = %263
+  %273 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %265, i64 0, i32 0, i32 0
+  store i8* %268, i8** %273, align 8, !tbaa !47, !noalias !31
+  %274 = load atomic i64, i64* %195 unordered, align 8, !tbaa !50, !noalias !31
+  %275 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %264, i64 %214, i32 2, i32 0
+  store i64 %274, i64* %275, align 8, !tbaa !50, !noalias !31
+  br label %276
 
-216:                                              ; preds = %212, %210
-  %217 = load i64, i64* %134, align 8, !tbaa !60, !noalias !38
-  %218 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %204, i64 %198, i32 1
-  store i64 %217, i64* %218, align 8, !tbaa !60, !noalias !38
-  store %union.anon.108* %129, %union.anon.108** %130, align 8, !tbaa !58, !noalias !38
-  store i64 0, i64* %134, align 8, !tbaa !60, !noalias !38
-  store i8 0, i8* %131, align 8, !tbaa !51, !noalias !38
-  %219 = icmp eq %"class.std::__cxx11::basic_string"* %141, %196
-  br i1 %219, label %.loopexit16.thread, label %.preheader15
+276:                                              ; preds = %272, %270
+  %277 = load atomic i64, i64* %196 unordered, align 8, !tbaa !51, !noalias !31
+  %278 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %264, i64 %214, i32 1
+  store i64 %277, i64* %278, align 8, !tbaa !51, !noalias !31
+  store %union.anon.108* %191, %union.anon.108** %192, align 8, !tbaa !47, !noalias !31
+  store i64 0, i64* %196, align 8, !tbaa !51, !noalias !31
+  store i8 0, i8* %193, align 8, !tbaa !50, !noalias !31
+  %279 = icmp eq %"class.std::__cxx11::basic_string"* %215, %258
+  br i1 %279, label %.loopexit7.thread, label %.preheader6
 
-.loopexit16.thread:                               ; preds = %216
-  %220 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %204, i64 1
-  br label %.loopexit12
+.loopexit7.thread:                                ; preds = %276
+  %280 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %264, i64 1
+  br label %.loopexit3
 
-.preheader15:                                     ; preds = %237, %216
-  %221 = phi %"class.std::__cxx11::basic_string"* [ %243, %237 ], [ %204, %216 ]
-  %222 = phi %"class.std::__cxx11::basic_string"* [ %242, %237 ], [ %196, %216 ]
-  %223 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %221, i64 0, i32 2
-  %224 = bitcast %"class.std::__cxx11::basic_string"* %221 to %union.anon.108**
-  store %union.anon.108* %223, %union.anon.108** %224, align 8, !tbaa !56, !noalias !38
-  %225 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %222, i64 0, i32 0, i32 0
-  %226 = load i8*, i8** %225, align 8, !tbaa !58, !noalias !38
-  %227 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %222, i64 0, i32 2
-  %228 = bitcast %union.anon.108* %227 to i8*
-  %229 = icmp eq i8* %226, %228
-  br i1 %229, label %230, label %232
+.preheader6:                                      ; preds = %297, %276
+  %281 = phi %"class.std::__cxx11::basic_string"* [ %303, %297 ], [ %264, %276 ]
+  %282 = phi %"class.std::__cxx11::basic_string"* [ %302, %297 ], [ %258, %276 ]
+  %283 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %281, i64 0, i32 2
+  %284 = bitcast %"class.std::__cxx11::basic_string"* %281 to %union.anon.108**
+  store %union.anon.108* %283, %union.anon.108** %284, align 8, !tbaa !45, !noalias !31
+  %285 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %282, i64 0, i32 0, i32 0
+  %286 = load atomic i8*, i8** %285 unordered, align 8, !tbaa !47, !noalias !31
+  %287 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %282, i64 0, i32 2
+  %288 = bitcast %union.anon.108* %287 to i8*
+  %289 = icmp eq i8* %286, %288
+  br i1 %289, label %290, label %292
 
-230:                                              ; preds = %.preheader15
-  %231 = bitcast %union.anon.108* %223 to i8*
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(16) %231, i8* nonnull align 8 dereferenceable(16) %226, i64 16, i1 false) #37, !noalias !38
-  br label %237
+290:                                              ; preds = %.preheader6
+  %291 = bitcast %union.anon.108* %283 to i8*
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(16) %291, i8* nonnull align 8 dereferenceable(16) %286, i64 16, i1 false) #37, !noalias !31
+  br label %297
 
-232:                                              ; preds = %.preheader15
-  %233 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %221, i64 0, i32 0, i32 0
-  store i8* %226, i8** %233, align 8, !tbaa !58, !noalias !38
-  %234 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %222, i64 0, i32 2, i32 0
-  %235 = load i64, i64* %234, align 8, !tbaa !51, !noalias !38
-  %236 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %221, i64 0, i32 2, i32 0
-  store i64 %235, i64* %236, align 8, !tbaa !51, !noalias !38
-  br label %237
+292:                                              ; preds = %.preheader6
+  %293 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %281, i64 0, i32 0, i32 0
+  store i8* %286, i8** %293, align 8, !tbaa !47, !noalias !31
+  %294 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %282, i64 0, i32 2, i32 0
+  %295 = load atomic i64, i64* %294 unordered, align 8, !tbaa !50, !noalias !31
+  %296 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %281, i64 0, i32 2, i32 0
+  store i64 %295, i64* %296, align 8, !tbaa !50, !noalias !31
+  br label %297
 
-237:                                              ; preds = %232, %230
-  %238 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %222, i64 0, i32 1
-  %239 = load i64, i64* %238, align 8, !tbaa !60, !noalias !38
-  %240 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %221, i64 0, i32 1
-  store i64 %239, i64* %240, align 8, !tbaa !60, !noalias !38
-  %241 = bitcast %"class.std::__cxx11::basic_string"* %222 to %union.anon.108**
-  store %union.anon.108* %227, %union.anon.108** %241, align 8, !tbaa !58, !noalias !38
-  store i64 0, i64* %238, align 8, !tbaa !60, !noalias !38
-  store i8 0, i8* %228, align 8, !tbaa !51, !noalias !38
-  %242 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %222, i64 1
-  %243 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %221, i64 1
-  %244 = icmp eq %"class.std::__cxx11::basic_string"* %242, %141
-  br i1 %244, label %.loopexit16, label %.preheader15
+297:                                              ; preds = %292, %290
+  %298 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %282, i64 0, i32 1
+  %299 = load atomic i64, i64* %298 unordered, align 8, !tbaa !51, !noalias !31
+  %300 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %281, i64 0, i32 1
+  store i64 %299, i64* %300, align 8, !tbaa !51, !noalias !31
+  %301 = bitcast %"class.std::__cxx11::basic_string"* %282 to %union.anon.108**
+  store %union.anon.108* %287, %union.anon.108** %301, align 8, !tbaa !47, !noalias !31
+  store i64 0, i64* %298, align 8, !tbaa !51, !noalias !31
+  store i8 0, i8* %288, align 8, !tbaa !50, !noalias !31
+  %302 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %282, i64 1
+  %303 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %281, i64 1
+  %304 = icmp eq %"class.std::__cxx11::basic_string"* %302, %215
+  br i1 %304, label %.loopexit7, label %.preheader6
 
-.loopexit16:                                      ; preds = %237
-  %245 = phi %"class.std::__cxx11::basic_string"* [ %243, %237 ]
-  %246 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %245, i64 1
-  br i1 %219, label %.loopexit12, label %.preheader11
+.loopexit7:                                       ; preds = %297
+  %305 = phi %"class.std::__cxx11::basic_string"* [ %303, %297 ]
+  %306 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %305, i64 1
+  br i1 %279, label %.loopexit3, label %.preheader2
 
-.preheader11:                                     ; preds = %254, %.loopexit16
-  %247 = phi %"class.std::__cxx11::basic_string"* [ %255, %254 ], [ %196, %.loopexit16 ]
-  %248 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %247, i64 0, i32 0, i32 0
-  %249 = load i8*, i8** %248, align 8, !tbaa !58, !noalias !38
-  %250 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %247, i64 0, i32 2
-  %251 = bitcast %union.anon.108* %250 to i8*
-  %252 = icmp eq i8* %249, %251
-  br i1 %252, label %254, label %253
+.preheader2:                                      ; preds = %314, %.loopexit7
+  %307 = phi %"class.std::__cxx11::basic_string"* [ %315, %314 ], [ %258, %.loopexit7 ]
+  %308 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %307, i64 0, i32 0, i32 0
+  %309 = load atomic i8*, i8** %308 unordered, align 8, !tbaa !47, !noalias !31
+  %310 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %307, i64 0, i32 2
+  %311 = bitcast %union.anon.108* %310 to i8*
+  %312 = icmp eq i8* %309, %311
+  br i1 %312, label %314, label %313
 
-253:                                              ; preds = %.preheader11
-  call void @free(i8* %249) #37, !noalias !38
-  br label %254
+313:                                              ; preds = %.preheader2
+  call void @free(i8* %309) #37, !noalias !31
+  br label %314
 
-254:                                              ; preds = %253, %.preheader11
-  %255 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %247, i64 1
-  %256 = icmp eq %"class.std::__cxx11::basic_string"* %255, %141
-  br i1 %256, label %.loopexit12, label %.preheader11
+314:                                              ; preds = %313, %.preheader2
+  %315 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %307, i64 1
+  %316 = icmp eq %"class.std::__cxx11::basic_string"* %315, %215
+  br i1 %316, label %.loopexit3, label %.preheader2
 
-.loopexit12:                                      ; preds = %254, %.loopexit16, %.loopexit16.thread
-  %257 = phi %"class.std::__cxx11::basic_string"* [ %220, %.loopexit16.thread ], [ %246, %254 ], [ %246, %.loopexit16 ]
-  %258 = icmp eq i64 %151, 0
-  br i1 %258, label %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE17_M_realloc_insertIJS8_EEEvN9__gnu_cxx17__normal_iteratorIPS8_SA_EEDpOT_.exit.i.i.i, label %259
+.loopexit3:                                       ; preds = %314, %.loopexit7, %.loopexit7.thread
+  %317 = phi %"class.std::__cxx11::basic_string"* [ %280, %.loopexit7.thread ], [ %306, %314 ], [ %306, %.loopexit7 ]
+  %318 = icmp eq i64 %212, 0
+  br i1 %318, label %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE17_M_realloc_insertIJS8_EEEvN9__gnu_cxx17__normal_iteratorIPS8_SA_EEDpOT_.exit.i.i.i, label %319
 
-259:                                              ; preds = %.loopexit12
-  %260 = inttoptr i64 %151 to i8*
-  call void @free(i8* %260) #37, !noalias !38
+319:                                              ; preds = %.loopexit3
+  %320 = inttoptr i64 %212 to i8*
+  call void @free(i8* %320) #37, !noalias !31
   br label %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE17_M_realloc_insertIJS8_EEEvN9__gnu_cxx17__normal_iteratorIPS8_SA_EEDpOT_.exit.i.i.i
 
-_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE17_M_realloc_insertIJS8_EEEvN9__gnu_cxx17__normal_iteratorIPS8_SA_EEDpOT_.exit.i.i.i: ; preds = %259, %.loopexit12
-  store %"class.std::__cxx11::basic_string"* %204, %"class.std::__cxx11::basic_string"** %135, align 8, !tbaa !41, !alias.scope !38
-  store %"class.std::__cxx11::basic_string"* %257, %"class.std::__cxx11::basic_string"** %126, align 8, !tbaa !44, !alias.scope !38
-  %261 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %204, i64 %195
-  %262 = load i8*, i8** %132, align 8, !tbaa !58, !noalias !38
-  %263 = icmp eq i8* %262, %131
-  br i1 %263, label %265, label %264
+_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE17_M_realloc_insertIJS8_EEEvN9__gnu_cxx17__normal_iteratorIPS8_SA_EEDpOT_.exit.i.i.i: ; preds = %319, %.loopexit3
+  store %"class.std::__cxx11::basic_string"* %264, %"class.std::__cxx11::basic_string"** %197, align 8, !tbaa !43, !alias.scope !31
+  store %"class.std::__cxx11::basic_string"* %317, %"class.std::__cxx11::basic_string"** %188, align 8, !tbaa !44, !alias.scope !31
+  %321 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %264, i64 %257
+  store %"class.std::__cxx11::basic_string"* %321, %"class.std::__cxx11::basic_string"** %55, align 8, !tbaa !40, !alias.scope !31
+  %322 = load atomic i8*, i8** %194 unordered, align 8, !tbaa !47, !noalias !31
+  %323 = icmp eq i8* %322, %193
+  br i1 %323, label %325, label %324
 
-264:                                              ; preds = %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE17_M_realloc_insertIJS8_EEEvN9__gnu_cxx17__normal_iteratorIPS8_SA_EEDpOT_.exit.i.i.i
-  call void @free(i8* %262) #37, !noalias !38
-  br label %265
+324:                                              ; preds = %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE17_M_realloc_insertIJS8_EEEvN9__gnu_cxx17__normal_iteratorIPS8_SA_EEDpOT_.exit.i.i.i
+  call void @free(i8* %322) #37, !noalias !31
+  br label %325
 
-265:                                              ; preds = %264, %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE17_M_realloc_insertIJS8_EEEvN9__gnu_cxx17__normal_iteratorIPS8_SA_EEDpOT_.exit.i.i.i, %183
-  %266 = phi %"class.std::__cxx11::basic_string"* [ %261, %264 ], [ %261, %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE17_M_realloc_insertIJS8_EEEvN9__gnu_cxx17__normal_iteratorIPS8_SA_EEDpOT_.exit.i.i.i ], [ %141, %183 ]
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %128) #37, !noalias !38
-  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %125) #37, !noalias !38
-  br label %272
+325:                                              ; preds = %324, %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE17_M_realloc_insertIJS8_EEEvN9__gnu_cxx17__normal_iteratorIPS8_SA_EEDpOT_.exit.i.i.i, %246
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %190) #37, !noalias !31
+  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %187) #37, !noalias !31
+  br label %331
 
-267:                                              ; preds = %147
-  %268 = landingpad { i8*, i32 }
+326:                                              ; preds = %208
+  %327 = landingpad { i8*, i32 }
           catch i8* null
-  store %"class.std::__cxx11::basic_string"* %141, %"class.std::__cxx11::basic_string"** %47, align 8, !tbaa !45, !alias.scope !38
-  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %125) #37, !noalias !38
-  %269 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 9, i32 0, i32 0, i32 0
-  %270 = load i8*, i8** %269, align 8, !tbaa !55, !noalias !38
-  %271 = icmp eq i8* %270, %122
-  br i1 %271, label %282, label %281
+  call void @llvm.lifetime.end.p0i8(i64 1024, i8* nonnull %187) #37, !noalias !31
+  %328 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 9, i32 0, i32 0, i32 0
+  %329 = load atomic i8*, i8** %328 unordered, align 8, !tbaa !59, !noalias !31
+  %330 = icmp eq i8* %329, %184
+  br i1 %330, label %340, label %339
 
-272:                                              ; preds = %265, %140
-  %273 = phi %"class.std::__cxx11::basic_string"* [ %266, %265 ], [ %141, %140 ]
-  %274 = add nuw nsw i64 %142, 1
-  %275 = icmp eq i64 %274, %36
-  br i1 %275, label %136, label %140
+331:                                              ; preds = %325, %202
+  %332 = add nuw nsw i64 %203, 1
+  %333 = icmp eq i64 %332, %37
+  br i1 %333, label %198, label %202
 
-276:                                              ; preds = %136
-  call void @_ZdlPv(i8* %138) #37, !noalias !38
-  br label %277
+334:                                              ; preds = %198
+  call void @_ZdlPv(i8* %200) #37, !noalias !31
+  br label %335
 
-277:                                              ; preds = %276, %136
-  %278 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 8, i32 0, i32 0, i32 0
-  %279 = load i8*, i8** %278, align 16, !tbaa !55, !noalias !38
-  %280 = icmp eq i8* %279, %115
-  br i1 %280, label %302, label %301
+335:                                              ; preds = %334, %198
+  %336 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 8, i32 0, i32 0, i32 0
+  %337 = load atomic i8*, i8** %336 unordered, align 16, !tbaa !59, !noalias !31
+  %338 = icmp eq i8* %337, %177
+  br i1 %338, label %363, label %362
 
-281:                                              ; preds = %267
-  call void @_ZdlPv(i8* %270) #37, !noalias !38
-  br label %282
+339:                                              ; preds = %326
+  call void @_ZdlPv(i8* %329) #37, !noalias !31
+  br label %340
 
-282:                                              ; preds = %281, %267
-  %283 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 8, i32 0, i32 0, i32 0
-  %284 = load i8*, i8** %283, align 16, !tbaa !55, !noalias !38
-  %285 = icmp eq i8* %284, %115
-  br i1 %285, label %344, label %343
+340:                                              ; preds = %339, %326
+  %341 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 8, i32 0, i32 0, i32 0
+  %342 = load atomic i8*, i8** %341 unordered, align 16, !tbaa !59, !noalias !31
+  %343 = icmp eq i8* %342, %177
+  br i1 %343, label %405, label %404
 
-286:                                              ; preds = %342, %46
-  %287 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %.sroa.3.0, null
-  br i1 %287, label %_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE.exit.i.i, label %288
+344:                                              ; preds = %403, %_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE7reserveEm.exit.i.i.i
+  %345 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %2, i64 0, i32 1, i32 0
+  %346 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %345 unordered, align 8, !tbaa !34, !noalias !31
+  %347 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %346, null
+  br i1 %347, label %_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE.exit.i.i, label %348
 
-288:                                              ; preds = %286
-  %289 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %.sroa.3.0, i64 328
-  %290 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %289 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %291 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %289 to i32*
-  %292 = atomicrmw xchg i32* %291, i32 %.sroa.7.0 seq_cst, align 4, !noalias !38
-  %293 = icmp eq i32 %292, 1
-  %294 = icmp eq i32 %.sroa.7.0, 0
-  %295 = and i1 %294, %293
-  br i1 %295, label %296, label %_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE.exit.i.i
+348:                                              ; preds = %344
+  %349 = load atomic i32, i32* %46 unordered, align 8, !tbaa !38, !noalias !31
+  %350 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %346, i64 328
+  %351 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %350 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %352 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %350 to i32*
+  %353 = atomicrmw xchg i32* %352, i32 %349 seq_cst, align 4, !noalias !31
+  %354 = icmp eq i32 %353, 1
+  %355 = icmp eq i32 %349, 0
+  %356 = and i1 %355, %354
+  br i1 %356, label %357, label %_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE.exit.i.i
 
-296:                                              ; preds = %288
-  %297 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1, !noalias !38
-  %298 = and i8 %297, 1
-  %299 = icmp eq i8 %298, 0
-  br i1 %299, label %_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE.exit.i.i, label %300
+357:                                              ; preds = %348
+  %358 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1, !noalias !31
+  %359 = and i8 %358, 1
+  %360 = icmp eq i8 %359, 0
+  br i1 %360, label %_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE.exit.i.i, label %361
 
-300:                                              ; preds = %296
-  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %290) #37, !noalias !38
+361:                                              ; preds = %357
+  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %351) #37, !noalias !31
   br label %_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE.exit.i.i
 
-301:                                              ; preds = %277
-  call void @_ZdlPv(i8* %279) #37, !noalias !38
-  br label %302
-
-302:                                              ; preds = %301, %277
-  %303 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 7, i32 0, i32 0, i32 0
-  %304 = load i8*, i8** %303, align 8, !tbaa !55, !noalias !38
-  %305 = icmp eq i8* %304, %108
-  br i1 %305, label %307, label %306
+362:                                              ; preds = %335
+  call void @_ZdlPv(i8* %337) #37, !noalias !31
+  br label %363
 
-306:                                              ; preds = %302
-  call void @_ZdlPv(i8* %304) #37, !noalias !38
-  br label %307
+363:                                              ; preds = %362, %335
+  %364 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 7, i32 0, i32 0, i32 0
+  %365 = load atomic i8*, i8** %364 unordered, align 8, !tbaa !59, !noalias !31
+  %366 = icmp eq i8* %365, %170
+  br i1 %366, label %368, label %367
 
-307:                                              ; preds = %306, %302
-  %308 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 6, i32 0, i32 0, i32 0
-  %309 = load i8*, i8** %308, align 16, !tbaa !55, !noalias !38
-  %310 = icmp eq i8* %309, %101
-  br i1 %310, label %312, label %311
+367:                                              ; preds = %363
+  call void @_ZdlPv(i8* %365) #37, !noalias !31
+  br label %368
 
-311:                                              ; preds = %307
-  call void @_ZdlPv(i8* %309) #37, !noalias !38
-  br label %312
+368:                                              ; preds = %367, %363
+  %369 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 6, i32 0, i32 0, i32 0
+  %370 = load atomic i8*, i8** %369 unordered, align 16, !tbaa !59, !noalias !31
+  %371 = icmp eq i8* %370, %163
+  br i1 %371, label %373, label %372
 
-312:                                              ; preds = %311, %307
-  %313 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 5, i32 0, i32 0, i32 0
-  %314 = load i8*, i8** %313, align 8, !tbaa !55, !noalias !38
-  %315 = icmp eq i8* %314, %94
-  br i1 %315, label %317, label %316
+372:                                              ; preds = %368
+  call void @_ZdlPv(i8* %370) #37, !noalias !31
+  br label %373
 
-316:                                              ; preds = %312
-  call void @_ZdlPv(i8* %314) #37, !noalias !38
-  br label %317
+373:                                              ; preds = %372, %368
+  %374 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 5, i32 0, i32 0, i32 0
+  %375 = load atomic i8*, i8** %374 unordered, align 8, !tbaa !59, !noalias !31
+  %376 = icmp eq i8* %375, %156
+  br i1 %376, label %378, label %377
 
-317:                                              ; preds = %316, %312
-  %318 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 4, i32 0, i32 0, i32 0
-  %319 = load i8*, i8** %318, align 16, !tbaa !55, !noalias !38
-  %320 = icmp eq i8* %319, %87
-  br i1 %320, label %322, label %321
+377:                                              ; preds = %373
+  call void @_ZdlPv(i8* %375) #37, !noalias !31
+  br label %378
 
-321:                                              ; preds = %317
-  call void @_ZdlPv(i8* %319) #37, !noalias !38
-  br label %322
+378:                                              ; preds = %377, %373
+  %379 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 4, i32 0, i32 0, i32 0
+  %380 = load atomic i8*, i8** %379 unordered, align 16, !tbaa !59, !noalias !31
+  %381 = icmp eq i8* %380, %149
+  br i1 %381, label %383, label %382
 
-322:                                              ; preds = %321, %317
-  %323 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 3, i32 0, i32 0, i32 0
-  %324 = load i8*, i8** %323, align 8, !tbaa !55, !noalias !38
-  %325 = icmp eq i8* %324, %80
-  br i1 %325, label %327, label %326
+382:                                              ; preds = %378
+  call void @_ZdlPv(i8* %380) #37, !noalias !31
+  br label %383
 
-326:                                              ; preds = %322
-  call void @_ZdlPv(i8* %324) #37, !noalias !38
-  br label %327
+383:                                              ; preds = %382, %378
+  %384 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 3, i32 0, i32 0, i32 0
+  %385 = load atomic i8*, i8** %384 unordered, align 8, !tbaa !59, !noalias !31
+  %386 = icmp eq i8* %385, %142
+  br i1 %386, label %388, label %387
 
-327:                                              ; preds = %326, %322
-  %328 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 2, i32 0, i32 0, i32 0
-  %329 = load i8*, i8** %328, align 16, !tbaa !55, !noalias !38
-  %330 = icmp eq i8* %329, %73
-  br i1 %330, label %332, label %331
+387:                                              ; preds = %383
+  call void @_ZdlPv(i8* %385) #37, !noalias !31
+  br label %388
 
-331:                                              ; preds = %327
-  call void @_ZdlPv(i8* %329) #37, !noalias !38
-  br label %332
+388:                                              ; preds = %387, %383
+  %389 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 2, i32 0, i32 0, i32 0
+  %390 = load atomic i8*, i8** %389 unordered, align 16, !tbaa !59, !noalias !31
+  %391 = icmp eq i8* %390, %135
+  br i1 %391, label %393, label %392
 
-332:                                              ; preds = %331, %327
-  %333 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 1, i32 0, i32 0, i32 0
-  %334 = load i8*, i8** %333, align 8, !tbaa !55, !noalias !38
-  %335 = icmp eq i8* %334, %66
-  br i1 %335, label %337, label %336
+392:                                              ; preds = %388
+  call void @_ZdlPv(i8* %390) #37, !noalias !31
+  br label %393
 
-336:                                              ; preds = %332
-  call void @_ZdlPv(i8* %334) #37, !noalias !38
-  br label %337
+393:                                              ; preds = %392, %388
+  %394 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 1, i32 0, i32 0, i32 0
+  %395 = load atomic i8*, i8** %394 unordered, align 8, !tbaa !59, !noalias !31
+  %396 = icmp eq i8* %395, %128
+  br i1 %396, label %398, label %397
 
-337:                                              ; preds = %336, %332
-  %338 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 0, i32 0, i32 0, i32 0
-  %339 = load i8*, i8** %338, align 16, !tbaa !55, !noalias !38
-  %340 = icmp eq i8* %339, %59
-  br i1 %340, label %342, label %341
+397:                                              ; preds = %393
+  call void @_ZdlPv(i8* %395) #37, !noalias !31
+  br label %398
 
-341:                                              ; preds = %337
-  call void @_ZdlPv(i8* %339) #37, !noalias !38
-  br label %342
+398:                                              ; preds = %397, %393
+  %399 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 0, i32 0, i32 0, i32 0
+  %400 = load atomic i8*, i8** %399 unordered, align 16, !tbaa !59, !noalias !31
+  %401 = icmp eq i8* %400, %121
+  br i1 %401, label %403, label %402
 
-342:                                              ; preds = %341, %337
-  call void @llvm.lifetime.end.p0i8(i64 400, i8* nonnull %55) #37, !noalias !38
-  br label %286
+402:                                              ; preds = %398
+  call void @_ZdlPv(i8* %400) #37, !noalias !31
+  br label %403
 
-343:                                              ; preds = %282
-  call void @_ZdlPv(i8* %284) #37, !noalias !38
+403:                                              ; preds = %402, %398
+  call void @llvm.lifetime.end.p0i8(i64 400, i8* nonnull %117) #37, !noalias !31
   br label %344
 
-344:                                              ; preds = %343, %282
-  %345 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 7, i32 0, i32 0, i32 0
-  %346 = load i8*, i8** %345, align 8, !tbaa !55, !noalias !38
-  %347 = icmp eq i8* %346, %108
-  br i1 %347, label %349, label %348
+404:                                              ; preds = %340
+  call void @_ZdlPv(i8* %342) #37, !noalias !31
+  br label %405
 
-348:                                              ; preds = %344
-  call void @_ZdlPv(i8* %346) #37, !noalias !38
-  br label %349
+405:                                              ; preds = %404, %340
+  %406 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 7, i32 0, i32 0, i32 0
+  %407 = load atomic i8*, i8** %406 unordered, align 8, !tbaa !59, !noalias !31
+  %408 = icmp eq i8* %407, %170
+  br i1 %408, label %410, label %409
 
-349:                                              ; preds = %348, %344
-  %350 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 6, i32 0, i32 0, i32 0
-  %351 = load i8*, i8** %350, align 16, !tbaa !55, !noalias !38
-  %352 = icmp eq i8* %351, %101
-  br i1 %352, label %354, label %353
+409:                                              ; preds = %405
+  call void @_ZdlPv(i8* %407) #37, !noalias !31
+  br label %410
 
-353:                                              ; preds = %349
-  call void @_ZdlPv(i8* %351) #37, !noalias !38
-  br label %354
+410:                                              ; preds = %409, %405
+  %411 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 6, i32 0, i32 0, i32 0
+  %412 = load atomic i8*, i8** %411 unordered, align 16, !tbaa !59, !noalias !31
+  %413 = icmp eq i8* %412, %163
+  br i1 %413, label %415, label %414
 
-354:                                              ; preds = %353, %349
-  %355 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 5, i32 0, i32 0, i32 0
-  %356 = load i8*, i8** %355, align 8, !tbaa !55, !noalias !38
-  %357 = icmp eq i8* %356, %94
-  br i1 %357, label %359, label %358
+414:                                              ; preds = %410
+  call void @_ZdlPv(i8* %412) #37, !noalias !31
+  br label %415
 
-358:                                              ; preds = %354
-  call void @_ZdlPv(i8* %356) #37, !noalias !38
-  br label %359
+415:                                              ; preds = %414, %410
+  %416 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 5, i32 0, i32 0, i32 0
+  %417 = load atomic i8*, i8** %416 unordered, align 8, !tbaa !59, !noalias !31
+  %418 = icmp eq i8* %417, %156
+  br i1 %418, label %420, label %419
 
-359:                                              ; preds = %358, %354
-  %360 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 4, i32 0, i32 0, i32 0
-  %361 = load i8*, i8** %360, align 16, !tbaa !55, !noalias !38
-  %362 = icmp eq i8* %361, %87
-  br i1 %362, label %364, label %363
+419:                                              ; preds = %415
+  call void @_ZdlPv(i8* %417) #37, !noalias !31
+  br label %420
 
-363:                                              ; preds = %359
-  call void @_ZdlPv(i8* %361) #37, !noalias !38
-  br label %364
+420:                                              ; preds = %419, %415
+  %421 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 4, i32 0, i32 0, i32 0
+  %422 = load atomic i8*, i8** %421 unordered, align 16, !tbaa !59, !noalias !31
+  %423 = icmp eq i8* %422, %149
+  br i1 %423, label %425, label %424
 
-364:                                              ; preds = %363, %359
-  %365 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 3, i32 0, i32 0, i32 0
-  %366 = load i8*, i8** %365, align 8, !tbaa !55, !noalias !38
-  %367 = icmp eq i8* %366, %80
-  br i1 %367, label %369, label %368
+424:                                              ; preds = %420
+  call void @_ZdlPv(i8* %422) #37, !noalias !31
+  br label %425
 
-368:                                              ; preds = %364
-  call void @_ZdlPv(i8* %366) #37, !noalias !38
-  br label %369
+425:                                              ; preds = %424, %420
+  %426 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 3, i32 0, i32 0, i32 0
+  %427 = load atomic i8*, i8** %426 unordered, align 8, !tbaa !59, !noalias !31
+  %428 = icmp eq i8* %427, %142
+  br i1 %428, label %430, label %429
 
-369:                                              ; preds = %368, %364
-  %370 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 2, i32 0, i32 0, i32 0
-  %371 = load i8*, i8** %370, align 16, !tbaa !55, !noalias !38
-  %372 = icmp eq i8* %371, %73
-  br i1 %372, label %374, label %373
+429:                                              ; preds = %425
+  call void @_ZdlPv(i8* %427) #37, !noalias !31
+  br label %430
 
-373:                                              ; preds = %369
-  call void @_ZdlPv(i8* %371) #37, !noalias !38
-  br label %374
+430:                                              ; preds = %429, %425
+  %431 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 2, i32 0, i32 0, i32 0
+  %432 = load atomic i8*, i8** %431 unordered, align 16, !tbaa !59, !noalias !31
+  %433 = icmp eq i8* %432, %135
+  br i1 %433, label %435, label %434
 
-374:                                              ; preds = %373, %369
-  %375 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 1, i32 0, i32 0, i32 0
-  %376 = load i8*, i8** %375, align 8, !tbaa !55, !noalias !38
-  %377 = icmp eq i8* %376, %66
-  br i1 %377, label %379, label %378
+434:                                              ; preds = %430
+  call void @_ZdlPv(i8* %432) #37, !noalias !31
+  br label %435
 
-378:                                              ; preds = %374
-  call void @_ZdlPv(i8* %376) #37, !noalias !38
-  br label %379
+435:                                              ; preds = %434, %430
+  %436 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 1, i32 0, i32 0, i32 0
+  %437 = load atomic i8*, i8** %436 unordered, align 8, !tbaa !59, !noalias !31
+  %438 = icmp eq i8* %437, %128
+  br i1 %438, label %440, label %439
 
-379:                                              ; preds = %378, %374
-  %380 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %2, i64 0, i64 0, i32 0, i32 0, i32 0
-  %381 = load i8*, i8** %380, align 16, !tbaa !55, !noalias !38
-  %382 = icmp eq i8* %381, %59
-  br i1 %382, label %384, label %383
+439:                                              ; preds = %435
+  call void @_ZdlPv(i8* %437) #37, !noalias !31
+  br label %440
 
-383:                                              ; preds = %379
-  call void @_ZdlPv(i8* %381) #37, !noalias !38
-  br label %384
+440:                                              ; preds = %439, %435
+  %441 = getelementptr inbounds [10 x %class.SourceInfo], [10 x %class.SourceInfo]* %3, i64 0, i64 0, i32 0, i32 0, i32 0
+  %442 = load atomic i8*, i8** %441 unordered, align 16, !tbaa !59, !noalias !31
+  %443 = icmp eq i8* %442, %121
+  br i1 %443, label %445, label %444
 
-384:                                              ; preds = %383, %379
-  %385 = extractvalue { i8*, i32 } %268, 0
-  call void @llvm.lifetime.end.p0i8(i64 400, i8* nonnull %55) #37, !noalias !38
-  call fastcc void @_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEED2Ev(%"class.std::vector.1"* nonnull %5) #37
-  call fastcc void @_ZN6kotlin31NativeOrUnregisteredThreadGuardD2Ev(%"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %.sroa.3.0, i32 %.sroa.7.0) #37
-  call fastcc void @__clang_call_terminate(i8* %385) #51, !noalias !38
+444:                                              ; preds = %440
+  call void @_ZdlPv(i8* %442) #37, !noalias !31
+  br label %445
+
+445:                                              ; preds = %444, %440
+  %446 = extractvalue { i8*, i32 } %327, 0
+  call void @llvm.lifetime.end.p0i8(i64 400, i8* nonnull %117) #37, !noalias !31
+  call fastcc void @_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEED2Ev(%"class.std::vector.1"* nonnull %6) #37
+  call fastcc void @_ZN6kotlin31NativeOrUnregisteredThreadGuardD2Ev(%"class.kotlin::NativeOrUnregisteredThreadGuard"* nonnull %2) #37, !noalias !31
+  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %43) #37, !noalias !31
+  call fastcc void @__clang_call_terminate(i8* %446) #51, !noalias !31
   unreachable
 
-_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE.exit.i.i: ; preds = %300, %296, %288, %286
-  %386 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %38, null
-  br i1 %386, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i, label %387
+_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE.exit.i.i: ; preds = %361, %357, %348, %344
+  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %43) #37, !noalias !31
+  %447 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %39, null
+  br i1 %447, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i, label %448
 
-387:                                              ; preds = %_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE.exit.i.i
-  %388 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %39 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %389 = atomicrmw xchg i32* %40, i32 %41 seq_cst, align 4
-  %390 = icmp eq i32 %389, 1
-  %391 = icmp eq i32 %41, 0
-  %392 = and i1 %391, %390
-  br i1 %392, label %393, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i
+448:                                              ; preds = %_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE.exit.i.i
+  %449 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %40 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %450 = atomicrmw xchg i32* %41, i32 %42 seq_cst, align 4
+  %451 = icmp eq i32 %450, 1
+  %452 = icmp eq i32 %42, 0
+  %453 = and i1 %452, %451
+  br i1 %453, label %454, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i
 
-393:                                              ; preds = %387
-  %394 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %395 = and i8 %394, 1
-  %396 = icmp eq i8 %395, 0
-  br i1 %396, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i, label %397
+454:                                              ; preds = %448
+  %455 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %456 = and i8 %455, 1
+  %457 = icmp eq i8 %456, 0
+  br i1 %457, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i, label %458
 
-397:                                              ; preds = %393
-  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %388) #37
+458:                                              ; preds = %454
+  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %449) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i: ; preds = %397, %393, %387, %_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE.exit.i.i
-  %398 = bitcast %class.ObjHolder* %6 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %398) #37
-  %399 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %6, i64 0, i32 1
-  store %struct.ObjHeader* null, %struct.ObjHeader** %399, align 8, !tbaa !61
-  %400 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %401 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %400, i64 0, i32 1, i32 5
-  %402 = bitcast %"class.kotlin::mm::ShadowStack"* %401 to i64*
-  %403 = load i64, i64* %402, align 8, !tbaa !7
-  %404 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %6, i64 0, i32 0, i32 1
-  %405 = bitcast %struct.FrameOverlay.6** %404 to i64*
-  store i64 %403, i64* %405, align 8, !tbaa !9
-  %406 = bitcast %"class.kotlin::mm::ShadowStack"* %401 to %class.ObjHolder**
-  store %class.ObjHolder* %6, %class.ObjHolder** %406, align 8, !tbaa !7
-  %407 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %6, i64 0, i32 0, i32 2
-  store i32 0, i32* %407, align 8, !tbaa !12
-  %408 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %6, i64 0, i32 0, i32 3
-  store i32 4, i32* %408, align 4, !tbaa !13
-  %409 = getelementptr inbounds %"class.std::vector.1", %"class.std::vector.1"* %5, i64 0, i32 0, i32 0, i32 1
-  %410 = bitcast %"class.std::__cxx11::basic_string"** %409 to i64*
-  %411 = load i64, i64* %410, align 8, !tbaa !44
-  %412 = load i64, i64* %48, align 8, !tbaa !41
-  %413 = sub i64 %411, %412
-  %414 = lshr exact i64 %413, 5
-  %415 = trunc i64 %414 to i32
-  %416 = icmp slt i32 %415, 0
-  %417 = inttoptr i64 %412 to %"class.std::__cxx11::basic_string"*
-  %418 = inttoptr i64 %411 to %"class.std::__cxx11::basic_string"*
-  br i1 %416, label %419, label %AllocArrayInstance.exit.i.i
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i: ; preds = %458, %454, %448, %_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE.exit.i.i
+  %459 = bitcast %class.ObjHolder* %7 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %459) #37
+  %460 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %7, i64 0, i32 1
+  store %struct.ObjHeader* null, %struct.ObjHeader** %460, align 8, !tbaa !60
+  %461 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %462 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %461, i64 0, i32 1, i32 5
+  %463 = bitcast %"class.kotlin::mm::ShadowStack"* %462 to i64*
+  %464 = load atomic i64, i64* %463 unordered, align 8, !tbaa !7
+  %465 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %7, i64 0, i32 0, i32 1
+  %466 = bitcast %struct.FrameOverlay.6** %465 to i64*
+  store i64 %464, i64* %466, align 8, !tbaa !9
+  %467 = bitcast %"class.kotlin::mm::ShadowStack"* %462 to %class.ObjHolder**
+  store %class.ObjHolder* %7, %class.ObjHolder** %467, align 8, !tbaa !7
+  %468 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %7, i64 0, i32 0, i32 2
+  store i32 0, i32* %468, align 8, !tbaa !12
+  %469 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %7, i64 0, i32 0, i32 3
+  store i32 4, i32* %469, align 4, !tbaa !13
+  %470 = getelementptr inbounds %"class.std::vector.1", %"class.std::vector.1"* %6, i64 0, i32 0, i32 0, i32 1
+  %471 = bitcast %"class.std::__cxx11::basic_string"** %470 to i64*
+  %472 = load atomic i64, i64* %471 unordered, align 8, !tbaa !44
+  %473 = load atomic i64, i64* %58 unordered, align 8, !tbaa !43
+  %474 = sub i64 %472, %473
+  %475 = lshr exact i64 %474, 5
+  %476 = trunc i64 %475 to i32
+  %477 = icmp slt i32 %476, 0
+  %478 = inttoptr i64 %473 to %"class.std::__cxx11::basic_string"*
+  %479 = inttoptr i64 %472 to %"class.std::__cxx11::basic_string"*
+  br i1 %477, label %480, label %AllocArrayInstance.exit.i.i
 
-419:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i
+480:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i
   invoke fastcc void @ThrowIllegalArgumentException() #50
-          to label %.noexc.i.i unwind label %468
+          to label %.noexc.i.i unwind label %529
 
-.noexc.i.i:                                       ; preds = %419
+.noexc.i.i:                                       ; preds = %480
   unreachable
 
 AllocArrayInstance.exit.i.i:                      ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i
-  %420 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %400, i64 0, i32 1, i32 6
-  %421 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %420 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %422 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %421, align 8, !tbaa !3
-  %423 = lshr exact i64 %413, 2
-  %424 = and i64 %423, 34359738360
-  %425 = add nuw nsw i64 %424, 31
-  %426 = and i64 %425, 68719476728
-  %427 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %422, i64 0, i32 2, i32 1
-  %428 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %427, i64 %426) #37
-  %429 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %428, i64 1
-  %430 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %428, i64 2
-  %431 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %430 to %struct.TypeInfo**
-  %432 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %429 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %432, i8 0, i64 24, i1 false) #37
-  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [3 x i8*] }, { %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.Array#internal", i64 0, i32 0), %struct.TypeInfo** %431, align 8, !tbaa !16
-  %433 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %428, i64 3
-  %434 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %433 to i32*
-  store i32 %415, i32* %434, align 8, !tbaa !18
-  %435 = bitcast %struct.ObjHeader** %399 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %430, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %435, align 8, !tbaa !3
-  %436 = icmp eq i64 %411, %412
-  br i1 %436, label %AllocArrayInstance.exit.i.i._crit_edge, label %437
+  %481 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %461, i64 0, i32 1, i32 6
+  %482 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %481 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
+  %483 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %482 unordered, align 8, !tbaa !3
+  %484 = lshr exact i64 %474, 2
+  %485 = and i64 %484, 34359738360
+  %486 = add nuw nsw i64 %485, 31
+  %487 = and i64 %486, 68719476728
+  %488 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %483, i64 0, i32 2, i32 1
+  %489 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %488, i64 %487) #37
+  %490 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %489, i64 1
+  %491 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %489, i64 2
+  %492 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %491 to %struct.TypeInfo**
+  %493 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %490 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %493, i8 0, i64 24, i1 false) #37
+  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [3 x i8*] }, { %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.Array#internal", i64 0, i32 0), %struct.TypeInfo** %492, align 8, !tbaa !16
+  %494 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %489, i64 3
+  %495 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %494 to i32*
+  store i32 %476, i32* %495, align 8, !tbaa !18
+  %496 = bitcast %struct.ObjHeader** %460 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %491, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %496, align 8, !tbaa !3
+  %497 = icmp eq i64 %472, %473
+  br i1 %497, label %AllocArrayInstance.exit.i.i._crit_edge, label %498
 
 AllocArrayInstance.exit.i.i._crit_edge:           ; preds = %AllocArrayInstance.exit.i.i
-  %.pre26 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %.pre12 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   br label %.loopexit
 
-437:                                              ; preds = %AllocArrayInstance.exit.i.i
-  %438 = bitcast %class.ObjHolder* %7 to i8*
-  %439 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %7, i64 0, i32 1
-  %440 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %428, i64 4
-  %441 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %7, i64 0, i32 0, i32 1
-  %442 = bitcast %struct.FrameOverlay.6** %441 to i64*
-  %443 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %7, i64 0, i32 0, i32 2
-  %444 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %7, i64 0, i32 0, i32 3
-  %445 = bitcast %struct.ObjHeader** %439 to i64*
-  %446 = ashr exact i64 %413, 5
-  %.pre = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %.phi.trans.insert = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %.pre, i64 0, i32 1, i32 5
-  %.phi.trans.insert24 = bitcast %"class.kotlin::mm::ShadowStack"* %.phi.trans.insert to i64*
-  %.pre25 = load i64, i64* %.phi.trans.insert24, align 8, !tbaa !7
-  %447 = icmp ugt i64 %446, 1
-  %umax = select i1 %447, i64 %446, i64 1
-  br label %472
+498:                                              ; preds = %AllocArrayInstance.exit.i.i
+  %499 = bitcast %class.ObjHolder* %8 to i8*
+  %500 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %8, i64 0, i32 1
+  %501 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %489, i64 4
+  %502 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %8, i64 0, i32 0, i32 1
+  %503 = bitcast %struct.FrameOverlay.6** %502 to i64*
+  %504 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %8, i64 0, i32 0, i32 2
+  %505 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %8, i64 0, i32 0, i32 3
+  %506 = bitcast %struct.ObjHeader** %500 to i64*
+  %507 = ashr exact i64 %474, 5
+  %.pre = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %508 = icmp ugt i64 %507, 1
+  %umax = select i1 %508, i64 %507, i64 1
+  br label %533
 
-.loopexit:                                        ; preds = %481, %AllocArrayInstance.exit.i.i._crit_edge
-  %448 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %.pre26, %AllocArrayInstance.exit.i.i._crit_edge ], [ %487, %481 ]
-  %449 = bitcast %struct.ObjHeader** %17 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %430, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %449, align 8, !tbaa !3
-  %450 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %448, i64 0, i32 1, i32 5
-  %451 = load i64, i64* %405, align 8, !tbaa !9
-  %452 = bitcast %"class.kotlin::mm::ShadowStack"* %450 to i64*
-  store i64 %451, i64* %452, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %398) #37
-  %453 = icmp eq %"class.std::__cxx11::basic_string"* %417, %418
-  br i1 %453, label %464, label %.preheader10
+.loopexit:                                        ; preds = %543, %AllocArrayInstance.exit.i.i._crit_edge
+  %509 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %.pre12, %AllocArrayInstance.exit.i.i._crit_edge ], [ %549, %543 ]
+  %510 = bitcast %struct.ObjHeader** %18 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %491, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %510, align 8, !tbaa !3
+  %511 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %509, i64 0, i32 1, i32 5
+  %512 = load atomic i64, i64* %466 unordered, align 8, !tbaa !9
+  %513 = bitcast %"class.kotlin::mm::ShadowStack"* %511 to i64*
+  store i64 %512, i64* %513, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %459) #37
+  %514 = icmp eq %"class.std::__cxx11::basic_string"* %478, %479
+  br i1 %514, label %525, label %.preheader1
 
-.preheader10:                                     ; preds = %461, %.loopexit
-  %454 = phi %"class.std::__cxx11::basic_string"* [ %462, %461 ], [ %417, %.loopexit ]
-  %455 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %454, i64 0, i32 0, i32 0
-  %456 = load i8*, i8** %455, align 8, !tbaa !58
-  %457 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %454, i64 0, i32 2
-  %458 = bitcast %union.anon.108* %457 to i8*
-  %459 = icmp eq i8* %456, %458
-  br i1 %459, label %461, label %460
+.preheader1:                                      ; preds = %522, %.loopexit
+  %515 = phi %"class.std::__cxx11::basic_string"* [ %523, %522 ], [ %478, %.loopexit ]
+  %516 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %515, i64 0, i32 0, i32 0
+  %517 = load atomic i8*, i8** %516 unordered, align 8, !tbaa !47
+  %518 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %515, i64 0, i32 2
+  %519 = bitcast %union.anon.108* %518 to i8*
+  %520 = icmp eq i8* %517, %519
+  br i1 %520, label %522, label %521
 
-460:                                              ; preds = %.preheader10
-  call void @free(i8* %456) #37
-  br label %461
+521:                                              ; preds = %.preheader1
+  call void @free(i8* %517) #37
+  br label %522
 
-461:                                              ; preds = %460, %.preheader10
-  %462 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %454, i64 1
-  %463 = icmp eq %"class.std::__cxx11::basic_string"* %462, %418
-  br i1 %463, label %464, label %.preheader10
+522:                                              ; preds = %521, %.preheader1
+  %523 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %515, i64 1
+  %524 = icmp eq %"class.std::__cxx11::basic_string"* %523, %479
+  br i1 %524, label %525, label %.preheader1
 
-464:                                              ; preds = %461, %.loopexit
-  %465 = icmp eq i64 %412, 0
-  br i1 %465, label %epilogue, label %466
+525:                                              ; preds = %522, %.loopexit
+  %526 = icmp eq i64 %473, 0
+  br i1 %526, label %epilogue, label %527
 
-466:                                              ; preds = %464
-  %467 = inttoptr i64 %412 to i8*
-  call void @free(i8* %467) #37
+527:                                              ; preds = %525
+  %528 = inttoptr i64 %473 to i8*
+  call void @free(i8* %528) #37
   br label %epilogue
 
-468:                                              ; preds = %419
-  %469 = landingpad { i8*, i32 }
+529:                                              ; preds = %480
+  %530 = landingpad { i8*, i32 }
           cleanup
-  %470 = extractvalue { i8*, i32 } %469, 0
-  %471 = extractvalue { i8*, i32 } %469, 1
-  %.pre27 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  br label %500
+  %531 = extractvalue { i8*, i32 } %530, 0
+  %532 = extractvalue { i8*, i32 } %530, 1
+  %.pre13 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  br label %562
 
-472:                                              ; preds = %481, %437
-  %473 = phi i64 [ %.pre25, %437 ], [ %489, %481 ]
-  %474 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %.pre, %437 ], [ %487, %481 ]
-  %475 = phi i64 [ 0, %437 ], [ %491, %481 ]
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %438) #37
-  store %struct.ObjHeader* null, %struct.ObjHeader** %439, align 8, !tbaa !61
-  %476 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %474, i64 0, i32 1, i32 5
-  store i64 %473, i64* %442, align 8, !tbaa !9
-  %477 = bitcast %"class.kotlin::mm::ShadowStack"* %476 to %class.ObjHolder**
-  store %class.ObjHolder* %7, %class.ObjHolder** %477, align 8, !tbaa !7
-  store i32 0, i32* %443, align 8, !tbaa !12
-  store i32 4, i32* %444, align 4, !tbaa !13
-  %478 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %417, i64 %475, i32 0, i32 0
-  %479 = load i8*, i8** %478, align 8, !tbaa !58
-  %480 = invoke fastcc %struct.ObjHeader* @CreateStringFromCString(i8* %479, %struct.ObjHeader** nonnull %439)
-          to label %481 unwind label %492
+533:                                              ; preds = %543, %498
+  %534 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %.pre, %498 ], [ %549, %543 ]
+  %535 = phi i64 [ 0, %498 ], [ %553, %543 ]
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %499) #37
+  store %struct.ObjHeader* null, %struct.ObjHeader** %500, align 8, !tbaa !60
+  %536 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %534, i64 0, i32 1, i32 5
+  %537 = bitcast %"class.kotlin::mm::ShadowStack"* %536 to i64*
+  %538 = load atomic i64, i64* %537 unordered, align 8, !tbaa !7
+  store i64 %538, i64* %503, align 8, !tbaa !9
+  %539 = bitcast %"class.kotlin::mm::ShadowStack"* %536 to %class.ObjHolder**
+  store %class.ObjHolder* %8, %class.ObjHolder** %539, align 8, !tbaa !7
+  store i32 0, i32* %504, align 8, !tbaa !12
+  store i32 4, i32* %505, align 4, !tbaa !13
+  %540 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %478, i64 %535, i32 0, i32 0
+  %541 = load atomic i8*, i8** %540 unordered, align 8, !tbaa !47
+  %542 = invoke fastcc %struct.ObjHeader* @CreateStringFromCString(i8* %541, %struct.ObjHeader** nonnull %500)
+          to label %543 unwind label %554
 
-481:                                              ; preds = %472
-  %482 = shl i64 %475, 32
-  %483 = ashr exact i64 %482, 32
-  %484 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %440, i64 %483
-  %485 = load i64, i64* %445, align 8, !tbaa !61
-  %486 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %484 to i64*
-  store i64 %485, i64* %486, align 8, !tbaa !3
-  %487 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %488 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %487, i64 0, i32 1, i32 5
-  %489 = load i64, i64* %442, align 8, !tbaa !9
-  %490 = bitcast %"class.kotlin::mm::ShadowStack"* %488 to i64*
-  store i64 %489, i64* %490, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %438) #37
-  %491 = add nuw i64 %475, 1
-  %exitcond.not = icmp eq i64 %491, %umax
-  br i1 %exitcond.not, label %.loopexit, label %472
+543:                                              ; preds = %533
+  %544 = shl i64 %535, 32
+  %545 = ashr exact i64 %544, 32
+  %546 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %501, i64 %545
+  %547 = load atomic i64, i64* %506 unordered, align 8, !tbaa !60
+  %548 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %546 to i64*
+  store i64 %547, i64* %548, align 8, !tbaa !3
+  %549 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %550 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %549, i64 0, i32 1, i32 5
+  %551 = load atomic i64, i64* %503 unordered, align 8, !tbaa !9
+  %552 = bitcast %"class.kotlin::mm::ShadowStack"* %550 to i64*
+  store i64 %551, i64* %552, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %499) #37
+  %553 = add nuw i64 %535, 1
+  %exitcond.not = icmp eq i64 %553, %umax
+  br i1 %exitcond.not, label %.loopexit, label %533
 
-492:                                              ; preds = %472
-  %493 = landingpad { i8*, i32 }
+554:                                              ; preds = %533
+  %555 = landingpad { i8*, i32 }
           cleanup
-  %494 = extractvalue { i8*, i32 } %493, 0
-  %495 = extractvalue { i8*, i32 } %493, 1
-  %496 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %497 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %496, i64 0, i32 1, i32 5
-  %498 = load i64, i64* %442, align 8, !tbaa !9
-  %499 = bitcast %"class.kotlin::mm::ShadowStack"* %497 to i64*
-  store i64 %498, i64* %499, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %438) #37
-  br label %500
+  %556 = extractvalue { i8*, i32 } %555, 0
+  %557 = extractvalue { i8*, i32 } %555, 1
+  %558 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %559 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %558, i64 0, i32 1, i32 5
+  %560 = load atomic i64, i64* %503 unordered, align 8, !tbaa !9
+  %561 = bitcast %"class.kotlin::mm::ShadowStack"* %559 to i64*
+  store i64 %560, i64* %561, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %499) #37
+  br label %562
 
-500:                                              ; preds = %492, %468
-  %501 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %496, %492 ], [ %.pre27, %468 ]
-  %502 = phi i32 [ %495, %492 ], [ %471, %468 ]
-  %503 = phi i8* [ %494, %492 ], [ %470, %468 ]
-  %504 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %501, i64 0, i32 1, i32 5
-  %505 = load i64, i64* %405, align 8, !tbaa !9
-  %506 = bitcast %"class.kotlin::mm::ShadowStack"* %504 to i64*
-  store i64 %505, i64* %506, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %398) #37
-  %507 = icmp eq %"class.std::__cxx11::basic_string"* %417, %418
-  br i1 %507, label %518, label %.preheader
+562:                                              ; preds = %554, %529
+  %563 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %558, %554 ], [ %.pre13, %529 ]
+  %564 = phi i32 [ %557, %554 ], [ %532, %529 ]
+  %565 = phi i8* [ %556, %554 ], [ %531, %529 ]
+  %566 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %563, i64 0, i32 1, i32 5
+  %567 = load atomic i64, i64* %466 unordered, align 8, !tbaa !9
+  %568 = bitcast %"class.kotlin::mm::ShadowStack"* %566 to i64*
+  store i64 %567, i64* %568, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %459) #37
+  %569 = icmp eq %"class.std::__cxx11::basic_string"* %478, %479
+  br i1 %569, label %580, label %.preheader
 
-.preheader:                                       ; preds = %515, %500
-  %508 = phi %"class.std::__cxx11::basic_string"* [ %516, %515 ], [ %417, %500 ]
-  %509 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %508, i64 0, i32 0, i32 0
-  %510 = load i8*, i8** %509, align 8, !tbaa !58
-  %511 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %508, i64 0, i32 2
-  %512 = bitcast %union.anon.108* %511 to i8*
-  %513 = icmp eq i8* %510, %512
-  br i1 %513, label %515, label %514
+.preheader:                                       ; preds = %577, %562
+  %570 = phi %"class.std::__cxx11::basic_string"* [ %578, %577 ], [ %478, %562 ]
+  %571 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %570, i64 0, i32 0, i32 0
+  %572 = load atomic i8*, i8** %571 unordered, align 8, !tbaa !47
+  %573 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %570, i64 0, i32 2
+  %574 = bitcast %union.anon.108* %573 to i8*
+  %575 = icmp eq i8* %572, %574
+  br i1 %575, label %577, label %576
 
-514:                                              ; preds = %.preheader
-  call void @free(i8* %510) #37
-  br label %515
+576:                                              ; preds = %.preheader
+  call void @free(i8* %572) #37
+  br label %577
 
-515:                                              ; preds = %514, %.preheader
-  %516 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %508, i64 1
-  %517 = icmp eq %"class.std::__cxx11::basic_string"* %516, %418
-  br i1 %517, label %518, label %.preheader
+577:                                              ; preds = %576, %.preheader
+  %578 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %570, i64 1
+  %579 = icmp eq %"class.std::__cxx11::basic_string"* %578, %479
+  br i1 %579, label %580, label %.preheader
 
-518:                                              ; preds = %515, %500
-  %519 = icmp eq i64 %412, 0
-  br i1 %519, label %522, label %520
+580:                                              ; preds = %577, %562
+  %581 = icmp eq i64 %473, 0
+  br i1 %581, label %584, label %582
 
-520:                                              ; preds = %518
-  %521 = inttoptr i64 %412 to i8*
-  call void @free(i8* %521) #37
-  br label %522
+582:                                              ; preds = %580
+  %583 = inttoptr i64 %473 to i8*
+  call void @free(i8* %583) #37
+  br label %584
 
-522:                                              ; preds = %520, %518
-  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %37) #37
-  %523 = insertvalue { i8*, i32 } undef, i8* %503, 0
-  %524 = insertvalue { i8*, i32 } %523, i32 %502, 1
-  resume { i8*, i32 } %524
+584:                                              ; preds = %582, %580
+  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %38) #37
+  %585 = insertvalue { i8*, i32 } undef, i8* %565, 0
+  %586 = insertvalue { i8*, i32 } %585, i32 %564, 1
+  resume { i8*, i32 } %586
 
-epilogue:                                         ; preds = %466, %464
-  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %37) #37
-  %525 = bitcast %struct.ObjHeader** %1 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %430, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %525, align 8, !tbaa !3
-  %526 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %527 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %526, i64 0, i32 1, i32 5
-  %528 = load i64, i64* %24, align 8, !tbaa !9
-  %529 = bitcast %"class.kotlin::mm::ShadowStack"* %527 to i64*
-  store i64 %528, i64* %529, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %16)
-  %530 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %430 to %struct.ObjHeader*
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %430, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %525, align 8, !tbaa !3
-  ret %struct.ObjHeader* %530
+epilogue:                                         ; preds = %527, %525
+  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %38) #37
+  %587 = bitcast %struct.ObjHeader** %1 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %491, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %587, align 8, !tbaa !3
+  %588 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %589 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %588, i64 0, i32 1, i32 5
+  %590 = load atomic i64, i64* %25 unordered, align 8, !tbaa !9
+  %591 = bitcast %"class.kotlin::mm::ShadowStack"* %589 to i64*
+  store i64 %590, i64* %591, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %17)
+  %592 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %491 to %struct.ObjHeader*
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %491, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %587, align 8, !tbaa !3
+  ret %struct.ObjHeader* %592
 }
 
 define internal fastcc void @checkRangeIndexes(i32 %0, i32 %1, i32 %2) unnamed_addr #3 personality i32 (...)* @__gxx_personality_v0 {
@@ -4850,11 +4922,11 @@
   %objHeader14 = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %23, i64 0, i32 0
   %typeInfoOrMeta_15 = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %23, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_15, align 8
-  %26 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %26 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %27 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %26, i64 0, i32 1, i32 5
   %28 = bitcast [19 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %29 = bitcast %"class.kotlin::mm::ShadowStack"* %27 to i64*
-  %30 = load i64, i64* %29, align 8, !tbaa !7
+  %30 = load atomic i64, i64* %29 unordered, align 8, !tbaa !7
   %31 = getelementptr inbounds [19 x %struct.ObjHeader*], [19 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %32 = bitcast %struct.ObjHeader** %31 to i64*
   store i64 %30, i64* %32, align 8, !tbaa !9
@@ -4915,10 +4987,10 @@
           to label %call_success9 unwind label %cleanup_landingpad
 
 call_success9:                                    ; preds = %call_success8
-  %51 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %51 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %52 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %51, i64 0, i32 1, i32 6
   %53 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %52 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %54 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %53, align 8, !tbaa !3
+  %54 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %53 unordered, align 8, !tbaa !3
   %55 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %54, i64 0, i32 2, i32 1
   %56 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %55, i64 56) #37
   %57 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %56, i64 1
@@ -4970,10 +5042,10 @@
           to label %call_success21 unwind label %cleanup_landingpad
 
 call_success21:                                   ; preds = %call_success20
-  %69 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %69 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %70 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %69, i64 0, i32 1, i32 6
   %71 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %70 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %72 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %71, align 8, !tbaa !3
+  %72 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %71 unordered, align 8, !tbaa !3
   %73 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %72, i64 0, i32 2, i32 1
   %74 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %73, i64 56) #37
   %75 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %74, i64 1
@@ -4996,9 +5068,9 @@
   unreachable
 
 epilogue:                                         ; preds = %when_exit2
-  %81 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %81 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %82 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %81, i64 0, i32 1, i32 5
-  %83 = load i64, i64* %32, align 8, !tbaa !9
+  %83 = load atomic i64, i64* %32 unordered, align 8, !tbaa !9
   %84 = bitcast %"class.kotlin::mm::ShadowStack"* %82 to i64*
   store i64 %83, i64* %84, align 8, !tbaa !7
   ret void
@@ -5006,9 +5078,9 @@
 cleanup_landingpad:                               ; preds = %call_success22, %call_success21, %call_success20, %call_success19, %call_success18, %call_success17, %call_success16, %when_case12, %call_success10, %call_success9, %call_success8, %call_success7, %call_success6, %call_success5, %call_success4, %call_success3, %call_success, %when_case
   %85 = landingpad { i8*, i32 }
           cleanup
-  %86 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %86 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %87 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %86, i64 0, i32 1, i32 5
-  %88 = load i64, i64* %32, align 8, !tbaa !9
+  %88 = load atomic i64, i64* %32 unordered, align 8, !tbaa !9
   %89 = bitcast %"class.kotlin::mm::ShadowStack"* %87 to i64*
   store i64 %88, i64* %89, align 8, !tbaa !7
   resume { i8*, i32 } %85
@@ -5033,7 +5105,7 @@
   %10 = load atomic volatile i64, i64* %9 monotonic, align 8
   %11 = inttoptr i64 %10 to %struct.TypeInfo*
   %12 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %11, i64 0, i32 14
-  %13 = load i32, i32* %12, align 4, !tbaa !19
+  %13 = load atomic i32, i32* %12 unordered, align 4, !tbaa !19
   %14 = icmp eq i32 %13, 72
   br i1 %14, label %label_, label %label_1
 
@@ -5044,7 +5116,7 @@
 label_:                                           ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
   %15 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %16 = bitcast %struct.ObjHeader* %15 to i32*
-  %17 = load i32, i32* %16, align 8, !tbaa !18
+  %17 = load atomic i32, i32* %16 unordered, align 8, !tbaa !18
   %18 = icmp ugt i32 %17, %1
   br i1 %18, label %epilogue, label %19
 
@@ -5081,7 +5153,7 @@
   %11 = load atomic volatile i64, i64* %10 monotonic, align 8
   %12 = inttoptr i64 %11 to %struct.TypeInfo*
   %13 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %12, i64 0, i32 14
-  %14 = load i32, i32* %13, align 4, !tbaa !19
+  %14 = load atomic i32, i32* %13 unordered, align 4, !tbaa !19
   %15 = icmp eq i32 %14, 72
   br i1 %15, label %label_, label %label_1
 
@@ -5092,7 +5164,7 @@
 label_:                                           ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
   %16 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %17 = bitcast %struct.ObjHeader* %16 to i32*
-  %18 = load i32, i32* %17, align 8, !tbaa !18
+  %18 = load atomic i32, i32* %17 unordered, align 8, !tbaa !18
   tail call fastcc void @checkRangeIndexes(i32 %1, i32 %2, i32 %18)
   %19 = load atomic volatile i64, i64* %7 monotonic, align 8
   %20 = icmp slt i32 %1, %2
@@ -5121,7 +5193,7 @@
   store <2 x %struct.ObjHeader*> zeroinitializer, <2 x %struct.ObjHeader*>* %29, align 8, !tbaa !3
   %index.next = add i64 %index, 2
   %30 = icmp eq i64 %index.next, %n.vec
-  br i1 %30, label %middle.block, label %vector.body, !llvm.loop !63
+  br i1 %30, label %middle.block, label %vector.body, !llvm.loop !62
 
 middle.block:                                     ; preds = %vector.body
   %cmp.n = icmp eq i64 %27, %n.vec
@@ -5139,7 +5211,7 @@
   %35 = add nsw i64 %32, 1
   %36 = trunc i64 %35 to i32
   %37 = icmp eq i32 %36, %2
-  br i1 %37, label %epilogue, label %31, !llvm.loop !64
+  br i1 %37, label %epilogue, label %31, !llvm.loop !63
 
 epilogue:                                         ; preds = %31, %middle.block, %label_
   ret void
@@ -5188,11 +5260,11 @@
   %27 = getelementptr inbounds [37 x %struct.ObjHeader*], [37 x %struct.ObjHeader*]* %2, i64 0, i64 34
   %28 = getelementptr inbounds [37 x %struct.ObjHeader*], [37 x %struct.ObjHeader*]* %2, i64 0, i64 35
   %29 = getelementptr inbounds [37 x %struct.ObjHeader*], [37 x %struct.ObjHeader*]* %2, i64 0, i64 36
-  %30 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %30 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %31 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %30, i64 0, i32 1, i32 5
   %32 = bitcast [37 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %33 = bitcast %"class.kotlin::mm::ShadowStack"* %31 to i64*
-  %34 = load i64, i64* %33, align 8, !tbaa !7
+  %34 = load atomic i64, i64* %33 unordered, align 8, !tbaa !7
   %35 = getelementptr inbounds [37 x %struct.ObjHeader*], [37 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %36 = bitcast %struct.ObjHeader** %35 to i64*
   store i64 %34, i64* %36, align 8, !tbaa !9
@@ -5215,7 +5287,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %44, %call_success1
   %45 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %30, i64 0, i32 1, i32 6
   %46 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %45 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %47 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %46, align 8, !tbaa !3
+  %47 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %46 unordered, align 8, !tbaa !3
   %48 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %47, i64 0, i32 2, i32 1
   %49 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %48, i64 32) #37
   %50 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %49, i64 1
@@ -5230,7 +5302,7 @@
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %51, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %55, align 8, !tbaa !3
   %56 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %30, i64 0, i32 1, i32 6
   %57 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %56 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %58 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %57, align 8, !tbaa !3
+  %58 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %57 unordered, align 8, !tbaa !3
   %59 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %58, i64 0, i32 2, i32 1
   %60 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %59, i64 32) #37
   %61 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %60, i64 1
@@ -5245,7 +5317,7 @@
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %62, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %66, align 8, !tbaa !3
   %67 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %30, i64 0, i32 1, i32 6
   %68 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %67 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %69 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %68, align 8, !tbaa !3
+  %69 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %68 unordered, align 8, !tbaa !3
   %70 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %69, i64 0, i32 2, i32 1
   %71 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %70, i64 32) #37
   %72 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %71, i64 1
@@ -5260,7 +5332,7 @@
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %73, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %77, align 8, !tbaa !3
   %78 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %30, i64 0, i32 1, i32 6
   %79 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %78 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %80 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %79, align 8, !tbaa !3
+  %80 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %79 unordered, align 8, !tbaa !3
   %81 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %80, i64 0, i32 2, i32 1
   %82 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %81, i64 48) #37
   %83 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %82, i64 1
@@ -5276,21 +5348,21 @@
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %84, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %89, align 8, !tbaa !3
   %90 = bitcast %struct.ObjHeader** %"tmp3_$array" to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %84, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %90, align 8, !tbaa !3
-  %91 = bitcast %struct.ObjHeader** %8 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %84, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %91, align 8, !tbaa !3
+  %91 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %"tmp3_$array" unordered, align 8
+  store %struct.ObjHeader* %91, %struct.ObjHeader** %8, align 8, !tbaa !3
   %92 = bitcast %struct.ObjHeader** %"tmp0_$elem" to i64*
-  %93 = load i64, i64* %92, align 8
+  %93 = load atomic i64, i64* %92 unordered, align 8
   %94 = bitcast %struct.ObjHeader** %9 to i64*
   store i64 %93, i64* %94, align 8, !tbaa !3
-  %95 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %84 to i64*
+  %95 = bitcast %struct.ObjHeader* %91 to i64*
   %96 = load atomic volatile i64, i64* %95 monotonic, align 8
-  %97 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %82, i64 4
-  %98 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97 to i64*
+  %97 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %91, i64 2
+  %98 = bitcast %struct.ObjHeader* %97 to i64*
   store i64 %93, i64* %98, align 8, !tbaa !3
-  %99 = load %struct.ObjHeader*, %struct.ObjHeader** %"tmp3_$array", align 8
+  %99 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %"tmp3_$array" unordered, align 8
   store %struct.ObjHeader* %99, %struct.ObjHeader** %10, align 8, !tbaa !3
   %100 = bitcast %struct.ObjHeader** %"tmp1_$elem" to i64*
-  %101 = load i64, i64* %100, align 8
+  %101 = load atomic i64, i64* %100 unordered, align 8
   %102 = bitcast %struct.ObjHeader** %11 to i64*
   store i64 %101, i64* %102, align 8, !tbaa !3
   %103 = bitcast %struct.ObjHeader* %99 to i64*
@@ -5298,10 +5370,10 @@
   %105 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %99, i64 3
   %106 = bitcast %struct.ObjHeader* %105 to i64*
   store i64 %101, i64* %106, align 8, !tbaa !3
-  %107 = load %struct.ObjHeader*, %struct.ObjHeader** %"tmp3_$array", align 8
+  %107 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %"tmp3_$array" unordered, align 8
   store %struct.ObjHeader* %107, %struct.ObjHeader** %12, align 8, !tbaa !3
   %108 = bitcast %struct.ObjHeader** %"tmp2_$elem" to i64*
-  %109 = load i64, i64* %108, align 8
+  %109 = load atomic i64, i64* %108 unordered, align 8
   %110 = bitcast %struct.ObjHeader** %13 to i64*
   store i64 %109, i64* %110, align 8, !tbaa !3
   %111 = bitcast %struct.ObjHeader* %107 to i64*
@@ -5309,12 +5381,12 @@
   %113 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %107, i64 4
   %114 = bitcast %struct.ObjHeader* %113 to i64*
   store i64 %109, i64* %114, align 8, !tbaa !3
-  %115 = load %struct.ObjHeader*, %struct.ObjHeader** %"tmp3_$array", align 8
+  %115 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %"tmp3_$array" unordered, align 8
   store %struct.ObjHeader* %115, %struct.ObjHeader** %14, align 8, !tbaa !3
   store %struct.ObjHeader* %115, %struct.ObjHeader** @"kvar:kotlin.native.MemoryModel.$VALUES#internal", align 8, !tbaa !3
   %116 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %115, i64 4
   %117 = bitcast %struct.ObjHeader* %116 to %struct.ObjHeader**
-  %118 = load %struct.ObjHeader*, %struct.ObjHeader** %117, align 8, !tbaa !3
+  %118 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %117 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %118, %struct.ObjHeader** %15, align 8, !tbaa !3
   %119 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %118, i64 1
   %120 = bitcast %struct.ObjHeader* %119 to %struct.ObjHeader**
@@ -5324,7 +5396,7 @@
   store i32 0, i32* %122, align 4
   %123 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %115, i64 3
   %124 = bitcast %struct.ObjHeader* %123 to %struct.ObjHeader**
-  %125 = load %struct.ObjHeader*, %struct.ObjHeader** %124, align 8, !tbaa !3
+  %125 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %124 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %125, %struct.ObjHeader** %16, align 8, !tbaa !3
   %126 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %125, i64 1
   %127 = bitcast %struct.ObjHeader* %126 to %struct.ObjHeader**
@@ -5334,7 +5406,7 @@
   store i32 1, i32* %129, align 4
   %130 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %115, i64 2
   %131 = bitcast %struct.ObjHeader* %130 to %struct.ObjHeader**
-  %132 = load %struct.ObjHeader*, %struct.ObjHeader** %131, align 8, !tbaa !3
+  %132 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %131 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %132, %struct.ObjHeader** %17, align 8, !tbaa !3
   %133 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %132, i64 1
   %134 = bitcast %struct.ObjHeader* %133 to %struct.ObjHeader**
@@ -5343,31 +5415,31 @@
   %136 = bitcast %struct.ObjHeader* %135 to i32*
   store i32 2, i32* %136, align 4
   call fastcc void @InitAndRegisterGlobal(%struct.ObjHeader** nonnull @"kvar:kotlin.native.MemoryModel.$VALUES#internal", %struct.ObjHeader* %115) #37
-  %137 = load %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.MemoryModel.$VALUES#internal", align 8
+  %137 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.MemoryModel.$VALUES#internal" unordered, align 8
   %138 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %137, i64 4
   %139 = bitcast %struct.ObjHeader* %138 to i64*
-  %140 = load i64, i64* %139, align 8, !tbaa !3
+  %140 = load atomic i64, i64* %139 unordered, align 8, !tbaa !3
   %141 = bitcast %struct.ObjHeader** %18 to i64*
   store i64 %140, i64* %141, align 8, !tbaa !3
   %142 = bitcast %struct.ObjHeader** %"tmp0_$elem12" to i64*
   store i64 %140, i64* %142, align 8, !tbaa !3
   %143 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %137, i64 3
   %144 = bitcast %struct.ObjHeader* %143 to i64*
-  %145 = load i64, i64* %144, align 8, !tbaa !3
+  %145 = load atomic i64, i64* %144 unordered, align 8, !tbaa !3
   %146 = bitcast %struct.ObjHeader** %19 to i64*
   store i64 %145, i64* %146, align 8, !tbaa !3
   %147 = bitcast %struct.ObjHeader** %"tmp1_$elem14" to i64*
   store i64 %145, i64* %147, align 8, !tbaa !3
   %148 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %137, i64 2
   %149 = bitcast %struct.ObjHeader* %148 to i64*
-  %150 = load i64, i64* %149, align 8, !tbaa !3
+  %150 = load atomic i64, i64* %149 unordered, align 8, !tbaa !3
   %151 = bitcast %struct.ObjHeader** %20 to i64*
   store i64 %150, i64* %151, align 8, !tbaa !3
   %152 = bitcast %struct.ObjHeader** %"tmp2_$elem16" to i64*
   store i64 %150, i64* %152, align 8, !tbaa !3
   %153 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %30, i64 0, i32 1, i32 6
   %154 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %153 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %155 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %154, align 8, !tbaa !3
+  %155 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %154 unordered, align 8, !tbaa !3
   %156 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %155, i64 0, i32 2, i32 1
   %157 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %156, i64 48) #37
   %158 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %157, i64 1
@@ -5383,19 +5455,19 @@
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %159, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %164, align 8, !tbaa !3
   %165 = bitcast %struct.ObjHeader** %"tmp3_$array19" to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %159, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %165, align 8, !tbaa !3
-  %166 = bitcast %struct.ObjHeader** %22 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %159, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %166, align 8, !tbaa !3
-  %167 = load i64, i64* %142, align 8
+  %166 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %"tmp3_$array19" unordered, align 8
+  store %struct.ObjHeader* %166, %struct.ObjHeader** %22, align 8, !tbaa !3
+  %167 = load atomic i64, i64* %142 unordered, align 8
   %168 = bitcast %struct.ObjHeader** %23 to i64*
   store i64 %167, i64* %168, align 8, !tbaa !3
-  %169 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %159 to i64*
+  %169 = bitcast %struct.ObjHeader* %166 to i64*
   %170 = load atomic volatile i64, i64* %169 monotonic, align 8
-  %171 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %157, i64 4
-  %172 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %171 to i64*
+  %171 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %166, i64 2
+  %172 = bitcast %struct.ObjHeader* %171 to i64*
   store i64 %167, i64* %172, align 8, !tbaa !3
-  %173 = load %struct.ObjHeader*, %struct.ObjHeader** %"tmp3_$array19", align 8
+  %173 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %"tmp3_$array19" unordered, align 8
   store %struct.ObjHeader* %173, %struct.ObjHeader** %24, align 8, !tbaa !3
-  %174 = load i64, i64* %147, align 8
+  %174 = load atomic i64, i64* %147 unordered, align 8
   %175 = bitcast %struct.ObjHeader** %25 to i64*
   store i64 %174, i64* %175, align 8, !tbaa !3
   %176 = bitcast %struct.ObjHeader* %173 to i64*
@@ -5403,9 +5475,9 @@
   %178 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %173, i64 3
   %179 = bitcast %struct.ObjHeader* %178 to i64*
   store i64 %174, i64* %179, align 8, !tbaa !3
-  %180 = load %struct.ObjHeader*, %struct.ObjHeader** %"tmp3_$array19", align 8
+  %180 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %"tmp3_$array19" unordered, align 8
   store %struct.ObjHeader* %180, %struct.ObjHeader** %26, align 8, !tbaa !3
-  %181 = load i64, i64* %152, align 8
+  %181 = load atomic i64, i64* %152 unordered, align 8
   %182 = bitcast %struct.ObjHeader** %27 to i64*
   store i64 %181, i64* %182, align 8, !tbaa !3
   %183 = bitcast %struct.ObjHeader* %180 to i64*
@@ -5414,7 +5486,7 @@
   %186 = bitcast %struct.ObjHeader* %185 to i64*
   store i64 %181, i64* %186, align 8, !tbaa !3
   %187 = bitcast %struct.ObjHeader** %"tmp3_$array19" to i64*
-  %188 = load i64, i64* %187, align 8
+  %188 = load atomic i64, i64* %187 unordered, align 8
   %189 = bitcast %struct.ObjHeader** %28 to i64*
   store i64 %188, i64* %189, align 8, !tbaa !3
   %190 = bitcast [5 x %struct.ObjHeader*]* %1 to i8*
@@ -5426,7 +5498,7 @@
   %193 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %30, i64 0, i32 1, i32 5
   %194 = bitcast [5 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
   %195 = bitcast %"class.kotlin::mm::ShadowStack"* %193 to i64*
-  %196 = load i64, i64* %195, align 8, !tbaa !7
+  %196 = load atomic i64, i64* %195 unordered, align 8, !tbaa !7
   %197 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %1, i64 0, i64 1
   %198 = bitcast %struct.ObjHeader** %197 to i64*
   store i64 %196, i64* %198, align 8, !tbaa !9
@@ -5439,7 +5511,7 @@
   store i32 5, i32* %202, align 4, !tbaa !13
   %203 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %30, i64 0, i32 1, i32 6
   %204 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %203 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %205 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %204, align 8, !tbaa !3
+  %205 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %204 unordered, align 8, !tbaa !3
   %206 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %205, i64 0, i32 2, i32 1
   %207 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %206, i64 24) #37
   %208 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %207, i64 1
@@ -5455,7 +5527,7 @@
   store i64 %188, i64* %214, align 8, !tbaa !3
   %215 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %30, i64 0, i32 1, i32 6
   %216 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %215 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %217 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %216, align 8, !tbaa !3
+  %217 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %216 unordered, align 8, !tbaa !3
   %218 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %217, i64 0, i32 2, i32 1
   %219 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %218, i64 32) #37
   %220 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %219, i64 1
@@ -5477,7 +5549,7 @@
   %229 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %30, i64 0, i32 1, i32 5
   %230 = bitcast [4 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
   %231 = bitcast %"class.kotlin::mm::ShadowStack"* %229 to i64*
-  %232 = load i64, i64* %231, align 8, !tbaa !7
+  %232 = load atomic i64, i64* %231 unordered, align 8, !tbaa !7
   %233 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 1
   %234 = bitcast %struct.ObjHeader** %233 to i64*
   store i64 %232, i64* %234, align 8, !tbaa !9
@@ -5494,12 +5566,12 @@
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %227) #37
   %242 = bitcast %struct.ObjHeader** %29 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %221, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %242, align 8, !tbaa !3
-  %243 = load i64, i64* %198, align 8, !tbaa !9
+  %243 = load atomic i64, i64* %198 unordered, align 8, !tbaa !9
   store i64 %243, i64* %241, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %190)
   call fastcc void @InitAndRegisterGlobal(%struct.ObjHeader** nonnull @"kvar:kotlin.native.MemoryModel.$ENTRIES#internal", %struct.ObjHeader* nonnull %222) #37
   %244 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %30, i64 0, i32 1, i32 5
-  %245 = load i64, i64* %36, align 8, !tbaa !9
+  %245 = load atomic i64, i64* %36 unordered, align 8, !tbaa !9
   %246 = bitcast %"class.kotlin::mm::ShadowStack"* %244 to i64*
   store i64 %245, i64* %246, align 8, !tbaa !7
   ret void
@@ -5525,11 +5597,11 @@
   %objHeader = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %11, i64 0, i32 0
   %typeInfoOrMeta_ = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %11, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_, align 8
-  %14 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %14 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %15 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %14, i64 0, i32 1, i32 5
   %16 = bitcast [10 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %17 = bitcast %"class.kotlin::mm::ShadowStack"* %15 to i64*
-  %18 = load i64, i64* %17, align 8, !tbaa !7
+  %18 = load atomic i64, i64* %17 unordered, align 8, !tbaa !7
   %19 = getelementptr inbounds [10 x %struct.ObjHeader*], [10 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %20 = bitcast %struct.ObjHeader** %19 to i64*
   store i64 %18, i64* %20, align 8, !tbaa !9
@@ -5565,7 +5637,7 @@
   %38 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#toString(){}kotlin.String"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader** %1)
   store %struct.ObjHeader* %38, %struct.ObjHeader** %1, align 8, !tbaa !3
   %39 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %14, i64 0, i32 1, i32 5
-  %40 = load i64, i64* %20, align 8, !tbaa !9
+  %40 = load atomic i64, i64* %20 unordered, align 8, !tbaa !9
   %41 = bitcast %"class.kotlin::mm::ShadowStack"* %39 to i64*
   store i64 %40, i64* %41, align 8, !tbaa !7
   ret %struct.ObjHeader* %38
@@ -5593,11 +5665,11 @@
   %objHeader2 = getelementptr inbounds %"kclassbody:kotlin.native.internal.KClassImpl#internal", %"kclassbody:kotlin.native.internal.KClassImpl#internal"* %9, i64 0, i32 0
   %typeInfoOrMeta_3 = getelementptr inbounds %"kclassbody:kotlin.native.internal.KClassImpl#internal", %"kclassbody:kotlin.native.internal.KClassImpl#internal"* %9, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.native.internal.KClassImpl#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_3, align 8
-  %12 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %12 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %13 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %14 = bitcast [10 x %struct.ObjHeader*]* %4 to %struct.FrameOverlay.6*
   %15 = bitcast %"class.kotlin::mm::ShadowStack"* %13 to i64*
-  %16 = load i64, i64* %15, align 8, !tbaa !7
+  %16 = load atomic i64, i64* %15 unordered, align 8, !tbaa !7
   %17 = getelementptr inbounds [10 x %struct.ObjHeader*], [10 x %struct.ObjHeader*]* %4, i64 0, i64 1
   %18 = bitcast %struct.ObjHeader** %17 to i64*
   store i64 %16, i64* %18, align 8, !tbaa !9
@@ -5652,7 +5724,7 @@
   %48 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %49 = bitcast [4 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %50 = bitcast %"class.kotlin::mm::ShadowStack"* %48 to i64*
-  %51 = load i64, i64* %50, align 8, !tbaa !7
+  %51 = load atomic i64, i64* %50 unordered, align 8, !tbaa !7
   %52 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %53 = bitcast %struct.ObjHeader** %52 to i64*
   store i64 %51, i64* %53, align 8, !tbaa !9
@@ -5672,7 +5744,7 @@
   %64 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %63 monotonic, align 8
   %65 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %64, i64 1, i32 1
   %66 = bitcast %struct.ExtendedTypeInfo** %65 to i32 (%struct.ObjHeader*)**
-  %67 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %66, align 8
+  %67 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %66 unordered, align 8
   %68 = call i32 %67(%struct.ObjHeader* nonnull %0)
   %69 = zext i32 %68 to i64
   %70 = bitcast [12 x %struct.ObjHeader*]* %2 to i8*
@@ -5682,7 +5754,7 @@
   %71 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %72 = bitcast [12 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %73 = bitcast %"class.kotlin::mm::ShadowStack"* %71 to i64*
-  %74 = load i64, i64* %73, align 8, !tbaa !7
+  %74 = load atomic i64, i64* %73 unordered, align 8, !tbaa !7
   %75 = getelementptr inbounds [12 x %struct.ObjHeader*], [12 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %76 = bitcast %struct.ObjHeader** %75 to i64*
   store i64 %74, i64* %76, align 8, !tbaa !9
@@ -5694,7 +5766,7 @@
   %80 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %72, i64 0, i32 3
   store i32 12, i32* %80, align 4, !tbaa !13
   %81 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %82 = load i64, i64* %76, align 8, !tbaa !9
+  %82 = load atomic i64, i64* %76 unordered, align 8, !tbaa !9
   %83 = bitcast %"class.kotlin::mm::ShadowStack"* %81 to i64*
   store i64 %82, i64* %83, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 96, i8* nonnull %70)
@@ -5702,7 +5774,7 @@
   store %struct.ObjHeader* %84, %struct.ObjHeader** %47, align 8, !tbaa !3
   store %struct.ObjHeader* %84, %struct.ObjHeader** %29, align 8, !tbaa !3
   %85 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %86 = load i64, i64* %53, align 8, !tbaa !9
+  %86 = load atomic i64, i64* %53 unordered, align 8, !tbaa !9
   %87 = bitcast %"class.kotlin::mm::ShadowStack"* %85 to i64*
   store i64 %86, i64* %87, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %46)
@@ -5714,7 +5786,7 @@
   %90 = phi %struct.ObjHeader* [ %89, %call_success5 ], [ bitcast ({ %struct.ArrayHeader, [4 x i16] }* @105 to %struct.ObjHeader*), %Kotlin_mm_safePointFunctionPrologue.exit ]
   store %struct.ObjHeader* %90, %struct.ObjHeader** %1, align 8, !tbaa !3
   %91 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %92 = load i64, i64* %18, align 8, !tbaa !9
+  %92 = load atomic i64, i64* %18 unordered, align 8, !tbaa !9
   %93 = bitcast %"class.kotlin::mm::ShadowStack"* %91 to i64*
   store i64 %92, i64* %93, align 8, !tbaa !7
   ret %struct.ObjHeader* %90
@@ -5760,11 +5832,11 @@
   %10 = getelementptr inbounds [15 x %struct.ObjHeader*], [15 x %struct.ObjHeader*]* %2, i64 0, i64 10
   %11 = getelementptr inbounds [15 x %struct.ObjHeader*], [15 x %struct.ObjHeader*]* %2, i64 0, i64 13
   %12 = getelementptr inbounds [15 x %struct.ObjHeader*], [15 x %struct.ObjHeader*]* %2, i64 0, i64 14
-  %13 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %13 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %14 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %13, i64 0, i32 1, i32 5
   %15 = bitcast [15 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %16 = bitcast %"class.kotlin::mm::ShadowStack"* %14 to i64*
-  %17 = load i64, i64* %16, align 8, !tbaa !7
+  %17 = load atomic i64, i64* %16 unordered, align 8, !tbaa !7
   %18 = getelementptr inbounds [15 x %struct.ObjHeader*], [15 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %19 = bitcast %struct.ObjHeader** %18 to i64*
   store i64 %17, i64* %19, align 8, !tbaa !9
@@ -5787,7 +5859,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %27, %call_success
   %28 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %29 = bitcast %struct.ObjHeader* %28 to %struct.ObjHeader**
-  %30 = load %struct.ObjHeader*, %struct.ObjHeader** %29, align 8
+  %30 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %29 unordered, align 8
   store %struct.ObjHeader* %30, %struct.ObjHeader** %4, align 8, !tbaa !3
   %31 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %30, i64 1
   %32 = bitcast %struct.ObjHeader* %31 to i64*
@@ -5803,30 +5875,30 @@
   br label %label_continue
 
 label_continue:                                   ; preds = %call_success1, %Kotlin_mm_safePointFunctionPrologue.exit
-  %37 = load %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal", align 8
+  %37 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal" unordered, align 8
   %.not = icmp eq %struct.ObjHeader* %37, %34
   br i1 %.not, label %call_success6, label %epilogue
 
 call_success6:                                    ; preds = %label_continue
   %38 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 3
   %39 = bitcast %struct.ObjHeader* %38 to %struct.ObjHeader**
-  %40 = load %struct.ObjHeader*, %struct.ObjHeader** %39, align 8
+  %40 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %39 unordered, align 8
   call fastcc void @"kfun:kotlin.native.concurrent.Lock#lock(){}"(%struct.ObjHeader* %40)
-  %41 = load %struct.ObjHeader*, %struct.ObjHeader** %29, align 8
+  %41 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %29 unordered, align 8
   store %struct.ObjHeader* %41, %struct.ObjHeader** %6, align 8, !tbaa !3
   %42 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %41, i64 1
   %43 = bitcast %struct.ObjHeader* %42 to i64*
   %44 = load atomic i64, i64* %43 acquire, align 8
   %45 = inttoptr i64 %44 to %struct.ObjHeader*
   store %struct.ObjHeader* %45, %struct.ObjHeader** %7, align 8, !tbaa !3
-  %46 = load %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal", align 8
+  %46 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal" unordered, align 8
   %47 = icmp eq %struct.ObjHeader* %46, %45
   br i1 %47, label %call_success9, label %returnable_block_exit31
 
 call_success9:                                    ; preds = %call_success6
   %48 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %49 = bitcast %struct.ObjHeader* %48 to %struct.ObjHeader**
-  %50 = load %struct.ObjHeader*, %struct.ObjHeader** %49, align 8
+  %50 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %49 unordered, align 8
   store %struct.ObjHeader* %50, %struct.ObjHeader** %8, align 8, !tbaa !3
   %51 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %50, i64 1
   %52 = bitcast %struct.ObjHeader* %51 to i64*
@@ -5852,26 +5924,26 @@
   %61 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %60, i64 0, i32 0
   %62 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %61 monotonic, align 8
   %63 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %62, i64 0, i32 9
-  %64 = load i32, i32* %63, align 4
+  %64 = load atomic i32, i32* %63 unordered, align 4
   %65 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %62, i64 0, i32 10
-  %66 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %65, align 8
+  %66 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %65 unordered, align 8
   %67 = and i32 %64, 89
   %68 = zext i32 %67 to i64
   %69 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %66, i64 %68, i32 2
   %70 = bitcast i8*** %69 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)***
-  %71 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %70, align 8
-  %72 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %71, align 8
+  %71 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %70 unordered, align 8
+  %72 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %71 unordered, align 8
   %73 = invoke %struct.ObjHeader* %72(%struct.ObjHeader* nonnull %54, %struct.ObjHeader** nonnull %10)
           to label %call_success24 unwind label %call_success4
 
 call_success24:                                   ; preds = %when_exit11
-  %74 = load %struct.ObjHeader*, %struct.ObjHeader** %29, align 8
+  %74 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %29 unordered, align 8
   store %struct.ObjHeader* %74, %struct.ObjHeader** %11, align 8, !tbaa !3
   %75 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %74, i64 1
   %76 = ptrtoint %struct.ObjHeader* %73 to i64
   %77 = bitcast %struct.ObjHeader* %75 to i64*
   store atomic i64 %76, i64* %77 release, align 8
-  %78 = load %struct.ObjHeader*, %struct.ObjHeader** %49, align 8
+  %78 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %49 unordered, align 8
   store %struct.ObjHeader* %78, %struct.ObjHeader** %12, align 8, !tbaa !3
   %79 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %78, i64 1
   %80 = bitcast %struct.ObjHeader* %79 to i64*
@@ -5894,9 +5966,9 @@
   %85 = call i8* @__cxa_begin_catch(i8* %er) #37
   %86 = getelementptr inbounds i8, i8* %85, i64 8
   %87 = bitcast i8* %86 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"**
-  %88 = load %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %87, align 8, !tbaa !65
+  %88 = load atomic %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %87 unordered, align 8, !tbaa !64
   %89 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %88, i64 0, i32 0
-  %90 = load %struct.ObjHeader*, %struct.ObjHeader** %89, align 8, !tbaa !3
+  %90 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %89 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %90, %struct.ObjHeader** %82, align 8, !tbaa !3
   call void @__cxa_end_catch() #37
   call fastcc void @"kfun:kotlin.native.concurrent.Lock#unlock(){}"(%struct.ObjHeader* %40)
@@ -5907,7 +5979,7 @@
   %91 = phi %struct.ObjHeader* [ %81, %returnable_block_exit31 ], [ %34, %label_continue ]
   store %struct.ObjHeader* %91, %struct.ObjHeader** %1, align 8, !tbaa !3
   %92 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %13, i64 0, i32 1, i32 5
-  %93 = load i64, i64* %19, align 8, !tbaa !9
+  %93 = load atomic i64, i64* %19 unordered, align 8, !tbaa !9
   %94 = bitcast %"class.kotlin::mm::ShadowStack"* %92 to i64*
   store i64 %93, i64* %94, align 8, !tbaa !7
   ret %struct.ObjHeader* %91
@@ -5921,11 +5993,11 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %2, i8 0, i32 40, i1 immarg false) #49
   %3 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %1, i64 0, i64 3
   %4 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %1, i64 0, i64 4
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %7 = bitcast [5 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
   %8 = bitcast %"class.kotlin::mm::ShadowStack"* %6 to i64*
-  %9 = load i64, i64* %8, align 8, !tbaa !7
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !7
   %10 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %1, i64 0, i64 1
   %11 = bitcast %struct.ObjHeader** %10 to i64*
   store i64 %9, i64* %11, align 8, !tbaa !9
@@ -5948,7 +6020,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %19, %call_success
   %20 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %21 = bitcast %struct.ObjHeader* %20 to %struct.ObjHeader**
-  %22 = load %struct.ObjHeader*, %struct.ObjHeader** %21, align 8
+  %22 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %21 unordered, align 8
   store %struct.ObjHeader* %22, %struct.ObjHeader** %3, align 8, !tbaa !3
   %23 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %22, i64 1
   %24 = bitcast %struct.ObjHeader* %23 to i64*
@@ -5964,10 +6036,10 @@
   br label %epilogue
 
 epilogue:                                         ; preds = %call_success1, %Kotlin_mm_safePointFunctionPrologue.exit
-  %29 = load %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal", align 8
+  %29 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal" unordered, align 8
   %30 = icmp ne %struct.ObjHeader* %29, %26
   %31 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %32 = load i64, i64* %11, align 8, !tbaa !9
+  %32 = load atomic i64, i64* %11 unordered, align 8, !tbaa !9
   %33 = bitcast %"class.kotlin::mm::ShadowStack"* %31 to i64*
   store i64 %32, i64* %33, align 8, !tbaa !7
   ret i1 %30
@@ -5979,11 +6051,11 @@
   %.sub = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 0
   %3 = bitcast [4 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %3, i8 0, i32 32, i1 immarg false) #49
-  %4 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %4 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %5 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
   %6 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %7 = bitcast %"class.kotlin::mm::ShadowStack"* %5 to i64*
-  %8 = load i64, i64* %7, align 8, !tbaa !7
+  %8 = load atomic i64, i64* %7 unordered, align 8, !tbaa !7
   %9 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %10 = bitcast %struct.ObjHeader** %9 to i64*
   store i64 %8, i64* %10, align 8, !tbaa !9
@@ -6023,7 +6095,7 @@
   %29 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %28 monotonic, align 8
   %30 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %29, i64 1, i32 2
   %31 = bitcast i32* %30 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %32 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %31, align 8
+  %32 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %31 unordered, align 8
   %33 = call %struct.ObjHeader* %32(%struct.ObjHeader* nonnull %21, %struct.ObjHeader** %1)
   br label %epilogue
 
@@ -6031,7 +6103,7 @@
   %34 = phi %struct.ObjHeader* [ %33, %call_success4 ], [ bitcast ({ %struct.ArrayHeader, [4 x i16] }* @105 to %struct.ObjHeader*), %call_success1 ], [ bitcast ({ %struct.ArrayHeader, [31 x i16] }* @129 to %struct.ObjHeader*), %Kotlin_mm_safePointFunctionPrologue.exit ]
   store %struct.ObjHeader* %34, %struct.ObjHeader** %1, align 8, !tbaa !3
   %35 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %36 = load i64, i64* %10, align 8, !tbaa !9
+  %36 = load atomic i64, i64* %10 unordered, align 8, !tbaa !9
   %37 = bitcast %"class.kotlin::mm::ShadowStack"* %35 to i64*
   store i64 %36, i64* %37, align 8, !tbaa !7
   ret %struct.ObjHeader* %34
@@ -6044,11 +6116,11 @@
   %.sub = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 0
   %4 = bitcast [5 x %struct.ObjHeader*]* %3 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %4, i8 0, i32 40, i1 immarg false) #49
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %7 = bitcast [5 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %8 = bitcast %"class.kotlin::mm::ShadowStack"* %6 to i64*
-  %9 = load i64, i64* %8, align 8, !tbaa !7
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !7
   %10 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %11 = bitcast %struct.ObjHeader** %10 to i64*
   store i64 %9, i64* %11, align 8, !tbaa !9
@@ -6071,7 +6143,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %19, %call_success5
   %20 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 3
   %21 = bitcast %struct.ObjHeader* %20 to %struct.ObjHeader**
-  %22 = load %struct.ObjHeader*, %struct.ObjHeader** %21, align 8
+  %22 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %21 unordered, align 8
   call fastcc void @"kfun:kotlin.native.concurrent.Lock#lock(){}"(%struct.ObjHeader* %22)
   %23 = bitcast [17 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.lifetime.start.p0i8(i64 136, i8* nonnull %23)
@@ -6091,7 +6163,7 @@
   %34 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %35 = bitcast [17 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %36 = bitcast %"class.kotlin::mm::ShadowStack"* %34 to i64*
-  %37 = load i64, i64* %36, align 8, !tbaa !7
+  %37 = load atomic i64, i64* %36 unordered, align 8, !tbaa !7
   %38 = getelementptr inbounds [17 x %struct.ObjHeader*], [17 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %39 = bitcast %struct.ObjHeader** %38 to i64*
   store i64 %37, i64* %39, align 8, !tbaa !9
@@ -6104,101 +6176,102 @@
   store i32 17, i32* %43, align 4, !tbaa !13
   %44 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %45 = bitcast %struct.ObjHeader* %44 to %struct.ObjHeader**
-  %46 = load %struct.ObjHeader*, %struct.ObjHeader** %45, align 8
+  %46 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %45 unordered, align 8
   %47 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %46, i64 1
   %48 = bitcast %struct.ObjHeader* %47 to i64*
   %49 = load atomic i64, i64* %48 acquire, align 8
   %50 = inttoptr i64 %49 to %struct.ObjHeader*
   store %struct.ObjHeader* %50, %struct.ObjHeader** %24, align 8, !tbaa !3
   store %struct.ObjHeader* %50, %struct.ObjHeader** %result.i, align 8, !tbaa !3
-  store %struct.ObjHeader* %50, %struct.ObjHeader** %25, align 8, !tbaa !3
-  %51 = load atomic i32, i32* @"state_global$kotlin.native.concurrent.UNINITIALIZED" acquire, align 4
-  %52 = icmp eq i32 %51, 2
-  br i1 %52, label %label_continue.i, label %label_init.i
+  %51 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %result.i unordered, align 8
+  store %struct.ObjHeader* %51, %struct.ObjHeader** %25, align 8, !tbaa !3
+  %52 = load atomic i32, i32* @"state_global$kotlin.native.concurrent.UNINITIALIZED" acquire, align 4
+  %53 = icmp eq i32 %52, 2
+  br i1 %53, label %label_continue.i, label %label_init.i
 
 label_init.i:                                     ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
   invoke fastcc void @CallInitGlobalPossiblyLock(i32* nonnull @"state_global$kotlin.native.concurrent.UNINITIALIZED", void ()* nonnull @"kfun:kotlin.native.concurrent.UNINITIALIZED.$init_global#internal")
           to label %label_continue.i unwind label %call_success3
 
 label_continue.i:                                 ; preds = %label_init.i, %Kotlin_mm_safePointFunctionPrologue.exit
-  %53 = load %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal", align 8
-  %.not.i = icmp eq %struct.ObjHeader* %53, %50
+  %54 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal" unordered, align 8
+  %.not.i = icmp eq %struct.ObjHeader* %51, %54
   br i1 %.not.i, label %when_exit.i, label %when_case.i
 
 when_case.i:                                      ; preds = %label_continue.i
-  %54 = load %struct.ObjHeader*, %struct.ObjHeader** %result.i, align 8
-  store %struct.ObjHeader* %54, %struct.ObjHeader** %26, align 8, !tbaa !3
-  %55 = load atomic i32, i32* @"state_global$kotlin.native.concurrent.INITIALIZING" acquire, align 4
-  %56 = icmp eq i32 %55, 2
-  br i1 %56, label %"kfun:kotlin.native.concurrent.INITIALIZING#<get-$instance>#static(){}kotlin.native.concurrent.INITIALIZING.exit.i", label %label_init.i.i
+  %55 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %result.i unordered, align 8
+  store %struct.ObjHeader* %55, %struct.ObjHeader** %26, align 8, !tbaa !3
+  %56 = load atomic i32, i32* @"state_global$kotlin.native.concurrent.INITIALIZING" acquire, align 4
+  %57 = icmp eq i32 %56, 2
+  br i1 %57, label %"kfun:kotlin.native.concurrent.INITIALIZING#<get-$instance>#static(){}kotlin.native.concurrent.INITIALIZING.exit.i", label %label_init.i.i
 
 label_init.i.i:                                   ; preds = %when_case.i
   invoke fastcc void @CallInitGlobalPossiblyLock(i32* nonnull @"state_global$kotlin.native.concurrent.INITIALIZING", void ()* nonnull @"kfun:kotlin.native.concurrent.INITIALIZING.$init_global#internal")
           to label %"kfun:kotlin.native.concurrent.INITIALIZING#<get-$instance>#static(){}kotlin.native.concurrent.INITIALIZING.exit.i" unwind label %call_success3
 
 "kfun:kotlin.native.concurrent.INITIALIZING#<get-$instance>#static(){}kotlin.native.concurrent.INITIALIZING.exit.i": ; preds = %label_init.i.i, %when_case.i
-  %57 = load %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.INITIALIZING.$instance#internal", align 8
-  store %struct.ObjHeader* %57, %struct.ObjHeader** %27, align 8, !tbaa !3
-  %58 = icmp eq %struct.ObjHeader* %54, %57
-  br i1 %58, label %when_case2.i, label %when_exit4.i
+  %58 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.INITIALIZING.$instance#internal" unordered, align 8
+  store %struct.ObjHeader* %58, %struct.ObjHeader** %27, align 8, !tbaa !3
+  %59 = icmp eq %struct.ObjHeader* %55, %58
+  br i1 %59, label %when_case2.i, label %when_exit4.i
 
 when_case2.i:                                     ; preds = %"kfun:kotlin.native.concurrent.INITIALIZING#<get-$instance>#static(){}kotlin.native.concurrent.INITIALIZING.exit.i"
-  %59 = load %struct.ObjHeader*, %struct.ObjHeader** %45, align 8
-  %60 = load i64, i64* bitcast (%struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal" to i64*), align 8
-  %61 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %59, i64 1
-  %62 = bitcast %struct.ObjHeader* %61 to i64*
-  store atomic i64 %60, i64* %62 release, align 8
-  %63 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 6
-  %64 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %63 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %65 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %64, align 8, !tbaa !3
-  %66 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %65, i64 0, i32 2, i32 1
-  %67 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %66, i64 56) #37
-  %68 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %67, i64 1
-  %69 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %67, i64 2
-  %70 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %69 to %struct.ObjHeader*
-  %71 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %69 to %struct.TypeInfo**
-  %72 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %68 to i64*
-  store i64 0, i64* %72, align 8
-  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [5 x i8*] }, { %struct.TypeInfo, [5 x i8*] }* @"ktypeglobal:kotlin.IllegalStateException#internal", i64 0, i32 0), %struct.TypeInfo** %71, align 8, !tbaa !14
-  %73 = bitcast %struct.ObjHeader** %28 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %69, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %73, align 8, !tbaa !3
-  invoke fastcc void @"kfun:kotlin.RuntimeException#<init>(kotlin.String?){}"(%struct.ObjHeader* nonnull %70, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [26 x i16] }* @130 to %struct.ObjHeader*))
+  %60 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %45 unordered, align 8
+  %61 = load atomic i64, i64* bitcast (%struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal" to i64*) unordered, align 8
+  %62 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %60, i64 1
+  %63 = bitcast %struct.ObjHeader* %62 to i64*
+  store atomic i64 %61, i64* %63 release, align 8
+  %64 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 6
+  %65 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %64 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
+  %66 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %65 unordered, align 8, !tbaa !3
+  %67 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %66, i64 0, i32 2, i32 1
+  %68 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %67, i64 56) #37
+  %69 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %68, i64 1
+  %70 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %68, i64 2
+  %71 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %70 to %struct.ObjHeader*
+  %72 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %70 to %struct.TypeInfo**
+  %73 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %69 to i64*
+  store i64 0, i64* %73, align 8
+  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [5 x i8*] }, { %struct.TypeInfo, [5 x i8*] }* @"ktypeglobal:kotlin.IllegalStateException#internal", i64 0, i32 0), %struct.TypeInfo** %72, align 8, !tbaa !14
+  %74 = bitcast %struct.ObjHeader** %28 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %70, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %74, align 8, !tbaa !3
+  invoke fastcc void @"kfun:kotlin.RuntimeException#<init>(kotlin.String?){}"(%struct.ObjHeader* nonnull %71, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [26 x i16] }* @130 to %struct.ObjHeader*))
           to label %.noexc16 unwind label %call_success3
 
 .noexc16:                                         ; preds = %when_case2.i
-  invoke fastcc void @ThrowException(%struct.ObjHeader* nonnull %70) #50
+  invoke fastcc void @ThrowException(%struct.ObjHeader* nonnull %71) #50
           to label %.noexc17 unwind label %call_success3
 
 .noexc17:                                         ; preds = %.noexc16
   unreachable
 
 when_exit4.i:                                     ; preds = %"kfun:kotlin.native.concurrent.INITIALIZING#<get-$instance>#static(){}kotlin.native.concurrent.INITIALIZING.exit.i"
-  %74 = load %struct.ObjHeader*, %struct.ObjHeader** %result.i, align 8
+  %75 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %result.i unordered, align 8
   br label %epilogue
 
 when_exit.i:                                      ; preds = %label_continue.i
-  %75 = load %struct.ObjHeader*, %struct.ObjHeader** %45, align 8
-  %76 = load atomic i32, i32* @"state_global$kotlin.native.concurrent.INITIALIZING" acquire, align 4
-  %77 = icmp eq i32 %76, 2
-  br i1 %77, label %"kfun:kotlin.native.concurrent.INITIALIZING#<get-$instance>#static(){}kotlin.native.concurrent.INITIALIZING.exit2.i", label %label_init.i1.i
+  %76 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %45 unordered, align 8
+  %77 = load atomic i32, i32* @"state_global$kotlin.native.concurrent.INITIALIZING" acquire, align 4
+  %78 = icmp eq i32 %77, 2
+  br i1 %78, label %"kfun:kotlin.native.concurrent.INITIALIZING#<get-$instance>#static(){}kotlin.native.concurrent.INITIALIZING.exit2.i", label %label_init.i1.i
 
 label_init.i1.i:                                  ; preds = %when_exit.i
   invoke fastcc void @CallInitGlobalPossiblyLock(i32* nonnull @"state_global$kotlin.native.concurrent.INITIALIZING", void ()* nonnull @"kfun:kotlin.native.concurrent.INITIALIZING.$init_global#internal")
           to label %"kfun:kotlin.native.concurrent.INITIALIZING#<get-$instance>#static(){}kotlin.native.concurrent.INITIALIZING.exit2.i" unwind label %call_success3
 
 "kfun:kotlin.native.concurrent.INITIALIZING#<get-$instance>#static(){}kotlin.native.concurrent.INITIALIZING.exit2.i": ; preds = %label_init.i1.i, %when_exit.i
-  %78 = load %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.INITIALIZING.$instance#internal", align 8
-  store %struct.ObjHeader* %78, %struct.ObjHeader** %29, align 8, !tbaa !3
-  %79 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %75, i64 1
-  %80 = ptrtoint %struct.ObjHeader* %78 to i64
-  %81 = bitcast %struct.ObjHeader* %79 to i64*
-  store atomic i64 %80, i64* %81 release, align 8
-  %82 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
-  %83 = bitcast %struct.ObjHeader* %82 to %struct.ObjHeader**
-  %84 = load %struct.ObjHeader*, %struct.ObjHeader** %83, align 8
-  store %struct.ObjHeader* %84, %struct.ObjHeader** %30, align 8, !tbaa !3
-  %85 = icmp eq %struct.ObjHeader* %84, null
-  br i1 %85, label %when_case10.i, label %when_exit11.i
+  %79 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.INITIALIZING.$instance#internal" unordered, align 8
+  store %struct.ObjHeader* %79, %struct.ObjHeader** %29, align 8, !tbaa !3
+  %80 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %76, i64 1
+  %81 = ptrtoint %struct.ObjHeader* %79 to i64
+  %82 = bitcast %struct.ObjHeader* %80 to i64*
+  store atomic i64 %81, i64* %82 release, align 8
+  %83 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
+  %84 = bitcast %struct.ObjHeader* %83 to %struct.ObjHeader**
+  %85 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %84 unordered, align 8
+  store %struct.ObjHeader* %85, %struct.ObjHeader** %30, align 8, !tbaa !3
+  %86 = icmp eq %struct.ObjHeader* %85, null
+  br i1 %86, label %when_case10.i, label %when_exit11.i
 
 when_case10.i:                                    ; preds = %"kfun:kotlin.native.concurrent.INITIALIZING#<get-$instance>#static(){}kotlin.native.concurrent.INITIALIZING.exit2.i"
   invoke fastcc void @ThrowNullPointerException() #50
@@ -6210,82 +6283,82 @@
 landingpad.i:                                     ; preds = %when_exit11.i, %when_case10.i
   %lp.i = landingpad { i8*, i32 }
           catch i8* null
-  %86 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %87 = bitcast %"class.kotlin::mm::ShadowStack"* %86 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %87, align 8, !tbaa !7
+  %87 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
+  %88 = bitcast %"class.kotlin::mm::ShadowStack"* %87 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %88, align 8, !tbaa !7
   %er.i = extractvalue { i8*, i32 } %lp.i, 0
-  %88 = call i8* @__cxa_begin_catch(i8* %er.i) #37
-  %89 = getelementptr inbounds i8, i8* %88, i64 8
-  %90 = bitcast i8* %89 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"**
-  %91 = load %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %90, align 8, !tbaa !65
-  %92 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %91, i64 0, i32 0
-  %93 = load %struct.ObjHeader*, %struct.ObjHeader** %92, align 8, !tbaa !3
-  store %struct.ObjHeader* %93, %struct.ObjHeader** %31, align 8, !tbaa !3
+  %89 = call i8* @__cxa_begin_catch(i8* %er.i) #37
+  %90 = getelementptr inbounds i8, i8* %89, i64 8
+  %91 = bitcast i8* %90 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"**
+  %92 = load atomic %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %91 unordered, align 8, !tbaa !64
+  %93 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %92, i64 0, i32 0
+  %94 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %93 unordered, align 8, !tbaa !3
+  store %struct.ObjHeader* %94, %struct.ObjHeader** %31, align 8, !tbaa !3
   call void @__cxa_end_catch() #37
-  %94 = load %struct.ObjHeader*, %struct.ObjHeader** %45, align 8
-  %95 = load i64, i64* bitcast (%struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal" to i64*), align 8
-  %96 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %94, i64 1
-  %97 = bitcast %struct.ObjHeader* %96 to i64*
-  store atomic i64 %95, i64* %97 release, align 8
-  invoke fastcc void @ThrowException(%struct.ObjHeader* %93) #50
+  %95 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %45 unordered, align 8
+  %96 = load atomic i64, i64* bitcast (%struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal" to i64*) unordered, align 8
+  %97 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %95, i64 1
+  %98 = bitcast %struct.ObjHeader* %97 to i64*
+  store atomic i64 %96, i64* %98 release, align 8
+  invoke fastcc void @ThrowException(%struct.ObjHeader* %94) #50
           to label %.noexc19 unwind label %call_success3
 
 .noexc19:                                         ; preds = %landingpad.i
   unreachable
 
 when_exit11.i:                                    ; preds = %"kfun:kotlin.native.concurrent.INITIALIZING#<get-$instance>#static(){}kotlin.native.concurrent.INITIALIZING.exit2.i"
-  %98 = invoke %struct.ObjHeader* @"kfun:kotlin.Throwable.$<init>$lambda$0$FUNCTION_REFERENCE$1.invoke#internal"(%struct.ObjHeader* nonnull %84, %struct.ObjHeader** nonnull %32)
+  %99 = invoke %struct.ObjHeader* @"kfun:kotlin.Throwable.$<init>$lambda$0$FUNCTION_REFERENCE$1.invoke#internal"(%struct.ObjHeader* nonnull %85, %struct.ObjHeader** nonnull %32)
           to label %call_success18.i unwind label %landingpad.i
 
 call_success18.i:                                 ; preds = %when_exit11.i
-  store %struct.ObjHeader* %98, %struct.ObjHeader** %result.i, align 8, !tbaa !3
-  store %struct.ObjHeader* null, %struct.ObjHeader** %83, align 8, !tbaa !3
-  %99 = load %struct.ObjHeader*, %struct.ObjHeader** %45, align 8
-  %100 = load %struct.ObjHeader*, %struct.ObjHeader** %result.i, align 8
-  store %struct.ObjHeader* %100, %struct.ObjHeader** %33, align 8, !tbaa !3
-  %101 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %99, i64 1
-  %102 = ptrtoint %struct.ObjHeader* %100 to i64
-  %103 = bitcast %struct.ObjHeader* %101 to i64*
-  store atomic i64 %102, i64* %103 release, align 8
-  %104 = load %struct.ObjHeader*, %struct.ObjHeader** %result.i, align 8
+  store %struct.ObjHeader* %99, %struct.ObjHeader** %result.i, align 8, !tbaa !3
+  store %struct.ObjHeader* null, %struct.ObjHeader** %84, align 8, !tbaa !3
+  %100 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %45 unordered, align 8
+  %101 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %result.i unordered, align 8
+  store %struct.ObjHeader* %101, %struct.ObjHeader** %33, align 8, !tbaa !3
+  %102 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %100, i64 1
+  %103 = ptrtoint %struct.ObjHeader* %101 to i64
+  %104 = bitcast %struct.ObjHeader* %102 to i64*
+  store atomic i64 %103, i64* %104 release, align 8
+  %105 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %result.i unordered, align 8
   br label %epilogue
 
 call_success3:                                    ; preds = %landingpad.i, %label_init.i1.i, %.noexc16, %when_case2.i, %label_init.i.i, %label_init.i
   %lp = landingpad { i8*, i32 }
           catch i8* null
-  %105 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 3
-  %106 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %107 = bitcast %"class.kotlin::mm::ShadowStack"* %106 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub, %struct.ObjHeader*** %107, align 8, !tbaa !7
+  %106 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 3
+  %107 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
+  %108 = bitcast %"class.kotlin::mm::ShadowStack"* %107 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub, %struct.ObjHeader*** %108, align 8, !tbaa !7
   %er = extractvalue { i8*, i32 } %lp, 0
-  %108 = call i8* @__cxa_begin_catch(i8* %er) #37
-  %109 = getelementptr inbounds i8, i8* %108, i64 8
-  %110 = bitcast i8* %109 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"**
-  %111 = load %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %110, align 8, !tbaa !65
-  %112 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %111, i64 0, i32 0
-  %113 = load %struct.ObjHeader*, %struct.ObjHeader** %112, align 8, !tbaa !3
-  store %struct.ObjHeader* %113, %struct.ObjHeader** %105, align 8, !tbaa !3
+  %109 = call i8* @__cxa_begin_catch(i8* %er) #37
+  %110 = getelementptr inbounds i8, i8* %109, i64 8
+  %111 = bitcast i8* %110 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"**
+  %112 = load atomic %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %111 unordered, align 8, !tbaa !64
+  %113 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %112, i64 0, i32 0
+  %114 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %113 unordered, align 8, !tbaa !3
+  store %struct.ObjHeader* %114, %struct.ObjHeader** %106, align 8, !tbaa !3
   call void @__cxa_end_catch() #37
   call fastcc void @"kfun:kotlin.native.concurrent.Lock#unlock(){}"(%struct.ObjHeader* %22)
-  call fastcc void @ThrowException(%struct.ObjHeader* %113) #50
+  call fastcc void @ThrowException(%struct.ObjHeader* %114) #50
   unreachable
 
 epilogue:                                         ; preds = %call_success18.i, %when_exit4.i
-  %114 = phi %struct.ObjHeader* [ %74, %when_exit4.i ], [ %104, %call_success18.i ]
-  %115 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 4
-  store %struct.ObjHeader* %114, %struct.ObjHeader** %115, align 8, !tbaa !3
-  %116 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %117 = load i64, i64* %39, align 8, !tbaa !9
-  %118 = bitcast %"class.kotlin::mm::ShadowStack"* %116 to i64*
-  store i64 %117, i64* %118, align 8, !tbaa !7
+  %115 = phi %struct.ObjHeader* [ %75, %when_exit4.i ], [ %105, %call_success18.i ]
+  %116 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 4
+  store %struct.ObjHeader* %115, %struct.ObjHeader** %116, align 8, !tbaa !3
+  %117 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
+  %118 = load atomic i64, i64* %39 unordered, align 8, !tbaa !9
+  %119 = bitcast %"class.kotlin::mm::ShadowStack"* %117 to i64*
+  store i64 %118, i64* %119, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 136, i8* nonnull %23)
   call fastcc void @"kfun:kotlin.native.concurrent.Lock#unlock(){}"(%struct.ObjHeader* %22)
-  store %struct.ObjHeader* %114, %struct.ObjHeader** %1, align 8, !tbaa !3
-  %119 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %120 = load i64, i64* %11, align 8, !tbaa !9
-  %121 = bitcast %"class.kotlin::mm::ShadowStack"* %119 to i64*
-  store i64 %120, i64* %121, align 8, !tbaa !7
-  ret %struct.ObjHeader* %114
+  store %struct.ObjHeader* %115, %struct.ObjHeader** %1, align 8, !tbaa !3
+  %120 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
+  %121 = load atomic i64, i64* %11 unordered, align 8, !tbaa !9
+  %122 = bitcast %"class.kotlin::mm::ShadowStack"* %120 to i64*
+  store i64 %121, i64* %122, align 8, !tbaa !7
+  ret %struct.ObjHeader* %115
 }
 
 ; Function Attrs: nounwind
@@ -6297,11 +6370,11 @@
   %2 = bitcast [4 x %struct.ObjHeader*]* %1 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %2, i8 0, i32 32, i1 immarg false) #49
   %3 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 3
-  %4 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %4 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %5 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
   %6 = bitcast [4 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
   %7 = bitcast %"class.kotlin::mm::ShadowStack"* %5 to i64*
-  %8 = load i64, i64* %7, align 8, !tbaa !7
+  %8 = load atomic i64, i64* %7 unordered, align 8, !tbaa !7
   %9 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 1
   %10 = bitcast %struct.ObjHeader** %9 to i64*
   store i64 %8, i64* %10, align 8, !tbaa !9
@@ -6324,7 +6397,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %18, %epilogue
   %19 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 6
   %20 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %19 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %21 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %20, align 8, !tbaa !3
+  %21 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %20 unordered, align 8, !tbaa !3
   %22 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %21, i64 0, i32 2, i32 1
   %23 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %22, i64 16) #37
   %24 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %23, i64 1
@@ -6336,39 +6409,39 @@
   %28 = bitcast %struct.ObjHeader** %3 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %25, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %28, align 8, !tbaa !3
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %25, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** bitcast (%struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal" to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**), align 8, !tbaa !3
-  %.cast = ptrtoint %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %25 to i64
-  %29 = bitcast [4 x %struct.ObjHeader*]* %0 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %29)
+  %29 = load atomic i64, i64* bitcast (%struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal" to i64*) unordered, align 8
+  %30 = bitcast [4 x %struct.ObjHeader*]* %0 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %30)
   %.sub.i = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 0
-  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %29, i8 0, i32 32, i1 immarg false) #49
-  %30 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 3
-  %31 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %32 = bitcast [4 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
-  %33 = bitcast %"class.kotlin::mm::ShadowStack"* %31 to i64*
-  %34 = load i64, i64* %33, align 8, !tbaa !7
-  %35 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 1
-  %36 = bitcast %struct.ObjHeader** %35 to i64*
-  store i64 %34, i64* %36, align 8, !tbaa !9
-  %37 = bitcast %"class.kotlin::mm::ShadowStack"* %31 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %37, align 8, !tbaa !7
-  %38 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 2
-  %39 = bitcast %struct.ObjHeader** %38 to i32*
-  store i32 0, i32* %39, align 8, !tbaa !12
-  %40 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %32, i64 0, i32 3
-  store i32 4, i32* %40, align 4, !tbaa !13
-  %41 = bitcast %struct.ObjHeader** %30 to i64*
-  store i64 %.cast, i64* %41, align 8, !tbaa !3
-  %42 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %43 = load i64, i64* %36, align 8, !tbaa !9
-  %44 = bitcast %"class.kotlin::mm::ShadowStack"* %42 to i64*
-  store i64 %43, i64* %44, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %29)
-  %45 = load %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal", align 8
-  call fastcc void @InitAndRegisterGlobal(%struct.ObjHeader** nonnull @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal", %struct.ObjHeader* %45) #37
-  %46 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %47 = load i64, i64* %10, align 8, !tbaa !9
-  %48 = bitcast %"class.kotlin::mm::ShadowStack"* %46 to i64*
-  store i64 %47, i64* %48, align 8, !tbaa !7
+  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %30, i8 0, i32 32, i1 immarg false) #49
+  %31 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 3
+  %32 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
+  %33 = bitcast [4 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
+  %34 = bitcast %"class.kotlin::mm::ShadowStack"* %32 to i64*
+  %35 = load atomic i64, i64* %34 unordered, align 8, !tbaa !7
+  %36 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 1
+  %37 = bitcast %struct.ObjHeader** %36 to i64*
+  store i64 %35, i64* %37, align 8, !tbaa !9
+  %38 = bitcast %"class.kotlin::mm::ShadowStack"* %32 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %38, align 8, !tbaa !7
+  %39 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 2
+  %40 = bitcast %struct.ObjHeader** %39 to i32*
+  store i32 0, i32* %40, align 8, !tbaa !12
+  %41 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %33, i64 0, i32 3
+  store i32 4, i32* %41, align 4, !tbaa !13
+  %42 = bitcast %struct.ObjHeader** %31 to i64*
+  store i64 %29, i64* %42, align 8, !tbaa !3
+  %43 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
+  %44 = load atomic i64, i64* %37 unordered, align 8, !tbaa !9
+  %45 = bitcast %"class.kotlin::mm::ShadowStack"* %43 to i64*
+  store i64 %44, i64* %45, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %30)
+  %46 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal" unordered, align 8
+  call fastcc void @InitAndRegisterGlobal(%struct.ObjHeader** nonnull @"kvar:kotlin.native.concurrent.UNINITIALIZED.$instance#internal", %struct.ObjHeader* %46) #37
+  %47 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
+  %48 = load atomic i64, i64* %10 unordered, align 8, !tbaa !9
+  %49 = bitcast %"class.kotlin::mm::ShadowStack"* %47 to i64*
+  store i64 %48, i64* %49, align 8, !tbaa !7
   ret void
 }
 
@@ -6381,11 +6454,11 @@
   %2 = bitcast [4 x %struct.ObjHeader*]* %1 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %2, i8 0, i32 32, i1 immarg false) #49
   %3 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 3
-  %4 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %4 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %5 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
   %6 = bitcast [4 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
   %7 = bitcast %"class.kotlin::mm::ShadowStack"* %5 to i64*
-  %8 = load i64, i64* %7, align 8, !tbaa !7
+  %8 = load atomic i64, i64* %7 unordered, align 8, !tbaa !7
   %9 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 1
   %10 = bitcast %struct.ObjHeader** %9 to i64*
   store i64 %8, i64* %10, align 8, !tbaa !9
@@ -6408,7 +6481,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %18, %epilogue
   %19 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 6
   %20 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %19 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %21 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %20, align 8, !tbaa !3
+  %21 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %20 unordered, align 8, !tbaa !3
   %22 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %21, i64 0, i32 2, i32 1
   %23 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %22, i64 16) #37
   %24 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %23, i64 1
@@ -6420,39 +6493,39 @@
   %28 = bitcast %struct.ObjHeader** %3 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %25, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %28, align 8, !tbaa !3
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %25, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** bitcast (%struct.ObjHeader** @"kvar:kotlin.native.concurrent.INITIALIZING.$instance#internal" to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**), align 8, !tbaa !3
-  %.cast = ptrtoint %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %25 to i64
-  %29 = bitcast [4 x %struct.ObjHeader*]* %0 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %29)
+  %29 = load atomic i64, i64* bitcast (%struct.ObjHeader** @"kvar:kotlin.native.concurrent.INITIALIZING.$instance#internal" to i64*) unordered, align 8
+  %30 = bitcast [4 x %struct.ObjHeader*]* %0 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %30)
   %.sub.i = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 0
-  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %29, i8 0, i32 32, i1 immarg false) #49
-  %30 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 3
-  %31 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %32 = bitcast [4 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
-  %33 = bitcast %"class.kotlin::mm::ShadowStack"* %31 to i64*
-  %34 = load i64, i64* %33, align 8, !tbaa !7
-  %35 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 1
-  %36 = bitcast %struct.ObjHeader** %35 to i64*
-  store i64 %34, i64* %36, align 8, !tbaa !9
-  %37 = bitcast %"class.kotlin::mm::ShadowStack"* %31 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %37, align 8, !tbaa !7
-  %38 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 2
-  %39 = bitcast %struct.ObjHeader** %38 to i32*
-  store i32 0, i32* %39, align 8, !tbaa !12
-  %40 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %32, i64 0, i32 3
-  store i32 4, i32* %40, align 4, !tbaa !13
-  %41 = bitcast %struct.ObjHeader** %30 to i64*
-  store i64 %.cast, i64* %41, align 8, !tbaa !3
-  %42 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %43 = load i64, i64* %36, align 8, !tbaa !9
-  %44 = bitcast %"class.kotlin::mm::ShadowStack"* %42 to i64*
-  store i64 %43, i64* %44, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %29)
-  %45 = load %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.INITIALIZING.$instance#internal", align 8
-  call fastcc void @InitAndRegisterGlobal(%struct.ObjHeader** nonnull @"kvar:kotlin.native.concurrent.INITIALIZING.$instance#internal", %struct.ObjHeader* %45) #37
-  %46 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %47 = load i64, i64* %10, align 8, !tbaa !9
-  %48 = bitcast %"class.kotlin::mm::ShadowStack"* %46 to i64*
-  store i64 %47, i64* %48, align 8, !tbaa !7
+  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %30, i8 0, i32 32, i1 immarg false) #49
+  %31 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 3
+  %32 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
+  %33 = bitcast [4 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
+  %34 = bitcast %"class.kotlin::mm::ShadowStack"* %32 to i64*
+  %35 = load atomic i64, i64* %34 unordered, align 8, !tbaa !7
+  %36 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 1
+  %37 = bitcast %struct.ObjHeader** %36 to i64*
+  store i64 %35, i64* %37, align 8, !tbaa !9
+  %38 = bitcast %"class.kotlin::mm::ShadowStack"* %32 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %38, align 8, !tbaa !7
+  %39 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 2
+  %40 = bitcast %struct.ObjHeader** %39 to i32*
+  store i32 0, i32* %40, align 8, !tbaa !12
+  %41 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %33, i64 0, i32 3
+  store i32 4, i32* %41, align 4, !tbaa !13
+  %42 = bitcast %struct.ObjHeader** %31 to i64*
+  store i64 %29, i64* %42, align 8, !tbaa !3
+  %43 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
+  %44 = load atomic i64, i64* %37 unordered, align 8, !tbaa !9
+  %45 = bitcast %"class.kotlin::mm::ShadowStack"* %43 to i64*
+  store i64 %44, i64* %45, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %30)
+  %46 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.concurrent.INITIALIZING.$instance#internal" unordered, align 8
+  call fastcc void @InitAndRegisterGlobal(%struct.ObjHeader** nonnull @"kvar:kotlin.native.concurrent.INITIALIZING.$instance#internal", %struct.ObjHeader* %46) #37
+  %47 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
+  %48 = load atomic i64, i64* %10 unordered, align 8, !tbaa !9
+  %49 = bitcast %"class.kotlin::mm::ShadowStack"* %47 to i64*
+  store i64 %48, i64* %49, align 8, !tbaa !7
   ret void
 }
 
@@ -6468,7 +6541,7 @@
   br label %Kotlin_mm_safePointFunctionPrologue.exit
 
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %entry
-  %5 = load i32, i32* @"state_thread_local$kotlin.native.concurrent.CurrentThread", align 4
+  %5 = load atomic i32, i32* @"state_thread_local$kotlin.native.concurrent.CurrentThread" unordered, align 4
   %6 = icmp eq i32 %5, 2
   br i1 %6, label %call_success1, label %call_success
 
@@ -6479,9 +6552,9 @@
 call_success1:                                    ; preds = %call_success, %Kotlin_mm_safePointFunctionPrologue.exit
   %7 = tail call fastcc %struct.ObjHeader** @LookupTLS(i32 0) #37
   %8 = bitcast %struct.ObjHeader** %7 to %"kclassbody:kotlin.native.concurrent.CurrentThread#internal"**
-  %9 = load %"kclassbody:kotlin.native.concurrent.CurrentThread#internal"*, %"kclassbody:kotlin.native.concurrent.CurrentThread#internal"** %8, align 8
+  %9 = load atomic %"kclassbody:kotlin.native.concurrent.CurrentThread#internal"*, %"kclassbody:kotlin.native.concurrent.CurrentThread#internal"** %8 unordered, align 8
   %10 = getelementptr inbounds %"kclassbody:kotlin.native.concurrent.CurrentThread#internal", %"kclassbody:kotlin.native.concurrent.CurrentThread#internal"* %9, i64 0, i32 1
-  %11 = load %struct.ObjHeader*, %struct.ObjHeader** %10, align 8
+  %11 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %10 unordered, align 8
   %12 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %11, i64 0, i32 0
   %13 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %12 monotonic, align 8
   %14 = ptrtoint %struct.TypeInfo* %13 to i64
@@ -6491,7 +6564,7 @@
   %18 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %17 monotonic, align 8
   %19 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %18, i64 1, i32 1
   %20 = bitcast %struct.ExtendedTypeInfo** %19 to i32 (%struct.ObjHeader*)**
-  %21 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %20, align 8
+  %21 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %20 unordered, align 8
   %22 = tail call i32 %21(%struct.ObjHeader* %11)
   %23 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %24 = bitcast %struct.ObjHeader* %23 to %struct.ObjHeader**
@@ -6508,7 +6581,7 @@
   br label %call_success2
 
 call_success2:                                    ; preds = %28, %do_while_loop
-  %29 = load %struct.ObjHeader*, %struct.ObjHeader** %24, align 8
+  %29 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %24 unordered, align 8
   %30 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %29, i64 1
   %31 = bitcast %struct.ObjHeader* %30 to i32*
   %32 = cmpxchg volatile i32* %31, i32 0, i32 %22 seq_cst seq_cst, align 4
@@ -6519,7 +6592,7 @@
 call_success4:                                    ; preds = %call_success2
   %35 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %36 = bitcast %struct.ObjHeader* %35 to %struct.ObjHeader**
-  %37 = load %struct.ObjHeader*, %struct.ObjHeader** %36, align 8
+  %37 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %36 unordered, align 8
   %38 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %37, i64 1
   %39 = bitcast %struct.ObjHeader* %38 to i32*
   %40 = atomicrmw add i32* %39, i32 1 seq_cst, align 4
@@ -6547,7 +6620,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %call_success
   %5 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %6 = bitcast %struct.ObjHeader* %5 to %struct.ObjHeader**
-  %7 = load %struct.ObjHeader*, %struct.ObjHeader** %6, align 8
+  %7 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %6 unordered, align 8
   %8 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %7, i64 1
   %9 = bitcast %struct.ObjHeader* %8 to i32*
   %10 = load atomic volatile i32, i32* %9 seq_cst, align 4
@@ -6555,7 +6628,7 @@
   br i1 %11, label %call_success1, label %call_success3
 
 call_success1:                                    ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
-  %12 = load %struct.ObjHeader*, %struct.ObjHeader** %6, align 8
+  %12 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %6 unordered, align 8
   %13 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %12, i64 1
   %14 = bitcast %struct.ObjHeader* %13 to i32*
   %15 = atomicrmw add i32* %14, i32 -1 seq_cst, align 4
@@ -6564,9 +6637,9 @@
 call_success3:                                    ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
   %16 = tail call fastcc %struct.ObjHeader** @LookupTLS(i32 0) #37
   %17 = bitcast %struct.ObjHeader** %16 to %"kclassbody:kotlin.native.concurrent.CurrentThread#internal"**
-  %18 = load %"kclassbody:kotlin.native.concurrent.CurrentThread#internal"*, %"kclassbody:kotlin.native.concurrent.CurrentThread#internal"** %17, align 8
+  %18 = load atomic %"kclassbody:kotlin.native.concurrent.CurrentThread#internal"*, %"kclassbody:kotlin.native.concurrent.CurrentThread#internal"** %17 unordered, align 8
   %19 = getelementptr inbounds %"kclassbody:kotlin.native.concurrent.CurrentThread#internal", %"kclassbody:kotlin.native.concurrent.CurrentThread#internal"* %18, i64 0, i32 1
-  %20 = load %struct.ObjHeader*, %struct.ObjHeader** %19, align 8
+  %20 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %19 unordered, align 8
   %21 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %20, i64 0, i32 0
   %22 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %21 monotonic, align 8
   %23 = ptrtoint %struct.TypeInfo* %22 to i64
@@ -6576,11 +6649,11 @@
   %27 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %26 monotonic, align 8
   %28 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %27, i64 1, i32 1
   %29 = bitcast %struct.ExtendedTypeInfo** %28 to i32 (%struct.ObjHeader*)**
-  %30 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %29, align 8
+  %30 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %29 unordered, align 8
   %31 = tail call i32 %30(%struct.ObjHeader* %20)
   %32 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %33 = bitcast %struct.ObjHeader* %32 to %struct.ObjHeader**
-  %34 = load %struct.ObjHeader*, %struct.ObjHeader** %33, align 8
+  %34 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %33 unordered, align 8
   %35 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %34, i64 1
   %36 = bitcast %struct.ObjHeader* %35 to i32*
   %37 = cmpxchg volatile i32* %36, i32 %31, i32 0 seq_cst seq_cst, align 4
@@ -6599,11 +6672,11 @@
   %2 = bitcast [4 x %struct.ObjHeader*]* %1 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %2, i8 0, i32 32, i1 immarg false) #49
   %3 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 3
-  %4 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %4 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %5 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
   %6 = bitcast [4 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
   %7 = bitcast %"class.kotlin::mm::ShadowStack"* %5 to i64*
-  %8 = load i64, i64* %7, align 8, !tbaa !7
+  %8 = load atomic i64, i64* %7 unordered, align 8, !tbaa !7
   %9 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 1
   %10 = bitcast %struct.ObjHeader** %9 to i64*
   store i64 %8, i64* %10, align 8, !tbaa !9
@@ -6627,7 +6700,7 @@
   %19 = call fastcc %struct.ObjHeader** @LookupTLS(i32 0) #37
   %20 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 6
   %21 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %20 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %22 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %21, align 8, !tbaa !3
+  %22 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %21 unordered, align 8, !tbaa !3
   %23 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %22, i64 0, i32 2, i32 1
   %24 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %23, i64 24) #37
   %25 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %24, i64 1
@@ -6642,7 +6715,7 @@
   %31 = bitcast %struct.ObjHeader** %30 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %26, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %31, align 8, !tbaa !3
   %32 = call fastcc %struct.ObjHeader** @LookupTLS(i32 0) #37
-  %33 = load %struct.ObjHeader*, %struct.ObjHeader** %32, align 8
+  %33 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %32 unordered, align 8
   %34 = bitcast [5 x %struct.ObjHeader*]* %0 to i8*
   call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %34)
   %.sub.i = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %0, i64 0, i64 0
@@ -6652,7 +6725,7 @@
   %37 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
   %38 = bitcast [5 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
   %39 = bitcast %"class.kotlin::mm::ShadowStack"* %37 to i64*
-  %40 = load i64, i64* %39, align 8, !tbaa !7
+  %40 = load atomic i64, i64* %39 unordered, align 8, !tbaa !7
   %41 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %0, i64 0, i64 1
   %42 = bitcast %struct.ObjHeader** %41 to i64*
   store i64 %40, i64* %42, align 8, !tbaa !9
@@ -6665,7 +6738,7 @@
   store i32 5, i32* %46, align 4, !tbaa !13
   %47 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 6
   %48 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %47 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %49 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %48, align 8, !tbaa !3
+  %49 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %48 unordered, align 8, !tbaa !3
   %50 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %49, i64 0, i32 2, i32 1
   %51 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %50, i64 16) #37
   %52 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %51, i64 1
@@ -6682,17 +6755,17 @@
   %59 = bitcast %struct.ObjHeader* %58 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %53, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %59, align 8, !tbaa !3
   %60 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %61 = load i64, i64* %42, align 8, !tbaa !9
+  %61 = load atomic i64, i64* %42 unordered, align 8, !tbaa !9
   %62 = bitcast %"class.kotlin::mm::ShadowStack"* %60 to i64*
   store i64 %61, i64* %62, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %34)
   %63 = call fastcc %struct.ObjHeader** @LookupTLS(i32 0) #37
   %64 = bitcast %struct.ObjHeader** %63 to i64*
-  %65 = load i64, i64* %64, align 8
+  %65 = load atomic i64, i64* %64 unordered, align 8
   %66 = bitcast %struct.ObjHeader** %19 to i64*
   store i64 %65, i64* %66, align 8, !tbaa !3
   %67 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %68 = load i64, i64* %10, align 8, !tbaa !9
+  %68 = load atomic i64, i64* %10 unordered, align 8, !tbaa !9
   %69 = bitcast %"class.kotlin::mm::ShadowStack"* %67 to i64*
   store i64 %68, i64* %69, align 8, !tbaa !7
   ret void
@@ -6705,11 +6778,11 @@
   %3 = bitcast [5 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %3, i8 0, i32 40, i1 immarg false) #49
   %4 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 4
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %7 = bitcast [5 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %8 = bitcast %"class.kotlin::mm::ShadowStack"* %6 to i64*
-  %9 = load i64, i64* %8, align 8, !tbaa !7
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !7
   %10 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %11 = bitcast %struct.ObjHeader** %10 to i64*
   store i64 %9, i64* %11, align 8, !tbaa !9
@@ -6732,10 +6805,10 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %19, %entry
   %20 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %21 = bitcast %struct.ObjHeader* %20 to i8**
-  %22 = load i8*, i8** %21, align 8
+  %22 = load atomic i8*, i8** %21 unordered, align 8
   %23 = getelementptr inbounds i8, i8* %22, i64 88
   %24 = bitcast i8* %23 to i32*
-  %25 = load i32, i32* %24, align 8, !tbaa !67
+  %25 = load atomic i32, i32* %24 unordered, align 8, !tbaa !66
   %26 = and i32 %25, 512
   %27 = icmp eq i32 %26, 0
   br i1 %27, label %epilogue, label %call_success
@@ -6744,7 +6817,7 @@
   %28 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %29 = getelementptr inbounds i8, i8* %22, i64 80
   %30 = bitcast i8* %29 to %struct.ObjHeader**
-  %31 = load %struct.ObjHeader*, %struct.ObjHeader** %30, align 8, !tbaa !68
+  %31 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %30 unordered, align 8, !tbaa !67
   store %struct.ObjHeader* %31, %struct.ObjHeader** %28, align 8, !tbaa !3
   %32 = icmp eq %struct.ObjHeader* %31, null
   br i1 %32, label %epilogue, label %call_success2
@@ -6758,7 +6831,7 @@
   %35 = phi %struct.ObjHeader* [ %34, %call_success2 ], [ null, %call_success ], [ null, %Kotlin_mm_safePointFunctionPrologue.exit ]
   store %struct.ObjHeader* %35, %struct.ObjHeader** %1, align 8, !tbaa !3
   %36 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %37 = load i64, i64* %11, align 8, !tbaa !9
+  %37 = load atomic i64, i64* %11 unordered, align 8, !tbaa !9
   %38 = bitcast %"class.kotlin::mm::ShadowStack"* %36 to i64*
   store i64 %37, i64* %38, align 8, !tbaa !7
   ret %struct.ObjHeader* %35
@@ -6782,11 +6855,11 @@
   %objHeader = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %9, i64 0, i32 0
   %typeInfoOrMeta_ = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %9, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_, align 8
-  %12 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %12 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %13 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %14 = bitcast [9 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %15 = bitcast %"class.kotlin::mm::ShadowStack"* %13 to i64*
-  %16 = load i64, i64* %15, align 8, !tbaa !7
+  %16 = load atomic i64, i64* %15 unordered, align 8, !tbaa !7
   %17 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %18 = bitcast %struct.ObjHeader** %17 to i64*
   store i64 %16, i64* %18, align 8, !tbaa !9
@@ -6809,10 +6882,10 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %26, %entry
   %27 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %28 = bitcast %struct.ObjHeader* %27 to i8**
-  %29 = load i8*, i8** %28, align 8
+  %29 = load atomic i8*, i8** %28 unordered, align 8
   %30 = getelementptr inbounds i8, i8* %29, i64 88
   %31 = bitcast i8* %30 to i32*
-  %32 = load i32, i32* %31, align 8, !tbaa !67
+  %32 = load atomic i32, i32* %31 unordered, align 8, !tbaa !66
   %33 = and i32 %32, 256
   %34 = icmp eq i32 %33, 0
   br i1 %34, label %epilogue, label %call_success
@@ -6821,7 +6894,7 @@
   %35 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %36 = getelementptr inbounds i8, i8* %29, i64 72
   %37 = bitcast i8* %36 to %struct.ObjHeader**
-  %38 = load %struct.ObjHeader*, %struct.ObjHeader** %37, align 8, !tbaa !69
+  %38 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %37 unordered, align 8, !tbaa !68
   store %struct.ObjHeader* %38, %struct.ObjHeader** %35, align 8, !tbaa !3
   %39 = icmp eq %struct.ObjHeader* %38, null
   %40 = and i32 %32, 512
@@ -6832,7 +6905,7 @@
 call_success1:                                    ; preds = %call_success
   %42 = getelementptr inbounds i8, i8* %29, i64 80
   %43 = bitcast i8* %42 to %struct.ObjHeader**
-  %44 = load %struct.ObjHeader*, %struct.ObjHeader** %43, align 8, !tbaa !68
+  %44 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %43 unordered, align 8, !tbaa !67
   store %struct.ObjHeader* %44, %struct.ObjHeader** %4, align 8, !tbaa !3
   %45 = icmp eq %struct.ObjHeader* %44, null
   br i1 %45, label %epilogue, label %returnable_block_exit
@@ -6840,7 +6913,7 @@
 returnable_block_exit:                            ; preds = %call_success1
   %46 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %38, i64 1
   %47 = bitcast %struct.ObjHeader* %46 to i32*
-  %48 = load i32, i32* %47, align 8, !tbaa !18
+  %48 = load atomic i32, i32* %47 unordered, align 8, !tbaa !18
   %49 = icmp eq i32 %48, 0
   br i1 %49, label %epilogue, label %call_success13
 
@@ -6857,7 +6930,7 @@
   %54 = phi %struct.ObjHeader* [ null, %call_success ], [ null, %call_success1 ], [ %53, %call_success13 ], [ %44, %returnable_block_exit ], [ null, %Kotlin_mm_safePointFunctionPrologue.exit ]
   store %struct.ObjHeader* %54, %struct.ObjHeader** %1, align 8, !tbaa !3
   %55 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %56 = load i64, i64* %18, align 8, !tbaa !9
+  %56 = load atomic i64, i64* %18 unordered, align 8, !tbaa !9
   %57 = bitcast %"class.kotlin::mm::ShadowStack"* %55 to i64*
   store i64 %56, i64* %57, align 8, !tbaa !7
   ret %struct.ObjHeader* %54
@@ -6887,17 +6960,17 @@
   %11 = load atomic volatile i64, i64* %10 monotonic, align 8
   %12 = inttoptr i64 %11 to %struct.TypeInfo*
   %13 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %12, i64 0, i32 14
-  %14 = load i32, i32* %13, align 4, !tbaa !19
+  %14 = load atomic i32, i32* %13 unordered, align 4, !tbaa !19
   %15 = icmp eq i32 %14, 202
   br i1 %15, label %when_case, label %epilogue
 
 when_case:                                        ; preds = %instance_of_exit
   %16 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %17 = bitcast %struct.ObjHeader* %16 to i8**
-  %18 = load i8*, i8** %17, align 8
+  %18 = load atomic i8*, i8** %17 unordered, align 8
   %19 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %1, i64 1
   %20 = bitcast %struct.ObjHeader* %19 to i8**
-  %21 = load i8*, i8** %20, align 8
+  %21 = load atomic i8*, i8** %20 unordered, align 8
   %22 = icmp eq i8* %18, %21
   br label %epilogue
 
@@ -6920,7 +6993,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %entry
   %5 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %6 = bitcast %struct.ObjHeader* %5 to i64*
-  %7 = load i64, i64* %6, align 8
+  %7 = load atomic i64, i64* %6 unordered, align 8
   %8 = load atomic i32, i32* @"state_global$kotlin.native.internal.NativePtr" acquire, align 4
   %9 = icmp eq i32 %8, 2
   br i1 %9, label %epilogue, label %label_init.i
@@ -6943,11 +7016,11 @@
   %3 = bitcast [4 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %3, i8 0, i32 32, i1 immarg false) #49
   %4 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 3
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %7 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %8 = bitcast %"class.kotlin::mm::ShadowStack"* %6 to i64*
-  %9 = load i64, i64* %8, align 8, !tbaa !7
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !7
   %10 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %11 = bitcast %struct.ObjHeader** %10 to i64*
   store i64 %9, i64* %11, align 8, !tbaa !9
@@ -6975,7 +7048,7 @@
   %23 = call fastcc %struct.ObjHeader* @Kotlin_String_plusImpl(%struct.ArrayHeader* getelementptr inbounds ({ %struct.ArrayHeader, [6 x i16] }, { %struct.ArrayHeader, [6 x i16] }* @132, i64 0, i32 0), %struct.ArrayHeader* %22, %struct.ObjHeader** %1)
   store %struct.ObjHeader* %23, %struct.ObjHeader** %1, align 8, !tbaa !3
   %24 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %25 = load i64, i64* %11, align 8, !tbaa !9
+  %25 = load atomic i64, i64* %11 unordered, align 8, !tbaa !9
   %26 = bitcast %"class.kotlin::mm::ShadowStack"* %24 to i64*
   store i64 %25, i64* %26, align 8, !tbaa !7
   ret %struct.ObjHeader* %23
@@ -7001,11 +7074,11 @@
   %objHeader = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %11, i64 0, i32 0
   %typeInfoOrMeta_ = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %11, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_, align 8
-  %14 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %14 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %15 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %14, i64 0, i32 1, i32 5
   %16 = bitcast [10 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %17 = bitcast %"class.kotlin::mm::ShadowStack"* %15 to i64*
-  %18 = load i64, i64* %17, align 8, !tbaa !7
+  %18 = load atomic i64, i64* %17 unordered, align 8, !tbaa !7
   %19 = getelementptr inbounds [10 x %struct.ObjHeader*], [10 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %20 = bitcast %struct.ObjHeader** %19 to i64*
   store i64 %18, i64* %20, align 8, !tbaa !9
@@ -7028,10 +7101,10 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %28, %call_success
   %29 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %30 = bitcast %struct.ObjHeader* %29 to i8**
-  %31 = load i8*, i8** %30, align 8
+  %31 = load atomic i8*, i8** %30 unordered, align 8
   %32 = getelementptr inbounds i8, i8* %31, i64 80
   %33 = bitcast i8* %32 to %struct.ObjHeader**
-  %34 = load %struct.ObjHeader*, %struct.ObjHeader** %33, align 8, !tbaa !68
+  %34 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %33 unordered, align 8, !tbaa !67
   store %struct.ObjHeader* %34, %struct.ObjHeader** %5, align 8, !tbaa !3
   %35 = icmp eq %struct.ObjHeader* %34, null
   br i1 %35, label %epilogue, label %call_success1
@@ -7040,7 +7113,7 @@
   %36 = getelementptr inbounds [10 x %struct.ObjHeader*], [10 x %struct.ObjHeader*]* %3, i64 0, i64 4
   %37 = getelementptr inbounds i8, i8* %31, i64 72
   %38 = bitcast i8* %37 to %struct.ObjHeader**
-  %39 = load %struct.ObjHeader*, %struct.ObjHeader** %38, align 8, !tbaa !69
+  %39 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %38 unordered, align 8, !tbaa !68
   store %struct.ObjHeader* %39, %struct.ObjHeader** %36, align 8, !tbaa !3
   %40 = icmp eq %struct.ObjHeader* %39, null
   br i1 %40, label %epilogue, label %returnable_block_exit
@@ -7048,7 +7121,7 @@
 returnable_block_exit:                            ; preds = %call_success1
   %41 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %39, i64 1
   %42 = bitcast %struct.ObjHeader* %41 to i32*
-  %43 = load i32, i32* %42, align 8, !tbaa !18
+  %43 = load atomic i32, i32* %42 unordered, align 8, !tbaa !18
   %44 = icmp eq i32 %43, 0
   %45 = bitcast [4 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %45)
@@ -7057,7 +7130,7 @@
   %46 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %14, i64 0, i32 1, i32 5
   %47 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %48 = bitcast %"class.kotlin::mm::ShadowStack"* %46 to i64*
-  %49 = load i64, i64* %48, align 8, !tbaa !7
+  %49 = load atomic i64, i64* %48 unordered, align 8, !tbaa !7
   %50 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %51 = bitcast %struct.ObjHeader** %50 to i64*
   store i64 %49, i64* %51, align 8, !tbaa !9
@@ -7068,7 +7141,7 @@
   store i32 0, i32* %54, align 8, !tbaa !12
   %55 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %47, i64 0, i32 3
   store i32 4, i32* %55, align 4, !tbaa !13
-  %56 = load i8, i8* bitcast (i1* @BOOLEAN_RANGE_TO to i8*), align 1, !tbaa !70, !range !72
+  %56 = load atomic i8, i8* bitcast (i1* @BOOLEAN_RANGE_TO to i8*) unordered, align 1, !tbaa !69, !range !70
   %57 = icmp ne i8 %56, 0
   %58 = xor i1 %44, true
   %59 = or i1 %57, %58
@@ -7084,7 +7157,7 @@
   %62 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %63 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %14, i64 0, i32 1, i32 6
   %64 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %63 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %65 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %64, align 8, !tbaa !3
+  %65 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %64 unordered, align 8, !tbaa !3
   %66 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %65, i64 0, i32 2, i32 1
   %67 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %66, i64 24) #37
   %68 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %67, i64 1
@@ -7105,7 +7178,7 @@
   %76 = phi %struct.ObjHeader* [ %61, %when_case.i ], [ %70, %when_exit.i ]
   store %struct.ObjHeader* %76, %struct.ObjHeader** %6, align 8, !tbaa !3
   %77 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %14, i64 0, i32 1, i32 5
-  %78 = load i64, i64* %51, align 8, !tbaa !9
+  %78 = load atomic i64, i64* %51 unordered, align 8, !tbaa !9
   %79 = bitcast %"class.kotlin::mm::ShadowStack"* %77 to i64*
   store i64 %78, i64* %79, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %45)
@@ -7131,7 +7204,7 @@
   %88 = phi %struct.ObjHeader* [ null, %Kotlin_mm_safePointFunctionPrologue.exit ], [ %87, %call_success20 ], [ %34, %when_exit6 ], [ %34, %call_success1 ], [ %34, %call_success8 ]
   store %struct.ObjHeader* %88, %struct.ObjHeader** %1, align 8, !tbaa !3
   %89 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %14, i64 0, i32 1, i32 5
-  %90 = load i64, i64* %20, align 8, !tbaa !9
+  %90 = load atomic i64, i64* %20 unordered, align 8, !tbaa !9
   %91 = bitcast %"class.kotlin::mm::ShadowStack"* %89 to i64*
   store i64 %90, i64* %91, align 8, !tbaa !7
   ret %struct.ObjHeader* %88
@@ -7145,11 +7218,11 @@
   %1 = bitcast [4 x %struct.ObjHeader*]* %0 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %1, i8 0, i32 32, i1 immarg false) #49
   %2 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 3
-  %3 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %3 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %4 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 5
   %5 = bitcast [4 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
   %6 = bitcast %"class.kotlin::mm::ShadowStack"* %4 to i64*
-  %7 = load i64, i64* %6, align 8, !tbaa !7
+  %7 = load atomic i64, i64* %6 unordered, align 8, !tbaa !7
   %8 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 1
   %9 = bitcast %struct.ObjHeader** %8 to i64*
   store i64 %7, i64* %9, align 8, !tbaa !9
@@ -7172,7 +7245,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %17, %epilogue
   %18 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 6
   %19 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %18 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %20 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %19, align 8, !tbaa !3
+  %20 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %19 unordered, align 8, !tbaa !3
   %21 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %20, i64 0, i32 2, i32 1
   %22 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %21, i64 24) #37
   %23 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %22, i64 1
@@ -7184,15 +7257,16 @@
   %27 = bitcast %struct.ObjHeader** %2 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %24, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %27, align 8, !tbaa !3
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %24, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** bitcast (%struct.ObjHeader** @"kvar:kotlin.native.internal.NativePtr.$companion#internal" to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**), align 8, !tbaa !3
-  %28 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %22, i64 3
-  %29 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %28 to i8**
-  store i8* null, i8** %29, align 8
-  %30 = load %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.internal.NativePtr.$companion#internal", align 8
-  call fastcc void @InitAndRegisterGlobal(%struct.ObjHeader** nonnull @"kvar:kotlin.native.internal.NativePtr.$companion#internal", %struct.ObjHeader* %30) #37
-  %31 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 5
-  %32 = load i64, i64* %9, align 8, !tbaa !9
-  %33 = bitcast %"class.kotlin::mm::ShadowStack"* %31 to i64*
-  store i64 %32, i64* %33, align 8, !tbaa !7
+  %28 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.internal.NativePtr.$companion#internal" unordered, align 8
+  %29 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %28, i64 1
+  %30 = bitcast %struct.ObjHeader* %29 to i8**
+  store i8* null, i8** %30, align 8
+  %31 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.internal.NativePtr.$companion#internal" unordered, align 8
+  call fastcc void @InitAndRegisterGlobal(%struct.ObjHeader** nonnull @"kvar:kotlin.native.internal.NativePtr.$companion#internal", %struct.ObjHeader* %31) #37
+  %32 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 5
+  %33 = load atomic i64, i64* %9 unordered, align 8, !tbaa !9
+  %34 = bitcast %"class.kotlin::mm::ShadowStack"* %32 to i64*
+  store i64 %33, i64* %34, align 8, !tbaa !7
   ret void
 }
 
@@ -7216,11 +7290,11 @@
   %objHeader = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %12, i64 0, i32 0
   %typeInfoOrMeta_ = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %12, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_, align 8
-  %15 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %15 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %16 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %15, i64 0, i32 1, i32 5
   %17 = bitcast [11 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %18 = bitcast %"class.kotlin::mm::ShadowStack"* %16 to i64*
-  %19 = load i64, i64* %18, align 8, !tbaa !7
+  %19 = load atomic i64, i64* %18 unordered, align 8, !tbaa !7
   %20 = getelementptr inbounds [11 x %struct.ObjHeader*], [11 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %21 = bitcast %struct.ObjHeader** %20 to i64*
   store i64 %19, i64* %21, align 8, !tbaa !9
@@ -7251,15 +7325,15 @@
   %35 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %34, i64 0, i32 0
   %36 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %35 monotonic, align 8
   %37 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %36, i64 0, i32 9
-  %38 = load i32, i32* %37, align 4
+  %38 = load atomic i32, i32* %37 unordered, align 4
   %39 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %36, i64 0, i32 10
-  %40 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %39, align 8
+  %40 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %39 unordered, align 8
   %41 = and i32 %38, 168
   %42 = zext i32 %41 to i64
   %43 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %40, i64 %42, i32 2
   %44 = bitcast i8*** %43 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)***
-  %45 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %44, align 8
-  %46 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %45, align 8
+  %45 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %44 unordered, align 8
+  %46 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %45 unordered, align 8
   %47 = call %struct.ObjHeader* %46(%struct.ObjHeader* %1, %struct.ObjHeader** nonnull %6)
   %48 = icmp eq %struct.ObjHeader* %47, %0
   br i1 %48, label %call_success5, label %when_next.i
@@ -7278,7 +7352,7 @@
   %56 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %55 monotonic, align 8
   %57 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %56, i64 1, i32 2
   %58 = bitcast i32* %57 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %59 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %58, align 8
+  %59 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %58 unordered, align 8
   %60 = call %struct.ObjHeader* %59(%struct.ObjHeader* nonnull %47, %struct.ObjHeader** nonnull %7)
   br label %call_success5
 
@@ -7294,16 +7368,16 @@
   %68 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %67, i64 0, i32 0
   %69 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %68 monotonic, align 8
   %70 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %69, i64 0, i32 9
-  %71 = load i32, i32* %70, align 4
+  %71 = load atomic i32, i32* %70 unordered, align 4
   %72 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %69, i64 0, i32 10
-  %73 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %72, align 8
+  %73 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %72 unordered, align 8
   %74 = and i32 %71, 168
   %75 = zext i32 %74 to i64
   %76 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %73, i64 %75, i32 2
-  %77 = load i8**, i8*** %76, align 8
+  %77 = load atomic i8**, i8*** %76 unordered, align 8
   %78 = getelementptr i8*, i8** %77, i64 1
   %79 = bitcast i8** %78 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %80 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %79, align 8
+  %80 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %79 unordered, align 8
   %81 = call %struct.ObjHeader* %80(%struct.ObjHeader* %1, %struct.ObjHeader** nonnull %10)
   %82 = icmp eq %struct.ObjHeader* %81, %0
   br i1 %82, label %epilogue, label %when_next.i10
@@ -7322,7 +7396,7 @@
   %90 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %89 monotonic, align 8
   %91 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %90, i64 1, i32 2
   %92 = bitcast i32* %91 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %93 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %92, align 8
+  %93 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %92 unordered, align 8
   %94 = call %struct.ObjHeader* %93(%struct.ObjHeader* nonnull %81, %struct.ObjHeader** nonnull %11)
   br label %epilogue
 
@@ -7334,7 +7408,7 @@
   %98 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#toString(){}kotlin.String"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader** %2)
   store %struct.ObjHeader* %98, %struct.ObjHeader** %2, align 8, !tbaa !3
   %99 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %15, i64 0, i32 1, i32 5
-  %100 = load i64, i64* %21, align 8, !tbaa !9
+  %100 = load atomic i64, i64* %21 unordered, align 8, !tbaa !9
   %101 = bitcast %"class.kotlin::mm::ShadowStack"* %99 to i64*
   store i64 %100, i64* %101, align 8, !tbaa !7
   ret %struct.ObjHeader* %98
@@ -7354,7 +7428,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %6, %epilogue
   %7 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %8 = bitcast %struct.ObjHeader* %7 to %struct.ObjHeader**
-  %9 = load %struct.ObjHeader*, %struct.ObjHeader** %8, align 8
+  %9 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %8 unordered, align 8
   %10 = tail call fastcc %struct.ObjHeader* @"kfun:kotlin.native.internal.NSDictionaryAsKMap.toString$lambda$0#internal"(%struct.ObjHeader* %9, %struct.ObjHeader* %1, %struct.ObjHeader** %2)
   store %struct.ObjHeader* %10, %struct.ObjHeader** %2, align 8, !tbaa !3
   ret %struct.ObjHeader* %10
@@ -7368,11 +7442,11 @@
   %1 = bitcast [4 x %struct.ObjHeader*]* %0 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %1, i8 0, i32 32, i1 immarg false) #49
   %2 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 3
-  %3 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %3 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %4 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 5
   %5 = bitcast [4 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
   %6 = bitcast %"class.kotlin::mm::ShadowStack"* %4 to i64*
-  %7 = load i64, i64* %6, align 8, !tbaa !7
+  %7 = load atomic i64, i64* %6 unordered, align 8, !tbaa !7
   %8 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 1
   %9 = bitcast %struct.ObjHeader** %8 to i64*
   store i64 %7, i64* %9, align 8, !tbaa !9
@@ -7393,10 +7467,10 @@
   br label %Kotlin_mm_safePointFunctionPrologue.exit
 
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %17, %entry
-  %18 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %18 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %19 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %18, i64 0, i32 1, i32 6
   %20 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %19 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %21 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %20, align 8, !tbaa !3
+  %21 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %20 unordered, align 8, !tbaa !3
   %22 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %21, i64 0, i32 2, i32 1
   %23 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %22, i64 56) #37
   %24 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %23, i64 1
@@ -7421,9 +7495,9 @@
 cleanup_landingpad:                               ; preds = %call_success, %Kotlin_mm_safePointFunctionPrologue.exit
   %30 = landingpad { i8*, i32 }
           cleanup
-  %31 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %31 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %32 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %31, i64 0, i32 1, i32 5
-  %33 = load i64, i64* %9, align 8, !tbaa !9
+  %33 = load atomic i64, i64* %9 unordered, align 8, !tbaa !9
   %34 = bitcast %"class.kotlin::mm::ShadowStack"* %32 to i64*
   store i64 %33, i64* %34, align 8, !tbaa !7
   resume { i8*, i32 } %30
@@ -7437,11 +7511,11 @@
   %1 = bitcast [4 x %struct.ObjHeader*]* %0 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %1, i8 0, i32 32, i1 immarg false) #49
   %2 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 3
-  %3 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %3 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %4 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 5
   %5 = bitcast [4 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
   %6 = bitcast %"class.kotlin::mm::ShadowStack"* %4 to i64*
-  %7 = load i64, i64* %6, align 8, !tbaa !7
+  %7 = load atomic i64, i64* %6 unordered, align 8, !tbaa !7
   %8 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 1
   %9 = bitcast %struct.ObjHeader** %8 to i64*
   store i64 %7, i64* %9, align 8, !tbaa !9
@@ -7462,10 +7536,10 @@
   br label %Kotlin_mm_safePointFunctionPrologue.exit
 
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %17, %entry
-  %18 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %18 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %19 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %18, i64 0, i32 1, i32 6
   %20 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %19 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %21 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %20, align 8, !tbaa !3
+  %21 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %20 unordered, align 8, !tbaa !3
   %22 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %21, i64 0, i32 2, i32 1
   %23 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %22, i64 56) #37
   %24 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %23, i64 1
@@ -7490,9 +7564,9 @@
 cleanup_landingpad:                               ; preds = %call_success, %Kotlin_mm_safePointFunctionPrologue.exit
   %30 = landingpad { i8*, i32 }
           cleanup
-  %31 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %31 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %32 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %31, i64 0, i32 1, i32 5
-  %33 = load i64, i64* %9, align 8, !tbaa !9
+  %33 = load atomic i64, i64* %9 unordered, align 8, !tbaa !9
   %34 = bitcast %"class.kotlin::mm::ShadowStack"* %32 to i64*
   store i64 %33, i64* %34, align 8, !tbaa !7
   resume { i8*, i32 } %30
@@ -7534,11 +7608,11 @@
   %objHeader5 = getelementptr inbounds %"kclassbody:kotlin.native.internal.KClassImpl#internal", %"kclassbody:kotlin.native.internal.KClassImpl#internal"* %18, i64 0, i32 0
   %typeInfoOrMeta_6 = getelementptr inbounds %"kclassbody:kotlin.native.internal.KClassImpl#internal", %"kclassbody:kotlin.native.internal.KClassImpl#internal"* %18, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.native.internal.KClassImpl#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_6, align 8
-  %21 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %21 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %22 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %21, i64 0, i32 1, i32 5
   %23 = bitcast [13 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %24 = bitcast %"class.kotlin::mm::ShadowStack"* %22 to i64*
-  %25 = load i64, i64* %24, align 8, !tbaa !7
+  %25 = load atomic i64, i64* %24 unordered, align 8, !tbaa !7
   %26 = getelementptr inbounds [13 x %struct.ObjHeader*], [13 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %27 = bitcast %struct.ObjHeader** %26 to i64*
   store i64 %25, i64* %27, align 8, !tbaa !9
@@ -7604,10 +7678,10 @@
           to label %call_success13 unwind label %cleanup_landingpad
 
 call_success13:                                   ; preds = %call_success12
-  %54 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %54 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %55 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %54, i64 0, i32 1, i32 6
   %56 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %55 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %57 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %56, align 8, !tbaa !3
+  %57 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %56 unordered, align 8, !tbaa !3
   %58 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %57, i64 0, i32 2, i32 1
   %59 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %58, i64 56) #37
   %60 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %59, i64 1
@@ -7632,9 +7706,9 @@
 cleanup_landingpad:                               ; preds = %call_success14, %call_success13, %call_success12, %call_success11, %call_success10, %call_success9, %call_success8, %call_success7, %Kotlin_mm_safePointFunctionPrologue.exit
   %66 = landingpad { i8*, i32 }
           cleanup
-  %67 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %67 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %68 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %67, i64 0, i32 1, i32 5
-  %69 = load i64, i64* %27, align 8, !tbaa !9
+  %69 = load atomic i64, i64* %27 unordered, align 8, !tbaa !9
   %70 = bitcast %"class.kotlin::mm::ShadowStack"* %68 to i64*
   store i64 %69, i64* %70, align 8, !tbaa !7
   resume { i8*, i32 } %66
@@ -7649,11 +7723,11 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(48) %2, i8 0, i32 48, i1 immarg false) #49
   %3 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %1, i64 0, i64 3
   %4 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %1, i64 0, i64 5
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %7 = bitcast [6 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
   %8 = bitcast %"class.kotlin::mm::ShadowStack"* %6 to i64*
-  %9 = load i64, i64* %8, align 8, !tbaa !7
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !7
   %10 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %1, i64 0, i64 1
   %11 = bitcast %struct.ObjHeader** %10 to i64*
   store i64 %9, i64* %11, align 8, !tbaa !9
@@ -7682,15 +7756,15 @@
   %25 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %24, i64 0, i32 0
   %26 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %25 monotonic, align 8
   %27 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %26, i64 0, i32 9
-  %28 = load i32, i32* %27, align 4
+  %28 = load atomic i32, i32* %27 unordered, align 4
   %29 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %26, i64 0, i32 10
-  %30 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %29, align 8
+  %30 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %29 unordered, align 8
   %31 = and i32 %28, 27
   %32 = zext i32 %31 to i64
   %33 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %30, i64 %32, i32 2
   %34 = bitcast i8*** %33 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)***
-  %35 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %34, align 8
-  %36 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %35, align 8
+  %35 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %34 unordered, align 8
+  %36 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %35 unordered, align 8
   %37 = invoke %struct.ObjHeader* %36(%struct.ObjHeader* %0, %struct.ObjHeader** nonnull %3)
           to label %call_success unwind label %cleanup_landingpad
 
@@ -7703,10 +7777,10 @@
           to label %call_success1 unwind label %cleanup_landingpad
 
 call_success1:                                    ; preds = %call_success
-  %42 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %42 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %43 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %42, i64 0, i32 1, i32 6
   %44 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %43 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %45 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %44, align 8, !tbaa !3
+  %45 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %44 unordered, align 8, !tbaa !3
   %46 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %45, i64 0, i32 2, i32 1
   %47 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %46, i64 56) #37
   %48 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %47, i64 1
@@ -7731,9 +7805,9 @@
 cleanup_landingpad:                               ; preds = %call_success2, %call_success1, %call_success, %Kotlin_mm_safePointFunctionPrologue.exit
   %54 = landingpad { i8*, i32 }
           cleanup
-  %55 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %55 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %56 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %55, i64 0, i32 1, i32 5
-  %57 = load i64, i64* %11, align 8, !tbaa !9
+  %57 = load atomic i64, i64* %11 unordered, align 8, !tbaa !9
   %58 = bitcast %"class.kotlin::mm::ShadowStack"* %56 to i64*
   store i64 %57, i64* %58, align 8, !tbaa !7
   resume { i8*, i32 } %54
@@ -7747,11 +7821,11 @@
   %1 = bitcast [4 x %struct.ObjHeader*]* %0 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %1, i8 0, i32 32, i1 immarg false) #49
   %2 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 3
-  %3 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %3 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %4 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 5
   %5 = bitcast [4 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
   %6 = bitcast %"class.kotlin::mm::ShadowStack"* %4 to i64*
-  %7 = load i64, i64* %6, align 8, !tbaa !7
+  %7 = load atomic i64, i64* %6 unordered, align 8, !tbaa !7
   %8 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 1
   %9 = bitcast %struct.ObjHeader** %8 to i64*
   store i64 %7, i64* %9, align 8, !tbaa !9
@@ -7772,10 +7846,10 @@
   br label %Kotlin_mm_safePointFunctionPrologue.exit
 
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %17, %entry
-  %18 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %18 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %19 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %18, i64 0, i32 1, i32 6
   %20 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %19 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %21 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %20, align 8, !tbaa !3
+  %21 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %20 unordered, align 8, !tbaa !3
   %22 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %21, i64 0, i32 2, i32 1
   %23 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %22, i64 56) #37
   %24 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %23, i64 1
@@ -7800,9 +7874,9 @@
 cleanup_landingpad:                               ; preds = %call_success, %Kotlin_mm_safePointFunctionPrologue.exit
   %30 = landingpad { i8*, i32 }
           cleanup
-  %31 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %31 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %32 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %31, i64 0, i32 1, i32 5
-  %33 = load i64, i64* %9, align 8, !tbaa !9
+  %33 = load atomic i64, i64* %9 unordered, align 8, !tbaa !9
   %34 = bitcast %"class.kotlin::mm::ShadowStack"* %32 to i64*
   store i64 %33, i64* %34, align 8, !tbaa !7
   resume { i8*, i32 } %30
@@ -7815,11 +7889,11 @@
   %1 = bitcast [4 x %struct.ObjHeader*]* %0 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %1, i8 0, i32 32, i1 immarg false) #49
   %2 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 3
-  %3 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %3 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %4 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 5
   %5 = bitcast [4 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
   %6 = bitcast %"class.kotlin::mm::ShadowStack"* %4 to i64*
-  %7 = load i64, i64* %6, align 8, !tbaa !7
+  %7 = load atomic i64, i64* %6 unordered, align 8, !tbaa !7
   %8 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 1
   %9 = bitcast %struct.ObjHeader** %8 to i64*
   store i64 %7, i64* %9, align 8, !tbaa !9
@@ -7840,10 +7914,10 @@
   br label %Kotlin_mm_safePointFunctionPrologue.exit
 
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %17, %entry
-  %18 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %18 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %19 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %18, i64 0, i32 1, i32 6
   %20 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %19 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %21 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %20, align 8, !tbaa !3
+  %21 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %20 unordered, align 8, !tbaa !3
   %22 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %21, i64 0, i32 2, i32 1
   %23 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %22, i64 56) #37
   %24 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %23, i64 1
@@ -7868,9 +7942,9 @@
 cleanup_landingpad:                               ; preds = %call_success, %Kotlin_mm_safePointFunctionPrologue.exit
   %30 = landingpad { i8*, i32 }
           cleanup
-  %31 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %31 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %32 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %31, i64 0, i32 1, i32 5
-  %33 = load i64, i64* %9, align 8, !tbaa !9
+  %33 = load atomic i64, i64* %9 unordered, align 8, !tbaa !9
   %34 = bitcast %"class.kotlin::mm::ShadowStack"* %32 to i64*
   store i64 %33, i64* %34, align 8, !tbaa !7
   resume { i8*, i32 } %30
@@ -7882,11 +7956,11 @@
   %.sub = getelementptr inbounds [3 x %struct.ObjHeader*], [3 x %struct.ObjHeader*]* %1, i64 0, i64 0
   %2 = bitcast [3 x %struct.ObjHeader*]* %1 to i64*
   store i64 0, i64* %2, align 8
-  %3 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %3 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %4 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 5
   %5 = bitcast [3 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
   %6 = bitcast %"class.kotlin::mm::ShadowStack"* %4 to i64*
-  %7 = load i64, i64* %6, align 8, !tbaa !7
+  %7 = load atomic i64, i64* %6 unordered, align 8, !tbaa !7
   %8 = getelementptr inbounds [3 x %struct.ObjHeader*], [3 x %struct.ObjHeader*]* %1, i64 0, i64 1
   %9 = bitcast %struct.ObjHeader** %8 to i64*
   store i64 %7, i64* %9, align 8, !tbaa !9
@@ -7915,9 +7989,9 @@
           to label %epilogue unwind label %cleanup_landingpad
 
 epilogue:                                         ; preds = %call_success
-  %18 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %18 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %19 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %18, i64 0, i32 1, i32 5
-  %20 = load i64, i64* %9, align 8, !tbaa !9
+  %20 = load atomic i64, i64* %9 unordered, align 8, !tbaa !9
   %21 = bitcast %"class.kotlin::mm::ShadowStack"* %19 to i64*
   store i64 %20, i64* %21, align 8, !tbaa !7
   ret void
@@ -7925,9 +7999,9 @@
 cleanup_landingpad:                               ; preds = %call_success, %Kotlin_mm_safePointFunctionPrologue.exit
   %22 = landingpad { i8*, i32 }
           cleanup
-  %23 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %23 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %24 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %23, i64 0, i32 1, i32 5
-  %25 = load i64, i64* %9, align 8, !tbaa !9
+  %25 = load atomic i64, i64* %9 unordered, align 8, !tbaa !9
   %26 = bitcast %"class.kotlin::mm::ShadowStack"* %24 to i64*
   store i64 %25, i64* %26, align 8, !tbaa !7
   resume { i8*, i32 } %22
@@ -7943,11 +8017,11 @@
   %4 = bitcast [4 x %struct.ObjHeader*]* %3 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %4, i8 0, i32 32, i1 immarg false) #49
   %5 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 3
-  %6 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %7 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
   %8 = bitcast [4 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %9 = bitcast %"class.kotlin::mm::ShadowStack"* %7 to i64*
-  %10 = load i64, i64* %9, align 8, !tbaa !7
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa !7
   %11 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %12 = bitcast %struct.ObjHeader** %11 to i64*
   store i64 %10, i64* %12, align 8, !tbaa !9
@@ -7970,7 +8044,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %20, %entry
   %21 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 6
   %22 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %21 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %23 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %22, align 8, !tbaa !3
+  %23 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %22 unordered, align 8, !tbaa !3
   %24 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %23, i64 0, i32 2, i32 1
   %25 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %24, i64 24) #37
   %26 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %25, i64 1
@@ -7982,259 +8056,261 @@
   %30 = bitcast %struct.ObjHeader** %5 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %27, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %30, align 8, !tbaa !3
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %27, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** bitcast (%struct.ObjHeader** @"kvar:kotlin.native.internal.UnhandledExceptionHookHolder.$instance#internal" to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**), align 8, !tbaa !3
-  %31 = bitcast [8 x %struct.ObjHeader*]* %2 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %31)
+  %31 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.internal.UnhandledExceptionHookHolder.$instance#internal" unordered, align 8
+  %32 = bitcast [8 x %struct.ObjHeader*]* %2 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %32)
   %.sub.i = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 0
-  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(64) %31, i8 0, i32 64, i1 immarg false) #49
-  %32 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 3
-  %33 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 4
-  %34 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 5
-  %35 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 6
-  %36 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 7
-  %37 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %38 = bitcast [8 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
-  %39 = bitcast %"class.kotlin::mm::ShadowStack"* %37 to i64*
-  %40 = load i64, i64* %39, align 8, !tbaa !7
-  %41 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 1
-  %42 = bitcast %struct.ObjHeader** %41 to i64*
-  store i64 %40, i64* %42, align 8, !tbaa !9
-  %43 = bitcast %"class.kotlin::mm::ShadowStack"* %37 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %43, align 8, !tbaa !7
-  %44 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 2
-  %45 = bitcast %struct.ObjHeader** %44 to i32*
-  store i32 0, i32* %45, align 8, !tbaa !12
-  %46 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %38, i64 0, i32 3
-  store i32 8, i32* %46, align 4, !tbaa !13
-  %47 = bitcast [4 x %struct.ObjHeader*]* %1 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %47)
+  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(64) %32, i8 0, i32 64, i1 immarg false) #49
+  %33 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 3
+  %34 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 4
+  %35 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 5
+  %36 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 6
+  %37 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 7
+  %38 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
+  %39 = bitcast [8 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
+  %40 = bitcast %"class.kotlin::mm::ShadowStack"* %38 to i64*
+  %41 = load atomic i64, i64* %40 unordered, align 8, !tbaa !7
+  %42 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 1
+  %43 = bitcast %struct.ObjHeader** %42 to i64*
+  store i64 %41, i64* %43, align 8, !tbaa !9
+  %44 = bitcast %"class.kotlin::mm::ShadowStack"* %38 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %44, align 8, !tbaa !7
+  %45 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 2
+  %46 = bitcast %struct.ObjHeader** %45 to i32*
+  store i32 0, i32* %46, align 8, !tbaa !12
+  %47 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %39, i64 0, i32 3
+  store i32 8, i32* %47, align 4, !tbaa !13
+  %48 = bitcast [4 x %struct.ObjHeader*]* %1 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %48)
   %.sub.i.i = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 0
-  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %47, i8 0, i32 32, i1 immarg false) #49
-  %48 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 3
-  %49 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %50 = bitcast [4 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
-  %51 = bitcast %"class.kotlin::mm::ShadowStack"* %49 to i64*
-  %52 = load i64, i64* %51, align 8, !tbaa !7
-  %53 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 1
-  %54 = bitcast %struct.ObjHeader** %53 to i64*
-  store i64 %52, i64* %54, align 8, !tbaa !9
-  %55 = bitcast %"class.kotlin::mm::ShadowStack"* %49 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i.i, %struct.ObjHeader*** %55, align 8, !tbaa !7
-  %56 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 2
-  %57 = bitcast %struct.ObjHeader** %56 to i32*
-  store i32 0, i32* %57, align 8, !tbaa !12
-  %58 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %50, i64 0, i32 3
-  store i32 4, i32* %58, align 4, !tbaa !13
-  %59 = load atomic i32, i32* @"state_global$kotlin.native.MemoryModel" acquire, align 4
-  %60 = icmp eq i32 %59, 2
-  br i1 %60, label %label_continue.i.i.i, label %label_init.i.i.i
+  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %48, i8 0, i32 32, i1 immarg false) #49
+  %49 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 3
+  %50 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
+  %51 = bitcast [4 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
+  %52 = bitcast %"class.kotlin::mm::ShadowStack"* %50 to i64*
+  %53 = load atomic i64, i64* %52 unordered, align 8, !tbaa !7
+  %54 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 1
+  %55 = bitcast %struct.ObjHeader** %54 to i64*
+  store i64 %53, i64* %55, align 8, !tbaa !9
+  %56 = bitcast %"class.kotlin::mm::ShadowStack"* %50 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i.i, %struct.ObjHeader*** %56, align 8, !tbaa !7
+  %57 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 2
+  %58 = bitcast %struct.ObjHeader** %57 to i32*
+  store i32 0, i32* %58, align 8, !tbaa !12
+  %59 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %51, i64 0, i32 3
+  store i32 4, i32* %59, align 4, !tbaa !13
+  %60 = load atomic i32, i32* @"state_global$kotlin.native.MemoryModel" acquire, align 4
+  %61 = icmp eq i32 %60, 2
+  br i1 %61, label %label_continue.i.i.i, label %label_init.i.i.i
 
 label_init.i.i.i:                                 ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
   call fastcc void @CallInitGlobalPossiblyLock(i32* nonnull @"state_global$kotlin.native.MemoryModel", void ()* nonnull @"kfun:kotlin.native.MemoryModel.$init_global#internal")
   br label %label_continue.i.i.i
 
 label_continue.i.i.i:                             ; preds = %label_init.i.i.i, %Kotlin_mm_safePointFunctionPrologue.exit
-  %61 = load %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.MemoryModel.$VALUES#internal", align 8
-  %62 = bitcast [5 x %struct.ObjHeader*]* %0 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %62)
+  %62 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.MemoryModel.$VALUES#internal" unordered, align 8
+  %63 = bitcast [5 x %struct.ObjHeader*]* %0 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %63)
   %.sub.i.i.i.i = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %0, i64 0, i64 0
-  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %62, i8 0, i32 40, i1 immarg false) #49
-  %63 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %0, i64 0, i64 4
-  %64 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %65 = bitcast [5 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
-  %66 = bitcast %"class.kotlin::mm::ShadowStack"* %64 to i64*
-  %67 = load i64, i64* %66, align 8, !tbaa !7
-  %68 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %0, i64 0, i64 1
-  %69 = bitcast %struct.ObjHeader** %68 to i64*
-  store i64 %67, i64* %69, align 8, !tbaa !9
-  %70 = bitcast %"class.kotlin::mm::ShadowStack"* %64 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i.i.i.i, %struct.ObjHeader*** %70, align 8, !tbaa !7
-  %71 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %0, i64 0, i64 2
-  %72 = bitcast %struct.ObjHeader** %71 to i32*
-  store i32 0, i32* %72, align 8, !tbaa !12
-  %73 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %65, i64 0, i32 3
-  store i32 5, i32* %73, align 4, !tbaa !13
-  %74 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %61, i64 1
-  %75 = bitcast %struct.ObjHeader* %74 to i32*
-  %76 = load i32, i32* %75, align 8, !tbaa !18
-  %77 = icmp slt i32 %76, 0
-  br i1 %77, label %78, label %AllocArrayInstance.exit.i.i.i.i
+  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %63, i8 0, i32 40, i1 immarg false) #49
+  %64 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %0, i64 0, i64 4
+  %65 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
+  %66 = bitcast [5 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
+  %67 = bitcast %"class.kotlin::mm::ShadowStack"* %65 to i64*
+  %68 = load atomic i64, i64* %67 unordered, align 8, !tbaa !7
+  %69 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %0, i64 0, i64 1
+  %70 = bitcast %struct.ObjHeader** %69 to i64*
+  store i64 %68, i64* %70, align 8, !tbaa !9
+  %71 = bitcast %"class.kotlin::mm::ShadowStack"* %65 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i.i.i.i, %struct.ObjHeader*** %71, align 8, !tbaa !7
+  %72 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %0, i64 0, i64 2
+  %73 = bitcast %struct.ObjHeader** %72 to i32*
+  store i32 0, i32* %73, align 8, !tbaa !12
+  %74 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %66, i64 0, i32 3
+  store i32 5, i32* %74, align 4, !tbaa !13
+  %75 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %62, i64 1
+  %76 = bitcast %struct.ObjHeader* %75 to i32*
+  %77 = load atomic i32, i32* %76 unordered, align 8, !tbaa !18
+  %78 = icmp slt i32 %77, 0
+  br i1 %78, label %79, label %AllocArrayInstance.exit.i.i.i.i
 
-78:                                               ; preds = %label_continue.i.i.i
+79:                                               ; preds = %label_continue.i.i.i
   call fastcc void @ThrowIllegalArgumentException() #50
   unreachable
 
 AllocArrayInstance.exit.i.i.i.i:                  ; preds = %label_continue.i.i.i
-  %79 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %0, i64 0, i64 3
-  %80 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 6
-  %81 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %80 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %82 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %81, align 8, !tbaa !3
-  %83 = zext i32 %76 to i64
-  %84 = shl nuw nsw i64 %83, 3
-  %85 = add nuw nsw i64 %84, 31
-  %86 = and i64 %85, 68719476728
-  %87 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %82, i64 0, i32 2, i32 1
-  %88 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %87, i64 %86) #37
-  %89 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %88, i64 1
-  %90 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %88, i64 2
-  %91 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %90 to %struct.TypeInfo**
-  %92 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %89 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %92, i8 0, i64 24, i1 false) #37
-  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [3 x i8*] }, { %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.Array#internal", i64 0, i32 0), %struct.TypeInfo** %91, align 8, !tbaa !16
-  %93 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %88, i64 3
-  %94 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %93 to i32*
-  store i32 %76, i32* %94, align 8, !tbaa !18
-  %95 = bitcast %struct.ObjHeader** %79 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %90, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %95, align 8, !tbaa !3
-  %96 = load i32, i32* %75, align 8, !tbaa !18
-  %97 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %61, i64 2
-  %98 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %90 to i64*
-  %99 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %88, i64 4
-  %100 = icmp sgt i32 %96, 0
-  %smax = select i1 %100, i32 %96, i32 0
+  %80 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %0, i64 0, i64 3
+  %81 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 6
+  %82 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %81 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
+  %83 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %82 unordered, align 8, !tbaa !3
+  %84 = zext i32 %77 to i64
+  %85 = shl nuw nsw i64 %84, 3
+  %86 = add nuw nsw i64 %85, 31
+  %87 = and i64 %86, 68719476728
+  %88 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %83, i64 0, i32 2, i32 1
+  %89 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %88, i64 %87) #37
+  %90 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %89, i64 1
+  %91 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %89, i64 2
+  %92 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %91 to %struct.TypeInfo**
+  %93 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %90 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %93, i8 0, i64 24, i1 false) #37
+  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [3 x i8*] }, { %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.Array#internal", i64 0, i32 0), %struct.TypeInfo** %92, align 8, !tbaa !16
+  %94 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %89, i64 3
+  %95 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %94 to i32*
+  store i32 %77, i32* %95, align 8, !tbaa !18
+  %96 = bitcast %struct.ObjHeader** %80 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %91, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %96, align 8, !tbaa !3
+  %97 = load atomic i32, i32* %76 unordered, align 8, !tbaa !18
+  %98 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %62, i64 2
+  %99 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %91 to i64*
+  %100 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %89, i64 4
+  %101 = icmp sgt i32 %97, 0
+  %smax = select i1 %101, i32 %97, i32 0
   br label %loop_check.i.i.i.i
 
 while_loop.i.i.i.i:                               ; preds = %loop_check.i.i.i.i
-  %101 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %102 = and i8 %101, 1
-  %103 = icmp eq i8 %102, 0
-  br i1 %103, label %Kotlin_mm_safePointWhileLoopBody.exit.i.i.i.i, label %104
+  %102 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %103 = and i8 %102, 1
+  %104 = icmp eq i8 %103, 0
+  br i1 %104, label %Kotlin_mm_safePointWhileLoopBody.exit.i.i.i.i, label %105
 
-104:                                              ; preds = %while_loop.i.i.i.i
+105:                                              ; preds = %while_loop.i.i.i.i
   call fastcc void @_ZN6kotlin2mm26SuspendIfRequestedSlowPathEv() #37
   br label %Kotlin_mm_safePointWhileLoopBody.exit.i.i.i.i
 
-Kotlin_mm_safePointWhileLoopBody.exit.i.i.i.i:    ; preds = %104, %while_loop.i.i.i.i
-  %105 = sext i32 %inductionVariable.0.i.i.i.i to i64
-  %106 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %97, i64 %105
-  %107 = bitcast %struct.ObjHeader* %106 to %struct.ObjHeader**
-  %108 = load %struct.ObjHeader*, %struct.ObjHeader** %107, align 8, !tbaa !3
-  store %struct.ObjHeader* %108, %struct.ObjHeader** %63, align 8, !tbaa !3
-  %109 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %108, i64 2
-  %110 = bitcast %struct.ObjHeader* %109 to i32*
-  %111 = load i32, i32* %110, align 4
-  %112 = load i32, i32* %94, align 8, !tbaa !18
-  %113 = icmp ugt i32 %112, %111
-  br i1 %113, label %Kotlin_Array_set.exit.i.i.i.i, label %114
+Kotlin_mm_safePointWhileLoopBody.exit.i.i.i.i:    ; preds = %105, %while_loop.i.i.i.i
+  %106 = sext i32 %inductionVariable.0.i.i.i.i to i64
+  %107 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 %106
+  %108 = bitcast %struct.ObjHeader* %107 to %struct.ObjHeader**
+  %109 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %108 unordered, align 8, !tbaa !3
+  store %struct.ObjHeader* %109, %struct.ObjHeader** %64, align 8, !tbaa !3
+  %110 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %109, i64 2
+  %111 = bitcast %struct.ObjHeader* %110 to i32*
+  %112 = load atomic i32, i32* %111 unordered, align 4
+  %113 = load atomic i32, i32* %95 unordered, align 8, !tbaa !18
+  %114 = icmp ugt i32 %113, %112
+  br i1 %114, label %Kotlin_Array_set.exit.i.i.i.i, label %115
 
-114:                                              ; preds = %Kotlin_mm_safePointWhileLoopBody.exit.i.i.i.i
+115:                                              ; preds = %Kotlin_mm_safePointWhileLoopBody.exit.i.i.i.i
   call fastcc void @ThrowArrayIndexOutOfBoundsException() #50
   unreachable
 
 Kotlin_Array_set.exit.i.i.i.i:                    ; preds = %Kotlin_mm_safePointWhileLoopBody.exit.i.i.i.i
-  %115 = load atomic volatile i64, i64* %98 monotonic, align 8
-  %116 = sext i32 %111 to i64
-  %117 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %99, i64 %116
-  %118 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %117 to %struct.ObjHeader**
-  store %struct.ObjHeader* %108, %struct.ObjHeader** %118, align 8, !tbaa !3
-  %119 = add nuw i32 %inductionVariable.0.i.i.i.i, 1
+  %116 = load atomic volatile i64, i64* %99 monotonic, align 8
+  %117 = sext i32 %112 to i64
+  %118 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %100, i64 %117
+  %119 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %118 to %struct.ObjHeader**
+  store %struct.ObjHeader* %109, %struct.ObjHeader** %119, align 8, !tbaa !3
+  %120 = add nuw i32 %inductionVariable.0.i.i.i.i, 1
   br label %loop_check.i.i.i.i
 
 loop_check.i.i.i.i:                               ; preds = %Kotlin_Array_set.exit.i.i.i.i, %AllocArrayInstance.exit.i.i.i.i
-  %inductionVariable.0.i.i.i.i = phi i32 [ 0, %AllocArrayInstance.exit.i.i.i.i ], [ %119, %Kotlin_Array_set.exit.i.i.i.i ]
+  %inductionVariable.0.i.i.i.i = phi i32 [ 0, %AllocArrayInstance.exit.i.i.i.i ], [ %120, %Kotlin_Array_set.exit.i.i.i.i ]
   %exitcond.not = icmp eq i32 %inductionVariable.0.i.i.i.i, %smax
   br i1 %exitcond.not, label %loop_exit.i.i.i.i, label %while_loop.i.i.i.i
 
 loop_exit.i.i.i.i:                                ; preds = %loop_check.i.i.i.i
-  %120 = load atomic volatile i64, i64* %98 monotonic, align 8
-  %121 = and i64 %120, -4
-  %122 = inttoptr i64 %121 to i64*
-  %123 = load atomic volatile i64, i64* %122 monotonic, align 8
-  %124 = inttoptr i64 %123 to %struct.TypeInfo*
-  %125 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %124, i64 0, i32 14
-  %126 = load i32, i32* %125, align 4, !tbaa !19
-  %127 = icmp eq i32 %126, 72
-  br i1 %127, label %"kfun:kotlin.native.MemoryModel#values#static(){}kotlin.Array<kotlin.native.MemoryModel>.exit.i.i", label %label_6.i.i.i.i
+  %121 = load atomic volatile i64, i64* %99 monotonic, align 8
+  %122 = and i64 %121, -4
+  %123 = inttoptr i64 %122 to i64*
+  %124 = load atomic volatile i64, i64* %123 monotonic, align 8
+  %125 = inttoptr i64 %124 to %struct.TypeInfo*
+  %126 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %125, i64 0, i32 14
+  %127 = load atomic i32, i32* %126 unordered, align 4, !tbaa !19
+  %128 = icmp eq i32 %127, 72
+  br i1 %128, label %"kfun:kotlin.native.MemoryModel#values#static(){}kotlin.Array<kotlin.native.MemoryModel>.exit.i.i", label %label_6.i.i.i.i
 
 label_6.i.i.i.i:                                  ; preds = %loop_exit.i.i.i.i
-  %128 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %90 to %struct.ObjHeader*
-  call fastcc void @ThrowClassCastException(%struct.ObjHeader* nonnull %128, i8* bitcast ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.Array#internal" to i8*)) #50
+  %129 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %91 to %struct.ObjHeader*
+  call fastcc void @ThrowClassCastException(%struct.ObjHeader* nonnull %129, i8* bitcast ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.Array#internal" to i8*)) #50
   unreachable
 
 "kfun:kotlin.native.MemoryModel#values#static(){}kotlin.Array<kotlin.native.MemoryModel>.exit.i.i": ; preds = %loop_exit.i.i.i.i
-  %129 = bitcast %struct.ObjHeader** %48 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  %130 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %131 = load i64, i64* %69, align 8, !tbaa !9
-  %132 = bitcast %"class.kotlin::mm::ShadowStack"* %130 to i64*
-  store i64 %131, i64* %132, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %62)
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %90, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %129, align 8, !tbaa !3
-  %133 = load i32, i32* %94, align 8, !tbaa !18
-  %134 = icmp ugt i32 %133, 2
-  br i1 %134, label %"kfun:kotlin.native.Platform#<get-memoryModel>(){}kotlin.native.MemoryModel.exit.i", label %135
+  %130 = bitcast %struct.ObjHeader** %49 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  %131 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
+  %132 = load atomic i64, i64* %70 unordered, align 8, !tbaa !9
+  %133 = bitcast %"class.kotlin::mm::ShadowStack"* %131 to i64*
+  store i64 %132, i64* %133, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %63)
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %91, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %130, align 8, !tbaa !3
+  %134 = load atomic i32, i32* %95 unordered, align 8, !tbaa !18
+  %135 = icmp ugt i32 %134, 2
+  br i1 %135, label %"kfun:kotlin.native.Platform#<get-memoryModel>(){}kotlin.native.MemoryModel.exit.i", label %136
 
-135:                                              ; preds = %"kfun:kotlin.native.MemoryModel#values#static(){}kotlin.Array<kotlin.native.MemoryModel>.exit.i.i"
+136:                                              ; preds = %"kfun:kotlin.native.MemoryModel#values#static(){}kotlin.Array<kotlin.native.MemoryModel>.exit.i.i"
   call fastcc void @ThrowArrayIndexOutOfBoundsException() #50
   unreachable
 
 "kfun:kotlin.native.Platform#<get-memoryModel>(){}kotlin.native.MemoryModel.exit.i": ; preds = %"kfun:kotlin.native.MemoryModel#values#static(){}kotlin.Array<kotlin.native.MemoryModel>.exit.i.i"
-  %136 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %88, i64 6
-  %137 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %136 to %struct.ObjHeader**
-  %138 = load %struct.ObjHeader*, %struct.ObjHeader** %137, align 8, !tbaa !3
-  store %struct.ObjHeader* %138, %struct.ObjHeader** %32, align 8, !tbaa !3
-  %139 = load i64, i64* %54, align 8, !tbaa !9
-  store i64 %139, i64* %132, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %47)
-  %140 = load %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.MemoryModel.$VALUES#internal", align 8
-  %141 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %140, i64 2
-  %142 = bitcast %struct.ObjHeader* %141 to %struct.ObjHeader**
-  %143 = load %struct.ObjHeader*, %struct.ObjHeader** %142, align 8, !tbaa !3
-  store %struct.ObjHeader* %143, %struct.ObjHeader** %33, align 8, !tbaa !3
-  %144 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %138, i64 0, i32 0
-  %145 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %144 monotonic, align 8
-  %146 = ptrtoint %struct.TypeInfo* %145 to i64
-  %147 = and i64 %146, -4
-  %148 = inttoptr i64 %147 to %struct.TypeInfo*
-  %149 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %148, i64 0, i32 0
-  %150 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %149 monotonic, align 8
-  %151 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %150, i64 1
-  %152 = bitcast %struct.TypeInfo* %151 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
-  %153 = load i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %152, align 8
-  %154 = call zeroext i1 %153(%struct.ObjHeader* %138, %struct.ObjHeader* %143)
-  %155 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 6
-  %156 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %155 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %157 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %156, align 8, !tbaa !3
-  %158 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %157, i64 0, i32 2, i32 1
-  %159 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %158, i64 32) #37
-  %160 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %159, i64 1
-  %161 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %159, i64 2
-  %162 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %161 to %struct.TypeInfo**
-  %163 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %160 to i64*
-  store i64 0, i64* %163, align 8
-  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [3 x i8*] }, { %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.native.concurrent.FreezableAtomicReference#internal", i64 0, i32 0), %struct.TypeInfo** %162, align 8, !tbaa !14
-  br i1 %154, label %when_case.i, label %when_next.i
+  %137 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %89, i64 6
+  %138 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %137 to %struct.ObjHeader**
+  %139 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %138 unordered, align 8, !tbaa !3
+  store %struct.ObjHeader* %139, %struct.ObjHeader** %33, align 8, !tbaa !3
+  %140 = load atomic i64, i64* %55 unordered, align 8, !tbaa !9
+  store i64 %140, i64* %133, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %48)
+  %141 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.MemoryModel.$VALUES#internal" unordered, align 8
+  %142 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %141, i64 2
+  %143 = bitcast %struct.ObjHeader* %142 to %struct.ObjHeader**
+  %144 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %143 unordered, align 8, !tbaa !3
+  store %struct.ObjHeader* %144, %struct.ObjHeader** %34, align 8, !tbaa !3
+  %145 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %139, i64 0, i32 0
+  %146 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %145 monotonic, align 8
+  %147 = ptrtoint %struct.TypeInfo* %146 to i64
+  %148 = and i64 %147, -4
+  %149 = inttoptr i64 %148 to %struct.TypeInfo*
+  %150 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %149, i64 0, i32 0
+  %151 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %150 monotonic, align 8
+  %152 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %151, i64 1
+  %153 = bitcast %struct.TypeInfo* %152 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
+  %154 = load atomic i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %153 unordered, align 8
+  %155 = call zeroext i1 %154(%struct.ObjHeader* %139, %struct.ObjHeader* %144)
+  %156 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 6
+  %157 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %156 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
+  %158 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %157 unordered, align 8, !tbaa !3
+  %159 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %158, i64 0, i32 2, i32 1
+  %160 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %159, i64 32) #37
+  %161 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %160, i64 1
+  %162 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %160, i64 2
+  %163 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %162 to %struct.TypeInfo**
+  %164 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %161 to i64*
+  store i64 0, i64* %164, align 8
+  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [3 x i8*] }, { %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.native.concurrent.FreezableAtomicReference#internal", i64 0, i32 0), %struct.TypeInfo** %163, align 8, !tbaa !14
+  br i1 %155, label %when_case.i, label %when_next.i
 
 when_case.i:                                      ; preds = %"kfun:kotlin.native.Platform#<get-memoryModel>(){}kotlin.native.MemoryModel.exit.i"
-  %164 = bitcast %struct.ObjHeader** %34 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %161, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %164, align 8, !tbaa !3
-  %165 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %159, i64 3
-  %166 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %165 to %struct.ObjHeader**
-  store %struct.ObjHeader* null, %struct.ObjHeader** %166, align 8, !tbaa !3
+  %165 = bitcast %struct.ObjHeader** %35 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %162, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %165, align 8, !tbaa !3
+  %166 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %160, i64 3
+  %167 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %166 to %struct.ObjHeader**
+  store %struct.ObjHeader* null, %struct.ObjHeader** %167, align 8, !tbaa !3
   br label %epilogue
 
 when_next.i:                                      ; preds = %"kfun:kotlin.native.Platform#<get-memoryModel>(){}kotlin.native.MemoryModel.exit.i"
-  %167 = bitcast %struct.ObjHeader** %35 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %161, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %167, align 8, !tbaa !3
-  %168 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %159, i64 3
-  %169 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %168 to %struct.ObjHeader**
-  store %struct.ObjHeader* null, %struct.ObjHeader** %169, align 8, !tbaa !3
-  %170 = bitcast %struct.ObjHeader** %36 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %161, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %170, align 8, !tbaa !3
+  %168 = bitcast %struct.ObjHeader** %36 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %162, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %168, align 8, !tbaa !3
+  %169 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %160, i64 3
+  %170 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %169 to %struct.ObjHeader**
+  store %struct.ObjHeader* null, %struct.ObjHeader** %170, align 8, !tbaa !3
+  %171 = bitcast %struct.ObjHeader** %37 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %162, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %171, align 8, !tbaa !3
   br label %epilogue
 
 epilogue:                                         ; preds = %when_next.i, %when_case.i
-  %171 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %25, i64 3, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %161, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %171, align 8, !tbaa !3
-  %172 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %173 = load i64, i64* %42, align 8, !tbaa !9
-  %174 = bitcast %"class.kotlin::mm::ShadowStack"* %172 to i64*
-  store i64 %173, i64* %174, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %31)
-  %175 = load %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.internal.UnhandledExceptionHookHolder.$instance#internal", align 8
-  call fastcc void @InitAndRegisterGlobal(%struct.ObjHeader** nonnull @"kvar:kotlin.native.internal.UnhandledExceptionHookHolder.$instance#internal", %struct.ObjHeader* %175) #37
-  %176 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %177 = load i64, i64* %12, align 8, !tbaa !9
-  %178 = bitcast %"class.kotlin::mm::ShadowStack"* %176 to i64*
-  store i64 %177, i64* %178, align 8, !tbaa !7
+  %172 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %31, i64 1
+  %173 = bitcast %struct.ObjHeader* %172 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %162, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %173, align 8, !tbaa !3
+  %174 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
+  %175 = load atomic i64, i64* %43 unordered, align 8, !tbaa !9
+  %176 = bitcast %"class.kotlin::mm::ShadowStack"* %174 to i64*
+  store i64 %175, i64* %176, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %32)
+  %177 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.internal.UnhandledExceptionHookHolder.$instance#internal" unordered, align 8
+  call fastcc void @InitAndRegisterGlobal(%struct.ObjHeader** nonnull @"kvar:kotlin.native.internal.UnhandledExceptionHookHolder.$instance#internal", %struct.ObjHeader* %177) #37
+  %178 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
+  %179 = load atomic i64, i64* %12 unordered, align 8, !tbaa !9
+  %180 = bitcast %"class.kotlin::mm::ShadowStack"* %178 to i64*
+  store i64 %179, i64* %180, align 8, !tbaa !7
   ret void
 }
 
@@ -8258,11 +8334,11 @@
   %objHeader = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %8, i64 0, i32 0
   %typeInfoOrMeta_ = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %8, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_, align 8
-  %11 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %11 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %12 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
   %13 = bitcast [9 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
   %14 = bitcast %"class.kotlin::mm::ShadowStack"* %12 to i64*
-  %15 = load i64, i64* %14, align 8, !tbaa !7
+  %15 = load atomic i64, i64* %14 unordered, align 8, !tbaa !7
   %16 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %0, i64 0, i64 1
   %17 = bitcast %struct.ObjHeader** %16 to i64*
   store i64 %15, i64* %17, align 8, !tbaa !9
@@ -8291,7 +8367,7 @@
   %29 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#toString(){}kotlin.String"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader** nonnull %6)
   %30 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 6
   %31 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %30 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %32 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %31, align 8, !tbaa !3
+  %32 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %31 unordered, align 8, !tbaa !3
   %33 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %32, i64 0, i32 2, i32 1
   %34 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %33, i64 56) #37
   %35 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %34, i64 1
@@ -8328,11 +8404,11 @@
   %objHeader14 = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %8, i64 0, i32 0
   %typeInfoOrMeta_15 = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %8, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_15, align 8
-  %11 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %11 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %12 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
   %13 = bitcast [19 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %14 = bitcast %"class.kotlin::mm::ShadowStack"* %12 to i64*
-  %15 = load i64, i64* %14, align 8, !tbaa !7
+  %15 = load atomic i64, i64* %14 unordered, align 8, !tbaa !7
   %16 = getelementptr inbounds [19 x %struct.ObjHeader*], [19 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %17 = bitcast %struct.ObjHeader** %16 to i64*
   store i64 %15, i64* %17, align 8, !tbaa !9
@@ -8379,7 +8455,7 @@
   %43 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#toString(){}kotlin.String"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader** nonnull %29)
   %44 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 6
   %45 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %44 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %46 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %45, align 8, !tbaa !3
+  %46 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %45 unordered, align 8, !tbaa !3
   %47 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %46, i64 0, i32 2, i32 1
   %48 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %47, i64 56) #37
   %49 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %48, i64 1
@@ -8416,7 +8492,7 @@
   %67 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#toString(){}kotlin.String"(%struct.ObjHeader* nonnull %objHeader14, %struct.ObjHeader** nonnull %57)
   %68 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 6
   %69 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %68 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %70 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %69, align 8, !tbaa !3
+  %70 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %69 unordered, align 8, !tbaa !3
   %71 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %70, i64 0, i32 2, i32 1
   %72 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %71, i64 56) #37
   %73 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %72, i64 1
@@ -8434,7 +8510,7 @@
 
 epilogue:                                         ; preds = %when_exit2
   %79 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
-  %80 = load i64, i64* %17, align 8, !tbaa !9
+  %80 = load atomic i64, i64* %17 unordered, align 8, !tbaa !9
   %81 = bitcast %"class.kotlin::mm::ShadowStack"* %79 to i64*
   store i64 %80, i64* %81, align 8, !tbaa !7
   ret void
@@ -8456,11 +8532,11 @@
   %objHeader = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %8, i64 0, i32 0
   %typeInfoOrMeta_ = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %8, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_, align 8
-  %11 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %11 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %12 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
   %13 = bitcast [5 x %struct.ObjHeader*]* %5 to %struct.FrameOverlay.6*
   %14 = bitcast %"class.kotlin::mm::ShadowStack"* %12 to i64*
-  %15 = load i64, i64* %14, align 8, !tbaa !7
+  %15 = load atomic i64, i64* %14 unordered, align 8, !tbaa !7
   %16 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %5, i64 0, i64 1
   %17 = bitcast %struct.ObjHeader** %16 to i64*
   store i64 %15, i64* %17, align 8, !tbaa !9
@@ -8494,7 +8570,7 @@
   %31 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
   %32 = bitcast [9 x %struct.ObjHeader*]* %4 to %struct.FrameOverlay.6*
   %33 = bitcast %"class.kotlin::mm::ShadowStack"* %31 to i64*
-  %34 = load i64, i64* %33, align 8, !tbaa !7
+  %34 = load atomic i64, i64* %33 unordered, align 8, !tbaa !7
   %35 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %4, i64 0, i64 1
   %36 = bitcast %struct.ObjHeader** %35 to i64*
   store i64 %34, i64* %36, align 8, !tbaa !9
@@ -8507,15 +8583,15 @@
   store i32 9, i32* %40, align 4, !tbaa !13
   %41 = load atomic %struct.TypeInfo*, %struct.TypeInfo** getelementptr (%struct.TypeInfo, %struct.TypeInfo* inttoptr (i64 and (i64 ptrtoint (i8* getelementptr (i8, i8* bitcast ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.String#internal" to i8*), i64 1) to i64), i64 -4) to %struct.TypeInfo*), i64 0, i32 0) monotonic, align 8
   %42 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %41, i64 0, i32 9
-  %43 = load i32, i32* %42, align 4
+  %43 = load atomic i32, i32* %42 unordered, align 4
   %44 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %41, i64 0, i32 10
-  %45 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %44, align 8
+  %45 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %44 unordered, align 8
   %46 = and i32 %43, 25
   %47 = zext i32 %46 to i64
   %48 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %45, i64 %47, i32 2
   %49 = bitcast i8*** %48 to i32 (%struct.ObjHeader*)***
-  %50 = load i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %49, align 8
-  %51 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %50, align 8
+  %50 = load atomic i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %49 unordered, align 8
+  %51 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %50 unordered, align 8
   %52 = call i32 %51(%struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [1 x i16] }* @107 to %struct.ObjHeader*))
   %53 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.CharSequence?;kotlin.Int;kotlin.Int){}kotlin.text.StringBuilder"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [1 x i16] }* @107 to %struct.ObjHeader*), i32 0, i32 %52, %struct.ObjHeader** nonnull %27)
   store %struct.ObjHeader* %objHeader, %struct.ObjHeader** %27, align 8, !tbaa !3
@@ -8527,15 +8603,15 @@
   %59 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %58, i64 0, i32 0
   %60 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %59 monotonic, align 8
   %61 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %60, i64 0, i32 9
-  %62 = load i32, i32* %61, align 4
+  %62 = load atomic i32, i32* %61 unordered, align 4
   %63 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %60, i64 0, i32 10
-  %64 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %63, align 8
+  %64 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %63 unordered, align 8
   %65 = and i32 %62, 49
   %66 = zext i32 %65 to i64
   %67 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %64, i64 %66, i32 2
   %68 = bitcast i8*** %67 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)***
-  %69 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %68, align 8
-  %70 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %69, align 8
+  %69 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %68 unordered, align 8
+  %70 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %69 unordered, align 8
   %71 = call %struct.ObjHeader* %70(%struct.ObjHeader* %0, %struct.ObjHeader** nonnull %28)
   %72 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %71, i64 0, i32 0
   %73 = bitcast [10 x %struct.ObjHeader*]* %3 to i8*
@@ -8577,16 +8653,16 @@
   %98 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %97, i64 0, i32 0
   %99 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %98 monotonic, align 8
   %100 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %99, i64 0, i32 9
-  %101 = load i32, i32* %100, align 4
+  %101 = load atomic i32, i32* %100 unordered, align 4
   %102 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %99, i64 0, i32 10
-  %103 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %102, align 8
+  %103 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %102 unordered, align 8
   %104 = and i32 %101, 160
   %105 = zext i32 %104 to i64
   %106 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %103, i64 %105, i32 2
-  %107 = load i8**, i8*** %106, align 8
+  %107 = load atomic i8**, i8*** %106 unordered, align 8
   %108 = getelementptr i8*, i8** %107, i64 1
   %109 = bitcast i8** %108 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %110 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %109, align 8
+  %110 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %109 unordered, align 8
   %111 = call %struct.ObjHeader* %110(%struct.ObjHeader* %71, %struct.ObjHeader** nonnull %29)
   %112 = add i32 %count.0.i, 1
   %113 = icmp sgt i32 %112, 1
@@ -8595,15 +8671,15 @@
 when_case.i:                                      ; preds = %Kotlin_mm_safePointWhileLoopBody.exit.i
   %114 = load atomic %struct.TypeInfo*, %struct.TypeInfo** getelementptr (%struct.TypeInfo, %struct.TypeInfo* inttoptr (i64 and (i64 ptrtoint (i8* getelementptr (i8, i8* bitcast ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.String#internal" to i8*), i64 1) to i64), i64 -4) to %struct.TypeInfo*), i64 0, i32 0) monotonic, align 8
   %115 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %114, i64 0, i32 9
-  %116 = load i32, i32* %115, align 4
+  %116 = load atomic i32, i32* %115 unordered, align 4
   %117 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %114, i64 0, i32 10
-  %118 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %117, align 8
+  %118 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %117 unordered, align 8
   %119 = and i32 %116, 25
   %120 = zext i32 %119 to i64
   %121 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %118, i64 %120, i32 2
   %122 = bitcast i8*** %121 to i32 (%struct.ObjHeader*)***
-  %123 = load i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %122, align 8
-  %124 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %123, align 8
+  %123 = load atomic i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %122 unordered, align 8
+  %124 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %123 unordered, align 8
   %125 = call i32 %124(%struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [2 x i16] }* @106 to %struct.ObjHeader*))
   %126 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.CharSequence?;kotlin.Int;kotlin.Int){}kotlin.text.StringBuilder"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [2 x i16] }* @106 to %struct.ObjHeader*), i32 0, i32 %125, %struct.ObjHeader** nonnull %30)
   store %struct.ObjHeader* %objHeader, %struct.ObjHeader** %30, align 8, !tbaa !3
@@ -8614,7 +8690,7 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(80) %73, i8 0, i32 80, i1 immarg false) #49
   %127 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
   %128 = bitcast %"class.kotlin::mm::ShadowStack"* %127 to i64*
-  %129 = load i64, i64* %128, align 8, !tbaa !7
+  %129 = load atomic i64, i64* %128 unordered, align 8, !tbaa !7
   store i64 %129, i64* %83, align 8, !tbaa !9
   %130 = bitcast %"class.kotlin::mm::ShadowStack"* %127 to %struct.ObjHeader***
   store %struct.ObjHeader** %.sub.i.i, %struct.ObjHeader*** %130, align 8, !tbaa !7
@@ -8629,7 +8705,7 @@
   %134 = load atomic volatile i64, i64* %133 monotonic, align 8
   %135 = inttoptr i64 %134 to i8*
   %136 = icmp eq i8* %135, bitcast ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.native.internal.NSDictionaryAsKMap.$toString$lambda$0$FUNCTION_REFERENCE$0#internal" to i8*)
-  %137 = load %struct.ObjHeader*, %struct.ObjHeader** %89, align 8
+  %137 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %89 unordered, align 8
   br i1 %136, label %when_case5.i.i, label %when_next6.i.i
 
 when_case5.i.i:                                   ; preds = %when_case.i.i
@@ -8655,7 +8731,7 @@
   %147 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %146 monotonic, align 8
   %148 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %147, i64 1, i32 2
   %149 = bitcast i32* %148 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %150 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %149, align 8
+  %150 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %149 unordered, align 8
   %151 = call %struct.ObjHeader* %150(%struct.ObjHeader* nonnull %111, %struct.ObjHeader** nonnull %75)
   br label %"kfun:kotlin.collections.AbstractCollection.$toString$lambda$0$FUNCTION_REFERENCE$0.invoke#internal.exit.i.i"
 
@@ -8682,13 +8758,13 @@
   %161 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %160, i64 0, i32 0
   %162 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %161 monotonic, align 8
   %163 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %162, i64 0, i32 9
-  %164 = load i32, i32* %163, align 4
+  %164 = load atomic i32, i32* %163 unordered, align 4
   %165 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %162, i64 0, i32 10
-  %166 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %165, align 8
+  %166 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %165 unordered, align 8
   %167 = and i32 %164, 25
   %168 = zext i32 %167 to i64
   %169 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %166, i64 %168, i32 0
-  %170 = load i32, i32* %169, align 4
+  %170 = load atomic i32, i32* %169 unordered, align 4
   %171 = icmp eq i32 %170, 25
   br i1 %171, label %when_case1.i.i, label %instance_of_exit12.i.i
 
@@ -8704,14 +8780,14 @@
   %177 = load atomic volatile i64, i64* %176 monotonic, align 8
   %178 = inttoptr i64 %177 to %struct.TypeInfo*
   %179 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %178, i64 0, i32 14
-  %180 = load i32, i32* %179, align 4, !tbaa !19
+  %180 = load atomic i32, i32* %179 unordered, align 4, !tbaa !19
   %181 = icmp eq i32 %180, 84
   br i1 %181, label %when_case3.i.i, label %when_exit18.i.i
 
 when_case3.i.i:                                   ; preds = %instance_of_exit12.i.i
   %182 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %111, i64 1
   %183 = bitcast %struct.ObjHeader* %182 to i16*
-  %184 = load i16, i16* %183, align 2
+  %184 = load atomic i16, i16* %183 unordered, align 2
   %185 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.Char){}kotlin.text.StringBuilder"(%struct.ObjHeader* nonnull %objHeader, i16 zeroext %184, %struct.ObjHeader** nonnull %78)
   br label %"kfun:kotlin.text#appendElement__at__kotlin.text.Appendable(0:0;kotlin.Function1<0:0,kotlin.CharSequence>?){0\C2\A7<kotlin.Any?>}.exit.i"
 
@@ -8724,14 +8800,14 @@
   %191 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %190 monotonic, align 8
   %192 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %191, i64 1, i32 2
   %193 = bitcast i32* %192 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %194 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %193, align 8
+  %194 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %193 unordered, align 8
   %195 = call %struct.ObjHeader* %194(%struct.ObjHeader* nonnull %111, %struct.ObjHeader** nonnull %79)
   %196 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.CharSequence?){}kotlin.text.StringBuilder"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader* %195, %struct.ObjHeader** nonnull %80)
   br label %"kfun:kotlin.text#appendElement__at__kotlin.text.Appendable(0:0;kotlin.Function1<0:0,kotlin.CharSequence>?){0\C2\A7<kotlin.Any?>}.exit.i"
 
 "kfun:kotlin.text#appendElement__at__kotlin.text.Appendable(0:0;kotlin.Function1<0:0,kotlin.CharSequence>?){0\C2\A7<kotlin.Any?>}.exit.i": ; preds = %when_exit18.i.i, %when_case3.i.i, %when_case1.i.i, %when_exit.i.i
   %197 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
-  %198 = load i64, i64* %83, align 8, !tbaa !9
+  %198 = load atomic i64, i64* %83 unordered, align 8, !tbaa !9
   %199 = bitcast %"class.kotlin::mm::ShadowStack"* %197 to i64*
   store i64 %198, i64* %199, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %73)
@@ -8746,15 +8822,15 @@
   %204 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %203, i64 0, i32 0
   %205 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %204 monotonic, align 8
   %206 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %205, i64 0, i32 9
-  %207 = load i32, i32* %206, align 4
+  %207 = load atomic i32, i32* %206 unordered, align 4
   %208 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %205, i64 0, i32 10
-  %209 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %208, align 8
+  %209 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %208 unordered, align 8
   %210 = and i32 %207, 160
   %211 = zext i32 %210 to i64
   %212 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %209, i64 %211, i32 2
   %213 = bitcast i8*** %212 to i1 (%struct.ObjHeader*)***
-  %214 = load i1 (%struct.ObjHeader*)**, i1 (%struct.ObjHeader*)*** %213, align 8
-  %215 = load i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %214, align 8
+  %214 = load atomic i1 (%struct.ObjHeader*)**, i1 (%struct.ObjHeader*)*** %213 unordered, align 8
+  %215 = load atomic i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %214 unordered, align 8
   %216 = call zeroext i1 %215(%struct.ObjHeader* %71)
   br i1 %216, label %while_loop.i, label %epilogue
 
@@ -8763,28 +8839,28 @@
   %218 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %4, i64 0, i64 8
   %219 = load atomic %struct.TypeInfo*, %struct.TypeInfo** getelementptr (%struct.TypeInfo, %struct.TypeInfo* inttoptr (i64 and (i64 ptrtoint (i8* getelementptr (i8, i8* bitcast ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.String#internal" to i8*), i64 1) to i64), i64 -4) to %struct.TypeInfo*), i64 0, i32 0) monotonic, align 8
   %220 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %219, i64 0, i32 9
-  %221 = load i32, i32* %220, align 4
+  %221 = load atomic i32, i32* %220 unordered, align 4
   %222 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %219, i64 0, i32 10
-  %223 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %222, align 8
+  %223 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %222 unordered, align 8
   %224 = and i32 %221, 25
   %225 = zext i32 %224 to i64
   %226 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %223, i64 %225, i32 2
   %227 = bitcast i8*** %226 to i32 (%struct.ObjHeader*)***
-  %228 = load i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %227, align 8
-  %229 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %228, align 8
+  %228 = load atomic i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %227 unordered, align 8
+  %229 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %228 unordered, align 8
   %230 = call i32 %229(%struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [1 x i16] }* @108 to %struct.ObjHeader*))
   %231 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.CharSequence?;kotlin.Int;kotlin.Int){}kotlin.text.StringBuilder"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [1 x i16] }* @108 to %struct.ObjHeader*), i32 0, i32 %230, %struct.ObjHeader** nonnull %218)
   store %struct.ObjHeader* %objHeader, %struct.ObjHeader** %218, align 8, !tbaa !3
   store %struct.ObjHeader* %objHeader, %struct.ObjHeader** %217, align 8, !tbaa !3
   %232 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
-  %233 = load i64, i64* %36, align 8, !tbaa !9
+  %233 = load atomic i64, i64* %36 unordered, align 8, !tbaa !9
   %234 = bitcast %"class.kotlin::mm::ShadowStack"* %232 to i64*
   store i64 %233, i64* %234, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 72, i8* nonnull %26)
   %235 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#toString(){}kotlin.String"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader** %2)
   store %struct.ObjHeader* %235, %struct.ObjHeader** %2, align 8, !tbaa !3
   %236 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
-  %237 = load i64, i64* %17, align 8, !tbaa !9
+  %237 = load atomic i64, i64* %17 unordered, align 8, !tbaa !9
   %238 = bitcast %"class.kotlin::mm::ShadowStack"* %236 to i64*
   store i64 %237, i64* %238, align 8, !tbaa !7
   ret %struct.ObjHeader* %235
@@ -8818,13 +8894,13 @@
   %13 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %12, i64 0, i32 0
   %14 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %13 monotonic, align 8
   %15 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %14, i64 0, i32 9
-  %16 = load i32, i32* %15, align 4
+  %16 = load atomic i32, i32* %15 unordered, align 4
   %17 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %14, i64 0, i32 10
-  %18 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %17, align 8
+  %18 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %17 unordered, align 8
   %19 = and i32 %16, 30
   %20 = zext i32 %19 to i64
   %21 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %18, i64 %20, i32 0
-  %22 = load i32, i32* %21, align 4
+  %22 = load atomic i32, i32* %21 unordered, align 4
   %.not = icmp eq i32 %22, 30
   br i1 %.not, label %when_exit2, label %epilogue
 
@@ -8837,15 +8913,15 @@
   %28 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %27, i64 0, i32 0
   %29 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %28 monotonic, align 8
   %30 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %29, i64 0, i32 9
-  %31 = load i32, i32* %30, align 4
+  %31 = load atomic i32, i32* %30 unordered, align 4
   %32 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %29, i64 0, i32 10
-  %33 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %32, align 8
+  %33 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %32 unordered, align 8
   %34 = and i32 %31, 30
   %35 = zext i32 %34 to i64
   %36 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %33, i64 %35, i32 2
   %37 = bitcast i8*** %36 to i32 (%struct.ObjHeader*)***
-  %38 = load i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %37, align 8
-  %39 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %38, align 8
+  %38 = load atomic i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %37 unordered, align 8
+  %39 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %38 unordered, align 8
   %40 = tail call i32 %39(%struct.ObjHeader* %0)
   %41 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %8 monotonic, align 8
   %42 = ptrtoint %struct.TypeInfo* %41 to i64
@@ -8854,15 +8930,15 @@
   %45 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %44, i64 0, i32 0
   %46 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %45 monotonic, align 8
   %47 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %46, i64 0, i32 9
-  %48 = load i32, i32* %47, align 4
+  %48 = load atomic i32, i32* %47 unordered, align 4
   %49 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %46, i64 0, i32 10
-  %50 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %49, align 8
+  %50 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %49 unordered, align 8
   %51 = and i32 %48, 30
   %52 = zext i32 %51 to i64
   %53 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %50, i64 %52, i32 2
   %54 = bitcast i8*** %53 to i32 (%struct.ObjHeader*)***
-  %55 = load i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %54, align 8
-  %56 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %55, align 8
+  %55 = load atomic i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %54 unordered, align 8
+  %56 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %55 unordered, align 8
   %57 = tail call i32 %56(%struct.ObjHeader* nonnull %1)
   %.not.i = icmp eq i32 %40, %57
   br i1 %.not.i, label %when_exit.i, label %epilogue
@@ -8875,16 +8951,16 @@
   %62 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %61, i64 0, i32 0
   %63 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %62 monotonic, align 8
   %64 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %63, i64 0, i32 9
-  %65 = load i32, i32* %64, align 4
+  %65 = load atomic i32, i32* %64 unordered, align 4
   %66 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %63, i64 0, i32 10
-  %67 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %66, align 8
+  %67 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %66 unordered, align 8
   %68 = and i32 %65, 18
   %69 = zext i32 %68 to i64
   %70 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %67, i64 %69, i32 2
-  %71 = load i8**, i8*** %70, align 8
+  %71 = load atomic i8**, i8*** %70 unordered, align 8
   %72 = getelementptr i8*, i8** %71, i64 2
   %73 = bitcast i8** %72 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
-  %74 = load i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %73, align 8
+  %74 = load atomic i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %73 unordered, align 8
   %75 = tail call zeroext i1 %74(%struct.ObjHeader* %0, %struct.ObjHeader* nonnull %1)
   br label %epilogue
 
@@ -8912,11 +8988,11 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %6, i8 0, i32 40, i1 immarg false) #49
   %7 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %1, i64 0, i64 3
   %8 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %1, i64 0, i64 4
-  %9 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %9 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %10 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
   %11 = bitcast [5 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
   %12 = bitcast %"class.kotlin::mm::ShadowStack"* %10 to i64*
-  %13 = load i64, i64* %12, align 8, !tbaa !7
+  %13 = load atomic i64, i64* %12 unordered, align 8, !tbaa !7
   %14 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %1, i64 0, i64 1
   %15 = bitcast %struct.ObjHeader** %14 to i64*
   store i64 %13, i64* %15, align 8, !tbaa !9
@@ -8935,16 +9011,16 @@
   %25 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %24, i64 0, i32 0
   %26 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %25 monotonic, align 8
   %27 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %26, i64 0, i32 9
-  %28 = load i32, i32* %27, align 4
+  %28 = load atomic i32, i32* %27 unordered, align 4
   %29 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %26, i64 0, i32 10
-  %30 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %29, align 8
+  %30 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %29 unordered, align 8
   %31 = and i32 %28, 18
   %32 = zext i32 %31 to i64
   %33 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %30, i64 %32, i32 2
-  %34 = load i8**, i8*** %33, align 8
+  %34 = load atomic i8**, i8*** %33 unordered, align 8
   %35 = getelementptr i8*, i8** %34, i64 4
   %36 = bitcast i8** %35 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %37 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %36, align 8
+  %37 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %36 unordered, align 8
   %38 = call %struct.ObjHeader* %37(%struct.ObjHeader* %0, %struct.ObjHeader** nonnull %7)
   %39 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %38, i64 0, i32 0
   br label %loop_check.i
@@ -8967,16 +9043,16 @@
   %48 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %47, i64 0, i32 0
   %49 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %48 monotonic, align 8
   %50 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %49, i64 0, i32 9
-  %51 = load i32, i32* %50, align 4
+  %51 = load atomic i32, i32* %50 unordered, align 4
   %52 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %49, i64 0, i32 10
-  %53 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %52, align 8
+  %53 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %52 unordered, align 8
   %54 = and i32 %51, 160
   %55 = zext i32 %54 to i64
   %56 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %53, i64 %55, i32 2
-  %57 = load i8**, i8*** %56, align 8
+  %57 = load atomic i8**, i8*** %56 unordered, align 8
   %58 = getelementptr i8*, i8** %57, i64 1
   %59 = bitcast i8** %58 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %60 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %59, align 8
+  %60 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %59 unordered, align 8
   %61 = call %struct.ObjHeader* %60(%struct.ObjHeader* %38, %struct.ObjHeader** nonnull %8)
   %62 = icmp eq %struct.ObjHeader* %61, null
   br i1 %62, label %when_exit.i, label %when_next.i
@@ -8991,7 +9067,7 @@
   %69 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %68 monotonic, align 8
   %70 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %69, i64 1, i32 1
   %71 = bitcast %struct.ExtendedTypeInfo** %70 to i32 (%struct.ObjHeader*)**
-  %72 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %71, align 8
+  %72 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %71 unordered, align 8
   %73 = call i32 %72(%struct.ObjHeader* nonnull %61)
   br label %when_exit.i
 
@@ -9009,22 +9085,22 @@
   %80 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %79, i64 0, i32 0
   %81 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %80 monotonic, align 8
   %82 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %81, i64 0, i32 9
-  %83 = load i32, i32* %82, align 4
+  %83 = load atomic i32, i32* %82 unordered, align 4
   %84 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %81, i64 0, i32 10
-  %85 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %84, align 8
+  %85 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %84 unordered, align 8
   %86 = and i32 %83, 160
   %87 = zext i32 %86 to i64
   %88 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %85, i64 %87, i32 2
   %89 = bitcast i8*** %88 to i1 (%struct.ObjHeader*)***
-  %90 = load i1 (%struct.ObjHeader*)**, i1 (%struct.ObjHeader*)*** %89, align 8
-  %91 = load i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %90, align 8
+  %90 = load atomic i1 (%struct.ObjHeader*)**, i1 (%struct.ObjHeader*)*** %89 unordered, align 8
+  %91 = load atomic i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %90 unordered, align 8
   %92 = call zeroext i1 %91(%struct.ObjHeader* %38)
   br i1 %92, label %while_loop.i, label %epilogue
 
 epilogue:                                         ; preds = %loop_check.i
-  %93 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %93 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %94 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %93, i64 0, i32 1, i32 5
-  %95 = load i64, i64* %15, align 8, !tbaa !9
+  %95 = load atomic i64, i64* %15 unordered, align 8, !tbaa !9
   %96 = bitcast %"class.kotlin::mm::ShadowStack"* %94 to i64*
   store i64 %95, i64* %96, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %6)
@@ -9046,7 +9122,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %epilogue
   %5 = bitcast %struct.ObjHeader* %0 to %"kclassbody:kotlin.collections.HashMap#internal"*
   %6 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %5, i64 0, i32 11
-  %7 = load i32, i32* %6, align 4
+  %7 = load atomic i32, i32* %6 unordered, align 4
   ret i32 %7
 }
 
@@ -9065,7 +9141,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %epilogue
   %5 = bitcast %struct.ObjHeader* %0 to %"kclassbody:kotlin.collections.HashMap#internal"*
   %6 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %5, i64 0, i32 11
-  %7 = load i32, i32* %6, align 4
+  %7 = load atomic i32, i32* %6 unordered, align 4
   %8 = icmp eq i32 %7, 0
   ret i1 %8
 }
@@ -9107,11 +9183,11 @@
   %8 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %9 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 4
   %10 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 5
-  %11 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %11 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %12 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
   %13 = bitcast [6 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %14 = bitcast %"class.kotlin::mm::ShadowStack"* %12 to i64*
-  %15 = load i64, i64* %14, align 8, !tbaa !7
+  %15 = load atomic i64, i64* %14 unordered, align 8, !tbaa !7
   %16 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %17 = bitcast %struct.ObjHeader** %16 to i64*
   store i64 %15, i64* %17, align 8, !tbaa !9
@@ -9124,7 +9200,7 @@
   store i32 6, i32* %21, align 4, !tbaa !13
   %22 = bitcast %struct.ObjHeader* %0 to %"kclassbody:kotlin.collections.HashMap#internal"*
   %23 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %22, i64 0, i32 9
-  %24 = load i32, i32* %23, align 4
+  %24 = load atomic i32, i32* %23 unordered, align 4
   %25 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 3
   %26 = bitcast %struct.ObjHeader* %25 to %struct.ObjHeader**
   %27 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
@@ -9143,11 +9219,11 @@
   br label %Kotlin_mm_safePointWhileLoopBody.exit.i
 
 Kotlin_mm_safePointWhileLoopBody.exit.i:          ; preds = %33, %while_loop.i
-  %34 = load %struct.ObjHeader*, %struct.ObjHeader** %26, align 8
+  %34 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %26 unordered, align 8
   store %struct.ObjHeader* %34, %struct.ObjHeader** %8, align 8, !tbaa !3
   %35 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %34, i64 1
   %36 = bitcast %struct.ObjHeader* %35 to i32*
-  %37 = load i32, i32* %36, align 8, !tbaa !18
+  %37 = load atomic i32, i32* %36 unordered, align 8, !tbaa !18
   %38 = icmp ugt i32 %37, %69
   br i1 %38, label %Kotlin_IntArray_get.exit.i, label %39
 
@@ -9160,12 +9236,12 @@
   %41 = bitcast %struct.ObjHeader* %40 to i32*
   %42 = sext i32 %69 to i64
   %43 = getelementptr inbounds i32, i32* %41, i64 %42
-  %44 = load i32, i32* %43, align 4, !tbaa !73
+  %44 = load atomic i32, i32* %43 unordered, align 4, !tbaa !71
   %45 = icmp sgt i32 %44, -1
   br i1 %45, label %when_case1.i, label %when_exit11.i
 
 when_case1.i:                                     ; preds = %Kotlin_IntArray_get.exit.i
-  %46 = load %struct.ObjHeader*, %struct.ObjHeader** %28, align 8
+  %46 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %28 unordered, align 8
   store %struct.ObjHeader* %46, %struct.ObjHeader** %9, align 8, !tbaa !3
   %47 = icmp eq %struct.ObjHeader* %46, null
   br i1 %47, label %when_case2.i, label %when_exit.i
@@ -9177,7 +9253,7 @@
 when_exit.i:                                      ; preds = %when_case1.i
   %48 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %46, i64 1
   %49 = bitcast %struct.ObjHeader* %48 to i32*
-  %50 = load i32, i32* %49, align 8, !tbaa !18
+  %50 = load atomic i32, i32* %49 unordered, align 8, !tbaa !18
   %51 = icmp ugt i32 %50, %69
   br i1 %51, label %Kotlin_Array_get.exit.i, label %52
 
@@ -9189,7 +9265,7 @@
   %53 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %46, i64 2
   %54 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %53, i64 %42
   %55 = bitcast %struct.ObjHeader* %54 to %struct.ObjHeader**
-  %56 = load %struct.ObjHeader*, %struct.ObjHeader** %55, align 8, !tbaa !3
+  %56 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %55 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %56, %struct.ObjHeader** %10, align 8, !tbaa !3
   %57 = icmp eq %struct.ObjHeader* %56, null
   br i1 %57, label %when_case6.i, label %when_exit10.i
@@ -9207,7 +9283,7 @@
   %64 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %63 monotonic, align 8
   %65 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %64, i64 1
   %66 = bitcast %struct.TypeInfo* %65 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
-  %67 = load i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %66, align 8
+  %67 = load atomic i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %66 unordered, align 8
   %68 = call zeroext i1 %67(%struct.ObjHeader* nonnull %56, %struct.ObjHeader* %1)
   br i1 %68, label %epilogue, label %when_exit11.i
 
@@ -9222,9 +9298,9 @@
 
 epilogue:                                         ; preds = %loop_check.i, %when_exit10.i, %when_case6.i
   %71 = phi i32 [ %69, %when_case6.i ], [ %69, %when_exit10.i ], [ -1, %loop_check.i ]
-  %72 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %72 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %73 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %72, i64 0, i32 1, i32 5
-  %74 = load i64, i64* %17, align 8, !tbaa !9
+  %74 = load atomic i64, i64* %17 unordered, align 8, !tbaa !9
   %75 = bitcast %"class.kotlin::mm::ShadowStack"* %73 to i64*
   store i64 %74, i64* %75, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 48, i8* nonnull %7)
@@ -9238,11 +9314,11 @@
   %.sub = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 0
   %4 = bitcast [4 x %struct.ObjHeader*]* %3 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %4, i8 0, i32 32, i1 immarg false) #49
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %7 = bitcast [4 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %8 = bitcast %"class.kotlin::mm::ShadowStack"* %6 to i64*
-  %9 = load i64, i64* %8, align 8, !tbaa !7
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !7
   %10 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %11 = bitcast %struct.ObjHeader** %10 to i64*
   store i64 %9, i64* %11, align 8, !tbaa !9
@@ -9271,7 +9347,7 @@
   %22 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 3
   %23 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %24 = bitcast %struct.ObjHeader* %23 to %struct.ObjHeader**
-  %25 = load %struct.ObjHeader*, %struct.ObjHeader** %24, align 8
+  %25 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %24 unordered, align 8
   store %struct.ObjHeader* %25, %struct.ObjHeader** %22, align 8, !tbaa !3
   %26 = icmp eq %struct.ObjHeader* %25, null
   br i1 %26, label %when_case1, label %when_exit2
@@ -9283,7 +9359,7 @@
 when_exit2:                                       ; preds = %when_exit
   %27 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %25, i64 1
   %28 = bitcast %struct.ObjHeader* %27 to i32*
-  %29 = load i32, i32* %28, align 8, !tbaa !18
+  %29 = load atomic i32, i32* %28 unordered, align 8, !tbaa !18
   %30 = icmp ugt i32 %29, %20
   br i1 %30, label %call_success5, label %31
 
@@ -9296,7 +9372,7 @@
   %33 = sext i32 %20 to i64
   %34 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %32, i64 %33
   %35 = bitcast %struct.ObjHeader* %34 to %struct.ObjHeader**
-  %36 = load %struct.ObjHeader*, %struct.ObjHeader** %35, align 8, !tbaa !3
+  %36 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %35 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %36, %struct.ObjHeader** %2, align 8, !tbaa !3
   br label %epilogue
 
@@ -9304,7 +9380,7 @@
   %37 = phi %struct.ObjHeader* [ %36, %call_success5 ], [ null, %Kotlin_mm_safePointFunctionPrologue.exit ]
   store %struct.ObjHeader* %37, %struct.ObjHeader** %2, align 8, !tbaa !3
   %38 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %39 = load i64, i64* %11, align 8, !tbaa !9
+  %39 = load atomic i64, i64* %11 unordered, align 8, !tbaa !9
   %40 = bitcast %"class.kotlin::mm::ShadowStack"* %38 to i64*
   store i64 %39, i64* %40, align 8, !tbaa !7
   ret %struct.ObjHeader* %37
@@ -9320,11 +9396,11 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %7, i8 0, i32 40, i1 immarg false) #49
   %8 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %6, i64 0, i64 3
   %9 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %6, i64 0, i64 4
-  %10 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %10 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %11 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %10, i64 0, i32 1, i32 5
   %12 = bitcast [5 x %struct.ObjHeader*]* %6 to %struct.FrameOverlay.6*
   %13 = bitcast %"class.kotlin::mm::ShadowStack"* %11 to i64*
-  %14 = load i64, i64* %13, align 8, !tbaa !7
+  %14 = load atomic i64, i64* %13 unordered, align 8, !tbaa !7
   %15 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %6, i64 0, i64 1
   %16 = bitcast %struct.ObjHeader** %15 to i64*
   store i64 %14, i64* %16, align 8, !tbaa !9
@@ -9356,7 +9432,7 @@
   %29 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %10, i64 0, i32 1, i32 5
   %30 = bitcast [6 x %struct.ObjHeader*]* %5 to %struct.FrameOverlay.6*
   %31 = bitcast %"class.kotlin::mm::ShadowStack"* %29 to i64*
-  %32 = load i64, i64* %31, align 8, !tbaa !7
+  %32 = load atomic i64, i64* %31 unordered, align 8, !tbaa !7
   %33 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %5, i64 0, i64 1
   %34 = bitcast %struct.ObjHeader** %33 to i64*
   store i64 %32, i64* %34, align 8, !tbaa !9
@@ -9369,7 +9445,7 @@
   store i32 6, i32* %38, align 4, !tbaa !13
   %39 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %40 = bitcast %struct.ObjHeader* %39 to %struct.ObjHeader**
-  %41 = load %struct.ObjHeader*, %struct.ObjHeader** %40, align 8
+  %41 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %40 unordered, align 8
   store %struct.ObjHeader* %41, %struct.ObjHeader** %27, align 8, !tbaa !3
   %.not.i = icmp eq %struct.ObjHeader* %41, null
   br i1 %.not.i, label %when_exit.i, label %call_success2
@@ -9383,7 +9459,7 @@
   %44 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %10, i64 0, i32 1, i32 5
   %45 = bitcast [4 x %struct.ObjHeader*]* %4 to %struct.FrameOverlay.6*
   %46 = bitcast %"class.kotlin::mm::ShadowStack"* %44 to i64*
-  %47 = load i64, i64* %46, align 8, !tbaa !7
+  %47 = load atomic i64, i64* %46 unordered, align 8, !tbaa !7
   %48 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %4, i64 0, i64 1
   %49 = bitcast %struct.ObjHeader** %48 to i64*
   store i64 %47, i64* %49, align 8, !tbaa !9
@@ -9396,13 +9472,13 @@
   store i32 4, i32* %53, align 4, !tbaa !13
   %54 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %55 = bitcast %struct.ObjHeader* %54 to %struct.ObjHeader**
-  %56 = load %struct.ObjHeader*, %struct.ObjHeader** %55, align 8
+  %56 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %55 unordered, align 8
   store %struct.ObjHeader* %56, %struct.ObjHeader** %43, align 8, !tbaa !3
   %57 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %56, i64 1
   %58 = bitcast %struct.ObjHeader* %57 to i32*
-  %59 = load i32, i32* %58, align 8, !tbaa !18
+  %59 = load atomic i32, i32* %58 unordered, align 8, !tbaa !18
   %60 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %10, i64 0, i32 1, i32 5
-  %61 = load i64, i64* %49, align 8, !tbaa !9
+  %61 = load atomic i64, i64* %49 unordered, align 8, !tbaa !9
   %62 = bitcast %"class.kotlin::mm::ShadowStack"* %60 to i64*
   store i64 %61, i64* %62, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %42)
@@ -9413,7 +9489,7 @@
   %64 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %5, i64 0, i64 4
   %65 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %10, i64 0, i32 1, i32 6
   %66 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %65 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %67 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %66, align 8, !tbaa !3
+  %67 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %66 unordered, align 8, !tbaa !3
   %68 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %67, i64 0, i32 2, i32 1
   %69 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %68, i64 56) #37
   %70 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %69, i64 1
@@ -9432,7 +9508,7 @@
 AllocArrayInstance.exit.i:                        ; preds = %when_exit.i
   %76 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %10, i64 0, i32 1, i32 6
   %77 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %76 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %78 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %77, align 8, !tbaa !3
+  %78 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %77 unordered, align 8, !tbaa !3
   %79 = zext i32 %59 to i64
   %80 = shl nuw nsw i64 %79, 3
   %81 = add nuw nsw i64 %80, 31
@@ -9459,7 +9535,7 @@
   %94 = phi %struct.ObjHeader* [ %91, %AllocArrayInstance.exit.i ], [ %41, %Kotlin_mm_safePointFunctionPrologue.exit ]
   store %struct.ObjHeader* %94, %struct.ObjHeader** %8, align 8, !tbaa !3
   %95 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %10, i64 0, i32 1, i32 5
-  %96 = load i64, i64* %34, align 8, !tbaa !9
+  %96 = load atomic i64, i64* %34 unordered, align 8, !tbaa !9
   %97 = bitcast %"class.kotlin::mm::ShadowStack"* %95 to i64*
   store i64 %96, i64* %97, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 48, i8* nonnull %26)
@@ -9470,7 +9546,7 @@
   %99 = xor i32 %25, -1
   %100 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %94, i64 1
   %101 = bitcast %struct.ObjHeader* %100 to i32*
-  %102 = load i32, i32* %101, align 8, !tbaa !18
+  %102 = load atomic i32, i32* %101 unordered, align 8, !tbaa !18
   %103 = icmp ugt i32 %102, %99
   br i1 %103, label %call_success3, label %104
 
@@ -9483,7 +9559,7 @@
   %106 = sext i32 %99 to i64
   %107 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %105, i64 %106
   %108 = bitcast %struct.ObjHeader* %107 to %struct.ObjHeader**
-  %109 = load %struct.ObjHeader*, %struct.ObjHeader** %108, align 8, !tbaa !3
+  %109 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %108 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %109, %struct.ObjHeader** %9, align 8, !tbaa !3
   %110 = bitcast %struct.ObjHeader* %94 to i64*
   %111 = load atomic volatile i64, i64* %110 monotonic, align 8
@@ -9493,7 +9569,7 @@
 when_next:                                        ; preds = %call_success2
   %112 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %94, i64 1
   %113 = bitcast %struct.ObjHeader* %112 to i32*
-  %114 = load i32, i32* %113, align 8, !tbaa !18
+  %114 = load atomic i32, i32* %113 unordered, align 8, !tbaa !18
   %115 = icmp ugt i32 %114, %25
   br i1 %115, label %call_success5, label %116
 
@@ -9515,7 +9591,7 @@
   %123 = phi %struct.ObjHeader* [ %109, %call_success3 ], [ null, %call_success5 ]
   store %struct.ObjHeader* %123, %struct.ObjHeader** %3, align 8, !tbaa !3
   %124 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %10, i64 0, i32 1, i32 5
-  %125 = load i64, i64* %16, align 8, !tbaa !9
+  %125 = load atomic i64, i64* %16 unordered, align 8, !tbaa !9
   %126 = bitcast %"class.kotlin::mm::ShadowStack"* %124 to i64*
   store i64 %125, i64* %126, align 8, !tbaa !7
   ret %struct.ObjHeader* %123
@@ -9528,11 +9604,11 @@
   %4 = bitcast [5 x %struct.ObjHeader*]* %3 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %4, i8 0, i32 40, i1 immarg false) #49
   %5 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 4
-  %6 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %7 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
   %8 = bitcast [5 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %9 = bitcast %"class.kotlin::mm::ShadowStack"* %7 to i64*
-  %10 = load i64, i64* %9, align 8, !tbaa !7
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa !7
   %11 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %12 = bitcast %struct.ObjHeader** %11 to i64*
   store i64 %10, i64* %12, align 8, !tbaa !9
@@ -9561,7 +9637,7 @@
   %23 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 3
   %24 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %25 = bitcast %struct.ObjHeader* %24 to %struct.ObjHeader**
-  %26 = load %struct.ObjHeader*, %struct.ObjHeader** %25, align 8
+  %26 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %25 unordered, align 8
   store %struct.ObjHeader* %26, %struct.ObjHeader** %23, align 8, !tbaa !3
   %27 = icmp eq %struct.ObjHeader* %26, null
   br i1 %27, label %when_case1, label %when_exit2
@@ -9573,7 +9649,7 @@
 when_exit2:                                       ; preds = %when_exit
   %28 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %26, i64 1
   %29 = bitcast %struct.ObjHeader* %28 to i32*
-  %30 = load i32, i32* %29, align 8, !tbaa !18
+  %30 = load atomic i32, i32* %29 unordered, align 8, !tbaa !18
   %31 = icmp ugt i32 %30, %21
   br i1 %31, label %call_success6, label %32
 
@@ -9586,7 +9662,7 @@
   %34 = sext i32 %21 to i64
   %35 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %33, i64 %34
   %36 = bitcast %struct.ObjHeader* %35 to %struct.ObjHeader**
-  %37 = load %struct.ObjHeader*, %struct.ObjHeader** %36, align 8, !tbaa !3
+  %37 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %36 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %37, %struct.ObjHeader** %5, align 8, !tbaa !3
   call fastcc void @"kfun:kotlin.collections#resetAt__at__kotlin.Array<0:0>(kotlin.Int){0\C2\A7<kotlin.Any?>}"(%struct.ObjHeader* nonnull %26, i32 %21)
   br label %epilogue
@@ -9595,7 +9671,7 @@
   %38 = phi %struct.ObjHeader* [ %37, %call_success6 ], [ null, %Kotlin_mm_safePointFunctionPrologue.exit ]
   store %struct.ObjHeader* %38, %struct.ObjHeader** %2, align 8, !tbaa !3
   %39 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %40 = load i64, i64* %12, align 8, !tbaa !9
+  %40 = load atomic i64, i64* %12 unordered, align 8, !tbaa !9
   %41 = bitcast %"class.kotlin::mm::ShadowStack"* %39 to i64*
   store i64 %40, i64* %41, align 8, !tbaa !7
   ret %struct.ObjHeader* %38
@@ -9609,11 +9685,11 @@
   %3 = bitcast [5 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %3, i8 0, i32 40, i1 immarg false) #49
   %4 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 3
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %7 = bitcast [5 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %8 = bitcast %"class.kotlin::mm::ShadowStack"* %6 to i64*
-  %9 = load i64, i64* %8, align 8, !tbaa !7
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !7
   %10 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %11 = bitcast %struct.ObjHeader** %10 to i64*
   store i64 %9, i64* %11, align 8, !tbaa !9
@@ -9636,7 +9712,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %19, %entry
   %20 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 5
   %21 = bitcast %struct.ObjHeader* %20 to %struct.ObjHeader**
-  %22 = load %struct.ObjHeader*, %struct.ObjHeader** %21, align 8
+  %22 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %21 unordered, align 8
   store %struct.ObjHeader* %22, %struct.ObjHeader** %4, align 8, !tbaa !3
   %23 = icmp eq %struct.ObjHeader* %22, null
   br i1 %23, label %when_exit, label %epilogue
@@ -9645,7 +9721,7 @@
   %24 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 4
   %25 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 6
   %26 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %25 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %27 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %26, align 8, !tbaa !3
+  %27 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %26 unordered, align 8, !tbaa !3
   %28 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %27, i64 0, i32 2, i32 1
   %29 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %28, i64 24) #37
   %30 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %29, i64 1
@@ -9668,7 +9744,7 @@
   %39 = phi %struct.ObjHeader* [ %32, %when_exit ], [ %22, %Kotlin_mm_safePointFunctionPrologue.exit ]
   store %struct.ObjHeader* %39, %struct.ObjHeader** %1, align 8, !tbaa !3
   %40 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %41 = load i64, i64* %11, align 8, !tbaa !9
+  %41 = load atomic i64, i64* %11 unordered, align 8, !tbaa !9
   %42 = bitcast %"class.kotlin::mm::ShadowStack"* %40 to i64*
   store i64 %41, i64* %42, align 8, !tbaa !7
   ret %struct.ObjHeader* %39
@@ -9682,11 +9758,11 @@
   %3 = bitcast [5 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %3, i8 0, i32 40, i1 immarg false) #49
   %4 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 3
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %7 = bitcast [5 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %8 = bitcast %"class.kotlin::mm::ShadowStack"* %6 to i64*
-  %9 = load i64, i64* %8, align 8, !tbaa !7
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !7
   %10 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %11 = bitcast %struct.ObjHeader** %10 to i64*
   store i64 %9, i64* %11, align 8, !tbaa !9
@@ -9709,7 +9785,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %19, %entry
   %20 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 7
   %21 = bitcast %struct.ObjHeader* %20 to %struct.ObjHeader**
-  %22 = load %struct.ObjHeader*, %struct.ObjHeader** %21, align 8
+  %22 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %21 unordered, align 8
   store %struct.ObjHeader* %22, %struct.ObjHeader** %4, align 8, !tbaa !3
   %23 = icmp eq %struct.ObjHeader* %22, null
   br i1 %23, label %when_exit, label %epilogue
@@ -9718,7 +9794,7 @@
   %24 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 4
   %25 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 6
   %26 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %25 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %27 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %26, align 8, !tbaa !3
+  %27 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %26 unordered, align 8, !tbaa !3
   %28 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %27, i64 0, i32 2, i32 1
   %29 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %28, i64 24) #37
   %30 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %29, i64 1
@@ -9741,7 +9817,7 @@
   %39 = phi %struct.ObjHeader* [ %32, %when_exit ], [ %22, %Kotlin_mm_safePointFunctionPrologue.exit ]
   store %struct.ObjHeader* %39, %struct.ObjHeader** %1, align 8, !tbaa !3
   %40 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %41 = load i64, i64* %11, align 8, !tbaa !9
+  %41 = load atomic i64, i64* %11 unordered, align 8, !tbaa !9
   %42 = bitcast %"class.kotlin::mm::ShadowStack"* %40 to i64*
   store i64 %41, i64* %42, align 8, !tbaa !7
   ret %struct.ObjHeader* %39
@@ -9776,13 +9852,13 @@
   %14 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %13, i64 0, i32 0
   %15 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %14 monotonic, align 8
   %16 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %15, i64 0, i32 9
-  %17 = load i32, i32* %16, align 4
+  %17 = load atomic i32, i32* %16 unordered, align 4
   %18 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %15, i64 0, i32 10
-  %19 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %18, align 8
+  %19 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %18 unordered, align 8
   %20 = and i32 %17, 65
   %21 = zext i32 %20 to i64
   %22 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %19, i64 %21, i32 0
-  %23 = load i32, i32* %22, align 4
+  %23 = load atomic i32, i32* %22 unordered, align 4
   %24 = icmp eq i32 %23, 65
   br i1 %24, label %when_case1, label %epilogue
 
@@ -9791,11 +9867,11 @@
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %25)
   %.sub.i = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 0
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %25, i8 0, i32 32, i1 immarg false) #49
-  %26 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %26 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %27 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %26, i64 0, i32 1, i32 5
   %28 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %29 = bitcast %"class.kotlin::mm::ShadowStack"* %27 to i64*
-  %30 = load i64, i64* %29, align 8, !tbaa !7
+  %30 = load atomic i64, i64* %29 unordered, align 8, !tbaa !7
   %31 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %32 = bitcast %struct.ObjHeader** %31 to i64*
   store i64 %30, i64* %32, align 8, !tbaa !9
@@ -9808,7 +9884,7 @@
   store i32 4, i32* %36, align 4, !tbaa !13
   %37 = bitcast %struct.ObjHeader* %0 to %"kclassbody:kotlin.collections.HashMap#internal"*
   %38 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %37, i64 0, i32 11
-  %39 = load i32, i32* %38, align 4
+  %39 = load atomic i32, i32* %38 unordered, align 4
   %40 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %9 monotonic, align 8
   %41 = ptrtoint %struct.TypeInfo* %40 to i64
   %42 = and i64 %41, -4
@@ -9816,16 +9892,16 @@
   %44 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %43, i64 0, i32 0
   %45 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %44 monotonic, align 8
   %46 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %45, i64 0, i32 9
-  %47 = load i32, i32* %46, align 4
+  %47 = load atomic i32, i32* %46 unordered, align 4
   %48 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %45, i64 0, i32 10
-  %49 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %48, align 8
+  %49 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %48 unordered, align 8
   %50 = and i32 %47, 65
   %51 = zext i32 %50 to i64
   %52 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %49, i64 %51, i32 2
-  %53 = load i8**, i8*** %52, align 8
+  %53 = load atomic i8**, i8*** %52 unordered, align 8
   %54 = getelementptr i8*, i8** %53, i64 2
   %55 = bitcast i8** %54 to i32 (%struct.ObjHeader*)**
-  %56 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %55, align 8
+  %56 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %55 unordered, align 8
   %57 = call i32 %56(%struct.ObjHeader* nonnull %1)
   %58 = icmp eq i32 %39, %57
   br i1 %58, label %when_case.i, label %call_success
@@ -9839,24 +9915,24 @@
   %64 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %63, i64 0, i32 0
   %65 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %64 monotonic, align 8
   %66 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %65, i64 0, i32 9
-  %67 = load i32, i32* %66, align 4
+  %67 = load atomic i32, i32* %66 unordered, align 4
   %68 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %65, i64 0, i32 10
-  %69 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %68, align 8
+  %69 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %68 unordered, align 8
   %70 = and i32 %67, 65
   %71 = zext i32 %70 to i64
   %72 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %69, i64 %71, i32 2
   %73 = bitcast i8*** %72 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)***
-  %74 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %73, align 8
-  %75 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %74, align 8
+  %74 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %73 unordered, align 8
+  %75 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %74 unordered, align 8
   %76 = call %struct.ObjHeader* %75(%struct.ObjHeader* nonnull %1, %struct.ObjHeader** nonnull %59)
   %77 = call fastcc zeroext i1 @"kfun:kotlin.collections.HashMap#containsAllEntries(kotlin.collections.Collection<*>){}kotlin.Boolean"(%struct.ObjHeader* %0, %struct.ObjHeader* %76)
   br label %call_success
 
 call_success:                                     ; preds = %when_case.i, %when_case1
   %78 = phi i1 [ %77, %when_case.i ], [ false, %when_case1 ]
-  %79 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %79 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %80 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %79, i64 0, i32 1, i32 5
-  %81 = load i64, i64* %32, align 8, !tbaa !9
+  %81 = load atomic i64, i64* %32 unordered, align 8, !tbaa !9
   %82 = bitcast %"class.kotlin::mm::ShadowStack"* %80 to i64*
   store i64 %81, i64* %82, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %25)
@@ -9875,11 +9951,11 @@
   %3 = bitcast [4 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %3, i8 0, i32 32, i1 immarg false) #49
   %4 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 3
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %7 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %8 = bitcast %"class.kotlin::mm::ShadowStack"* %6 to i64*
-  %9 = load i64, i64* %8, align 8, !tbaa !7
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !7
   %10 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %11 = bitcast %struct.ObjHeader** %10 to i64*
   store i64 %9, i64* %11, align 8, !tbaa !9
@@ -9936,16 +10012,16 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(64) %25, i8 0, i32 64, i1 immarg false) #49
   %42 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %43 = bitcast %"class.kotlin::mm::ShadowStack"* %42 to i64*
-  %44 = load i64, i64* %43, align 8, !tbaa !7
+  %44 = load atomic i64, i64* %43 unordered, align 8, !tbaa !7
   store i64 %44, i64* %31, align 8, !tbaa !9
   %45 = bitcast %"class.kotlin::mm::ShadowStack"* %42 to %struct.ObjHeader***
   store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %45, align 8, !tbaa !7
   store i32 0, i32* %33, align 8, !tbaa !12
   store i32 8, i32* %34, align 4, !tbaa !13
-  %46 = load i32, i32* %22, align 4
-  %47 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %24, align 8
+  %46 = load atomic i32, i32* %22 unordered, align 4
+  %47 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %24 unordered, align 8
   %48 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %47, i64 0, i32 9
-  %49 = load i32, i32* %48, align 4
+  %49 = load atomic i32, i32* %48 unordered, align 4
   %.not.i = icmp slt i32 %46, %49
   br i1 %.not.i, label %when_exit.i, label %when_case.i
 
@@ -9953,7 +10029,7 @@
   %50 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %1, i64 0, i64 3
   %51 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 6
   %52 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %51 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %53 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %52, align 8, !tbaa !3
+  %53 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %52 unordered, align 8, !tbaa !3
   %54 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %53, i64 0, i32 2, i32 1
   %55 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %54, i64 56) #37
   %56 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %55, i64 1
@@ -9974,12 +10050,12 @@
   store i32 %62, i32* %22, align 4
   store i32 %46, i32* %37, align 4
   %63 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %47, i64 0, i32 1
-  %64 = load %struct.ObjHeader*, %struct.ObjHeader** %63, align 8
+  %64 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %63 unordered, align 8
   store %struct.ObjHeader* %64, %struct.ObjHeader** %35, align 8, !tbaa !3
-  %65 = load i32, i32* %37, align 4
+  %65 = load atomic i32, i32* %37 unordered, align 4
   %66 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %64, i64 1
   %67 = bitcast %struct.ObjHeader* %66 to i32*
-  %68 = load i32, i32* %67, align 8, !tbaa !18
+  %68 = load atomic i32, i32* %67 unordered, align 8, !tbaa !18
   %69 = icmp ugt i32 %68, %65
   br i1 %69, label %Kotlin_Array_get.exit.i, label %70
 
@@ -9992,7 +10068,7 @@
   %72 = sext i32 %65 to i64
   %73 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %71, i64 %72
   %74 = bitcast %struct.ObjHeader* %73 to %struct.ObjHeader**
-  %75 = load %struct.ObjHeader*, %struct.ObjHeader** %74, align 8, !tbaa !3
+  %75 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %74 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %75, %struct.ObjHeader** %26, align 8, !tbaa !3
   %76 = icmp eq %struct.ObjHeader* %75, null
   br i1 %76, label %when_exit4.i, label %when_next.i
@@ -10007,15 +10083,15 @@
   %83 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %82 monotonic, align 8
   %84 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %83, i64 1, i32 1
   %85 = bitcast %struct.ExtendedTypeInfo** %84 to i32 (%struct.ObjHeader*)**
-  %86 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %85, align 8
+  %86 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %85 unordered, align 8
   %87 = call i32 %86(%struct.ObjHeader* nonnull %75)
   br label %when_exit4.i
 
 when_exit4.i:                                     ; preds = %when_next.i, %Kotlin_Array_get.exit.i
   %88 = phi i32 [ %87, %when_next.i ], [ 0, %Kotlin_Array_get.exit.i ]
-  %89 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %24, align 8
+  %89 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %24 unordered, align 8
   %90 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %89, i64 0, i32 2
-  %91 = load %struct.ObjHeader*, %struct.ObjHeader** %90, align 8
+  %91 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %90 unordered, align 8
   store %struct.ObjHeader* %91, %struct.ObjHeader** %27, align 8, !tbaa !3
   %92 = icmp eq %struct.ObjHeader* %91, null
   br i1 %92, label %when_case6.i, label %when_exit7.i
@@ -10025,10 +10101,10 @@
   unreachable
 
 when_exit7.i:                                     ; preds = %when_exit4.i
-  %93 = load i32, i32* %37, align 4
+  %93 = load atomic i32, i32* %37 unordered, align 4
   %94 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %91, i64 1
   %95 = bitcast %struct.ObjHeader* %94 to i32*
-  %96 = load i32, i32* %95, align 8, !tbaa !18
+  %96 = load atomic i32, i32* %95 unordered, align 8, !tbaa !18
   %97 = icmp ugt i32 %96, %93
   br i1 %97, label %Kotlin_Array_get.exit21.i, label %98
 
@@ -10041,7 +10117,7 @@
   %100 = sext i32 %93 to i64
   %101 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %99, i64 %100
   %102 = bitcast %struct.ObjHeader* %101 to %struct.ObjHeader**
-  %103 = load %struct.ObjHeader*, %struct.ObjHeader** %102, align 8, !tbaa !3
+  %103 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %102 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %103, %struct.ObjHeader** %28, align 8, !tbaa !3
   %104 = icmp eq %struct.ObjHeader* %103, null
   br i1 %104, label %call_success2, label %when_next13.i
@@ -10056,7 +10132,7 @@
   %111 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %110 monotonic, align 8
   %112 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %111, i64 1, i32 1
   %113 = bitcast %struct.ExtendedTypeInfo** %112 to i32 (%struct.ObjHeader*)**
-  %114 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %113, align 8
+  %114 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %113 unordered, align 8
   %115 = call i32 %114(%struct.ObjHeader* nonnull %103)
   br label %call_success2
 
@@ -10064,7 +10140,7 @@
   %116 = phi i32 [ %115, %when_next13.i ], [ 0, %Kotlin_Array_get.exit21.i ]
   call fastcc void @"kfun:kotlin.collections.HashMap.Itr#initNext(){}"(%struct.ObjHeader* nonnull %20)
   %117 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %118 = load i64, i64* %31, align 8, !tbaa !9
+  %118 = load atomic i64, i64* %31 unordered, align 8, !tbaa !9
   %119 = bitcast %"class.kotlin::mm::ShadowStack"* %117 to i64*
   store i64 %118, i64* %119, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %25)
@@ -10074,16 +10150,16 @@
 
 call_success1:                                    ; preds = %call_success2, %Kotlin_mm_safePointFunctionPrologue.exit
   %result.0 = phi i32 [ 0, %Kotlin_mm_safePointFunctionPrologue.exit ], [ %121, %call_success2 ]
-  %122 = load i32, i32* %22, align 4
-  %123 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %24, align 8
+  %122 = load atomic i32, i32* %22 unordered, align 4
+  %123 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %24 unordered, align 8
   %124 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %123, i64 0, i32 9
-  %125 = load i32, i32* %124, align 4
+  %125 = load atomic i32, i32* %124 unordered, align 4
   %126 = icmp slt i32 %122, %125
   br i1 %126, label %while_loop, label %epilogue
 
 epilogue:                                         ; preds = %call_success1
   %127 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %128 = load i64, i64* %11, align 8, !tbaa !9
+  %128 = load atomic i64, i64* %11 unordered, align 8, !tbaa !9
   %129 = bitcast %"class.kotlin::mm::ShadowStack"* %127 to i64*
   store i64 %128, i64* %129, align 8, !tbaa !7
   ret i32 %result.0
@@ -10107,11 +10183,11 @@
   %objHeader = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %9, i64 0, i32 0
   %typeInfoOrMeta_ = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %9, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_, align 8
-  %12 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %12 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %13 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %14 = bitcast [8 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %15 = bitcast %"class.kotlin::mm::ShadowStack"* %13 to i64*
-  %16 = load i64, i64* %15, align 8, !tbaa !7
+  %16 = load atomic i64, i64* %15 unordered, align 8, !tbaa !7
   %17 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %18 = bitcast %struct.ObjHeader** %17 to i64*
   store i64 %16, i64* %18, align 8, !tbaa !9
@@ -10134,7 +10210,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %26, %call_success2
   %27 = bitcast %struct.ObjHeader* %0 to %"kclassbody:kotlin.collections.HashMap#internal"*
   %28 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %27, i64 0, i32 11
-  %29 = load i32, i32* %28, align 4
+  %29 = load atomic i32, i32* %28 unordered, align 4
   %30 = mul i32 %29, 3
   %31 = add i32 %30, 2
   store %struct.ObjHeader* %objHeader, %struct.ObjHeader** %5, align 8, !tbaa !3
@@ -10192,16 +10268,16 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(120) %38, i8 0, i32 120, i1 immarg false) #49
   %65 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %66 = bitcast %"class.kotlin::mm::ShadowStack"* %65 to i64*
-  %67 = load i64, i64* %66, align 8, !tbaa !7
+  %67 = load atomic i64, i64* %66 unordered, align 8, !tbaa !7
   store i64 %67, i64* %51, align 8, !tbaa !9
   %68 = bitcast %"class.kotlin::mm::ShadowStack"* %65 to %struct.ObjHeader***
   store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %68, align 8, !tbaa !7
   store i32 0, i32* %53, align 8, !tbaa !12
   store i32 15, i32* %54, align 4, !tbaa !13
-  %69 = load i32, i32* %35, align 4
-  %70 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %37, align 8
+  %69 = load atomic i32, i32* %35 unordered, align 4
+  %70 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %37 unordered, align 8
   %71 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %70, i64 0, i32 9
-  %72 = load i32, i32* %71, align 4
+  %72 = load atomic i32, i32* %71 unordered, align 4
   %.not.i = icmp slt i32 %69, %72
   br i1 %.not.i, label %when_exit.i, label %when_case.i
 
@@ -10209,7 +10285,7 @@
   %73 = getelementptr inbounds [15 x %struct.ObjHeader*], [15 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %74 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 6
   %75 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %74 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %76 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %75, align 8, !tbaa !3
+  %76 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %75 unordered, align 8, !tbaa !3
   %77 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %76, i64 0, i32 2, i32 1
   %78 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %77, i64 56) #37
   %79 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %78, i64 1
@@ -10230,12 +10306,12 @@
   store i32 %85, i32* %35, align 4
   store i32 %69, i32* %57, align 4
   %86 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %70, i64 0, i32 1
-  %87 = load %struct.ObjHeader*, %struct.ObjHeader** %86, align 8
+  %87 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %86 unordered, align 8
   store %struct.ObjHeader* %87, %struct.ObjHeader** %55, align 8, !tbaa !3
-  %88 = load i32, i32* %57, align 4
+  %88 = load atomic i32, i32* %57 unordered, align 4
   %89 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %87, i64 1
   %90 = bitcast %struct.ObjHeader* %89 to i32*
-  %91 = load i32, i32* %90, align 8, !tbaa !18
+  %91 = load atomic i32, i32* %90 unordered, align 8, !tbaa !18
   %92 = icmp ugt i32 %91, %88
   br i1 %92, label %Kotlin_Array_get.exit.i, label %93
 
@@ -10248,13 +10324,13 @@
   %95 = sext i32 %88 to i64
   %96 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %94, i64 %95
   %97 = bitcast %struct.ObjHeader* %96 to %struct.ObjHeader**
-  %98 = load %struct.ObjHeader*, %struct.ObjHeader** %97, align 8, !tbaa !3
+  %98 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %97 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %98, %struct.ObjHeader** %39, align 8, !tbaa !3
   %.not37.i = icmp eq %struct.ObjHeader* %98, null
   br i1 %.not37.i, label %when_exit12.i, label %when_exit7.i
 
 when_exit7.i:                                     ; preds = %Kotlin_Array_get.exit.i
-  %99 = load %struct.ObjHeader*, %struct.ObjHeader** %58, align 8
+  %99 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %58 unordered, align 8
   %100 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %98, i64 0, i32 0
   %101 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %100 monotonic, align 8
   %102 = ptrtoint %struct.TypeInfo* %101 to i64
@@ -10264,7 +10340,7 @@
   %106 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %105 monotonic, align 8
   %107 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %106, i64 1
   %108 = bitcast %struct.TypeInfo* %107 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
-  %109 = load i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %108, align 8
+  %109 = load atomic i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %108 unordered, align 8
   %110 = call zeroext i1 %109(%struct.ObjHeader* nonnull %98, %struct.ObjHeader* %99)
   br i1 %110, label %when_case3.i, label %when_next11.i
 
@@ -10281,7 +10357,7 @@
   %117 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %116 monotonic, align 8
   %118 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %117, i64 1, i32 2
   %119 = bitcast i32* %118 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %120 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %119, align 8
+  %120 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %119 unordered, align 8
   %121 = call %struct.ObjHeader* %120(%struct.ObjHeader* nonnull %98, %struct.ObjHeader** nonnull %41)
   br label %when_exit12.i
 
@@ -10292,9 +10368,9 @@
 
 when_exit9.i:                                     ; preds = %when_exit12.i, %when_case3.i
   %124 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.Char){}kotlin.text.StringBuilder"(%struct.ObjHeader* nonnull %objHeader, i16 zeroext 61, %struct.ObjHeader** nonnull %43)
-  %125 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %37, align 8
+  %125 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %37 unordered, align 8
   %126 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %125, i64 0, i32 2
-  %127 = load %struct.ObjHeader*, %struct.ObjHeader** %126, align 8
+  %127 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %126 unordered, align 8
   store %struct.ObjHeader* %127, %struct.ObjHeader** %44, align 8, !tbaa !3
   %128 = icmp eq %struct.ObjHeader* %127, null
   br i1 %128, label %when_case16.i, label %when_exit17.i
@@ -10304,10 +10380,10 @@
   unreachable
 
 when_exit17.i:                                    ; preds = %when_exit9.i
-  %129 = load i32, i32* %57, align 4
+  %129 = load atomic i32, i32* %57 unordered, align 4
   %130 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %127, i64 1
   %131 = bitcast %struct.ObjHeader* %130 to i32*
-  %132 = load i32, i32* %131, align 8, !tbaa !18
+  %132 = load atomic i32, i32* %131 unordered, align 8, !tbaa !18
   %133 = icmp ugt i32 %132, %129
   br i1 %133, label %Kotlin_Array_get.exit39.i, label %134
 
@@ -10320,13 +10396,13 @@
   %136 = sext i32 %129 to i64
   %137 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %135, i64 %136
   %138 = bitcast %struct.ObjHeader* %137 to %struct.ObjHeader**
-  %139 = load %struct.ObjHeader*, %struct.ObjHeader** %138, align 8, !tbaa !3
+  %139 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %138 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %139, %struct.ObjHeader** %45, align 8, !tbaa !3
   %.not38.i = icmp eq %struct.ObjHeader* %139, null
   br i1 %.not38.i, label %when_exit31.i, label %when_exit26.i
 
 when_exit26.i:                                    ; preds = %Kotlin_Array_get.exit39.i
-  %140 = load %struct.ObjHeader*, %struct.ObjHeader** %58, align 8
+  %140 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %58 unordered, align 8
   %141 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %139, i64 0, i32 0
   %142 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %141 monotonic, align 8
   %143 = ptrtoint %struct.TypeInfo* %142 to i64
@@ -10336,7 +10412,7 @@
   %147 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %146 monotonic, align 8
   %148 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %147, i64 1
   %149 = bitcast %struct.TypeInfo* %148 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
-  %150 = load i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %149, align 8
+  %150 = load atomic i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %149 unordered, align 8
   %151 = call zeroext i1 %150(%struct.ObjHeader* nonnull %139, %struct.ObjHeader* %140)
   br i1 %151, label %when_case21.i, label %when_next30.i
 
@@ -10353,7 +10429,7 @@
   %158 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %157 monotonic, align 8
   %159 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %158, i64 1, i32 2
   %160 = bitcast i32* %159 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %161 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %160, align 8
+  %161 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %160 unordered, align 8
   %162 = call %struct.ObjHeader* %161(%struct.ObjHeader* nonnull %139, %struct.ObjHeader** nonnull %47)
   br label %when_exit31.i
 
@@ -10365,7 +10441,7 @@
 call_success5:                                    ; preds = %when_exit31.i, %when_case21.i
   call fastcc void @"kfun:kotlin.collections.HashMap.Itr#initNext(){}"(%struct.ObjHeader* nonnull %33)
   %165 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %166 = load i64, i64* %51, align 8, !tbaa !9
+  %166 = load atomic i64, i64* %51 unordered, align 8, !tbaa !9
   %167 = bitcast %"class.kotlin::mm::ShadowStack"* %165 to i64*
   store i64 %166, i64* %167, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 120, i8* nonnull %38)
@@ -10374,10 +10450,10 @@
 
 call_success3:                                    ; preds = %call_success5, %Kotlin_mm_safePointFunctionPrologue.exit
   %i.0 = phi i32 [ 0, %Kotlin_mm_safePointFunctionPrologue.exit ], [ %168, %call_success5 ]
-  %169 = load i32, i32* %35, align 4
-  %170 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %37, align 8
+  %169 = load atomic i32, i32* %35 unordered, align 4
+  %170 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %37 unordered, align 8
   %171 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %170, i64 0, i32 9
-  %172 = load i32, i32* %171, align 4
+  %172 = load atomic i32, i32* %171 unordered, align 4
   %173 = icmp slt i32 %169, %172
   br i1 %173, label %while_loop, label %epilogue
 
@@ -10387,7 +10463,7 @@
   %176 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#toString(){}kotlin.String"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader** %1)
   store %struct.ObjHeader* %176, %struct.ObjHeader** %1, align 8, !tbaa !3
   %177 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %178 = load i64, i64* %18, align 8, !tbaa !9
+  %178 = load atomic i64, i64* %18 unordered, align 8, !tbaa !9
   %179 = bitcast %"class.kotlin::mm::ShadowStack"* %177 to i64*
   store i64 %178, i64* %179, align 8, !tbaa !7
   ret %struct.ObjHeader* %176
@@ -10399,11 +10475,11 @@
   %.sub = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 0
   %2 = bitcast [4 x %struct.ObjHeader*]* %1 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %2, i8 0, i32 32, i1 immarg false) #49
-  %3 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %3 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %4 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 5
   %5 = bitcast [4 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
   %6 = bitcast %"class.kotlin::mm::ShadowStack"* %4 to i64*
-  %7 = load i64, i64* %6, align 8, !tbaa !7
+  %7 = load atomic i64, i64* %6 unordered, align 8, !tbaa !7
   %8 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 1
   %9 = bitcast %struct.ObjHeader** %8 to i64*
   store i64 %7, i64* %9, align 8, !tbaa !9
@@ -10433,7 +10509,7 @@
   %21 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 3
   %22 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 6
   %23 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %22 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %24 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %23, align 8, !tbaa !3
+  %24 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %23 unordered, align 8, !tbaa !3
   %25 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %24, i64 0, i32 2, i32 1
   %26 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %25, i64 56) #37
   %27 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %26, i64 1
@@ -10451,7 +10527,7 @@
 
 epilogue:                                         ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
   %33 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 5
-  %34 = load i64, i64* %9, align 8, !tbaa !9
+  %34 = load atomic i64, i64* %9 unordered, align 8, !tbaa !9
   %35 = bitcast %"class.kotlin::mm::ShadowStack"* %33 to i64*
   store i64 %34, i64* %35, align 8, !tbaa !7
   ret void
@@ -10468,11 +10544,11 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(48) %6, i8 0, i32 48, i1 immarg false) #49
   %7 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %5, i64 0, i64 3
   %8 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %5, i64 0, i64 4
-  %9 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %9 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %10 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
   %11 = bitcast [6 x %struct.ObjHeader*]* %5 to %struct.FrameOverlay.6*
   %12 = bitcast %"class.kotlin::mm::ShadowStack"* %10 to i64*
-  %13 = load i64, i64* %12, align 8, !tbaa !7
+  %13 = load atomic i64, i64* %12 unordered, align 8, !tbaa !7
   %14 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %5, i64 0, i64 1
   %15 = bitcast %struct.ObjHeader** %14 to i64*
   store i64 %13, i64* %15, align 8, !tbaa !9
@@ -10495,16 +10571,13 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %23, %entry
   %24 = bitcast %struct.ObjHeader* %0 to %"kclassbody:kotlin.collections.HashMap#internal"*
   %25 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %24, i64 0, i32 9
-  %26 = load i32, i32* %25, align 4
+  %26 = load atomic i32, i32* %25 unordered, align 4
   %27 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %24, i64 0, i32 11
-  %28 = load i32, i32* %27, align 4
+  %28 = load atomic i32, i32* %27 unordered, align 4
   %29 = icmp sgt i32 %26, %28
   br i1 %29, label %when_case, label %entry.call_success2_crit_edge
 
 entry.call_success2_crit_edge:                    ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
-  %.phi.trans.insert = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
-  %.phi.trans.insert34 = bitcast %"class.kotlin::mm::ShadowStack"* %.phi.trans.insert to i64*
-  %.pre35 = load i64, i64* %.phi.trans.insert34, align 8, !tbaa !7
   br label %call_success2
 
 when_case:                                        ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
@@ -10522,7 +10595,7 @@
   %38 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
   %39 = bitcast [10 x %struct.ObjHeader*]* %4 to %struct.FrameOverlay.6*
   %40 = bitcast %"class.kotlin::mm::ShadowStack"* %38 to i64*
-  %41 = load i64, i64* %40, align 8, !tbaa !7
+  %41 = load atomic i64, i64* %40 unordered, align 8, !tbaa !7
   %42 = getelementptr inbounds [10 x %struct.ObjHeader*], [10 x %struct.ObjHeader*]* %4, i64 0, i64 1
   %43 = bitcast %struct.ObjHeader** %42 to i64*
   store i64 %41, i64* %43, align 8, !tbaa !9
@@ -10535,7 +10608,7 @@
   store i32 10, i32* %47, align 4, !tbaa !13
   %48 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %49 = bitcast %struct.ObjHeader* %48 to %struct.ObjHeader**
-  %50 = load %struct.ObjHeader*, %struct.ObjHeader** %49, align 8
+  %50 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %49 unordered, align 8
   store %struct.ObjHeader* %50, %struct.ObjHeader** %31, align 8, !tbaa !3
   %51 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 3
   %52 = bitcast %struct.ObjHeader* %51 to %struct.ObjHeader**
@@ -10561,13 +10634,13 @@
   br label %Kotlin_mm_safePointWhileLoopBody.exit.i
 
 Kotlin_mm_safePointWhileLoopBody.exit.i:          ; preds = %64, %while_loop.i
-  %65 = load %struct.ObjHeader*, %struct.ObjHeader** %52, align 8
+  %65 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %52 unordered, align 8
   store %struct.ObjHeader* %65, %struct.ObjHeader** %32, align 8, !tbaa !3
   %66 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %65, i64 1
   %67 = bitcast %struct.ObjHeader* %66 to i32*
-  %68 = load i32, i32* %67, align 8, !tbaa !18
+  %68 = load atomic i32, i32* %67 unordered, align 8, !tbaa !18
   %69 = zext i32 %68 to i64
-  %70 = icmp ult i64 %indvars.iv54, %69
+  %70 = icmp ult i64 %indvars.iv52, %69
   br i1 %70, label %Kotlin_IntArray_get.exit.i, label %71
 
 71:                                               ; preds = %Kotlin_mm_safePointWhileLoopBody.exit.i
@@ -10577,20 +10650,20 @@
 Kotlin_IntArray_get.exit.i:                       ; preds = %Kotlin_mm_safePointWhileLoopBody.exit.i
   %72 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %65, i64 2
   %73 = bitcast %struct.ObjHeader* %72 to i32*
-  %74 = getelementptr inbounds i32, i32* %73, i64 %indvars.iv54
-  %75 = load i32, i32* %74, align 4, !tbaa !73
+  %74 = getelementptr inbounds i32, i32* %73, i64 %indvars.iv52
+  %75 = load atomic i32, i32* %74 unordered, align 4, !tbaa !71
   %76 = icmp sgt i32 %75, -1
   br i1 %76, label %when_case.i, label %when_exit.i
 
 when_case.i:                                      ; preds = %Kotlin_IntArray_get.exit.i
-  %77 = load %struct.ObjHeader*, %struct.ObjHeader** %54, align 8
+  %77 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %54 unordered, align 8
   store %struct.ObjHeader* %77, %struct.ObjHeader** %33, align 8, !tbaa !3
   store %struct.ObjHeader* %77, %struct.ObjHeader** %34, align 8, !tbaa !3
   %78 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %77, i64 1
   %79 = bitcast %struct.ObjHeader* %78 to i32*
-  %80 = load i32, i32* %79, align 8, !tbaa !18
+  %80 = load atomic i32, i32* %79 unordered, align 8, !tbaa !18
   %81 = zext i32 %80 to i64
-  %82 = icmp ult i64 %indvars.iv54, %81
+  %82 = icmp ult i64 %indvars.iv52, %81
   br i1 %82, label %Kotlin_Array_get.exit12.i, label %83
 
 83:                                               ; preds = %when_case.i
@@ -10599,9 +10672,9 @@
 
 Kotlin_Array_get.exit12.i:                        ; preds = %when_case.i
   %84 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %77, i64 2
-  %85 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %84, i64 %indvars.iv54
+  %85 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %84, i64 %indvars.iv52
   %86 = bitcast %struct.ObjHeader* %85 to i64*
-  %87 = load i64, i64* %86, align 8, !tbaa !3
+  %87 = load atomic i64, i64* %86 unordered, align 8, !tbaa !3
   store i64 %87, i64* %55, align 8, !tbaa !3
   %88 = icmp ugt i32 %80, %j.1.i
   br i1 %88, label %Kotlin_Array_set.exit11.i, label %89
@@ -10620,9 +10693,9 @@
   br i1 %.not.i, label %when_exit4.i, label %when_case3.i
 
 when_case3.i:                                     ; preds = %Kotlin_Array_set.exit11.i
-  %95 = load i32, i32* %57, align 8, !tbaa !18
+  %95 = load atomic i32, i32* %57 unordered, align 8, !tbaa !18
   %96 = zext i32 %95 to i64
-  %97 = icmp ult i64 %indvars.iv54, %96
+  %97 = icmp ult i64 %indvars.iv52, %96
   br i1 %97, label %Kotlin_Array_get.exit.i, label %98
 
 98:                                               ; preds = %when_case3.i
@@ -10630,9 +10703,9 @@
   unreachable
 
 Kotlin_Array_get.exit.i:                          ; preds = %when_case3.i
-  %99 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %58, i64 %indvars.iv54
+  %99 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %58, i64 %indvars.iv52
   %100 = bitcast %struct.ObjHeader* %99 to i64*
-  %101 = load i64, i64* %100, align 8, !tbaa !3
+  %101 = load atomic i64, i64* %100 unordered, align 8, !tbaa !3
   store i64 %101, i64* %59, align 8, !tbaa !3
   %102 = icmp ugt i32 %95, %j.1.i
   br i1 %102, label %Kotlin_Array_set.exit.i, label %103
@@ -10654,470 +10727,472 @@
 
 when_exit.i:                                      ; preds = %when_exit4.i, %Kotlin_IntArray_get.exit.i
   %j.0.i = phi i32 [ %107, %when_exit4.i ], [ %j.1.i, %Kotlin_IntArray_get.exit.i ]
-  %indvars.iv.next55 = add nuw nsw i64 %indvars.iv54, 1
+  %indvars.iv.next53 = add nuw nsw i64 %indvars.iv52, 1
   br label %loop_check.i
 
 loop_check.i:                                     ; preds = %when_exit.i, %when_case
-  %indvars.iv54 = phi i64 [ %indvars.iv.next55, %when_exit.i ], [ 0, %when_case ]
+  %indvars.iv52 = phi i64 [ %indvars.iv.next53, %when_exit.i ], [ 0, %when_case ]
   %j.1.i = phi i32 [ %j.0.i, %when_exit.i ], [ 0, %when_case ]
-  %108 = load i32, i32* %25, align 4
+  %108 = load atomic i32, i32* %25 unordered, align 4
   %109 = sext i32 %108 to i64
-  %110 = icmp slt i64 %indvars.iv54, %109
+  %110 = icmp slt i64 %indvars.iv52, %109
   br i1 %110, label %while_loop.i, label %loop_exit.i
 
 loop_exit.i:                                      ; preds = %loop_check.i
-  %111 = load %struct.ObjHeader*, %struct.ObjHeader** %54, align 8
+  %111 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %54 unordered, align 8
   store %struct.ObjHeader* %111, %struct.ObjHeader** %37, align 8, !tbaa !3
   call fastcc void @"kfun:kotlin.collections#resetRange__at__kotlin.Array<0:0>(kotlin.Int;kotlin.Int){0\C2\A7<kotlin.Any?>}"(%struct.ObjHeader* %111, i32 %j.1.i, i32 %108)
   br i1 %.not.i, label %call_success, label %when_next.i
 
 when_next.i:                                      ; preds = %loop_exit.i
-  %112 = load i32, i32* %25, align 4
+  %112 = load atomic i32, i32* %25 unordered, align 4
   call fastcc void @"kfun:kotlin.collections#resetRange__at__kotlin.Array<0:0>(kotlin.Int;kotlin.Int){0\C2\A7<kotlin.Any?>}"(%struct.ObjHeader* nonnull %50, i32 %j.1.i, i32 %112)
   br label %call_success
 
 call_success:                                     ; preds = %when_next.i, %loop_exit.i
   store i32 %j.1.i, i32* %25, align 4
   %113 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
-  %114 = load i64, i64* %43, align 8, !tbaa !9
+  %114 = load atomic i64, i64* %43 unordered, align 8, !tbaa !9
   %115 = bitcast %"class.kotlin::mm::ShadowStack"* %113 to i64*
   store i64 %114, i64* %115, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %30)
   br label %call_success2
 
 call_success2:                                    ; preds = %call_success, %entry.call_success2_crit_edge
-  %116 = phi i64 [ %.pre35, %entry.call_success2_crit_edge ], [ %114, %call_success ]
-  %117 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %9, %entry.call_success2_crit_edge ], [ %9, %call_success ]
-  %118 = bitcast [4 x %struct.ObjHeader*]* %3 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %118)
+  %116 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %9, %entry.call_success2_crit_edge ], [ %9, %call_success ]
+  %117 = bitcast [4 x %struct.ObjHeader*]* %3 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %117)
   %.sub.i14 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 0
-  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %118, i8 0, i32 32, i1 immarg false) #49
-  %119 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 3
-  %120 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %117, i64 0, i32 1, i32 5
-  %121 = bitcast [4 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
-  %122 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 1
-  %123 = bitcast %struct.ObjHeader** %122 to i64*
-  store i64 %116, i64* %123, align 8, !tbaa !9
-  %124 = bitcast %"class.kotlin::mm::ShadowStack"* %120 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i14, %struct.ObjHeader*** %124, align 8, !tbaa !7
-  %125 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 2
-  %126 = bitcast %struct.ObjHeader** %125 to i32*
-  store i32 0, i32* %126, align 8, !tbaa !12
-  %127 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %121, i64 0, i32 3
-  store i32 4, i32* %127, align 4, !tbaa !13
-  %128 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 4
-  %129 = bitcast %struct.ObjHeader* %128 to %struct.ObjHeader**
-  %130 = load %struct.ObjHeader*, %struct.ObjHeader** %129, align 8
-  store %struct.ObjHeader* %130, %struct.ObjHeader** %119, align 8, !tbaa !3
-  %131 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %130, i64 1
-  %132 = bitcast %struct.ObjHeader* %131 to i32*
-  %133 = load i32, i32* %132, align 8, !tbaa !18
-  %134 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
-  %135 = load i64, i64* %123, align 8, !tbaa !9
-  %136 = bitcast %"class.kotlin::mm::ShadowStack"* %134 to i64*
-  store i64 %135, i64* %136, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %118)
-  %.not = icmp eq i32 %133, %1
+  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %117, i8 0, i32 32, i1 immarg false) #49
+  %118 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 3
+  %119 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %116, i64 0, i32 1, i32 5
+  %120 = bitcast [4 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
+  %121 = bitcast %"class.kotlin::mm::ShadowStack"* %119 to i64*
+  %122 = load atomic i64, i64* %121 unordered, align 8, !tbaa !7
+  %123 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 1
+  %124 = bitcast %struct.ObjHeader** %123 to i64*
+  store i64 %122, i64* %124, align 8, !tbaa !9
+  %125 = bitcast %"class.kotlin::mm::ShadowStack"* %119 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i14, %struct.ObjHeader*** %125, align 8, !tbaa !7
+  %126 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 2
+  %127 = bitcast %struct.ObjHeader** %126 to i32*
+  store i32 0, i32* %127, align 8, !tbaa !12
+  %128 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %120, i64 0, i32 3
+  store i32 4, i32* %128, align 4, !tbaa !13
+  %129 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 4
+  %130 = bitcast %struct.ObjHeader* %129 to %struct.ObjHeader**
+  %131 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %130 unordered, align 8
+  store %struct.ObjHeader* %131, %struct.ObjHeader** %118, align 8, !tbaa !3
+  %132 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %131, i64 1
+  %133 = bitcast %struct.ObjHeader* %132 to i32*
+  %134 = load atomic i32, i32* %133 unordered, align 8, !tbaa !18
+  %135 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
+  %136 = load atomic i64, i64* %124 unordered, align 8, !tbaa !9
+  %137 = bitcast %"class.kotlin::mm::ShadowStack"* %135 to i64*
+  store i64 %136, i64* %137, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %117)
+  %.not = icmp eq i32 %134, %1
   br i1 %.not, label %call_success7, label %when_case1
 
 when_case1:                                       ; preds = %call_success2
-  %137 = icmp slt i32 %1, 0
-  br i1 %137, label %138, label %call_success4
+  %138 = icmp slt i32 %1, 0
+  br i1 %138, label %139, label %call_success4
 
-138:                                              ; preds = %when_case1
+139:                                              ; preds = %when_case1
   call fastcc void @ThrowIllegalArgumentException() #50
   unreachable
 
 call_success4:                                    ; preds = %when_case1
-  %139 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 6
-  %140 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %139 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %141 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %140, align 8, !tbaa !3
-  %142 = zext i32 %1 to i64
-  %143 = shl nuw nsw i64 %142, 2
-  %144 = add nuw nsw i64 %143, 31
-  %145 = and i64 %144, 34359738360
-  %146 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %141, i64 0, i32 2, i32 1
-  %147 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %146, i64 %145) #37
-  %148 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %147, i64 1
-  %149 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %147, i64 2
-  %150 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %149 to %struct.TypeInfo**
-  %151 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %148 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %151, i8 0, i64 24, i1 false) #37
-  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [3 x i8*] }, { %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.IntArray#internal", i64 0, i32 0), %struct.TypeInfo** %150, align 8, !tbaa !16
-  %152 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %147, i64 3
-  %153 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %152 to i32*
-  store i32 %1, i32* %153, align 8, !tbaa !18
-  %154 = bitcast %struct.ObjHeader** %7 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %149, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %154, align 8, !tbaa !3
-  %155 = bitcast %struct.ObjHeader* %128 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %149, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %155, align 8, !tbaa !3
-  %156 = icmp eq i32 %1, 0
-  %157 = call i32 @llvm.ctlz.i32(i32 %1, i1 true) #37, !range !31
-  %phi.bo = add nuw nsw i32 %157, 1
-  %158 = select i1 %156, i32 33, i32 %phi.bo
-  %159 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 9
-  %160 = bitcast %struct.ObjHeader* %159 to i32*
-  store i32 %158, i32* %160, align 4
+  %140 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 6
+  %141 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %140 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
+  %142 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %141 unordered, align 8, !tbaa !3
+  %143 = zext i32 %1 to i64
+  %144 = shl nuw nsw i64 %143, 2
+  %145 = add nuw nsw i64 %144, 31
+  %146 = and i64 %145, 34359738360
+  %147 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %142, i64 0, i32 2, i32 1
+  %148 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %147, i64 %146) #37
+  %149 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %148, i64 1
+  %150 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %148, i64 2
+  %151 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %150 to %struct.TypeInfo**
+  %152 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %149 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %152, i8 0, i64 24, i1 false) #37
+  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [3 x i8*] }, { %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.IntArray#internal", i64 0, i32 0), %struct.TypeInfo** %151, align 8, !tbaa !16
+  %153 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %148, i64 3
+  %154 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %153 to i32*
+  store i32 %1, i32* %154, align 8, !tbaa !18
+  %155 = bitcast %struct.ObjHeader** %7 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %150, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %155, align 8, !tbaa !3
+  %156 = bitcast %struct.ObjHeader* %129 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %150, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %156, align 8, !tbaa !3
+  %157 = icmp eq i32 %1, 0
+  %158 = call i32 @llvm.ctlz.i32(i32 %1, i1 true) #37, !range !23
+  %phi.bo = add nuw nsw i32 %158, 1
+  %159 = select i1 %157, i32 33, i32 %phi.bo
+  %160 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 9
+  %161 = bitcast %struct.ObjHeader* %160 to i32*
+  store i32 %159, i32* %161, align 4
   br label %when_exit6
 
 call_success7:                                    ; preds = %call_success2
-  %161 = load %struct.ObjHeader*, %struct.ObjHeader** %129, align 8
-  store %struct.ObjHeader* %161, %struct.ObjHeader** %8, align 8, !tbaa !3
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %118)
-  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %118, i8 0, i32 32, i1 immarg false) #49
-  store i64 %135, i64* %123, align 8, !tbaa !9
-  %162 = bitcast %"class.kotlin::mm::ShadowStack"* %134 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i14, %struct.ObjHeader*** %162, align 8, !tbaa !7
-  store i32 0, i32* %126, align 8, !tbaa !12
-  store i32 4, i32* %127, align 4, !tbaa !13
-  %163 = load %struct.ObjHeader*, %struct.ObjHeader** %129, align 8
-  store %struct.ObjHeader* %163, %struct.ObjHeader** %119, align 8, !tbaa !3
-  %164 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %163, i64 1
-  %165 = bitcast %struct.ObjHeader* %164 to i32*
-  %166 = load i32, i32* %165, align 8, !tbaa !18
-  %167 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
-  %168 = load i64, i64* %123, align 8, !tbaa !9
-  %169 = bitcast %"class.kotlin::mm::ShadowStack"* %167 to i64*
-  store i64 %168, i64* %169, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %118)
-  %170 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %161, i64 1
-  %171 = bitcast %struct.ObjHeader* %170 to i32*
-  %172 = load i32, i32* %171, align 8, !tbaa !18
-  call fastcc void @checkRangeIndexes(i32 0, i32 %166, i32 %172)
-  %173 = bitcast %struct.ObjHeader* %161 to i64*
-  %174 = load atomic volatile i64, i64* %173 monotonic, align 8
-  %175 = icmp sgt i32 %166, 0
-  br i1 %175, label %176, label %when_exit6
+  %162 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %130 unordered, align 8
+  store %struct.ObjHeader* %162, %struct.ObjHeader** %8, align 8, !tbaa !3
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %117)
+  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %117, i8 0, i32 32, i1 immarg false) #49
+  %163 = load atomic i64, i64* %137 unordered, align 8, !tbaa !7
+  store i64 %163, i64* %124, align 8, !tbaa !9
+  %164 = bitcast %"class.kotlin::mm::ShadowStack"* %135 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i14, %struct.ObjHeader*** %164, align 8, !tbaa !7
+  store i32 0, i32* %127, align 8, !tbaa !12
+  store i32 4, i32* %128, align 4, !tbaa !13
+  %165 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %130 unordered, align 8
+  store %struct.ObjHeader* %165, %struct.ObjHeader** %118, align 8, !tbaa !3
+  %166 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %165, i64 1
+  %167 = bitcast %struct.ObjHeader* %166 to i32*
+  %168 = load atomic i32, i32* %167 unordered, align 8, !tbaa !18
+  %169 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
+  %170 = load atomic i64, i64* %124 unordered, align 8, !tbaa !9
+  %171 = bitcast %"class.kotlin::mm::ShadowStack"* %169 to i64*
+  store i64 %170, i64* %171, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %117)
+  %172 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %162, i64 1
+  %173 = bitcast %struct.ObjHeader* %172 to i32*
+  %174 = load atomic i32, i32* %173 unordered, align 8, !tbaa !18
+  call fastcc void @checkRangeIndexes(i32 0, i32 %168, i32 %174)
+  %175 = bitcast %struct.ObjHeader* %162 to i64*
+  %176 = load atomic volatile i64, i64* %175 monotonic, align 8
+  %177 = icmp sgt i32 %168, 0
+  br i1 %177, label %178, label %when_exit6
 
-176:                                              ; preds = %call_success7
-  %177 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %161, i64 2
-  %178 = bitcast %struct.ObjHeader* %177 to i32*
-  %179 = add i32 %166, -1
-  %180 = zext i32 %179 to i64
-  %181 = add nuw nsw i64 %180, 1
-  %182 = icmp ult i32 %179, 7
-  br i1 %182, label %233, label %183
+178:                                              ; preds = %call_success7
+  %179 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %162, i64 2
+  %180 = bitcast %struct.ObjHeader* %179 to i32*
+  %181 = add i32 %168, -1
+  %182 = zext i32 %181 to i64
+  %183 = add nuw nsw i64 %182, 1
+  %184 = icmp ult i32 %181, 7
+  br i1 %184, label %235, label %185
 
-183:                                              ; preds = %176
-  %184 = and i64 %181, 8589934584
-  %185 = trunc i64 %184 to i32
-  %186 = getelementptr i32, i32* %178, i64 %184
-  %187 = add nsw i64 %184, -8
-  %188 = lshr exact i64 %187, 3
-  %189 = add nuw nsw i64 %188, 1
-  %190 = and i64 %189, 7
-  %191 = icmp ult i64 %187, 56
-  br i1 %191, label %.loopexit26, label %192
+185:                                              ; preds = %178
+  %186 = and i64 %183, 8589934584
+  %187 = trunc i64 %186 to i32
+  %188 = getelementptr i32, i32* %180, i64 %186
+  %189 = add nsw i64 %186, -8
+  %190 = lshr exact i64 %189, 3
+  %191 = add nuw nsw i64 %190, 1
+  %192 = and i64 %191, 7
+  %193 = icmp ult i64 %189, 56
+  br i1 %193, label %.loopexit26, label %194
 
-192:                                              ; preds = %183
-  %193 = and i64 %189, 4611686018427387896
-  br label %194
+194:                                              ; preds = %185
+  %195 = and i64 %191, 4611686018427387896
+  br label %196
 
-194:                                              ; preds = %194, %192
-  %195 = phi i64 [ 0, %192 ], [ %219, %194 ]
-  %196 = phi i64 [ %193, %192 ], [ %220, %194 ]
-  %197 = getelementptr i32, i32* %178, i64 %195
-  %198 = or i64 %195, 8
-  %199 = getelementptr i32, i32* %178, i64 %198
-  %200 = bitcast i32* %197 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %200, i8 0, i64 32, i1 false)
-  %201 = or i64 %195, 16
-  %202 = getelementptr i32, i32* %178, i64 %201
-  %203 = bitcast i32* %199 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %203, i8 0, i64 32, i1 false)
-  %204 = or i64 %195, 24
-  %205 = getelementptr i32, i32* %178, i64 %204
-  %206 = bitcast i32* %202 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %206, i8 0, i64 32, i1 false)
-  %207 = or i64 %195, 32
-  %208 = getelementptr i32, i32* %178, i64 %207
-  %209 = bitcast i32* %205 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %209, i8 0, i64 32, i1 false)
-  %210 = or i64 %195, 40
-  %211 = getelementptr i32, i32* %178, i64 %210
-  %212 = bitcast i32* %208 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %212, i8 0, i64 32, i1 false)
-  %213 = or i64 %195, 48
-  %214 = getelementptr i32, i32* %178, i64 %213
-  %215 = bitcast i32* %211 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %215, i8 0, i64 32, i1 false)
-  %216 = or i64 %195, 56
-  %217 = getelementptr i32, i32* %178, i64 %216
-  %218 = bitcast i32* %214 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %218, i8 0, i64 32, i1 false)
-  %219 = add i64 %195, 64
-  %220 = add i64 %196, -8
-  %221 = icmp eq i64 %220, 0
-  %222 = bitcast i32* %217 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %222, i8 0, i64 32, i1 false)
-  br i1 %221, label %.loopexit26, label %194, !llvm.loop !74
+196:                                              ; preds = %196, %194
+  %197 = phi i64 [ 0, %194 ], [ %221, %196 ]
+  %198 = phi i64 [ %195, %194 ], [ %222, %196 ]
+  %199 = getelementptr i32, i32* %180, i64 %197
+  %200 = or i64 %197, 8
+  %201 = getelementptr i32, i32* %180, i64 %200
+  %202 = bitcast i32* %199 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %202, i8 0, i64 32, i1 false)
+  %203 = or i64 %197, 16
+  %204 = getelementptr i32, i32* %180, i64 %203
+  %205 = bitcast i32* %201 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %205, i8 0, i64 32, i1 false)
+  %206 = or i64 %197, 24
+  %207 = getelementptr i32, i32* %180, i64 %206
+  %208 = bitcast i32* %204 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %208, i8 0, i64 32, i1 false)
+  %209 = or i64 %197, 32
+  %210 = getelementptr i32, i32* %180, i64 %209
+  %211 = bitcast i32* %207 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %211, i8 0, i64 32, i1 false)
+  %212 = or i64 %197, 40
+  %213 = getelementptr i32, i32* %180, i64 %212
+  %214 = bitcast i32* %210 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %214, i8 0, i64 32, i1 false)
+  %215 = or i64 %197, 48
+  %216 = getelementptr i32, i32* %180, i64 %215
+  %217 = bitcast i32* %213 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %217, i8 0, i64 32, i1 false)
+  %218 = or i64 %197, 56
+  %219 = getelementptr i32, i32* %180, i64 %218
+  %220 = bitcast i32* %216 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %220, i8 0, i64 32, i1 false)
+  %221 = add i64 %197, 64
+  %222 = add i64 %198, -8
+  %223 = icmp eq i64 %222, 0
+  %224 = bitcast i32* %219 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %224, i8 0, i64 32, i1 false)
+  br i1 %223, label %.loopexit26, label %196, !llvm.loop !72
 
-.loopexit26:                                      ; preds = %194, %183
-  %223 = phi i64 [ 0, %183 ], [ %219, %194 ]
-  %224 = icmp eq i64 %190, 0
-  br i1 %224, label %.loopexit, label %.preheader
+.loopexit26:                                      ; preds = %196, %185
+  %225 = phi i64 [ 0, %185 ], [ %221, %196 ]
+  %226 = icmp eq i64 %192, 0
+  br i1 %226, label %.loopexit, label %.preheader
 
 .preheader:                                       ; preds = %.preheader, %.loopexit26
-  %225 = phi i64 [ %228, %.preheader ], [ %223, %.loopexit26 ]
-  %226 = phi i64 [ %229, %.preheader ], [ %190, %.loopexit26 ]
-  %227 = getelementptr i32, i32* %178, i64 %225
-  %228 = add i64 %225, 8
-  %229 = add nsw i64 %226, -1
-  %230 = icmp eq i64 %229, 0
-  %231 = bitcast i32* %227 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %231, i8 0, i64 32, i1 false)
-  br i1 %230, label %.loopexit, label %.preheader, !llvm.loop !75
+  %227 = phi i64 [ %230, %.preheader ], [ %225, %.loopexit26 ]
+  %228 = phi i64 [ %231, %.preheader ], [ %192, %.loopexit26 ]
+  %229 = getelementptr i32, i32* %180, i64 %227
+  %230 = add i64 %227, 8
+  %231 = add nsw i64 %228, -1
+  %232 = icmp eq i64 %231, 0
+  %233 = bitcast i32* %229 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(32) %233, i8 0, i64 32, i1 false)
+  br i1 %232, label %.loopexit, label %.preheader, !llvm.loop !73
 
 .loopexit:                                        ; preds = %.preheader, %.loopexit26
-  %232 = icmp eq i64 %181, %184
-  br i1 %232, label %when_exit6, label %233
+  %234 = icmp eq i64 %183, %186
+  br i1 %234, label %when_exit6, label %235
 
-233:                                              ; preds = %.loopexit, %176
-  %234 = phi i32 [ 0, %176 ], [ %185, %.loopexit ]
-  %235 = phi i32* [ %178, %176 ], [ %186, %.loopexit ]
-  br label %236
+235:                                              ; preds = %.loopexit, %178
+  %236 = phi i32 [ 0, %178 ], [ %187, %.loopexit ]
+  %237 = phi i32* [ %180, %178 ], [ %188, %.loopexit ]
+  br label %238
 
-236:                                              ; preds = %236, %233
-  %237 = phi i32 [ %240, %236 ], [ %234, %233 ]
-  %238 = phi i32* [ %239, %236 ], [ %235, %233 ]
-  %239 = getelementptr inbounds i32, i32* %238, i64 1
-  store i32 0, i32* %238, align 4, !tbaa !73
-  %240 = add nsw i32 %237, 1
-  %241 = icmp eq i32 %240, %166
-  br i1 %241, label %when_exit6, label %236, !llvm.loop !76
+238:                                              ; preds = %238, %235
+  %239 = phi i32 [ %242, %238 ], [ %236, %235 ]
+  %240 = phi i32* [ %241, %238 ], [ %237, %235 ]
+  %241 = getelementptr inbounds i32, i32* %240, i64 1
+  store i32 0, i32* %240, align 4, !tbaa !71
+  %242 = add nsw i32 %239, 1
+  %243 = icmp eq i32 %242, %168
+  br i1 %243, label %when_exit6, label %238, !llvm.loop !74
 
-when_exit6:                                       ; preds = %236, %.loopexit, %call_success7, %call_success4
-  %242 = bitcast [8 x %struct.ObjHeader*]* %2 to i8*
+when_exit6:                                       ; preds = %238, %.loopexit, %call_success7, %call_success4
+  %244 = bitcast [8 x %struct.ObjHeader*]* %2 to i8*
   %.sub.i16 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 0
-  %243 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 3
-  %244 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 5
-  %245 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 6
-  %246 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 7
-  %247 = bitcast [8 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
-  %248 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 1
-  %249 = bitcast %struct.ObjHeader** %248 to i64*
-  %250 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 2
-  %251 = bitcast %struct.ObjHeader** %250 to i32*
-  %252 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %247, i64 0, i32 3
-  %253 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
-  %254 = bitcast %struct.ObjHeader* %253 to %struct.ObjHeader**
-  %255 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 4
-  %256 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 9
-  %257 = bitcast %struct.ObjHeader* %256 to i32*
-  %258 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 8
+  %245 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 3
+  %246 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 5
+  %247 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 6
+  %248 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 7
+  %249 = bitcast [8 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
+  %250 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 1
+  %251 = bitcast %struct.ObjHeader** %250 to i64*
+  %252 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 2
+  %253 = bitcast %struct.ObjHeader** %252 to i32*
+  %254 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %249, i64 0, i32 3
+  %255 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
+  %256 = bitcast %struct.ObjHeader* %255 to %struct.ObjHeader**
+  %257 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 4
+  %258 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 9
   %259 = bitcast %struct.ObjHeader* %258 to i32*
-  %260 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 3
-  %261 = bitcast %struct.ObjHeader* %260 to %struct.ObjHeader**
+  %260 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 8
+  %261 = bitcast %struct.ObjHeader* %260 to i32*
+  %262 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 3
+  %263 = bitcast %struct.ObjHeader* %262 to %struct.ObjHeader**
   br label %loop_check
 
 while_loop:                                       ; preds = %loop_check
-  %262 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %263 = and i8 %262, 1
-  %264 = icmp eq i8 %263, 0
-  br i1 %264, label %Kotlin_mm_safePointWhileLoopBody.exit, label %265
+  %264 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %265 = and i8 %264, 1
+  %266 = icmp eq i8 %265, 0
+  br i1 %266, label %Kotlin_mm_safePointWhileLoopBody.exit, label %267
 
-265:                                              ; preds = %while_loop
+267:                                              ; preds = %while_loop
   call fastcc void @_ZN6kotlin2mm26SuspendIfRequestedSlowPathEv() #37
   br label %Kotlin_mm_safePointWhileLoopBody.exit
 
-Kotlin_mm_safePointWhileLoopBody.exit:            ; preds = %265, %while_loop
+Kotlin_mm_safePointWhileLoopBody.exit:            ; preds = %267, %while_loop
   %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
-  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %242)
-  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(64) %242, i8 0, i32 64, i1 immarg false) #49
-  %266 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
-  %267 = bitcast %"class.kotlin::mm::ShadowStack"* %266 to i64*
-  %268 = load i64, i64* %267, align 8, !tbaa !7
-  store i64 %268, i64* %249, align 8, !tbaa !9
-  %269 = bitcast %"class.kotlin::mm::ShadowStack"* %266 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i16, %struct.ObjHeader*** %269, align 8, !tbaa !7
-  store i32 0, i32* %251, align 8, !tbaa !12
-  store i32 8, i32* %252, align 4, !tbaa !13
-  %270 = load %struct.ObjHeader*, %struct.ObjHeader** %254, align 8
-  store %struct.ObjHeader* %270, %struct.ObjHeader** %243, align 8, !tbaa !3
-  %271 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %270, i64 1
-  %272 = bitcast %struct.ObjHeader* %271 to i32*
-  %273 = load i32, i32* %272, align 8, !tbaa !18
-  %274 = zext i32 %273 to i64
-  %275 = icmp ult i64 %indvars.iv, %274
-  br i1 %275, label %Kotlin_Array_get.exit.i17, label %276
+  call void @llvm.lifetime.start.p0i8(i64 64, i8* nonnull %244)
+  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(64) %244, i8 0, i32 64, i1 immarg false) #49
+  %268 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
+  %269 = bitcast %"class.kotlin::mm::ShadowStack"* %268 to i64*
+  %270 = load atomic i64, i64* %269 unordered, align 8, !tbaa !7
+  store i64 %270, i64* %251, align 8, !tbaa !9
+  %271 = bitcast %"class.kotlin::mm::ShadowStack"* %268 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i16, %struct.ObjHeader*** %271, align 8, !tbaa !7
+  store i32 0, i32* %253, align 8, !tbaa !12
+  store i32 8, i32* %254, align 4, !tbaa !13
+  %272 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %256 unordered, align 8
+  store %struct.ObjHeader* %272, %struct.ObjHeader** %245, align 8, !tbaa !3
+  %273 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %272, i64 1
+  %274 = bitcast %struct.ObjHeader* %273 to i32*
+  %275 = load atomic i32, i32* %274 unordered, align 8, !tbaa !18
+  %276 = zext i32 %275 to i64
+  %277 = icmp ult i64 %indvars.iv, %276
+  br i1 %277, label %Kotlin_Array_get.exit.i17, label %278
 
-276:                                              ; preds = %Kotlin_mm_safePointWhileLoopBody.exit
+278:                                              ; preds = %Kotlin_mm_safePointWhileLoopBody.exit
   call fastcc void @ThrowArrayIndexOutOfBoundsException() #50
   unreachable
 
 Kotlin_Array_get.exit.i17:                        ; preds = %Kotlin_mm_safePointWhileLoopBody.exit
-  %277 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %270, i64 2
-  %278 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %277, i64 %indvars.iv
-  %279 = bitcast %struct.ObjHeader* %278 to %struct.ObjHeader**
-  %280 = load %struct.ObjHeader*, %struct.ObjHeader** %279, align 8, !tbaa !3
-  store %struct.ObjHeader* %280, %struct.ObjHeader** %255, align 8, !tbaa !3
-  %281 = icmp eq %struct.ObjHeader* %280, null
-  br i1 %281, label %"kfun:kotlin.collections.HashMap.hash#internal.exit.i", label %when_next.i.i19
+  %279 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %272, i64 2
+  %280 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %279, i64 %indvars.iv
+  %281 = bitcast %struct.ObjHeader* %280 to %struct.ObjHeader**
+  %282 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %281 unordered, align 8, !tbaa !3
+  store %struct.ObjHeader* %282, %struct.ObjHeader** %257, align 8, !tbaa !3
+  %283 = icmp eq %struct.ObjHeader* %282, null
+  br i1 %283, label %"kfun:kotlin.collections.HashMap.hash#internal.exit.i", label %when_next.i.i19
 
 when_next.i.i19:                                  ; preds = %Kotlin_Array_get.exit.i17
-  %282 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %280, i64 0, i32 0
-  %283 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %282 monotonic, align 8
-  %284 = ptrtoint %struct.TypeInfo* %283 to i64
-  %285 = and i64 %284, -4
-  %286 = inttoptr i64 %285 to %struct.TypeInfo*
-  %287 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %286, i64 0, i32 0
-  %288 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %287 monotonic, align 8
-  %289 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %288, i64 1, i32 1
-  %290 = bitcast %struct.ExtendedTypeInfo** %289 to i32 (%struct.ObjHeader*)**
-  %291 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %290, align 8
-  %292 = call i32 %291(%struct.ObjHeader* nonnull %280)
-  %293 = mul i32 %292, -1640531527
-  %294 = load i32, i32* %257, align 4
-  %295 = and i32 %294, 31
-  %296 = lshr i32 %293, %295
+  %284 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %282, i64 0, i32 0
+  %285 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %284 monotonic, align 8
+  %286 = ptrtoint %struct.TypeInfo* %285 to i64
+  %287 = and i64 %286, -4
+  %288 = inttoptr i64 %287 to %struct.TypeInfo*
+  %289 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %288, i64 0, i32 0
+  %290 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %289 monotonic, align 8
+  %291 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %290, i64 1, i32 1
+  %292 = bitcast %struct.ExtendedTypeInfo** %291 to i32 (%struct.ObjHeader*)**
+  %293 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %292 unordered, align 8
+  %294 = call i32 %293(%struct.ObjHeader* nonnull %282)
+  %295 = mul i32 %294, -1640531527
+  %296 = load atomic i32, i32* %259 unordered, align 4
+  %297 = and i32 %296, 31
+  %298 = lshr i32 %295, %297
   br label %"kfun:kotlin.collections.HashMap.hash#internal.exit.i"
 
 "kfun:kotlin.collections.HashMap.hash#internal.exit.i": ; preds = %when_next.i.i19, %Kotlin_Array_get.exit.i17
-  %297 = phi i32 [ %296, %when_next.i.i19 ], [ 0, %Kotlin_Array_get.exit.i17 ]
-  %298 = load i32, i32* %259, align 4
+  %299 = phi i32 [ %298, %when_next.i.i19 ], [ 0, %Kotlin_Array_get.exit.i17 ]
+  %300 = load atomic i32, i32* %261 unordered, align 4
   br label %loop_check.i25
 
-299:                                              ; preds = %loop_check.i25
+301:                                              ; preds = %loop_check.i25
   call fastcc void @_ZN6kotlin2mm26SuspendIfRequestedSlowPathEv() #37
   br label %Kotlin_mm_safePointWhileLoopBody.exit.i21
 
-Kotlin_mm_safePointWhileLoopBody.exit.i21:        ; preds = %loop_check.i25, %299
-  %300 = load %struct.ObjHeader*, %struct.ObjHeader** %129, align 8
-  store %struct.ObjHeader* %300, %struct.ObjHeader** %244, align 8, !tbaa !3
-  %301 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %300, i64 1
-  %302 = bitcast %struct.ObjHeader* %301 to i32*
-  %303 = load i32, i32* %302, align 8, !tbaa !18
-  %304 = icmp ugt i32 %303, %hash.1.i
-  br i1 %304, label %Kotlin_IntArray_get.exit.i22, label %305
+Kotlin_mm_safePointWhileLoopBody.exit.i21:        ; preds = %loop_check.i25, %301
+  %302 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %130 unordered, align 8
+  store %struct.ObjHeader* %302, %struct.ObjHeader** %246, align 8, !tbaa !3
+  %303 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %302, i64 1
+  %304 = bitcast %struct.ObjHeader* %303 to i32*
+  %305 = load atomic i32, i32* %304 unordered, align 8, !tbaa !18
+  %306 = icmp ugt i32 %305, %hash.1.i
+  br i1 %306, label %Kotlin_IntArray_get.exit.i22, label %307
 
-305:                                              ; preds = %Kotlin_mm_safePointWhileLoopBody.exit.i21
+307:                                              ; preds = %Kotlin_mm_safePointWhileLoopBody.exit.i21
   call fastcc void @ThrowArrayIndexOutOfBoundsException() #50
   unreachable
 
 Kotlin_IntArray_get.exit.i22:                     ; preds = %Kotlin_mm_safePointWhileLoopBody.exit.i21
-  %306 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %300, i64 2
-  %307 = bitcast %struct.ObjHeader* %306 to i32*
-  %308 = sext i32 %hash.1.i to i64
-  %309 = getelementptr inbounds i32, i32* %307, i64 %308
-  %310 = load i32, i32* %309, align 4, !tbaa !73
-  %311 = icmp eq i32 %310, 0
-  br i1 %311, label %when_case.i23, label %when_exit.i24
+  %308 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %302, i64 2
+  %309 = bitcast %struct.ObjHeader* %308 to i32*
+  %310 = sext i32 %hash.1.i to i64
+  %311 = getelementptr inbounds i32, i32* %309, i64 %310
+  %312 = load atomic i32, i32* %311 unordered, align 4, !tbaa !71
+  %313 = icmp eq i32 %312, 0
+  br i1 %313, label %when_case.i23, label %when_exit.i24
 
 when_case.i23:                                    ; preds = %Kotlin_IntArray_get.exit.i22
-  store %struct.ObjHeader* %300, %struct.ObjHeader** %245, align 8, !tbaa !3
-  %312 = bitcast %struct.ObjHeader* %300 to i64*
-  %313 = load atomic volatile i64, i64* %312 monotonic, align 8
-  %314 = trunc i64 %indvars.iv.next to i32
-  store i32 %314, i32* %309, align 4, !tbaa !73
-  %315 = load %struct.ObjHeader*, %struct.ObjHeader** %261, align 8
-  store %struct.ObjHeader* %315, %struct.ObjHeader** %246, align 8, !tbaa !3
-  %316 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %315, i64 1
-  %317 = bitcast %struct.ObjHeader* %316 to i32*
-  %318 = load i32, i32* %317, align 8, !tbaa !18
-  %319 = zext i32 %318 to i64
-  %320 = icmp ult i64 %indvars.iv, %319
-  br i1 %320, label %call_success10, label %321
+  store %struct.ObjHeader* %302, %struct.ObjHeader** %247, align 8, !tbaa !3
+  %314 = bitcast %struct.ObjHeader* %302 to i64*
+  %315 = load atomic volatile i64, i64* %314 monotonic, align 8
+  %316 = trunc i64 %indvars.iv.next to i32
+  store i32 %316, i32* %311, align 4, !tbaa !71
+  %317 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %263 unordered, align 8
+  store %struct.ObjHeader* %317, %struct.ObjHeader** %248, align 8, !tbaa !3
+  %318 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %317, i64 1
+  %319 = bitcast %struct.ObjHeader* %318 to i32*
+  %320 = load atomic i32, i32* %319 unordered, align 8, !tbaa !18
+  %321 = zext i32 %320 to i64
+  %322 = icmp ult i64 %indvars.iv, %321
+  br i1 %322, label %call_success10, label %323
 
-321:                                              ; preds = %when_case.i23
+323:                                              ; preds = %when_case.i23
   call fastcc void @ThrowArrayIndexOutOfBoundsException() #50
   unreachable
 
 when_exit.i24:                                    ; preds = %Kotlin_IntArray_get.exit.i22
-  %322 = add i32 %probesLeft.0.i, -1
-  %323 = icmp slt i32 %322, 0
-  br i1 %323, label %call_success12, label %when_exit6.i
+  %324 = add i32 %probesLeft.0.i, -1
+  %325 = icmp slt i32 %324, 0
+  br i1 %325, label %call_success12, label %when_exit6.i
 
 when_exit6.i:                                     ; preds = %when_exit.i24
-  %324 = icmp eq i32 %hash.1.i, 0
-  br i1 %324, label %when_case7.i, label %when_exit8.i
+  %326 = icmp eq i32 %hash.1.i, 0
+  br i1 %326, label %when_case7.i, label %when_exit8.i
 
 when_case7.i:                                     ; preds = %when_exit6.i
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %118)
-  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %118, i8 0, i32 32, i1 immarg false) #49
-  %325 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
-  %326 = bitcast %"class.kotlin::mm::ShadowStack"* %325 to i64*
-  %327 = load i64, i64* %326, align 8, !tbaa !7
-  store i64 %327, i64* %123, align 8, !tbaa !9
-  %328 = bitcast %"class.kotlin::mm::ShadowStack"* %325 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i14, %struct.ObjHeader*** %328, align 8, !tbaa !7
-  store i32 0, i32* %126, align 8, !tbaa !12
-  store i32 4, i32* %127, align 4, !tbaa !13
-  %329 = load %struct.ObjHeader*, %struct.ObjHeader** %129, align 8
-  store %struct.ObjHeader* %329, %struct.ObjHeader** %119, align 8, !tbaa !3
-  %330 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %329, i64 1
-  %331 = bitcast %struct.ObjHeader* %330 to i32*
-  %332 = load i32, i32* %331, align 8, !tbaa !18
-  %333 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
-  %334 = load i64, i64* %123, align 8, !tbaa !9
-  %335 = bitcast %"class.kotlin::mm::ShadowStack"* %333 to i64*
-  store i64 %334, i64* %335, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %118)
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %117)
+  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %117, i8 0, i32 32, i1 immarg false) #49
+  %327 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
+  %328 = bitcast %"class.kotlin::mm::ShadowStack"* %327 to i64*
+  %329 = load atomic i64, i64* %328 unordered, align 8, !tbaa !7
+  store i64 %329, i64* %124, align 8, !tbaa !9
+  %330 = bitcast %"class.kotlin::mm::ShadowStack"* %327 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i14, %struct.ObjHeader*** %330, align 8, !tbaa !7
+  store i32 0, i32* %127, align 8, !tbaa !12
+  store i32 4, i32* %128, align 4, !tbaa !13
+  %331 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %130 unordered, align 8
+  store %struct.ObjHeader* %331, %struct.ObjHeader** %118, align 8, !tbaa !3
+  %332 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %331, i64 1
+  %333 = bitcast %struct.ObjHeader* %332 to i32*
+  %334 = load atomic i32, i32* %333 unordered, align 8, !tbaa !18
+  %335 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
+  %336 = load atomic i64, i64* %124 unordered, align 8, !tbaa !9
+  %337 = bitcast %"class.kotlin::mm::ShadowStack"* %335 to i64*
+  store i64 %336, i64* %337, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %117)
   br label %when_exit8.i
 
 when_exit8.i:                                     ; preds = %when_case7.i, %when_exit6.i
-  %hash.0.in.i = phi i32 [ %332, %when_case7.i ], [ %hash.1.i, %when_exit6.i ]
+  %hash.0.in.i = phi i32 [ %334, %when_case7.i ], [ %hash.1.i, %when_exit6.i ]
   %hash.0.i = add i32 %hash.0.in.i, -1
   br label %loop_check.i25
 
 loop_check.i25:                                   ; preds = %when_exit8.i, %"kfun:kotlin.collections.HashMap.hash#internal.exit.i"
-  %probesLeft.0.i = phi i32 [ %298, %"kfun:kotlin.collections.HashMap.hash#internal.exit.i" ], [ %322, %when_exit8.i ]
-  %hash.1.i = phi i32 [ %297, %"kfun:kotlin.collections.HashMap.hash#internal.exit.i" ], [ %hash.0.i, %when_exit8.i ]
-  %336 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %337 = and i8 %336, 1
-  %338 = icmp eq i8 %337, 0
-  br i1 %338, label %Kotlin_mm_safePointWhileLoopBody.exit.i21, label %299
+  %probesLeft.0.i = phi i32 [ %300, %"kfun:kotlin.collections.HashMap.hash#internal.exit.i" ], [ %324, %when_exit8.i ]
+  %hash.1.i = phi i32 [ %299, %"kfun:kotlin.collections.HashMap.hash#internal.exit.i" ], [ %hash.0.i, %when_exit8.i ]
+  %338 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %339 = and i8 %338, 1
+  %340 = icmp eq i8 %339, 0
+  br i1 %340, label %Kotlin_mm_safePointWhileLoopBody.exit.i21, label %301
 
 call_success10:                                   ; preds = %when_case.i23
-  %339 = bitcast %struct.ObjHeader* %315 to i64*
-  %340 = load atomic volatile i64, i64* %339 monotonic, align 8
-  %341 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %315, i64 2
-  %342 = bitcast %struct.ObjHeader* %341 to i32*
-  %343 = getelementptr inbounds i32, i32* %342, i64 %indvars.iv
-  store i32 %hash.1.i, i32* %343, align 4, !tbaa !73
-  %344 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
-  %345 = load i64, i64* %249, align 8, !tbaa !9
-  %346 = bitcast %"class.kotlin::mm::ShadowStack"* %344 to i64*
-  store i64 %345, i64* %346, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %242)
+  %341 = bitcast %struct.ObjHeader* %317 to i64*
+  %342 = load atomic volatile i64, i64* %341 monotonic, align 8
+  %343 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %317, i64 2
+  %344 = bitcast %struct.ObjHeader* %343 to i32*
+  %345 = getelementptr inbounds i32, i32* %344, i64 %indvars.iv
+  store i32 %hash.1.i, i32* %345, align 4, !tbaa !71
+  %346 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
+  %347 = load atomic i64, i64* %251 unordered, align 8, !tbaa !9
+  %348 = bitcast %"class.kotlin::mm::ShadowStack"* %346 to i64*
+  store i64 %347, i64* %348, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %244)
   br label %loop_check
 
 call_success12:                                   ; preds = %when_exit.i24
-  %347 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
-  %348 = load i64, i64* %249, align 8, !tbaa !9
-  %349 = bitcast %"class.kotlin::mm::ShadowStack"* %347 to i64*
-  store i64 %348, i64* %349, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %242)
-  %350 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %5, i64 0, i64 5
-  %351 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 6
-  %352 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %351 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %353 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %352, align 8, !tbaa !3
-  %354 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %353, i64 0, i32 2, i32 1
-  %355 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %354, i64 56) #37
-  %356 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %355, i64 1
-  %357 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %355, i64 2
-  %358 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %357 to %struct.ObjHeader*
-  %359 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %357 to %struct.TypeInfo**
-  %360 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %356 to i64*
-  store i64 0, i64* %360, align 8
-  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [5 x i8*] }, { %struct.TypeInfo, [5 x i8*] }* @"ktypeglobal:kotlin.IllegalStateException#internal", i64 0, i32 0), %struct.TypeInfo** %359, align 8, !tbaa !14
-  %361 = bitcast %struct.ObjHeader** %350 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %357, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %361, align 8, !tbaa !3
-  call fastcc void @"kfun:kotlin.RuntimeException#<init>(kotlin.String?){}"(%struct.ObjHeader* nonnull %358, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [103 x i16] }* @151 to %struct.ObjHeader*))
-  call fastcc void @ThrowException(%struct.ObjHeader* nonnull %358) #50
+  %349 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
+  %350 = load atomic i64, i64* %251 unordered, align 8, !tbaa !9
+  %351 = bitcast %"class.kotlin::mm::ShadowStack"* %349 to i64*
+  store i64 %350, i64* %351, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 64, i8* nonnull %244)
+  %352 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %5, i64 0, i64 5
+  %353 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 6
+  %354 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %353 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
+  %355 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %354 unordered, align 8, !tbaa !3
+  %356 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %355, i64 0, i32 2, i32 1
+  %357 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %356, i64 56) #37
+  %358 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %357, i64 1
+  %359 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %357, i64 2
+  %360 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %359 to %struct.ObjHeader*
+  %361 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %359 to %struct.TypeInfo**
+  %362 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %358 to i64*
+  store i64 0, i64* %362, align 8
+  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [5 x i8*] }, { %struct.TypeInfo, [5 x i8*] }* @"ktypeglobal:kotlin.IllegalStateException#internal", i64 0, i32 0), %struct.TypeInfo** %361, align 8, !tbaa !14
+  %363 = bitcast %struct.ObjHeader** %352 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %359, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %363, align 8, !tbaa !3
+  call fastcc void @"kfun:kotlin.RuntimeException#<init>(kotlin.String?){}"(%struct.ObjHeader* nonnull %360, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [103 x i16] }* @151 to %struct.ObjHeader*))
+  call fastcc void @ThrowException(%struct.ObjHeader* nonnull %360) #50
   unreachable
 
 loop_check:                                       ; preds = %call_success10, %when_exit6
   %indvars.iv = phi i64 [ 0, %when_exit6 ], [ %indvars.iv.next, %call_success10 ]
-  %362 = load i32, i32* %25, align 4
-  %363 = sext i32 %362 to i64
-  %364 = icmp slt i64 %indvars.iv, %363
-  br i1 %364, label %while_loop, label %epilogue
+  %364 = load atomic i32, i32* %25 unordered, align 4
+  %365 = sext i32 %364 to i64
+  %366 = icmp slt i64 %indvars.iv, %365
+  br i1 %366, label %while_loop, label %epilogue
 
 epilogue:                                         ; preds = %loop_check
-  %365 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
-  %366 = load i64, i64* %15, align 8, !tbaa !9
-  %367 = bitcast %"class.kotlin::mm::ShadowStack"* %365 to i64*
-  store i64 %366, i64* %367, align 8, !tbaa !7
+  %367 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
+  %368 = load atomic i64, i64* %15 unordered, align 8, !tbaa !9
+  %369 = bitcast %"class.kotlin::mm::ShadowStack"* %367 to i64*
+  store i64 %368, i64* %369, align 8, !tbaa !7
   ret void
 }
 
@@ -11131,11 +11206,11 @@
   %5 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %3, i64 0, i64 3
   %6 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %3, i64 0, i64 4
   %7 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %3, i64 0, i64 5
-  %8 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %8 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %9 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
   %10 = bitcast [6 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %11 = bitcast %"class.kotlin::mm::ShadowStack"* %9 to i64*
-  %12 = load i64, i64* %11, align 8, !tbaa !7
+  %12 = load atomic i64, i64* %11 unordered, align 8, !tbaa !7
   %13 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %14 = bitcast %struct.ObjHeader** %13 to i64*
   store i64 %12, i64* %14, align 8, !tbaa !9
@@ -11169,12 +11244,12 @@
   %30 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %29 monotonic, align 8
   %31 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %30, i64 1, i32 1
   %32 = bitcast %struct.ExtendedTypeInfo** %31 to i32 (%struct.ObjHeader*)**
-  %33 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %32, align 8
+  %33 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %32 unordered, align 8
   %34 = call i32 %33(%struct.ObjHeader* nonnull %1)
   %35 = mul i32 %34, -1640531527
   %36 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 9
   %37 = bitcast %struct.ObjHeader* %36 to i32*
-  %38 = load i32, i32* %37, align 4
+  %38 = load atomic i32, i32* %37 unordered, align 4
   %39 = and i32 %38, 31
   %40 = lshr i32 %35, %39
   br label %call_success
@@ -11183,7 +11258,7 @@
   %41 = phi i32 [ %40, %when_next.i ], [ 0, %Kotlin_mm_safePointFunctionPrologue.exit ]
   %42 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 8
   %43 = bitcast %struct.ObjHeader* %42 to i32*
-  %44 = load i32, i32* %43, align 4
+  %44 = load atomic i32, i32* %43 unordered, align 4
   %45 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 4
   %46 = bitcast %struct.ObjHeader* %45 to %struct.ObjHeader**
   %47 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
@@ -11212,11 +11287,11 @@
   br label %Kotlin_mm_safePointWhileLoopBody.exit
 
 Kotlin_mm_safePointWhileLoopBody.exit:            ; preds = %60, %while_loop
-  %61 = load %struct.ObjHeader*, %struct.ObjHeader** %46, align 8
+  %61 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %46 unordered, align 8
   store %struct.ObjHeader* %61, %struct.ObjHeader** %5, align 8, !tbaa !3
   %62 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %61, i64 1
   %63 = bitcast %struct.ObjHeader* %62 to i32*
-  %64 = load i32, i32* %63, align 8, !tbaa !18
+  %64 = load atomic i32, i32* %63 unordered, align 8, !tbaa !18
   %65 = icmp ugt i32 %64, %hash.1
   br i1 %65, label %call_success1, label %66
 
@@ -11229,7 +11304,7 @@
   %68 = bitcast %struct.ObjHeader* %67 to i32*
   %69 = sext i32 %hash.1 to i64
   %70 = getelementptr inbounds i32, i32* %68, i64 %69
-  %71 = load i32, i32* %70, align 4, !tbaa !73
+  %71 = load atomic i32, i32* %70 unordered, align 4, !tbaa !71
   %72 = icmp eq i32 %71, 0
   br i1 %72, label %epilogue, label %when_exit
 
@@ -11238,12 +11313,12 @@
   br i1 %73, label %when_case3, label %when_exit10
 
 when_case3:                                       ; preds = %when_exit
-  %74 = load %struct.ObjHeader*, %struct.ObjHeader** %48, align 8
+  %74 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %48 unordered, align 8
   store %struct.ObjHeader* %74, %struct.ObjHeader** %6, align 8, !tbaa !3
   %75 = add i32 %71, -1
   %76 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %74, i64 1
   %77 = bitcast %struct.ObjHeader* %76 to i32*
-  %78 = load i32, i32* %77, align 8, !tbaa !18
+  %78 = load atomic i32, i32* %77 unordered, align 8, !tbaa !18
   %79 = icmp ugt i32 %78, %75
   br i1 %79, label %call_success4, label %80
 
@@ -11256,7 +11331,7 @@
   %82 = sext i32 %75 to i64
   %83 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %81, i64 %82
   %84 = bitcast %struct.ObjHeader* %83 to %struct.ObjHeader**
-  %85 = load %struct.ObjHeader*, %struct.ObjHeader** %84, align 8, !tbaa !3
+  %85 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %84 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %85, %struct.ObjHeader** %7, align 8, !tbaa !3
   %86 = icmp eq %struct.ObjHeader* %85, null
   br i1 %86, label %when_case5, label %when_exit9
@@ -11274,7 +11349,7 @@
   %93 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %92 monotonic, align 8
   %94 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %93, i64 1
   %95 = bitcast %struct.TypeInfo* %94 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
-  %96 = load i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %95, align 8
+  %96 = load atomic i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %95 unordered, align 8
   %97 = call zeroext i1 %96(%struct.ObjHeader* nonnull %85, %struct.ObjHeader* %1)
   br i1 %97, label %epilogue, label %when_exit10
 
@@ -11292,19 +11367,19 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %49, i8 0, i32 32, i1 immarg false) #49
   %101 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
   %102 = bitcast %"class.kotlin::mm::ShadowStack"* %101 to i64*
-  %103 = load i64, i64* %102, align 8, !tbaa !7
+  %103 = load atomic i64, i64* %102 unordered, align 8, !tbaa !7
   store i64 %103, i64* %53, align 8, !tbaa !9
   %104 = bitcast %"class.kotlin::mm::ShadowStack"* %101 to %struct.ObjHeader***
   store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %104, align 8, !tbaa !7
   store i32 0, i32* %55, align 8, !tbaa !12
   store i32 4, i32* %56, align 4, !tbaa !13
-  %105 = load %struct.ObjHeader*, %struct.ObjHeader** %46, align 8
+  %105 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %46 unordered, align 8
   store %struct.ObjHeader* %105, %struct.ObjHeader** %50, align 8, !tbaa !3
   %106 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %105, i64 1
   %107 = bitcast %struct.ObjHeader* %106 to i32*
-  %108 = load i32, i32* %107, align 8, !tbaa !18
+  %108 = load atomic i32, i32* %107 unordered, align 8, !tbaa !18
   %109 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
-  %110 = load i64, i64* %53, align 8, !tbaa !9
+  %110 = load atomic i64, i64* %53 unordered, align 8, !tbaa !9
   %111 = bitcast %"class.kotlin::mm::ShadowStack"* %109 to i64*
   store i64 %110, i64* %111, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %49)
@@ -11318,7 +11393,7 @@
 epilogue:                                         ; preds = %when_exit10, %when_exit9, %when_case5, %call_success1
   %112 = phi i32 [ %75, %when_case5 ], [ %75, %when_exit9 ], [ -1, %call_success1 ], [ -1, %when_exit10 ]
   %113 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
-  %114 = load i64, i64* %14, align 8, !tbaa !9
+  %114 = load atomic i64, i64* %14 unordered, align 8, !tbaa !9
   %115 = bitcast %"class.kotlin::mm::ShadowStack"* %113 to i64*
   store i64 %114, i64* %115, align 8, !tbaa !7
   ret i32 %112
@@ -11338,11 +11413,11 @@
   %9 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %4, i64 0, i64 6
   %10 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %4, i64 0, i64 7
   %11 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %4, i64 0, i64 8
-  %12 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %12 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %13 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %14 = bitcast [9 x %struct.ObjHeader*]* %4 to %struct.FrameOverlay.6*
   %15 = bitcast %"class.kotlin::mm::ShadowStack"* %13 to i64*
-  %16 = load i64, i64* %15, align 8, !tbaa !7
+  %16 = load atomic i64, i64* %15 unordered, align 8, !tbaa !7
   %17 = getelementptr inbounds [9 x %struct.ObjHeader*], [9 x %struct.ObjHeader*]* %4, i64 0, i64 1
   %18 = bitcast %struct.ObjHeader** %17 to i64*
   store i64 %16, i64* %18, align 8, !tbaa !9
@@ -11428,35 +11503,35 @@
   %74 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %73 monotonic, align 8
   %75 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %74, i64 1, i32 1
   %76 = bitcast %struct.ExtendedTypeInfo** %75 to i32 (%struct.ObjHeader*)**
-  %77 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %76, align 8
+  %77 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %76 unordered, align 8
   %78 = call i32 %77(%struct.ObjHeader* nonnull %1)
   %79 = mul i32 %78, -1640531527
-  %80 = load i32, i32* %30, align 4
+  %80 = load atomic i32, i32* %30 unordered, align 4
   %81 = and i32 %80, 31
   %82 = lshr i32 %79, %81
   br label %label_5
 
 label_5:                                          ; preds = %when_next.i, %Kotlin_mm_safePointWhileLoopBody.exit
   %83 = phi i32 [ %82, %when_next.i ], [ 0, %Kotlin_mm_safePointWhileLoopBody.exit ]
-  %84 = load i32, i32* %32, align 4
+  %84 = load atomic i32, i32* %32 unordered, align 4
   %85 = shl i32 %84, 1
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %33)
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %33, i8 0, i32 32, i1 immarg false) #49
   %86 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %87 = bitcast %"class.kotlin::mm::ShadowStack"* %86 to i64*
-  %88 = load i64, i64* %87, align 8, !tbaa !7
+  %88 = load atomic i64, i64* %87 unordered, align 8, !tbaa !7
   store i64 %88, i64* %37, align 8, !tbaa !9
   %89 = bitcast %"class.kotlin::mm::ShadowStack"* %86 to %struct.ObjHeader***
   store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %89, align 8, !tbaa !7
   store i32 0, i32* %39, align 8, !tbaa !12
   store i32 4, i32* %40, align 4, !tbaa !13
-  %90 = load %struct.ObjHeader*, %struct.ObjHeader** %42, align 8
+  %90 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %42 unordered, align 8
   store %struct.ObjHeader* %90, %struct.ObjHeader** %34, align 8, !tbaa !3
   %91 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %90, i64 1
   %92 = bitcast %struct.ObjHeader* %91 to i32*
-  %93 = load i32, i32* %92, align 8, !tbaa !18
+  %93 = load atomic i32, i32* %92 unordered, align 8, !tbaa !18
   %94 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %95 = load i64, i64* %37, align 8, !tbaa !9
+  %95 = load atomic i64, i64* %37 unordered, align 8, !tbaa !9
   %96 = bitcast %"class.kotlin::mm::ShadowStack"* %94 to i64*
   store i64 %95, i64* %96, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %33)
@@ -11468,7 +11543,7 @@
   br label %while_loop10
 
 while_loop10:                                     ; preds = %when_exit32, %label_5
-  %probeDistance.0 = phi i32 [ 0, %label_5 ], [ %305, %when_exit32 ]
+  %probeDistance.0 = phi i32 [ 0, %label_5 ], [ %307, %when_exit32 ]
   %hash.1 = phi i32 [ %83, %label_5 ], [ %hash.0, %when_exit32 ]
   %100 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
   %101 = and i8 %100, 1
@@ -11480,11 +11555,11 @@
   br label %Kotlin_mm_safePointWhileLoopBody.exit38
 
 Kotlin_mm_safePointWhileLoopBody.exit38:          ; preds = %103, %while_loop10
-  %104 = load %struct.ObjHeader*, %struct.ObjHeader** %42, align 8
+  %104 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %42 unordered, align 8
   store %struct.ObjHeader* %104, %struct.ObjHeader** %6, align 8, !tbaa !3
   %105 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %104, i64 1
   %106 = bitcast %struct.ObjHeader* %105 to i32*
-  %107 = load i32, i32* %106, align 8, !tbaa !18
+  %107 = load atomic i32, i32* %106 unordered, align 8, !tbaa !18
   %108 = icmp ugt i32 %107, %hash.1
   br i1 %108, label %call_success11, label %109
 
@@ -11497,29 +11572,29 @@
   %111 = bitcast %struct.ObjHeader* %110 to i32*
   %112 = sext i32 %hash.1 to i64
   %113 = getelementptr inbounds i32, i32* %111, i64 %112
-  %114 = load i32, i32* %113, align 4, !tbaa !73
+  %114 = load atomic i32, i32* %113 unordered, align 4, !tbaa !71
   %115 = icmp slt i32 %114, 1
   br i1 %115, label %call_success13, label %when_exit
 
 call_success13:                                   ; preds = %call_success11
-  %116 = load i32, i32* %46, align 4
+  %116 = load atomic i32, i32* %46 unordered, align 4
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %33)
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %33, i8 0, i32 32, i1 immarg false) #49
   %117 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %118 = bitcast %"class.kotlin::mm::ShadowStack"* %117 to i64*
-  %119 = load i64, i64* %118, align 8, !tbaa !7
+  %119 = load atomic i64, i64* %118 unordered, align 8, !tbaa !7
   store i64 %119, i64* %37, align 8, !tbaa !9
   %120 = bitcast %"class.kotlin::mm::ShadowStack"* %117 to %struct.ObjHeader***
   store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %120, align 8, !tbaa !7
   store i32 0, i32* %39, align 8, !tbaa !12
   store i32 4, i32* %40, align 4, !tbaa !13
-  %121 = load %struct.ObjHeader*, %struct.ObjHeader** %44, align 8
+  %121 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %44 unordered, align 8
   store %struct.ObjHeader* %121, %struct.ObjHeader** %34, align 8, !tbaa !3
   %122 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %121, i64 1
   %123 = bitcast %struct.ObjHeader* %122 to i32*
-  %124 = load i32, i32* %123, align 8, !tbaa !18
+  %124 = load atomic i32, i32* %123 unordered, align 8, !tbaa !18
   %125 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %126 = load i64, i64* %37, align 8, !tbaa !9
+  %126 = load atomic i64, i64* %37 unordered, align 8, !tbaa !9
   %127 = bitcast %"class.kotlin::mm::ShadowStack"* %125 to i64*
   store i64 %126, i64* %127, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %33)
@@ -11531,25 +11606,25 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %33, i8 0, i32 32, i1 immarg false) #49
   %128 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %129 = bitcast %"class.kotlin::mm::ShadowStack"* %128 to i64*
-  %130 = load i64, i64* %129, align 8, !tbaa !7
+  %130 = load atomic i64, i64* %129 unordered, align 8, !tbaa !7
   store i64 %130, i64* %37, align 8, !tbaa !9
   %131 = bitcast %"class.kotlin::mm::ShadowStack"* %128 to %struct.ObjHeader***
   store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %131, align 8, !tbaa !7
   store i32 0, i32* %39, align 8, !tbaa !12
   store i32 4, i32* %40, align 4, !tbaa !13
-  %132 = load %struct.ObjHeader*, %struct.ObjHeader** %44, align 8
+  %132 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %44 unordered, align 8
   store %struct.ObjHeader* %132, %struct.ObjHeader** %34, align 8, !tbaa !3
   %133 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %132, i64 1
   %134 = bitcast %struct.ObjHeader* %133 to i32*
-  %135 = load i32, i32* %134, align 8, !tbaa !18
+  %135 = load atomic i32, i32* %134 unordered, align 8, !tbaa !18
   %136 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %137 = load i64, i64* %37, align 8, !tbaa !9
+  %137 = load atomic i64, i64* %37 unordered, align 8, !tbaa !9
   %138 = bitcast %"class.kotlin::mm::ShadowStack"* %136 to i64*
   store i64 %137, i64* %138, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %33) #37
-  %139 = load i32, i32* %46, align 4
+  %139 = load atomic i32, i32* %46 unordered, align 4
   %140 = sub i32 %135, %139
-  %141 = load i32, i32* %47, align 4
+  %141 = load atomic i32, i32* %47 unordered, align 4
   %142 = sub i32 %139, %141
   %143 = icmp slt i32 %140, 1
   %144 = add i32 %142, %140
@@ -11562,19 +11637,19 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %33, i8 0, i32 32, i1 immarg false) #49
   %146 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
   %147 = bitcast %"class.kotlin::mm::ShadowStack"* %146 to i64*
-  %148 = load i64, i64* %147, align 8, !tbaa !7
+  %148 = load atomic i64, i64* %147 unordered, align 8, !tbaa !7
   store i64 %148, i64* %37, align 8, !tbaa !9
   %149 = bitcast %"class.kotlin::mm::ShadowStack"* %146 to %struct.ObjHeader***
   store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %149, align 8, !tbaa !7
   store i32 0, i32* %39, align 8, !tbaa !12
   store i32 4, i32* %40, align 4, !tbaa !13
-  %150 = load %struct.ObjHeader*, %struct.ObjHeader** %44, align 8
+  %150 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %44 unordered, align 8
   store %struct.ObjHeader* %150, %struct.ObjHeader** %34, align 8, !tbaa !3
   %151 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %150, i64 1
   %152 = bitcast %struct.ObjHeader* %151 to i32*
-  %153 = load i32, i32* %152, align 8, !tbaa !18
+  %153 = load atomic i32, i32* %152 unordered, align 8, !tbaa !18
   %154 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %155 = load i64, i64* %37, align 8, !tbaa !9
+  %155 = load atomic i64, i64* %37 unordered, align 8, !tbaa !9
   %156 = bitcast %"class.kotlin::mm::ShadowStack"* %154 to i64*
   store i64 %155, i64* %156, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %33) #37
@@ -11585,375 +11660,377 @@
 when_case.i40:                                    ; preds = %"kfun:kotlin.collections.HashMap.shouldCompact#internal.exit.i"
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %33)
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %33, i8 0, i32 32, i1 immarg false) #49
-  store i64 %155, i64* %37, align 8, !tbaa !9
-  %158 = bitcast %"class.kotlin::mm::ShadowStack"* %154 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %158, align 8, !tbaa !7
+  %158 = load atomic i64, i64* %156 unordered, align 8, !tbaa !7
+  store i64 %158, i64* %37, align 8, !tbaa !9
+  %159 = bitcast %"class.kotlin::mm::ShadowStack"* %154 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %159, align 8, !tbaa !7
   store i32 0, i32* %39, align 8, !tbaa !12
   store i32 4, i32* %40, align 4, !tbaa !13
-  %159 = load %struct.ObjHeader*, %struct.ObjHeader** %42, align 8
-  store %struct.ObjHeader* %159, %struct.ObjHeader** %34, align 8, !tbaa !3
-  %160 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %159, i64 1
-  %161 = bitcast %struct.ObjHeader* %160 to i32*
-  %162 = load i32, i32* %161, align 8, !tbaa !18
-  %163 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %164 = load i64, i64* %37, align 8, !tbaa !9
-  %165 = bitcast %"class.kotlin::mm::ShadowStack"* %163 to i64*
-  store i64 %164, i64* %165, align 8, !tbaa !7
+  %160 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %42 unordered, align 8
+  store %struct.ObjHeader* %160, %struct.ObjHeader** %34, align 8, !tbaa !3
+  %161 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %160, i64 1
+  %162 = bitcast %struct.ObjHeader* %161 to i32*
+  %163 = load atomic i32, i32* %162 unordered, align 8, !tbaa !18
+  %164 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
+  %165 = load atomic i64, i64* %37 unordered, align 8, !tbaa !9
+  %166 = bitcast %"class.kotlin::mm::ShadowStack"* %164 to i64*
+  store i64 %165, i64* %166, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %33)
-  call fastcc void @"kfun:kotlin.collections.HashMap.rehash#internal"(%struct.ObjHeader* %0, i32 %162)
+  call fastcc void @"kfun:kotlin.collections.HashMap.rehash#internal"(%struct.ObjHeader* %0, i32 %163)
   br label %while_loop.backedge
 
 when_next.i41:                                    ; preds = %"kfun:kotlin.collections.HashMap.shouldCompact#internal.exit.i", %when_case12
-  %166 = load i32, i32* %46, align 4
-  %167 = add i32 %166, 1
+  %167 = load atomic i32, i32* %46 unordered, align 4
+  %168 = add i32 %167, 1
   call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %48)
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(80) %48, i8 0, i32 80, i1 immarg false) #49
-  %168 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %169 = bitcast %"class.kotlin::mm::ShadowStack"* %168 to i64*
-  %170 = load i64, i64* %169, align 8, !tbaa !7
-  store i64 %170, i64* %57, align 8, !tbaa !9
-  %171 = bitcast %"class.kotlin::mm::ShadowStack"* %168 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i1.i, %struct.ObjHeader*** %171, align 8, !tbaa !7
+  %169 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
+  %170 = bitcast %"class.kotlin::mm::ShadowStack"* %169 to i64*
+  %171 = load atomic i64, i64* %170 unordered, align 8, !tbaa !7
+  store i64 %171, i64* %57, align 8, !tbaa !9
+  %172 = bitcast %"class.kotlin::mm::ShadowStack"* %169 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i1.i, %struct.ObjHeader*** %172, align 8, !tbaa !7
   store i32 0, i32* %59, align 8, !tbaa !12
   store i32 10, i32* %60, align 4, !tbaa !13
-  %172 = icmp slt i32 %167, 0
-  br i1 %172, label %when_case.i2.i, label %when_exit.i4.i
+  %173 = icmp slt i32 %168, 0
+  br i1 %173, label %when_case.i2.i, label %when_exit.i4.i
 
 when_case.i2.i:                                   ; preds = %when_next.i41
-  %173 = getelementptr inbounds [10 x %struct.ObjHeader*], [10 x %struct.ObjHeader*]* %2, i64 0, i64 3
-  %174 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 6
-  %175 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %174 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %176 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %175, align 8, !tbaa !3
-  %177 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %176, i64 0, i32 2, i32 1
-  %178 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %177, i64 56) #37
-  %179 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %178, i64 1
-  %180 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %178, i64 2
-  %181 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %180 to %struct.ObjHeader*
-  %182 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %180 to %struct.TypeInfo**
-  %183 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %179 to i64*
-  store i64 0, i64* %183, align 8
-  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [5 x i8*] }, { %struct.TypeInfo, [5 x i8*] }* @"ktypeglobal:kotlin.OutOfMemoryError#internal", i64 0, i32 0), %struct.TypeInfo** %182, align 8, !tbaa !14
-  %184 = bitcast %struct.ObjHeader** %173 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %180, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %184, align 8, !tbaa !3
-  call fastcc void @"kfun:kotlin.Throwable#<init>(kotlin.String?;kotlin.Throwable?){}"(%struct.ObjHeader* nonnull %181, %struct.ObjHeader* null)
-  call fastcc void @ThrowException(%struct.ObjHeader* nonnull %181) #50
+  %174 = getelementptr inbounds [10 x %struct.ObjHeader*], [10 x %struct.ObjHeader*]* %2, i64 0, i64 3
+  %175 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 6
+  %176 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %175 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
+  %177 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %176 unordered, align 8, !tbaa !3
+  %178 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %177, i64 0, i32 2, i32 1
+  %179 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %178, i64 56) #37
+  %180 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %179, i64 1
+  %181 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %179, i64 2
+  %182 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %181 to %struct.ObjHeader*
+  %183 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %181 to %struct.TypeInfo**
+  %184 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %180 to i64*
+  store i64 0, i64* %184, align 8
+  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [5 x i8*] }, { %struct.TypeInfo, [5 x i8*] }* @"ktypeglobal:kotlin.OutOfMemoryError#internal", i64 0, i32 0), %struct.TypeInfo** %183, align 8, !tbaa !14
+  %185 = bitcast %struct.ObjHeader** %174 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %181, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %185, align 8, !tbaa !3
+  call fastcc void @"kfun:kotlin.Throwable#<init>(kotlin.String?;kotlin.Throwable?){}"(%struct.ObjHeader* nonnull %182, %struct.ObjHeader* null)
+  call fastcc void @ThrowException(%struct.ObjHeader* nonnull %182) #50
   unreachable
 
 when_exit.i4.i:                                   ; preds = %when_next.i41
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %33)
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %33, i8 0, i32 32, i1 immarg false) #49
-  %185 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %186 = bitcast %"class.kotlin::mm::ShadowStack"* %185 to i64*
-  %187 = load i64, i64* %186, align 8, !tbaa !7
-  store i64 %187, i64* %37, align 8, !tbaa !9
-  %188 = bitcast %"class.kotlin::mm::ShadowStack"* %185 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %188, align 8, !tbaa !7
+  %186 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
+  %187 = bitcast %"class.kotlin::mm::ShadowStack"* %186 to i64*
+  %188 = load atomic i64, i64* %187 unordered, align 8, !tbaa !7
+  store i64 %188, i64* %37, align 8, !tbaa !9
+  %189 = bitcast %"class.kotlin::mm::ShadowStack"* %186 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %189, align 8, !tbaa !7
   store i32 0, i32* %39, align 8, !tbaa !12
   store i32 4, i32* %40, align 4, !tbaa !13
-  %189 = load %struct.ObjHeader*, %struct.ObjHeader** %44, align 8
-  store %struct.ObjHeader* %189, %struct.ObjHeader** %34, align 8, !tbaa !3
-  %190 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %189, i64 1
-  %191 = bitcast %struct.ObjHeader* %190 to i32*
-  %192 = load i32, i32* %191, align 8, !tbaa !18
-  %193 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %194 = load i64, i64* %37, align 8, !tbaa !9
-  %195 = bitcast %"class.kotlin::mm::ShadowStack"* %193 to i64*
-  store i64 %194, i64* %195, align 8, !tbaa !7
+  %190 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %44 unordered, align 8
+  store %struct.ObjHeader* %190, %struct.ObjHeader** %34, align 8, !tbaa !3
+  %191 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %190, i64 1
+  %192 = bitcast %struct.ObjHeader* %191 to i32*
+  %193 = load atomic i32, i32* %192 unordered, align 8, !tbaa !18
+  %194 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
+  %195 = load atomic i64, i64* %37 unordered, align 8, !tbaa !9
+  %196 = bitcast %"class.kotlin::mm::ShadowStack"* %194 to i64*
+  store i64 %195, i64* %196, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %33)
-  %196 = icmp slt i32 %192, %167
-  br i1 %196, label %when_case2.i5.i, label %"kfun:kotlin.collections.HashMap.ensureCapacity#internal.exit.i"
+  %197 = icmp slt i32 %193, %168
+  br i1 %197, label %when_case2.i5.i, label %"kfun:kotlin.collections.HashMap.ensureCapacity#internal.exit.i"
 
 when_case2.i5.i:                                  ; preds = %when_exit.i4.i
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %33)
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %33, i8 0, i32 32, i1 immarg false) #49
-  store i64 %194, i64* %37, align 8, !tbaa !9
-  %197 = bitcast %"class.kotlin::mm::ShadowStack"* %193 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %197, align 8, !tbaa !7
+  %198 = load atomic i64, i64* %196 unordered, align 8, !tbaa !7
+  store i64 %198, i64* %37, align 8, !tbaa !9
+  %199 = bitcast %"class.kotlin::mm::ShadowStack"* %194 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %199, align 8, !tbaa !7
   store i32 0, i32* %39, align 8, !tbaa !12
   store i32 4, i32* %40, align 4, !tbaa !13
-  %198 = load %struct.ObjHeader*, %struct.ObjHeader** %44, align 8
-  store %struct.ObjHeader* %198, %struct.ObjHeader** %34, align 8, !tbaa !3
-  %199 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %198, i64 1
-  %200 = bitcast %struct.ObjHeader* %199 to i32*
-  %201 = load i32, i32* %200, align 8, !tbaa !18
-  %202 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %203 = load i64, i64* %37, align 8, !tbaa !9
-  %204 = bitcast %"class.kotlin::mm::ShadowStack"* %202 to i64*
-  store i64 %203, i64* %204, align 8, !tbaa !7
+  %200 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %44 unordered, align 8
+  store %struct.ObjHeader* %200, %struct.ObjHeader** %34, align 8, !tbaa !3
+  %201 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %200, i64 1
+  %202 = bitcast %struct.ObjHeader* %201 to i32*
+  %203 = load atomic i32, i32* %202 unordered, align 8, !tbaa !18
+  %204 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
+  %205 = load atomic i64, i64* %37 unordered, align 8, !tbaa !9
+  %206 = bitcast %"class.kotlin::mm::ShadowStack"* %204 to i64*
+  store i64 %205, i64* %206, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %33)
-  %205 = mul i32 %201, 3
-  %206 = sdiv i32 %205, 2
-  %207 = icmp slt i32 %206, %167
-  %spec.select77 = select i1 %207, i32 %167, i32 %206
-  %208 = load %struct.ObjHeader*, %struct.ObjHeader** %44, align 8
-  store %struct.ObjHeader* %208, %struct.ObjHeader** %49, align 8, !tbaa !3
-  %209 = call fastcc %struct.ObjHeader* @"kfun:kotlin.collections#copyOfUninitializedElements__at__kotlin.Array<0:0>(kotlin.Int;kotlin.Int){0\C2\A7<kotlin.Any?>}kotlin.Array<0:0>"(%struct.ObjHeader* %208, i32 %spec.select77, %struct.ObjHeader** nonnull %50)
-  store %struct.ObjHeader* %209, %struct.ObjHeader** %50, align 8, !tbaa !3
-  store %struct.ObjHeader* %209, %struct.ObjHeader** %44, align 8, !tbaa !3
-  %210 = load %struct.ObjHeader*, %struct.ObjHeader** %62, align 8
-  store %struct.ObjHeader* %210, %struct.ObjHeader** %51, align 8, !tbaa !3
-  %211 = icmp eq %struct.ObjHeader* %210, null
-  br i1 %211, label %when_exit14.i.i, label %when_next.i6.i
+  %207 = mul i32 %203, 3
+  %208 = sdiv i32 %207, 2
+  %209 = icmp slt i32 %208, %168
+  %spec.select77 = select i1 %209, i32 %168, i32 %208
+  %210 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %44 unordered, align 8
+  store %struct.ObjHeader* %210, %struct.ObjHeader** %49, align 8, !tbaa !3
+  %211 = call fastcc %struct.ObjHeader* @"kfun:kotlin.collections#copyOfUninitializedElements__at__kotlin.Array<0:0>(kotlin.Int;kotlin.Int){0\C2\A7<kotlin.Any?>}kotlin.Array<0:0>"(%struct.ObjHeader* %210, i32 %spec.select77, %struct.ObjHeader** nonnull %50)
+  store %struct.ObjHeader* %211, %struct.ObjHeader** %50, align 8, !tbaa !3
+  store %struct.ObjHeader* %211, %struct.ObjHeader** %44, align 8, !tbaa !3
+  %212 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %62 unordered, align 8
+  store %struct.ObjHeader* %212, %struct.ObjHeader** %51, align 8, !tbaa !3
+  %213 = icmp eq %struct.ObjHeader* %212, null
+  br i1 %213, label %when_exit14.i.i, label %when_next.i6.i
 
 when_next.i6.i:                                   ; preds = %when_case2.i5.i
-  %212 = call fastcc %struct.ObjHeader* @"kfun:kotlin.collections#copyOfUninitializedElements__at__kotlin.Array<0:0>(kotlin.Int;kotlin.Int){0\C2\A7<kotlin.Any?>}kotlin.Array<0:0>"(%struct.ObjHeader* nonnull %210, i32 %spec.select77, %struct.ObjHeader** nonnull %52)
-  store %struct.ObjHeader* %212, %struct.ObjHeader** %52, align 8, !tbaa !3
+  %214 = call fastcc %struct.ObjHeader* @"kfun:kotlin.collections#copyOfUninitializedElements__at__kotlin.Array<0:0>(kotlin.Int;kotlin.Int){0\C2\A7<kotlin.Any?>}kotlin.Array<0:0>"(%struct.ObjHeader* nonnull %212, i32 %spec.select77, %struct.ObjHeader** nonnull %52)
+  store %struct.ObjHeader* %214, %struct.ObjHeader** %52, align 8, !tbaa !3
   br label %when_exit14.i.i
 
 when_exit14.i.i:                                  ; preds = %when_next.i6.i, %when_case2.i5.i
-  %213 = phi %struct.ObjHeader* [ %212, %when_next.i6.i ], [ null, %when_case2.i5.i ]
-  store %struct.ObjHeader* %213, %struct.ObjHeader** %62, align 8, !tbaa !3
-  %214 = load %struct.ObjHeader*, %struct.ObjHeader** %64, align 8
-  store %struct.ObjHeader* %214, %struct.ObjHeader** %53, align 8, !tbaa !3
-  %215 = call fastcc %struct.ObjHeader* @"kfun:kotlin.collections#copyOfUninitializedElements__at__kotlin.IntArray(kotlin.Int;kotlin.Int){}kotlin.IntArray"(%struct.ObjHeader* %214, i32 %spec.select77, %struct.ObjHeader** nonnull %54)
-  store %struct.ObjHeader* %215, %struct.ObjHeader** %54, align 8, !tbaa !3
-  store %struct.ObjHeader* %215, %struct.ObjHeader** %64, align 8, !tbaa !3
-  %216 = icmp slt i32 %spec.select77, 1
-  br i1 %216, label %"kfun:kotlin.ranges#coerceAtLeast__at__kotlin.Int(kotlin.Int){}kotlin.Int.exit.i.i.i.thread", label %"kfun:kotlin.ranges#coerceAtLeast__at__kotlin.Int(kotlin.Int){}kotlin.Int.exit.i.i.i"
+  %215 = phi %struct.ObjHeader* [ %214, %when_next.i6.i ], [ null, %when_case2.i5.i ]
+  store %struct.ObjHeader* %215, %struct.ObjHeader** %62, align 8, !tbaa !3
+  %216 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %64 unordered, align 8
+  store %struct.ObjHeader* %216, %struct.ObjHeader** %53, align 8, !tbaa !3
+  %217 = call fastcc %struct.ObjHeader* @"kfun:kotlin.collections#copyOfUninitializedElements__at__kotlin.IntArray(kotlin.Int;kotlin.Int){}kotlin.IntArray"(%struct.ObjHeader* %216, i32 %spec.select77, %struct.ObjHeader** nonnull %54)
+  store %struct.ObjHeader* %217, %struct.ObjHeader** %54, align 8, !tbaa !3
+  store %struct.ObjHeader* %217, %struct.ObjHeader** %64, align 8, !tbaa !3
+  %218 = icmp slt i32 %spec.select77, 1
+  br i1 %218, label %"kfun:kotlin.ranges#coerceAtLeast__at__kotlin.Int(kotlin.Int){}kotlin.Int.exit.i.i.i.thread", label %"kfun:kotlin.ranges#coerceAtLeast__at__kotlin.Int(kotlin.Int){}kotlin.Int.exit.i.i.i"
 
 "kfun:kotlin.ranges#coerceAtLeast__at__kotlin.Int(kotlin.Int){}kotlin.Int.exit.i.i.i.thread": ; preds = %when_exit14.i.i
   br label %when_next.i2.i.i.i
 
 "kfun:kotlin.ranges#coerceAtLeast__at__kotlin.Int(kotlin.Int){}kotlin.Int.exit.i.i.i": ; preds = %when_exit14.i.i
-  %217 = mul i32 %spec.select77, 3
-  %218 = icmp eq i32 %217, 0
-  br i1 %218, label %"kfun:kotlin.collections.HashMap.Companion.computeHashSize#internal.exit.i.i", label %when_next.i2.i.i.i
+  %219 = mul i32 %spec.select77, 3
+  %220 = icmp eq i32 %219, 0
+  br i1 %220, label %"kfun:kotlin.collections.HashMap.Companion.computeHashSize#internal.exit.i.i", label %when_next.i2.i.i.i
 
 when_next.i2.i.i.i:                               ; preds = %"kfun:kotlin.ranges#coerceAtLeast__at__kotlin.Int(kotlin.Int){}kotlin.Int.exit.i.i.i", %"kfun:kotlin.ranges#coerceAtLeast__at__kotlin.Int(kotlin.Int){}kotlin.Int.exit.i.i.i.thread"
-  %219 = phi i32 [ 3, %"kfun:kotlin.ranges#coerceAtLeast__at__kotlin.Int(kotlin.Int){}kotlin.Int.exit.i.i.i.thread" ], [ %217, %"kfun:kotlin.ranges#coerceAtLeast__at__kotlin.Int(kotlin.Int){}kotlin.Int.exit.i.i.i" ]
-  %220 = call i32 @llvm.ctlz.i32(i32 %219, i1 true) #37, !range !31
-  %221 = xor i32 %220, 31
-  %222 = shl i32 1, %221
+  %221 = phi i32 [ 3, %"kfun:kotlin.ranges#coerceAtLeast__at__kotlin.Int(kotlin.Int){}kotlin.Int.exit.i.i.i.thread" ], [ %219, %"kfun:kotlin.ranges#coerceAtLeast__at__kotlin.Int(kotlin.Int){}kotlin.Int.exit.i.i.i" ]
+  %222 = call i32 @llvm.ctlz.i32(i32 %221, i1 true) #37, !range !23
+  %223 = xor i32 %222, 31
+  %224 = shl i32 1, %223
   br label %"kfun:kotlin.collections.HashMap.Companion.computeHashSize#internal.exit.i.i"
 
 "kfun:kotlin.collections.HashMap.Companion.computeHashSize#internal.exit.i.i": ; preds = %when_next.i2.i.i.i, %"kfun:kotlin.ranges#coerceAtLeast__at__kotlin.Int(kotlin.Int){}kotlin.Int.exit.i.i.i"
-  %223 = phi i32 [ %222, %when_next.i2.i.i.i ], [ 0, %"kfun:kotlin.ranges#coerceAtLeast__at__kotlin.Int(kotlin.Int){}kotlin.Int.exit.i.i.i" ]
+  %225 = phi i32 [ %224, %when_next.i2.i.i.i ], [ 0, %"kfun:kotlin.ranges#coerceAtLeast__at__kotlin.Int(kotlin.Int){}kotlin.Int.exit.i.i.i" ]
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %33)
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %33, i8 0, i32 32, i1 immarg false) #49
-  %224 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %225 = bitcast %"class.kotlin::mm::ShadowStack"* %224 to i64*
-  %226 = load i64, i64* %225, align 8, !tbaa !7
-  store i64 %226, i64* %37, align 8, !tbaa !9
-  %227 = bitcast %"class.kotlin::mm::ShadowStack"* %224 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %227, align 8, !tbaa !7
+  %226 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
+  %227 = bitcast %"class.kotlin::mm::ShadowStack"* %226 to i64*
+  %228 = load atomic i64, i64* %227 unordered, align 8, !tbaa !7
+  store i64 %228, i64* %37, align 8, !tbaa !9
+  %229 = bitcast %"class.kotlin::mm::ShadowStack"* %226 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %229, align 8, !tbaa !7
   store i32 0, i32* %39, align 8, !tbaa !12
   store i32 4, i32* %40, align 4, !tbaa !13
-  %228 = load %struct.ObjHeader*, %struct.ObjHeader** %42, align 8
-  store %struct.ObjHeader* %228, %struct.ObjHeader** %34, align 8, !tbaa !3
-  %229 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %228, i64 1
-  %230 = bitcast %struct.ObjHeader* %229 to i32*
-  %231 = load i32, i32* %230, align 8, !tbaa !18
-  %232 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %233 = load i64, i64* %37, align 8, !tbaa !9
-  %234 = bitcast %"class.kotlin::mm::ShadowStack"* %232 to i64*
-  store i64 %233, i64* %234, align 8, !tbaa !7
+  %230 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %42 unordered, align 8
+  store %struct.ObjHeader* %230, %struct.ObjHeader** %34, align 8, !tbaa !3
+  %231 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %230, i64 1
+  %232 = bitcast %struct.ObjHeader* %231 to i32*
+  %233 = load atomic i32, i32* %232 unordered, align 8, !tbaa !18
+  %234 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
+  %235 = load atomic i64, i64* %37 unordered, align 8, !tbaa !9
+  %236 = bitcast %"class.kotlin::mm::ShadowStack"* %234 to i64*
+  store i64 %235, i64* %236, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %33)
-  %235 = icmp sgt i32 %223, %231
-  br i1 %235, label %when_case18.i.i, label %"kfun:kotlin.collections.HashMap.ensureCapacity#internal.exit.i"
+  %237 = icmp sgt i32 %225, %233
+  br i1 %237, label %when_case18.i.i, label %"kfun:kotlin.collections.HashMap.ensureCapacity#internal.exit.i"
 
 when_case18.i.i:                                  ; preds = %"kfun:kotlin.collections.HashMap.Companion.computeHashSize#internal.exit.i.i"
-  call fastcc void @"kfun:kotlin.collections.HashMap.rehash#internal"(%struct.ObjHeader* %0, i32 %223)
+  call fastcc void @"kfun:kotlin.collections.HashMap.rehash#internal"(%struct.ObjHeader* %0, i32 %225)
   br label %"kfun:kotlin.collections.HashMap.ensureCapacity#internal.exit.i"
 
 "kfun:kotlin.collections.HashMap.ensureCapacity#internal.exit.i": ; preds = %when_case18.i.i, %"kfun:kotlin.collections.HashMap.Companion.computeHashSize#internal.exit.i.i", %when_exit.i4.i
-  %236 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %12, %"kfun:kotlin.collections.HashMap.Companion.computeHashSize#internal.exit.i.i" ], [ %12, %when_case18.i.i ], [ %12, %when_exit.i4.i ]
-  %237 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %236, i64 0, i32 1, i32 5
-  %238 = load i64, i64* %57, align 8, !tbaa !9
-  %239 = bitcast %"class.kotlin::mm::ShadowStack"* %237 to i64*
-  store i64 %238, i64* %239, align 8, !tbaa !7
+  %238 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %12, %"kfun:kotlin.collections.HashMap.Companion.computeHashSize#internal.exit.i.i" ], [ %12, %when_case18.i.i ], [ %12, %when_exit.i4.i ]
+  %239 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %238, i64 0, i32 1, i32 5
+  %240 = load atomic i64, i64* %57 unordered, align 8, !tbaa !9
+  %241 = bitcast %"class.kotlin::mm::ShadowStack"* %239 to i64*
+  store i64 %240, i64* %241, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %48)
   br label %while_loop.backedge
 
 when_exit14:                                      ; preds = %call_success13
-  %240 = load i32, i32* %46, align 4
-  %241 = add i32 %240, 1
-  store i32 %241, i32* %46, align 4
-  %242 = load %struct.ObjHeader*, %struct.ObjHeader** %44, align 8
-  store %struct.ObjHeader* %242, %struct.ObjHeader** %7, align 8, !tbaa !3
-  %243 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %242, i64 1
-  %244 = bitcast %struct.ObjHeader* %243 to i32*
-  %245 = load i32, i32* %244, align 8, !tbaa !18
-  %246 = icmp ugt i32 %245, %240
-  br i1 %246, label %call_success16, label %247
+  %242 = load atomic i32, i32* %46 unordered, align 4
+  %243 = add i32 %242, 1
+  store i32 %243, i32* %46, align 4
+  %244 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %44 unordered, align 8
+  store %struct.ObjHeader* %244, %struct.ObjHeader** %7, align 8, !tbaa !3
+  %245 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %244, i64 1
+  %246 = bitcast %struct.ObjHeader* %245 to i32*
+  %247 = load atomic i32, i32* %246 unordered, align 8, !tbaa !18
+  %248 = icmp ugt i32 %247, %242
+  br i1 %248, label %call_success16, label %249
 
-247:                                              ; preds = %when_exit14
+249:                                              ; preds = %when_exit14
   call fastcc void @ThrowArrayIndexOutOfBoundsException() #50
   unreachable
 
 call_success16:                                   ; preds = %when_exit14
-  %248 = bitcast %struct.ObjHeader* %242 to i64*
-  %249 = load atomic volatile i64, i64* %248 monotonic, align 8
-  %250 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %242, i64 2
-  %251 = sext i32 %240 to i64
-  %252 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %250, i64 %251
-  %253 = bitcast %struct.ObjHeader* %252 to %struct.ObjHeader**
-  store %struct.ObjHeader* %1, %struct.ObjHeader** %253, align 8, !tbaa !3
-  %254 = load %struct.ObjHeader*, %struct.ObjHeader** %64, align 8
-  store %struct.ObjHeader* %254, %struct.ObjHeader** %8, align 8, !tbaa !3
-  %255 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %254, i64 1
-  %256 = bitcast %struct.ObjHeader* %255 to i32*
-  %257 = load i32, i32* %256, align 8, !tbaa !18
-  %258 = icmp ugt i32 %257, %240
-  br i1 %258, label %call_success17, label %259
+  %250 = bitcast %struct.ObjHeader* %244 to i64*
+  %251 = load atomic volatile i64, i64* %250 monotonic, align 8
+  %252 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %244, i64 2
+  %253 = sext i32 %242 to i64
+  %254 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %252, i64 %253
+  %255 = bitcast %struct.ObjHeader* %254 to %struct.ObjHeader**
+  store %struct.ObjHeader* %1, %struct.ObjHeader** %255, align 8, !tbaa !3
+  %256 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %64 unordered, align 8
+  store %struct.ObjHeader* %256, %struct.ObjHeader** %8, align 8, !tbaa !3
+  %257 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %256, i64 1
+  %258 = bitcast %struct.ObjHeader* %257 to i32*
+  %259 = load atomic i32, i32* %258 unordered, align 8, !tbaa !18
+  %260 = icmp ugt i32 %259, %242
+  br i1 %260, label %call_success17, label %261
 
-259:                                              ; preds = %call_success16
+261:                                              ; preds = %call_success16
   call fastcc void @ThrowArrayIndexOutOfBoundsException() #50
   unreachable
 
 call_success17:                                   ; preds = %call_success16
-  %260 = bitcast %struct.ObjHeader* %254 to i64*
-  %261 = load atomic volatile i64, i64* %260 monotonic, align 8
-  %262 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %254, i64 2
-  %263 = bitcast %struct.ObjHeader* %262 to i32*
-  %264 = getelementptr inbounds i32, i32* %263, i64 %251
-  store i32 %hash.1, i32* %264, align 4, !tbaa !73
-  %265 = load %struct.ObjHeader*, %struct.ObjHeader** %42, align 8
-  store %struct.ObjHeader* %265, %struct.ObjHeader** %9, align 8, !tbaa !3
-  %266 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %265, i64 1
-  %267 = bitcast %struct.ObjHeader* %266 to i32*
-  %268 = load i32, i32* %267, align 8, !tbaa !18
-  %269 = icmp ugt i32 %268, %hash.1
-  br i1 %269, label %call_success18, label %270
+  %262 = bitcast %struct.ObjHeader* %256 to i64*
+  %263 = load atomic volatile i64, i64* %262 monotonic, align 8
+  %264 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %256, i64 2
+  %265 = bitcast %struct.ObjHeader* %264 to i32*
+  %266 = getelementptr inbounds i32, i32* %265, i64 %253
+  store i32 %hash.1, i32* %266, align 4, !tbaa !71
+  %267 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %42 unordered, align 8
+  store %struct.ObjHeader* %267, %struct.ObjHeader** %9, align 8, !tbaa !3
+  %268 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %267, i64 1
+  %269 = bitcast %struct.ObjHeader* %268 to i32*
+  %270 = load atomic i32, i32* %269 unordered, align 8, !tbaa !18
+  %271 = icmp ugt i32 %270, %hash.1
+  br i1 %271, label %call_success18, label %272
 
-270:                                              ; preds = %call_success17
+272:                                              ; preds = %call_success17
   call fastcc void @ThrowArrayIndexOutOfBoundsException() #50
   unreachable
 
 call_success18:                                   ; preds = %call_success17
-  %271 = bitcast %struct.ObjHeader* %265 to i64*
-  %272 = load atomic volatile i64, i64* %271 monotonic, align 8
-  %273 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %265, i64 2
-  %274 = bitcast %struct.ObjHeader* %273 to i32*
-  %275 = getelementptr inbounds i32, i32* %274, i64 %112
-  store i32 %241, i32* %275, align 4, !tbaa !73
-  %276 = load i32, i32* %47, align 4
-  %277 = add i32 %276, 1
-  store i32 %277, i32* %47, align 4
-  %278 = load i32, i32* %32, align 4
-  %279 = icmp sgt i32 %probeDistance.0, %278
-  br i1 %279, label %when_case19, label %epilogue
+  %273 = bitcast %struct.ObjHeader* %267 to i64*
+  %274 = load atomic volatile i64, i64* %273 monotonic, align 8
+  %275 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %267, i64 2
+  %276 = bitcast %struct.ObjHeader* %275 to i32*
+  %277 = getelementptr inbounds i32, i32* %276, i64 %112
+  store i32 %243, i32* %277, align 4, !tbaa !71
+  %278 = load atomic i32, i32* %47 unordered, align 4
+  %279 = add i32 %278, 1
+  store i32 %279, i32* %47, align 4
+  %280 = load atomic i32, i32* %32 unordered, align 4
+  %281 = icmp sgt i32 %probeDistance.0, %280
+  br i1 %281, label %when_case19, label %epilogue
 
 when_case19:                                      ; preds = %call_success18
   store i32 %probeDistance.0, i32* %32, align 4
   br label %epilogue
 
 when_exit:                                        ; preds = %call_success11
-  %280 = load %struct.ObjHeader*, %struct.ObjHeader** %44, align 8
-  store %struct.ObjHeader* %280, %struct.ObjHeader** %10, align 8, !tbaa !3
-  %281 = add i32 %114, -1
-  %282 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %280, i64 1
-  %283 = bitcast %struct.ObjHeader* %282 to i32*
-  %284 = load i32, i32* %283, align 8, !tbaa !18
-  %285 = icmp ugt i32 %284, %281
-  br i1 %285, label %call_success22, label %286
+  %282 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %44 unordered, align 8
+  store %struct.ObjHeader* %282, %struct.ObjHeader** %10, align 8, !tbaa !3
+  %283 = add i32 %114, -1
+  %284 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %282, i64 1
+  %285 = bitcast %struct.ObjHeader* %284 to i32*
+  %286 = load atomic i32, i32* %285 unordered, align 8, !tbaa !18
+  %287 = icmp ugt i32 %286, %283
+  br i1 %287, label %call_success22, label %288
 
-286:                                              ; preds = %when_exit
+288:                                              ; preds = %when_exit
   call fastcc void @ThrowArrayIndexOutOfBoundsException() #50
   unreachable
 
 call_success22:                                   ; preds = %when_exit
-  %287 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %280, i64 2
-  %288 = sext i32 %281 to i64
-  %289 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %287, i64 %288
-  %290 = bitcast %struct.ObjHeader* %289 to %struct.ObjHeader**
-  %291 = load %struct.ObjHeader*, %struct.ObjHeader** %290, align 8, !tbaa !3
-  store %struct.ObjHeader* %291, %struct.ObjHeader** %11, align 8, !tbaa !3
-  %292 = icmp eq %struct.ObjHeader* %291, null
-  br i1 %292, label %when_case23, label %when_exit24
+  %289 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %282, i64 2
+  %290 = sext i32 %283 to i64
+  %291 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %289, i64 %290
+  %292 = bitcast %struct.ObjHeader* %291 to %struct.ObjHeader**
+  %293 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %292 unordered, align 8, !tbaa !3
+  store %struct.ObjHeader* %293, %struct.ObjHeader** %11, align 8, !tbaa !3
+  %294 = icmp eq %struct.ObjHeader* %293, null
+  br i1 %294, label %when_case23, label %when_exit24
 
 when_case23:                                      ; preds = %call_success22
   br i1 %27, label %when_case21, label %when_exit26
 
 when_exit24:                                      ; preds = %call_success22
-  %293 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %291, i64 0, i32 0
-  %294 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %293 monotonic, align 8
-  %295 = ptrtoint %struct.TypeInfo* %294 to i64
-  %296 = and i64 %295, -4
-  %297 = inttoptr i64 %296 to %struct.TypeInfo*
-  %298 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %297, i64 0, i32 0
-  %299 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %298 monotonic, align 8
-  %300 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %299, i64 1
-  %301 = bitcast %struct.TypeInfo* %300 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
-  %302 = load i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %301, align 8
-  %303 = call zeroext i1 %302(%struct.ObjHeader* nonnull %291, %struct.ObjHeader* %1)
-  br i1 %303, label %when_case21, label %when_exit26
+  %295 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %293, i64 0, i32 0
+  %296 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %295 monotonic, align 8
+  %297 = ptrtoint %struct.TypeInfo* %296 to i64
+  %298 = and i64 %297, -4
+  %299 = inttoptr i64 %298 to %struct.TypeInfo*
+  %300 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %299, i64 0, i32 0
+  %301 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %300 monotonic, align 8
+  %302 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %301, i64 1
+  %303 = bitcast %struct.TypeInfo* %302 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
+  %304 = load atomic i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %303 unordered, align 8
+  %305 = call zeroext i1 %304(%struct.ObjHeader* nonnull %293, %struct.ObjHeader* %1)
+  br i1 %305, label %when_case21, label %when_exit26
 
 when_case21:                                      ; preds = %when_exit24, %when_case23
-  %304 = sub i32 0, %114
+  %306 = sub i32 0, %114
   br label %epilogue
 
 when_exit26:                                      ; preds = %when_exit24, %when_case23
-  %305 = add nuw nsw i32 %probeDistance.0, 1
+  %307 = add nuw nsw i32 %probeDistance.0, 1
   %exitcond = icmp eq i32 %probeDistance.0, %99
   br i1 %exitcond, label %call_success30, label %when_exit28
 
 call_success30:                                   ; preds = %when_exit26
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %33)
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %33, i8 0, i32 32, i1 immarg false) #49
-  %306 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %307 = bitcast %"class.kotlin::mm::ShadowStack"* %306 to i64*
-  %308 = load i64, i64* %307, align 8, !tbaa !7
-  store i64 %308, i64* %37, align 8, !tbaa !9
-  %309 = bitcast %"class.kotlin::mm::ShadowStack"* %306 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %309, align 8, !tbaa !7
+  %308 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
+  %309 = bitcast %"class.kotlin::mm::ShadowStack"* %308 to i64*
+  %310 = load atomic i64, i64* %309 unordered, align 8, !tbaa !7
+  store i64 %310, i64* %37, align 8, !tbaa !9
+  %311 = bitcast %"class.kotlin::mm::ShadowStack"* %308 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %311, align 8, !tbaa !7
   store i32 0, i32* %39, align 8, !tbaa !12
   store i32 4, i32* %40, align 4, !tbaa !13
-  %310 = load %struct.ObjHeader*, %struct.ObjHeader** %42, align 8
-  store %struct.ObjHeader* %310, %struct.ObjHeader** %34, align 8, !tbaa !3
-  %311 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %310, i64 1
-  %312 = bitcast %struct.ObjHeader* %311 to i32*
-  %313 = load i32, i32* %312, align 8, !tbaa !18
-  %314 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %315 = load i64, i64* %37, align 8, !tbaa !9
-  %316 = bitcast %"class.kotlin::mm::ShadowStack"* %314 to i64*
-  store i64 %315, i64* %316, align 8, !tbaa !7
+  %312 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %42 unordered, align 8
+  store %struct.ObjHeader* %312, %struct.ObjHeader** %34, align 8, !tbaa !3
+  %313 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %312, i64 1
+  %314 = bitcast %struct.ObjHeader* %313 to i32*
+  %315 = load atomic i32, i32* %314 unordered, align 8, !tbaa !18
+  %316 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
+  %317 = load atomic i64, i64* %37 unordered, align 8, !tbaa !9
+  %318 = bitcast %"class.kotlin::mm::ShadowStack"* %316 to i64*
+  store i64 %317, i64* %318, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %33)
-  %317 = shl i32 %313, 1
-  call fastcc void @"kfun:kotlin.collections.HashMap.rehash#internal"(%struct.ObjHeader* %0, i32 %317)
+  %319 = shl i32 %315, 1
+  call fastcc void @"kfun:kotlin.collections.HashMap.rehash#internal"(%struct.ObjHeader* %0, i32 %319)
   br label %while_loop.backedge
 
 while_loop.backedge:                              ; preds = %call_success30, %"kfun:kotlin.collections.HashMap.ensureCapacity#internal.exit.i", %when_case.i40
   br label %while_loop
 
 when_exit28:                                      ; preds = %when_exit26
-  %318 = icmp eq i32 %hash.1, 0
-  br i1 %318, label %call_success33, label %when_exit32
+  %320 = icmp eq i32 %hash.1, 0
+  br i1 %320, label %call_success33, label %when_exit32
 
 call_success33:                                   ; preds = %when_exit28
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %33)
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %33, i8 0, i32 32, i1 immarg false) #49
-  %319 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %320 = bitcast %"class.kotlin::mm::ShadowStack"* %319 to i64*
-  %321 = load i64, i64* %320, align 8, !tbaa !7
-  store i64 %321, i64* %37, align 8, !tbaa !9
-  %322 = bitcast %"class.kotlin::mm::ShadowStack"* %319 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %322, align 8, !tbaa !7
+  %321 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
+  %322 = bitcast %"class.kotlin::mm::ShadowStack"* %321 to i64*
+  %323 = load atomic i64, i64* %322 unordered, align 8, !tbaa !7
+  store i64 %323, i64* %37, align 8, !tbaa !9
+  %324 = bitcast %"class.kotlin::mm::ShadowStack"* %321 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i35, %struct.ObjHeader*** %324, align 8, !tbaa !7
   store i32 0, i32* %39, align 8, !tbaa !12
   store i32 4, i32* %40, align 4, !tbaa !13
-  %323 = load %struct.ObjHeader*, %struct.ObjHeader** %42, align 8
-  store %struct.ObjHeader* %323, %struct.ObjHeader** %34, align 8, !tbaa !3
-  %324 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %323, i64 1
-  %325 = bitcast %struct.ObjHeader* %324 to i32*
-  %326 = load i32, i32* %325, align 8, !tbaa !18
-  %327 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %328 = load i64, i64* %37, align 8, !tbaa !9
-  %329 = bitcast %"class.kotlin::mm::ShadowStack"* %327 to i64*
-  store i64 %328, i64* %329, align 8, !tbaa !7
+  %325 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %42 unordered, align 8
+  store %struct.ObjHeader* %325, %struct.ObjHeader** %34, align 8, !tbaa !3
+  %326 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %325, i64 1
+  %327 = bitcast %struct.ObjHeader* %326 to i32*
+  %328 = load atomic i32, i32* %327 unordered, align 8, !tbaa !18
+  %329 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
+  %330 = load atomic i64, i64* %37 unordered, align 8, !tbaa !9
+  %331 = bitcast %"class.kotlin::mm::ShadowStack"* %329 to i64*
+  store i64 %330, i64* %331, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %33)
   br label %when_exit32
 
 when_exit32:                                      ; preds = %call_success33, %when_exit28
-  %hash.0.in = phi i32 [ %326, %call_success33 ], [ %hash.1, %when_exit28 ]
+  %hash.0.in = phi i32 [ %328, %call_success33 ], [ %hash.1, %when_exit28 ]
   %hash.0 = add i32 %hash.0.in, -1
   br label %while_loop10
 
 epilogue:                                         ; preds = %when_case21, %when_case19, %call_success18
-  %330 = phi i32 [ %304, %when_case21 ], [ %240, %when_case19 ], [ %240, %call_success18 ]
-  %331 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
-  %332 = load i64, i64* %18, align 8, !tbaa !9
-  %333 = bitcast %"class.kotlin::mm::ShadowStack"* %331 to i64*
-  store i64 %332, i64* %333, align 8, !tbaa !7
-  ret i32 %330
+  %332 = phi i32 [ %306, %when_case21 ], [ %242, %when_case19 ], [ %242, %call_success18 ]
+  %333 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %12, i64 0, i32 1, i32 5
+  %334 = load atomic i64, i64* %18 unordered, align 8, !tbaa !9
+  %335 = bitcast %"class.kotlin::mm::ShadowStack"* %333 to i64*
+  store i64 %334, i64* %335, align 8, !tbaa !7
+  ret i32 %332
 }
 
 define internal fastcc i32 @"kfun:kotlin.collections.HashMap#removeKey(1:0){}kotlin.Int"(%struct.ObjHeader* nocapture %0, %struct.ObjHeader* %1) unnamed_addr #3 personality i32 (...)* @__gxx_personality_v0 {
@@ -11993,11 +12070,11 @@
   %6 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %4, i64 0, i64 3
   %7 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %4, i64 0, i64 4
   %8 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %4, i64 0, i64 5
-  %9 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %9 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %10 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
   %11 = bitcast [6 x %struct.ObjHeader*]* %4 to %struct.FrameOverlay.6*
   %12 = bitcast %"class.kotlin::mm::ShadowStack"* %10 to i64*
-  %13 = load i64, i64* %12, align 8, !tbaa !7
+  %13 = load atomic i64, i64* %12 unordered, align 8, !tbaa !7
   %14 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %4, i64 0, i64 1
   %15 = bitcast %struct.ObjHeader** %14 to i64*
   store i64 %13, i64* %15, align 8, !tbaa !9
@@ -12020,16 +12097,16 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %23, %call_success
   %24 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %25 = bitcast %struct.ObjHeader* %24 to %struct.ObjHeader**
-  %26 = load %struct.ObjHeader*, %struct.ObjHeader** %25, align 8
+  %26 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %25 unordered, align 8
   store %struct.ObjHeader* %26, %struct.ObjHeader** %6, align 8, !tbaa !3
   call fastcc void @"kfun:kotlin.collections#resetAt__at__kotlin.Array<0:0>(kotlin.Int){0\C2\A7<kotlin.Any?>}"(%struct.ObjHeader* %26, i32 %1)
   %27 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 3
   %28 = bitcast %struct.ObjHeader* %27 to %struct.ObjHeader**
-  %29 = load %struct.ObjHeader*, %struct.ObjHeader** %28, align 8
+  %29 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %28 unordered, align 8
   store %struct.ObjHeader* %29, %struct.ObjHeader** %7, align 8, !tbaa !3
   %30 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %29, i64 1
   %31 = bitcast %struct.ObjHeader* %30 to i32*
-  %32 = load i32, i32* %31, align 8, !tbaa !18
+  %32 = load atomic i32, i32* %31 unordered, align 8, !tbaa !18
   %33 = icmp ugt i32 %32, %1
   br i1 %33, label %call_success1, label %34
 
@@ -12042,7 +12119,7 @@
   %36 = bitcast %struct.ObjHeader* %35 to i32*
   %37 = sext i32 %1 to i64
   %38 = getelementptr inbounds i32, i32* %36, i64 %37
-  %39 = load i32, i32* %38, align 4, !tbaa !73
+  %39 = load atomic i32, i32* %38 unordered, align 4, !tbaa !71
   %40 = bitcast [12 x %struct.ObjHeader*]* %3 to i8*
   call void @llvm.lifetime.start.p0i8(i64 96, i8* nonnull %40)
   %.sub.i = getelementptr inbounds [12 x %struct.ObjHeader*], [12 x %struct.ObjHeader*]* %3, i64 0, i64 0
@@ -12059,7 +12136,7 @@
   %50 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
   %51 = bitcast [12 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %52 = bitcast %"class.kotlin::mm::ShadowStack"* %50 to i64*
-  %53 = load i64, i64* %52, align 8, !tbaa !7
+  %53 = load atomic i64, i64* %52 unordered, align 8, !tbaa !7
   %54 = getelementptr inbounds [12 x %struct.ObjHeader*], [12 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %55 = bitcast %struct.ObjHeader** %54 to i64*
   store i64 %53, i64* %55, align 8, !tbaa !9
@@ -12072,7 +12149,7 @@
   store i32 12, i32* %59, align 4, !tbaa !13
   %60 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 8
   %61 = bitcast %struct.ObjHeader* %60 to i32*
-  %62 = load i32, i32* %61, align 4
+  %62 = load atomic i32, i32* %61 unordered, align 4
   %63 = shl i32 %62, 1
   %64 = bitcast [4 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %64)
@@ -12082,7 +12159,7 @@
   %66 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
   %67 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %68 = bitcast %"class.kotlin::mm::ShadowStack"* %66 to i64*
-  %69 = load i64, i64* %68, align 8, !tbaa !7
+  %69 = load atomic i64, i64* %68 unordered, align 8, !tbaa !7
   %70 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %71 = bitcast %struct.ObjHeader** %70 to i64*
   store i64 %69, i64* %71, align 8, !tbaa !9
@@ -12095,13 +12172,13 @@
   store i32 4, i32* %75, align 4, !tbaa !13
   %76 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 4
   %77 = bitcast %struct.ObjHeader* %76 to %struct.ObjHeader**
-  %78 = load %struct.ObjHeader*, %struct.ObjHeader** %77, align 8
+  %78 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %77 unordered, align 8
   store %struct.ObjHeader* %78, %struct.ObjHeader** %65, align 8, !tbaa !3
   %79 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %78, i64 1
   %80 = bitcast %struct.ObjHeader* %79 to i32*
-  %81 = load i32, i32* %80, align 8, !tbaa !18
+  %81 = load atomic i32, i32* %80 unordered, align 8, !tbaa !18
   %82 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
-  %83 = load i64, i64* %71, align 8, !tbaa !9
+  %83 = load atomic i64, i64* %71 unordered, align 8, !tbaa !9
   %84 = bitcast %"class.kotlin::mm::ShadowStack"* %82 to i64*
   store i64 %83, i64* %84, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %64)
@@ -12125,19 +12202,19 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %64, i8 0, i32 32, i1 immarg false) #49
   %91 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
   %92 = bitcast %"class.kotlin::mm::ShadowStack"* %91 to i64*
-  %93 = load i64, i64* %92, align 8, !tbaa !7
+  %93 = load atomic i64, i64* %92 unordered, align 8, !tbaa !7
   store i64 %93, i64* %71, align 8, !tbaa !9
   %94 = bitcast %"class.kotlin::mm::ShadowStack"* %91 to %struct.ObjHeader***
   store %struct.ObjHeader** %.sub.i.i, %struct.ObjHeader*** %94, align 8, !tbaa !7
   store i32 0, i32* %74, align 8, !tbaa !12
   store i32 4, i32* %75, align 4, !tbaa !13
-  %95 = load %struct.ObjHeader*, %struct.ObjHeader** %77, align 8
+  %95 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %77 unordered, align 8
   store %struct.ObjHeader* %95, %struct.ObjHeader** %65, align 8, !tbaa !3
   %96 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %95, i64 1
   %97 = bitcast %struct.ObjHeader* %96 to i32*
-  %98 = load i32, i32* %97, align 8, !tbaa !18
+  %98 = load atomic i32, i32* %97 unordered, align 8, !tbaa !18
   %99 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
-  %100 = load i64, i64* %71, align 8, !tbaa !9
+  %100 = load atomic i64, i64* %71 unordered, align 8, !tbaa !9
   %101 = bitcast %"class.kotlin::mm::ShadowStack"* %99 to i64*
   store i64 %100, i64* %101, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %64)
@@ -12147,16 +12224,16 @@
   %hash.0.in.i = phi i32 [ %98, %when_case.i ], [ %hash.1.i, %Kotlin_mm_safePointWhileLoopBody.exit.i ]
   %hash.0.i = add i32 %hash.0.in.i, -1
   %102 = add i32 %probeDistance.2.i, 1
-  %103 = load i32, i32* %61, align 4
+  %103 = load atomic i32, i32* %61 unordered, align 4
   %104 = icmp sgt i32 %102, %103
-  %105 = load %struct.ObjHeader*, %struct.ObjHeader** %77, align 8
+  %105 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %77 unordered, align 8
   br i1 %104, label %when_case7.i, label %when_exit8.i
 
 when_case7.i:                                     ; preds = %when_exit.i
   store %struct.ObjHeader* %105, %struct.ObjHeader** %41, align 8, !tbaa !3
   %106 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %105, i64 1
   %107 = bitcast %struct.ObjHeader* %106 to i32*
-  %108 = load i32, i32* %107, align 8, !tbaa !18
+  %108 = load atomic i32, i32* %107 unordered, align 8, !tbaa !18
   %109 = icmp ugt i32 %108, %hole.2.i
   br i1 %109, label %Kotlin_IntArray_set.exit28.i, label %110
 
@@ -12171,14 +12248,14 @@
   %114 = bitcast %struct.ObjHeader* %113 to i32*
   %115 = sext i32 %hole.2.i to i64
   %116 = getelementptr inbounds i32, i32* %114, i64 %115
-  store i32 0, i32* %116, align 4, !tbaa !73
+  store i32 0, i32* %116, align 4, !tbaa !71
   br label %call_success2
 
 when_exit8.i:                                     ; preds = %when_exit.i
   store %struct.ObjHeader* %105, %struct.ObjHeader** %42, align 8, !tbaa !3
   %117 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %105, i64 1
   %118 = bitcast %struct.ObjHeader* %117 to i32*
-  %119 = load i32, i32* %118, align 8, !tbaa !18
+  %119 = load atomic i32, i32* %118 unordered, align 8, !tbaa !18
   %120 = icmp ugt i32 %119, %hash.0.i
   br i1 %120, label %Kotlin_IntArray_get.exit.i, label %121
 
@@ -12191,7 +12268,7 @@
   %123 = bitcast %struct.ObjHeader* %122 to i32*
   %124 = sext i32 %hash.0.i to i64
   %125 = getelementptr inbounds i32, i32* %123, i64 %124
-  %126 = load i32, i32* %125, align 4, !tbaa !73
+  %126 = load atomic i32, i32* %125 unordered, align 4, !tbaa !71
   %127 = icmp eq i32 %126, 0
   br i1 %127, label %when_case11.i, label %when_exit12.i
 
@@ -12209,7 +12286,7 @@
   %131 = load atomic volatile i64, i64* %130 monotonic, align 8
   %132 = sext i32 %hole.2.i to i64
   %133 = getelementptr inbounds i32, i32* %123, i64 %132
-  store i32 0, i32* %133, align 4, !tbaa !73
+  store i32 0, i32* %133, align 4, !tbaa !71
   br label %call_success2
 
 when_exit12.i:                                    ; preds = %Kotlin_IntArray_get.exit.i
@@ -12230,16 +12307,16 @@
   %138 = load atomic volatile i64, i64* %137 monotonic, align 8
   %139 = sext i32 %hole.2.i to i64
   %140 = getelementptr inbounds i32, i32* %123, i64 %139
-  store i32 -1, i32* %140, align 4, !tbaa !73
+  store i32 -1, i32* %140, align 4, !tbaa !71
   br label %when_exit16.i
 
 when_next.i:                                      ; preds = %when_exit12.i
-  %141 = load %struct.ObjHeader*, %struct.ObjHeader** %25, align 8
+  %141 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %25 unordered, align 8
   store %struct.ObjHeader* %141, %struct.ObjHeader** %45, align 8, !tbaa !3
   %142 = add i32 %126, -1
   %143 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %141, i64 1
   %144 = bitcast %struct.ObjHeader* %143 to i32*
-  %145 = load i32, i32* %144, align 8, !tbaa !18
+  %145 = load atomic i32, i32* %144 unordered, align 8, !tbaa !18
   %146 = icmp ugt i32 %145, %142
   br i1 %146, label %Kotlin_Array_get.exit.i, label %147
 
@@ -12252,7 +12329,7 @@
   %149 = sext i32 %142 to i64
   %150 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %148, i64 %149
   %151 = bitcast %struct.ObjHeader* %150 to %struct.ObjHeader**
-  %152 = load %struct.ObjHeader*, %struct.ObjHeader** %151, align 8, !tbaa !3
+  %152 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %151 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %152, %struct.ObjHeader** %46, align 8, !tbaa !3
   %153 = icmp eq %struct.ObjHeader* %152, null
   br i1 %153, label %"kfun:kotlin.collections.HashMap.hash#internal.exit.i", label %when_next.i35.i
@@ -12267,10 +12344,10 @@
   %160 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %159 monotonic, align 8
   %161 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %160, i64 1, i32 1
   %162 = bitcast %struct.ExtendedTypeInfo** %161 to i32 (%struct.ObjHeader*)**
-  %163 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %162, align 8
+  %163 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %162 unordered, align 8
   %164 = call i32 %163(%struct.ObjHeader* nonnull %152)
   %165 = mul i32 %164, -1640531527
-  %166 = load i32, i32* %88, align 4
+  %166 = load atomic i32, i32* %88 unordered, align 4
   %167 = and i32 %166, 31
   %168 = lshr i32 %165, %167
   br label %"kfun:kotlin.collections.HashMap.hash#internal.exit.i"
@@ -12281,19 +12358,19 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %64, i8 0, i32 32, i1 immarg false) #49
   %170 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
   %171 = bitcast %"class.kotlin::mm::ShadowStack"* %170 to i64*
-  %172 = load i64, i64* %171, align 8, !tbaa !7
+  %172 = load atomic i64, i64* %171 unordered, align 8, !tbaa !7
   store i64 %172, i64* %71, align 8, !tbaa !9
   %173 = bitcast %"class.kotlin::mm::ShadowStack"* %170 to %struct.ObjHeader***
   store %struct.ObjHeader** %.sub.i.i, %struct.ObjHeader*** %173, align 8, !tbaa !7
   store i32 0, i32* %74, align 8, !tbaa !12
   store i32 4, i32* %75, align 4, !tbaa !13
-  %174 = load %struct.ObjHeader*, %struct.ObjHeader** %77, align 8
+  %174 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %77 unordered, align 8
   store %struct.ObjHeader* %174, %struct.ObjHeader** %65, align 8, !tbaa !3
   %175 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %174, i64 1
   %176 = bitcast %struct.ObjHeader* %175 to i32*
-  %177 = load i32, i32* %176, align 8, !tbaa !18
+  %177 = load atomic i32, i32* %176 unordered, align 8, !tbaa !18
   %178 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
-  %179 = load i64, i64* %71, align 8, !tbaa !9
+  %179 = load atomic i64, i64* %71 unordered, align 8, !tbaa !9
   %180 = bitcast %"class.kotlin::mm::ShadowStack"* %178 to i64*
   store i64 %179, i64* %180, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %64)
@@ -12304,11 +12381,11 @@
   br i1 %.not.i, label %when_exit16.i, label %when_case19.i
 
 when_case19.i:                                    ; preds = %"kfun:kotlin.collections.HashMap.hash#internal.exit.i"
-  %184 = load %struct.ObjHeader*, %struct.ObjHeader** %77, align 8
+  %184 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %77 unordered, align 8
   store %struct.ObjHeader* %184, %struct.ObjHeader** %47, align 8, !tbaa !3
   %185 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %184, i64 1
   %186 = bitcast %struct.ObjHeader* %185 to i32*
-  %187 = load i32, i32* %186, align 8, !tbaa !18
+  %187 = load atomic i32, i32* %186 unordered, align 8, !tbaa !18
   %188 = icmp ugt i32 %187, %hole.2.i
   br i1 %188, label %Kotlin_IntArray_set.exit31.i, label %189
 
@@ -12323,12 +12400,12 @@
   %193 = bitcast %struct.ObjHeader* %192 to i32*
   %194 = sext i32 %hole.2.i to i64
   %195 = getelementptr inbounds i32, i32* %193, i64 %194
-  store i32 %126, i32* %195, align 4, !tbaa !73
-  %196 = load %struct.ObjHeader*, %struct.ObjHeader** %28, align 8
+  store i32 %126, i32* %195, align 4, !tbaa !71
+  %196 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %28 unordered, align 8
   store %struct.ObjHeader* %196, %struct.ObjHeader** %48, align 8, !tbaa !3
   %197 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %196, i64 1
   %198 = bitcast %struct.ObjHeader* %197 to i32*
-  %199 = load i32, i32* %198, align 8, !tbaa !18
+  %199 = load atomic i32, i32* %198 unordered, align 8, !tbaa !18
   %200 = icmp ugt i32 %199, %142
   br i1 %200, label %Kotlin_IntArray_set.exit29.i, label %201
 
@@ -12342,7 +12419,7 @@
   %204 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %196, i64 2
   %205 = bitcast %struct.ObjHeader* %204 to i32*
   %206 = getelementptr inbounds i32, i32* %205, i64 %149
-  store i32 %hole.2.i, i32* %206, align 4, !tbaa !73
+  store i32 %hole.2.i, i32* %206, align 4, !tbaa !71
   br label %when_exit16.i
 
 when_exit16.i:                                    ; preds = %Kotlin_IntArray_set.exit29.i, %"kfun:kotlin.collections.HashMap.hash#internal.exit.i", %Kotlin_IntArray_set.exit32.i
@@ -12353,11 +12430,11 @@
   br i1 %208, label %when_case24.i, label %loop_check.i
 
 when_case24.i:                                    ; preds = %when_exit16.i
-  %209 = load %struct.ObjHeader*, %struct.ObjHeader** %77, align 8
+  %209 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %77 unordered, align 8
   store %struct.ObjHeader* %209, %struct.ObjHeader** %49, align 8, !tbaa !3
   %210 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %209, i64 1
   %211 = bitcast %struct.ObjHeader* %210 to i32*
-  %212 = load i32, i32* %211, align 8, !tbaa !18
+  %212 = load atomic i32, i32* %211 unordered, align 8, !tbaa !18
   %213 = icmp ugt i32 %212, %hole.1.i
   br i1 %213, label %Kotlin_IntArray_set.exit.i, label %214
 
@@ -12372,7 +12449,7 @@
   %218 = bitcast %struct.ObjHeader* %217 to i32*
   %219 = sext i32 %hole.1.i to i64
   %220 = getelementptr inbounds i32, i32* %218, i64 %219
-  store i32 -1, i32* %220, align 4, !tbaa !73
+  store i32 -1, i32* %220, align 4, !tbaa !71
   br label %call_success2
 
 loop_check.i:                                     ; preds = %when_exit16.i, %call_success1
@@ -12387,15 +12464,15 @@
 
 call_success2:                                    ; preds = %Kotlin_IntArray_set.exit.i, %Kotlin_IntArray_set.exit30.i, %Kotlin_IntArray_set.exit28.i
   %224 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
-  %225 = load i64, i64* %55, align 8, !tbaa !9
+  %225 = load atomic i64, i64* %55 unordered, align 8, !tbaa !9
   %226 = bitcast %"class.kotlin::mm::ShadowStack"* %224 to i64*
   store i64 %225, i64* %226, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 96, i8* nonnull %40)
-  %227 = load %struct.ObjHeader*, %struct.ObjHeader** %28, align 8
+  %227 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %28 unordered, align 8
   store %struct.ObjHeader* %227, %struct.ObjHeader** %8, align 8, !tbaa !3
   %228 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %227, i64 1
   %229 = bitcast %struct.ObjHeader* %228 to i32*
-  %230 = load i32, i32* %229, align 8, !tbaa !18
+  %230 = load atomic i32, i32* %229 unordered, align 8, !tbaa !18
   %231 = icmp ugt i32 %230, %1
   br i1 %231, label %epilogue, label %232
 
@@ -12409,14 +12486,16 @@
   %235 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %227, i64 2
   %236 = bitcast %struct.ObjHeader* %235 to i32*
   %237 = getelementptr inbounds i32, i32* %236, i64 %37
-  store i32 -1, i32* %237, align 4, !tbaa !73
+  store i32 -1, i32* %237, align 4, !tbaa !71
   %238 = bitcast %struct.ObjHeader* %0 to %"kclassbody:kotlin.collections.HashMap#internal"*
   %239 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %238, i64 0, i32 11
-  %240 = load i32, i32* %239, align 4
+  %240 = load atomic i32, i32* %239 unordered, align 4
   %241 = add i32 %240, -1
   store i32 %241, i32* %239, align 4
-  %242 = load i64, i64* %15, align 8, !tbaa !9
-  store i64 %242, i64* %226, align 8, !tbaa !7
+  %242 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
+  %243 = load atomic i64, i64* %15 unordered, align 8, !tbaa !9
+  %244 = bitcast %"class.kotlin::mm::ShadowStack"* %242 to i64*
+  store i64 %243, i64* %244, align 8, !tbaa !7
   ret void
 }
 
@@ -12429,11 +12508,11 @@
   %4 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %5 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 5
   %6 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 6
-  %7 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %7 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %8 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 5
   %9 = bitcast [7 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %10 = bitcast %"class.kotlin::mm::ShadowStack"* %8 to i64*
-  %11 = load i64, i64* %10, align 8, !tbaa !7
+  %11 = load atomic i64, i64* %10 unordered, align 8, !tbaa !7
   %12 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %13 = bitcast %struct.ObjHeader** %12 to i64*
   store i64 %11, i64* %13, align 8, !tbaa !9
@@ -12462,15 +12541,15 @@
   %27 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %26, i64 0, i32 0
   %28 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %27 monotonic, align 8
   %29 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %28, i64 0, i32 9
-  %30 = load i32, i32* %29, align 4
+  %30 = load atomic i32, i32* %29 unordered, align 4
   %31 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %28, i64 0, i32 10
-  %32 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %31, align 8
+  %32 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %31 unordered, align 8
   %33 = and i32 %30, 168
   %34 = zext i32 %33 to i64
   %35 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %32, i64 %34, i32 2
   %36 = bitcast i8*** %35 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)***
-  %37 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %36, align 8
-  %38 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %37, align 8
+  %37 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %36 unordered, align 8
+  %38 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %37 unordered, align 8
   %39 = call %struct.ObjHeader* %38(%struct.ObjHeader* %1, %struct.ObjHeader** nonnull %4)
   %40 = call fastcc i32 @"kfun:kotlin.collections.HashMap.findKey#internal"(%struct.ObjHeader* %0, %struct.ObjHeader* %39)
   %41 = icmp slt i32 %40, 0
@@ -12480,7 +12559,7 @@
   %42 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 4
   %43 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %44 = bitcast %struct.ObjHeader* %43 to %struct.ObjHeader**
-  %45 = load %struct.ObjHeader*, %struct.ObjHeader** %44, align 8
+  %45 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %44 unordered, align 8
   store %struct.ObjHeader* %45, %struct.ObjHeader** %42, align 8, !tbaa !3
   %46 = icmp eq %struct.ObjHeader* %45, null
   br i1 %46, label %when_case2, label %when_exit3
@@ -12492,7 +12571,7 @@
 when_exit3:                                       ; preds = %when_exit
   %47 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %45, i64 1
   %48 = bitcast %struct.ObjHeader* %47 to i32*
-  %49 = load i32, i32* %48, align 8, !tbaa !18
+  %49 = load atomic i32, i32* %48 unordered, align 8, !tbaa !18
   %50 = icmp ugt i32 %49, %40
   br i1 %50, label %call_success7, label %51
 
@@ -12505,7 +12584,7 @@
   %53 = sext i32 %40 to i64
   %54 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %52, i64 %53
   %55 = bitcast %struct.ObjHeader* %54 to %struct.ObjHeader**
-  %56 = load %struct.ObjHeader*, %struct.ObjHeader** %55, align 8, !tbaa !3
+  %56 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %55 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %56, %struct.ObjHeader** %5, align 8, !tbaa !3
   %57 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %22 monotonic, align 8
   %58 = ptrtoint %struct.TypeInfo* %57 to i64
@@ -12514,16 +12593,16 @@
   %61 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %60, i64 0, i32 0
   %62 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %61 monotonic, align 8
   %63 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %62, i64 0, i32 9
-  %64 = load i32, i32* %63, align 4
+  %64 = load atomic i32, i32* %63 unordered, align 4
   %65 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %62, i64 0, i32 10
-  %66 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %65, align 8
+  %66 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %65 unordered, align 8
   %67 = and i32 %64, 168
   %68 = zext i32 %67 to i64
   %69 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %66, i64 %68, i32 2
-  %70 = load i8**, i8*** %69, align 8
+  %70 = load atomic i8**, i8*** %69 unordered, align 8
   %71 = getelementptr i8*, i8** %70, i64 1
   %72 = bitcast i8** %71 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %73 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %72, align 8
+  %73 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %72 unordered, align 8
   %74 = call %struct.ObjHeader* %73(%struct.ObjHeader* %1, %struct.ObjHeader** nonnull %6)
   %75 = icmp eq %struct.ObjHeader* %56, null
   br i1 %75, label %when_case8, label %call_success10
@@ -12542,14 +12621,14 @@
   %83 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %82 monotonic, align 8
   %84 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %83, i64 1
   %85 = bitcast %struct.TypeInfo* %84 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
-  %86 = load i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %85, align 8
+  %86 = load atomic i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %85 unordered, align 8
   %87 = call zeroext i1 %86(%struct.ObjHeader* nonnull %56, %struct.ObjHeader* %74)
   br label %epilogue
 
 epilogue:                                         ; preds = %call_success10, %when_case8, %Kotlin_mm_safePointFunctionPrologue.exit
   %88 = phi i1 [ false, %Kotlin_mm_safePointFunctionPrologue.exit ], [ %76, %when_case8 ], [ %87, %call_success10 ]
   %89 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 5
-  %90 = load i64, i64* %13, align 8, !tbaa !9
+  %90 = load atomic i64, i64* %13 unordered, align 8, !tbaa !9
   %91 = bitcast %"class.kotlin::mm::ShadowStack"* %89 to i64*
   store i64 %90, i64* %91, align 8, !tbaa !7
   ret i1 %88
@@ -12562,11 +12641,11 @@
   %4 = bitcast [5 x %struct.ObjHeader*]* %3 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %4, i8 0, i32 40, i1 immarg false) #49
   %5 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 4
-  %6 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %7 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
   %8 = bitcast [5 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %9 = bitcast %"class.kotlin::mm::ShadowStack"* %7 to i64*
-  %10 = load i64, i64* %9, align 8, !tbaa !7
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa !7
   %11 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %12 = bitcast %struct.ObjHeader** %11 to i64*
   store i64 %10, i64* %12, align 8, !tbaa !9
@@ -12595,11 +12674,11 @@
   %23 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 3
   %24 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %25 = bitcast %struct.ObjHeader* %24 to %struct.ObjHeader**
-  %26 = load %struct.ObjHeader*, %struct.ObjHeader** %25, align 8
+  %26 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %25 unordered, align 8
   store %struct.ObjHeader* %26, %struct.ObjHeader** %23, align 8, !tbaa !3
   %27 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %26, i64 1
   %28 = bitcast %struct.ObjHeader* %27 to i32*
-  %29 = load i32, i32* %28, align 8, !tbaa !18
+  %29 = load atomic i32, i32* %28 unordered, align 8, !tbaa !18
   %30 = icmp ugt i32 %29, %21
   br i1 %30, label %call_success1, label %31
 
@@ -12612,7 +12691,7 @@
   %33 = sext i32 %21 to i64
   %34 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %32, i64 %33
   %35 = bitcast %struct.ObjHeader* %34 to %struct.ObjHeader**
-  %36 = load %struct.ObjHeader*, %struct.ObjHeader** %35, align 8, !tbaa !3
+  %36 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %35 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %36, %struct.ObjHeader** %5, align 8, !tbaa !3
   %37 = icmp eq %struct.ObjHeader* %36, null
   br i1 %37, label %when_case2, label %epilogue
@@ -12625,7 +12704,7 @@
   %38 = phi %struct.ObjHeader* [ %36, %call_success1 ], [ null, %Kotlin_mm_safePointFunctionPrologue.exit ]
   store %struct.ObjHeader* %38, %struct.ObjHeader** %2, align 8, !tbaa !3
   %39 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %40 = load i64, i64* %12, align 8, !tbaa !9
+  %40 = load atomic i64, i64* %12 unordered, align 8, !tbaa !9
   %41 = bitcast %"class.kotlin::mm::ShadowStack"* %39 to i64*
   store i64 %40, i64* %41, align 8, !tbaa !7
   ret %struct.ObjHeader* %38
@@ -12640,11 +12719,11 @@
   %4 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %5 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 4
   %6 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 5
-  %7 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %7 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %8 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 5
   %9 = bitcast [6 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %10 = bitcast %"class.kotlin::mm::ShadowStack"* %8 to i64*
-  %11 = load i64, i64* %10, align 8, !tbaa !7
+  %11 = load atomic i64, i64* %10 unordered, align 8, !tbaa !7
   %12 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %13 = bitcast %struct.ObjHeader** %12 to i64*
   store i64 %11, i64* %13, align 8, !tbaa !9
@@ -12673,16 +12752,16 @@
   %27 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %26, i64 0, i32 0
   %28 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %27 monotonic, align 8
   %29 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %28, i64 0, i32 9
-  %30 = load i32, i32* %29, align 4
+  %30 = load atomic i32, i32* %29 unordered, align 4
   %31 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %28, i64 0, i32 10
-  %32 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %31, align 8
+  %32 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %31 unordered, align 8
   %33 = and i32 %30, 18
   %34 = zext i32 %33 to i64
   %35 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %32, i64 %34, i32 2
-  %36 = load i8**, i8*** %35, align 8
+  %36 = load atomic i8**, i8*** %35 unordered, align 8
   %37 = getelementptr i8*, i8** %36, i64 4
   %38 = bitcast i8** %37 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %39 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %38, align 8
+  %39 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %38 unordered, align 8
   %40 = call %struct.ObjHeader* %39(%struct.ObjHeader* %1, %struct.ObjHeader** nonnull %4)
   %41 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %40, i64 0, i32 0
   br label %call_success1
@@ -12705,16 +12784,16 @@
   %50 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %49, i64 0, i32 0
   %51 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %50 monotonic, align 8
   %52 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %51, i64 0, i32 9
-  %53 = load i32, i32* %52, align 4
+  %53 = load atomic i32, i32* %52 unordered, align 4
   %54 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %51, i64 0, i32 10
-  %55 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %54, align 8
+  %55 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %54 unordered, align 8
   %56 = and i32 %53, 160
   %57 = zext i32 %56 to i64
   %58 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %55, i64 %57, i32 2
-  %59 = load i8**, i8*** %58, align 8
+  %59 = load atomic i8**, i8*** %58 unordered, align 8
   %60 = getelementptr i8*, i8** %59, i64 1
   %61 = bitcast i8** %60 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %62 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %61, align 8
+  %62 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %61 unordered, align 8
   %63 = call %struct.ObjHeader* %62(%struct.ObjHeader* %40, %struct.ObjHeader** nonnull %5)
   %64 = icmp eq %struct.ObjHeader* %63, null
   br i1 %64, label %epilogue, label %when_next5
@@ -12738,9 +12817,9 @@
   %67 = call i8* @__cxa_begin_catch(i8* %er) #37
   %68 = getelementptr inbounds i8, i8* %67, i64 8
   %69 = bitcast i8* %68 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"**
-  %70 = load %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %69, align 8, !tbaa !65
+  %70 = load atomic %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %69 unordered, align 8, !tbaa !64
   %71 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %70, i64 0, i32 0
-  %72 = load %struct.ObjHeader*, %struct.ObjHeader** %71, align 8, !tbaa !3
+  %72 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %71 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %72, %struct.ObjHeader** %6, align 8, !tbaa !3
   call void @__cxa_end_catch() #37
   %73 = bitcast %struct.ObjHeader* %72 to i64*
@@ -12750,7 +12829,7 @@
   %77 = load atomic volatile i64, i64* %76 monotonic, align 8
   %78 = inttoptr i64 %77 to %struct.TypeInfo*
   %79 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %78, i64 0, i32 14
-  %80 = load i32, i32* %79, align 4, !tbaa !19
+  %80 = load atomic i32, i32* %79 unordered, align 4, !tbaa !19
   %.off = add i32 %80, -131
   %81 = icmp ult i32 %.off, 2
   br i1 %81, label %epilogue, label %catchCheck
@@ -12768,13 +12847,13 @@
   %87 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %86, i64 0, i32 0
   %88 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %87 monotonic, align 8
   %89 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %88, i64 0, i32 9
-  %90 = load i32, i32* %89, align 4
+  %90 = load atomic i32, i32* %89 unordered, align 4
   %91 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %88, i64 0, i32 10
-  %92 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %91, align 8
+  %92 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %91 unordered, align 8
   %93 = and i32 %90, 168
   %94 = zext i32 %93 to i64
   %95 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %92, i64 %94, i32 0
-  %96 = load i32, i32* %95, align 4
+  %96 = load atomic i32, i32* %95 unordered, align 4
   %.not = icmp eq i32 %96, 168
   br i1 %.not, label %when_exit11, label %label_9
 
@@ -12800,22 +12879,22 @@
   %102 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %101, i64 0, i32 0
   %103 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %102 monotonic, align 8
   %104 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %103, i64 0, i32 9
-  %105 = load i32, i32* %104, align 4
+  %105 = load atomic i32, i32* %104 unordered, align 4
   %106 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %103, i64 0, i32 10
-  %107 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %106, align 8
+  %107 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %106 unordered, align 8
   %108 = and i32 %105, 160
   %109 = zext i32 %108 to i64
   %110 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %107, i64 %109, i32 2
   %111 = bitcast i8*** %110 to i1 (%struct.ObjHeader*)***
-  %112 = load i1 (%struct.ObjHeader*)**, i1 (%struct.ObjHeader*)*** %111, align 8
-  %113 = load i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %112, align 8
+  %112 = load atomic i1 (%struct.ObjHeader*)**, i1 (%struct.ObjHeader*)*** %111 unordered, align 8
+  %113 = load atomic i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %112 unordered, align 8
   %114 = call zeroext i1 %113(%struct.ObjHeader* %40)
   br i1 %114, label %while_loop, label %epilogue
 
 epilogue:                                         ; preds = %call_success1, %when_exit, %continuation_block6, %call_success2
   %115 = phi i1 [ false, %continuation_block6 ], [ false, %call_success2 ], [ true, %call_success1 ], [ false, %when_exit ]
   %116 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 5
-  %117 = load i64, i64* %13, align 8, !tbaa !9
+  %117 = load atomic i64, i64* %13 unordered, align 8, !tbaa !9
   %118 = bitcast %"class.kotlin::mm::ShadowStack"* %116 to i64*
   store i64 %117, i64* %118, align 8, !tbaa !7
   ret i1 %115
@@ -12833,10 +12912,10 @@
   br label %Kotlin_mm_safePointFunctionPrologue.exit
 
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
-  %6 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %7 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 6
   %8 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %7 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %9 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %8, align 8, !tbaa !3
+  %9 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %8 unordered, align 8, !tbaa !3
   %10 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %9, i64 0, i32 2, i32 1
   %11 = tail call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %10, i64 32) #37
   %12 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %11, i64 1
@@ -12871,10 +12950,10 @@
   br label %Kotlin_mm_safePointFunctionPrologue.exit
 
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
-  %6 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %7 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 6
   %8 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %7 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %9 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %8, align 8, !tbaa !3
+  %9 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %8 unordered, align 8, !tbaa !3
   %10 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %9, i64 0, i32 2, i32 1
   %11 = tail call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %10, i64 32) #37
   %12 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %11, i64 1
@@ -12904,11 +12983,11 @@
   %2 = bitcast [4 x %struct.ObjHeader*]* %1 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %2, i8 0, i32 32, i1 immarg false) #49
   %3 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 3
-  %4 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %4 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %5 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
   %6 = bitcast [4 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
   %7 = bitcast %"class.kotlin::mm::ShadowStack"* %5 to i64*
-  %8 = load i64, i64* %7, align 8, !tbaa !7
+  %8 = load atomic i64, i64* %7 unordered, align 8, !tbaa !7
   %9 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 1
   %10 = bitcast %struct.ObjHeader** %9 to i64*
   store i64 %8, i64* %10, align 8, !tbaa !9
@@ -12933,7 +13012,6 @@
   %20 = bitcast %struct.ObjHeader* %19 to i32*
   %21 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %22 = bitcast %struct.ObjHeader* %21 to %"kclassbody:kotlin.collections.HashMap#internal"**
-  %.pre = load i32, i32* %20, align 4
   br label %loop_check
 
 while_loop:                                       ; preds = %when_exit
@@ -12947,26 +13025,26 @@
   br label %Kotlin_mm_safePointWhileLoopBody.exit
 
 Kotlin_mm_safePointWhileLoopBody.exit:            ; preds = %26, %while_loop
-  %27 = load i32, i32* %20, align 4
+  %27 = load atomic i32, i32* %20 unordered, align 4
   %28 = add i32 %27, 1
   store i32 %28, i32* %20, align 4
   br label %loop_check
 
 loop_check:                                       ; preds = %Kotlin_mm_safePointWhileLoopBody.exit, %Kotlin_mm_safePointFunctionPrologue.exit
-  %29 = phi i32 [ %28, %Kotlin_mm_safePointWhileLoopBody.exit ], [ %.pre, %Kotlin_mm_safePointFunctionPrologue.exit ]
-  %30 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %22, align 8
+  %29 = load atomic i32, i32* %20 unordered, align 4
+  %30 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %22 unordered, align 8
   %31 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %30, i64 0, i32 9
-  %32 = load i32, i32* %31, align 4
+  %32 = load atomic i32, i32* %31 unordered, align 4
   %33 = icmp slt i32 %29, %32
   br i1 %33, label %when_case, label %epilogue
 
 when_case:                                        ; preds = %loop_check
   %34 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %30, i64 0, i32 3
-  %35 = load %struct.ObjHeader*, %struct.ObjHeader** %34, align 8
+  %35 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %34 unordered, align 8
   store %struct.ObjHeader* %35, %struct.ObjHeader** %3, align 8, !tbaa !3
   %36 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %35, i64 1
   %37 = bitcast %struct.ObjHeader* %36 to i32*
-  %38 = load i32, i32* %37, align 8, !tbaa !18
+  %38 = load atomic i32, i32* %37 unordered, align 8, !tbaa !18
   %39 = icmp ugt i32 %38, %29
   br i1 %39, label %when_exit, label %40
 
@@ -12979,13 +13057,13 @@
   %42 = bitcast %struct.ObjHeader* %41 to i32*
   %43 = sext i32 %29 to i64
   %44 = getelementptr inbounds i32, i32* %42, i64 %43
-  %45 = load i32, i32* %44, align 4, !tbaa !73
+  %45 = load atomic i32, i32* %44 unordered, align 4, !tbaa !71
   %46 = icmp slt i32 %45, 0
   br i1 %46, label %while_loop, label %epilogue
 
 epilogue:                                         ; preds = %when_exit, %loop_check
   %47 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %48 = load i64, i64* %10, align 8, !tbaa !9
+  %48 = load atomic i64, i64* %10 unordered, align 8, !tbaa !9
   %49 = bitcast %"class.kotlin::mm::ShadowStack"* %47 to i64*
   store i64 %48, i64* %49, align 8, !tbaa !7
   ret void
@@ -13006,12 +13084,12 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %epilogue
   %5 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %6 = bitcast %struct.ObjHeader* %5 to i32*
-  %7 = load i32, i32* %6, align 4
+  %7 = load atomic i32, i32* %6 unordered, align 4
   %8 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %9 = bitcast %struct.ObjHeader* %8 to %"kclassbody:kotlin.collections.HashMap#internal"**
-  %10 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %9, align 8
+  %10 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %9 unordered, align 8
   %11 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %10, i64 0, i32 9
-  %12 = load i32, i32* %11, align 4
+  %12 = load atomic i32, i32* %11 unordered, align 4
   %13 = icmp slt i32 %7, %12
   ret i1 %13
 }
@@ -13030,12 +13108,12 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %epilogue
   %5 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %6 = bitcast %struct.ObjHeader* %5 to %struct.ObjHeader**
-  %7 = load %struct.ObjHeader*, %struct.ObjHeader** %6, align 8
+  %7 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %6 unordered, align 8
   tail call fastcc void @"kfun:kotlin.collections.HashMap#checkIsMutable(){}"(%struct.ObjHeader* %7)
-  %8 = load %struct.ObjHeader*, %struct.ObjHeader** %6, align 8
+  %8 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %6 unordered, align 8
   %9 = bitcast %struct.ObjHeader* %0 to %"kclassbody:kotlin.collections.HashMap.Itr#internal"*
   %10 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap.Itr#internal", %"kclassbody:kotlin.collections.HashMap.Itr#internal"* %9, i64 0, i32 3
-  %11 = load i32, i32* %10, align 4
+  %11 = load atomic i32, i32* %10 unordered, align 4
   tail call fastcc void @"kfun:kotlin.collections.HashMap.removeKeyAt#internal"(%struct.ObjHeader* %8, i32 %11)
   store i32 -1, i32* %10, align 4
   ret void
@@ -13047,11 +13125,11 @@
   %.sub = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 0
   %3 = bitcast [6 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(48) %3, i8 0, i32 48, i1 immarg false) #49
-  %4 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %4 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %5 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
   %6 = bitcast [6 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %7 = bitcast %"class.kotlin::mm::ShadowStack"* %5 to i64*
-  %8 = load i64, i64* %7, align 8, !tbaa !7
+  %8 = load atomic i64, i64* %7 unordered, align 8, !tbaa !7
   %9 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %10 = bitcast %struct.ObjHeader** %9 to i64*
   store i64 %8, i64* %10, align 8, !tbaa !9
@@ -13074,12 +13152,12 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %18, %entry
   %19 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %20 = bitcast %struct.ObjHeader* %19 to i32*
-  %21 = load i32, i32* %20, align 4
+  %21 = load atomic i32, i32* %20 unordered, align 4
   %22 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %23 = bitcast %struct.ObjHeader* %22 to %"kclassbody:kotlin.collections.HashMap#internal"**
-  %24 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %23, align 8
+  %24 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %23 unordered, align 8
   %25 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %24, i64 0, i32 9
-  %26 = load i32, i32* %25, align 4
+  %26 = load atomic i32, i32* %25 unordered, align 4
   %.not = icmp slt i32 %21, %26
   br i1 %.not, label %when_exit, label %call_success
 
@@ -13087,7 +13165,7 @@
   %27 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %28 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 6
   %29 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %28 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %30 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %29, align 8, !tbaa !3
+  %30 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %29 unordered, align 8, !tbaa !3
   %31 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %30, i64 0, i32 2, i32 1
   %32 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %31, i64 56) #37
   %33 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %32, i64 1
@@ -13111,33 +13189,34 @@
   %42 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap.Itr#internal", %"kclassbody:kotlin.collections.HashMap.Itr#internal"* %41, i64 0, i32 3
   store i32 %21, i32* %42, align 4
   %43 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %24, i64 0, i32 1
-  %44 = load %struct.ObjHeader*, %struct.ObjHeader** %43, align 8
+  %44 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %43 unordered, align 8
   store %struct.ObjHeader* %44, %struct.ObjHeader** %39, align 8, !tbaa !3
-  %45 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %44, i64 1
-  %46 = bitcast %struct.ObjHeader* %45 to i32*
-  %47 = load i32, i32* %46, align 8, !tbaa !18
-  %48 = icmp ugt i32 %47, %21
-  br i1 %48, label %epilogue, label %49
+  %45 = load atomic i32, i32* %42 unordered, align 4
+  %46 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %44, i64 1
+  %47 = bitcast %struct.ObjHeader* %46 to i32*
+  %48 = load atomic i32, i32* %47 unordered, align 8, !tbaa !18
+  %49 = icmp ugt i32 %48, %45
+  br i1 %49, label %epilogue, label %50
 
-49:                                               ; preds = %when_exit
+50:                                               ; preds = %when_exit
   call fastcc void @ThrowArrayIndexOutOfBoundsException() #50
   unreachable
 
 epilogue:                                         ; preds = %when_exit
-  %50 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 5
-  %51 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %44, i64 2
-  %52 = sext i32 %21 to i64
-  %53 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %51, i64 %52
-  %54 = bitcast %struct.ObjHeader* %53 to %struct.ObjHeader**
-  %55 = load %struct.ObjHeader*, %struct.ObjHeader** %54, align 8, !tbaa !3
-  store %struct.ObjHeader* %55, %struct.ObjHeader** %50, align 8, !tbaa !3
+  %51 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 5
+  %52 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %44, i64 2
+  %53 = sext i32 %45 to i64
+  %54 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %52, i64 %53
+  %55 = bitcast %struct.ObjHeader* %54 to %struct.ObjHeader**
+  %56 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %55 unordered, align 8, !tbaa !3
+  store %struct.ObjHeader* %56, %struct.ObjHeader** %51, align 8, !tbaa !3
   call fastcc void @"kfun:kotlin.collections.HashMap.Itr#initNext(){}"(%struct.ObjHeader* %0)
-  store %struct.ObjHeader* %55, %struct.ObjHeader** %1, align 8, !tbaa !3
-  %56 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %57 = load i64, i64* %10, align 8, !tbaa !9
-  %58 = bitcast %"class.kotlin::mm::ShadowStack"* %56 to i64*
-  store i64 %57, i64* %58, align 8, !tbaa !7
-  ret %struct.ObjHeader* %55
+  store %struct.ObjHeader* %56, %struct.ObjHeader** %1, align 8, !tbaa !3
+  %57 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
+  %58 = load atomic i64, i64* %10 unordered, align 8, !tbaa !9
+  %59 = bitcast %"class.kotlin::mm::ShadowStack"* %57 to i64*
+  store i64 %58, i64* %59, align 8, !tbaa !7
+  ret %struct.ObjHeader* %56
 }
 
 define internal nonnull %struct.ObjHeader* @"kfun:kotlin.collections.HashMap.EntriesItr#next(){}kotlin.collections.HashMap.EntryRef<1:0,1:1>"(%struct.ObjHeader* nocapture %0, %struct.ObjHeader** nocapture %1) #3 personality i32 (...)* @__gxx_personality_v0 {
@@ -13146,11 +13225,11 @@
   %.sub = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 0
   %3 = bitcast [5 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %3, i8 0, i32 40, i1 immarg false) #49
-  %4 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %4 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %5 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
   %6 = bitcast [5 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %7 = bitcast %"class.kotlin::mm::ShadowStack"* %5 to i64*
-  %8 = load i64, i64* %7, align 8, !tbaa !7
+  %8 = load atomic i64, i64* %7 unordered, align 8, !tbaa !7
   %9 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %10 = bitcast %struct.ObjHeader** %9 to i64*
   store i64 %8, i64* %10, align 8, !tbaa !9
@@ -13173,12 +13252,12 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %18, %entry
   %19 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %20 = bitcast %struct.ObjHeader* %19 to i32*
-  %21 = load i32, i32* %20, align 4
+  %21 = load atomic i32, i32* %20 unordered, align 4
   %22 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %23 = bitcast %struct.ObjHeader* %22 to %"kclassbody:kotlin.collections.HashMap#internal"**
-  %24 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %23, align 8
+  %24 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %23 unordered, align 8
   %25 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %24, i64 0, i32 9
-  %26 = load i32, i32* %25, align 4
+  %26 = load atomic i32, i32* %25 unordered, align 4
   %.not = icmp slt i32 %21, %26
   br i1 %.not, label %epilogue, label %call_success
 
@@ -13186,7 +13265,7 @@
   %27 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %28 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 6
   %29 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %28 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %30 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %29, align 8, !tbaa !3
+  %30 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %29 unordered, align 8, !tbaa !3
   %31 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %30, i64 0, i32 2, i32 1
   %32 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %31, i64 56) #37
   %33 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %32, i64 1
@@ -13210,34 +13289,35 @@
   %42 = bitcast %struct.ObjHeader* %0 to %"kclassbody:kotlin.collections.HashMap.Itr#internal"*
   %43 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap.Itr#internal", %"kclassbody:kotlin.collections.HashMap.Itr#internal"* %42, i64 0, i32 3
   store i32 %21, i32* %43, align 4
-  %44 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 6
-  %45 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %44 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %46 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %45, align 8, !tbaa !3
-  %47 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %46, i64 0, i32 2, i32 1
-  %48 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %47, i64 32) #37
-  %49 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %48, i64 1
-  %50 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %48, i64 2
-  %51 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %50 to %struct.TypeInfo**
-  %52 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %49 to i64*
-  store i64 0, i64* %52, align 8
-  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [3 x i8*] }, { %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.collections.HashMap.EntryRef#internal", i64 0, i32 0), %struct.TypeInfo** %51, align 8, !tbaa !14
-  %53 = bitcast %struct.ObjHeader** %40 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %50, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %53, align 8, !tbaa !3
-  %54 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %48, i64 3
-  %55 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %54 to i64*
-  store i64 %39, i64* %55, align 8, !tbaa !3
-  %56 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %48, i64 4
-  %57 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %56 to i32*
-  store i32 %21, i32* %57, align 8
+  %44 = load atomic i32, i32* %43 unordered, align 4
+  %45 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 6
+  %46 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %45 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
+  %47 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %46 unordered, align 8, !tbaa !3
+  %48 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %47, i64 0, i32 2, i32 1
+  %49 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %48, i64 32) #37
+  %50 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %49, i64 1
+  %51 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %49, i64 2
+  %52 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %51 to %struct.TypeInfo**
+  %53 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %50 to i64*
+  store i64 0, i64* %53, align 8
+  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [3 x i8*] }, { %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.collections.HashMap.EntryRef#internal", i64 0, i32 0), %struct.TypeInfo** %52, align 8, !tbaa !14
+  %54 = bitcast %struct.ObjHeader** %40 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %51, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %54, align 8, !tbaa !3
+  %55 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %49, i64 3
+  %56 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %55 to i64*
+  store i64 %39, i64* %56, align 8, !tbaa !3
+  %57 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %49, i64 4
+  %58 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %57 to i32*
+  store i32 %44, i32* %58, align 8
   call fastcc void @"kfun:kotlin.collections.HashMap.Itr#initNext(){}"(%struct.ObjHeader* %0)
-  %58 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %50 to %struct.ObjHeader*
-  %59 = bitcast %struct.ObjHeader** %1 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %50, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %59, align 8, !tbaa !3
-  %60 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %61 = load i64, i64* %10, align 8, !tbaa !9
-  %62 = bitcast %"class.kotlin::mm::ShadowStack"* %60 to i64*
-  store i64 %61, i64* %62, align 8, !tbaa !7
-  ret %struct.ObjHeader* %58
+  %59 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %51 to %struct.ObjHeader*
+  %60 = bitcast %struct.ObjHeader** %1 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %51, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %60, align 8, !tbaa !3
+  %61 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
+  %62 = load atomic i64, i64* %10 unordered, align 8, !tbaa !9
+  %63 = bitcast %"class.kotlin::mm::ShadowStack"* %61 to i64*
+  store i64 %62, i64* %63, align 8, !tbaa !7
+  ret %struct.ObjHeader* %59
 }
 
 define internal %struct.ObjHeader* @"kfun:kotlin.collections.HashMap.EntryRef#<get-key>(){}1:0"(%struct.ObjHeader* nocapture readonly %0, %struct.ObjHeader** nocapture %1) #3 personality i32 (...)* @__gxx_personality_v0 {
@@ -13247,11 +13327,11 @@
   %3 = bitcast [4 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %3, i8 0, i32 32, i1 immarg false) #49
   %4 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 3
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %7 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %8 = bitcast %"class.kotlin::mm::ShadowStack"* %6 to i64*
-  %9 = load i64, i64* %8, align 8, !tbaa !7
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !7
   %10 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %11 = bitcast %struct.ObjHeader** %10 to i64*
   store i64 %9, i64* %11, align 8, !tbaa !9
@@ -13274,16 +13354,16 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %19, %entry
   %20 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %21 = bitcast %struct.ObjHeader* %20 to %"kclassbody:kotlin.collections.HashMap#internal"**
-  %22 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %21, align 8
+  %22 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %21 unordered, align 8
   %23 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %22, i64 0, i32 1
-  %24 = load %struct.ObjHeader*, %struct.ObjHeader** %23, align 8
+  %24 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %23 unordered, align 8
   store %struct.ObjHeader* %24, %struct.ObjHeader** %4, align 8, !tbaa !3
   %25 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %26 = bitcast %struct.ObjHeader* %25 to i32*
-  %27 = load i32, i32* %26, align 4
+  %27 = load atomic i32, i32* %26 unordered, align 4
   %28 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %24, i64 1
   %29 = bitcast %struct.ObjHeader* %28 to i32*
-  %30 = load i32, i32* %29, align 8, !tbaa !18
+  %30 = load atomic i32, i32* %29 unordered, align 8, !tbaa !18
   %31 = icmp ugt i32 %30, %27
   br i1 %31, label %epilogue, label %32
 
@@ -13296,10 +13376,10 @@
   %34 = sext i32 %27 to i64
   %35 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %33, i64 %34
   %36 = bitcast %struct.ObjHeader* %35 to %struct.ObjHeader**
-  %37 = load %struct.ObjHeader*, %struct.ObjHeader** %36, align 8, !tbaa !3
+  %37 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %36 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %37, %struct.ObjHeader** %1, align 8, !tbaa !3
   %38 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %39 = load i64, i64* %11, align 8, !tbaa !9
+  %39 = load atomic i64, i64* %11 unordered, align 8, !tbaa !9
   %40 = bitcast %"class.kotlin::mm::ShadowStack"* %38 to i64*
   store i64 %39, i64* %40, align 8, !tbaa !7
   ret %struct.ObjHeader* %37
@@ -13312,11 +13392,11 @@
   %3 = bitcast [4 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %3, i8 0, i32 32, i1 immarg false) #49
   %4 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 3
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %7 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %8 = bitcast %"class.kotlin::mm::ShadowStack"* %6 to i64*
-  %9 = load i64, i64* %8, align 8, !tbaa !7
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !7
   %10 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %11 = bitcast %struct.ObjHeader** %10 to i64*
   store i64 %9, i64* %11, align 8, !tbaa !9
@@ -13339,9 +13419,9 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %19, %entry
   %20 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %21 = bitcast %struct.ObjHeader* %20 to %"kclassbody:kotlin.collections.HashMap#internal"**
-  %22 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %21, align 8
+  %22 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %21 unordered, align 8
   %23 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %22, i64 0, i32 2
-  %24 = load %struct.ObjHeader*, %struct.ObjHeader** %23, align 8
+  %24 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %23 unordered, align 8
   store %struct.ObjHeader* %24, %struct.ObjHeader** %4, align 8, !tbaa !3
   %25 = icmp eq %struct.ObjHeader* %24, null
   br i1 %25, label %when_case, label %when_exit
@@ -13353,10 +13433,10 @@
 when_exit:                                        ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
   %26 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %27 = bitcast %struct.ObjHeader* %26 to i32*
-  %28 = load i32, i32* %27, align 4
+  %28 = load atomic i32, i32* %27 unordered, align 4
   %29 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %24, i64 1
   %30 = bitcast %struct.ObjHeader* %29 to i32*
-  %31 = load i32, i32* %30, align 8, !tbaa !18
+  %31 = load atomic i32, i32* %30 unordered, align 8, !tbaa !18
   %32 = icmp ugt i32 %31, %28
   br i1 %32, label %epilogue, label %33
 
@@ -13369,10 +13449,10 @@
   %35 = sext i32 %28 to i64
   %36 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %34, i64 %35
   %37 = bitcast %struct.ObjHeader* %36 to %struct.ObjHeader**
-  %38 = load %struct.ObjHeader*, %struct.ObjHeader** %37, align 8, !tbaa !3
+  %38 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %37 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %38, %struct.ObjHeader** %1, align 8, !tbaa !3
   %39 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %40 = load i64, i64* %11, align 8, !tbaa !9
+  %40 = load atomic i64, i64* %11 unordered, align 8, !tbaa !9
   %41 = bitcast %"class.kotlin::mm::ShadowStack"* %39 to i64*
   store i64 %40, i64* %41, align 8, !tbaa !7
   ret %struct.ObjHeader* %38
@@ -13388,11 +13468,11 @@
   %5 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 4
   %6 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 5
   %7 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 6
-  %8 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %8 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %9 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
   %10 = bitcast [7 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %11 = bitcast %"class.kotlin::mm::ShadowStack"* %9 to i64*
-  %12 = load i64, i64* %11, align 8, !tbaa !7
+  %12 = load atomic i64, i64* %11 unordered, align 8, !tbaa !7
   %13 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %14 = bitcast %struct.ObjHeader** %13 to i64*
   store i64 %12, i64* %14, align 8, !tbaa !9
@@ -13425,13 +13505,13 @@
   %29 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %28, i64 0, i32 0
   %30 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %29 monotonic, align 8
   %31 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %30, i64 0, i32 9
-  %32 = load i32, i32* %31, align 4
+  %32 = load atomic i32, i32* %31 unordered, align 4
   %33 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %30, i64 0, i32 10
-  %34 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %33, align 8
+  %34 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %33 unordered, align 8
   %35 = and i32 %32, 168
   %36 = zext i32 %35 to i64
   %37 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %34, i64 %36, i32 0
-  %38 = load i32, i32* %37, align 4
+  %38 = load atomic i32, i32* %37 unordered, align 4
   %39 = icmp eq i32 %38, 168
   br i1 %39, label %call_success3, label %epilogue
 
@@ -13443,15 +13523,15 @@
   %44 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %43, i64 0, i32 0
   %45 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %44 monotonic, align 8
   %46 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %45, i64 0, i32 9
-  %47 = load i32, i32* %46, align 4
+  %47 = load atomic i32, i32* %46 unordered, align 4
   %48 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %45, i64 0, i32 10
-  %49 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %48, align 8
+  %49 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %48 unordered, align 8
   %50 = and i32 %47, 168
   %51 = zext i32 %50 to i64
   %52 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %49, i64 %51, i32 2
   %53 = bitcast i8*** %52 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)***
-  %54 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %53, align 8
-  %55 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %54, align 8
+  %54 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %53 unordered, align 8
+  %55 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %54 unordered, align 8
   %56 = call %struct.ObjHeader* %55(%struct.ObjHeader* nonnull %1, %struct.ObjHeader** nonnull %4)
   %57 = call %struct.ObjHeader* @"kfun:kotlin.collections.HashMap.EntryRef#<get-key>(){}1:0"(%struct.ObjHeader* %0, %struct.ObjHeader** nonnull %5)
   %58 = icmp eq %struct.ObjHeader* %56, null
@@ -13471,7 +13551,7 @@
   %66 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %65 monotonic, align 8
   %67 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %66, i64 1
   %68 = bitcast %struct.TypeInfo* %67 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
-  %69 = load i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %68, align 8
+  %69 = load atomic i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %68 unordered, align 8
   %70 = call zeroext i1 %69(%struct.ObjHeader* nonnull %56, %struct.ObjHeader* %57)
   br i1 %70, label %call_success9, label %epilogue
 
@@ -13483,16 +13563,16 @@
   %75 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %74, i64 0, i32 0
   %76 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %75 monotonic, align 8
   %77 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %76, i64 0, i32 9
-  %78 = load i32, i32* %77, align 4
+  %78 = load atomic i32, i32* %77 unordered, align 4
   %79 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %76, i64 0, i32 10
-  %80 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %79, align 8
+  %80 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %79 unordered, align 8
   %81 = and i32 %78, 168
   %82 = zext i32 %81 to i64
   %83 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %80, i64 %82, i32 2
-  %84 = load i8**, i8*** %83, align 8
+  %84 = load atomic i8**, i8*** %83 unordered, align 8
   %85 = getelementptr i8*, i8** %84, i64 1
   %86 = bitcast i8** %85 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %87 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %86, align 8
+  %87 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %86 unordered, align 8
   %88 = call %struct.ObjHeader* %87(%struct.ObjHeader* nonnull %1, %struct.ObjHeader** nonnull %6)
   %89 = call %struct.ObjHeader* @"kfun:kotlin.collections.HashMap.EntryRef#<get-value>(){}1:1"(%struct.ObjHeader* %0, %struct.ObjHeader** nonnull %7)
   %90 = icmp eq %struct.ObjHeader* %88, null
@@ -13512,14 +13592,14 @@
   %98 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %97 monotonic, align 8
   %99 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %98, i64 1
   %100 = bitcast %struct.TypeInfo* %99 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
-  %101 = load i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %100, align 8
+  %101 = load atomic i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %100 unordered, align 8
   %102 = call zeroext i1 %101(%struct.ObjHeader* nonnull %88, %struct.ObjHeader* %89)
   br label %epilogue
 
 epilogue:                                         ; preds = %call_success13, %when_case10, %when_exit7, %when_case4, %instance_of_exit, %Kotlin_mm_safePointFunctionPrologue.exit
   %103 = phi i1 [ %91, %when_case10 ], [ %102, %call_success13 ], [ false, %when_case4 ], [ false, %when_exit7 ], [ false, %instance_of_exit ], [ false, %Kotlin_mm_safePointFunctionPrologue.exit ]
   %104 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
-  %105 = load i64, i64* %14, align 8, !tbaa !9
+  %105 = load atomic i64, i64* %14 unordered, align 8, !tbaa !9
   %106 = bitcast %"class.kotlin::mm::ShadowStack"* %104 to i64*
   store i64 %105, i64* %106, align 8, !tbaa !7
   ret i1 %103
@@ -13533,11 +13613,11 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %2, i8 0, i32 40, i1 immarg false) #49
   %3 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %1, i64 0, i64 3
   %4 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %1, i64 0, i64 4
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %7 = bitcast [5 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
   %8 = bitcast %"class.kotlin::mm::ShadowStack"* %6 to i64*
-  %9 = load i64, i64* %8, align 8, !tbaa !7
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !7
   %10 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %1, i64 0, i64 1
   %11 = bitcast %struct.ObjHeader** %10 to i64*
   store i64 %9, i64* %11, align 8, !tbaa !9
@@ -13572,7 +13652,7 @@
   %28 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %27 monotonic, align 8
   %29 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %28, i64 1, i32 1
   %30 = bitcast %struct.ExtendedTypeInfo** %29 to i32 (%struct.ObjHeader*)**
-  %31 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %30, align 8
+  %31 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %30 unordered, align 8
   %32 = call i32 %31(%struct.ObjHeader* nonnull %20)
   br label %call_success2
 
@@ -13592,7 +13672,7 @@
   %42 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %41 monotonic, align 8
   %43 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %42, i64 1, i32 1
   %44 = bitcast %struct.ExtendedTypeInfo** %43 to i32 (%struct.ObjHeader*)**
-  %45 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %44, align 8
+  %45 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %44 unordered, align 8
   %46 = call i32 %45(%struct.ObjHeader* nonnull %34)
   br label %epilogue
 
@@ -13600,7 +13680,7 @@
   %47 = phi i32 [ %46, %call_success6 ], [ 0, %call_success2 ]
   %48 = xor i32 %33, %47
   %49 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %50 = load i64, i64* %11, align 8, !tbaa !9
+  %50 = load atomic i64, i64* %11 unordered, align 8, !tbaa !9
   %51 = bitcast %"class.kotlin::mm::ShadowStack"* %49 to i64*
   store i64 %50, i64* %51, align 8, !tbaa !7
   ret i32 %48
@@ -13625,11 +13705,11 @@
   %objHeader = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %10, i64 0, i32 0
   %typeInfoOrMeta_ = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %10, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_, align 8
-  %13 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %13 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %14 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %13, i64 0, i32 1, i32 5
   %15 = bitcast [11 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %16 = bitcast %"class.kotlin::mm::ShadowStack"* %14 to i64*
-  %17 = load i64, i64* %16, align 8, !tbaa !7
+  %17 = load atomic i64, i64* %16 unordered, align 8, !tbaa !7
   %18 = getelementptr inbounds [11 x %struct.ObjHeader*], [11 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %19 = bitcast %struct.ObjHeader** %18 to i64*
   store i64 %17, i64* %19, align 8, !tbaa !9
@@ -13667,7 +13747,7 @@
   %37 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %36 monotonic, align 8
   %38 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %37, i64 1, i32 2
   %39 = bitcast i32* %38 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %40 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %39, align 8
+  %40 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %39 unordered, align 8
   %41 = call %struct.ObjHeader* %40(%struct.ObjHeader* nonnull %28, %struct.ObjHeader** nonnull %30)
   br label %call_success5
 
@@ -13689,7 +13769,7 @@
   %53 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %52 monotonic, align 8
   %54 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %53, i64 1, i32 2
   %55 = bitcast i32* %54 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %56 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %55, align 8
+  %56 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %55 unordered, align 8
   %57 = call %struct.ObjHeader* %56(%struct.ObjHeader* nonnull %45, %struct.ObjHeader** nonnull %9)
   br label %epilogue
 
@@ -13700,7 +13780,7 @@
   %61 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#toString(){}kotlin.String"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader** %1)
   store %struct.ObjHeader* %61, %struct.ObjHeader** %1, align 8, !tbaa !3
   %62 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %13, i64 0, i32 1, i32 5
-  %63 = load i64, i64* %19, align 8, !tbaa !9
+  %63 = load atomic i64, i64* %19 unordered, align 8, !tbaa !9
   %64 = bitcast %"class.kotlin::mm::ShadowStack"* %62 to i64*
   store i64 %63, i64* %64, align 8, !tbaa !7
   ret %struct.ObjHeader* %61
@@ -13721,9 +13801,9 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %epilogue
   %5 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %6 = bitcast %struct.ObjHeader* %5 to %"kclassbody:kotlin.collections.HashMap#internal"**
-  %7 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %6, align 8
+  %7 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %6 unordered, align 8
   %8 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %7, i64 0, i32 11
-  %9 = load i32, i32* %8, align 4
+  %9 = load atomic i32, i32* %8 unordered, align 4
   ret i32 %9
 }
 
@@ -13742,9 +13822,9 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %epilogue
   %5 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %6 = bitcast %struct.ObjHeader* %5 to %"kclassbody:kotlin.collections.HashMap#internal"**
-  %7 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %6, align 8
+  %7 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %6 unordered, align 8
   %8 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %7, i64 0, i32 11
-  %9 = load i32, i32* %8, align 4
+  %9 = load atomic i32, i32* %8 unordered, align 4
   %10 = icmp eq i32 %9, 0
   ret i1 %10
 }
@@ -13763,7 +13843,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
   %6 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %7 = bitcast %struct.ObjHeader* %6 to %struct.ObjHeader**
-  %8 = load %struct.ObjHeader*, %struct.ObjHeader** %7, align 8
+  %8 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %7 unordered, align 8
   %9 = tail call fastcc i32 @"kfun:kotlin.collections.HashMap.findKey#internal"(%struct.ObjHeader* %8, %struct.ObjHeader* %1)
   %10 = icmp sgt i32 %9, -1
   ret i1 %10
@@ -13783,7 +13863,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %6, %epilogue
   %7 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %8 = bitcast %struct.ObjHeader* %7 to %struct.ObjHeader**
-  %9 = load %struct.ObjHeader*, %struct.ObjHeader** %8, align 8
+  %9 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %8 unordered, align 8
   %10 = tail call fastcc %struct.ObjHeader* @"kfun:kotlin.collections.HashMap#getKey(1:0){}1:0?"(%struct.ObjHeader* %9, %struct.ObjHeader* %1, %struct.ObjHeader** %2)
   store %struct.ObjHeader* %10, %struct.ObjHeader** %2, align 8, !tbaa !3
   ret %struct.ObjHeader* %10
@@ -13797,11 +13877,11 @@
   %3 = bitcast [4 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %3, i8 0, i32 32, i1 immarg false) #49
   %4 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 3
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %7 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %8 = bitcast %"class.kotlin::mm::ShadowStack"* %6 to i64*
-  %9 = load i64, i64* %8, align 8, !tbaa !7
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !7
   %10 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %11 = bitcast %struct.ObjHeader** %10 to i64*
   store i64 %9, i64* %11, align 8, !tbaa !9
@@ -13824,7 +13904,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %19, %call_success
   %20 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 6
   %21 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %20 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %22 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %21, align 8, !tbaa !3
+  %22 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %21 unordered, align 8, !tbaa !3
   %23 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %22, i64 0, i32 2, i32 1
   %24 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %23, i64 56) #37
   %25 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %24, i64 1
@@ -13855,7 +13935,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
   %6 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %7 = bitcast %struct.ObjHeader* %6 to %struct.ObjHeader**
-  %8 = load %struct.ObjHeader*, %struct.ObjHeader** %7, align 8
+  %8 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %7 unordered, align 8
   %9 = tail call fastcc i32 @"kfun:kotlin.collections.HashMap#removeKey(1:0){}kotlin.Int"(%struct.ObjHeader* %8, %struct.ObjHeader* %1)
   %10 = icmp sgt i32 %9, -1
   ret i1 %10
@@ -13875,7 +13955,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
   %6 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %7 = bitcast %struct.ObjHeader* %6 to %struct.ObjHeader**
-  %8 = load %struct.ObjHeader*, %struct.ObjHeader** %7, align 8
+  %8 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %7 unordered, align 8
   %9 = tail call fastcc %struct.ObjHeader* @"kfun:kotlin.collections.HashMap#keysIterator(){}kotlin.collections.HashMap.KeysItr<1:0,1:1>"(%struct.ObjHeader* %8, %struct.ObjHeader** %1)
   store %struct.ObjHeader* %9, %struct.ObjHeader** %1, align 8, !tbaa !3
   ret %struct.ObjHeader* %9
@@ -13896,7 +13976,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %7, %entry
   %8 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %9 = bitcast %struct.ObjHeader* %8 to %struct.ObjHeader**
-  %10 = load %struct.ObjHeader*, %struct.ObjHeader** %9, align 8
+  %10 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %9 unordered, align 8
   %11 = bitcast [7 x %struct.ObjHeader*]* %3 to i8*
   call void @llvm.lifetime.start.p0i8(i64 56, i8* nonnull %11)
   %.sub.i = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %3, i64 0, i64 0
@@ -13904,11 +13984,11 @@
   %12 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %3, i64 0, i64 3
   %13 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %3, i64 0, i64 5
   %14 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %3, i64 0, i64 6
-  %15 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %15 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %16 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %15, i64 0, i32 1, i32 5
   %17 = bitcast [7 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %18 = bitcast %"class.kotlin::mm::ShadowStack"* %16 to i64*
-  %19 = load i64, i64* %18, align 8, !tbaa !7
+  %19 = load atomic i64, i64* %18 unordered, align 8, !tbaa !7
   %20 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %21 = bitcast %struct.ObjHeader** %20 to i64*
   store i64 %19, i64* %21, align 8, !tbaa !9
@@ -13927,15 +14007,15 @@
   %31 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %30, i64 0, i32 0
   %32 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %31 monotonic, align 8
   %33 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %32, i64 0, i32 9
-  %34 = load i32, i32* %33, align 4
+  %34 = load atomic i32, i32* %33 unordered, align 4
   %35 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %32, i64 0, i32 10
-  %36 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %35, align 8
+  %36 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %35 unordered, align 8
   %37 = and i32 %34, 168
   %38 = zext i32 %37 to i64
   %39 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %36, i64 %38, i32 2
   %40 = bitcast i8*** %39 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)***
-  %41 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %40, align 8
-  %42 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %41, align 8
+  %41 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %40 unordered, align 8
+  %42 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %41 unordered, align 8
   %43 = call %struct.ObjHeader* %42(%struct.ObjHeader* %1, %struct.ObjHeader** nonnull %12)
   %44 = call fastcc i32 @"kfun:kotlin.collections.HashMap.findKey#internal"(%struct.ObjHeader* %10, %struct.ObjHeader* %43)
   %45 = icmp slt i32 %44, 0
@@ -13945,7 +14025,7 @@
   %46 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %3, i64 0, i64 4
   %47 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %10, i64 2
   %48 = bitcast %struct.ObjHeader* %47 to %struct.ObjHeader**
-  %49 = load %struct.ObjHeader*, %struct.ObjHeader** %48, align 8
+  %49 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %48 unordered, align 8
   store %struct.ObjHeader* %49, %struct.ObjHeader** %46, align 8, !tbaa !3
   %50 = icmp eq %struct.ObjHeader* %49, null
   br i1 %50, label %when_case4.i, label %when_exit5.i
@@ -13957,7 +14037,7 @@
 when_exit5.i:                                     ; preds = %when_next3.i
   %51 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %49, i64 1
   %52 = bitcast %struct.ObjHeader* %51 to i32*
-  %53 = load i32, i32* %52, align 8, !tbaa !18
+  %53 = load atomic i32, i32* %52 unordered, align 8, !tbaa !18
   %54 = icmp ugt i32 %53, %44
   br i1 %54, label %Kotlin_Array_get.exit.i, label %55
 
@@ -13970,7 +14050,7 @@
   %57 = sext i32 %44 to i64
   %58 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %56, i64 %57
   %59 = bitcast %struct.ObjHeader* %58 to %struct.ObjHeader**
-  %60 = load %struct.ObjHeader*, %struct.ObjHeader** %59, align 8, !tbaa !3
+  %60 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %59 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %60, %struct.ObjHeader** %13, align 8, !tbaa !3
   %61 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %26 monotonic, align 8
   %62 = ptrtoint %struct.TypeInfo* %61 to i64
@@ -13979,16 +14059,16 @@
   %65 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %64, i64 0, i32 0
   %66 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %65 monotonic, align 8
   %67 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %66, i64 0, i32 9
-  %68 = load i32, i32* %67, align 4
+  %68 = load atomic i32, i32* %67 unordered, align 4
   %69 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %66, i64 0, i32 10
-  %70 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %69, align 8
+  %70 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %69 unordered, align 8
   %71 = and i32 %68, 168
   %72 = zext i32 %71 to i64
   %73 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %70, i64 %72, i32 2
-  %74 = load i8**, i8*** %73, align 8
+  %74 = load atomic i8**, i8*** %73 unordered, align 8
   %75 = getelementptr i8*, i8** %74, i64 1
   %76 = bitcast i8** %75 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %77 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %76, align 8
+  %77 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %76 unordered, align 8
   %78 = call %struct.ObjHeader* %77(%struct.ObjHeader* %1, %struct.ObjHeader** nonnull %14)
   %79 = icmp eq %struct.ObjHeader* %60, null
   br i1 %79, label %when_case10.i, label %when_exit.i
@@ -14007,15 +14087,15 @@
   %87 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %86 monotonic, align 8
   %88 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %87, i64 1
   %89 = bitcast %struct.TypeInfo* %88 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
-  %90 = load i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %89, align 8
+  %90 = load atomic i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %89 unordered, align 8
   %91 = call zeroext i1 %90(%struct.ObjHeader* nonnull %60, %struct.ObjHeader* %78)
   br i1 %91, label %when_next.i, label %epilogue
 
 when_next.i:                                      ; preds = %when_exit.i, %when_case10.i
-  %92 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %92 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %93 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %92, i64 0, i32 1, i32 6
   %94 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %93 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %95 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %94, align 8, !tbaa !3
+  %95 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %94 unordered, align 8, !tbaa !3
   %96 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %95, i64 0, i32 2, i32 1
   %97 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %96, i64 32) #37
   %98 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %97, i64 1
@@ -14038,9 +14118,9 @@
 epilogue:                                         ; preds = %when_next.i, %when_exit.i, %when_case10.i, %Kotlin_mm_safePointFunctionPrologue.exit
   %108 = phi %struct.ObjHeader* [ %100, %when_next.i ], [ null, %when_exit.i ], [ null, %Kotlin_mm_safePointFunctionPrologue.exit ], [ null, %when_case10.i ]
   store %struct.ObjHeader* %108, %struct.ObjHeader** %2, align 8, !tbaa !3
-  %109 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %109 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %110 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %109, i64 0, i32 1, i32 5
-  %111 = load i64, i64* %21, align 8, !tbaa !9
+  %111 = load atomic i64, i64* %21 unordered, align 8, !tbaa !9
   %112 = bitcast %"class.kotlin::mm::ShadowStack"* %110 to i64*
   store i64 %111, i64* %112, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 56, i8* nonnull %11)
@@ -14062,7 +14142,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
   %6 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %7 = bitcast %struct.ObjHeader* %6 to %struct.ObjHeader**
-  %8 = load %struct.ObjHeader*, %struct.ObjHeader** %7, align 8
+  %8 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %7 unordered, align 8
   %9 = tail call fastcc %struct.ObjHeader* @"kfun:kotlin.collections.HashMap#entriesIterator(){}kotlin.collections.HashMap.EntriesItr<1:0,1:1>"(%struct.ObjHeader* %8, %struct.ObjHeader** %1)
   store %struct.ObjHeader* %9, %struct.ObjHeader** %1, align 8, !tbaa !3
   ret %struct.ObjHeader* %9
@@ -14083,9 +14163,9 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %epilogue
   %5 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %6 = bitcast %struct.ObjHeader* %5 to %"kclassbody:kotlin.collections.HashMap#internal"**
-  %7 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %6, align 8
+  %7 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %6 unordered, align 8
   %8 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %7, i64 0, i32 11
-  %9 = load i32, i32* %8, align 4
+  %9 = load atomic i32, i32* %8 unordered, align 4
   ret i32 %9
 }
 
@@ -14104,9 +14184,9 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %epilogue
   %5 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %6 = bitcast %struct.ObjHeader* %5 to %"kclassbody:kotlin.collections.HashMap#internal"**
-  %7 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %6, align 8
+  %7 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %6 unordered, align 8
   %8 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %7, i64 0, i32 11
-  %9 = load i32, i32* %8, align 4
+  %9 = load atomic i32, i32* %8 unordered, align 4
   %10 = icmp eq i32 %9, 0
   ret i1 %10
 }
@@ -14135,20 +14215,20 @@
   %12 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %11, i64 0, i32 0
   %13 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %12 monotonic, align 8
   %14 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %13, i64 0, i32 9
-  %15 = load i32, i32* %14, align 4
+  %15 = load atomic i32, i32* %14 unordered, align 4
   %16 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %13, i64 0, i32 10
-  %17 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %16, align 8
+  %17 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %16 unordered, align 8
   %18 = and i32 %15, 168
   %19 = zext i32 %18 to i64
   %20 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %17, i64 %19, i32 0
-  %21 = load i32, i32* %20, align 4
+  %21 = load atomic i32, i32* %20 unordered, align 4
   %.not = icmp eq i32 %21, 168
   br i1 %.not, label %call_success, label %epilogue
 
 call_success:                                     ; preds = %instance_of_exit
   %22 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %23 = bitcast %struct.ObjHeader* %22 to %struct.ObjHeader**
-  %24 = load %struct.ObjHeader*, %struct.ObjHeader** %23, align 8
+  %24 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %23 unordered, align 8
   %25 = tail call fastcc zeroext i1 @"kfun:kotlin.collections.HashMap#containsEntry(kotlin.collections.Map.Entry<1:0,1:1>){}kotlin.Boolean"(%struct.ObjHeader* %24, %struct.ObjHeader* nonnull %1)
   br label %epilogue
 
@@ -14178,7 +14258,7 @@
   %13 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %12 monotonic, align 8
   %14 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %13, i64 2, i32 4
   %15 = bitcast %struct.TypeInfo** %14 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader**)**
-  %16 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader**)** %15, align 8
+  %16 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader**)** %15 unordered, align 8
   %17 = tail call %struct.ObjHeader* %16(%struct.ObjHeader* %0, %struct.ObjHeader* %1, %struct.ObjHeader** %2)
   store %struct.ObjHeader* %17, %struct.ObjHeader** %2, align 8, !tbaa !3
   ret %struct.ObjHeader* %17
@@ -14192,11 +14272,11 @@
   %3 = bitcast [4 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %3, i8 0, i32 32, i1 immarg false) #49
   %4 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 3
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %7 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %8 = bitcast %"class.kotlin::mm::ShadowStack"* %6 to i64*
-  %9 = load i64, i64* %8, align 8, !tbaa !7
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !7
   %10 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %11 = bitcast %struct.ObjHeader** %10 to i64*
   store i64 %9, i64* %11, align 8, !tbaa !9
@@ -14219,7 +14299,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %19, %call_success
   %20 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 6
   %21 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %20 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %22 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %21, align 8, !tbaa !3
+  %22 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %21 unordered, align 8, !tbaa !3
   %23 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %22, i64 0, i32 2, i32 1
   %24 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %23, i64 56) #37
   %25 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %24, i64 1
@@ -14261,20 +14341,20 @@
   %13 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %12, i64 0, i32 0
   %14 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %13 monotonic, align 8
   %15 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %14, i64 0, i32 9
-  %16 = load i32, i32* %15, align 4
+  %16 = load atomic i32, i32* %15 unordered, align 4
   %17 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %14, i64 0, i32 10
-  %18 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %17, align 8
+  %18 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %17 unordered, align 8
   %19 = and i32 %16, 168
   %20 = zext i32 %19 to i64
   %21 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %18, i64 %20, i32 0
-  %22 = load i32, i32* %21, align 4
+  %22 = load atomic i32, i32* %21 unordered, align 4
   %.not = icmp eq i32 %22, 168
   br i1 %.not, label %when_exit, label %epilogue
 
 when_exit:                                        ; preds = %instance_of_exit
   %23 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %24 = bitcast %struct.ObjHeader* %23 to %struct.ObjHeader**
-  %25 = load %struct.ObjHeader*, %struct.ObjHeader** %24, align 8
+  %25 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %24 unordered, align 8
   %26 = bitcast [7 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.lifetime.start.p0i8(i64 56, i8* nonnull %26)
   %.sub.i = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 0
@@ -14282,11 +14362,11 @@
   %27 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %28 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 5
   %29 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 6
-  %30 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %30 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %31 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %30, i64 0, i32 1, i32 5
   %32 = bitcast [7 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %33 = bitcast %"class.kotlin::mm::ShadowStack"* %31 to i64*
-  %34 = load i64, i64* %33, align 8, !tbaa !7
+  %34 = load atomic i64, i64* %33 unordered, align 8, !tbaa !7
   %35 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %36 = bitcast %struct.ObjHeader** %35 to i64*
   store i64 %34, i64* %36, align 8, !tbaa !9
@@ -14305,15 +14385,15 @@
   %45 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %44, i64 0, i32 0
   %46 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %45 monotonic, align 8
   %47 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %46, i64 0, i32 9
-  %48 = load i32, i32* %47, align 4
+  %48 = load atomic i32, i32* %47 unordered, align 4
   %49 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %46, i64 0, i32 10
-  %50 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %49, align 8
+  %50 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %49 unordered, align 8
   %51 = and i32 %48, 168
   %52 = zext i32 %51 to i64
   %53 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %50, i64 %52, i32 2
   %54 = bitcast i8*** %53 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)***
-  %55 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %54, align 8
-  %56 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %55, align 8
+  %55 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %54 unordered, align 8
+  %56 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %55 unordered, align 8
   %57 = call %struct.ObjHeader* %56(%struct.ObjHeader* nonnull %1, %struct.ObjHeader** nonnull %27)
   %58 = call fastcc i32 @"kfun:kotlin.collections.HashMap.findKey#internal"(%struct.ObjHeader* %25, %struct.ObjHeader* %57)
   %59 = icmp slt i32 %58, 0
@@ -14323,7 +14403,7 @@
   %60 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 4
   %61 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %25, i64 2
   %62 = bitcast %struct.ObjHeader* %61 to %struct.ObjHeader**
-  %63 = load %struct.ObjHeader*, %struct.ObjHeader** %62, align 8
+  %63 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %62 unordered, align 8
   store %struct.ObjHeader* %63, %struct.ObjHeader** %60, align 8, !tbaa !3
   %64 = icmp eq %struct.ObjHeader* %63, null
   br i1 %64, label %when_case4.i, label %when_exit5.i
@@ -14335,7 +14415,7 @@
 when_exit5.i:                                     ; preds = %when_exit.i
   %65 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %63, i64 1
   %66 = bitcast %struct.ObjHeader* %65 to i32*
-  %67 = load i32, i32* %66, align 8, !tbaa !18
+  %67 = load atomic i32, i32* %66 unordered, align 8, !tbaa !18
   %68 = icmp ugt i32 %67, %58
   br i1 %68, label %Kotlin_Array_get.exit.i, label %69
 
@@ -14348,7 +14428,7 @@
   %71 = sext i32 %58 to i64
   %72 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %70, i64 %71
   %73 = bitcast %struct.ObjHeader* %72 to %struct.ObjHeader**
-  %74 = load %struct.ObjHeader*, %struct.ObjHeader** %73, align 8, !tbaa !3
+  %74 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %73 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %74, %struct.ObjHeader** %28, align 8, !tbaa !3
   %75 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %8 monotonic, align 8
   %76 = ptrtoint %struct.TypeInfo* %75 to i64
@@ -14357,16 +14437,16 @@
   %79 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %78, i64 0, i32 0
   %80 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %79 monotonic, align 8
   %81 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %80, i64 0, i32 9
-  %82 = load i32, i32* %81, align 4
+  %82 = load atomic i32, i32* %81 unordered, align 4
   %83 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %80, i64 0, i32 10
-  %84 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %83, align 8
+  %84 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %83 unordered, align 8
   %85 = and i32 %82, 168
   %86 = zext i32 %85 to i64
   %87 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %84, i64 %86, i32 2
-  %88 = load i8**, i8*** %87, align 8
+  %88 = load atomic i8**, i8*** %87 unordered, align 8
   %89 = getelementptr i8*, i8** %88, i64 1
   %90 = bitcast i8** %89 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %91 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %90, align 8
+  %91 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %90 unordered, align 8
   %92 = call %struct.ObjHeader* %91(%struct.ObjHeader* nonnull %1, %struct.ObjHeader** nonnull %29)
   %93 = icmp eq %struct.ObjHeader* %74, null
   br i1 %93, label %when_case10.i, label %when_exit11.i
@@ -14385,7 +14465,7 @@
   %101 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %100 monotonic, align 8
   %102 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %101, i64 1
   %103 = bitcast %struct.TypeInfo* %102 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
-  %104 = load i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %103, align 8
+  %104 = load atomic i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %103 unordered, align 8
   %105 = call zeroext i1 %104(%struct.ObjHeader* nonnull %74, %struct.ObjHeader* %92)
   br i1 %105, label %when_exit13.i, label %call_success
 
@@ -14395,9 +14475,9 @@
 
 call_success:                                     ; preds = %when_exit13.i, %when_exit11.i, %when_case10.i, %when_exit
   %106 = phi i1 [ true, %when_exit13.i ], [ false, %when_exit ], [ false, %when_case10.i ], [ false, %when_exit11.i ]
-  %107 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %107 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %108 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %107, i64 0, i32 1, i32 5
-  %109 = load i64, i64* %36, align 8, !tbaa !9
+  %109 = load atomic i64, i64* %36 unordered, align 8, !tbaa !9
   %110 = bitcast %"class.kotlin::mm::ShadowStack"* %108 to i64*
   store i64 %109, i64* %110, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 56, i8* nonnull %26)
@@ -14422,7 +14502,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
   %6 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %7 = bitcast %struct.ObjHeader* %6 to %struct.ObjHeader**
-  %8 = load %struct.ObjHeader*, %struct.ObjHeader** %7, align 8
+  %8 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %7 unordered, align 8
   %9 = tail call fastcc zeroext i1 @"kfun:kotlin.collections.HashMap#containsAllEntries(kotlin.collections.Collection<*>){}kotlin.Boolean"(%struct.ObjHeader* %8, %struct.ObjHeader* %1)
   ret i1 %9
 }
@@ -14442,9 +14522,9 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %epilogue
   %5 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %6 = bitcast %struct.ObjHeader* %5 to %"kclassbody:kotlin.collections.HashMap#internal"**
-  %7 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %6, align 8
+  %7 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %6 unordered, align 8
   %8 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %7, i64 0, i32 11
-  %9 = load i32, i32* %8, align 4
+  %9 = load atomic i32, i32* %8 unordered, align 4
   ret i32 %9
 }
 
@@ -14463,9 +14543,9 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %epilogue
   %5 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %6 = bitcast %struct.ObjHeader* %5 to %"kclassbody:kotlin.collections.HashMap#internal"**
-  %7 = load %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %6, align 8
+  %7 = load atomic %"kclassbody:kotlin.collections.HashMap#internal"*, %"kclassbody:kotlin.collections.HashMap#internal"** %6 unordered, align 8
   %8 = getelementptr inbounds %"kclassbody:kotlin.collections.HashMap#internal", %"kclassbody:kotlin.collections.HashMap#internal"* %7, i64 0, i32 11
-  %9 = load i32, i32* %8, align 4
+  %9 = load atomic i32, i32* %8 unordered, align 4
   %10 = icmp eq i32 %9, 0
   ret i1 %10
 }
@@ -14484,7 +14564,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
   %6 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %7 = bitcast %struct.ObjHeader* %6 to %struct.ObjHeader**
-  %8 = load %struct.ObjHeader*, %struct.ObjHeader** %7, align 8
+  %8 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %7 unordered, align 8
   %9 = tail call fastcc i32 @"kfun:kotlin.collections.HashMap.findKey#internal"(%struct.ObjHeader* %8, %struct.ObjHeader* %1)
   %10 = icmp sgt i32 %9, -1
   ret i1 %10
@@ -14504,7 +14584,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %6, %epilogue
   %7 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %8 = bitcast %struct.ObjHeader* %7 to %struct.ObjHeader**
-  %9 = load %struct.ObjHeader*, %struct.ObjHeader** %8, align 8
+  %9 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %8 unordered, align 8
   %10 = tail call fastcc %struct.ObjHeader* @"kfun:kotlin.collections.HashMap#getKey(1:0){}1:0?"(%struct.ObjHeader* %9, %struct.ObjHeader* %1, %struct.ObjHeader** %2)
   store %struct.ObjHeader* %10, %struct.ObjHeader** %2, align 8, !tbaa !3
   ret %struct.ObjHeader* %10
@@ -14524,7 +14604,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
   %6 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %7 = bitcast %struct.ObjHeader* %6 to %struct.ObjHeader**
-  %8 = load %struct.ObjHeader*, %struct.ObjHeader** %7, align 8
+  %8 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %7 unordered, align 8
   %9 = tail call fastcc i32 @"kfun:kotlin.collections.HashMap#addKey(1:0){}kotlin.Int"(%struct.ObjHeader* %8, %struct.ObjHeader* %1)
   %10 = icmp sgt i32 %9, -1
   ret i1 %10
@@ -14544,7 +14624,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
   %6 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %7 = bitcast %struct.ObjHeader* %6 to %struct.ObjHeader**
-  %8 = load %struct.ObjHeader*, %struct.ObjHeader** %7, align 8
+  %8 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %7 unordered, align 8
   %9 = tail call fastcc i32 @"kfun:kotlin.collections.HashMap#removeKey(1:0){}kotlin.Int"(%struct.ObjHeader* %8, %struct.ObjHeader* %1)
   %10 = icmp sgt i32 %9, -1
   ret i1 %10
@@ -14564,7 +14644,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
   %6 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %7 = bitcast %struct.ObjHeader* %6 to %struct.ObjHeader**
-  %8 = load %struct.ObjHeader*, %struct.ObjHeader** %7, align 8
+  %8 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %7 unordered, align 8
   %9 = tail call fastcc %struct.ObjHeader* @"kfun:kotlin.collections.HashMap#keysIterator(){}kotlin.collections.HashMap.KeysItr<1:0,1:1>"(%struct.ObjHeader* %8, %struct.ObjHeader** %1)
   store %struct.ObjHeader* %9, %struct.ObjHeader** %1, align 8, !tbaa !3
   ret %struct.ObjHeader* %9
@@ -14576,11 +14656,11 @@
   %.sub = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 0
   %3 = bitcast [4 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %3, i8 0, i32 32, i1 immarg false) #49
-  %4 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %4 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %5 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
   %6 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %7 = bitcast %"class.kotlin::mm::ShadowStack"* %5 to i64*
-  %8 = load i64, i64* %7, align 8, !tbaa !7
+  %8 = load atomic i64, i64* %7 unordered, align 8, !tbaa !7
   %9 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %10 = bitcast %struct.ObjHeader** %9 to i64*
   store i64 %8, i64* %10, align 8, !tbaa !9
@@ -14612,7 +14692,7 @@
   %21 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %22 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 6
   %23 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %22 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %24 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %23, align 8, !tbaa !3
+  %24 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %23 unordered, align 8, !tbaa !3
   %25 = zext i32 %1 to i64
   %26 = shl nuw nsw i64 %25, 1
   %27 = add nuw nsw i64 %26, 31
@@ -14634,7 +14714,7 @@
   %39 = bitcast %struct.ObjHeader* %38 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %32, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %39, align 8, !tbaa !3
   %40 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %41 = load i64, i64* %10, align 8, !tbaa !9
+  %41 = load atomic i64, i64* %10 unordered, align 8, !tbaa !9
   %42 = bitcast %"class.kotlin::mm::ShadowStack"* %40 to i64*
   store i64 %41, i64* %42, align 8, !tbaa !7
   ret void
@@ -14655,7 +14735,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %epilogue
   %5 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %6 = bitcast %struct.ObjHeader* %5 to i32*
-  %7 = load i32, i32* %6, align 4
+  %7 = load atomic i32, i32* %6 unordered, align 4
   ret i32 %7
 }
 
@@ -14667,11 +14747,11 @@
   %4 = bitcast [4 x %struct.ObjHeader*]* %3 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %4, i8 0, i32 32, i1 immarg false) #49
   %5 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 3
-  %6 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %7 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
   %8 = bitcast [4 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %9 = bitcast %"class.kotlin::mm::ShadowStack"* %7 to i64*
-  %10 = load i64, i64* %9, align 8, !tbaa !7
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa !7
   %11 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %12 = bitcast %struct.ObjHeader** %11 to i64*
   store i64 %10, i64* %12, align 8, !tbaa !9
@@ -14699,7 +14779,7 @@
   %22 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
   %23 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %24 = bitcast %"class.kotlin::mm::ShadowStack"* %22 to i64*
-  %25 = load i64, i64* %24, align 8, !tbaa !7
+  %25 = load atomic i64, i64* %24 unordered, align 8, !tbaa !7
   %26 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %27 = bitcast %struct.ObjHeader** %26 to i64*
   store i64 %25, i64* %27, align 8, !tbaa !9
@@ -14716,7 +14796,7 @@
 when_exit.i:                                      ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
   %33 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %34 = bitcast %struct.ObjHeader* %33 to i32*
-  %35 = load i32, i32* %34, align 4
+  %35 = load atomic i32, i32* %34 unordered, align 4
   %.not = icmp sgt i32 %35, %1
   br i1 %.not, label %call_success, label %when_case.i
 
@@ -14724,7 +14804,7 @@
   %36 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %37 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 6
   %38 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %37 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %39 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %38, align 8, !tbaa !3
+  %39 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %38 unordered, align 8, !tbaa !3
   %40 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %39, i64 0, i32 2, i32 1
   %41 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %40, i64 56) #37
   %42 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %41, i64 1
@@ -14742,17 +14822,17 @@
 
 call_success:                                     ; preds = %when_exit.i
   %48 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %49 = load i64, i64* %27, align 8, !tbaa !9
+  %49 = load atomic i64, i64* %27 unordered, align 8, !tbaa !9
   %50 = bitcast %"class.kotlin::mm::ShadowStack"* %48 to i64*
   store i64 %49, i64* %50, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %21)
   %51 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %52 = bitcast %struct.ObjHeader* %51 to %struct.ObjHeader**
-  %53 = load %struct.ObjHeader*, %struct.ObjHeader** %52, align 8
+  %53 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %52 unordered, align 8
   store %struct.ObjHeader* %53, %struct.ObjHeader** %5, align 8, !tbaa !3
   %54 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %53, i64 1
   %55 = bitcast %struct.ObjHeader* %54 to i32*
-  %56 = load i32, i32* %55, align 8, !tbaa !18
+  %56 = load atomic i32, i32* %55 unordered, align 8, !tbaa !18
   %57 = icmp ugt i32 %56, %1
   br i1 %57, label %epilogue, label %58
 
@@ -14765,8 +14845,8 @@
   %60 = bitcast %struct.ObjHeader* %59 to i16*
   %61 = sext i32 %1 to i64
   %62 = getelementptr inbounds i16, i16* %60, i64 %61
-  %63 = load i16, i16* %62, align 2, !tbaa !34
-  %64 = load i64, i64* %12, align 8, !tbaa !9
+  %63 = load atomic i16, i16* %62 unordered, align 2, !tbaa !27
+  %64 = load atomic i64, i64* %12 unordered, align 8, !tbaa !9
   store i64 %64, i64* %50, align 8, !tbaa !7
   ret i16 %63
 }
@@ -14778,11 +14858,11 @@
   %4 = bitcast [4 x %struct.ObjHeader*]* %3 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %4, i8 0, i32 32, i1 immarg false) #49
   %5 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 3
-  %6 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %7 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
   %8 = bitcast [4 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %9 = bitcast %"class.kotlin::mm::ShadowStack"* %7 to i64*
-  %10 = load i64, i64* %9, align 8, !tbaa !7
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa !7
   %11 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %12 = bitcast %struct.ObjHeader** %11 to i64*
   store i64 %10, i64* %12, align 8, !tbaa !9
@@ -14805,20 +14885,20 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %20, %call_success1
   %21 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %22 = bitcast %struct.ObjHeader* %21 to i32*
-  %23 = load i32, i32* %22, align 4
+  %23 = load atomic i32, i32* %22 unordered, align 4
   %24 = add i32 %23, 1
   call fastcc void @"kfun:kotlin.text.StringBuilder#ensureCapacity(kotlin.Int){}"(%struct.ObjHeader* %0, i32 %24)
   %25 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %26 = bitcast %struct.ObjHeader* %25 to %struct.ObjHeader**
-  %27 = load %struct.ObjHeader*, %struct.ObjHeader** %26, align 8
+  %27 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %26 unordered, align 8
   store %struct.ObjHeader* %27, %struct.ObjHeader** %5, align 8, !tbaa !3
-  %28 = load i32, i32* %22, align 4
+  %28 = load atomic i32, i32* %22 unordered, align 4
   %29 = add i32 %28, 1
   call fastcc void @"kfun:kotlin.text.StringBuilder#ensureCapacity(kotlin.Int){}"(%struct.ObjHeader* %0, i32 %29)
   store i32 %29, i32* %22, align 4
   %30 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %27, i64 1
   %31 = bitcast %struct.ObjHeader* %30 to i32*
-  %32 = load i32, i32* %31, align 8, !tbaa !18
+  %32 = load atomic i32, i32* %31 unordered, align 8, !tbaa !18
   %33 = icmp ugt i32 %32, %28
   br i1 %33, label %epilogue, label %34
 
@@ -14833,10 +14913,10 @@
   %38 = bitcast %struct.ObjHeader* %37 to i16*
   %39 = sext i32 %28 to i64
   %40 = getelementptr inbounds i16, i16* %38, i64 %39
-  store i16 %1, i16* %40, align 2, !tbaa !34
+  store i16 %1, i16* %40, align 2, !tbaa !27
   store %struct.ObjHeader* %0, %struct.ObjHeader** %2, align 8, !tbaa !3
   %41 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %42 = load i64, i64* %12, align 8, !tbaa !9
+  %42 = load atomic i64, i64* %12 unordered, align 8, !tbaa !9
   %43 = bitcast %"class.kotlin::mm::ShadowStack"* %41 to i64*
   store i64 %42, i64* %43, align 8, !tbaa !7
   ret %struct.ObjHeader* %0
@@ -14864,15 +14944,15 @@
   %13 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %12, i64 0, i32 0
   %14 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %13 monotonic, align 8
   %15 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %14, i64 0, i32 9
-  %16 = load i32, i32* %15, align 4
+  %16 = load atomic i32, i32* %15 unordered, align 4
   %17 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %14, i64 0, i32 10
-  %18 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %17, align 8
+  %18 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %17 unordered, align 8
   %19 = and i32 %16, 25
   %20 = zext i32 %19 to i64
   %21 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %18, i64 %20, i32 2
   %22 = bitcast i8*** %21 to i32 (%struct.ObjHeader*)***
-  %23 = load i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %22, align 8
-  %24 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %23, align 8
+  %23 = load atomic i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %22 unordered, align 8
+  %24 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %23 unordered, align 8
   %25 = tail call i32 %24(%struct.ObjHeader* %spec.select)
   %26 = tail call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#append(kotlin.CharSequence?;kotlin.Int;kotlin.Int){}kotlin.text.StringBuilder"(%struct.ObjHeader* %0, %struct.ObjHeader* %spec.select, i32 0, i32 %25, %struct.ObjHeader** %2)
   store %struct.ObjHeader* %0, %struct.ObjHeader** %2, align 8, !tbaa !3
@@ -14899,11 +14979,11 @@
   %.sub.i = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %5, i64 0, i64 0
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %11, i8 0, i32 40, i1 immarg false) #49
   %12 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %5, i64 0, i64 4
-  %13 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %13 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %14 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %13, i64 0, i32 1, i32 5
   %15 = bitcast [5 x %struct.ObjHeader*]* %5 to %struct.FrameOverlay.6*
   %16 = bitcast %"class.kotlin::mm::ShadowStack"* %14 to i64*
-  %17 = load i64, i64* %16, align 8, !tbaa !7
+  %17 = load atomic i64, i64* %16 unordered, align 8, !tbaa !7
   %18 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %5, i64 0, i64 1
   %19 = bitcast %struct.ObjHeader** %18 to i64*
   store i64 %17, i64* %19, align 8, !tbaa !9
@@ -14922,21 +15002,21 @@
   %29 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %28, i64 0, i32 0
   %30 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %29 monotonic, align 8
   %31 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %30, i64 0, i32 9
-  %32 = load i32, i32* %31, align 4
+  %32 = load atomic i32, i32* %31 unordered, align 4
   %33 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %30, i64 0, i32 10
-  %34 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %33, align 8
+  %34 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %33 unordered, align 8
   %35 = and i32 %32, 25
   %36 = zext i32 %35 to i64
   %37 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %34, i64 %36, i32 2
   %38 = bitcast i8*** %37 to i32 (%struct.ObjHeader*)***
-  %39 = load i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %38, align 8
-  %40 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %39, align 8
+  %39 = load atomic i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %38 unordered, align 8
+  %40 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %39 unordered, align 8
   %41 = call i32 %40(%struct.ObjHeader* %spec.select)
   call fastcc void @"kfun:kotlin.text#checkBoundsIndexes(kotlin.Int;kotlin.Int;kotlin.Int){}"(i32 %2, i32 %3, i32 %41)
   %42 = sub i32 %3, %2
   %43 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %44 = bitcast %struct.ObjHeader* %43 to i32*
-  %45 = load i32, i32* %44, align 4
+  %45 = load atomic i32, i32* %44 unordered, align 4
   %46 = add i32 %45, %42
   call fastcc void @"kfun:kotlin.text.StringBuilder#ensureCapacity(kotlin.Int){}"(%struct.ObjHeader* %0, i32 %46)
   %47 = bitcast %struct.ObjHeader* %spec.select to i64*
@@ -14946,7 +15026,7 @@
   %51 = load atomic volatile i64, i64* %50 monotonic, align 8
   %52 = inttoptr i64 %51 to %struct.TypeInfo*
   %53 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %52, i64 0, i32 14
-  %54 = load i32, i32* %53, align 4, !tbaa !19
+  %54 = load atomic i32, i32* %53 unordered, align 4, !tbaa !19
   %55 = icmp eq i32 %54, 116
   br i1 %55, label %when_next4.i, label %when_case3.i
 
@@ -14959,10 +15039,10 @@
 
 when_next4.i:                                     ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
   %59 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %5, i64 0, i64 3
-  %60 = load i32, i32* %44, align 4
+  %60 = load atomic i32, i32* %44 unordered, align 4
   %61 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %62 = bitcast %struct.ObjHeader* %61 to %struct.ObjHeader**
-  %63 = load %struct.ObjHeader*, %struct.ObjHeader** %62, align 8
+  %63 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %62 unordered, align 8
   store %struct.ObjHeader* %63, %struct.ObjHeader** %59, align 8, !tbaa !3
   %64 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %63, i64 2
   %65 = bitcast %struct.ObjHeader* %64 to i16*
@@ -14993,9 +15073,9 @@
   br label %Kotlin_mm_safePointWhileLoopBody.exit.i
 
 Kotlin_mm_safePointWhileLoopBody.exit.i:          ; preds = %80, %while_loop.i
-  %81 = load %struct.ObjHeader*, %struct.ObjHeader** %57, align 8
+  %81 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %57 unordered, align 8
   store %struct.ObjHeader* %81, %struct.ObjHeader** %12, align 8, !tbaa !3
-  %82 = load i32, i32* %44, align 4
+  %82 = load atomic i32, i32* %44 unordered, align 4
   %83 = add i32 %82, 1
   call fastcc void @"kfun:kotlin.text.StringBuilder#ensureCapacity(kotlin.Int){}"(%struct.ObjHeader* %0, i32 %83)
   store i32 %83, i32* %44, align 4
@@ -15006,20 +15086,20 @@
   %88 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %87, i64 0, i32 0
   %89 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %88 monotonic, align 8
   %90 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %89, i64 0, i32 9
-  %91 = load i32, i32* %90, align 4
+  %91 = load atomic i32, i32* %90 unordered, align 4
   %92 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %89, i64 0, i32 10
-  %93 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %92, align 8
+  %93 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %92 unordered, align 8
   %94 = and i32 %91, 25
   %95 = zext i32 %94 to i64
   %96 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %93, i64 %95, i32 2
-  %97 = load i8**, i8*** %96, align 8
+  %97 = load atomic i8**, i8*** %96 unordered, align 8
   %98 = getelementptr i8*, i8** %97, i64 1
   %99 = bitcast i8** %98 to i16 (%struct.ObjHeader*, i32)**
-  %100 = load i16 (%struct.ObjHeader*, i32)*, i16 (%struct.ObjHeader*, i32)** %99, align 8
+  %100 = load atomic i16 (%struct.ObjHeader*, i32)*, i16 (%struct.ObjHeader*, i32)** %99 unordered, align 8
   %101 = call zeroext i16 %100(%struct.ObjHeader* %spec.select, i32 %index.0.i)
   %102 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %81, i64 1
   %103 = bitcast %struct.ObjHeader* %102 to i32*
-  %104 = load i32, i32* %103, align 8, !tbaa !18
+  %104 = load atomic i32, i32* %103 unordered, align 8, !tbaa !18
   %105 = icmp ugt i32 %104, %82
   br i1 %105, label %Kotlin_CharArray_set.exit.i, label %106
 
@@ -15035,7 +15115,7 @@
   %111 = bitcast %struct.ObjHeader* %110 to i16*
   %112 = sext i32 %82 to i64
   %113 = getelementptr inbounds i16, i16* %111, i64 %112
-  store i16 %101, i16* %113, align 2, !tbaa !34
+  store i16 %101, i16* %113, align 2, !tbaa !27
   br label %loop_check.i
 
 loop_check.i:                                     ; preds = %Kotlin_CharArray_set.exit.i, %when_case3.i
@@ -15045,9 +15125,9 @@
 
 epilogue:                                         ; preds = %loop_check.i, %when_next4.i
   store %struct.ObjHeader* %0, %struct.ObjHeader** %4, align 8, !tbaa !3
-  %114 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %114 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %115 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %114, i64 0, i32 1, i32 5
-  %116 = load i64, i64* %19, align 8, !tbaa !9
+  %116 = load atomic i64, i64* %19 unordered, align 8, !tbaa !9
   %117 = bitcast %"class.kotlin::mm::ShadowStack"* %115 to i64*
   store i64 %116, i64* %117, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %11)
@@ -15063,11 +15143,11 @@
   %5 = bitcast [4 x %struct.ObjHeader*]* %4 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %5, i8 0, i32 32, i1 immarg false) #49
   %6 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %4, i64 0, i64 3
-  %7 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %7 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %8 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 5
   %9 = bitcast [4 x %struct.ObjHeader*]* %4 to %struct.FrameOverlay.6*
   %10 = bitcast %"class.kotlin::mm::ShadowStack"* %8 to i64*
-  %11 = load i64, i64* %10, align 8, !tbaa !7
+  %11 = load atomic i64, i64* %10 unordered, align 8, !tbaa !7
   %12 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %4, i64 0, i64 1
   %13 = bitcast %struct.ObjHeader** %12 to i64*
   store i64 %11, i64* %13, align 8, !tbaa !9
@@ -15090,18 +15170,18 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %21, %call_success
   %22 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %23 = bitcast %struct.ObjHeader* %22 to i32*
-  %24 = load i32, i32* %23, align 4
+  %24 = load atomic i32, i32* %23 unordered, align 4
   %25 = add i32 %24, 11
   call fastcc void @"kfun:kotlin.text.StringBuilder#ensureCapacity(kotlin.Int){}"(%struct.ObjHeader* %0, i32 %25)
-  %26 = load i32, i32* %23, align 4
+  %26 = load atomic i32, i32* %23 unordered, align 4
   %27 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %28 = bitcast %struct.ObjHeader* %27 to %struct.ObjHeader**
-  %29 = load %struct.ObjHeader*, %struct.ObjHeader** %28, align 8
+  %29 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %28 unordered, align 8
   store %struct.ObjHeader* %29, %struct.ObjHeader** %6, align 8, !tbaa !3
   %30 = getelementptr inbounds [12 x i8], [12 x i8]* %3, i64 0, i64 0
   call void @llvm.lifetime.start.p0i8(i64 12, i8* nonnull %30) #37
   call void (i8*, i64, i8*, ...) @_ZN5konan8snprintfEPcmPKcz(i8* nonnull %30, i64 12, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.157.845, i64 0, i64 0), i32 %1) #37
-  %31 = load i8, i8* %30, align 1, !tbaa !51
+  %31 = load atomic i8, i8* %30 unordered, align 1, !tbaa !50
   %32 = icmp eq i8 %31, 0
   br i1 %32, label %epilogue, label %33
 
@@ -15119,8 +15199,8 @@
   %42 = getelementptr inbounds i8, i8* %41, i64 1
   %43 = sext i8 %39 to i16
   %44 = getelementptr inbounds i16, i16* %40, i64 1
-  store i16 %43, i16* %40, align 2, !tbaa !34
-  %45 = load i8, i8* %42, align 1, !tbaa !51
+  store i16 %43, i16* %40, align 2, !tbaa !27
+  %45 = load atomic i8, i8* %42 unordered, align 1, !tbaa !50
   %46 = icmp eq i8 %45, 0
   br i1 %46, label %epilogue, label %38
 
@@ -15136,7 +15216,7 @@
   store i32 %52, i32* %23, align 4
   store %struct.ObjHeader* %0, %struct.ObjHeader** %2, align 8, !tbaa !3
   %53 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 5
-  %54 = load i64, i64* %13, align 8, !tbaa !9
+  %54 = load atomic i64, i64* %13 unordered, align 8, !tbaa !9
   %55 = bitcast %"class.kotlin::mm::ShadowStack"* %53 to i64*
   store i64 %54, i64* %55, align 8, !tbaa !7
   ret %struct.ObjHeader* %0
@@ -15148,11 +15228,11 @@
   %.sub = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 0
   %4 = bitcast [4 x %struct.ObjHeader*]* %3 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %4, i8 0, i32 32, i1 immarg false) #49
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
   %7 = bitcast [4 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %8 = bitcast %"class.kotlin::mm::ShadowStack"* %6 to i64*
-  %9 = load i64, i64* %8, align 8, !tbaa !7
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !7
   %10 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %11 = bitcast %struct.ObjHeader** %10 to i64*
   store i64 %9, i64* %11, align 8, !tbaa !9
@@ -15178,18 +15258,18 @@
   %21 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 3
   %22 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %spec.select, i64 1
   %23 = bitcast %struct.ObjHeader* %22 to i32*
-  %24 = load i32, i32* %23, align 8, !tbaa !18
+  %24 = load atomic i32, i32* %23 unordered, align 8, !tbaa !18
   %25 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %26 = bitcast %struct.ObjHeader* %25 to i32*
-  %27 = load i32, i32* %26, align 4
+  %27 = load atomic i32, i32* %26 unordered, align 4
   %28 = add i32 %27, %24
   call fastcc void @"kfun:kotlin.text.StringBuilder#ensureCapacity(kotlin.Int){}"(%struct.ObjHeader* %0, i32 %28)
-  %29 = load i32, i32* %26, align 4
+  %29 = load atomic i32, i32* %26 unordered, align 4
   %30 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %31 = bitcast %struct.ObjHeader* %30 to %struct.ObjHeader**
-  %32 = load %struct.ObjHeader*, %struct.ObjHeader** %31, align 8
+  %32 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %31 unordered, align 8
   store %struct.ObjHeader* %32, %struct.ObjHeader** %21, align 8, !tbaa !3
-  %33 = load i32, i32* %23, align 8, !tbaa !18
+  %33 = load atomic i32, i32* %23 unordered, align 8, !tbaa !18
   %34 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %32, i64 2
   %35 = bitcast %struct.ObjHeader* %34 to i16*
   %36 = sext i32 %29 to i64
@@ -15205,7 +15285,7 @@
   store i32 %43, i32* %26, align 4
   store %struct.ObjHeader* %0, %struct.ObjHeader** %2, align 8, !tbaa !3
   %44 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 5
-  %45 = load i64, i64* %11, align 8, !tbaa !9
+  %45 = load atomic i64, i64* %11 unordered, align 8, !tbaa !9
   %46 = bitcast %"class.kotlin::mm::ShadowStack"* %44 to i64*
   store i64 %45, i64* %46, align 8, !tbaa !7
   ret %struct.ObjHeader* %0
@@ -15219,11 +15299,11 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(56) %3, i8 0, i32 56, i1 immarg false) #49
   %4 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %5 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 6
-  %6 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %7 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
   %8 = bitcast [7 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %9 = bitcast %"class.kotlin::mm::ShadowStack"* %7 to i64*
-  %10 = load i64, i64* %9, align 8, !tbaa !7
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa !7
   %11 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %12 = bitcast %struct.ObjHeader** %11 to i64*
   store i64 %10, i64* %12, align 8, !tbaa !9
@@ -15246,27 +15326,27 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %20, %call_success
   %21 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %22 = bitcast %struct.ObjHeader* %21 to %struct.ObjHeader**
-  %23 = load %struct.ObjHeader*, %struct.ObjHeader** %22, align 8
+  %23 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %22 unordered, align 8
   store %struct.ObjHeader* %23, %struct.ObjHeader** %4, align 8, !tbaa !3
   %24 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %23, i64 1
   %25 = bitcast %struct.ObjHeader* %24 to i32*
-  %26 = load i32, i32* %25, align 8, !tbaa !18
+  %26 = load atomic i32, i32* %25 unordered, align 8, !tbaa !18
   %27 = icmp slt i32 %26, %1
   br i1 %27, label %call_success1, label %epilogue
 
 call_success1:                                    ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
   %28 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 5
   %29 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 4
-  %30 = load %struct.ObjHeader*, %struct.ObjHeader** %22, align 8
+  %30 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %22 unordered, align 8
   store %struct.ObjHeader* %30, %struct.ObjHeader** %29, align 8, !tbaa !3
   %31 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %30, i64 1
   %32 = bitcast %struct.ObjHeader* %31 to i32*
-  %33 = load i32, i32* %32, align 8, !tbaa !18
+  %33 = load atomic i32, i32* %32 unordered, align 8, !tbaa !18
   %34 = shl i32 %33, 1
   %35 = add i32 %34, 2
   %36 = icmp slt i32 %35, %1
   %spec.select = select i1 %36, i32 %1, i32 %35
-  %37 = load %struct.ObjHeader*, %struct.ObjHeader** %22, align 8
+  %37 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %22 unordered, align 8
   store %struct.ObjHeader* %37, %struct.ObjHeader** %28, align 8, !tbaa !3
   %38 = call fastcc %struct.ObjHeader* @"kfun:kotlin.collections#copyOfUninitializedElements__at__kotlin.CharArray(kotlin.Int;kotlin.Int){}kotlin.CharArray"(%struct.ObjHeader* %37, i32 %spec.select, %struct.ObjHeader** nonnull %5)
   store %struct.ObjHeader* %38, %struct.ObjHeader** %5, align 8, !tbaa !3
@@ -15275,7 +15355,7 @@
 
 epilogue:                                         ; preds = %call_success1, %Kotlin_mm_safePointFunctionPrologue.exit
   %39 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %40 = load i64, i64* %12, align 8, !tbaa !9
+  %40 = load atomic i64, i64* %12 unordered, align 8, !tbaa !9
   %41 = bitcast %"class.kotlin::mm::ShadowStack"* %39 to i64*
   store i64 %40, i64* %41, align 8, !tbaa !7
   ret void
@@ -15289,11 +15369,11 @@
   %4 = bitcast [4 x %struct.ObjHeader*]* %3 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %4, i8 0, i32 32, i1 immarg false) #49
   %5 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 3
-  %6 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %7 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
   %8 = bitcast [4 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %9 = bitcast %"class.kotlin::mm::ShadowStack"* %7 to i64*
-  %10 = load i64, i64* %9, align 8, !tbaa !7
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa !7
   %11 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %12 = bitcast %struct.ObjHeader** %11 to i64*
   store i64 %10, i64* %12, align 8, !tbaa !9
@@ -15316,11 +15396,11 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %20, %entry
   %21 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %22 = bitcast %struct.ObjHeader* %21 to %struct.ObjHeader**
-  %23 = load %struct.ObjHeader*, %struct.ObjHeader** %22, align 8
+  %23 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %22 unordered, align 8
   store %struct.ObjHeader* %23, %struct.ObjHeader** %5, align 8, !tbaa !3
   %24 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %25 = bitcast %struct.ObjHeader* %24 to i32*
-  %26 = load i32, i32* %25, align 4
+  %26 = load atomic i32, i32* %25 unordered, align 4
   %27 = icmp eq i32 %26, 0
   br i1 %27, label %28, label %44
 
@@ -15333,7 +15413,7 @@
   %31 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
   %32 = bitcast [3 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %33 = bitcast %"class.kotlin::mm::ShadowStack"* %31 to i64*
-  %34 = load i64, i64* %33, align 8, !tbaa !7
+  %34 = load atomic i64, i64* %33 unordered, align 8, !tbaa !7
   %35 = getelementptr inbounds [3 x %struct.ObjHeader*], [3 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %36 = bitcast %struct.ObjHeader** %35 to i64*
   store i64 %34, i64* %36, align 8, !tbaa !9
@@ -15346,7 +15426,7 @@
   store i32 3, i32* %40, align 4, !tbaa !13
   store %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [0 x i8] }* @102 to %struct.ObjHeader*), %struct.ObjHeader** %1, align 8, !tbaa !3
   %41 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %42 = load i64, i64* %36, align 8, !tbaa !9
+  %42 = load atomic i64, i64* %36 unordered, align 8, !tbaa !9
   %43 = bitcast %"class.kotlin::mm::ShadowStack"* %41 to i64*
   store i64 %42, i64* %43, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %29)
@@ -15363,7 +15443,7 @@
 AllocArrayInstance.exit.i:                        ; preds = %44
   %47 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 6
   %48 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %47 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %49 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %48, align 8, !tbaa !3
+  %49 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %48 unordered, align 8, !tbaa !3
   %50 = zext i32 %26 to i64
   %51 = shl nuw nsw i64 %50, 1
   %52 = add nuw nsw i64 %51, 31
@@ -15396,7 +15476,7 @@
   %70 = phi %struct.ObjHeader* [ bitcast ({ %struct.ArrayHeader, [0 x i8] }* @102 to %struct.ObjHeader*), %28 ], [ %62, %AllocArrayInstance.exit.i ]
   store %struct.ObjHeader* %70, %struct.ObjHeader** %1, align 8, !tbaa !3
   %71 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %72 = load i64, i64* %12, align 8, !tbaa !9
+  %72 = load atomic i64, i64* %12 unordered, align 8, !tbaa !9
   %73 = bitcast %"class.kotlin::mm::ShadowStack"* %71 to i64*
   store i64 %72, i64* %73, align 8, !tbaa !7
   ret %struct.ObjHeader* %70
@@ -15410,11 +15490,11 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %3, i8 0, i32 40, i1 immarg false) #49
   %4 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %5 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 4
-  %6 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %7 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
   %8 = bitcast [5 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %9 = bitcast %"class.kotlin::mm::ShadowStack"* %7 to i64*
-  %10 = load i64, i64* %9, align 8, !tbaa !7
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa !7
   %11 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %12 = bitcast %struct.ObjHeader** %11 to i64*
   store i64 %10, i64* %12, align 8, !tbaa !9
@@ -15447,13 +15527,13 @@
   %27 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %26, i64 0, i32 0
   %28 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %27 monotonic, align 8
   %29 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %28, i64 0, i32 9
-  %30 = load i32, i32* %29, align 4
+  %30 = load atomic i32, i32* %29 unordered, align 4
   %31 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %28, i64 0, i32 10
-  %32 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %31, align 8
+  %32 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %31 unordered, align 8
   %33 = and i32 %30, 18
   %34 = zext i32 %33 to i64
   %35 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %32, i64 %34, i32 0
-  %36 = load i32, i32* %35, align 4
+  %36 = load atomic i32, i32* %35 unordered, align 4
   %37 = icmp eq i32 %36, 18
   br i1 %37, label %when_exit, label %call_success3
 
@@ -15465,16 +15545,16 @@
   %42 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %41, i64 0, i32 0
   %43 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %42 monotonic, align 8
   %44 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %43, i64 0, i32 9
-  %45 = load i32, i32* %44, align 4
+  %45 = load atomic i32, i32* %44 unordered, align 4
   %46 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %43, i64 0, i32 10
-  %47 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %46, align 8
+  %47 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %46 unordered, align 8
   %48 = and i32 %45, 18
   %49 = zext i32 %48 to i64
   %50 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %47, i64 %49, i32 2
-  %51 = load i8**, i8*** %50, align 8
+  %51 = load atomic i8**, i8*** %50 unordered, align 8
   %52 = getelementptr i8*, i8** %51, i64 3
   %53 = bitcast i8** %52 to i1 (%struct.ObjHeader*)**
-  %54 = load i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %53, align 8
+  %54 = load atomic i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %53 unordered, align 8
   %55 = call zeroext i1 %54(%struct.ObjHeader* nonnull %1)
   br i1 %55, label %epilogue, label %call_success3
 
@@ -15487,15 +15567,15 @@
   %61 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %60, i64 0, i32 0
   %62 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %61 monotonic, align 8
   %63 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %62, i64 0, i32 9
-  %64 = load i32, i32* %63, align 4
+  %64 = load atomic i32, i32* %63 unordered, align 4
   %65 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %62, i64 0, i32 10
-  %66 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %65, align 8
+  %66 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %65 unordered, align 8
   %67 = and i32 %64, 49
   %68 = zext i32 %67 to i64
   %69 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %66, i64 %68, i32 2
   %70 = bitcast i8*** %69 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)***
-  %71 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %70, align 8
-  %72 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %71, align 8
+  %71 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*** %70 unordered, align 8
+  %72 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %71 unordered, align 8
   %73 = call %struct.ObjHeader* %72(%struct.ObjHeader* %1, %struct.ObjHeader** nonnull %4)
   %74 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %73, i64 0, i32 0
   %75 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 0, i32 0
@@ -15519,16 +15599,16 @@
   %84 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %83, i64 0, i32 0
   %85 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %84 monotonic, align 8
   %86 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %85, i64 0, i32 9
-  %87 = load i32, i32* %86, align 4
+  %87 = load atomic i32, i32* %86 unordered, align 4
   %88 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %85, i64 0, i32 10
-  %89 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %88, align 8
+  %89 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %88 unordered, align 8
   %90 = and i32 %87, 160
   %91 = zext i32 %90 to i64
   %92 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %89, i64 %91, i32 2
-  %93 = load i8**, i8*** %92, align 8
+  %93 = load atomic i8**, i8*** %92 unordered, align 8
   %94 = getelementptr i8*, i8** %93, i64 1
   %95 = bitcast i8** %94 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %96 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %95, align 8
+  %96 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %95 unordered, align 8
   %97 = call %struct.ObjHeader* %96(%struct.ObjHeader* %73, %struct.ObjHeader** nonnull %5)
   %98 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %75 monotonic, align 8
   %99 = ptrtoint %struct.TypeInfo* %98 to i64
@@ -15538,7 +15618,7 @@
   %103 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %102 monotonic, align 8
   %104 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %103, i64 1, i32 5
   %105 = bitcast i32** %104 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
-  %106 = load i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %105, align 8
+  %106 = load atomic i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %105 unordered, align 8
   %107 = call zeroext i1 %106(%struct.ObjHeader* %0, %struct.ObjHeader* %97)
   br i1 %107, label %call_success4, label %epilogue
 
@@ -15550,22 +15630,22 @@
   %112 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %111, i64 0, i32 0
   %113 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %112 monotonic, align 8
   %114 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %113, i64 0, i32 9
-  %115 = load i32, i32* %114, align 4
+  %115 = load atomic i32, i32* %114 unordered, align 4
   %116 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %113, i64 0, i32 10
-  %117 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %116, align 8
+  %117 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %116 unordered, align 8
   %118 = and i32 %115, 160
   %119 = zext i32 %118 to i64
   %120 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %117, i64 %119, i32 2
   %121 = bitcast i8*** %120 to i1 (%struct.ObjHeader*)***
-  %122 = load i1 (%struct.ObjHeader*)**, i1 (%struct.ObjHeader*)*** %121, align 8
-  %123 = load i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %122, align 8
+  %122 = load atomic i1 (%struct.ObjHeader*)**, i1 (%struct.ObjHeader*)*** %121 unordered, align 8
+  %123 = load atomic i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %122 unordered, align 8
   %124 = call zeroext i1 %123(%struct.ObjHeader* %73)
   br i1 %124, label %while_loop, label %epilogue
 
 epilogue:                                         ; preds = %call_success4, %returnable_block_exit8, %when_exit
   %125 = phi i1 [ true, %when_exit ], [ true, %call_success4 ], [ false, %returnable_block_exit8 ]
   %126 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %127 = load i64, i64* %12, align 8, !tbaa !9
+  %127 = load atomic i64, i64* %12 unordered, align 8, !tbaa !9
   %128 = bitcast %"class.kotlin::mm::ShadowStack"* %126 to i64*
   store i64 %127, i64* %128, align 8, !tbaa !7
   ret i1 %125
@@ -15592,7 +15672,7 @@
   %11 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %10 monotonic, align 8
   %12 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %11, i64 1, i32 4
   %13 = bitcast %struct.TypeInfo** %12 to i32 (%struct.ObjHeader*)**
-  %14 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %13, align 8
+  %14 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %13 unordered, align 8
   %15 = tail call i32 %14(%struct.ObjHeader* %0)
   %16 = icmp eq i32 %15, 0
   ret i1 %16
@@ -15612,11 +15692,11 @@
   %objHeader = getelementptr inbounds %"kclassbody:kotlin.collections.AbstractCollection.$toString$lambda$0$FUNCTION_REFERENCE$0#internal", %"kclassbody:kotlin.collections.AbstractCollection.$toString$lambda$0$FUNCTION_REFERENCE$0#internal"* %5, i64 0, i32 0
   %typeInfoOrMeta_ = getelementptr inbounds %"kclassbody:kotlin.collections.AbstractCollection.$toString$lambda$0$FUNCTION_REFERENCE$0#internal", %"kclassbody:kotlin.collections.AbstractCollection.$toString$lambda$0$FUNCTION_REFERENCE$0#internal"* %5, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.collections.AbstractCollection.$toString$lambda$0$FUNCTION_REFERENCE$0#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_, align 8
-  %8 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %8 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %9 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
   %10 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %11 = bitcast %"class.kotlin::mm::ShadowStack"* %9 to i64*
-  %12 = load i64, i64* %11, align 8, !tbaa !7
+  %12 = load atomic i64, i64* %11 unordered, align 8, !tbaa !7
   %13 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %14 = bitcast %struct.ObjHeader** %13 to i64*
   store i64 %12, i64* %14, align 8, !tbaa !9
@@ -15644,7 +15724,7 @@
   %25 = call fastcc %struct.ObjHeader* @"kfun:kotlin.collections#joinToString__at__kotlin.collections.Iterable<0:0>(kotlin.CharSequence;kotlin.CharSequence;kotlin.CharSequence;kotlin.Int;kotlin.CharSequence;kotlin.Function1<0:0,kotlin.CharSequence>?){0\C2\A7<kotlin.Any?>}kotlin.String"(%struct.ObjHeader* %0, %struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader** %1)
   store %struct.ObjHeader* %25, %struct.ObjHeader** %1, align 8, !tbaa !3
   %26 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
-  %27 = load i64, i64* %14, align 8, !tbaa !9
+  %27 = load atomic i64, i64* %14 unordered, align 8, !tbaa !9
   %28 = bitcast %"class.kotlin::mm::ShadowStack"* %26 to i64*
   store i64 %27, i64* %28, align 8, !tbaa !7
   ret %struct.ObjHeader* %25
@@ -15664,7 +15744,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %6, %entry
   %7 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %8 = bitcast %struct.ObjHeader* %7 to %struct.ObjHeader**
-  %9 = load %struct.ObjHeader*, %struct.ObjHeader** %8, align 8
+  %9 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %8 unordered, align 8
   %10 = icmp eq %struct.ObjHeader* %9, %1
   br i1 %10, label %epilogue, label %when_next.i
 
@@ -15682,7 +15762,7 @@
   %18 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %17 monotonic, align 8
   %19 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %18, i64 1, i32 2
   %20 = bitcast i32* %19 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %21 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %20, align 8
+  %21 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %20 unordered, align 8
   %22 = tail call %struct.ObjHeader* %21(%struct.ObjHeader* nonnull %1, %struct.ObjHeader** %2)
   br label %epilogue
 
@@ -15705,10 +15785,10 @@
   br label %Kotlin_mm_safePointFunctionPrologue.exit
 
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
-  %6 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %7 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 6
   %8 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %7 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %9 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %8, align 8, !tbaa !3
+  %9 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %8 unordered, align 8, !tbaa !3
   %10 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %9, i64 0, i32 2, i32 1
   %11 = tail call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %10, i64 32) #37
   %12 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %11, i64 1
@@ -15756,13 +15836,13 @@
   %14 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %13, i64 0, i32 0
   %15 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %14 monotonic, align 8
   %16 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %15, i64 0, i32 9
-  %17 = load i32, i32* %16, align 4
+  %17 = load atomic i32, i32* %16 unordered, align 4
   %18 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %15, i64 0, i32 10
-  %19 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %18, align 8
+  %19 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %18 unordered, align 8
   %20 = and i32 %17, 43
   %21 = zext i32 %20 to i64
   %22 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %19, i64 %21, i32 0
-  %23 = load i32, i32* %22, align 4
+  %23 = load atomic i32, i32* %22 unordered, align 4
   %.not = icmp eq i32 %23, 43
   br i1 %.not, label %when_exit2, label %epilogue
 
@@ -15773,11 +15853,11 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(56) %24, i8 0, i32 56, i1 immarg false) #49
   %25 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 5
   %26 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 6
-  %27 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %27 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %28 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %27, i64 0, i32 1, i32 5
   %29 = bitcast [7 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %30 = bitcast %"class.kotlin::mm::ShadowStack"* %28 to i64*
-  %31 = load i64, i64* %30, align 8, !tbaa !7
+  %31 = load atomic i64, i64* %30 unordered, align 8, !tbaa !7
   %32 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %33 = bitcast %struct.ObjHeader** %32 to i64*
   store i64 %31, i64* %33, align 8, !tbaa !9
@@ -15796,15 +15876,15 @@
   %43 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %42, i64 0, i32 0
   %44 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %43 monotonic, align 8
   %45 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %44, i64 0, i32 9
-  %46 = load i32, i32* %45, align 4
+  %46 = load atomic i32, i32* %45 unordered, align 4
   %47 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %44, i64 0, i32 10
-  %48 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %47, align 8
+  %48 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %47 unordered, align 8
   %49 = and i32 %46, 18
   %50 = zext i32 %49 to i64
   %51 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %48, i64 %50, i32 2
   %52 = bitcast i8*** %51 to i32 (%struct.ObjHeader*)***
-  %53 = load i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %52, align 8
-  %54 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %53, align 8
+  %53 = load atomic i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %52 unordered, align 8
+  %54 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %53 unordered, align 8
   %55 = call i32 %54(%struct.ObjHeader* %0)
   %56 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %9 monotonic, align 8
   %57 = ptrtoint %struct.TypeInfo* %56 to i64
@@ -15813,15 +15893,15 @@
   %60 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %59, i64 0, i32 0
   %61 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %60 monotonic, align 8
   %62 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %61, i64 0, i32 9
-  %63 = load i32, i32* %62, align 4
+  %63 = load atomic i32, i32* %62 unordered, align 4
   %64 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %61, i64 0, i32 10
-  %65 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %64, align 8
+  %65 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %64 unordered, align 8
   %66 = and i32 %63, 18
   %67 = zext i32 %66 to i64
   %68 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %65, i64 %67, i32 2
   %69 = bitcast i8*** %68 to i32 (%struct.ObjHeader*)***
-  %70 = load i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %69, align 8
-  %71 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %70, align 8
+  %70 = load atomic i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %69 unordered, align 8
+  %71 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %70 unordered, align 8
   %72 = call i32 %71(%struct.ObjHeader* nonnull %1)
   %.not.i = icmp eq i32 %55, %72
   br i1 %.not.i, label %when_exit.i, label %call_success
@@ -15836,16 +15916,16 @@
   %79 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %78, i64 0, i32 0
   %80 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %79 monotonic, align 8
   %81 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %80, i64 0, i32 9
-  %82 = load i32, i32* %81, align 4
+  %82 = load atomic i32, i32* %81 unordered, align 4
   %83 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %80, i64 0, i32 10
-  %84 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %83, align 8
+  %84 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %83 unordered, align 8
   %85 = and i32 %82, 18
   %86 = zext i32 %85 to i64
   %87 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %84, i64 %86, i32 2
-  %88 = load i8**, i8*** %87, align 8
+  %88 = load atomic i8**, i8*** %87 unordered, align 8
   %89 = getelementptr i8*, i8** %88, i64 4
   %90 = bitcast i8** %89 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %91 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %90, align 8
+  %91 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %90 unordered, align 8
   %92 = call %struct.ObjHeader* %91(%struct.ObjHeader* nonnull %1, %struct.ObjHeader** nonnull %74)
   %93 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %38 monotonic, align 8
   %94 = ptrtoint %struct.TypeInfo* %93 to i64
@@ -15854,16 +15934,16 @@
   %97 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %96, i64 0, i32 0
   %98 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %97 monotonic, align 8
   %99 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %98, i64 0, i32 9
-  %100 = load i32, i32* %99, align 4
+  %100 = load atomic i32, i32* %99 unordered, align 4
   %101 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %98, i64 0, i32 10
-  %102 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %101, align 8
+  %102 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %101 unordered, align 8
   %103 = and i32 %100, 18
   %104 = zext i32 %103 to i64
   %105 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %102, i64 %104, i32 2
-  %106 = load i8**, i8*** %105, align 8
+  %106 = load atomic i8**, i8*** %105 unordered, align 8
   %107 = getelementptr i8*, i8** %106, i64 4
   %108 = bitcast i8** %107 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %109 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %108, align 8
+  %109 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %108 unordered, align 8
   %110 = call %struct.ObjHeader* %109(%struct.ObjHeader* %0, %struct.ObjHeader** nonnull %73)
   %111 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %110, i64 0, i32 0
   %112 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %92, i64 0, i32 0
@@ -15887,16 +15967,16 @@
   %121 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %120, i64 0, i32 0
   %122 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %121 monotonic, align 8
   %123 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %122, i64 0, i32 9
-  %124 = load i32, i32* %123, align 4
+  %124 = load atomic i32, i32* %123 unordered, align 4
   %125 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %122, i64 0, i32 10
-  %126 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %125, align 8
+  %126 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %125 unordered, align 8
   %127 = and i32 %124, 160
   %128 = zext i32 %127 to i64
   %129 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %126, i64 %128, i32 2
-  %130 = load i8**, i8*** %129, align 8
+  %130 = load atomic i8**, i8*** %129 unordered, align 8
   %131 = getelementptr i8*, i8** %130, i64 1
   %132 = bitcast i8** %131 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %133 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %132, align 8
+  %133 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %132 unordered, align 8
   %134 = call %struct.ObjHeader* %133(%struct.ObjHeader* %110, %struct.ObjHeader** nonnull %25)
   %135 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %112 monotonic, align 8
   %136 = ptrtoint %struct.TypeInfo* %135 to i64
@@ -15905,16 +15985,16 @@
   %139 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %138, i64 0, i32 0
   %140 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %139 monotonic, align 8
   %141 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %140, i64 0, i32 9
-  %142 = load i32, i32* %141, align 4
+  %142 = load atomic i32, i32* %141 unordered, align 4
   %143 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %140, i64 0, i32 10
-  %144 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %143, align 8
+  %144 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %143 unordered, align 8
   %145 = and i32 %142, 160
   %146 = zext i32 %145 to i64
   %147 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %144, i64 %146, i32 2
-  %148 = load i8**, i8*** %147, align 8
+  %148 = load atomic i8**, i8*** %147 unordered, align 8
   %149 = getelementptr i8*, i8** %148, i64 1
   %150 = bitcast i8** %149 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %151 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %150, align 8
+  %151 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %150 unordered, align 8
   %152 = call %struct.ObjHeader* %151(%struct.ObjHeader* %92, %struct.ObjHeader** nonnull %26)
   %153 = icmp eq %struct.ObjHeader* %134, null
   br i1 %153, label %when_case8.i, label %when_exit9.i
@@ -15933,7 +16013,7 @@
   %161 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %160 monotonic, align 8
   %162 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %161, i64 1
   %163 = bitcast %struct.TypeInfo* %162 to i1 (%struct.ObjHeader*, %struct.ObjHeader*)**
-  %164 = load i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %163, align 8
+  %164 = load atomic i1 (%struct.ObjHeader*, %struct.ObjHeader*)*, i1 (%struct.ObjHeader*, %struct.ObjHeader*)** %163 unordered, align 8
   %165 = call zeroext i1 %164(%struct.ObjHeader* nonnull %134, %struct.ObjHeader* %152)
   br i1 %165, label %when_exit11.i, label %call_success
 
@@ -15948,23 +16028,23 @@
   %170 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %169, i64 0, i32 0
   %171 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %170 monotonic, align 8
   %172 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %171, i64 0, i32 9
-  %173 = load i32, i32* %172, align 4
+  %173 = load atomic i32, i32* %172 unordered, align 4
   %174 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %171, i64 0, i32 10
-  %175 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %174, align 8
+  %175 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %174 unordered, align 8
   %176 = and i32 %173, 160
   %177 = zext i32 %176 to i64
   %178 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %175, i64 %177, i32 2
   %179 = bitcast i8*** %178 to i1 (%struct.ObjHeader*)***
-  %180 = load i1 (%struct.ObjHeader*)**, i1 (%struct.ObjHeader*)*** %179, align 8
-  %181 = load i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %180, align 8
+  %180 = load atomic i1 (%struct.ObjHeader*)**, i1 (%struct.ObjHeader*)*** %179 unordered, align 8
+  %181 = load atomic i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %180 unordered, align 8
   %182 = call zeroext i1 %181(%struct.ObjHeader* %110)
   br i1 %182, label %while_loop.i, label %call_success
 
 call_success:                                     ; preds = %loop_check.i, %when_exit9.i, %when_case8.i, %when_exit2
   %183 = phi i1 [ false, %when_exit2 ], [ true, %loop_check.i ], [ false, %when_exit9.i ], [ false, %when_case8.i ]
-  %184 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %184 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %185 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %184, i64 0, i32 1, i32 5
-  %186 = load i64, i64* %33, align 8, !tbaa !9
+  %186 = load atomic i64, i64* %33 unordered, align 8, !tbaa !9
   %187 = bitcast %"class.kotlin::mm::ShadowStack"* %185 to i64*
   store i64 %186, i64* %187, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 56, i8* nonnull %24)
@@ -15994,11 +16074,11 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %6, i8 0, i32 40, i1 immarg false) #49
   %7 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %1, i64 0, i64 3
   %8 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %1, i64 0, i64 4
-  %9 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %9 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %10 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %9, i64 0, i32 1, i32 5
   %11 = bitcast [5 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
   %12 = bitcast %"class.kotlin::mm::ShadowStack"* %10 to i64*
-  %13 = load i64, i64* %12, align 8, !tbaa !7
+  %13 = load atomic i64, i64* %12 unordered, align 8, !tbaa !7
   %14 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %1, i64 0, i64 1
   %15 = bitcast %struct.ObjHeader** %14 to i64*
   store i64 %13, i64* %15, align 8, !tbaa !9
@@ -16017,16 +16097,16 @@
   %25 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %24, i64 0, i32 0
   %26 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %25 monotonic, align 8
   %27 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %26, i64 0, i32 9
-  %28 = load i32, i32* %27, align 4
+  %28 = load atomic i32, i32* %27 unordered, align 4
   %29 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %26, i64 0, i32 10
-  %30 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %29, align 8
+  %30 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %29 unordered, align 8
   %31 = and i32 %28, 18
   %32 = zext i32 %31 to i64
   %33 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %30, i64 %32, i32 2
-  %34 = load i8**, i8*** %33, align 8
+  %34 = load atomic i8**, i8*** %33 unordered, align 8
   %35 = getelementptr i8*, i8** %34, i64 4
   %36 = bitcast i8** %35 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %37 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %36, align 8
+  %37 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %36 unordered, align 8
   %38 = call %struct.ObjHeader* %37(%struct.ObjHeader* %0, %struct.ObjHeader** nonnull %7)
   %39 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %38, i64 0, i32 0
   br label %loop_check.i
@@ -16049,16 +16129,16 @@
   %48 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %47, i64 0, i32 0
   %49 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %48 monotonic, align 8
   %50 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %49, i64 0, i32 9
-  %51 = load i32, i32* %50, align 4
+  %51 = load atomic i32, i32* %50 unordered, align 4
   %52 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %49, i64 0, i32 10
-  %53 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %52, align 8
+  %53 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %52 unordered, align 8
   %54 = and i32 %51, 160
   %55 = zext i32 %54 to i64
   %56 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %53, i64 %55, i32 2
-  %57 = load i8**, i8*** %56, align 8
+  %57 = load atomic i8**, i8*** %56 unordered, align 8
   %58 = getelementptr i8*, i8** %57, i64 1
   %59 = bitcast i8** %58 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)**
-  %60 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %59, align 8
+  %60 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %59 unordered, align 8
   %61 = call %struct.ObjHeader* %60(%struct.ObjHeader* %38, %struct.ObjHeader** nonnull %8)
   %62 = mul i32 %hashCode.0.i, 31
   %63 = icmp eq %struct.ObjHeader* %61, null
@@ -16074,7 +16154,7 @@
   %70 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %69 monotonic, align 8
   %71 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %70, i64 1, i32 1
   %72 = bitcast %struct.ExtendedTypeInfo** %71 to i32 (%struct.ObjHeader*)**
-  %73 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %72, align 8
+  %73 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %72 unordered, align 8
   %74 = call i32 %73(%struct.ObjHeader* nonnull %61)
   br label %when_exit.i
 
@@ -16092,22 +16172,22 @@
   %81 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %80, i64 0, i32 0
   %82 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %81 monotonic, align 8
   %83 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %82, i64 0, i32 9
-  %84 = load i32, i32* %83, align 4
+  %84 = load atomic i32, i32* %83 unordered, align 4
   %85 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %82, i64 0, i32 10
-  %86 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %85, align 8
+  %86 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %85 unordered, align 8
   %87 = and i32 %84, 160
   %88 = zext i32 %87 to i64
   %89 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %86, i64 %88, i32 2
   %90 = bitcast i8*** %89 to i1 (%struct.ObjHeader*)***
-  %91 = load i1 (%struct.ObjHeader*)**, i1 (%struct.ObjHeader*)*** %90, align 8
-  %92 = load i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %91, align 8
+  %91 = load atomic i1 (%struct.ObjHeader*)**, i1 (%struct.ObjHeader*)*** %90 unordered, align 8
+  %92 = load atomic i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %91 unordered, align 8
   %93 = call zeroext i1 %92(%struct.ObjHeader* %38)
   br i1 %93, label %while_loop.i, label %epilogue
 
 epilogue:                                         ; preds = %loop_check.i
-  %94 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %94 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %95 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %94, i64 0, i32 1, i32 5
-  %96 = load i64, i64* %15, align 8, !tbaa !9
+  %96 = load atomic i64, i64* %15 unordered, align 8, !tbaa !9
   %97 = bitcast %"class.kotlin::mm::ShadowStack"* %95 to i64*
   store i64 %96, i64* %97, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %6)
@@ -16128,10 +16208,10 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %4, %epilogue
   %5 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %6 = bitcast %struct.ObjHeader* %5 to i32*
-  %7 = load i32, i32* %6, align 4
+  %7 = load atomic i32, i32* %6 unordered, align 4
   %8 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %9 = bitcast %struct.ObjHeader* %8 to %struct.ObjHeader**
-  %10 = load %struct.ObjHeader*, %struct.ObjHeader** %9, align 8
+  %10 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %9 unordered, align 8
   %11 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %10, i64 0, i32 0
   %12 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %11 monotonic, align 8
   %13 = ptrtoint %struct.TypeInfo* %12 to i64
@@ -16141,7 +16221,7 @@
   %17 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %16 monotonic, align 8
   %18 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %17, i64 1, i32 4
   %19 = bitcast %struct.TypeInfo** %18 to i32 (%struct.ObjHeader*)**
-  %20 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %19, align 8
+  %20 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %19 unordered, align 8
   %21 = tail call i32 %20(%struct.ObjHeader* %10)
   %22 = icmp slt i32 %7, %21
   ret i1 %22
@@ -16153,11 +16233,11 @@
   %.sub = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 0
   %3 = bitcast [4 x %struct.ObjHeader*]* %2 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %3, i8 0, i32 32, i1 immarg false) #49
-  %4 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %4 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %5 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
   %6 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %7 = bitcast %"class.kotlin::mm::ShadowStack"* %5 to i64*
-  %8 = load i64, i64* %7, align 8, !tbaa !7
+  %8 = load atomic i64, i64* %7 unordered, align 8, !tbaa !7
   %9 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %10 = bitcast %struct.ObjHeader** %9 to i64*
   store i64 %8, i64* %10, align 8, !tbaa !9
@@ -16187,7 +16267,7 @@
   %25 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %24 monotonic, align 8
   %26 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %25, i64 1, i32 4
   %27 = bitcast %struct.TypeInfo** %26 to i1 (%struct.ObjHeader*)**
-  %28 = load i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %27, align 8
+  %28 = load atomic i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %27 unordered, align 8
   %29 = call zeroext i1 %28(%struct.ObjHeader* %0)
   br i1 %29, label %epilogue, label %call_success1
 
@@ -16195,7 +16275,7 @@
   %30 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %31 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 6
   %32 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %31 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %33 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %32, align 8, !tbaa !3
+  %33 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %32 unordered, align 8, !tbaa !3
   %34 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %33, i64 0, i32 2, i32 1
   %35 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %34, i64 56) #37
   %36 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %35, i64 1
@@ -16214,10 +16294,10 @@
 epilogue:                                         ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
   %42 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %43 = bitcast %struct.ObjHeader* %42 to %struct.ObjHeader**
-  %44 = load %struct.ObjHeader*, %struct.ObjHeader** %43, align 8
+  %44 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %43 unordered, align 8
   %45 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %46 = bitcast %struct.ObjHeader* %45 to i32*
-  %47 = load i32, i32* %46, align 4
+  %47 = load atomic i32, i32* %46 unordered, align 4
   %48 = add i32 %47, 1
   store i32 %48, i32* %46, align 4
   %49 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %44, i64 0, i32 0
@@ -16229,11 +16309,11 @@
   %55 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %54 monotonic, align 8
   %56 = getelementptr %struct.TypeInfo, %struct.TypeInfo* %55, i64 1, i32 12
   %57 = bitcast %struct.ObjHeader** %56 to %struct.ObjHeader* (%struct.ObjHeader*, i32, %struct.ObjHeader**)**
-  %58 = load %struct.ObjHeader* (%struct.ObjHeader*, i32, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, i32, %struct.ObjHeader**)** %57, align 8
+  %58 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, i32, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, i32, %struct.ObjHeader**)** %57 unordered, align 8
   %59 = call %struct.ObjHeader* %58(%struct.ObjHeader* %44, i32 %47, %struct.ObjHeader** %1)
   store %struct.ObjHeader* %59, %struct.ObjHeader** %1, align 8, !tbaa !3
   %60 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %61 = load i64, i64* %10, align 8, !tbaa !9
+  %61 = load atomic i64, i64* %10 unordered, align 8, !tbaa !9
   %62 = bitcast %"class.kotlin::mm::ShadowStack"* %60 to i64*
   store i64 %61, i64* %62, align 8, !tbaa !7
   ret %struct.ObjHeader* %59
@@ -16252,11 +16332,11 @@
   %objHeader = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %4, i64 0, i32 0
   %typeInfoOrMeta_ = getelementptr inbounds %"kclassbody:kotlin.text.StringBuilder#internal", %"kclassbody:kotlin.text.StringBuilder#internal"* %4, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.text.StringBuilder#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_, align 8
-  %7 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %7 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %8 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 5
   %9 = bitcast [10 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %10 = bitcast %"class.kotlin::mm::ShadowStack"* %8 to i64*
-  %11 = load i64, i64* %10, align 8, !tbaa !7
+  %11 = load atomic i64, i64* %10 unordered, align 8, !tbaa !7
   %12 = getelementptr inbounds [10 x %struct.ObjHeader*], [10 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %13 = bitcast %struct.ObjHeader** %12 to i64*
   store i64 %11, i64* %13, align 8, !tbaa !9
@@ -16299,7 +16379,7 @@
   %34 = call %struct.ObjHeader* @"kfun:kotlin.text.StringBuilder#toString(){}kotlin.String"(%struct.ObjHeader* nonnull %objHeader, %struct.ObjHeader** nonnull %24)
   %35 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 6
   %36 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %35 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %37 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %36, align 8, !tbaa !3
+  %37 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %36 unordered, align 8, !tbaa !3
   %38 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %37, i64 0, i32 2, i32 1
   %39 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %38, i64 56) #37
   %40 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %39, i64 1
@@ -16317,7 +16397,7 @@
 
 epilogue:                                         ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
   %46 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 5
-  %47 = load i64, i64* %13, align 8, !tbaa !9
+  %47 = load atomic i64, i64* %13 unordered, align 8, !tbaa !9
   %48 = bitcast %"class.kotlin::mm::ShadowStack"* %46 to i64*
   store i64 %47, i64* %48, align 8, !tbaa !7
   ret void
@@ -16347,11 +16427,11 @@
   %1 = bitcast [4 x %struct.ObjHeader*]* %0 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %1, i8 0, i32 32, i1 immarg false) #49
   %2 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 3
-  %3 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %3 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %4 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 5
   %5 = bitcast [4 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
   %6 = bitcast %"class.kotlin::mm::ShadowStack"* %4 to i64*
-  %7 = load i64, i64* %6, align 8, !tbaa !7
+  %7 = load atomic i64, i64* %6 unordered, align 8, !tbaa !7
   %8 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 1
   %9 = bitcast %struct.ObjHeader** %8 to i64*
   store i64 %7, i64* %9, align 8, !tbaa !9
@@ -16374,7 +16454,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %17, %call_success
   %18 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 6
   %19 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %18 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %20 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %19, align 8, !tbaa !3
+  %20 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %19 unordered, align 8, !tbaa !3
   %21 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %20, i64 0, i32 2, i32 1
   %22 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %21, i64 56) #37
   %23 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %22, i64 1
@@ -16432,13 +16512,13 @@
   %12 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %11, i64 0, i32 0
   %13 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %12 monotonic, align 8
   %14 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %13, i64 0, i32 9
-  %15 = load i32, i32* %14, align 4
+  %15 = load atomic i32, i32* %14 unordered, align 4
   %16 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %13, i64 0, i32 10
-  %17 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %16, align 8
+  %17 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %16 unordered, align 8
   %18 = and i32 %15, 30
   %19 = zext i32 %18 to i64
   %20 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %17, i64 %19, i32 0
-  %21 = load i32, i32* %20, align 4
+  %21 = load atomic i32, i32* %20 unordered, align 4
   %22 = icmp eq i32 %21, 30
   br i1 %22, label %call_success, label %epilogue
 
@@ -16450,16 +16530,16 @@
   %27 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %26, i64 0, i32 0
   %28 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %27 monotonic, align 8
   %29 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %28, i64 0, i32 9
-  %30 = load i32, i32* %29, align 4
+  %30 = load atomic i32, i32* %29 unordered, align 4
   %31 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %28, i64 0, i32 10
-  %32 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %31, align 8
+  %32 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %31 unordered, align 8
   %33 = and i32 %30, 30
   %34 = zext i32 %33 to i64
   %35 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %32, i64 %34, i32 2
-  %36 = load i8**, i8*** %35, align 8
+  %36 = load atomic i8**, i8*** %35 unordered, align 8
   %37 = getelementptr i8*, i8** %36, i64 3
   %38 = bitcast i8** %37 to i1 (%struct.ObjHeader*)**
-  %39 = load i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %38, align 8
+  %39 = load atomic i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %38 unordered, align 8
   %40 = tail call zeroext i1 %39(%struct.ObjHeader* nonnull %1)
   br label %epilogue
 
@@ -16581,16 +16661,16 @@
   %11 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %10, i64 0, i32 0
   %12 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %11 monotonic, align 8
   %13 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %12, i64 0, i32 9
-  %14 = load i32, i32* %13, align 4
+  %14 = load atomic i32, i32* %13 unordered, align 4
   %15 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %12, i64 0, i32 10
-  %16 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %15, align 8
+  %16 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %15 unordered, align 8
   %17 = and i32 %14, 18
   %18 = zext i32 %17 to i64
   %19 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %16, i64 %18, i32 2
-  %20 = load i8**, i8*** %19, align 8
+  %20 = load atomic i8**, i8*** %19 unordered, align 8
   %21 = getelementptr i8*, i8** %20, i64 3
   %22 = bitcast i8** %21 to i1 (%struct.ObjHeader*)**
-  %23 = load i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %22, align 8
+  %23 = load atomic i1 (%struct.ObjHeader*)*, i1 (%struct.ObjHeader*)** %22 unordered, align 8
   %24 = tail call zeroext i1 %23(%struct.ObjHeader* %1)
   ret i1 %24
 }
@@ -16608,7 +16688,7 @@
   br label %Kotlin_mm_safePointFunctionPrologue.exit
 
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
-  %6 = load %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.collections.EmptyIterator.$instance#internal", align 8
+  %6 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.collections.EmptyIterator.$instance#internal" unordered, align 8
   store %struct.ObjHeader* %6, %struct.ObjHeader** %1, align 8, !tbaa !3
   ret %struct.ObjHeader* %6
 }
@@ -16707,11 +16787,11 @@
   %4 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %e = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 4
   %5 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 5
-  %6 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %7 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
   %8 = bitcast [8 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %9 = bitcast %"class.kotlin::mm::ShadowStack"* %7 to i64*
-  %10 = load i64, i64* %9, align 8, !tbaa !7
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa !7
   %11 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %12 = bitcast %struct.ObjHeader** %11 to i64*
   store i64 %10, i64* %12, align 8, !tbaa !9
@@ -16734,42 +16814,43 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %20, %entry
   %21 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
   %22 = bitcast %struct.ObjHeader* %21 to i64*
-  %23 = load i64, i64* %22, align 8
+  %23 = load atomic i64, i64* %22 unordered, align 8
   %24 = bitcast %struct.ObjHeader** %4 to i64*
   store i64 %23, i64* %24, align 8, !tbaa !3
   %25 = bitcast %struct.ObjHeader** %e to i64*
   store i64 %23, i64* %25, align 8, !tbaa !3
-  %.cast = inttoptr i64 %23 to %struct.ObjHeader*
-  store %struct.ObjHeader* %.cast, %struct.ObjHeader** %5, align 8, !tbaa !3
-  %.not = icmp eq i64 %23, 0
+  %26 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %e unordered, align 8
+  store %struct.ObjHeader* %26, %struct.ObjHeader** %5, align 8, !tbaa !3
+  %.not = icmp eq %struct.ObjHeader* %26, null
   br i1 %.not, label %call_success, label %epilogue
 
 call_success:                                     ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
-  %26 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 7
-  %27 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 6
-  %28 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
-  %29 = bitcast %struct.ObjHeader* %28 to %struct.ObjHeader**
-  %30 = load %struct.ObjHeader*, %struct.ObjHeader** %29, align 8
-  %31 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %30, i64 1
-  %32 = bitcast %struct.ObjHeader* %31 to i64*
-  %33 = load i64, i64* %32, align 8
-  %34 = bitcast %struct.ObjHeader** %27 to i64*
-  store i64 %33, i64* %34, align 8, !tbaa !3
-  store i64 %33, i64* %25, align 8, !tbaa !3
-  %35 = bitcast %struct.ObjHeader** %26 to i64*
-  store i64 %33, i64* %35, align 8, !tbaa !3
-  store i64 %33, i64* %22, align 8, !tbaa !3
-  %.cast1 = inttoptr i64 %33 to %struct.ObjHeader*
+  %27 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 7
+  %28 = getelementptr inbounds [8 x %struct.ObjHeader*], [8 x %struct.ObjHeader*]* %2, i64 0, i64 6
+  %29 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
+  %30 = bitcast %struct.ObjHeader* %29 to %struct.ObjHeader**
+  %31 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %30 unordered, align 8
+  %32 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %31, i64 1
+  %33 = bitcast %struct.ObjHeader* %32 to i64*
+  %34 = load atomic i64, i64* %33 unordered, align 8
+  %35 = bitcast %struct.ObjHeader** %28 to i64*
+  store i64 %34, i64* %35, align 8, !tbaa !3
+  store i64 %34, i64* %25, align 8, !tbaa !3
+  %36 = load atomic i64, i64* %25 unordered, align 8
+  %37 = bitcast %struct.ObjHeader** %27 to i64*
+  store i64 %36, i64* %37, align 8, !tbaa !3
+  store i64 %36, i64* %22, align 8, !tbaa !3
+  %.cast = inttoptr i64 %36 to %struct.ObjHeader*
   br label %epilogue
 
 epilogue:                                         ; preds = %call_success, %Kotlin_mm_safePointFunctionPrologue.exit
-  %36 = phi %struct.ObjHeader* [ %.cast1, %call_success ], [ %.cast, %Kotlin_mm_safePointFunctionPrologue.exit ]
-  store %struct.ObjHeader* %36, %struct.ObjHeader** %1, align 8, !tbaa !3
-  %37 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %38 = load i64, i64* %12, align 8, !tbaa !9
-  %39 = bitcast %"class.kotlin::mm::ShadowStack"* %37 to i64*
-  store i64 %38, i64* %39, align 8, !tbaa !7
-  ret %struct.ObjHeader* %36
+  %38 = phi %struct.ObjHeader* [ %.cast, %call_success ], [ %26, %Kotlin_mm_safePointFunctionPrologue.exit ]
+  store %struct.ObjHeader* %38, %struct.ObjHeader** %1, align 8, !tbaa !3
+  %39 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
+  %40 = load atomic i64, i64* %12 unordered, align 8, !tbaa !9
+  %41 = bitcast %"class.kotlin::mm::ShadowStack"* %39 to i64*
+  store i64 %40, i64* %41, align 8, !tbaa !7
+  ret %struct.ObjHeader* %38
 }
 
 ; Function Attrs: nounwind
@@ -16780,11 +16861,11 @@
   %2 = bitcast [4 x %struct.ObjHeader*]* %1 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %2, i8 0, i32 32, i1 immarg false) #49
   %3 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 3
-  %4 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %4 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %5 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
   %6 = bitcast [4 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
   %7 = bitcast %"class.kotlin::mm::ShadowStack"* %5 to i64*
-  %8 = load i64, i64* %7, align 8, !tbaa !7
+  %8 = load atomic i64, i64* %7 unordered, align 8, !tbaa !7
   %9 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %1, i64 0, i64 1
   %10 = bitcast %struct.ObjHeader** %9 to i64*
   store i64 %8, i64* %10, align 8, !tbaa !9
@@ -16808,9 +16889,9 @@
   %19 = call fastcc %struct.ObjHeader* @"kfun:kotlin.enums.EnumEntriesList.<get-entries>#internal"(%struct.ObjHeader* %0, %struct.ObjHeader** nonnull %3)
   %20 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %19, i64 1
   %21 = bitcast %struct.ObjHeader* %20 to i32*
-  %22 = load i32, i32* %21, align 8, !tbaa !18
+  %22 = load atomic i32, i32* %21 unordered, align 8, !tbaa !18
   %23 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 5
-  %24 = load i64, i64* %10, align 8, !tbaa !9
+  %24 = load atomic i64, i64* %10 unordered, align 8, !tbaa !9
   %25 = bitcast %"class.kotlin::mm::ShadowStack"* %23 to i64*
   store i64 %24, i64* %25, align 8, !tbaa !7
   ret i32 %22
@@ -16823,11 +16904,11 @@
   %4 = bitcast [4 x %struct.ObjHeader*]* %3 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %4, i8 0, i32 32, i1 immarg false) #49
   %5 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 3
-  %6 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %7 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
   %8 = bitcast [4 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
   %9 = bitcast %"class.kotlin::mm::ShadowStack"* %7 to i64*
-  %10 = load i64, i64* %9, align 8, !tbaa !7
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa !7
   %11 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %3, i64 0, i64 1
   %12 = bitcast %struct.ObjHeader** %11 to i64*
   store i64 %10, i64* %12, align 8, !tbaa !9
@@ -16851,9 +16932,9 @@
   %21 = call fastcc %struct.ObjHeader* @"kfun:kotlin.enums.EnumEntriesList.<get-entries>#internal"(%struct.ObjHeader* %0, %struct.ObjHeader** nonnull %5)
   %22 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %21, i64 1
   %23 = bitcast %struct.ObjHeader* %22 to i32*
-  %24 = load i32, i32* %23, align 8, !tbaa !18
+  %24 = load atomic i32, i32* %23 unordered, align 8, !tbaa !18
   call fastcc void @"kfun:kotlin.collections.AbstractList.Companion#checkElementIndex(kotlin.Int;kotlin.Int){}"(i32 %1, i32 %24)
-  %25 = load i32, i32* %23, align 8, !tbaa !18
+  %25 = load atomic i32, i32* %23 unordered, align 8, !tbaa !18
   %26 = icmp ugt i32 %25, %1
   br i1 %26, label %epilogue, label %27
 
@@ -16866,10 +16947,10 @@
   %29 = sext i32 %1 to i64
   %30 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %28, i64 %29
   %31 = bitcast %struct.ObjHeader* %30 to %struct.ObjHeader**
-  %32 = load %struct.ObjHeader*, %struct.ObjHeader** %31, align 8, !tbaa !3
+  %32 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %31 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %32, %struct.ObjHeader** %2, align 8, !tbaa !3
   %33 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %34 = load i64, i64* %12, align 8, !tbaa !9
+  %34 = load atomic i64, i64* %12 unordered, align 8, !tbaa !9
   %35 = bitcast %"class.kotlin::mm::ShadowStack"* %33 to i64*
   store i64 %34, i64* %35, align 8, !tbaa !7
   ret %struct.ObjHeader* %32
@@ -16883,11 +16964,11 @@
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %3, i8 0, i32 40, i1 immarg false) #49
   %4 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %5 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 4
-  %6 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %7 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
   %8 = bitcast [5 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %9 = bitcast %"class.kotlin::mm::ShadowStack"* %7 to i64*
-  %10 = load i64, i64* %9, align 8, !tbaa !7
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa !7
   %11 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %12 = bitcast %struct.ObjHeader** %11 to i64*
   store i64 %10, i64* %12, align 8, !tbaa !9
@@ -16919,7 +17000,7 @@
   %26 = load atomic volatile i64, i64* %25 monotonic, align 8
   %27 = inttoptr i64 %26 to %struct.TypeInfo*
   %28 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %27, i64 0, i32 14
-  %29 = load i32, i32* %28, align 4, !tbaa !19
+  %29 = load atomic i32, i32* %28 unordered, align 4, !tbaa !19
   %.off = add i32 %29, -86
   %30 = icmp ugt i32 %.off, 14
   br i1 %30, label %epilogue, label %call_success
@@ -16928,14 +17009,14 @@
   %31 = call fastcc %struct.ObjHeader* @"kfun:kotlin.enums.EnumEntriesList.<get-entries>#internal"(%struct.ObjHeader* %0, %struct.ObjHeader** nonnull %4)
   %32 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %1, i64 2
   %33 = bitcast %struct.ObjHeader* %32 to i32*
-  %34 = load i32, i32* %33, align 4
+  %34 = load atomic i32, i32* %33 unordered, align 4
   %35 = icmp sgt i32 %34, -1
   br i1 %35, label %when_exit.i, label %call_success3
 
 when_exit.i:                                      ; preds = %call_success
   %36 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %31, i64 1
   %37 = bitcast %struct.ObjHeader* %36 to i32*
-  %38 = load i32, i32* %37, align 8, !tbaa !18
+  %38 = load atomic i32, i32* %37 unordered, align 8, !tbaa !18
   %39 = add i32 %38, -1
   %.not = icmp slt i32 %39, %34
   br i1 %.not, label %call_success3, label %when_case.i
@@ -16953,7 +17034,7 @@
   %43 = sext i32 %34 to i64
   %44 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %42, i64 %43
   %45 = bitcast %struct.ObjHeader* %44 to %struct.ObjHeader**
-  %46 = load %struct.ObjHeader*, %struct.ObjHeader** %45, align 8, !tbaa !3
+  %46 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %45 unordered, align 8, !tbaa !3
   store %struct.ObjHeader* %46, %struct.ObjHeader** %5, align 8, !tbaa !3
   br label %call_success3
 
@@ -16966,7 +17047,7 @@
 epilogue:                                         ; preds = %call_success3, %instance_of_exit, %Kotlin_mm_safePointFunctionPrologue.exit
   %49 = phi i1 [ %48, %call_success3 ], [ false, %instance_of_exit ], [ false, %Kotlin_mm_safePointFunctionPrologue.exit ]
   %50 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 5
-  %51 = load i64, i64* %12, align 8, !tbaa !9
+  %51 = load atomic i64, i64* %12 unordered, align 8, !tbaa !9
   %52 = bitcast %"class.kotlin::mm::ShadowStack"* %50 to i64*
   store i64 %51, i64* %52, align 8, !tbaa !7
   ret i1 %49
@@ -16987,7 +17068,7 @@
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %5, %epilogue
   %6 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %7 = bitcast %struct.ObjHeader* %6 to %struct.ObjHeader**
-  %8 = load %struct.ObjHeader*, %struct.ObjHeader** %7, align 8
+  %8 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %7 unordered, align 8
   store %struct.ObjHeader* %8, %struct.ObjHeader** %1, align 8, !tbaa !3
   ret %struct.ObjHeader* %8
 }
@@ -17012,15 +17093,15 @@
   %12 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %11, i64 0, i32 0
   %13 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %12 monotonic, align 8
   %14 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %13, i64 0, i32 9
-  %15 = load i32, i32* %14, align 4
+  %15 = load atomic i32, i32* %14 unordered, align 4
   %16 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %13, i64 0, i32 10
-  %17 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %16, align 8
+  %17 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %16 unordered, align 8
   %18 = and i32 %15, 25
   %19 = zext i32 %18 to i64
   %20 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %17, i64 %19, i32 2
   %21 = bitcast i8*** %20 to i32 (%struct.ObjHeader*)***
-  %22 = load i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %21, align 8
-  %23 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %22, align 8
+  %22 = load atomic i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %21 unordered, align 8
+  %23 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %22 unordered, align 8
   %24 = tail call i32 %23(%struct.ObjHeader* %0)
   %25 = add i32 %24, -1
   %26 = tail call fastcc i32 @"kfun:kotlin.text#lastIndexOf__at__kotlin.CharSequence(kotlin.Char;kotlin.Int;kotlin.Boolean){}kotlin.Int"(%struct.ObjHeader* %0, i16 zeroext %1, i32 %25)
@@ -17030,7 +17111,7 @@
 when_next.i:                                      ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
   %28 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %29 = bitcast %struct.ObjHeader* %28 to i32*
-  %30 = load i32, i32* %29, align 8, !tbaa !18
+  %30 = load atomic i32, i32* %29 unordered, align 8, !tbaa !18
   %31 = add i32 %26, 1
   %32 = bitcast %struct.ObjHeader* %0 to %struct.ArrayHeader*
   %33 = tail call %struct.ObjHeader* @Kotlin_String_subSequence(%struct.ArrayHeader* %32, i32 %31, i32 %30, %struct.ObjHeader** %2)
@@ -17041,7 +17122,7 @@
   %38 = load atomic volatile i64, i64* %37 monotonic, align 8
   %39 = inttoptr i64 %38 to %struct.TypeInfo*
   %40 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %39, i64 0, i32 14
-  %41 = load i32, i32* %40, align 4, !tbaa !19
+  %41 = load atomic i32, i32* %40 unordered, align 4, !tbaa !19
   %42 = icmp eq i32 %41, 116
   br i1 %42, label %epilogue, label %label_3.i
 
@@ -17073,11 +17154,11 @@
   store i32 1, i32* %count_, align 8
   %10 = getelementptr inbounds %"local#CharArray1#internal", %"local#CharArray1#internal"* %9, i64 0, i32 1, i64 0
   store i16 0, i16* %10, align 8
-  %11 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %11 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %12 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
   %13 = bitcast [7 x %struct.ObjHeader*]* %4 to %struct.FrameOverlay.6*
   %14 = bitcast %"class.kotlin::mm::ShadowStack"* %12 to i64*
-  %15 = load i64, i64* %14, align 8, !tbaa !7
+  %15 = load atomic i64, i64* %14 unordered, align 8, !tbaa !7
   %16 = getelementptr inbounds [7 x %struct.ObjHeader*], [7 x %struct.ObjHeader*]* %4, i64 0, i64 1
   %17 = bitcast %struct.ObjHeader** %16 to i64*
   store i64 %15, i64* %17, align 8, !tbaa !9
@@ -17109,7 +17190,7 @@
   %31 = load atomic volatile i64, i64* %30 monotonic, align 8
   %32 = inttoptr i64 %31 to %struct.TypeInfo*
   %33 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %32, i64 0, i32 14
-  %34 = load i32, i32* %33, align 4, !tbaa !19
+  %34 = load atomic i32, i32* %33 unordered, align 4, !tbaa !19
   %.not = icmp eq i32 %34, 116
   br i1 %.not, label %call_success6, label %call_success
 
@@ -17118,277 +17199,286 @@
   store %"local#CharArray1#internal"* %9, %"local#CharArray1#internal"** %35, align 8, !tbaa !3
   %36 = bitcast %struct.ObjHeader** %"tmp1_$array" to %"local#CharArray1#internal"**
   store %"local#CharArray1#internal"* %9, %"local#CharArray1#internal"** %36, align 8, !tbaa !3
-  %37 = bitcast %struct.ObjHeader** %7 to %"local#CharArray1#internal"**
-  store %"local#CharArray1#internal"* %9, %"local#CharArray1#internal"** %37, align 8, !tbaa !3
-  %38 = bitcast %"local#CharArray1#internal"* %9 to i64*
+  %37 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %"tmp1_$array" unordered, align 8
+  store %struct.ObjHeader* %37, %struct.ObjHeader** %7, align 8, !tbaa !3
+  %38 = bitcast %struct.ObjHeader* %37 to i64*
   %39 = load atomic volatile i64, i64* %38 monotonic, align 8
-  store i16 %1, i16* %10, align 8, !tbaa !34
-  %40 = bitcast %struct.ObjHeader** %8 to %"local#CharArray1#internal"**
-  store %"local#CharArray1#internal"* %9, %"local#CharArray1#internal"** %40, align 8, !tbaa !3
-  %41 = getelementptr inbounds %"local#CharArray1#internal", %"local#CharArray1#internal"* %9, i64 0, i32 0, i32 1
-  %42 = load i32, i32* %41, align 8, !tbaa !18
-  %43 = icmp ne i32 %42, 1
-  %brmerge = or i1 %43, %26
+  %40 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %37, i64 2
+  %41 = bitcast %struct.ObjHeader* %40 to i16*
+  store i16 %1, i16* %41, align 2, !tbaa !27
+  %42 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %"tmp1_$array" unordered, align 8
+  store %struct.ObjHeader* %42, %struct.ObjHeader** %8, align 8, !tbaa !3
+  %43 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %42, i64 1
+  %44 = bitcast %struct.ObjHeader* %43 to i32*
+  %45 = load atomic i32, i32* %44 unordered, align 8, !tbaa !18
+  %46 = icmp ne i32 %45, 1
+  %brmerge = or i1 %46, %26
   br i1 %brmerge, label %when_exit5.i, label %when_exit4.i
 
 when_exit4.i:                                     ; preds = %call_success
-  %44 = bitcast %struct.ObjHeader* %0 to i64*
-  %45 = load atomic volatile i64, i64* %44 monotonic, align 8
-  %46 = and i64 %45, -4
-  %47 = inttoptr i64 %46 to i64*
+  %47 = bitcast %struct.ObjHeader* %0 to i64*
   %48 = load atomic volatile i64, i64* %47 monotonic, align 8
-  %49 = inttoptr i64 %48 to %struct.TypeInfo*
-  %50 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %49, i64 0, i32 14
-  %51 = load i32, i32* %50, align 4, !tbaa !19
-  %52 = icmp eq i32 %51, 116
-  br i1 %52, label %when_case.i, label %when_exit5.i
+  %49 = and i64 %48, -4
+  %50 = inttoptr i64 %49 to i64*
+  %51 = load atomic volatile i64, i64* %50 monotonic, align 8
+  %52 = inttoptr i64 %51 to %struct.TypeInfo*
+  %53 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %52, i64 0, i32 14
+  %54 = load atomic i32, i32* %53 unordered, align 4, !tbaa !19
+  %55 = icmp eq i32 %54, 116
+  br i1 %55, label %when_case.i, label %when_exit5.i
 
 when_case.i:                                      ; preds = %when_exit4.i
-  %53 = bitcast [5 x %struct.ObjHeader*]* %3 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %53)
+  %56 = bitcast [5 x %struct.ObjHeader*]* %3 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %56)
   %.sub.i.i = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 0
-  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %53, i8 0, i32 40, i1 immarg false) #49
-  %54 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
-  %55 = bitcast [5 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
-  %56 = bitcast %"class.kotlin::mm::ShadowStack"* %54 to i64*
-  %57 = load i64, i64* %56, align 8, !tbaa !7
-  %58 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 1
-  %59 = bitcast %struct.ObjHeader** %58 to i64*
-  store i64 %57, i64* %59, align 8, !tbaa !9
-  %60 = bitcast %"class.kotlin::mm::ShadowStack"* %54 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i.i, %struct.ObjHeader*** %60, align 8, !tbaa !7
-  %61 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 2
-  %62 = bitcast %struct.ObjHeader** %61 to i32*
-  store i32 0, i32* %62, align 8, !tbaa !12
-  %63 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %55, i64 0, i32 3
-  store i32 5, i32* %63, align 4, !tbaa !13
-  %64 = load i32, i32* %41, align 8, !tbaa !18
-  switch i32 %64, label %when_next2.i.i [
+  call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(40) %56, i8 0, i32 40, i1 immarg false) #49
+  %57 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
+  %58 = bitcast [5 x %struct.ObjHeader*]* %3 to %struct.FrameOverlay.6*
+  %59 = bitcast %"class.kotlin::mm::ShadowStack"* %57 to i64*
+  %60 = load atomic i64, i64* %59 unordered, align 8, !tbaa !7
+  %61 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 1
+  %62 = bitcast %struct.ObjHeader** %61 to i64*
+  store i64 %60, i64* %62, align 8, !tbaa !9
+  %63 = bitcast %"class.kotlin::mm::ShadowStack"* %57 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i.i, %struct.ObjHeader*** %63, align 8, !tbaa !7
+  %64 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 2
+  %65 = bitcast %struct.ObjHeader** %64 to i32*
+  store i32 0, i32* %65, align 8, !tbaa !12
+  %66 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %58, i64 0, i32 3
+  store i32 5, i32* %66, align 4, !tbaa !13
+  %67 = load atomic i32, i32* %44 unordered, align 8, !tbaa !18
+  switch i32 %67, label %when_next2.i.i [
     i32 0, label %when_case.i1.i
     i32 1, label %"kfun:kotlin.collections#single__at__kotlin.CharArray(){}kotlin.Char.exit.i"
   ]
 
 when_case.i1.i:                                   ; preds = %when_case.i
-  %65 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 3
-  %66 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 6
-  %67 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %66 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %68 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %67, align 8, !tbaa !3
-  %69 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %68, i64 0, i32 2, i32 1
-  %70 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %69, i64 56) #37
-  %71 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %70, i64 1
-  %72 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %70, i64 2
-  %73 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %72 to %struct.ObjHeader*
-  %74 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %72 to %struct.TypeInfo**
-  %75 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %71 to i64*
-  store i64 0, i64* %75, align 8
-  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [5 x i8*] }, { %struct.TypeInfo, [5 x i8*] }* @"ktypeglobal:kotlin.NoSuchElementException#internal", i64 0, i32 0), %struct.TypeInfo** %74, align 8, !tbaa !14
-  %76 = bitcast %struct.ObjHeader** %65 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %72, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %76, align 8, !tbaa !3
-  call fastcc void @"kfun:kotlin.RuntimeException#<init>(kotlin.String?){}"(%struct.ObjHeader* nonnull %73, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [15 x i16] }* @148 to %struct.ObjHeader*))
-  call fastcc void @ThrowException(%struct.ObjHeader* nonnull %73) #50
+  %68 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 3
+  %69 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 6
+  %70 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %69 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
+  %71 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %70 unordered, align 8, !tbaa !3
+  %72 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %71, i64 0, i32 2, i32 1
+  %73 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %72, i64 56) #37
+  %74 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %73, i64 1
+  %75 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %73, i64 2
+  %76 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %75 to %struct.ObjHeader*
+  %77 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %75 to %struct.TypeInfo**
+  %78 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %74 to i64*
+  store i64 0, i64* %78, align 8
+  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [5 x i8*] }, { %struct.TypeInfo, [5 x i8*] }* @"ktypeglobal:kotlin.NoSuchElementException#internal", i64 0, i32 0), %struct.TypeInfo** %77, align 8, !tbaa !14
+  %79 = bitcast %struct.ObjHeader** %68 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %75, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %79, align 8, !tbaa !3
+  call fastcc void @"kfun:kotlin.RuntimeException#<init>(kotlin.String?){}"(%struct.ObjHeader* nonnull %76, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [15 x i16] }* @148 to %struct.ObjHeader*))
+  call fastcc void @ThrowException(%struct.ObjHeader* nonnull %76) #50
   unreachable
 
 when_next2.i.i:                                   ; preds = %when_case.i
-  %77 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 4
-  %78 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 6
-  %79 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %78 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %80 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %79, align 8, !tbaa !3
-  %81 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %80, i64 0, i32 2, i32 1
-  %82 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %81, i64 56) #37
-  %83 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %82, i64 1
-  %84 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %82, i64 2
-  %85 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %84 to %struct.ObjHeader*
-  %86 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %84 to %struct.TypeInfo**
-  %87 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %83 to i64*
-  store i64 0, i64* %87, align 8
-  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [5 x i8*] }, { %struct.TypeInfo, [5 x i8*] }* @"ktypeglobal:kotlin.IllegalArgumentException#internal", i64 0, i32 0), %struct.TypeInfo** %86, align 8, !tbaa !14
-  %88 = bitcast %struct.ObjHeader** %77 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %84, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %88, align 8, !tbaa !3
-  call fastcc void @"kfun:kotlin.RuntimeException#<init>(kotlin.String?){}"(%struct.ObjHeader* nonnull %85, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [32 x i16] }* @149 to %struct.ObjHeader*))
-  call fastcc void @ThrowException(%struct.ObjHeader* nonnull %85) #50
+  %80 = getelementptr inbounds [5 x %struct.ObjHeader*], [5 x %struct.ObjHeader*]* %3, i64 0, i64 4
+  %81 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 6
+  %82 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %81 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
+  %83 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %82 unordered, align 8, !tbaa !3
+  %84 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %83, i64 0, i32 2, i32 1
+  %85 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %84, i64 56) #37
+  %86 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %85, i64 1
+  %87 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %85, i64 2
+  %88 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %87 to %struct.ObjHeader*
+  %89 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %87 to %struct.TypeInfo**
+  %90 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %86 to i64*
+  store i64 0, i64* %90, align 8
+  store %struct.TypeInfo* getelementptr inbounds ({ %struct.TypeInfo, [5 x i8*] }, { %struct.TypeInfo, [5 x i8*] }* @"ktypeglobal:kotlin.IllegalArgumentException#internal", i64 0, i32 0), %struct.TypeInfo** %89, align 8, !tbaa !14
+  %91 = bitcast %struct.ObjHeader** %80 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %87, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %91, align 8, !tbaa !3
+  call fastcc void @"kfun:kotlin.RuntimeException#<init>(kotlin.String?){}"(%struct.ObjHeader* nonnull %88, %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [32 x i16] }* @149 to %struct.ObjHeader*))
+  call fastcc void @ThrowException(%struct.ObjHeader* nonnull %88) #50
   unreachable
 
 "kfun:kotlin.collections#single__at__kotlin.CharArray(){}kotlin.Char.exit.i": ; preds = %when_case.i
-  %89 = getelementptr inbounds %"local#CharArray1#internal", %"local#CharArray1#internal"* %9, i64 0, i32 1, i64 0
-  %90 = load i16, i16* %89, align 8, !tbaa !34
-  %91 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
-  %92 = load i64, i64* %59, align 8, !tbaa !9
-  %93 = bitcast %"class.kotlin::mm::ShadowStack"* %91 to i64*
-  store i64 %92, i64* %93, align 8, !tbaa !7
-  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %53)
-  %94 = icmp slt i32 %2, 0
-  br i1 %94, label %epilogue, label %95
+  %92 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %42, i64 2
+  %93 = bitcast %struct.ObjHeader* %92 to i16*
+  %94 = load atomic i16, i16* %93 unordered, align 2, !tbaa !27
+  %95 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
+  %96 = load atomic i64, i64* %62 unordered, align 8, !tbaa !9
+  %97 = bitcast %"class.kotlin::mm::ShadowStack"* %95 to i64*
+  store i64 %96, i64* %97, align 8, !tbaa !7
+  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %56)
+  %98 = icmp slt i32 %2, 0
+  br i1 %98, label %epilogue, label %99
 
-95:                                               ; preds = %"kfun:kotlin.collections#single__at__kotlin.CharArray(){}kotlin.Char.exit.i"
-  %96 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
-  %97 = bitcast %struct.ObjHeader* %96 to i32*
-  %98 = load i32, i32* %97, align 8, !tbaa !18
-  %99 = icmp eq i32 %98, 0
-  br i1 %99, label %epilogue, label %100
+99:                                               ; preds = %"kfun:kotlin.collections#single__at__kotlin.CharArray(){}kotlin.Char.exit.i"
+  %100 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
+  %101 = bitcast %struct.ObjHeader* %100 to i32*
+  %102 = load atomic i32, i32* %101 unordered, align 8, !tbaa !18
+  %103 = icmp eq i32 %102, 0
+  br i1 %103, label %epilogue, label %104
 
-100:                                              ; preds = %95
-  %101 = icmp ugt i32 %98, %2
-  %102 = add i32 %98, -1
-  %103 = select i1 %101, i32 %2, i32 %102
-  %104 = icmp sgt i32 %103, -1
-  br i1 %104, label %105, label %epilogue
+104:                                              ; preds = %99
+  %105 = icmp ugt i32 %102, %2
+  %106 = add i32 %102, -1
+  %107 = select i1 %105, i32 %2, i32 %106
+  %108 = icmp sgt i32 %107, -1
+  br i1 %108, label %109, label %epilogue
 
-105:                                              ; preds = %100
-  %106 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
-  %107 = bitcast %struct.ObjHeader* %106 to i16*
-  %108 = zext i32 %103 to i64
-  %109 = getelementptr inbounds i16, i16* %107, i64 %108
-  br label %110
+109:                                              ; preds = %104
+  %110 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
+  %111 = bitcast %struct.ObjHeader* %110 to i16*
+  %112 = zext i32 %107 to i64
+  %113 = getelementptr inbounds i16, i16* %111, i64 %112
+  br label %114
 
-110:                                              ; preds = %115, %105
-  %111 = phi i16* [ %116, %115 ], [ %109, %105 ]
-  %112 = phi i32 [ %117, %115 ], [ %103, %105 ]
-  %113 = load i16, i16* %111, align 2, !tbaa !34
-  %114 = icmp eq i16 %113, %90
-  br i1 %114, label %epilogue, label %115
+114:                                              ; preds = %119, %109
+  %115 = phi i16* [ %120, %119 ], [ %113, %109 ]
+  %116 = phi i32 [ %121, %119 ], [ %107, %109 ]
+  %117 = load atomic i16, i16* %115 unordered, align 2, !tbaa !27
+  %118 = icmp eq i16 %117, %94
+  br i1 %118, label %epilogue, label %119
 
-115:                                              ; preds = %110
-  %116 = getelementptr inbounds i16, i16* %111, i64 -1
-  %117 = add nsw i32 %112, -1
-  %118 = icmp sgt i32 %112, 0
-  br i1 %118, label %110, label %epilogue
+119:                                              ; preds = %114
+  %120 = getelementptr inbounds i16, i16* %115, i64 -1
+  %121 = add nsw i32 %116, -1
+  %122 = icmp sgt i32 %116, 0
+  br i1 %122, label %114, label %epilogue
 
 when_exit5.i:                                     ; preds = %when_exit4.i, %call_success
-  %119 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 0, i32 0
-  %120 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %119 monotonic, align 8
-  %121 = ptrtoint %struct.TypeInfo* %120 to i64
-  %122 = and i64 %121, -4
-  %123 = inttoptr i64 %122 to %struct.TypeInfo*
-  %124 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %123, i64 0, i32 0
-  %125 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %124 monotonic, align 8
-  %126 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %125, i64 0, i32 9
-  %127 = load i32, i32* %126, align 4
-  %128 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %125, i64 0, i32 10
-  %129 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %128, align 8
-  %130 = and i32 %127, 25
-  %131 = zext i32 %130 to i64
-  %132 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %129, i64 %131, i32 2
-  %133 = bitcast i8*** %132 to i32 (%struct.ObjHeader*)***
-  %134 = load i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %133, align 8
-  %135 = load i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %134, align 8
-  %136 = call i32 %135(%struct.ObjHeader* %0)
-  %137 = add i32 %136, -1
-  %138 = icmp slt i32 %137, %2
-  %spec.select = select i1 %138, i32 %137, i32 %2
-  %139 = icmp sgt i32 %spec.select, -1
-  br i1 %139, label %do_while_loop.i, label %epilogue
+  %123 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 0, i32 0
+  %124 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %123 monotonic, align 8
+  %125 = ptrtoint %struct.TypeInfo* %124 to i64
+  %126 = and i64 %125, -4
+  %127 = inttoptr i64 %126 to %struct.TypeInfo*
+  %128 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %127, i64 0, i32 0
+  %129 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %128 monotonic, align 8
+  %130 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %129, i64 0, i32 9
+  %131 = load atomic i32, i32* %130 unordered, align 4
+  %132 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %129, i64 0, i32 10
+  %133 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %132 unordered, align 8
+  %134 = and i32 %131, 25
+  %135 = zext i32 %134 to i64
+  %136 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %133, i64 %135, i32 2
+  %137 = bitcast i8*** %136 to i32 (%struct.ObjHeader*)***
+  %138 = load atomic i32 (%struct.ObjHeader*)**, i32 (%struct.ObjHeader*)*** %137 unordered, align 8
+  %139 = load atomic i32 (%struct.ObjHeader*)*, i32 (%struct.ObjHeader*)** %138 unordered, align 8
+  %140 = call i32 %139(%struct.ObjHeader* %0)
+  %141 = add i32 %140, -1
+  %142 = icmp slt i32 %141, %2
+  %spec.select = select i1 %142, i32 %141, i32 %2
+  %143 = icmp sgt i32 %spec.select, -1
+  br i1 %143, label %when_case10.i, label %epilogue
 
-do_while_loop.i:                                  ; preds = %when_exit24.i, %when_exit5.i
-  %inductionVariable.0.i = phi i32 [ %144, %when_exit24.i ], [ %spec.select, %when_exit5.i ]
-  %140 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %141 = and i8 %140, 1
-  %142 = icmp eq i8 %141, 0
-  br i1 %142, label %Kotlin_mm_safePointWhileLoopBody.exit.i, label %143
+when_case10.i:                                    ; preds = %when_exit5.i
+  %144 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %42, i64 2
+  %145 = bitcast %struct.ObjHeader* %144 to i16*
+  br label %do_while_loop.i
 
-143:                                              ; preds = %do_while_loop.i
+do_while_loop.i:                                  ; preds = %when_exit24.i, %when_case10.i
+  %inductionVariable.0.i = phi i32 [ %spec.select, %when_case10.i ], [ %150, %when_exit24.i ]
+  %146 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %147 = and i8 %146, 1
+  %148 = icmp eq i8 %147, 0
+  br i1 %148, label %Kotlin_mm_safePointWhileLoopBody.exit.i, label %149
+
+149:                                              ; preds = %do_while_loop.i
   call fastcc void @_ZN6kotlin2mm26SuspendIfRequestedSlowPathEv() #37
   br label %Kotlin_mm_safePointWhileLoopBody.exit.i
 
-Kotlin_mm_safePointWhileLoopBody.exit.i:          ; preds = %143, %do_while_loop.i
-  %144 = add nsw i32 %inductionVariable.0.i, -1
-  %145 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %119 monotonic, align 8
-  %146 = ptrtoint %struct.TypeInfo* %145 to i64
-  %147 = and i64 %146, -4
-  %148 = inttoptr i64 %147 to %struct.TypeInfo*
-  %149 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %148, i64 0, i32 0
-  %150 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %149 monotonic, align 8
-  %151 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %150, i64 0, i32 9
-  %152 = load i32, i32* %151, align 4
-  %153 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %150, i64 0, i32 10
-  %154 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %153, align 8
-  %155 = and i32 %152, 25
-  %156 = zext i32 %155 to i64
-  %157 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %154, i64 %156, i32 2
-  %158 = load i8**, i8*** %157, align 8
-  %159 = getelementptr i8*, i8** %158, i64 1
-  %160 = bitcast i8** %159 to i16 (%struct.ObjHeader*, i32)**
-  %161 = load i16 (%struct.ObjHeader*, i32)*, i16 (%struct.ObjHeader*, i32)** %160, align 8
-  %162 = call zeroext i16 %161(%struct.ObjHeader* %0, i32 %inductionVariable.0.i)
-  %163 = load i32, i32* %41, align 8, !tbaa !18
-  %164 = icmp sgt i32 %163, 0
-  %smax = select i1 %164, i32 %163, i32 0
+Kotlin_mm_safePointWhileLoopBody.exit.i:          ; preds = %149, %do_while_loop.i
+  %150 = add nsw i32 %inductionVariable.0.i, -1
+  %151 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %123 monotonic, align 8
+  %152 = ptrtoint %struct.TypeInfo* %151 to i64
+  %153 = and i64 %152, -4
+  %154 = inttoptr i64 %153 to %struct.TypeInfo*
+  %155 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %154, i64 0, i32 0
+  %156 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %155 monotonic, align 8
+  %157 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %156, i64 0, i32 9
+  %158 = load atomic i32, i32* %157 unordered, align 4
+  %159 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %156, i64 0, i32 10
+  %160 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %159 unordered, align 8
+  %161 = and i32 %158, 25
+  %162 = zext i32 %161 to i64
+  %163 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %160, i64 %162, i32 2
+  %164 = load atomic i8**, i8*** %163 unordered, align 8
+  %165 = getelementptr i8*, i8** %164, i64 1
+  %166 = bitcast i8** %165 to i16 (%struct.ObjHeader*, i32)**
+  %167 = load atomic i16 (%struct.ObjHeader*, i32)*, i16 (%struct.ObjHeader*, i32)** %166 unordered, align 8
+  %168 = call zeroext i16 %167(%struct.ObjHeader* %0, i32 %inductionVariable.0.i)
+  %169 = load atomic i32, i32* %44 unordered, align 8, !tbaa !18
+  %170 = icmp sgt i32 %169, 0
+  %smax = select i1 %170, i32 %169, i32 0
   br label %loop_check17.i
 
 while_loop.i:                                     ; preds = %loop_check17.i
-  %165 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %166 = and i8 %165, 1
-  %167 = icmp eq i8 %166, 0
-  br i1 %167, label %Kotlin_mm_safePointWhileLoopBody.exit6.i, label %168
+  %171 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %172 = and i8 %171, 1
+  %173 = icmp eq i8 %172, 0
+  br i1 %173, label %Kotlin_mm_safePointWhileLoopBody.exit6.i, label %174
 
-168:                                              ; preds = %while_loop.i
+174:                                              ; preds = %while_loop.i
   call fastcc void @_ZN6kotlin2mm26SuspendIfRequestedSlowPathEv() #37
   br label %Kotlin_mm_safePointWhileLoopBody.exit6.i
 
-Kotlin_mm_safePointWhileLoopBody.exit6.i:         ; preds = %168, %while_loop.i
-  %169 = sext i32 %inductionVariable14.0.i to i64
-  %170 = getelementptr inbounds %"local#CharArray1#internal", %"local#CharArray1#internal"* %9, i64 0, i32 1, i64 %169
-  %171 = load i16, i16* %170, align 2, !tbaa !34
-  %172 = icmp eq i16 %171, %162
-  br i1 %172, label %epilogue, label %when_exit21.i
+Kotlin_mm_safePointWhileLoopBody.exit6.i:         ; preds = %174, %while_loop.i
+  %175 = sext i32 %inductionVariable14.0.i to i64
+  %176 = getelementptr inbounds i16, i16* %145, i64 %175
+  %177 = load atomic i16, i16* %176 unordered, align 2, !tbaa !27
+  %178 = icmp eq i16 %177, %168
+  br i1 %178, label %epilogue, label %when_exit21.i
 
 when_exit21.i:                                    ; preds = %Kotlin_mm_safePointWhileLoopBody.exit6.i
-  %173 = add nuw i32 %inductionVariable14.0.i, 1
+  %179 = add nuw i32 %inductionVariable14.0.i, 1
   br label %loop_check17.i
 
 loop_check17.i:                                   ; preds = %when_exit21.i, %Kotlin_mm_safePointWhileLoopBody.exit.i
-  %inductionVariable14.0.i = phi i32 [ 0, %Kotlin_mm_safePointWhileLoopBody.exit.i ], [ %173, %when_exit21.i ]
+  %inductionVariable14.0.i = phi i32 [ 0, %Kotlin_mm_safePointWhileLoopBody.exit.i ], [ %179, %when_exit21.i ]
   %exitcond.not = icmp eq i32 %inductionVariable14.0.i, %smax
   br i1 %exitcond.not, label %when_exit24.i, label %while_loop.i
 
 when_exit24.i:                                    ; preds = %loop_check17.i
-  %174 = icmp sgt i32 %inductionVariable.0.i, 0
-  br i1 %174, label %do_while_loop.i, label %epilogue
+  %180 = icmp sgt i32 %inductionVariable.0.i, 0
+  br i1 %180, label %do_while_loop.i, label %epilogue
 
 call_success6:                                    ; preds = %when_exit
-  %175 = icmp slt i32 %2, 0
-  br i1 %175, label %epilogue, label %176
+  %181 = icmp slt i32 %2, 0
+  br i1 %181, label %epilogue, label %182
 
-176:                                              ; preds = %call_success6
-  %177 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
-  %178 = bitcast %struct.ObjHeader* %177 to i32*
-  %179 = load i32, i32* %178, align 8, !tbaa !18
-  %180 = icmp eq i32 %179, 0
-  br i1 %180, label %epilogue, label %181
+182:                                              ; preds = %call_success6
+  %183 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
+  %184 = bitcast %struct.ObjHeader* %183 to i32*
+  %185 = load atomic i32, i32* %184 unordered, align 8, !tbaa !18
+  %186 = icmp eq i32 %185, 0
+  br i1 %186, label %epilogue, label %187
 
-181:                                              ; preds = %176
-  %182 = icmp ugt i32 %179, %2
-  %183 = add i32 %179, -1
-  %184 = select i1 %182, i32 %2, i32 %183
-  %185 = icmp sgt i32 %184, -1
-  br i1 %185, label %186, label %epilogue
+187:                                              ; preds = %182
+  %188 = icmp ugt i32 %185, %2
+  %189 = add i32 %185, -1
+  %190 = select i1 %188, i32 %2, i32 %189
+  %191 = icmp sgt i32 %190, -1
+  br i1 %191, label %192, label %epilogue
 
-186:                                              ; preds = %181
-  %187 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
-  %188 = bitcast %struct.ObjHeader* %187 to i16*
-  %189 = zext i32 %184 to i64
-  %190 = getelementptr inbounds i16, i16* %188, i64 %189
-  br label %191
+192:                                              ; preds = %187
+  %193 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 2
+  %194 = bitcast %struct.ObjHeader* %193 to i16*
+  %195 = zext i32 %190 to i64
+  %196 = getelementptr inbounds i16, i16* %194, i64 %195
+  br label %197
 
-191:                                              ; preds = %196, %186
-  %192 = phi i16* [ %197, %196 ], [ %190, %186 ]
-  %193 = phi i32 [ %198, %196 ], [ %184, %186 ]
-  %194 = load i16, i16* %192, align 2, !tbaa !34
-  %195 = icmp eq i16 %194, %1
-  br i1 %195, label %epilogue, label %196
+197:                                              ; preds = %202, %192
+  %198 = phi i16* [ %203, %202 ], [ %196, %192 ]
+  %199 = phi i32 [ %204, %202 ], [ %190, %192 ]
+  %200 = load atomic i16, i16* %198 unordered, align 2, !tbaa !27
+  %201 = icmp eq i16 %200, %1
+  br i1 %201, label %epilogue, label %202
 
-196:                                              ; preds = %191
-  %197 = getelementptr inbounds i16, i16* %192, i64 -1
-  %198 = add nsw i32 %193, -1
-  %199 = icmp sgt i32 %193, 0
-  br i1 %199, label %191, label %epilogue
+202:                                              ; preds = %197
+  %203 = getelementptr inbounds i16, i16* %198, i64 -1
+  %204 = add nsw i32 %199, -1
+  %205 = icmp sgt i32 %199, 0
+  br i1 %205, label %197, label %epilogue
 
-epilogue:                                         ; preds = %196, %191, %181, %176, %call_success6, %when_exit24.i, %Kotlin_mm_safePointWhileLoopBody.exit6.i, %when_exit5.i, %115, %110, %100, %95, %"kfun:kotlin.collections#single__at__kotlin.CharArray(){}kotlin.Char.exit.i"
-  %200 = phi i32 [ -1, %95 ], [ -1, %"kfun:kotlin.collections#single__at__kotlin.CharArray(){}kotlin.Char.exit.i" ], [ -1, %100 ], [ -1, %when_exit5.i ], [ -1, %176 ], [ -1, %call_success6 ], [ -1, %181 ], [ %inductionVariable.0.i, %Kotlin_mm_safePointWhileLoopBody.exit6.i ], [ -1, %when_exit24.i ], [ %112, %110 ], [ -1, %115 ], [ %193, %191 ], [ -1, %196 ]
-  %201 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
-  %202 = load i64, i64* %17, align 8, !tbaa !9
-  %203 = bitcast %"class.kotlin::mm::ShadowStack"* %201 to i64*
-  store i64 %202, i64* %203, align 8, !tbaa !7
-  ret i32 %200
+epilogue:                                         ; preds = %202, %197, %187, %182, %call_success6, %when_exit24.i, %Kotlin_mm_safePointWhileLoopBody.exit6.i, %when_exit5.i, %119, %114, %104, %99, %"kfun:kotlin.collections#single__at__kotlin.CharArray(){}kotlin.Char.exit.i"
+  %206 = phi i32 [ -1, %99 ], [ -1, %"kfun:kotlin.collections#single__at__kotlin.CharArray(){}kotlin.Char.exit.i" ], [ -1, %104 ], [ -1, %when_exit5.i ], [ -1, %182 ], [ -1, %call_success6 ], [ -1, %187 ], [ %inductionVariable.0.i, %Kotlin_mm_safePointWhileLoopBody.exit6.i ], [ -1, %when_exit24.i ], [ %116, %114 ], [ -1, %119 ], [ %199, %197 ], [ -1, %202 ]
+  %207 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 5
+  %208 = load atomic i64, i64* %17 unordered, align 8, !tbaa !9
+  %209 = bitcast %"class.kotlin::mm::ShadowStack"* %207 to i64*
+  store i64 %208, i64* %209, align 8, !tbaa !7
+  ret i32 %206
 }
 
 define internal void @"kfun:$init_global#internal"() #3 personality i32 (...)* @__gxx_personality_v0 {
@@ -17398,11 +17488,11 @@
   %1 = bitcast [4 x %struct.ObjHeader*]* %0 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %1, i8 0, i32 32, i1 immarg false) #49
   %2 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 3
-  %3 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %3 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %4 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 5
   %5 = bitcast [4 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
   %6 = bitcast %"class.kotlin::mm::ShadowStack"* %4 to i64*
-  %7 = load i64, i64* %6, align 8, !tbaa !7
+  %7 = load atomic i64, i64* %6 unordered, align 8, !tbaa !7
   %8 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 1
   %9 = bitcast %struct.ObjHeader** %8 to i64*
   store i64 %7, i64* %9, align 8, !tbaa !9
@@ -17427,7 +17517,7 @@
   store %struct.ObjHeader* %18, %struct.ObjHeader** %2, align 8, !tbaa !3
   call fastcc void @InitAndRegisterGlobal(%struct.ObjHeader** nonnull @"kvar:SPARSE_SWITCH_CASES#internal", %struct.ObjHeader* nonnull %18) #37
   %19 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 5
-  %20 = load i64, i64* %9, align 8, !tbaa !9
+  %20 = load atomic i64, i64* %9 unordered, align 8, !tbaa !9
   %21 = bitcast %"class.kotlin::mm::ShadowStack"* %19 to i64*
   store i64 %20, i64* %21, align 8, !tbaa !7
   ret void
@@ -17450,11 +17540,11 @@
   %objHeader = getelementptr inbounds %"kclassbody:SwitchBenchmark#internal", %"kclassbody:SwitchBenchmark#internal"* %5, i64 0, i32 0
   %typeInfoOrMeta_ = getelementptr inbounds %"kclassbody:SwitchBenchmark#internal", %"kclassbody:SwitchBenchmark#internal"* %5, i64 0, i32 0, i32 0
   store %struct.TypeInfo* inttoptr (i64 or (i64 ptrtoint ({ %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:SwitchBenchmark#internal" to i64), i64 3) to %struct.TypeInfo*), %struct.TypeInfo** %typeInfoOrMeta_, align 8
-  %8 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %8 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %9 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
   %10 = bitcast [4 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %11 = bitcast %"class.kotlin::mm::ShadowStack"* %9 to i64*
-  %12 = load i64, i64* %11, align 8, !tbaa !7
+  %12 = load atomic i64, i64* %11 unordered, align 8, !tbaa !7
   %13 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %14 = bitcast %struct.ObjHeader** %13 to i64*
   store i64 %12, i64* %14, align 8, !tbaa !9
@@ -17494,7 +17584,7 @@
   %28 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
   %29 = bitcast [6 x %struct.ObjHeader*]* %1 to %struct.FrameOverlay.6*
   %30 = bitcast %"class.kotlin::mm::ShadowStack"* %28 to i64*
-  %31 = load i64, i64* %30, align 8, !tbaa !7
+  %31 = load atomic i64, i64* %30 unordered, align 8, !tbaa !7
   %32 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %1, i64 0, i64 1
   %33 = bitcast %struct.ObjHeader** %32 to i64*
   store i64 %31, i64* %33, align 8, !tbaa !9
@@ -17513,7 +17603,7 @@
   %40 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
   %41 = bitcast [4 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
   %42 = bitcast %"class.kotlin::mm::ShadowStack"* %40 to i64*
-  %43 = load i64, i64* %42, align 8, !tbaa !7
+  %43 = load atomic i64, i64* %42 unordered, align 8, !tbaa !7
   %44 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 1
   %45 = bitcast %struct.ObjHeader** %44 to i64*
   store i64 %43, i64* %45, align 8, !tbaa !9
@@ -17526,7 +17616,7 @@
   store i32 4, i32* %49, align 4, !tbaa !13
   %50 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %objHeader, i64 1
   %51 = bitcast %struct.ObjHeader* %50 to %struct.ObjHeader**
-  %52 = load %struct.ObjHeader*, %struct.ObjHeader** %51, align 8
+  %52 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %51 unordered, align 8
   store %struct.ObjHeader* %52, %struct.ObjHeader** %39, align 8, !tbaa !3
   %.not.i.i = icmp eq %struct.ObjHeader* %52, null
   br i1 %.not.i.i, label %when_next.i.i, label %"kfun:SwitchBenchmark#<get-denseIntData>(){}kotlin.IntArray.exit.i"
@@ -17539,13 +17629,13 @@
   %53 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %1, i64 0, i64 3
   store %struct.ObjHeader* %52, %struct.ObjHeader** %53, align 8, !tbaa !3
   %54 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
-  %55 = load i64, i64* %45, align 8, !tbaa !9
+  %55 = load atomic i64, i64* %45 unordered, align 8, !tbaa !9
   %56 = bitcast %"class.kotlin::mm::ShadowStack"* %54 to i64*
   store i64 %55, i64* %56, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %38)
   %57 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %52, i64 1
   %58 = bitcast %struct.ObjHeader* %57 to i32*
-  %59 = load i32, i32* %58, align 8, !tbaa !18
+  %59 = load atomic i32, i32* %58 unordered, align 8, !tbaa !18
   %60 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %52, i64 2
   %61 = bitcast %struct.ObjHeader* %60 to i32*
   %62 = icmp sgt i32 %59, 0
@@ -17565,9 +17655,9 @@
 
 Kotlin_mm_safePointWhileLoopBody.exit.i:          ; preds = %66, %while_loop.i
   %67 = getelementptr inbounds i32, i32* %61, i64 %indvars.iv
-  %68 = load i32, i32* %67, align 4, !tbaa !73
+  %68 = load atomic i32, i32* %67 unordered, align 4, !tbaa !71
   %indvars.iv.next = add nuw nsw i64 %indvars.iv, 1
-  %69 = load i32, i32* @"state_thread_local$Blackhole", align 4
+  %69 = load atomic i32, i32* @"state_thread_local$Blackhole" unordered, align 4
   %70 = icmp eq i32 %69, 2
   br i1 %70, label %"kfun:Blackhole#<get-$companion>#static(){}Blackhole.Companion.exit.i", label %label_init.i.i
 
@@ -17577,7 +17667,7 @@
 
 "kfun:Blackhole#<get-$companion>#static(){}Blackhole.Companion.exit.i": ; preds = %label_init.i.i, %Kotlin_mm_safePointWhileLoopBody.exit.i
   %71 = call fastcc %struct.ObjHeader** @LookupTLS(i32 3) #37
-  %72 = load %struct.ObjHeader*, %struct.ObjHeader** %71, align 8
+  %72 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %71 unordered, align 8
   store %struct.ObjHeader* %72, %struct.ObjHeader** %26, align 8, !tbaa !3
   switch i32 %68, label %when_next38.i.i [
     i32 1, label %"kfun:SwitchBenchmark#objConstSwitch(kotlin.Int){}kotlin.Int.exit.i"
@@ -17649,10 +17739,10 @@
   %73 = call fastcc %struct.ObjHeader* @"kfun:kotlin#<Int-box>(kotlin.Int){}kotlin.Any"(i32 %t.0.i.i, %struct.ObjHeader** nonnull %27)
   %74 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %72, i64 1
   %75 = bitcast %struct.ObjHeader* %74 to i32*
-  %76 = load i32, i32* %75, align 4
+  %76 = load atomic i32, i32* %75 unordered, align 4
   %77 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %73, i64 1
   %78 = bitcast %struct.ObjHeader* %77 to i32*
-  %79 = load i32, i32* %78, align 4
+  %79 = load atomic i32, i32* %78 unordered, align 4
   %80 = add i32 %76, %79
   store i32 %80, i32* %75, align 4
   br label %loop_check.i
@@ -17666,7 +17756,7 @@
   %81 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %8, i64 0, i32 1, i32 5
   %82 = bitcast %"class.kotlin::mm::ShadowStack"* %81 to i64*
   call void @llvm.lifetime.end.p0i8(i64 48, i8* nonnull %25)
-  %83 = load i64, i64* %14, align 8, !tbaa !9
+  %83 = load atomic i64, i64* %14 unordered, align 8, !tbaa !9
   store i64 %83, i64* %82, align 8, !tbaa !7
   ret void
 }
@@ -17679,11 +17769,11 @@
   %1 = bitcast [4 x %struct.ObjHeader*]* %0 to i8*
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %1, i8 0, i32 32, i1 immarg false) #49
   %2 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 3
-  %3 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %3 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %4 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 5
   %5 = bitcast [4 x %struct.ObjHeader*]* %0 to %struct.FrameOverlay.6*
   %6 = bitcast %"class.kotlin::mm::ShadowStack"* %4 to i64*
-  %7 = load i64, i64* %6, align 8, !tbaa !7
+  %7 = load atomic i64, i64* %6 unordered, align 8, !tbaa !7
   %8 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %0, i64 0, i64 1
   %9 = bitcast %struct.ObjHeader** %8 to i64*
   store i64 %7, i64* %9, align 8, !tbaa !9
@@ -17707,7 +17797,7 @@
   %18 = call fastcc %struct.ObjHeader** @LookupTLS(i32 3) #37
   %19 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 6
   %20 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %19 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %21 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %20, align 8, !tbaa !3
+  %21 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %20 unordered, align 8, !tbaa !3
   %22 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %21, i64 0, i32 2, i32 1
   %23 = call fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %22, i64 24) #37
   %24 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %23, i64 1
@@ -17724,11 +17814,11 @@
   %31 = call fastcc %struct.ObjHeader** @LookupTLS(i32 3) #37
   %32 = call fastcc %struct.ObjHeader** @LookupTLS(i32 3) #37
   %33 = bitcast %struct.ObjHeader** %32 to i64*
-  %34 = load i64, i64* %33, align 8
+  %34 = load atomic i64, i64* %33 unordered, align 8
   %35 = bitcast %struct.ObjHeader** %18 to i64*
   store i64 %34, i64* %35, align 8, !tbaa !3
   %36 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 5
-  %37 = load i64, i64* %9, align 8, !tbaa !9
+  %37 = load atomic i64, i64* %9 unordered, align 8, !tbaa !9
   %38 = bitcast %"class.kotlin::mm::ShadowStack"* %36 to i64*
   store i64 %37, i64* %38, align 8, !tbaa !7
   ret void
@@ -20419,424 +20509,717 @@
 ; Function Attrs: nofree norecurse nounwind
 define dso_local void @_Konan_constructors() #6 {
 entry:
-  %.b.i = load i1, i1* @_Konan_init_stdlib_guard, align 1
-  br i1 %.b.i, label %call_success, label %need_init.i
+  %0 = load atomic i32, i32* @_Konan_init_stdlib_guard unordered, align 4
+  %1 = icmp eq i32 %0, 0
+  br i1 %1, label %need_init.i, label %call_success
 
 need_init.i:                                      ; preds = %entry
-  store i1 true, i1* @_Konan_init_stdlib_guard, align 1
-  %0 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %1 = icmp eq %struct.InitNode.173* %0, null
-  %2 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8
-  %3 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %2, i64 0, i32 1
-  %4 = select i1 %1, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %3
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node to %struct.InitNode.173*), %struct.InitNode.173** %4, align 8, !tbaa !3
-  %5 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %6 = icmp eq %struct.InitNode.173* %5, null
-  %7 = select i1 %6, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.16 to %struct.InitNode.173*), %struct.InitNode.173** %7, align 8, !tbaa !3
-  %8 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %9 = icmp eq %struct.InitNode.173* %8, null
-  %10 = select i1 %9, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.16, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.17 to %struct.InitNode.173*), %struct.InitNode.173** %10, align 8, !tbaa !3
-  %11 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %12 = icmp eq %struct.InitNode.173* %11, null
-  %13 = select i1 %12, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.17, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.18 to %struct.InitNode.173*), %struct.InitNode.173** %13, align 8, !tbaa !3
-  %14 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %15 = icmp eq %struct.InitNode.173* %14, null
-  %16 = select i1 %15, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.18, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.19 to %struct.InitNode.173*), %struct.InitNode.173** %16, align 8, !tbaa !3
-  %17 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  store i32 1, i32* @_Konan_init_stdlib_guard, align 4
+  %2 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %3 = icmp eq %struct.InitNode.173* %2, null
+  %4 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %5 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %4, i64 0, i32 1
+  %6 = select i1 %3, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %5
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node to %struct.InitNode.173*), %struct.InitNode.173** %6, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %7 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %8 = icmp eq %struct.InitNode.173* %7, null
+  %9 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %10 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %9, i64 0, i32 1
+  %11 = select i1 %8, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %10
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.16 to %struct.InitNode.173*), %struct.InitNode.173** %11, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.16 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %12 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %13 = icmp eq %struct.InitNode.173* %12, null
+  %14 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %15 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %14, i64 0, i32 1
+  %16 = select i1 %13, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %15
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.17 to %struct.InitNode.173*), %struct.InitNode.173** %16, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.17 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %17 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %18 = icmp eq %struct.InitNode.173* %17, null
-  %19 = select i1 %18, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.19, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.20 to %struct.InitNode.173*), %struct.InitNode.173** %19, align 8, !tbaa !3
-  %20 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %21 = icmp eq %struct.InitNode.173* %20, null
-  %22 = select i1 %21, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.20, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.21 to %struct.InitNode.173*), %struct.InitNode.173** %22, align 8, !tbaa !3
-  %23 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %24 = icmp eq %struct.InitNode.173* %23, null
-  %25 = select i1 %24, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.21, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.22 to %struct.InitNode.173*), %struct.InitNode.173** %25, align 8, !tbaa !3
-  %26 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %27 = icmp eq %struct.InitNode.173* %26, null
-  %28 = select i1 %27, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.22, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.23 to %struct.InitNode.173*), %struct.InitNode.173** %28, align 8, !tbaa !3
-  %29 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %30 = icmp eq %struct.InitNode.173* %29, null
-  %31 = select i1 %30, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.23, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.24 to %struct.InitNode.173*), %struct.InitNode.173** %31, align 8, !tbaa !3
-  %32 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %19 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %20 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %19, i64 0, i32 1
+  %21 = select i1 %18, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %20
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.18 to %struct.InitNode.173*), %struct.InitNode.173** %21, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.18 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %22 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %23 = icmp eq %struct.InitNode.173* %22, null
+  %24 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %25 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %24, i64 0, i32 1
+  %26 = select i1 %23, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %25
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.19 to %struct.InitNode.173*), %struct.InitNode.173** %26, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.19 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %27 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %28 = icmp eq %struct.InitNode.173* %27, null
+  %29 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %30 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %29, i64 0, i32 1
+  %31 = select i1 %28, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %30
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.20 to %struct.InitNode.173*), %struct.InitNode.173** %31, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.20 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %32 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %33 = icmp eq %struct.InitNode.173* %32, null
-  %34 = select i1 %33, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.24, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.25 to %struct.InitNode.173*), %struct.InitNode.173** %34, align 8, !tbaa !3
-  %35 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %36 = icmp eq %struct.InitNode.173* %35, null
-  %37 = select i1 %36, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.25, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.26 to %struct.InitNode.173*), %struct.InitNode.173** %37, align 8, !tbaa !3
-  %38 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %39 = icmp eq %struct.InitNode.173* %38, null
-  %40 = select i1 %39, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.26, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.27 to %struct.InitNode.173*), %struct.InitNode.173** %40, align 8, !tbaa !3
-  %41 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %42 = icmp eq %struct.InitNode.173* %41, null
-  %43 = select i1 %42, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.27, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.28 to %struct.InitNode.173*), %struct.InitNode.173** %43, align 8, !tbaa !3
-  %44 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %45 = icmp eq %struct.InitNode.173* %44, null
-  %46 = select i1 %45, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.28, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.29 to %struct.InitNode.173*), %struct.InitNode.173** %46, align 8, !tbaa !3
-  %47 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %34 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %35 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %34, i64 0, i32 1
+  %36 = select i1 %33, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %35
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.21 to %struct.InitNode.173*), %struct.InitNode.173** %36, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.21 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %37 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %38 = icmp eq %struct.InitNode.173* %37, null
+  %39 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %40 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %39, i64 0, i32 1
+  %41 = select i1 %38, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %40
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.22 to %struct.InitNode.173*), %struct.InitNode.173** %41, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.22 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %42 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %43 = icmp eq %struct.InitNode.173* %42, null
+  %44 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %45 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %44, i64 0, i32 1
+  %46 = select i1 %43, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %45
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.23 to %struct.InitNode.173*), %struct.InitNode.173** %46, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.23 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %47 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %48 = icmp eq %struct.InitNode.173* %47, null
-  %49 = select i1 %48, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.29, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.30 to %struct.InitNode.173*), %struct.InitNode.173** %49, align 8, !tbaa !3
-  %50 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %51 = icmp eq %struct.InitNode.173* %50, null
-  %52 = select i1 %51, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.30, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.31 to %struct.InitNode.173*), %struct.InitNode.173** %52, align 8, !tbaa !3
-  %53 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %54 = icmp eq %struct.InitNode.173* %53, null
-  %55 = select i1 %54, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.31, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.32 to %struct.InitNode.173*), %struct.InitNode.173** %55, align 8, !tbaa !3
-  %56 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %57 = icmp eq %struct.InitNode.173* %56, null
-  %58 = select i1 %57, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.32, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.33 to %struct.InitNode.173*), %struct.InitNode.173** %58, align 8, !tbaa !3
-  %59 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %60 = icmp eq %struct.InitNode.173* %59, null
-  %61 = select i1 %60, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.33, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.34 to %struct.InitNode.173*), %struct.InitNode.173** %61, align 8, !tbaa !3
-  %62 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %49 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %50 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %49, i64 0, i32 1
+  %51 = select i1 %48, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %50
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.24 to %struct.InitNode.173*), %struct.InitNode.173** %51, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.24 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %52 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %53 = icmp eq %struct.InitNode.173* %52, null
+  %54 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %55 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %54, i64 0, i32 1
+  %56 = select i1 %53, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %55
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.25 to %struct.InitNode.173*), %struct.InitNode.173** %56, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.25 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %57 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %58 = icmp eq %struct.InitNode.173* %57, null
+  %59 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %60 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %59, i64 0, i32 1
+  %61 = select i1 %58, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %60
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.26 to %struct.InitNode.173*), %struct.InitNode.173** %61, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.26 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %62 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %63 = icmp eq %struct.InitNode.173* %62, null
-  %64 = select i1 %63, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.34, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.35 to %struct.InitNode.173*), %struct.InitNode.173** %64, align 8, !tbaa !3
-  %65 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %66 = icmp eq %struct.InitNode.173* %65, null
-  %67 = select i1 %66, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.35, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.36 to %struct.InitNode.173*), %struct.InitNode.173** %67, align 8, !tbaa !3
-  %68 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %69 = icmp eq %struct.InitNode.173* %68, null
-  %70 = select i1 %69, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.36, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.37 to %struct.InitNode.173*), %struct.InitNode.173** %70, align 8, !tbaa !3
-  %71 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %72 = icmp eq %struct.InitNode.173* %71, null
-  %73 = select i1 %72, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.37, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.38 to %struct.InitNode.173*), %struct.InitNode.173** %73, align 8, !tbaa !3
-  %74 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %75 = icmp eq %struct.InitNode.173* %74, null
-  %76 = select i1 %75, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.38, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.39 to %struct.InitNode.173*), %struct.InitNode.173** %76, align 8, !tbaa !3
-  %77 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %64 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %65 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %64, i64 0, i32 1
+  %66 = select i1 %63, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %65
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.27 to %struct.InitNode.173*), %struct.InitNode.173** %66, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.27 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %67 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %68 = icmp eq %struct.InitNode.173* %67, null
+  %69 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %70 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %69, i64 0, i32 1
+  %71 = select i1 %68, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %70
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.28 to %struct.InitNode.173*), %struct.InitNode.173** %71, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.28 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %72 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %73 = icmp eq %struct.InitNode.173* %72, null
+  %74 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %75 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %74, i64 0, i32 1
+  %76 = select i1 %73, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %75
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.29 to %struct.InitNode.173*), %struct.InitNode.173** %76, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.29 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %77 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %78 = icmp eq %struct.InitNode.173* %77, null
-  %79 = select i1 %78, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.39, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.40 to %struct.InitNode.173*), %struct.InitNode.173** %79, align 8, !tbaa !3
-  %80 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %81 = icmp eq %struct.InitNode.173* %80, null
-  %82 = select i1 %81, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.40, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.41 to %struct.InitNode.173*), %struct.InitNode.173** %82, align 8, !tbaa !3
-  %83 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %84 = icmp eq %struct.InitNode.173* %83, null
-  %85 = select i1 %84, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.41, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.42 to %struct.InitNode.173*), %struct.InitNode.173** %85, align 8, !tbaa !3
-  %86 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %87 = icmp eq %struct.InitNode.173* %86, null
-  %88 = select i1 %87, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.42, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.43 to %struct.InitNode.173*), %struct.InitNode.173** %88, align 8, !tbaa !3
-  %89 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %90 = icmp eq %struct.InitNode.173* %89, null
-  %91 = select i1 %90, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.43, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.44 to %struct.InitNode.173*), %struct.InitNode.173** %91, align 8, !tbaa !3
-  %92 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %79 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %80 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %79, i64 0, i32 1
+  %81 = select i1 %78, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %80
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.30 to %struct.InitNode.173*), %struct.InitNode.173** %81, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.30 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %82 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %83 = icmp eq %struct.InitNode.173* %82, null
+  %84 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %85 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %84, i64 0, i32 1
+  %86 = select i1 %83, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %85
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.31 to %struct.InitNode.173*), %struct.InitNode.173** %86, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.31 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %87 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %88 = icmp eq %struct.InitNode.173* %87, null
+  %89 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %90 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %89, i64 0, i32 1
+  %91 = select i1 %88, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %90
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.32 to %struct.InitNode.173*), %struct.InitNode.173** %91, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.32 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %92 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %93 = icmp eq %struct.InitNode.173* %92, null
-  %94 = select i1 %93, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.44, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.45 to %struct.InitNode.173*), %struct.InitNode.173** %94, align 8, !tbaa !3
-  %95 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %96 = icmp eq %struct.InitNode.173* %95, null
-  %97 = select i1 %96, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.45, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.46 to %struct.InitNode.173*), %struct.InitNode.173** %97, align 8, !tbaa !3
-  %98 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %99 = icmp eq %struct.InitNode.173* %98, null
-  %100 = select i1 %99, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.46, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.47 to %struct.InitNode.173*), %struct.InitNode.173** %100, align 8, !tbaa !3
-  %101 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %102 = icmp eq %struct.InitNode.173* %101, null
-  %103 = select i1 %102, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.47, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.48 to %struct.InitNode.173*), %struct.InitNode.173** %103, align 8, !tbaa !3
-  %104 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %105 = icmp eq %struct.InitNode.173* %104, null
-  %106 = select i1 %105, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.48, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.49 to %struct.InitNode.173*), %struct.InitNode.173** %106, align 8, !tbaa !3
-  %107 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %94 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %95 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %94, i64 0, i32 1
+  %96 = select i1 %93, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %95
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.33 to %struct.InitNode.173*), %struct.InitNode.173** %96, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.33 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %97 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %98 = icmp eq %struct.InitNode.173* %97, null
+  %99 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %100 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %99, i64 0, i32 1
+  %101 = select i1 %98, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %100
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.34 to %struct.InitNode.173*), %struct.InitNode.173** %101, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.34 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %102 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %103 = icmp eq %struct.InitNode.173* %102, null
+  %104 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %105 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %104, i64 0, i32 1
+  %106 = select i1 %103, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %105
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.35 to %struct.InitNode.173*), %struct.InitNode.173** %106, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.35 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %107 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %108 = icmp eq %struct.InitNode.173* %107, null
-  %109 = select i1 %108, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.49, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.50 to %struct.InitNode.173*), %struct.InitNode.173** %109, align 8, !tbaa !3
-  %110 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %111 = icmp eq %struct.InitNode.173* %110, null
-  %112 = select i1 %111, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.50, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.51 to %struct.InitNode.173*), %struct.InitNode.173** %112, align 8, !tbaa !3
-  %113 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %114 = icmp eq %struct.InitNode.173* %113, null
-  %115 = select i1 %114, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.51, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.52 to %struct.InitNode.173*), %struct.InitNode.173** %115, align 8, !tbaa !3
-  %116 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %117 = icmp eq %struct.InitNode.173* %116, null
-  %118 = select i1 %117, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.52, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.53 to %struct.InitNode.173*), %struct.InitNode.173** %118, align 8, !tbaa !3
-  %119 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %120 = icmp eq %struct.InitNode.173* %119, null
-  %121 = select i1 %120, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.53, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.54 to %struct.InitNode.173*), %struct.InitNode.173** %121, align 8, !tbaa !3
-  %122 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %109 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %110 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %109, i64 0, i32 1
+  %111 = select i1 %108, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %110
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.36 to %struct.InitNode.173*), %struct.InitNode.173** %111, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.36 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %112 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %113 = icmp eq %struct.InitNode.173* %112, null
+  %114 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %115 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %114, i64 0, i32 1
+  %116 = select i1 %113, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %115
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.37 to %struct.InitNode.173*), %struct.InitNode.173** %116, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.37 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %117 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %118 = icmp eq %struct.InitNode.173* %117, null
+  %119 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %120 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %119, i64 0, i32 1
+  %121 = select i1 %118, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %120
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.38 to %struct.InitNode.173*), %struct.InitNode.173** %121, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.38 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %122 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %123 = icmp eq %struct.InitNode.173* %122, null
-  %124 = select i1 %123, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.54, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.55 to %struct.InitNode.173*), %struct.InitNode.173** %124, align 8, !tbaa !3
-  %125 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %126 = icmp eq %struct.InitNode.173* %125, null
-  %127 = select i1 %126, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.55, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.56 to %struct.InitNode.173*), %struct.InitNode.173** %127, align 8, !tbaa !3
-  %128 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %129 = icmp eq %struct.InitNode.173* %128, null
-  %130 = select i1 %129, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.56, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.57 to %struct.InitNode.173*), %struct.InitNode.173** %130, align 8, !tbaa !3
-  %131 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %132 = icmp eq %struct.InitNode.173* %131, null
-  %133 = select i1 %132, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.57, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.58 to %struct.InitNode.173*), %struct.InitNode.173** %133, align 8, !tbaa !3
-  %134 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %135 = icmp eq %struct.InitNode.173* %134, null
-  %136 = select i1 %135, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.58, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.59 to %struct.InitNode.173*), %struct.InitNode.173** %136, align 8, !tbaa !3
-  %137 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %124 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %125 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %124, i64 0, i32 1
+  %126 = select i1 %123, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %125
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.39 to %struct.InitNode.173*), %struct.InitNode.173** %126, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.39 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %127 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %128 = icmp eq %struct.InitNode.173* %127, null
+  %129 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %130 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %129, i64 0, i32 1
+  %131 = select i1 %128, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %130
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.40 to %struct.InitNode.173*), %struct.InitNode.173** %131, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.40 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %132 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %133 = icmp eq %struct.InitNode.173* %132, null
+  %134 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %135 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %134, i64 0, i32 1
+  %136 = select i1 %133, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %135
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.41 to %struct.InitNode.173*), %struct.InitNode.173** %136, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.41 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %137 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %138 = icmp eq %struct.InitNode.173* %137, null
-  %139 = select i1 %138, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.59, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.60 to %struct.InitNode.173*), %struct.InitNode.173** %139, align 8, !tbaa !3
-  %140 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %141 = icmp eq %struct.InitNode.173* %140, null
-  %142 = select i1 %141, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.60, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.61 to %struct.InitNode.173*), %struct.InitNode.173** %142, align 8, !tbaa !3
-  %143 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %144 = icmp eq %struct.InitNode.173* %143, null
-  %145 = select i1 %144, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.61, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.62 to %struct.InitNode.173*), %struct.InitNode.173** %145, align 8, !tbaa !3
-  %146 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %147 = icmp eq %struct.InitNode.173* %146, null
-  %148 = select i1 %147, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.62, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.63 to %struct.InitNode.173*), %struct.InitNode.173** %148, align 8, !tbaa !3
-  %149 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %150 = icmp eq %struct.InitNode.173* %149, null
-  %151 = select i1 %150, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.63, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.64 to %struct.InitNode.173*), %struct.InitNode.173** %151, align 8, !tbaa !3
-  %152 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %139 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %140 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %139, i64 0, i32 1
+  %141 = select i1 %138, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %140
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.42 to %struct.InitNode.173*), %struct.InitNode.173** %141, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.42 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %142 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %143 = icmp eq %struct.InitNode.173* %142, null
+  %144 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %145 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %144, i64 0, i32 1
+  %146 = select i1 %143, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %145
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.43 to %struct.InitNode.173*), %struct.InitNode.173** %146, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.43 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %147 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %148 = icmp eq %struct.InitNode.173* %147, null
+  %149 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %150 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %149, i64 0, i32 1
+  %151 = select i1 %148, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %150
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.44 to %struct.InitNode.173*), %struct.InitNode.173** %151, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.44 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %152 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %153 = icmp eq %struct.InitNode.173* %152, null
-  %154 = select i1 %153, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.64, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.65 to %struct.InitNode.173*), %struct.InitNode.173** %154, align 8, !tbaa !3
-  %155 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %156 = icmp eq %struct.InitNode.173* %155, null
-  %157 = select i1 %156, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.65, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.66 to %struct.InitNode.173*), %struct.InitNode.173** %157, align 8, !tbaa !3
-  %158 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %159 = icmp eq %struct.InitNode.173* %158, null
-  %160 = select i1 %159, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.66, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.67 to %struct.InitNode.173*), %struct.InitNode.173** %160, align 8, !tbaa !3
-  %161 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %162 = icmp eq %struct.InitNode.173* %161, null
-  %163 = select i1 %162, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.67, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.68 to %struct.InitNode.173*), %struct.InitNode.173** %163, align 8, !tbaa !3
-  %164 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %165 = icmp eq %struct.InitNode.173* %164, null
-  %166 = select i1 %165, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.68, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.69 to %struct.InitNode.173*), %struct.InitNode.173** %166, align 8, !tbaa !3
-  %167 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %154 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %155 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %154, i64 0, i32 1
+  %156 = select i1 %153, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %155
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.45 to %struct.InitNode.173*), %struct.InitNode.173** %156, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.45 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %157 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %158 = icmp eq %struct.InitNode.173* %157, null
+  %159 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %160 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %159, i64 0, i32 1
+  %161 = select i1 %158, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %160
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.46 to %struct.InitNode.173*), %struct.InitNode.173** %161, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.46 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %162 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %163 = icmp eq %struct.InitNode.173* %162, null
+  %164 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %165 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %164, i64 0, i32 1
+  %166 = select i1 %163, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %165
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.47 to %struct.InitNode.173*), %struct.InitNode.173** %166, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.47 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %167 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %168 = icmp eq %struct.InitNode.173* %167, null
-  %169 = select i1 %168, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.69, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.70 to %struct.InitNode.173*), %struct.InitNode.173** %169, align 8, !tbaa !3
-  %170 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %171 = icmp eq %struct.InitNode.173* %170, null
-  %172 = select i1 %171, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.70, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.71 to %struct.InitNode.173*), %struct.InitNode.173** %172, align 8, !tbaa !3
-  %173 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %174 = icmp eq %struct.InitNode.173* %173, null
-  %175 = select i1 %174, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.71, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.72 to %struct.InitNode.173*), %struct.InitNode.173** %175, align 8, !tbaa !3
-  %176 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %177 = icmp eq %struct.InitNode.173* %176, null
-  %178 = select i1 %177, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.72, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.73 to %struct.InitNode.173*), %struct.InitNode.173** %178, align 8, !tbaa !3
-  %179 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %180 = icmp eq %struct.InitNode.173* %179, null
-  %181 = select i1 %180, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.73, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.74 to %struct.InitNode.173*), %struct.InitNode.173** %181, align 8, !tbaa !3
-  %182 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %169 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %170 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %169, i64 0, i32 1
+  %171 = select i1 %168, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %170
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.48 to %struct.InitNode.173*), %struct.InitNode.173** %171, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.48 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %172 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %173 = icmp eq %struct.InitNode.173* %172, null
+  %174 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %175 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %174, i64 0, i32 1
+  %176 = select i1 %173, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %175
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.49 to %struct.InitNode.173*), %struct.InitNode.173** %176, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.49 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %177 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %178 = icmp eq %struct.InitNode.173* %177, null
+  %179 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %180 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %179, i64 0, i32 1
+  %181 = select i1 %178, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %180
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.50 to %struct.InitNode.173*), %struct.InitNode.173** %181, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.50 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %182 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %183 = icmp eq %struct.InitNode.173* %182, null
-  %184 = select i1 %183, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.74, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.75 to %struct.InitNode.173*), %struct.InitNode.173** %184, align 8, !tbaa !3
-  %185 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %186 = icmp eq %struct.InitNode.173* %185, null
-  %187 = select i1 %186, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.75, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.76 to %struct.InitNode.173*), %struct.InitNode.173** %187, align 8, !tbaa !3
-  %188 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %189 = icmp eq %struct.InitNode.173* %188, null
-  %190 = select i1 %189, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.76, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.77 to %struct.InitNode.173*), %struct.InitNode.173** %190, align 8, !tbaa !3
-  %191 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %192 = icmp eq %struct.InitNode.173* %191, null
-  %193 = select i1 %192, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.77, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.78 to %struct.InitNode.173*), %struct.InitNode.173** %193, align 8, !tbaa !3
-  %194 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %195 = icmp eq %struct.InitNode.173* %194, null
-  %196 = select i1 %195, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.78, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.79 to %struct.InitNode.173*), %struct.InitNode.173** %196, align 8, !tbaa !3
-  %197 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %184 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %185 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %184, i64 0, i32 1
+  %186 = select i1 %183, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %185
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.51 to %struct.InitNode.173*), %struct.InitNode.173** %186, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.51 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %187 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %188 = icmp eq %struct.InitNode.173* %187, null
+  %189 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %190 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %189, i64 0, i32 1
+  %191 = select i1 %188, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %190
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.52 to %struct.InitNode.173*), %struct.InitNode.173** %191, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.52 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %192 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %193 = icmp eq %struct.InitNode.173* %192, null
+  %194 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %195 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %194, i64 0, i32 1
+  %196 = select i1 %193, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %195
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.53 to %struct.InitNode.173*), %struct.InitNode.173** %196, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.53 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %197 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %198 = icmp eq %struct.InitNode.173* %197, null
-  %199 = select i1 %198, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.79, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.80 to %struct.InitNode.173*), %struct.InitNode.173** %199, align 8, !tbaa !3
-  %200 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %201 = icmp eq %struct.InitNode.173* %200, null
-  %202 = select i1 %201, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.80, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.81 to %struct.InitNode.173*), %struct.InitNode.173** %202, align 8, !tbaa !3
-  %203 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %204 = icmp eq %struct.InitNode.173* %203, null
-  %205 = select i1 %204, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.81, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.82 to %struct.InitNode.173*), %struct.InitNode.173** %205, align 8, !tbaa !3
-  %206 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %207 = icmp eq %struct.InitNode.173* %206, null
-  %208 = select i1 %207, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.82, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.83 to %struct.InitNode.173*), %struct.InitNode.173** %208, align 8, !tbaa !3
-  %209 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %210 = icmp eq %struct.InitNode.173* %209, null
-  %211 = select i1 %210, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.83, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.84 to %struct.InitNode.173*), %struct.InitNode.173** %211, align 8, !tbaa !3
-  %212 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %199 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %200 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %199, i64 0, i32 1
+  %201 = select i1 %198, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %200
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.54 to %struct.InitNode.173*), %struct.InitNode.173** %201, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.54 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %202 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %203 = icmp eq %struct.InitNode.173* %202, null
+  %204 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %205 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %204, i64 0, i32 1
+  %206 = select i1 %203, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %205
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.55 to %struct.InitNode.173*), %struct.InitNode.173** %206, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.55 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %207 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %208 = icmp eq %struct.InitNode.173* %207, null
+  %209 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %210 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %209, i64 0, i32 1
+  %211 = select i1 %208, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %210
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.56 to %struct.InitNode.173*), %struct.InitNode.173** %211, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.56 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %212 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %213 = icmp eq %struct.InitNode.173* %212, null
-  %214 = select i1 %213, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.84, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.85 to %struct.InitNode.173*), %struct.InitNode.173** %214, align 8, !tbaa !3
-  %215 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %216 = icmp eq %struct.InitNode.173* %215, null
-  %217 = select i1 %216, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.85, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.86 to %struct.InitNode.173*), %struct.InitNode.173** %217, align 8, !tbaa !3
-  %218 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %219 = icmp eq %struct.InitNode.173* %218, null
-  %220 = select i1 %219, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.86, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.87 to %struct.InitNode.173*), %struct.InitNode.173** %220, align 8, !tbaa !3
-  %221 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %222 = icmp eq %struct.InitNode.173* %221, null
-  %223 = select i1 %222, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.87, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.88 to %struct.InitNode.173*), %struct.InitNode.173** %223, align 8, !tbaa !3
-  %224 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %225 = icmp eq %struct.InitNode.173* %224, null
-  %226 = select i1 %225, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.88, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.89 to %struct.InitNode.173*), %struct.InitNode.173** %226, align 8, !tbaa !3
-  %227 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %214 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %215 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %214, i64 0, i32 1
+  %216 = select i1 %213, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %215
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.57 to %struct.InitNode.173*), %struct.InitNode.173** %216, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.57 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %217 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %218 = icmp eq %struct.InitNode.173* %217, null
+  %219 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %220 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %219, i64 0, i32 1
+  %221 = select i1 %218, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %220
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.58 to %struct.InitNode.173*), %struct.InitNode.173** %221, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.58 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %222 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %223 = icmp eq %struct.InitNode.173* %222, null
+  %224 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %225 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %224, i64 0, i32 1
+  %226 = select i1 %223, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %225
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.59 to %struct.InitNode.173*), %struct.InitNode.173** %226, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.59 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %227 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %228 = icmp eq %struct.InitNode.173* %227, null
-  %229 = select i1 %228, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.89, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.90 to %struct.InitNode.173*), %struct.InitNode.173** %229, align 8, !tbaa !3
-  %230 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %231 = icmp eq %struct.InitNode.173* %230, null
-  %232 = select i1 %231, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.90, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.91 to %struct.InitNode.173*), %struct.InitNode.173** %232, align 8, !tbaa !3
-  %233 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %234 = icmp eq %struct.InitNode.173* %233, null
-  %235 = select i1 %234, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.91, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.92 to %struct.InitNode.173*), %struct.InitNode.173** %235, align 8, !tbaa !3
-  %236 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %237 = icmp eq %struct.InitNode.173* %236, null
-  %238 = select i1 %237, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.92, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.93 to %struct.InitNode.173*), %struct.InitNode.173** %238, align 8, !tbaa !3
-  %239 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %240 = icmp eq %struct.InitNode.173* %239, null
-  %241 = select i1 %240, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.93, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.94 to %struct.InitNode.173*), %struct.InitNode.173** %241, align 8, !tbaa !3
-  %242 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %229 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %230 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %229, i64 0, i32 1
+  %231 = select i1 %228, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %230
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.60 to %struct.InitNode.173*), %struct.InitNode.173** %231, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.60 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %232 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %233 = icmp eq %struct.InitNode.173* %232, null
+  %234 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %235 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %234, i64 0, i32 1
+  %236 = select i1 %233, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %235
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.61 to %struct.InitNode.173*), %struct.InitNode.173** %236, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.61 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %237 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %238 = icmp eq %struct.InitNode.173* %237, null
+  %239 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %240 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %239, i64 0, i32 1
+  %241 = select i1 %238, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %240
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.62 to %struct.InitNode.173*), %struct.InitNode.173** %241, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.62 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %242 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %243 = icmp eq %struct.InitNode.173* %242, null
-  %244 = select i1 %243, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.94, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.95 to %struct.InitNode.173*), %struct.InitNode.173** %244, align 8, !tbaa !3
-  %245 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %246 = icmp eq %struct.InitNode.173* %245, null
-  %247 = select i1 %246, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.95, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.96 to %struct.InitNode.173*), %struct.InitNode.173** %247, align 8, !tbaa !3
-  %248 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %249 = icmp eq %struct.InitNode.173* %248, null
-  %250 = select i1 %249, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.96, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.97 to %struct.InitNode.173*), %struct.InitNode.173** %250, align 8, !tbaa !3
-  %251 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %252 = icmp eq %struct.InitNode.173* %251, null
-  %253 = select i1 %252, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.97, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.98 to %struct.InitNode.173*), %struct.InitNode.173** %253, align 8, !tbaa !3
-  %254 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %255 = icmp eq %struct.InitNode.173* %254, null
-  %256 = select i1 %255, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.98, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.99 to %struct.InitNode.173*), %struct.InitNode.173** %256, align 8, !tbaa !3
-  %257 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %244 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %245 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %244, i64 0, i32 1
+  %246 = select i1 %243, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %245
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.63 to %struct.InitNode.173*), %struct.InitNode.173** %246, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.63 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %247 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %248 = icmp eq %struct.InitNode.173* %247, null
+  %249 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %250 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %249, i64 0, i32 1
+  %251 = select i1 %248, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %250
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.64 to %struct.InitNode.173*), %struct.InitNode.173** %251, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.64 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %252 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %253 = icmp eq %struct.InitNode.173* %252, null
+  %254 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %255 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %254, i64 0, i32 1
+  %256 = select i1 %253, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %255
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.65 to %struct.InitNode.173*), %struct.InitNode.173** %256, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.65 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %257 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %258 = icmp eq %struct.InitNode.173* %257, null
-  %259 = select i1 %258, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.99, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.100 to %struct.InitNode.173*), %struct.InitNode.173** %259, align 8, !tbaa !3
-  %260 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %261 = icmp eq %struct.InitNode.173* %260, null
-  %262 = select i1 %261, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.100, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.101 to %struct.InitNode.173*), %struct.InitNode.173** %262, align 8, !tbaa !3
-  %263 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %264 = icmp eq %struct.InitNode.173* %263, null
-  %265 = select i1 %264, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.101, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.102 to %struct.InitNode.173*), %struct.InitNode.173** %265, align 8, !tbaa !3
-  %266 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %267 = icmp eq %struct.InitNode.173* %266, null
-  %268 = select i1 %267, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.102, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.103 to %struct.InitNode.173*), %struct.InitNode.173** %268, align 8, !tbaa !3
-  %269 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %270 = icmp eq %struct.InitNode.173* %269, null
-  %271 = select i1 %270, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.103, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.104 to %struct.InitNode.173*), %struct.InitNode.173** %271, align 8, !tbaa !3
-  %272 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %259 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %260 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %259, i64 0, i32 1
+  %261 = select i1 %258, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %260
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.66 to %struct.InitNode.173*), %struct.InitNode.173** %261, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.66 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %262 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %263 = icmp eq %struct.InitNode.173* %262, null
+  %264 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %265 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %264, i64 0, i32 1
+  %266 = select i1 %263, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %265
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.67 to %struct.InitNode.173*), %struct.InitNode.173** %266, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.67 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %267 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %268 = icmp eq %struct.InitNode.173* %267, null
+  %269 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %270 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %269, i64 0, i32 1
+  %271 = select i1 %268, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %270
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.68 to %struct.InitNode.173*), %struct.InitNode.173** %271, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.68 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %272 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %273 = icmp eq %struct.InitNode.173* %272, null
-  %274 = select i1 %273, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.104, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.105 to %struct.InitNode.173*), %struct.InitNode.173** %274, align 8, !tbaa !3
-  %275 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %276 = icmp eq %struct.InitNode.173* %275, null
-  %277 = select i1 %276, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.105, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.106 to %struct.InitNode.173*), %struct.InitNode.173** %277, align 8, !tbaa !3
-  %278 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %279 = icmp eq %struct.InitNode.173* %278, null
-  %280 = select i1 %279, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.106, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.107 to %struct.InitNode.173*), %struct.InitNode.173** %280, align 8, !tbaa !3
-  %281 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %282 = icmp eq %struct.InitNode.173* %281, null
-  %283 = select i1 %282, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.107, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.108 to %struct.InitNode.173*), %struct.InitNode.173** %283, align 8, !tbaa !3
-  %284 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %285 = icmp eq %struct.InitNode.173* %284, null
-  %286 = select i1 %285, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.108, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.109 to %struct.InitNode.173*), %struct.InitNode.173** %286, align 8, !tbaa !3
-  %287 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
+  %274 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %275 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %274, i64 0, i32 1
+  %276 = select i1 %273, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %275
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.69 to %struct.InitNode.173*), %struct.InitNode.173** %276, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.69 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %277 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %278 = icmp eq %struct.InitNode.173* %277, null
+  %279 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %280 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %279, i64 0, i32 1
+  %281 = select i1 %278, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %280
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.70 to %struct.InitNode.173*), %struct.InitNode.173** %281, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.70 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %282 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %283 = icmp eq %struct.InitNode.173* %282, null
+  %284 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %285 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %284, i64 0, i32 1
+  %286 = select i1 %283, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %285
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.71 to %struct.InitNode.173*), %struct.InitNode.173** %286, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.71 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %287 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %288 = icmp eq %struct.InitNode.173* %287, null
-  %289 = select i1 %288, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.109, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.110 to %struct.InitNode.173*), %struct.InitNode.173** %289, align 8, !tbaa !3
+  %289 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %290 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %289, i64 0, i32 1
+  %291 = select i1 %288, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %290
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.72 to %struct.InitNode.173*), %struct.InitNode.173** %291, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.72 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %292 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %293 = icmp eq %struct.InitNode.173* %292, null
+  %294 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %295 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %294, i64 0, i32 1
+  %296 = select i1 %293, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %295
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.73 to %struct.InitNode.173*), %struct.InitNode.173** %296, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.73 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %297 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %298 = icmp eq %struct.InitNode.173* %297, null
+  %299 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %300 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %299, i64 0, i32 1
+  %301 = select i1 %298, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %300
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.74 to %struct.InitNode.173*), %struct.InitNode.173** %301, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.74 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %302 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %303 = icmp eq %struct.InitNode.173* %302, null
+  %304 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %305 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %304, i64 0, i32 1
+  %306 = select i1 %303, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %305
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.75 to %struct.InitNode.173*), %struct.InitNode.173** %306, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.75 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %307 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %308 = icmp eq %struct.InitNode.173* %307, null
+  %309 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %310 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %309, i64 0, i32 1
+  %311 = select i1 %308, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %310
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.76 to %struct.InitNode.173*), %struct.InitNode.173** %311, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.76 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %312 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %313 = icmp eq %struct.InitNode.173* %312, null
+  %314 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %315 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %314, i64 0, i32 1
+  %316 = select i1 %313, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %315
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.77 to %struct.InitNode.173*), %struct.InitNode.173** %316, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.77 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %317 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %318 = icmp eq %struct.InitNode.173* %317, null
+  %319 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %320 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %319, i64 0, i32 1
+  %321 = select i1 %318, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %320
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.78 to %struct.InitNode.173*), %struct.InitNode.173** %321, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.78 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %322 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %323 = icmp eq %struct.InitNode.173* %322, null
+  %324 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %325 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %324, i64 0, i32 1
+  %326 = select i1 %323, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %325
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.79 to %struct.InitNode.173*), %struct.InitNode.173** %326, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.79 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %327 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %328 = icmp eq %struct.InitNode.173* %327, null
+  %329 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %330 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %329, i64 0, i32 1
+  %331 = select i1 %328, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %330
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.80 to %struct.InitNode.173*), %struct.InitNode.173** %331, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.80 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %332 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %333 = icmp eq %struct.InitNode.173* %332, null
+  %334 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %335 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %334, i64 0, i32 1
+  %336 = select i1 %333, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %335
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.81 to %struct.InitNode.173*), %struct.InitNode.173** %336, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.81 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %337 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %338 = icmp eq %struct.InitNode.173* %337, null
+  %339 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %340 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %339, i64 0, i32 1
+  %341 = select i1 %338, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %340
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.82 to %struct.InitNode.173*), %struct.InitNode.173** %341, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.82 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %342 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %343 = icmp eq %struct.InitNode.173* %342, null
+  %344 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %345 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %344, i64 0, i32 1
+  %346 = select i1 %343, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %345
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.83 to %struct.InitNode.173*), %struct.InitNode.173** %346, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.83 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %347 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %348 = icmp eq %struct.InitNode.173* %347, null
+  %349 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %350 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %349, i64 0, i32 1
+  %351 = select i1 %348, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %350
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.84 to %struct.InitNode.173*), %struct.InitNode.173** %351, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.84 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %352 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %353 = icmp eq %struct.InitNode.173* %352, null
+  %354 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %355 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %354, i64 0, i32 1
+  %356 = select i1 %353, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %355
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.85 to %struct.InitNode.173*), %struct.InitNode.173** %356, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.85 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %357 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %358 = icmp eq %struct.InitNode.173* %357, null
+  %359 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %360 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %359, i64 0, i32 1
+  %361 = select i1 %358, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %360
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.86 to %struct.InitNode.173*), %struct.InitNode.173** %361, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.86 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %362 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %363 = icmp eq %struct.InitNode.173* %362, null
+  %364 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %365 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %364, i64 0, i32 1
+  %366 = select i1 %363, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %365
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.87 to %struct.InitNode.173*), %struct.InitNode.173** %366, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.87 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %367 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %368 = icmp eq %struct.InitNode.173* %367, null
+  %369 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %370 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %369, i64 0, i32 1
+  %371 = select i1 %368, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %370
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.88 to %struct.InitNode.173*), %struct.InitNode.173** %371, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.88 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %372 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %373 = icmp eq %struct.InitNode.173* %372, null
+  %374 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %375 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %374, i64 0, i32 1
+  %376 = select i1 %373, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %375
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.89 to %struct.InitNode.173*), %struct.InitNode.173** %376, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.89 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %377 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %378 = icmp eq %struct.InitNode.173* %377, null
+  %379 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %380 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %379, i64 0, i32 1
+  %381 = select i1 %378, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %380
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.90 to %struct.InitNode.173*), %struct.InitNode.173** %381, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.90 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %382 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %383 = icmp eq %struct.InitNode.173* %382, null
+  %384 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %385 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %384, i64 0, i32 1
+  %386 = select i1 %383, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %385
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.91 to %struct.InitNode.173*), %struct.InitNode.173** %386, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.91 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %387 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %388 = icmp eq %struct.InitNode.173* %387, null
+  %389 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %390 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %389, i64 0, i32 1
+  %391 = select i1 %388, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %390
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.92 to %struct.InitNode.173*), %struct.InitNode.173** %391, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.92 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %392 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %393 = icmp eq %struct.InitNode.173* %392, null
+  %394 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %395 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %394, i64 0, i32 1
+  %396 = select i1 %393, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %395
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.93 to %struct.InitNode.173*), %struct.InitNode.173** %396, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.93 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %397 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %398 = icmp eq %struct.InitNode.173* %397, null
+  %399 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %400 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %399, i64 0, i32 1
+  %401 = select i1 %398, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %400
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.94 to %struct.InitNode.173*), %struct.InitNode.173** %401, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.94 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %402 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %403 = icmp eq %struct.InitNode.173* %402, null
+  %404 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %405 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %404, i64 0, i32 1
+  %406 = select i1 %403, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %405
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.95 to %struct.InitNode.173*), %struct.InitNode.173** %406, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.95 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %407 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %408 = icmp eq %struct.InitNode.173* %407, null
+  %409 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %410 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %409, i64 0, i32 1
+  %411 = select i1 %408, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %410
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.96 to %struct.InitNode.173*), %struct.InitNode.173** %411, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.96 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %412 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %413 = icmp eq %struct.InitNode.173* %412, null
+  %414 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %415 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %414, i64 0, i32 1
+  %416 = select i1 %413, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %415
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.97 to %struct.InitNode.173*), %struct.InitNode.173** %416, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.97 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %417 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %418 = icmp eq %struct.InitNode.173* %417, null
+  %419 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %420 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %419, i64 0, i32 1
+  %421 = select i1 %418, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %420
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.98 to %struct.InitNode.173*), %struct.InitNode.173** %421, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.98 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %422 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %423 = icmp eq %struct.InitNode.173* %422, null
+  %424 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %425 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %424, i64 0, i32 1
+  %426 = select i1 %423, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %425
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.99 to %struct.InitNode.173*), %struct.InitNode.173** %426, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.99 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %427 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %428 = icmp eq %struct.InitNode.173* %427, null
+  %429 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %430 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %429, i64 0, i32 1
+  %431 = select i1 %428, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %430
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.100 to %struct.InitNode.173*), %struct.InitNode.173** %431, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.100 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %432 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %433 = icmp eq %struct.InitNode.173* %432, null
+  %434 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %435 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %434, i64 0, i32 1
+  %436 = select i1 %433, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %435
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.101 to %struct.InitNode.173*), %struct.InitNode.173** %436, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.101 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %437 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %438 = icmp eq %struct.InitNode.173* %437, null
+  %439 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %440 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %439, i64 0, i32 1
+  %441 = select i1 %438, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %440
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.102 to %struct.InitNode.173*), %struct.InitNode.173** %441, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.102 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %442 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %443 = icmp eq %struct.InitNode.173* %442, null
+  %444 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %445 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %444, i64 0, i32 1
+  %446 = select i1 %443, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %445
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.103 to %struct.InitNode.173*), %struct.InitNode.173** %446, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.103 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %447 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %448 = icmp eq %struct.InitNode.173* %447, null
+  %449 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %450 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %449, i64 0, i32 1
+  %451 = select i1 %448, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %450
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.104 to %struct.InitNode.173*), %struct.InitNode.173** %451, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.104 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %452 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %453 = icmp eq %struct.InitNode.173* %452, null
+  %454 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %455 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %454, i64 0, i32 1
+  %456 = select i1 %453, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %455
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.105 to %struct.InitNode.173*), %struct.InitNode.173** %456, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.105 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %457 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %458 = icmp eq %struct.InitNode.173* %457, null
+  %459 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %460 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %459, i64 0, i32 1
+  %461 = select i1 %458, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %460
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.106 to %struct.InitNode.173*), %struct.InitNode.173** %461, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.106 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %462 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %463 = icmp eq %struct.InitNode.173* %462, null
+  %464 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %465 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %464, i64 0, i32 1
+  %466 = select i1 %463, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %465
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.107 to %struct.InitNode.173*), %struct.InitNode.173** %466, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.107 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %467 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %468 = icmp eq %struct.InitNode.173* %467, null
+  %469 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %470 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %469, i64 0, i32 1
+  %471 = select i1 %468, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %470
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.108 to %struct.InitNode.173*), %struct.InitNode.173** %471, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.108 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %472 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %473 = icmp eq %struct.InitNode.173* %472, null
+  %474 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %475 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %474, i64 0, i32 1
+  %476 = select i1 %473, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %475
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.109 to %struct.InitNode.173*), %struct.InitNode.173** %476, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.109 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %477 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %478 = icmp eq %struct.InitNode.173* %477, null
+  %479 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %480 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %479, i64 0, i32 1
+  %481 = select i1 %478, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %480
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.110 to %struct.InitNode.173*), %struct.InitNode.173** %481, align 8, !tbaa !3
   store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.110 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
   br label %call_success
 
 call_success:                                     ; preds = %need_init.i, %entry
-  %.b.i2 = load i1, i1* @_Konan_init_main_guard, align 1
-  br i1 %.b.i2, label %epilogue, label %need_init.i3
+  %482 = load atomic i32, i32* @_Konan_init_main_guard unordered, align 4
+  %483 = icmp eq i32 %482, 0
+  br i1 %483, label %need_init.i2, label %epilogue
 
-need_init.i3:                                     ; preds = %call_success
-  store i1 true, i1* @_Konan_init_main_guard, align 1
-  %290 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %291 = icmp eq %struct.InitNode.173* %290, null
-  %292 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8
-  %293 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %292, i64 0, i32 1
-  %294 = select i1 %291, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %293
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.111 to %struct.InitNode.173*), %struct.InitNode.173** %294, align 8, !tbaa !3
-  %295 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %296 = icmp eq %struct.InitNode.173* %295, null
-  %297 = select i1 %296, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.111, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.112 to %struct.InitNode.173*), %struct.InitNode.173** %297, align 8, !tbaa !3
-  %298 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %299 = icmp eq %struct.InitNode.173* %298, null
-  %300 = select i1 %299, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** bitcast (%struct.InitNode** getelementptr inbounds (%struct.InitNode, %struct.InitNode* @init_node.112, i64 0, i32 1) to %struct.InitNode.173**)
-  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.113 to %struct.InitNode.173*), %struct.InitNode.173** %300, align 8, !tbaa !3
+need_init.i2:                                     ; preds = %call_success
+  store i32 1, i32* @_Konan_init_main_guard, align 4
+  %484 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %485 = icmp eq %struct.InitNode.173* %484, null
+  %486 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %487 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %486, i64 0, i32 1
+  %488 = select i1 %485, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %487
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.111 to %struct.InitNode.173*), %struct.InitNode.173** %488, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.111 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %489 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %490 = icmp eq %struct.InitNode.173* %489, null
+  %491 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %492 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %491, i64 0, i32 1
+  %493 = select i1 %490, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %492
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.112 to %struct.InitNode.173*), %struct.InitNode.173** %493, align 8, !tbaa !3
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.112 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
+  %494 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %495 = icmp eq %struct.InitNode.173* %494, null
+  %496 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE unordered, align 8
+  %497 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %496, i64 0, i32 1
+  %498 = select i1 %495, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, %struct.InitNode.173** %497
+  store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.113 to %struct.InitNode.173*), %struct.InitNode.173** %498, align 8, !tbaa !3
   store %struct.InitNode.173* bitcast (%struct.InitNode* @init_node.113 to %struct.InitNode.173*), %struct.InitNode.173** @_ZN12_GLOBAL__N_112initTailNodeE, align 8, !tbaa !3
   br label %epilogue
 
-epilogue:                                         ; preds = %need_init.i3, %call_success
+epilogue:                                         ; preds = %need_init.i2, %call_success
   ret void
 }
 
@@ -20926,7 +21309,7 @@
 
 10:                                               ; preds = %4, %2
   %11 = getelementptr inbounds %"class.kotlin::RepeatedTimer", %"class.kotlin::RepeatedTimer"* %0, i64 0, i32 2
-  %12 = load i8, i8* %11, align 8, !tbaa !77, !range !72
+  %12 = load atomic i8, i8* %11 unordered, align 8, !tbaa !75, !range !70
   %13 = icmp eq i8 %12, 0
   br i1 %13, label %.loopexit5, label %14
 
@@ -20943,8 +21326,8 @@
   br label %24
 
 24:                                               ; preds = %.loopexit, %14
-  store i8 0, i8* %15, align 8, !tbaa !87
-  %25 = load i64, i64* %16, align 8, !tbaa.struct !88
+  store i8 0, i8* %15, align 8, !tbaa !85
+  %25 = load atomic i64, i64* %16 unordered, align 8, !tbaa.struct !86
   br label %26
 
 26:                                               ; preds = %46, %24
@@ -20964,14 +21347,14 @@
   br label %38
 
 38:                                               ; preds = %43, %29
-  %39 = load i8, i8* %15, align 8, !tbaa !87, !range !72
+  %39 = load atomic i8, i8* %15 unordered, align 8, !tbaa !85, !range !70
   %40 = icmp eq i8 %39, 0
   br i1 %40, label %41, label %.loopexit
 
 41:                                               ; preds = %38
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %17) #37
-  store i64 %35, i64* %18, align 8, !tbaa !90
-  store i64 %37, i64* %19, align 8, !tbaa !92
+  store i64 %35, i64* %18, align 8, !tbaa !88
+  store i64 %37, i64* %19, align 8, !tbaa !90
   %42 = invoke i32 @pthread_cond_timedwait(%union.pthread_cond_t* nonnull %20, %union.pthread_mutex_t* nonnull %21, %"struct.kotlin::gc::MemoryUsage"* nonnull %3)
           to label %43 unwind label %111
 
@@ -20982,7 +21365,7 @@
   br i1 %45, label %38, label %46
 
 46:                                               ; preds = %43
-  %47 = load i8, i8* %15, align 8, !tbaa !87, !range !72
+  %47 = load atomic i8, i8* %15 unordered, align 8, !tbaa !85, !range !70
   %48 = icmp eq i8 %47, 0
   br i1 %48, label %26, label %.loopexit
 
@@ -21000,9 +21383,9 @@
   br label %55
 
 55:                                               ; preds = %53, %52
-  %56 = load %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"*, %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"** %22, align 8, !tbaa !93
+  %56 = load atomic %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"*, %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"** %22 unordered, align 8, !tbaa !91
   %57 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %56, i64 0, i32 2
-  %58 = load %"class.kotlin::mm::AppStateTracking"*, %"class.kotlin::mm::AppStateTracking"** %57, align 8, !tbaa !95
+  %58 = load atomic %"class.kotlin::mm::AppStateTracking"*, %"class.kotlin::mm::AppStateTracking"** %57 unordered, align 8, !tbaa !93
   %59 = getelementptr inbounds %"class.kotlin::mm::AppStateTracking", %"class.kotlin::mm::AppStateTracking"* %58, i64 0, i32 0, i32 0
   %60 = load atomic i32, i32* %59 seq_cst, align 4
   %61 = icmp eq i32 %60, 1
@@ -21013,7 +21396,7 @@
   %64 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %56, i64 0, i32 4, i32 1, i32 0, i32 0, i32 0, i32 0
   %65 = load atomic i64, i64* %64 seq_cst, align 8
   %66 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %56, i64 0, i32 4, i32 0
-  %67 = load %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %66, align 8, !tbaa !102
+  %67 = load atomic %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %66 unordered, align 8, !tbaa !100
   %68 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %67, i64 0, i32 3, i32 0, i32 0
   %69 = load atomic i64, i64* %68 seq_cst, align 8
   %70 = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 %69, i64 1000) #37
@@ -21028,7 +21411,7 @@
 
 78:                                               ; preds = %62
   %79 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %56, i64 0, i32 5, i32 0, i32 1
-  %80 = load i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %79, align 8, !tbaa !103
+  %80 = load atomic i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %79 unordered, align 8, !tbaa !101
   %81 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %80, null
   br i1 %81, label %82, label %84
 
@@ -21041,7 +21424,7 @@
 
 84:                                               ; preds = %78
   %85 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %56, i64 0, i32 5, i32 1
-  %86 = load void (%"union.std::_Any_data"*)*, void (%"union.std::_Any_data"*)** %85, align 8, !tbaa !105
+  %86 = load atomic void (%"union.std::_Any_data"*)*, void (%"union.std::_Any_data"*)** %85 unordered, align 8, !tbaa !103
   %87 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %56, i64 0, i32 5, i32 0, i32 0
   invoke void %86(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %87)
           to label %88 unwind label %100
@@ -21063,13 +21446,13 @@
 
 94:                                               ; preds = %89, %88
   %95 = call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37
-  %96 = load i64, i64* %23, align 8, !tbaa !89
+  %96 = load atomic i64, i64* %23 unordered, align 8, !tbaa !87
   %97 = call i64 @llvm.sadd.sat.i64(i64 %95, i64 %96) #37
-  store i64 %97, i64* %16, align 8, !tbaa.struct !88
+  store i64 %97, i64* %16, align 8, !tbaa.struct !86
   br label %.loopexit
 
 .loopexit:                                        ; preds = %94, %46, %38
-  %98 = load i8, i8* %11, align 8, !tbaa !77, !range !72
+  %98 = load atomic i8, i8* %11 unordered, align 8, !tbaa !75, !range !70
   %99 = icmp eq i8 %98, 0
   br i1 %99, label %.loopexit5, label %24
 
@@ -21118,24 +21501,24 @@
 ; Function Attrs: nounwind uwtable
 define internal void @_ZN6kotlin12ScopedThread3RunIMNS_13RepeatedTimerINS_12steady_clockEEEDoFvOZNS_2gc8internal24GCSchedulerDataWithTimerIS3_EC1ERNS5_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EJPS4_SE_EEENSt13invoke_resultIT_JDpT0_EE4typeENS0_10attributesEOSK_DpOSL_(%"class.kotlin::ScopedThread::attributes"* nocapture readonly %0, { i64, i64 }* nocapture nonnull readonly align 8 dereferenceable(16) %1, %"class.kotlin::RepeatedTimer"** nocapture nonnull readonly align 8 dereferenceable(8) %2, %class.anon* nonnull align 8 dereferenceable(8) %3) #17 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %5 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
-  %6 = load i8, i8* %5, align 8, !tbaa !106, !range !72
+  %6 = load atomic i8, i8* %5 unordered, align 8, !tbaa !104, !range !70
   %7 = icmp eq i8 %6, 0
   br i1 %7, label %_ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit, label %8
 
 8:                                                ; preds = %4
   %9 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %10 = load i8*, i8** %9, align 8, !tbaa !58
+  %10 = load atomic i8*, i8** %9 unordered, align 8, !tbaa !47
   %11 = tail call i64 @pthread_self() #1
   %12 = tail call i32 @pthread_setname_np(i64 %11, i8* %10) #37
   br label %_ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit
 
 _ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit: ; preds = %8, %4
   %13 = bitcast %"class.kotlin::RepeatedTimer"** %2 to i8**
-  %14 = load i8*, i8** %13, align 8, !tbaa !3
+  %14 = load atomic i8*, i8** %13 unordered, align 8, !tbaa !3
   %15 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %1, i64 0, i32 0
-  %16 = load i64, i64* %15, align 8, !tbaa !51
+  %16 = load atomic i64, i64* %15 unordered, align 8, !tbaa !50
   %17 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %1, i64 0, i32 1
-  %18 = load i64, i64* %17, align 8, !tbaa !51
+  %18 = load atomic i64, i64* %17 unordered, align 8, !tbaa !50
   %19 = getelementptr inbounds i8, i8* %14, i64 %18
   %20 = and i64 %16, 1
   %21 = icmp eq i64 %20, 0
@@ -21143,11 +21526,11 @@
 
 22:                                               ; preds = %_ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit
   %23 = bitcast i8* %19 to i8**
-  %24 = load i8*, i8** %23, align 8, !tbaa !109
+  %24 = load atomic i8*, i8** %23 unordered, align 8, !tbaa !107
   %25 = add i64 %16, -1
-  %26 = getelementptr i8, i8* %24, i64 %25, !nosanitize !111
-  %27 = bitcast i8* %26 to void (%"class.kotlin::RepeatedTimer"*, %class.anon*)**, !nosanitize !111
-  %28 = load void (%"class.kotlin::RepeatedTimer"*, %class.anon*)*, void (%"class.kotlin::RepeatedTimer"*, %class.anon*)** %27, align 8, !nosanitize !111
+  %26 = getelementptr i8, i8* %24, i64 %25, !nosanitize !109
+  %27 = bitcast i8* %26 to void (%"class.kotlin::RepeatedTimer"*, %class.anon*)**, !nosanitize !109
+  %28 = load atomic void (%"class.kotlin::RepeatedTimer"*, %class.anon*)*, void (%"class.kotlin::RepeatedTimer"*, %class.anon*)** %27 unordered, align 8, !nosanitize !109
   br label %31
 
 29:                                               ; preds = %_ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit
@@ -21175,15 +21558,15 @@
 ; Function Attrs: inlinehint nounwind uwtable
 define internal void @_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOMNS3_13RepeatedTimerINS3_12steady_clockEEEDoFvOZNS3_2gc8internal24GCSchedulerDataWithTimerIS7_EC1ERNS9_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS8_SJ_ES5_SL_SN_SI_EEEEED2Ev(%"struct.std::thread::_State_impl"* %0) unnamed_addr #19 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %2 = getelementptr %"struct.std::thread::_State_impl", %"struct.std::thread::_State_impl"* %0, i64 0, i32 0, i32 0
-  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOMNS3_13RepeatedTimerINS3_12steady_clockEEEDoFvOZNS3_2gc8internal24GCSchedulerDataWithTimerIS7_EC1ERNS9_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS8_SJ_ES5_SL_SN_SI_EEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !109
+  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOMNS3_13RepeatedTimerINS3_12steady_clockEEEDoFvOZNS3_2gc8internal24GCSchedulerDataWithTimerIS7_EC1ERNS9_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS8_SJ_ES5_SL_SN_SI_EEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !107
   %3 = getelementptr inbounds %"struct.std::thread::_State_impl", %"struct.std::thread::_State_impl"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1
-  %4 = load i8, i8* %3, align 8, !tbaa !112, !range !72
+  %4 = load atomic i8, i8* %3 unordered, align 8, !tbaa !110, !range !70
   %5 = icmp eq i8 %4, 0
   br i1 %5, label %13, label %6
 
 6:                                                ; preds = %1
   %7 = getelementptr inbounds %"struct.std::thread::_State_impl", %"struct.std::thread::_State_impl"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %8 = load i8*, i8** %7, align 8, !tbaa !58
+  %8 = load atomic i8*, i8** %7 unordered, align 8, !tbaa !47
   %9 = getelementptr inbounds %"struct.std::thread::_State_impl", %"struct.std::thread::_State_impl"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %10 = bitcast %union.anon.108* %9 to i8*
   %11 = icmp eq i8* %8, %10
@@ -21202,15 +21585,15 @@
 ; Function Attrs: inlinehint nounwind uwtable
 define internal void @_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOMNS3_13RepeatedTimerINS3_12steady_clockEEEDoFvOZNS3_2gc8internal24GCSchedulerDataWithTimerIS7_EC1ERNS9_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS8_SJ_ES5_SL_SN_SI_EEEEED0Ev(%"struct.std::thread::_State_impl"* %0) unnamed_addr #19 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %2 = getelementptr %"struct.std::thread::_State_impl", %"struct.std::thread::_State_impl"* %0, i64 0, i32 0, i32 0
-  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOMNS3_13RepeatedTimerINS3_12steady_clockEEEDoFvOZNS3_2gc8internal24GCSchedulerDataWithTimerIS7_EC1ERNS9_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS8_SJ_ES5_SL_SN_SI_EEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !109
+  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOMNS3_13RepeatedTimerINS3_12steady_clockEEEDoFvOZNS3_2gc8internal24GCSchedulerDataWithTimerIS7_EC1ERNS9_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS8_SJ_ES5_SL_SN_SI_EEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !107
   %3 = getelementptr inbounds %"struct.std::thread::_State_impl", %"struct.std::thread::_State_impl"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1
-  %4 = load i8, i8* %3, align 8, !tbaa !112, !range !72
+  %4 = load atomic i8, i8* %3 unordered, align 8, !tbaa !110, !range !70
   %5 = icmp eq i8 %4, 0
   br i1 %5, label %13, label %6
 
 6:                                                ; preds = %1
   %7 = getelementptr inbounds %"struct.std::thread::_State_impl", %"struct.std::thread::_State_impl"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %8 = load i8*, i8** %7, align 8, !tbaa !58
+  %8 = load atomic i8*, i8** %7 unordered, align 8, !tbaa !47
   %9 = getelementptr inbounds %"struct.std::thread::_State_impl", %"struct.std::thread::_State_impl"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %10 = bitcast %union.anon.108* %9 to i8*
   %11 = icmp eq i8* %8, %10
@@ -21238,20 +21621,20 @@
   %7 = getelementptr inbounds %"struct.std::thread::_State_impl", %"struct.std::thread::_State_impl"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
   %8 = bitcast %"class.kotlin::ScopedThread::attributes"* %2 to i8*
   call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %8)
-  %9 = load void (%"class.kotlin::ScopedThread::attributes"*, { i64, i64 }*, %"class.kotlin::RepeatedTimer"**, %class.anon*)*, void (%"class.kotlin::ScopedThread::attributes"*, { i64, i64 }*, %"class.kotlin::RepeatedTimer"**, %class.anon*)** %3, align 8, !tbaa !3
+  %9 = load atomic void (%"class.kotlin::ScopedThread::attributes"*, { i64, i64 }*, %"class.kotlin::RepeatedTimer"**, %class.anon*)*, void (%"class.kotlin::ScopedThread::attributes"*, { i64, i64 }*, %"class.kotlin::RepeatedTimer"**, %class.anon*)** %3 unordered, align 8, !tbaa !3
   %10 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 1
-  store i8 0, i8* %10, align 8, !tbaa !112
+  store i8 0, i8* %10, align 8, !tbaa !110
   %11 = getelementptr inbounds %"struct.std::thread::_State_impl", %"struct.std::thread::_State_impl"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1
-  %12 = load i8, i8* %11, align 8, !tbaa !112, !range !72
+  %12 = load atomic i8, i8* %11 unordered, align 8, !tbaa !110, !range !70
   %13 = icmp eq i8 %12, 0
   br i1 %13, label %34, label %14
 
 14:                                               ; preds = %1
   %15 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %16 = bitcast %"class.kotlin::ScopedThread::attributes"* %2 to %union.anon.108**
-  store %union.anon.108* %15, %union.anon.108** %16, align 8, !tbaa !56
+  store %union.anon.108* %15, %union.anon.108** %16, align 8, !tbaa !45
   %17 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %18 = load i8*, i8** %17, align 8, !tbaa !58
+  %18 = load atomic i8*, i8** %17 unordered, align 8, !tbaa !47
   %19 = getelementptr inbounds %"struct.std::thread::_State_impl", %"struct.std::thread::_State_impl"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %20 = bitcast %union.anon.108* %19 to i8*
   %21 = icmp eq i8* %18, %20
@@ -21264,23 +21647,23 @@
 
 24:                                               ; preds = %14
   %25 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  store i8* %18, i8** %25, align 8, !tbaa !58
+  store i8* %18, i8** %25, align 8, !tbaa !47
   %26 = getelementptr inbounds %"struct.std::thread::_State_impl", %"struct.std::thread::_State_impl"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
-  %27 = load i64, i64* %26, align 8, !tbaa !51
+  %27 = load atomic i64, i64* %26 unordered, align 8, !tbaa !50
   %28 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
-  store i64 %27, i64* %28, align 8, !tbaa !51
+  store i64 %27, i64* %28, align 8, !tbaa !50
   br label %29
 
 29:                                               ; preds = %24, %22
   %30 = getelementptr inbounds %"struct.std::thread::_State_impl", %"struct.std::thread::_State_impl"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  %31 = load i64, i64* %30, align 8, !tbaa !60
+  %31 = load atomic i64, i64* %30 unordered, align 8, !tbaa !51
   %32 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  store i64 %31, i64* %32, align 8, !tbaa !60
+  store i64 %31, i64* %32, align 8, !tbaa !51
   %33 = bitcast %"class.kotlin::ScopedThread::attributes"* %4 to %union.anon.108**
-  store %union.anon.108* %19, %union.anon.108** %33, align 8, !tbaa !58
-  store i64 0, i64* %30, align 8, !tbaa !60
-  store i8 0, i8* %20, align 8, !tbaa !51
-  store i8 1, i8* %10, align 8, !tbaa !112
+  store %union.anon.108* %19, %union.anon.108** %33, align 8, !tbaa !47
+  store i64 0, i64* %30, align 8, !tbaa !51
+  store i8 0, i8* %20, align 8, !tbaa !50
+  store i8 1, i8* %10, align 8, !tbaa !110
   br label %34
 
 34:                                               ; preds = %29, %1
@@ -21288,13 +21671,13 @@
           to label %35 unwind label %45
 
 35:                                               ; preds = %34
-  %36 = load i8, i8* %10, align 8, !tbaa !112, !range !72
+  %36 = load atomic i8, i8* %10 unordered, align 8, !tbaa !110, !range !70
   %37 = icmp eq i8 %36, 0
   br i1 %37, label %_ZNSt6thread8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOMNS2_13RepeatedTimerINS2_12steady_clockEEEDoFvOZNS2_2gc8internal24GCSchedulerDataWithTimerIS6_EC1ERNS8_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS7_SI_ES4_SK_SM_SH_EEE9_M_invokeIJLm0ELm1ELm2ELm3ELm4EEEEDTclsr3stdE8__invokespcl10_S_declvalIXT_EEEEESt12_Index_tupleIJXspT_EEE.exit, label %38
 
 38:                                               ; preds = %35
   %39 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %40 = load i8*, i8** %39, align 8, !tbaa !58
+  %40 = load atomic i8*, i8** %39 unordered, align 8, !tbaa !47
   %41 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %42 = bitcast %union.anon.108* %41 to i8*
   %43 = icmp eq i8* %40, %42
@@ -21307,13 +21690,13 @@
 45:                                               ; preds = %34
   %46 = landingpad { i8*, i32 }
           cleanup
-  %47 = load i8, i8* %10, align 8, !tbaa !112, !range !72
+  %47 = load atomic i8, i8* %10 unordered, align 8, !tbaa !110, !range !70
   %48 = icmp eq i8 %47, 0
   br i1 %48, label %56, label %49
 
 49:                                               ; preds = %45
   %50 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %51 = load i8*, i8** %50, align 8, !tbaa !58
+  %51 = load atomic i8*, i8** %50 unordered, align 8, !tbaa !47
   %52 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %53 = bitcast %union.anon.108* %52 to i8*
   %54 = icmp eq i8* %51, %53
@@ -21345,11 +21728,11 @@
 ; Function Attrs: inlinehint nounwind uwtable
 define internal void @_ZN6kotlin2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEED2Ev(%"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0) unnamed_addr #19 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %2 = getelementptr %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 0, i32 0
-  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVN6kotlin2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !109
+  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVN6kotlin2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !107
   %3 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 6
   tail call fastcc void @_ZN6kotlin13RepeatedTimerINS_12steady_clockEED2Ev(%"class.kotlin::RepeatedTimer"* nonnull %3) #37
   %4 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 5, i32 0, i32 1
-  %5 = load i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %4, align 8, !tbaa !103
+  %5 = load atomic i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %4 unordered, align 8, !tbaa !101
   %6 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %5, null
   br i1 %6, label %13, label %7
 
@@ -21372,11 +21755,11 @@
 ; Function Attrs: inlinehint nounwind uwtable
 define internal void @_ZN6kotlin2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEED0Ev(%"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0) unnamed_addr #19 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %2 = getelementptr %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 0, i32 0
-  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVN6kotlin2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !109
+  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVN6kotlin2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !107
   %3 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 6
   tail call fastcc void @_ZN6kotlin13RepeatedTimerINS_12steady_clockEED2Ev(%"class.kotlin::RepeatedTimer"* nonnull %3) #37
   %4 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 5, i32 0, i32 1
-  %5 = load i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %4, align 8, !tbaa !103
+  %5 = load atomic i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %4 unordered, align 8, !tbaa !101
   %6 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %5, null
   br i1 %6, label %13, label %7
 
@@ -21401,7 +21784,7 @@
 ; Function Attrs: nounwind uwtable
 define internal void @_ZN6kotlin2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEE20UpdateFromThreadDataERNS0_21GCSchedulerThreadDataE(%"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, %"class.kotlin::gc::GCSchedulerThreadData"* nocapture nonnull readonly align 8 dereferenceable(72) %1) unnamed_addr #17 align 2 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
   %3 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %1, i64 0, i32 2
-  %4 = load i64, i64* %3, align 8, !tbaa !113
+  %4 = load atomic i64, i64* %3 unordered, align 8, !tbaa !111
   %5 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 3, i32 1, i32 0, i32 0
   %6 = atomicrmw add i64* %5, i64 %4 seq_cst, align 8
   %7 = load atomic i64, i64* %5 seq_cst, align 8
@@ -21409,7 +21792,7 @@
   %9 = load atomic i64, i64* %8 seq_cst, align 8
   %10 = add i64 %9, %7
   %11 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 3, i32 0
-  %12 = load %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %11, align 8, !tbaa !116
+  %12 = load atomic %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %11 unordered, align 8, !tbaa !114
   %13 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %12, i64 0, i32 4, i32 0, i32 0
   %14 = load atomic i64, i64* %13 seq_cst, align 8
   %15 = icmp ult i64 %10, %14
@@ -21417,7 +21800,7 @@
 
 16:                                               ; preds = %2
   %17 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 5, i32 0, i32 1
-  %18 = load i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %17, align 8, !tbaa !103
+  %18 = load atomic i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %17 unordered, align 8, !tbaa !101
   %19 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %18, null
   br i1 %19, label %20, label %22
 
@@ -21430,7 +21813,7 @@
 
 22:                                               ; preds = %16
   %23 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 5, i32 1
-  %24 = load void (%"union.std::_Any_data"*)*, void (%"union.std::_Any_data"*)** %23, align 8, !tbaa !105
+  %24 = load atomic void (%"union.std::_Any_data"*)*, void (%"union.std::_Any_data"*)** %23 unordered, align 8, !tbaa !103
   %25 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 5, i32 0, i32 0
   invoke void %24(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %25)
           to label %26 unwind label %27
@@ -21454,7 +21837,7 @@
   %4 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 4, i32 1, i32 0, i32 0, i32 0, i32 0
   store atomic i64 %3, i64* %4 seq_cst, align 8
   %5 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 1
-  %6 = load %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %5, align 8, !tbaa !117
+  %6 = load atomic %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %5 unordered, align 8, !tbaa !115
   %7 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %6, i64 0, i32 3, i32 0, i32 0
   %8 = load atomic i64, i64* %7 seq_cst, align 8
   %9 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 6
@@ -21481,14 +21864,14 @@
   %21 = extractvalue { i64, i1 } %17, 0
   %22 = select i1 %18, i64 %20, i64 %21
   %23 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 6, i32 3, i32 0, i32 0
-  store i64 %22, i64* %23, align 8, !tbaa !89
+  store i64 %22, i64* %23, align 8, !tbaa !87
   %24 = tail call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37
-  %25 = load i64, i64* %23, align 8, !tbaa !89
+  %25 = load atomic i64, i64* %23 unordered, align 8, !tbaa !87
   %26 = tail call i64 @llvm.sadd.sat.i64(i64 %24, i64 %25) #37
   %27 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 6, i32 4, i32 0, i32 0, i32 0
-  store i64 %26, i64* %27, align 8, !tbaa.struct !88
+  store i64 %26, i64* %27, align 8, !tbaa.struct !86
   %28 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 6, i32 5
-  store i8 1, i8* %28, align 8, !tbaa !87
+  store i8 1, i8* %28, align 8, !tbaa !85
   br i1 icmp eq (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %_ZN6kotlin13RepeatedTimerINS_12steady_clockEE7restartIlSt5ratioILl1ELl1000000EEEEvNSt6chrono8durationIT_T0_EE.exit, label %29
 
 29:                                               ; preds = %16
@@ -21514,7 +21897,7 @@
   %3 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 3, i32 2, i32 0, i32 0
   store atomic i64 %1, i64* %3 seq_cst, align 8
   %4 = getelementptr inbounds %"class.kotlin::gc::internal::GCSchedulerDataWithTimer", %"class.kotlin::gc::internal::GCSchedulerDataWithTimer"* %0, i64 0, i32 3, i32 0
-  %5 = load %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %4, align 8, !tbaa !116
+  %5 = load atomic %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %4 unordered, align 8, !tbaa !114
   %6 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %5, i64 0, i32 2, i32 0, i32 0
   %7 = load atomic i8, i8* %6 seq_cst, align 1
   %8 = and i8 %7, 1
@@ -21523,7 +21906,7 @@
 
 10:                                               ; preds = %2
   %11 = uitofp i64 %1 to double
-  %12 = load %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %4, align 8, !tbaa !116
+  %12 = load atomic %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %4 unordered, align 8, !tbaa !114
   %13 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %12, i64 0, i32 5
   %14 = bitcast %"struct.std::atomic.4"* %13 to i64*
   %15 = load atomic i64, i64* %14 seq_cst, align 8
@@ -21534,11 +21917,11 @@
   br i1 %19, label %36, label %20
 
 20:                                               ; preds = %10
-  %21 = load %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %4, align 8, !tbaa !116
+  %21 = load atomic %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %4 unordered, align 8, !tbaa !114
   %22 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %21, i64 0, i32 6, i32 0, i32 0
   %23 = load atomic i64, i64* %22 seq_cst, align 8
   %24 = sitofp i64 %23 to double
-  %25 = load %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %4, align 8, !tbaa !116
+  %25 = load atomic %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %4 unordered, align 8, !tbaa !114
   %26 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %25, i64 0, i32 7, i32 0, i32 0
   %27 = load atomic i64, i64* %26 seq_cst, align 8
   %28 = sitofp i64 %27 to double
@@ -21547,7 +21930,7 @@
   %31 = fcmp ogt double %30, %28
   %32 = select i1 %31, double %28, double %30
   %33 = fptosi double %32 to i64
-  %34 = load %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %4, align 8, !tbaa !116
+  %34 = load atomic %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %4 unordered, align 8, !tbaa !114
   %35 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %34, i64 0, i32 4, i32 0, i32 0
   store atomic i64 %33, i64* %35 seq_cst, align 8
   br label %36
@@ -21578,9 +21961,9 @@
 
 8:                                                ; preds = %2, %1
   %9 = getelementptr inbounds %"class.kotlin::RepeatedTimer", %"class.kotlin::RepeatedTimer"* %0, i64 0, i32 2
-  store i8 0, i8* %9, align 8, !tbaa !77
+  store i8 0, i8* %9, align 8, !tbaa !75
   %10 = getelementptr inbounds %"class.kotlin::RepeatedTimer", %"class.kotlin::RepeatedTimer"* %0, i64 0, i32 5
-  store i8 1, i8* %10, align 8, !tbaa !87
+  store i8 1, i8* %10, align 8, !tbaa !85
   %11 = icmp eq %"class.kotlin::RepeatedTimer"* %0, null
   %12 = or i1 %11, icmp eq (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null)
   br i1 %12, label %16, label %13
@@ -21600,7 +21983,7 @@
 
 20:                                               ; preds = %16
   %21 = getelementptr inbounds %"struct.std::chrono::time_point", %"struct.std::chrono::time_point"* %18, i64 0, i32 0, i32 0, i32 0
-  %22 = load i64, i64* %21, align 8
+  %22 = load atomic i64, i64* %21 unordered, align 8
   %23 = icmp eq i64 %22, 0
   br i1 %23, label %32, label %24
 
@@ -21612,13 +21995,12 @@
   %26 = landingpad { i8*, i32 }
           catch i8* null
   %27 = extractvalue { i8*, i32 } %26, 0
-  %.idx.val = load i64, i64* %21, align 8, !tbaa.struct !88
-  tail call fastcc void @_ZNSt6threadD2Ev(i64 %.idx.val) #37
+  tail call fastcc void @_ZNSt6threadD2Ev(%"struct.std::atomic.0"* nonnull %19) #37
   tail call fastcc void @__clang_call_terminate(i8* %27) #51
   unreachable
 
 28:                                               ; preds = %24
-  %29 = load i64, i64* %21, align 8, !tbaa.struct !88
+  %29 = load atomic i64, i64* %21 unordered, align 8, !tbaa.struct !86
   %30 = icmp eq i64 %29, 0
   br i1 %30, label %32, label %31
 
@@ -21654,41 +22036,42 @@
 declare void @_ZNSt6thread4joinEv(%"struct.std::atomic.0"*) local_unnamed_addr #15
 
 ; Function Attrs: nounwind uwtable
-define internal fastcc void @_ZNSt6threadD2Ev(i64 %.0.0.0.val) unnamed_addr #17 align 2 {
-  %1 = icmp eq i64 %.0.0.0.val, 0
-  br i1 %1, label %3, label %2
+define internal fastcc void @_ZNSt6threadD2Ev(%"struct.std::atomic.0"* nocapture readonly %0) unnamed_addr #17 align 2 {
+  %2 = getelementptr inbounds %"struct.std::atomic.0", %"struct.std::atomic.0"* %0, i64 0, i32 0, i32 0
+  %3 = load atomic i64, i64* %2 unordered, align 8, !tbaa.struct !86
+  %4 = icmp eq i64 %3, 0
+  br i1 %4, label %6, label %5
 
-2:                                                ; preds = %0
+5:                                                ; preds = %1
   tail call void @_ZSt9terminatev() #51
   unreachable
 
-3:                                                ; preds = %0
+6:                                                ; preds = %1
   ret void
 }
 
 ; Function Attrs: nounwind uwtable
 define internal fastcc void @_ZN6kotlin12ScopedThreadD2Ev(%"struct.std::chrono::time_point"* %0) unnamed_addr #17 align 2 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
-  %2 = getelementptr inbounds %"struct.std::chrono::time_point", %"struct.std::chrono::time_point"* %0, i64 0, i32 0, i32 0, i32 0
-  %3 = load i64, i64* %2, align 8
-  %4 = icmp eq i64 %3, 0
-  br i1 %4, label %14, label %5
+  %2 = getelementptr inbounds %"struct.std::chrono::time_point", %"struct.std::chrono::time_point"* %0, i64 0, i32 0
+  %3 = getelementptr inbounds %"struct.std::chrono::time_point", %"struct.std::chrono::time_point"* %0, i64 0, i32 0, i32 0, i32 0
+  %4 = load atomic i64, i64* %3 unordered, align 8
+  %5 = icmp eq i64 %4, 0
+  br i1 %5, label %14, label %6
 
-5:                                                ; preds = %1
-  %6 = getelementptr inbounds %"struct.std::chrono::time_point", %"struct.std::chrono::time_point"* %0, i64 0, i32 0
-  invoke void @_ZNSt6thread4joinEv(%"struct.std::atomic.0"* %6)
+6:                                                ; preds = %1
+  invoke void @_ZNSt6thread4joinEv(%"struct.std::atomic.0"* %2)
           to label %10 unwind label %7
 
-7:                                                ; preds = %5
+7:                                                ; preds = %6
   %8 = landingpad { i8*, i32 }
           catch i8* null
   %9 = extractvalue { i8*, i32 } %8, 0
-  %.idx.val = load i64, i64* %2, align 8, !tbaa.struct !88
-  tail call fastcc void @_ZNSt6threadD2Ev(i64 %.idx.val) #37
+  tail call fastcc void @_ZNSt6threadD2Ev(%"struct.std::atomic.0"* %2) #37
   tail call fastcc void @__clang_call_terminate(i8* %9) #51
   unreachable
 
-10:                                               ; preds = %5
-  %11 = load i64, i64* %2, align 8, !tbaa.struct !88
+10:                                               ; preds = %6
+  %11 = load atomic i64, i64* %3 unordered, align 8, !tbaa.struct !86
   %12 = icmp eq i64 %11, 0
   br i1 %12, label %14, label %13
 
@@ -21716,1055 +22099,1156 @@
   %12 = alloca %"struct.std::chrono::time_point", align 8
   %13 = alloca %"class.kotlin::ScopedThread::attributes", align 8
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(32) bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) to i8*), i8 0, i64 32, i1 false) #37
-  store i32 1, i32* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0, i32 0, i32 4), align 8, !tbaa !118
-  store %"class.kotlin::mm::AppStateTracking::Impl"* null, %"class.kotlin::mm::AppStateTracking::Impl"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 2, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !121
+  store i32 1, i32* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0, i32 0, i32 4), align 8, !tbaa !116
+  store %"class.kotlin::mm::AppStateTracking::Impl"* null, %"class.kotlin::mm::AppStateTracking::Impl"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 2, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !119
   call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(24) bitcast (i16* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0, i32 0, i32 5) to i8*), i8 0, i64 24, i1 false)
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !123
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !125
-  store i64 0, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !126
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !123
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !125
-  store i64 0, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !126
-  store i8 0, i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 2, i32 0, i32 0, i32 0), align 8, !tbaa !128
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !123
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !125
-  store i64 0, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !126
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !123
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !125
-  store i64 0, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !126
-  store i8 0, i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 2, i32 0, i32 0, i32 0), align 8, !tbaa !128
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !123
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !125
-  store i64 0, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !126
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !123
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !125
-  store i64 0, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !126
-  store i8 0, i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 2, i32 0, i32 0, i32 0), align 8, !tbaa !128
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !121
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !123
+  store i64 0, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !124
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !121
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !123
+  store i64 0, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !124
+  store i8 0, i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 2, i32 0, i32 0, i32 0), align 8, !tbaa !126
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !121
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !123
+  store i64 0, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !124
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !121
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !123
+  store i64 0, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !124
+  store i8 0, i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 2, i32 0, i32 0, i32 0), align 8, !tbaa !126
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !121
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !123
+  store i64 0, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !124
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !121
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !123
+  store i64 0, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !124
+  store i8 0, i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 2, i32 0, i32 0, i32 0), align 8, !tbaa !126
   %14 = tail call noalias dereferenceable_or_null(512) i8* @calloc(i64 1, i64 512) #37
   %15 = getelementptr inbounds i8, i8* %14, i64 8
   %16 = getelementptr inbounds i8, i8* %14, i64 16
-  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(33) %16, i8 0, i64 33, i1 false) #37, !noalias !130
+  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(33) %16, i8 0, i64 33, i1 false) #37, !noalias !128
   %17 = getelementptr inbounds i8, i8* %14, i64 56
   %18 = bitcast i8* %17 to i32*
-  store i32 100000, i32* %18, align 4, !tbaa !135, !noalias !130
+  store i32 100000, i32* %18, align 4, !tbaa !133, !noalias !128
   %19 = getelementptr inbounds i8, i8* %14, i64 64
   %20 = bitcast i8* %19 to i64*
-  store i64 10240, i64* %20, align 8, !tbaa !137, !noalias !130
+  store i64 10240, i64* %20, align 8, !tbaa !135, !noalias !128
   %21 = getelementptr inbounds i8, i8* %14, i64 72
-  store i8 1, i8* %21, align 1, !tbaa !139, !noalias !130
+  store i8 1, i8* %21, align 1, !tbaa !137, !noalias !128
   %22 = getelementptr inbounds i8, i8* %14, i64 80
   %23 = bitcast i8* %22 to <2 x i64>*
-  store <2 x i64> <i64 10000000, i64 1048576>, <2 x i64>* %23, align 8, !tbaa !137, !noalias !130
+  store <2 x i64> <i64 10000000, i64 1048576>, <2 x i64>* %23, align 8, !tbaa !135, !noalias !128
   %24 = getelementptr inbounds i8, i8* %14, i64 96
   %25 = bitcast i8* %24 to double*
-  store double 5.000000e-01, double* %25, align 8, !tbaa !141, !noalias !130
+  store double 5.000000e-01, double* %25, align 8, !tbaa !139, !noalias !128
   %26 = getelementptr inbounds i8, i8* %14, i64 104
   %27 = bitcast i8* %26 to <2 x i64>*
-  store <2 x i64> <i64 1048576, i64 9223372036854775807>, <2 x i64>* %27, align 8, !tbaa !137, !noalias !130
+  store <2 x i64> <i64 1048576, i64 9223372036854775807>, <2 x i64>* %27, align 8, !tbaa !135, !noalias !128
   %28 = getelementptr inbounds i8, i8* %14, i64 160
   %29 = bitcast %"class.std::function"* %11 to i8*
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %29) #37
   %30 = bitcast i8* %28 to i8**
-  store i8* %15, i8** %30, align 8, !tbaa !3, !noalias !130
+  store i8* %15, i8** %30, align 8, !tbaa !3, !noalias !128
   %31 = getelementptr inbounds i8, i8* %14, i64 168
   %32 = bitcast i8* %31 to %"class.kotlin::gc::GCScheduler"**
   %33 = bitcast i8* %31 to i8**
-  store i8* %17, i8** %33, align 8, !tbaa !3, !noalias !130
+  store i8* %17, i8** %33, align 8, !tbaa !3, !noalias !128
   %34 = getelementptr inbounds i8, i8* %14, i64 176
   %35 = getelementptr inbounds i8, i8* %14, i64 224
-  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(48) %34, i8 0, i64 48, i1 false) #37, !noalias !130
+  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(48) %34, i8 0, i64 48, i1 false) #37, !noalias !128
   %36 = bitcast i8* %35 to i8**
-  store i8* %34, i8** %36, align 8, !tbaa !3, !noalias !130
+  store i8* %34, i8** %36, align 8, !tbaa !3, !noalias !128
   %37 = getelementptr inbounds i8, i8* %14, i64 232
   %38 = bitcast i8* %37 to %"class.std::condition_variable"*
-  tail call void @_ZNSt18condition_variableC1Ev(%"class.std::condition_variable"* nonnull %38) #37, !noalias !130
+  tail call void @_ZNSt18condition_variableC1Ev(%"class.std::condition_variable"* nonnull %38) #37, !noalias !128
   %39 = getelementptr inbounds i8, i8* %14, i64 280
   %40 = bitcast i8* %39 to i64*
-  store i64 0, i64* %40, align 8, !tbaa !144, !noalias !130
+  store i64 0, i64* %40, align 8, !tbaa !142, !noalias !128
   %41 = getelementptr inbounds i8, i8* %14, i64 288
   %42 = bitcast i8* %41 to i8**
-  store i8* %34, i8** %42, align 8, !tbaa !3, !noalias !130
+  store i8* %34, i8** %42, align 8, !tbaa !3, !noalias !128
   %43 = getelementptr inbounds i8, i8* %14, i64 296
   %44 = bitcast i8* %43 to %"class.std::condition_variable"*
-  tail call void @_ZNSt18condition_variableC1Ev(%"class.std::condition_variable"* nonnull %44) #37, !noalias !130
+  tail call void @_ZNSt18condition_variableC1Ev(%"class.std::condition_variable"* nonnull %44) #37, !noalias !128
   %45 = getelementptr inbounds i8, i8* %14, i64 344
   %46 = bitcast i8* %45 to i64*
-  store i64 0, i64* %46, align 8, !tbaa !144, !noalias !130
+  store i64 0, i64* %46, align 8, !tbaa !142, !noalias !128
   %47 = getelementptr inbounds i8, i8* %14, i64 352
   %48 = bitcast i8* %47 to i8**
-  store i8* %34, i8** %48, align 8, !tbaa !3, !noalias !130
+  store i8* %34, i8** %48, align 8, !tbaa !3, !noalias !128
   %49 = getelementptr inbounds i8, i8* %14, i64 360
   %50 = bitcast i8* %49 to %"class.std::condition_variable"*
-  tail call void @_ZNSt18condition_variableC1Ev(%"class.std::condition_variable"* nonnull %50) #37, !noalias !130
+  tail call void @_ZNSt18condition_variableC1Ev(%"class.std::condition_variable"* nonnull %50) #37, !noalias !128
   %51 = getelementptr inbounds i8, i8* %14, i64 408
   %52 = bitcast i8* %51 to i64*
-  store i64 0, i64* %52, align 8, !tbaa !144, !noalias !130
+  store i64 0, i64* %52, align 8, !tbaa !142, !noalias !128
   %53 = getelementptr inbounds i8, i8* %14, i64 416
   %54 = bitcast i8* %53 to i8**
-  store i8* %34, i8** %54, align 8, !tbaa !3, !noalias !130
+  store i8* %34, i8** %54, align 8, !tbaa !3, !noalias !128
   %55 = getelementptr inbounds i8, i8* %14, i64 424
   %56 = bitcast i8* %55 to %"class.std::condition_variable"*
-  tail call void @_ZNSt18condition_variableC1Ev(%"class.std::condition_variable"* nonnull %56) #37, !noalias !130
+  tail call void @_ZNSt18condition_variableC1Ev(%"class.std::condition_variable"* nonnull %56) #37, !noalias !128
   %57 = getelementptr inbounds i8, i8* %14, i64 472
-  store i8 0, i8* %57, align 8, !tbaa !146, !noalias !130
+  store i8 0, i8* %57, align 8, !tbaa !144, !noalias !128
   %58 = getelementptr inbounds i8, i8* %14, i64 480
   %59 = bitcast i8* %58 to i64*
-  store i64 0, i64* %59, align 8, !tbaa !148, !noalias !130
+  store i64 0, i64* %59, align 8, !tbaa !146, !noalias !128
   %60 = getelementptr inbounds i8, i8* %14, i64 488
   %61 = ptrtoint i8* %28 to i64
-  %62 = tail call noalias dereferenceable_or_null(312) i8* @calloc(i64 1, i64 312) #37, !noalias !130
+  %62 = tail call noalias dereferenceable_or_null(312) i8* @calloc(i64 1, i64 312) #37, !noalias !128
   %63 = getelementptr inbounds i8, i8* %62, i64 16
-  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %63, i8 0, i64 24, i1 false) #37, !noalias !149
+  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %63, i8 0, i64 24, i1 false) #37, !noalias !147
   %64 = getelementptr inbounds i8, i8* %62, i64 40
   %65 = bitcast i8* %64 to %"class.std::condition_variable"*
-  tail call void @_ZNSt18condition_variableC1Ev(%"class.std::condition_variable"* nonnull %65) #37, !noalias !149
+  tail call void @_ZNSt18condition_variableC1Ev(%"class.std::condition_variable"* nonnull %65) #37, !noalias !147
   %66 = getelementptr inbounds i8, i8* %62, i64 88
-  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %66, i8 0, i64 40, i1 false) #37, !noalias !149
+  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %66, i8 0, i64 40, i1 false) #37, !noalias !147
   %67 = getelementptr inbounds i8, i8* %62, i64 144
   %68 = getelementptr inbounds i8, i8* %62, i64 128
   %69 = bitcast i8* %68 to i64*
-  store i64 %61, i64* %69, align 8, !tbaa.struct !154, !noalias !149
+  store i64 %61, i64* %69, align 8, !tbaa.struct !152, !noalias !147
   %70 = bitcast i8* %67 to i64*
-  store i64 ptrtoint (i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* @"_ZNSt14_Function_base13_Base_managerIZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS1_2mm13ObjectFactoryIS3_EERNS2_11GCSchedulerEE3$_1E10_M_managerERSt9_Any_dataRKSC_St18_Manager_operation" to i64), i64* %70, align 8, !tbaa !3, !noalias !149
+  store i64 ptrtoint (i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* @"_ZNSt14_Function_base13_Base_managerIZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS1_2mm13ObjectFactoryIS3_EERNS2_11GCSchedulerEE3$_1E10_M_managerERSt9_Any_dataRKSC_St18_Manager_operation" to i64), i64* %70, align 8, !tbaa !3, !noalias !147
   %71 = getelementptr inbounds i8, i8* %62, i64 152
   %72 = bitcast i8* %71 to i64*
-  store i64 ptrtoint (void (%"union.std::_Any_data"*, i64*)* @"_ZNSt17_Function_handlerIFvlEZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS1_2mm13ObjectFactoryIS3_EERNS2_11GCSchedulerEE3$_1E9_M_invokeERKSt9_Any_dataOl" to i64), i64* %72, align 8, !tbaa !3, !noalias !149
+  store i64 ptrtoint (void (%"union.std::_Any_data"*, i64*)* @"_ZNSt17_Function_handlerIFvlEZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS1_2mm13ObjectFactoryIS3_EERNS2_11GCSchedulerEE3$_1E9_M_invokeERKSt9_Any_dataOl" to i64), i64* %72, align 8, !tbaa !3, !noalias !147
   %73 = getelementptr inbounds i8, i8* %62, i64 160
   %74 = bitcast i8* %73 to i64*
-  store i64 0, i64* %74, align 8, !tbaa !155, !noalias !149
+  store i64 0, i64* %74, align 8, !tbaa !153, !noalias !147
   %75 = getelementptr inbounds i8, i8* %62, i64 168
-  store i8 0, i8* %75, align 8, !tbaa !163, !noalias !149
+  store i8 0, i8* %75, align 8, !tbaa !161, !noalias !147
   %76 = getelementptr inbounds i8, i8* %62, i64 169
-  store i8 1, i8* %76, align 1, !tbaa !164, !noalias !149
+  store i8 1, i8* %76, align 1, !tbaa !162, !noalias !147
   %77 = getelementptr inbounds i8, i8* %62, i64 176
-  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %77, i8 0, i64 40, i1 false) #37, !noalias !149
+  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %77, i8 0, i64 40, i1 false) #37, !noalias !147
   %78 = getelementptr inbounds i8, i8* %62, i64 216
   %79 = bitcast i8* %78 to %"class.std::condition_variable"*
-  tail call void @_ZNSt18condition_variableC1Ev(%"class.std::condition_variable"* nonnull %79) #37, !noalias !149
+  tail call void @_ZNSt18condition_variableC1Ev(%"class.std::condition_variable"* nonnull %79) #37, !noalias !147
   %80 = getelementptr inbounds i8, i8* %62, i64 264
-  store i8 0, i8* %80, align 8, !tbaa !165, !noalias !149
+  store i8 0, i8* %80, align 8, !tbaa !163, !noalias !147
   %81 = getelementptr inbounds i8, i8* %62, i64 272
-  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %81, i8 0, i64 40, i1 false) #37, !noalias !149
+  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %81, i8 0, i64 40, i1 false) #37, !noalias !147
   %82 = ptrtoint i8* %62 to i64
   %83 = bitcast i8* %60 to i64*
-  store i64 %82, i64* %83, align 8, !tbaa !166, !alias.scope !168, !noalias !130
+  store i64 %82, i64* %83, align 8, !tbaa !164, !alias.scope !166, !noalias !128
   %84 = getelementptr inbounds i8, i8* %14, i64 496
   %85 = bitcast i8* %84 to i64*
-  store atomic i64 ptrtoint ([8 x i8]* @_ZN6kotlin22intrusive_forward_listINS_2gc22ConcurrentMarkAndSweep10ObjectDataENS_33DefaultIntrusiveForwardListTraitsIS3_EEE12tailStorage_E to i64), i64* %85 monotonic, align 8, !noalias !130
-  %86 = load %"class.kotlin::gc::GCScheduler"*, %"class.kotlin::gc::GCScheduler"** %32, align 8, !tbaa !169, !noalias !130
+  store atomic i64 ptrtoint ([8 x i8]* @_ZN6kotlin22intrusive_forward_listINS_2gc22ConcurrentMarkAndSweep10ObjectDataENS_33DefaultIntrusiveForwardListTraitsIS3_EEE12tailStorage_E to i64), i64* %85 monotonic, align 8, !noalias !128
+  %86 = load atomic %"class.kotlin::gc::GCScheduler"*, %"class.kotlin::gc::GCScheduler"** %32 unordered, align 8, !tbaa !167, !noalias !128
   %87 = getelementptr inbounds %"class.std::function", %"class.std::function"* %11, i64 0, i32 0, i32 1
   %88 = getelementptr inbounds %"class.std::function", %"class.std::function"* %11, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  store i64 %61, i64* %88, align 8, !tbaa !3, !noalias !130
+  store i64 %61, i64* %88, align 8, !tbaa !3, !noalias !128
   %89 = getelementptr inbounds %"class.std::function", %"class.std::function"* %11, i64 0, i32 1
-  store void (%"union.std::_Any_data"*)* @"_ZNSt17_Function_handlerIFvvEZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS1_2mm13ObjectFactoryIS3_EERNS2_11GCSchedulerEE3$_2E9_M_invokeERKSt9_Any_data", void (%"union.std::_Any_data"*)** %89, align 8, !tbaa !105, !noalias !130
-  store i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* @"_ZNSt14_Function_base13_Base_managerIZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS1_2mm13ObjectFactoryIS3_EERNS2_11GCSchedulerEE3$_2E10_M_managerERSt9_Any_dataRKSC_St18_Manager_operation", i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %87, align 8, !tbaa !103, !noalias !130
+  store void (%"union.std::_Any_data"*)* @"_ZNSt17_Function_handlerIFvvEZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS1_2mm13ObjectFactoryIS3_EERNS2_11GCSchedulerEE3$_2E9_M_invokeERKSt9_Any_data", void (%"union.std::_Any_data"*)** %89, align 8, !tbaa !103, !noalias !128
+  store i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* @"_ZNSt14_Function_base13_Base_managerIZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS1_2mm13ObjectFactoryIS3_EERNS2_11GCSchedulerEE3$_2E10_M_managerERSt9_Any_dataRKSC_St18_Manager_operation", i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %87, align 8, !tbaa !101, !noalias !128
   %90 = bitcast %"class.std::function"* %8 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %90) #37, !noalias !130
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %90) #37, !noalias !128
   %91 = getelementptr inbounds %"class.kotlin::gc::GCScheduler", %"class.kotlin::gc::GCScheduler"* %86, i64 0, i32 2
   %92 = bitcast %"class.std::function"* %7 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %92) #37, !noalias !130
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %92) #37, !noalias !128
   %93 = getelementptr inbounds %"class.std::function", %"class.std::function"* %7, i64 0, i32 0, i32 1
   %94 = bitcast i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %87 to i64*
   %95 = bitcast i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %87 to <2 x i64>*
-  %96 = load <2 x i64>, <2 x i64>* %95, align 8, !tbaa !3, !noalias !130
-  store i64 0, i64* %94, align 8, !tbaa !3, !noalias !130
+  %96 = load <2 x i64>, <2 x i64>* %95, align 8, !tbaa !3, !noalias !128
+  store i64 0, i64* %94, align 8, !tbaa !3, !noalias !128
   %97 = bitcast %"class.std::function"* %91 to i8*
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %92, i8* nonnull align 8 dereferenceable(16) %97, i64 16, i1 false) #37, !tbaa.struct !154, !noalias !130
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %92, i8* nonnull align 8 dereferenceable(16) %97, i64 16, i1 false) #37, !tbaa.struct !152, !noalias !128
   call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %97, i8* nonnull align 8 dereferenceable(16) %29, i64 16, i1 false)
   %98 = getelementptr inbounds %"class.kotlin::gc::GCScheduler", %"class.kotlin::gc::GCScheduler"* %86, i64 0, i32 2, i32 0, i32 1
   %99 = bitcast i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %98 to <2 x i64>*
-  %100 = load <2 x i64>, <2 x i64>* %99, align 8, !tbaa !3, !noalias !130
+  %100 = load <2 x i64>, <2 x i64>* %99, align 8, !tbaa !3, !noalias !128
   %101 = bitcast i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %93 to <2 x i64>*
-  store <2 x i64> %100, <2 x i64>* %101, align 8, !tbaa !3, !noalias !130
-  store <2 x i64> %96, <2 x i64>* %99, align 8, !tbaa !3, !noalias !130
+  store <2 x i64> %100, <2 x i64>* %101, align 8, !tbaa !3, !noalias !128
+  store <2 x i64> %96, <2 x i64>* %99, align 8, !tbaa !3, !noalias !128
   %102 = extractelement <2 x i64> %100, i32 0
   %103 = icmp eq i64 %102, 0
-  %104 = extractelement <2 x i64> %96, i32 0
-  %105 = inttoptr i64 %104 to i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*
-  br i1 %103, label %113, label %106
-
-106:                                              ; preds = %0
-  %107 = inttoptr i64 %102 to i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*
-  %108 = getelementptr inbounds %"class.std::function", %"class.std::function"* %7, i64 0, i32 0, i32 0
-  %109 = invoke zeroext i1 %107(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %108, %"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %108, i32 3)
-          to label %._crit_edge unwind label %110, !noalias !130
+  br i1 %103, label %111, label %104
 
-._crit_edge:                                      ; preds = %106
-  %.pre = load i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %98, align 8, !tbaa !103, !noalias !130
-  br label %113
+104:                                              ; preds = %0
+  %105 = inttoptr i64 %102 to i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*
+  %106 = getelementptr inbounds %"class.std::function", %"class.std::function"* %7, i64 0, i32 0, i32 0
+  %107 = invoke zeroext i1 %105(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %106, %"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %106, i32 3)
+          to label %111 unwind label %108, !noalias !128
 
-110:                                              ; preds = %106
-  %111 = landingpad { i8*, i32 }
+108:                                              ; preds = %104
+  %109 = landingpad { i8*, i32 }
           catch i8* null
-  %112 = extractvalue { i8*, i32 } %111, 0
-  call fastcc void @__clang_call_terminate(i8* %112) #51, !noalias !130
+  %110 = extractvalue { i8*, i32 } %109, 0
+  call fastcc void @__clang_call_terminate(i8* %110) #51, !noalias !128
   unreachable
 
-113:                                              ; preds = %._crit_edge, %0
-  %114 = phi i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* [ %.pre, %._crit_edge ], [ %105, %0 ]
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %92) #37, !noalias !130
-  %115 = getelementptr inbounds %"class.std::function", %"class.std::function"* %8, i64 0, i32 0, i32 1
-  store i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* null, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %115, align 8, !tbaa !103, !noalias !130
-  %116 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %114, null
-  br i1 %116, label %._crit_edge14, label %117
+111:                                              ; preds = %104, %0
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %92) #37, !noalias !128
+  %112 = getelementptr inbounds %"class.std::function", %"class.std::function"* %8, i64 0, i32 0, i32 1
+  store i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* null, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %112, align 8, !tbaa !101, !noalias !128
+  %113 = load atomic i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %98 unordered, align 8, !tbaa !101, !noalias !128
+  %114 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %113, null
+  br i1 %114, label %._crit_edge, label %115
 
-._crit_edge14:                                    ; preds = %113
-  %.phi.trans.insert = bitcast i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %115 to <2 x i64>*
-  %.pre15 = load <2 x i64>, <2 x i64>* %.phi.trans.insert, align 8, !tbaa !3, !noalias !130
-  br label %133
+._crit_edge:                                      ; preds = %111
+  %.phi.trans.insert = bitcast i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %112 to <2 x i64>*
+  %.pre = load <2 x i64>, <2 x i64>* %.phi.trans.insert, align 8, !tbaa !3, !noalias !128
+  br label %131
 
-117:                                              ; preds = %113
-  %118 = getelementptr inbounds %"class.std::function", %"class.std::function"* %8, i64 0, i32 0, i32 0
-  %119 = getelementptr inbounds %"class.std::function", %"class.std::function"* %91, i64 0, i32 0, i32 0
-  %120 = invoke zeroext i1 %114(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %118, %"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %119, i32 2)
-          to label %121 unwind label %124, !noalias !130
+115:                                              ; preds = %111
+  %116 = getelementptr inbounds %"class.std::function", %"class.std::function"* %8, i64 0, i32 0, i32 0
+  %117 = getelementptr inbounds %"class.std::function", %"class.std::function"* %91, i64 0, i32 0, i32 0
+  %118 = invoke zeroext i1 %113(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %116, %"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %117, i32 2)
+          to label %119 unwind label %122, !noalias !128
 
-121:                                              ; preds = %117
-  %122 = load <2 x i64>, <2 x i64>* %99, align 8, !tbaa !3, !noalias !130
-  %123 = bitcast i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %115 to <2 x i64>*
-  store <2 x i64> %122, <2 x i64>* %123, align 8, !tbaa !3, !noalias !130
-  br label %133
+119:                                              ; preds = %115
+  %120 = load <2 x i64>, <2 x i64>* %99, align 8, !tbaa !3, !noalias !128
+  %121 = bitcast i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %112 to <2 x i64>*
+  store <2 x i64> %120, <2 x i64>* %121, align 8, !tbaa !3, !noalias !128
+  br label %131
 
-124:                                              ; preds = %117
-  %125 = landingpad { i8*, i32 }
+122:                                              ; preds = %115
+  %123 = landingpad { i8*, i32 }
           catch i8* null
-  %126 = load i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %115, align 8, !tbaa !103, !noalias !130
-  %127 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %126, null
-  br i1 %127, label %334, label %128
+  %124 = load atomic i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %112 unordered, align 8, !tbaa !101, !noalias !128
+  %125 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %124, null
+  br i1 %125, label %363, label %126
 
-128:                                              ; preds = %124
-  %129 = invoke zeroext i1 %126(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %118, %"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %118, i32 3)
-          to label %334 unwind label %130, !noalias !130
+126:                                              ; preds = %122
+  %127 = invoke zeroext i1 %124(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %116, %"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %116, i32 3)
+          to label %363 unwind label %128, !noalias !128
 
-130:                                              ; preds = %128
-  %131 = landingpad { i8*, i32 }
+128:                                              ; preds = %126
+  %129 = landingpad { i8*, i32 }
           catch i8* null
-  %132 = extractvalue { i8*, i32 } %131, 0
-  call fastcc void @__clang_call_terminate(i8* %132) #51, !noalias !130
+  %130 = extractvalue { i8*, i32 } %129, 0
+  call fastcc void @__clang_call_terminate(i8* %130) #51, !noalias !128
   unreachable
 
-133:                                              ; preds = %121, %._crit_edge14
-  %134 = phi <2 x i64> [ %.pre15, %._crit_edge14 ], [ %122, %121 ]
-  %135 = getelementptr inbounds %"class.kotlin::gc::GCScheduler", %"class.kotlin::gc::GCScheduler"* %86, i64 0, i32 0
-  %136 = call noalias dereferenceable_or_null(224) i8* @calloc(i64 1, i64 224) #37, !noalias !130
-  %137 = bitcast %"class.std::function"* %6 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %137) #37, !noalias !130
-  %138 = getelementptr inbounds %"class.std::function", %"class.std::function"* %6, i64 0, i32 0, i32 1
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %137, i8* nonnull align 8 dereferenceable(16) %90, i64 16, i1 false) #37, !noalias !130
-  %139 = bitcast i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %115 to i64*
-  %140 = bitcast i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %138 to i64*
-  store i64 0, i64* %139, align 8, !tbaa !3, !noalias !130
-  %141 = getelementptr inbounds %"class.std::function", %"class.std::function"* %6, i64 0, i32 1
-  %142 = bitcast void (%"union.std::_Any_data"*)** %141 to i64*
-  %143 = bitcast i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %138 to <2 x i64>*
-  store <2 x i64> %134, <2 x i64>* %143, align 8, !tbaa !3, !noalias !130
-  %144 = bitcast i8* %136 to i32 (...)***
-  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVN6kotlin2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %144, align 8, !tbaa !109, !noalias !130
-  %145 = getelementptr inbounds i8, i8* %136, i64 8
-  %146 = bitcast i8* %145 to %"struct.kotlin::gc::GCSchedulerConfig"**
-  store %"struct.kotlin::gc::GCSchedulerConfig"* %135, %"struct.kotlin::gc::GCSchedulerConfig"** %146, align 8, !tbaa !3, !noalias !130
-  %147 = getelementptr inbounds i8, i8* %136, i64 16
-  %148 = bitcast i8* %147 to %"class.kotlin::mm::AppStateTracking"**
-  store %"class.kotlin::mm::AppStateTracking"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 2), %"class.kotlin::mm::AppStateTracking"** %148, align 8, !tbaa !3, !noalias !130
-  %149 = getelementptr inbounds i8, i8* %136, i64 24
-  %150 = bitcast i8* %149 to %"struct.kotlin::gc::GCSchedulerConfig"**
-  store %"struct.kotlin::gc::GCSchedulerConfig"* %135, %"struct.kotlin::gc::GCSchedulerConfig"** %150, align 8, !tbaa !3, !noalias !130
-  %151 = getelementptr inbounds i8, i8* %136, i64 32
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %151, i8 0, i64 16, i1 false) #37, !noalias !130
-  %152 = getelementptr inbounds i8, i8* %136, i64 48
-  %153 = bitcast i8* %152 to %"struct.kotlin::gc::GCSchedulerConfig"**
-  store %"struct.kotlin::gc::GCSchedulerConfig"* %135, %"struct.kotlin::gc::GCSchedulerConfig"** %153, align 8, !tbaa !3, !noalias !130
-  %154 = call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37, !noalias !130
-  %155 = getelementptr inbounds i8, i8* %136, i64 56
-  %156 = bitcast i8* %155 to i64*
-  store i64 %154, i64* %156, align 8, !tbaa.struct !88, !noalias !130
-  %157 = getelementptr inbounds i8, i8* %136, i64 64
-  %158 = getelementptr inbounds i8, i8* %136, i64 80
-  %159 = bitcast { i64, i64 }* %5 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %159)
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %159, i8* nonnull align 8 dereferenceable(16) %137, i64 16, i1 false) #37, !tbaa.struct !154, !noalias !130
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %137, i8* nonnull align 8 dereferenceable(16) %157, i64 16, i1 false) #37, !tbaa.struct !154, !noalias !130
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %157, i8* nonnull align 8 dereferenceable(16) %159, i64 16, i1 false) #37, !tbaa.struct !154, !noalias !130
-  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %159)
-  %160 = load <2 x i64>, <2 x i64>* %143, align 8, !tbaa !3, !noalias !130
-  store i64 0, i64* %140, align 8, !tbaa !3, !noalias !130
-  %161 = getelementptr inbounds i8, i8* %136, i64 88
-  %162 = bitcast i8* %161 to i64*
-  %163 = load i64, i64* %162, align 8, !tbaa !3, !noalias !130
-  store i64 %163, i64* %142, align 8, !tbaa !3, !noalias !130
-  %164 = bitcast i8* %158 to <2 x i64>*
-  store <2 x i64> %160, <2 x i64>* %164, align 8, !tbaa !3, !noalias !130
-  %165 = load %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %146, align 8, !tbaa !117, !noalias !130
-  %166 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %165, i64 0, i32 3, i32 0, i32 0
-  %167 = load atomic i64, i64* %166 seq_cst, align 8, !noalias !130
-  %168 = getelementptr inbounds i8, i8* %136, i64 96
-  %169 = ptrtoint i8* %136 to i64
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %168, i8 0, i64 40, i1 false) #37, !noalias !130
-  %170 = getelementptr inbounds i8, i8* %136, i64 136
-  %171 = bitcast i8* %170 to %"class.std::condition_variable"*
-  call void @_ZNSt18condition_variableC1Ev(%"class.std::condition_variable"* nonnull %171) #37, !noalias !130
-  %172 = getelementptr inbounds i8, i8* %136, i64 184
-  store i8 1, i8* %172, align 8, !tbaa !77, !noalias !130
-  %173 = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 %167, i64 1000) #37
-  %174 = extractvalue { i64, i1 } %173, 1
-  %175 = icmp sgt i64 %167, -1
-  %176 = select i1 %175, i64 9223372036854775807, i64 -9223372036854775808
-  %177 = extractvalue { i64, i1 } %173, 0
-  %178 = select i1 %174, i64 %176, i64 %177
-  %179 = getelementptr inbounds i8, i8* %136, i64 192
-  %180 = bitcast i8* %179 to i64*
-  store i64 %178, i64* %180, align 8, !noalias !130
-  %181 = call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37, !noalias !130
-  %182 = load i64, i64* %180, align 8, !tbaa !89, !noalias !130
-  %183 = call i64 @llvm.sadd.sat.i64(i64 %181, i64 %182) #37
-  %184 = getelementptr inbounds i8, i8* %136, i64 200
-  %185 = bitcast i8* %184 to i64*
-  store i64 %183, i64* %185, align 8, !noalias !130
-  %186 = getelementptr inbounds i8, i8* %136, i64 208
-  store i8 0, i8* %186, align 8, !tbaa !87, !noalias !130
-  %187 = bitcast %"class.kotlin::ScopedThread::attributes"* %4 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %187) #37, !noalias !130
-  %188 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %4, i64 0, i32 0, i32 0, i32 0, i32 1
-  %189 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
-  %190 = bitcast %"class.kotlin::ScopedThread::attributes"* %4 to %union.anon.108**
-  %191 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  %192 = bitcast i64* %191 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %192, i8 0, i64 32, i1 false) #37, !noalias !130
-  store %union.anon.108* %189, %union.anon.108** %190, align 8, !tbaa !56, !noalias !130
-  %193 = bitcast %union.anon.108* %189 to i8*
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(15) %193, i8* nonnull align 1 dereferenceable(15) getelementptr inbounds ([16 x i8], [16 x i8]* @.str.11.37, i64 0, i64 0), i64 15, i1 false) #37, !noalias !130
-  %194 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  store i64 15, i64* %191, align 8, !tbaa !60, !noalias !130
-  %195 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 1, i64 7
-  store i8 0, i8* %195, align 1, !tbaa !51, !noalias !130
-  store i8 1, i8* %188, align 8, !tbaa !106, !noalias !130
-  %196 = ptrtoint i8* %168 to i64
-  %197 = getelementptr inbounds i8, i8* %136, i64 216
-  %198 = bitcast i8* %197 to %"struct.std::atomic.0"*
-  %199 = bitcast %"class.std::unique_ptr"* %2 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %199) #37, !noalias !130
-  %200 = bitcast i8* %197 to i64*
-  store i64 0, i64* %200, align 8, !tbaa !148, !noalias !130
-  %201 = bitcast %"struct.std::thread::_Invoker"* %3 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %201) #37, !noalias !130
-  %202 = bitcast %"struct.std::thread::_Invoker"* %3 to i64*
-  store i64 %169, i64* %202, align 16, !tbaa !3, !noalias !130
-  %203 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  %204 = bitcast %"struct.std::_Head_base.130"* %203 to i64*
-  store i64 %196, i64* %204, align 8, !tbaa !176, !noalias !130
-  %205 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0
-  %206 = bitcast i64* %205 to <2 x i64>*
-  store <2 x i64> <i64 ptrtoint (void (%"class.kotlin::RepeatedTimer"*, %class.anon*)* @_ZN6kotlin13RepeatedTimerINS_12steady_clockEE3RunIZNS_2gc8internal24GCSchedulerDataWithTimerIS1_EC1ERNS4_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EEvOT_ to i64), i64 0>, <2 x i64>* %206, align 16, !tbaa !178, !noalias !130
+131:                                              ; preds = %119, %._crit_edge
+  %132 = phi <2 x i64> [ %.pre, %._crit_edge ], [ %120, %119 ]
+  %133 = getelementptr inbounds %"class.kotlin::gc::GCScheduler", %"class.kotlin::gc::GCScheduler"* %86, i64 0, i32 0
+  %134 = call noalias dereferenceable_or_null(224) i8* @calloc(i64 1, i64 224) #37, !noalias !128
+  %135 = bitcast %"class.std::function"* %6 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %135) #37, !noalias !128
+  %136 = getelementptr inbounds %"class.std::function", %"class.std::function"* %6, i64 0, i32 0, i32 1
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %135, i8* nonnull align 8 dereferenceable(16) %90, i64 16, i1 false) #37, !noalias !128
+  %137 = bitcast i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %112 to i64*
+  %138 = bitcast i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %136 to i64*
+  store i64 0, i64* %137, align 8, !tbaa !3, !noalias !128
+  %139 = getelementptr inbounds %"class.std::function", %"class.std::function"* %6, i64 0, i32 1
+  %140 = bitcast void (%"union.std::_Any_data"*)** %139 to i64*
+  %141 = bitcast i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %136 to <2 x i64>*
+  store <2 x i64> %132, <2 x i64>* %141, align 8, !tbaa !3, !noalias !128
+  %142 = bitcast i8* %134 to i32 (...)***
+  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [7 x i8*] }, { [7 x i8*] }* @_ZTVN6kotlin2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %142, align 8, !tbaa !107, !noalias !128
+  %143 = getelementptr inbounds i8, i8* %134, i64 8
+  %144 = bitcast i8* %143 to %"struct.kotlin::gc::GCSchedulerConfig"**
+  store %"struct.kotlin::gc::GCSchedulerConfig"* %133, %"struct.kotlin::gc::GCSchedulerConfig"** %144, align 8, !tbaa !3, !noalias !128
+  %145 = getelementptr inbounds i8, i8* %134, i64 16
+  %146 = bitcast i8* %145 to %"class.kotlin::mm::AppStateTracking"**
+  store %"class.kotlin::mm::AppStateTracking"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 2), %"class.kotlin::mm::AppStateTracking"** %146, align 8, !tbaa !3, !noalias !128
+  %147 = getelementptr inbounds i8, i8* %134, i64 24
+  %148 = bitcast i8* %147 to %"struct.kotlin::gc::GCSchedulerConfig"**
+  store %"struct.kotlin::gc::GCSchedulerConfig"* %133, %"struct.kotlin::gc::GCSchedulerConfig"** %148, align 8, !tbaa !3, !noalias !128
+  %149 = getelementptr inbounds i8, i8* %134, i64 32
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %149, i8 0, i64 16, i1 false) #37, !noalias !128
+  %150 = getelementptr inbounds i8, i8* %134, i64 48
+  %151 = bitcast i8* %150 to %"struct.kotlin::gc::GCSchedulerConfig"**
+  store %"struct.kotlin::gc::GCSchedulerConfig"* %133, %"struct.kotlin::gc::GCSchedulerConfig"** %151, align 8, !tbaa !3, !noalias !128
+  %152 = call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37, !noalias !128
+  %153 = getelementptr inbounds i8, i8* %134, i64 56
+  %154 = bitcast i8* %153 to i64*
+  store i64 %152, i64* %154, align 8, !tbaa.struct !86, !noalias !128
+  %155 = getelementptr inbounds i8, i8* %134, i64 64
+  %156 = getelementptr inbounds i8, i8* %134, i64 80
+  %157 = bitcast { i64, i64 }* %5 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %157)
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %157, i8* nonnull align 8 dereferenceable(16) %135, i64 16, i1 false) #37, !tbaa.struct !152, !noalias !128
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %135, i8* nonnull align 8 dereferenceable(16) %155, i64 16, i1 false) #37, !tbaa.struct !152, !noalias !128
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %155, i8* nonnull align 8 dereferenceable(16) %157, i64 16, i1 false) #37, !tbaa.struct !152, !noalias !128
+  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %157)
+  %158 = load <2 x i64>, <2 x i64>* %141, align 8, !tbaa !3, !noalias !128
+  store i64 0, i64* %138, align 8, !tbaa !3, !noalias !128
+  %159 = getelementptr inbounds i8, i8* %134, i64 88
+  %160 = bitcast i8* %159 to i64*
+  %161 = load atomic i64, i64* %160 unordered, align 8, !tbaa !3, !noalias !128
+  store i64 %161, i64* %140, align 8, !tbaa !3, !noalias !128
+  %162 = bitcast i8* %156 to <2 x i64>*
+  store <2 x i64> %158, <2 x i64>* %162, align 8, !tbaa !3, !noalias !128
+  %163 = load atomic %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %144 unordered, align 8, !tbaa !115, !noalias !128
+  %164 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %163, i64 0, i32 3, i32 0, i32 0
+  %165 = load atomic i64, i64* %164 seq_cst, align 8, !noalias !128
+  %166 = getelementptr inbounds i8, i8* %134, i64 96
+  %167 = ptrtoint i8* %134 to i64
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %166, i8 0, i64 40, i1 false) #37, !noalias !128
+  %168 = getelementptr inbounds i8, i8* %134, i64 136
+  %169 = bitcast i8* %168 to %"class.std::condition_variable"*
+  call void @_ZNSt18condition_variableC1Ev(%"class.std::condition_variable"* nonnull %169) #37, !noalias !128
+  %170 = getelementptr inbounds i8, i8* %134, i64 184
+  store i8 1, i8* %170, align 8, !tbaa !75, !noalias !128
+  %171 = call { i64, i1 } @llvm.smul.with.overflow.i64(i64 %165, i64 1000) #37
+  %172 = extractvalue { i64, i1 } %171, 1
+  %173 = icmp sgt i64 %165, -1
+  %174 = select i1 %173, i64 9223372036854775807, i64 -9223372036854775808
+  %175 = extractvalue { i64, i1 } %171, 0
+  %176 = select i1 %172, i64 %174, i64 %175
+  %177 = getelementptr inbounds i8, i8* %134, i64 192
+  %178 = bitcast i8* %177 to i64*
+  store i64 %176, i64* %178, align 8, !noalias !128
+  %179 = call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37, !noalias !128
+  %180 = load atomic i64, i64* %178 unordered, align 8, !tbaa !87, !noalias !128
+  %181 = call i64 @llvm.sadd.sat.i64(i64 %179, i64 %180) #37
+  %182 = getelementptr inbounds i8, i8* %134, i64 200
+  %183 = bitcast i8* %182 to i64*
+  store i64 %181, i64* %183, align 8, !noalias !128
+  %184 = getelementptr inbounds i8, i8* %134, i64 208
+  store i8 0, i8* %184, align 8, !tbaa !85, !noalias !128
+  %185 = bitcast %"class.kotlin::ScopedThread::attributes"* %4 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %185) #37, !noalias !128
+  %186 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %4, i64 0, i32 0, i32 0, i32 0, i32 1
+  %187 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
+  %188 = bitcast %"class.kotlin::ScopedThread::attributes"* %4 to %union.anon.108**
+  %189 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
+  %190 = bitcast i64* %189 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %190, i8 0, i64 32, i1 false) #37, !noalias !128
+  store %union.anon.108* %187, %union.anon.108** %188, align 8, !tbaa !45, !noalias !128
+  %191 = bitcast %union.anon.108* %187 to i8*
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(15) %191, i8* nonnull align 1 dereferenceable(15) getelementptr inbounds ([16 x i8], [16 x i8]* @.str.11.37, i64 0, i64 0), i64 15, i1 false) #37, !noalias !128
+  %192 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  store i64 15, i64* %189, align 8, !tbaa !51, !noalias !128
+  %193 = load atomic i8*, i8** %192 unordered, align 8, !tbaa !47, !noalias !128
+  %194 = getelementptr inbounds i8, i8* %193, i64 15
+  store i8 0, i8* %194, align 1, !tbaa !50, !noalias !128
+  store i8 1, i8* %186, align 8, !tbaa !104, !noalias !128
+  %195 = ptrtoint i8* %166 to i64
+  %196 = getelementptr inbounds i8, i8* %134, i64 216
+  %197 = bitcast i8* %196 to %"struct.std::atomic.0"*
+  %198 = bitcast %"class.std::unique_ptr"* %2 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %198) #37, !noalias !128
+  %199 = bitcast i8* %196 to i64*
+  store i64 0, i64* %199, align 8, !tbaa !146, !noalias !128
+  %200 = bitcast %"struct.std::thread::_Invoker"* %3 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 80, i8* nonnull %200) #37, !noalias !128
+  %201 = bitcast %"struct.std::thread::_Invoker"* %3 to i64*
+  store i64 %167, i64* %201, align 16, !tbaa !3, !noalias !128
+  %202 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
+  %203 = bitcast %"struct.std::_Head_base.130"* %202 to i64*
+  store i64 %195, i64* %203, align 8, !tbaa !174, !noalias !128
+  %204 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0
+  %205 = bitcast i64* %204 to <2 x i64>*
+  store <2 x i64> <i64 ptrtoint (void (%"class.kotlin::RepeatedTimer"*, %class.anon*)* @_ZN6kotlin13RepeatedTimerINS_12steady_clockEE3RunIZNS_2gc8internal24GCSchedulerDataWithTimerIS1_EC1ERNS4_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EEvOT_ to i64), i64 0>, <2 x i64>* %205, align 16, !tbaa !176, !noalias !128
+  %206 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1
   %207 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1
-  store i8 0, i8* %207, align 16, !tbaa !112, !noalias !130
-  %208 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1
-  %209 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
-  %210 = bitcast %"struct.std::_Head_base.132"* %208 to %union.anon.108**
-  store %union.anon.108* %209, %union.anon.108** %210, align 16, !tbaa !56, !noalias !130
-  %211 = bitcast %union.anon.108* %209 to i8*
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 16 dereferenceable(15) %211, i8* nonnull align 8 dereferenceable(15) %193, i64 15, i1 false) #37, !noalias !130
-  %212 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  store i64 15, i64* %212, align 8, !tbaa !60, !noalias !130
-  %213 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 1, i64 7
-  store i8 0, i8* %213, align 1, !tbaa !51, !noalias !130
-  store i8 1, i8* %207, align 16, !tbaa !112, !noalias !130
-  %214 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 1
-  %215 = bitcast %"struct.std::_Head_base.133"* %214 to i64*
-  store i64 ptrtoint (void (%"class.kotlin::ScopedThread::attributes"*, { i64, i64 }*, %"class.kotlin::RepeatedTimer"**, %class.anon*)* @_ZN6kotlin12ScopedThread3RunIMNS_13RepeatedTimerINS_12steady_clockEEEDoFvOZNS_2gc8internal24GCSchedulerDataWithTimerIS3_EC1ERNS5_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EJPS4_SE_EEENSt13invoke_resultIT_JDpT0_EE4typeENS0_10attributesEOSK_DpOSL_ to i64), i64* %215, align 8, !tbaa !180, !alias.scope !182, !noalias !130
-  %216 = invoke noalias nonnull dereferenceable(88) i8* @_Znwm(i64 88) #53
-          to label %217 unwind label %.thread, !noalias !130
+  store i8 0, i8* %207, align 16, !tbaa !110, !noalias !128
+  %208 = load atomic i8, i8* %186 unordered, align 8, !tbaa !110, !range !70, !noalias !128
+  %209 = icmp eq i8 %208, 0
+  br i1 %209, label %235, label %210
 
-217:                                              ; preds = %133
-  %218 = bitcast i8* %216 to i32 (...)***
-  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOMNS3_13RepeatedTimerINS3_12steady_clockEEEDoFvOZNS3_2gc8internal24GCSchedulerDataWithTimerIS7_EC1ERNS9_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS8_SJ_ES5_SL_SN_SI_EEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %218, align 8, !tbaa !109, !noalias !185
-  %219 = getelementptr inbounds i8, i8* %216, i64 8
-  %220 = bitcast %"struct.std::thread::_Invoker"* %3 to <2 x i64>*
-  %221 = load <2 x i64>, <2 x i64>* %220, align 16, !tbaa !3, !noalias !185
-  %222 = bitcast i8* %219 to <2 x i64>*
-  store <2 x i64> %221, <2 x i64>* %222, align 8, !tbaa !3, !noalias !185
-  %223 = load <2 x i64>, <2 x i64>* %206, align 16, !tbaa !51, !noalias !185
-  %224 = getelementptr inbounds i8, i8* %216, i64 24
-  %225 = bitcast i8* %224 to <2 x i64>*
-  store <2 x i64> %223, <2 x i64>* %225, align 8, !tbaa !178, !noalias !185
-  %226 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0
-  %227 = getelementptr inbounds i8, i8* %216, i64 72
-  store i8 0, i8* %227, align 8, !tbaa !112, !noalias !185
-  %228 = getelementptr inbounds i8, i8* %216, i64 40
-  %229 = getelementptr inbounds i8, i8* %216, i64 56
-  %230 = bitcast i8* %228 to i8**
-  store i8* %229, i8** %230, align 8, !tbaa !56, !noalias !185
-  %231 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %226, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %232 = load i8*, i8** %231, align 16, !tbaa !58, !noalias !185
-  %233 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
-  %234 = bitcast %union.anon.108* %233 to i8*
-  %235 = icmp eq i8* %232, %234
-  br i1 %235, label %236, label %237
+210:                                              ; preds = %131
+  %211 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
+  %212 = bitcast %"struct.std::_Head_base.132"* %206 to %union.anon.108**
+  store %union.anon.108* %211, %union.anon.108** %212, align 16, !tbaa !45, !noalias !128
+  %213 = load atomic i64, i64* %189 unordered, align 8, !tbaa !51, !noalias !128
+  %214 = icmp ugt i64 %213, 15
+  br i1 %214, label %217, label %215
 
-236:                                              ; preds = %217
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(16) %229, i8* nonnull align 16 dereferenceable(16) %234, i64 16, i1 false) #37, !noalias !185
-  br label %241
+215:                                              ; preds = %210
+  %216 = bitcast %union.anon.108* %211 to i8*
+  br label %225
 
-237:                                              ; preds = %217
-  store i8* %232, i8** %230, align 8, !tbaa !58, !noalias !185
-  %238 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
-  %239 = load i64, i64* %238, align 16, !tbaa !51, !noalias !185
-  %240 = bitcast i8* %229 to i64*
-  store i64 %239, i64* %240, align 8, !tbaa !51, !noalias !185
-  br label %241
+217:                                              ; preds = %210
+  %218 = icmp slt i64 %213, 0
+  br i1 %218, label %219, label %220
 
-241:                                              ; preds = %237, %236
-  %242 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  %243 = load i64, i64* %242, align 8, !tbaa !60, !noalias !185
-  %244 = getelementptr inbounds i8, i8* %216, i64 48
-  %245 = bitcast i8* %244 to i64*
-  store i64 %243, i64* %245, align 8, !tbaa !60, !noalias !185
-  %246 = bitcast %"class.kotlin::ScopedThread::attributes"* %226 to %union.anon.108**
-  store %union.anon.108* %233, %union.anon.108** %246, align 16, !tbaa !58, !noalias !185
-  store i64 0, i64* %242, align 8, !tbaa !60, !noalias !185
-  store i8 0, i8* %234, align 16, !tbaa !51, !noalias !185
-  store i8 1, i8* %227, align 8, !tbaa !112, !noalias !185
-  %247 = getelementptr inbounds i8, i8* %216, i64 80
-  %248 = bitcast i8* %247 to i64*
-  store i64 ptrtoint (void (%"class.kotlin::ScopedThread::attributes"*, { i64, i64 }*, %"class.kotlin::RepeatedTimer"**, %class.anon*)* @_ZN6kotlin12ScopedThread3RunIMNS_13RepeatedTimerINS_12steady_clockEEEDoFvOZNS_2gc8internal24GCSchedulerDataWithTimerIS3_EC1ERNS5_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EJPS4_SE_EEENSt13invoke_resultIT_JDpT0_EE4typeENS0_10attributesEOSK_DpOSL_ to i64), i64* %248, align 8, !tbaa !180, !noalias !185
-  %249 = bitcast %"class.std::unique_ptr"* %2 to i8**
-  store i8* %216, i8** %249, align 8, !tbaa !3, !alias.scope !188, !noalias !130
-  invoke void @_ZNSt6thread15_M_start_threadESt10unique_ptrINS_6_StateESt14default_deleteIS1_EEPFvvE(%"struct.std::atomic.0"* nonnull %198, %"class.std::unique_ptr"* nonnull %2, void ()* bitcast (i32 (i64*, %union.pthread_attr_t*, i8* (i8*)*, i8*)* @pthread_create to void ()*))
-          to label %250 unwind label %271, !noalias !130
+219:                                              ; preds = %217
+  call fastcc void @_ZSt20__throw_length_errorPKc(i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.14.134.831, i64 0, i64 0)) #51, !noalias !128
+  unreachable
 
-250:                                              ; preds = %241
-  %251 = getelementptr inbounds %"class.std::unique_ptr", %"class.std::unique_ptr"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %252 = load %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %251, align 8, !tbaa !3, !noalias !130
-  %253 = icmp eq %"class.kotlin::gc::GC::ThreadData::Impl"* %252, null
-  br i1 %253, label %259, label %254
+220:                                              ; preds = %217
+  %221 = add nuw i64 %213, 1
+  %222 = call noalias i8* @calloc(i64 %221, i64 1) #37, !noalias !128
+  %223 = getelementptr inbounds %"struct.std::_Head_base.132", %"struct.std::_Head_base.132"* %206, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  store i8* %222, i8** %223, align 16, !tbaa !47, !noalias !128
+  %224 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
+  store i64 %213, i64* %224, align 16, !tbaa !50, !noalias !128
+  br label %225
 
-254:                                              ; preds = %250
-  %255 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %252 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*)***
-  %256 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %255, align 8, !tbaa !109, !noalias !130
-  %257 = getelementptr inbounds void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %256, i64 1
-  %258 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %257, align 8, !noalias !130
-  call void %258(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %252) #37, !noalias !130
-  br label %259
+225:                                              ; preds = %220, %215
+  %226 = phi i8* [ %216, %215 ], [ %222, %220 ]
+  switch i64 %213, label %229 [
+    i64 1, label %227
+    i64 0, label %230
+  ]
 
-259:                                              ; preds = %254, %250
-  store %"class.kotlin::gc::GC::ThreadData::Impl"* null, %"class.kotlin::gc::GC::ThreadData::Impl"** %251, align 8, !tbaa !3, !noalias !130
-  %260 = load i8, i8* %207, align 16, !tbaa !112, !range !72, !noalias !130
-  %261 = icmp eq i8 %260, 0
-  br i1 %261, label %_ZNSt6threadC2IPFvN6kotlin12ScopedThread10attributesEOMNS1_13RepeatedTimerINS1_12steady_clockEEEDoFvOZNS1_2gc8internal24GCSchedulerDataWithTimerIS5_EC1ERNS7_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS6_SH_EJRKS3_SJ_SL_SG_EvEEOT_DpOT0_.exit.i.i.i.i.i.i, label %262
+227:                                              ; preds = %225
+  %228 = load atomic i8, i8* %193 unordered, align 1, !tbaa !50, !noalias !128
+  store i8 %228, i8* %226, align 1, !tbaa !50, !noalias !128
+  br label %230
 
-262:                                              ; preds = %259
-  %263 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %264 = load i8*, i8** %263, align 16, !tbaa !58, !noalias !130
-  %265 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
-  %266 = bitcast %union.anon.108* %265 to i8*
-  %267 = icmp eq i8* %264, %266
-  br i1 %267, label %_ZNSt6threadC2IPFvN6kotlin12ScopedThread10attributesEOMNS1_13RepeatedTimerINS1_12steady_clockEEEDoFvOZNS1_2gc8internal24GCSchedulerDataWithTimerIS5_EC1ERNS7_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS6_SH_EJRKS3_SJ_SL_SG_EvEEOT_DpOT0_.exit.i.i.i.i.i.i, label %268
+229:                                              ; preds = %225
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %226, i8* align 1 %193, i64 %213, i1 false) #37, !noalias !128
+  br label %230
 
-268:                                              ; preds = %262
-  call void @free(i8* %264) #37, !noalias !130
+230:                                              ; preds = %229, %227, %225
+  %231 = getelementptr inbounds %"struct.std::_Head_base.132", %"struct.std::_Head_base.132"* %206, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %232 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
+  store i64 %213, i64* %232, align 8, !tbaa !51, !noalias !128
+  %233 = load atomic i8*, i8** %231 unordered, align 16, !tbaa !47, !noalias !128
+  %234 = getelementptr inbounds i8, i8* %233, i64 %213
+  store i8 0, i8* %234, align 1, !tbaa !50, !noalias !128
+  store i8 1, i8* %207, align 16, !tbaa !110, !noalias !128
+  br label %235
+
+235:                                              ; preds = %230, %131
+  %236 = phi i1 [ true, %131 ], [ false, %230 ]
+  %237 = phi i8 [ 0, %131 ], [ 1, %230 ]
+  %238 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 1
+  %239 = bitcast %"struct.std::_Head_base.133"* %238 to i64*
+  store i64 ptrtoint (void (%"class.kotlin::ScopedThread::attributes"*, { i64, i64 }*, %"class.kotlin::RepeatedTimer"**, %class.anon*)* @_ZN6kotlin12ScopedThread3RunIMNS_13RepeatedTimerINS_12steady_clockEEEDoFvOZNS_2gc8internal24GCSchedulerDataWithTimerIS3_EC1ERNS5_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EJPS4_SE_EEENSt13invoke_resultIT_JDpT0_EE4typeENS0_10attributesEOSK_DpOSL_ to i64), i64* %239, align 8, !tbaa !178, !alias.scope !180, !noalias !128
+  %240 = invoke noalias nonnull dereferenceable(88) i8* @_Znwm(i64 88) #53
+          to label %241 unwind label %295, !noalias !128
+
+241:                                              ; preds = %235
+  %242 = bitcast i8* %240 to i32 (...)***
+  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOMNS3_13RepeatedTimerINS3_12steady_clockEEEDoFvOZNS3_2gc8internal24GCSchedulerDataWithTimerIS7_EC1ERNS9_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS8_SJ_ES5_SL_SN_SI_EEEEEE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %242, align 8, !tbaa !107, !noalias !183
+  %243 = getelementptr inbounds i8, i8* %240, i64 8
+  %244 = bitcast %"struct.std::thread::_Invoker"* %3 to <2 x i64>*
+  %245 = load <2 x i64>, <2 x i64>* %244, align 16, !tbaa !3, !noalias !183
+  %246 = bitcast i8* %243 to <2 x i64>*
+  store <2 x i64> %245, <2 x i64>* %246, align 8, !tbaa !3, !noalias !183
+  %247 = load <2 x i64>, <2 x i64>* %205, align 16, !tbaa !50, !noalias !183
+  %248 = getelementptr inbounds i8, i8* %240, i64 24
+  %249 = bitcast i8* %248 to <2 x i64>*
+  store <2 x i64> %247, <2 x i64>* %249, align 8, !tbaa !176, !noalias !183
+  %250 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0
+  %251 = getelementptr inbounds i8, i8* %240, i64 72
+  store i8 0, i8* %251, align 8, !tbaa !110, !noalias !183
+  br i1 %236, label %272, label %252
+
+252:                                              ; preds = %241
+  %253 = getelementptr inbounds i8, i8* %240, i64 40
+  %254 = getelementptr inbounds i8, i8* %240, i64 56
+  %255 = bitcast i8* %253 to i8**
+  store i8* %254, i8** %255, align 8, !tbaa !45, !noalias !183
+  %256 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %250, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %257 = load atomic i8*, i8** %256 unordered, align 16, !tbaa !47, !noalias !183
+  %258 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
+  %259 = bitcast %union.anon.108* %258 to i8*
+  %260 = icmp eq i8* %257, %259
+  br i1 %260, label %261, label %262
+
+261:                                              ; preds = %252
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(16) %254, i8* nonnull align 16 dereferenceable(16) %259, i64 16, i1 false) #37, !noalias !183
+  br label %266
+
+262:                                              ; preds = %252
+  store i8* %257, i8** %255, align 8, !tbaa !47, !noalias !183
+  %263 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
+  %264 = load atomic i64, i64* %263 unordered, align 16, !tbaa !50, !noalias !183
+  %265 = bitcast i8* %254 to i64*
+  store i64 %264, i64* %265, align 8, !tbaa !50, !noalias !183
+  br label %266
+
+266:                                              ; preds = %262, %261
+  %267 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
+  %268 = load atomic i64, i64* %267 unordered, align 8, !tbaa !51, !noalias !183
+  %269 = getelementptr inbounds i8, i8* %240, i64 48
+  %270 = bitcast i8* %269 to i64*
+  store i64 %268, i64* %270, align 8, !tbaa !51, !noalias !183
+  %271 = bitcast %"class.kotlin::ScopedThread::attributes"* %250 to %union.anon.108**
+  store %union.anon.108* %258, %union.anon.108** %271, align 16, !tbaa !47, !noalias !183
+  store i64 0, i64* %267, align 8, !tbaa !51, !noalias !183
+  store i8 0, i8* %259, align 16, !tbaa !50, !noalias !183
+  store i8 1, i8* %251, align 8, !tbaa !110, !noalias !183
+  br label %272
+
+272:                                              ; preds = %266, %241
+  %273 = getelementptr inbounds i8, i8* %240, i64 80
+  %274 = bitcast i8* %273 to i64*
+  store i64 ptrtoint (void (%"class.kotlin::ScopedThread::attributes"*, { i64, i64 }*, %"class.kotlin::RepeatedTimer"**, %class.anon*)* @_ZN6kotlin12ScopedThread3RunIMNS_13RepeatedTimerINS_12steady_clockEEEDoFvOZNS_2gc8internal24GCSchedulerDataWithTimerIS3_EC1ERNS5_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EJPS4_SE_EEENSt13invoke_resultIT_JDpT0_EE4typeENS0_10attributesEOSK_DpOSL_ to i64), i64* %274, align 8, !tbaa !178, !noalias !183
+  %275 = bitcast %"class.std::unique_ptr"* %2 to i8**
+  store i8* %240, i8** %275, align 8, !tbaa !3, !alias.scope !186, !noalias !128
+  invoke void @_ZNSt6thread15_M_start_threadESt10unique_ptrINS_6_StateESt14default_deleteIS1_EEPFvvE(%"struct.std::atomic.0"* nonnull %197, %"class.std::unique_ptr"* nonnull %2, void ()* bitcast (i32 (i64*, %union.pthread_attr_t*, i8* (i8*)*, i8*)* @pthread_create to void ()*))
+          to label %276 unwind label %298, !noalias !128
+
+276:                                              ; preds = %272
+  %277 = getelementptr inbounds %"class.std::unique_ptr", %"class.std::unique_ptr"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %278 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %277 unordered, align 8, !tbaa !3, !noalias !128
+  %279 = icmp eq %"class.kotlin::gc::GC::ThreadData::Impl"* %278, null
+  br i1 %279, label %285, label %280
+
+280:                                              ; preds = %276
+  %281 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %278 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*)***
+  %282 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %281 unordered, align 8, !tbaa !107, !noalias !128
+  %283 = getelementptr inbounds void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %282, i64 1
+  %284 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %283 unordered, align 8, !noalias !128
+  call void %284(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %278) #37, !noalias !128
+  br label %285
+
+285:                                              ; preds = %280, %276
+  store %"class.kotlin::gc::GC::ThreadData::Impl"* null, %"class.kotlin::gc::GC::ThreadData::Impl"** %277, align 8, !tbaa !3, !noalias !128
+  %286 = load atomic i8, i8* %207 unordered, align 16, !tbaa !110, !range !70, !noalias !128
+  %287 = icmp eq i8 %286, 0
+  br i1 %287, label %_ZNSt6threadC2IPFvN6kotlin12ScopedThread10attributesEOMNS1_13RepeatedTimerINS1_12steady_clockEEEDoFvOZNS1_2gc8internal24GCSchedulerDataWithTimerIS5_EC1ERNS7_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS6_SH_EJRKS3_SJ_SL_SG_EvEEOT_DpOT0_.exit.i.i.i.i.i.i, label %288
+
+288:                                              ; preds = %285
+  %289 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %290 = load atomic i8*, i8** %289 unordered, align 16, !tbaa !47, !noalias !128
+  %291 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
+  %292 = bitcast %union.anon.108* %291 to i8*
+  %293 = icmp eq i8* %290, %292
+  br i1 %293, label %_ZNSt6threadC2IPFvN6kotlin12ScopedThread10attributesEOMNS1_13RepeatedTimerINS1_12steady_clockEEEDoFvOZNS1_2gc8internal24GCSchedulerDataWithTimerIS5_EC1ERNS7_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS6_SH_EJRKS3_SJ_SL_SG_EvEEOT_DpOT0_.exit.i.i.i.i.i.i, label %294
+
+294:                                              ; preds = %288
+  call void @free(i8* %290) #37, !noalias !128
   br label %_ZNSt6threadC2IPFvN6kotlin12ScopedThread10attributesEOMNS1_13RepeatedTimerINS1_12steady_clockEEEDoFvOZNS1_2gc8internal24GCSchedulerDataWithTimerIS5_EC1ERNS7_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS6_SH_EJRKS3_SJ_SL_SG_EvEEOT_DpOT0_.exit.i.i.i.i.i.i
 
-.thread:                                          ; preds = %133
-  %269 = landingpad { i8*, i32 }
+295:                                              ; preds = %235
+  %296 = landingpad { i8*, i32 }
           catch i8* null
-  %270 = extractvalue { i8*, i32 } %269, 0
-  br label %284
+  %297 = extractvalue { i8*, i32 } %296, 0
+  br label %311
 
-271:                                              ; preds = %241
-  %272 = landingpad { i8*, i32 }
+298:                                              ; preds = %272
+  %299 = landingpad { i8*, i32 }
           catch i8* null
-  %273 = extractvalue { i8*, i32 } %272, 0
-  %274 = getelementptr inbounds %"class.std::unique_ptr", %"class.std::unique_ptr"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %275 = load %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %274, align 8, !tbaa !3, !noalias !130
-  %276 = icmp eq %"class.kotlin::gc::GC::ThreadData::Impl"* %275, null
-  br i1 %276, label %282, label %277
+  %300 = extractvalue { i8*, i32 } %299, 0
+  %301 = getelementptr inbounds %"class.std::unique_ptr", %"class.std::unique_ptr"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %302 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %301 unordered, align 8, !tbaa !3, !noalias !128
+  %303 = icmp eq %"class.kotlin::gc::GC::ThreadData::Impl"* %302, null
+  br i1 %303, label %309, label %304
 
-277:                                              ; preds = %271
-  %278 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %275 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*)***
-  %279 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %278, align 8, !tbaa !109, !noalias !130
-  %280 = getelementptr inbounds void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %279, i64 1
-  %281 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %280, align 8, !noalias !130
-  call void %281(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %275) #37, !noalias !130
-  br label %282
+304:                                              ; preds = %298
+  %305 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %302 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*)***
+  %306 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %305 unordered, align 8, !tbaa !107, !noalias !128
+  %307 = getelementptr inbounds void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %306, i64 1
+  %308 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %307 unordered, align 8, !noalias !128
+  call void %308(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %302) #37, !noalias !128
+  br label %309
 
-282:                                              ; preds = %277, %271
-  store %"class.kotlin::gc::GC::ThreadData::Impl"* null, %"class.kotlin::gc::GC::ThreadData::Impl"** %274, align 8, !tbaa !3, !noalias !130
-  %283 = load i8, i8* %207, align 16, !tbaa !112, !range !72, !noalias !130
-  %phi.cmp = icmp eq i8 %283, 0
-  br i1 %phi.cmp, label %292, label %284
+309:                                              ; preds = %304, %298
+  store %"class.kotlin::gc::GC::ThreadData::Impl"* null, %"class.kotlin::gc::GC::ThreadData::Impl"** %301, align 8, !tbaa !3, !noalias !128
+  %310 = load atomic i8, i8* %207 unordered, align 16, !tbaa !110, !range !70, !noalias !128
+  br label %311
 
-284:                                              ; preds = %282, %.thread
-  %285 = phi i8* [ %270, %.thread ], [ %273, %282 ]
-  %286 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %287 = load i8*, i8** %286, align 16, !tbaa !58, !noalias !130
-  %288 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
-  %289 = bitcast %union.anon.108* %288 to i8*
-  %290 = icmp eq i8* %287, %289
-  br i1 %290, label %292, label %291
+311:                                              ; preds = %309, %295
+  %312 = phi i8 [ %310, %309 ], [ %237, %295 ]
+  %313 = phi i8* [ %300, %309 ], [ %297, %295 ]
+  %314 = icmp eq i8 %312, 0
+  br i1 %314, label %322, label %315
 
-291:                                              ; preds = %284
-  call void @free(i8* %287) #37, !noalias !130
-  br label %292
+315:                                              ; preds = %311
+  %316 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %317 = load atomic i8*, i8** %316 unordered, align 16, !tbaa !47, !noalias !128
+  %318 = getelementptr inbounds %"struct.std::thread::_Invoker", %"struct.std::thread::_Invoker"* %3, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
+  %319 = bitcast %union.anon.108* %318 to i8*
+  %320 = icmp eq i8* %317, %319
+  br i1 %320, label %322, label %321
 
-292:                                              ; preds = %291, %284, %282
-  %293 = phi i8* [ %285, %291 ], [ %285, %284 ], [ %273, %282 ]
-  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %201) #37, !noalias !130
-  %294 = load i8, i8* %188, align 8, !tbaa !112, !range !72, !noalias !130
-  %295 = icmp eq i8 %294, 0
-  br i1 %295, label %306, label %302
+321:                                              ; preds = %315
+  call void @free(i8* %317) #37, !noalias !128
+  br label %322
 
-_ZNSt6threadC2IPFvN6kotlin12ScopedThread10attributesEOMNS1_13RepeatedTimerINS1_12steady_clockEEEDoFvOZNS1_2gc8internal24GCSchedulerDataWithTimerIS5_EC1ERNS7_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS6_SH_EJRKS3_SJ_SL_SG_EvEEOT_DpOT0_.exit.i.i.i.i.i.i: ; preds = %268, %262, %259
-  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %201) #37, !noalias !130
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %199) #37, !noalias !130
-  %296 = load i8, i8* %188, align 8, !tbaa !112, !range !72, !noalias !130
-  %297 = icmp eq i8 %296, 0
-  br i1 %297, label %_ZN6kotlin13RepeatedTimerINS_12steady_clockEEC2IlSt5ratioILl1ELl1000000EEZNS_2gc8internal24GCSchedulerDataWithTimerIS1_EC1ERNS6_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EESt17basic_string_viewIcSt11char_traitsIcEENSt6chrono8durationIT_T0_EEOT1_.exit.i.i.i.i.i, label %298
+322:                                              ; preds = %321, %315, %311
+  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %200) #37, !noalias !128
+  %323 = load atomic i8, i8* %186 unordered, align 8, !tbaa !110, !range !70, !noalias !128
+  %324 = icmp eq i8 %323, 0
+  br i1 %324, label %335, label %331
 
-298:                                              ; preds = %_ZNSt6threadC2IPFvN6kotlin12ScopedThread10attributesEOMNS1_13RepeatedTimerINS1_12steady_clockEEEDoFvOZNS1_2gc8internal24GCSchedulerDataWithTimerIS5_EC1ERNS7_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS6_SH_EJRKS3_SJ_SL_SG_EvEEOT_DpOT0_.exit.i.i.i.i.i.i
-  %299 = load i8*, i8** %194, align 8, !tbaa !58, !noalias !130
-  %300 = icmp eq i8* %299, %193
-  br i1 %300, label %_ZN6kotlin13RepeatedTimerINS_12steady_clockEEC2IlSt5ratioILl1ELl1000000EEZNS_2gc8internal24GCSchedulerDataWithTimerIS1_EC1ERNS6_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EESt17basic_string_viewIcSt11char_traitsIcEENSt6chrono8durationIT_T0_EEOT1_.exit.i.i.i.i.i, label %301
+_ZNSt6threadC2IPFvN6kotlin12ScopedThread10attributesEOMNS1_13RepeatedTimerINS1_12steady_clockEEEDoFvOZNS1_2gc8internal24GCSchedulerDataWithTimerIS5_EC1ERNS7_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS6_SH_EJRKS3_SJ_SL_SG_EvEEOT_DpOT0_.exit.i.i.i.i.i.i: ; preds = %294, %288, %285
+  call void @llvm.lifetime.end.p0i8(i64 80, i8* nonnull %200) #37, !noalias !128
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %198) #37, !noalias !128
+  %325 = load atomic i8, i8* %186 unordered, align 8, !tbaa !110, !range !70, !noalias !128
+  %326 = icmp eq i8 %325, 0
+  br i1 %326, label %_ZN6kotlin13RepeatedTimerINS_12steady_clockEEC2IlSt5ratioILl1ELl1000000EEZNS_2gc8internal24GCSchedulerDataWithTimerIS1_EC1ERNS6_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EESt17basic_string_viewIcSt11char_traitsIcEENSt6chrono8durationIT_T0_EEOT1_.exit.i.i.i.i.i, label %327
 
-301:                                              ; preds = %298
-  call void @free(i8* %299) #37, !noalias !130
+327:                                              ; preds = %_ZNSt6threadC2IPFvN6kotlin12ScopedThread10attributesEOMNS1_13RepeatedTimerINS1_12steady_clockEEEDoFvOZNS1_2gc8internal24GCSchedulerDataWithTimerIS5_EC1ERNS7_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS6_SH_EJRKS3_SJ_SL_SG_EvEEOT_DpOT0_.exit.i.i.i.i.i.i
+  %328 = load atomic i8*, i8** %192 unordered, align 8, !tbaa !47, !noalias !128
+  %329 = icmp eq i8* %328, %191
+  br i1 %329, label %_ZN6kotlin13RepeatedTimerINS_12steady_clockEEC2IlSt5ratioILl1ELl1000000EEZNS_2gc8internal24GCSchedulerDataWithTimerIS1_EC1ERNS6_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EESt17basic_string_viewIcSt11char_traitsIcEENSt6chrono8durationIT_T0_EEOT1_.exit.i.i.i.i.i, label %330
+
+330:                                              ; preds = %327
+  call void @free(i8* %328) #37, !noalias !128
   br label %_ZN6kotlin13RepeatedTimerINS_12steady_clockEEC2IlSt5ratioILl1ELl1000000EEZNS_2gc8internal24GCSchedulerDataWithTimerIS1_EC1ERNS6_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EESt17basic_string_viewIcSt11char_traitsIcEENSt6chrono8durationIT_T0_EEOT1_.exit.i.i.i.i.i
 
-302:                                              ; preds = %292
-  %303 = load i8*, i8** %194, align 8, !tbaa !58, !noalias !130
-  %304 = icmp eq i8* %303, %193
-  br i1 %304, label %306, label %305
+331:                                              ; preds = %322
+  %332 = load atomic i8*, i8** %192 unordered, align 8, !tbaa !47, !noalias !128
+  %333 = icmp eq i8* %332, %191
+  br i1 %333, label %335, label %334
 
-305:                                              ; preds = %302
-  call void @free(i8* %303) #37, !noalias !130
-  br label %306
+334:                                              ; preds = %331
+  call void @free(i8* %332) #37, !noalias !128
+  br label %335
 
-306:                                              ; preds = %305, %302, %292
-  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %187) #37, !noalias !130
-  call void @_ZNSt18condition_variableD1Ev(%"class.std::condition_variable"* nonnull %171) #37, !noalias !130
-  call fastcc void @__clang_call_terminate(i8* %293) #51, !noalias !130
+335:                                              ; preds = %334, %331, %322
+  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %185) #37, !noalias !128
+  call void @_ZNSt18condition_variableD1Ev(%"class.std::condition_variable"* nonnull %169) #37, !noalias !128
+  call fastcc void @__clang_call_terminate(i8* %313) #51, !noalias !128
   unreachable
 
-_ZN6kotlin13RepeatedTimerINS_12steady_clockEEC2IlSt5ratioILl1ELl1000000EEZNS_2gc8internal24GCSchedulerDataWithTimerIS1_EC1ERNS6_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EESt17basic_string_viewIcSt11char_traitsIcEENSt6chrono8durationIT_T0_EEOT1_.exit.i.i.i.i.i: ; preds = %301, %298, %_ZNSt6threadC2IPFvN6kotlin12ScopedThread10attributesEOMNS1_13RepeatedTimerINS1_12steady_clockEEEDoFvOZNS1_2gc8internal24GCSchedulerDataWithTimerIS5_EC1ERNS7_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS6_SH_EJRKS3_SJ_SL_SG_EvEEOT_DpOT0_.exit.i.i.i.i.i.i
-  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %187) #37, !noalias !130
-  %307 = load i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %138, align 8, !tbaa !103, !noalias !130
-  %308 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %307, null
-  br i1 %308, label %_ZN6kotlin11std_support13allocator_newINS_2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEENS0_9allocatorIS6_EEJRNS2_17GCSchedulerConfigESt8functionIFvvEEEEEPT_RKT0_DpOT1_.exit.i.i.i.i, label %309
+_ZN6kotlin13RepeatedTimerINS_12steady_clockEEC2IlSt5ratioILl1ELl1000000EEZNS_2gc8internal24GCSchedulerDataWithTimerIS1_EC1ERNS6_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EESt17basic_string_viewIcSt11char_traitsIcEENSt6chrono8durationIT_T0_EEOT1_.exit.i.i.i.i.i: ; preds = %330, %327, %_ZNSt6threadC2IPFvN6kotlin12ScopedThread10attributesEOMNS1_13RepeatedTimerINS1_12steady_clockEEEDoFvOZNS1_2gc8internal24GCSchedulerDataWithTimerIS5_EC1ERNS7_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS6_SH_EJRKS3_SJ_SL_SG_EvEEOT_DpOT0_.exit.i.i.i.i.i.i
+  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %185) #37, !noalias !128
+  %336 = load atomic i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %136 unordered, align 8, !tbaa !101, !noalias !128
+  %337 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %336, null
+  br i1 %337, label %_ZN6kotlin11std_support13allocator_newINS_2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEENS0_9allocatorIS6_EEJRNS2_17GCSchedulerConfigESt8functionIFvvEEEEEPT_RKT0_DpOT1_.exit.i.i.i.i, label %338
 
-309:                                              ; preds = %_ZN6kotlin13RepeatedTimerINS_12steady_clockEEC2IlSt5ratioILl1ELl1000000EEZNS_2gc8internal24GCSchedulerDataWithTimerIS1_EC1ERNS6_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EESt17basic_string_viewIcSt11char_traitsIcEENSt6chrono8durationIT_T0_EEOT1_.exit.i.i.i.i.i
-  %310 = getelementptr inbounds %"class.std::function", %"class.std::function"* %6, i64 0, i32 0, i32 0
-  %311 = invoke zeroext i1 %307(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %310, %"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %310, i32 3)
-          to label %_ZN6kotlin11std_support13allocator_newINS_2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEENS0_9allocatorIS6_EEJRNS2_17GCSchedulerConfigESt8functionIFvvEEEEEPT_RKT0_DpOT1_.exit.i.i.i.i unwind label %312, !noalias !130
+338:                                              ; preds = %_ZN6kotlin13RepeatedTimerINS_12steady_clockEEC2IlSt5ratioILl1ELl1000000EEZNS_2gc8internal24GCSchedulerDataWithTimerIS1_EC1ERNS6_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EESt17basic_string_viewIcSt11char_traitsIcEENSt6chrono8durationIT_T0_EEOT1_.exit.i.i.i.i.i
+  %339 = getelementptr inbounds %"class.std::function", %"class.std::function"* %6, i64 0, i32 0, i32 0
+  %340 = invoke zeroext i1 %336(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %339, %"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %339, i32 3)
+          to label %_ZN6kotlin11std_support13allocator_newINS_2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEENS0_9allocatorIS6_EEJRNS2_17GCSchedulerConfigESt8functionIFvvEEEEEPT_RKT0_DpOT1_.exit.i.i.i.i unwind label %341, !noalias !128
 
-312:                                              ; preds = %309
-  %313 = landingpad { i8*, i32 }
+341:                                              ; preds = %338
+  %342 = landingpad { i8*, i32 }
           catch i8* null
-  %314 = extractvalue { i8*, i32 } %313, 0
-  call fastcc void @__clang_call_terminate(i8* %314) #51, !noalias !130
+  %343 = extractvalue { i8*, i32 } %342, 0
+  call fastcc void @__clang_call_terminate(i8* %343) #51, !noalias !128
   unreachable
 
-_ZN6kotlin11std_support13allocator_newINS_2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEENS0_9allocatorIS6_EEJRNS2_17GCSchedulerConfigESt8functionIFvvEEEEEPT_RKT0_DpOT1_.exit.i.i.i.i: ; preds = %309, %_ZN6kotlin13RepeatedTimerINS_12steady_clockEEC2IlSt5ratioILl1ELl1000000EEZNS_2gc8internal24GCSchedulerDataWithTimerIS1_EC1ERNS6_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EESt17basic_string_viewIcSt11char_traitsIcEENSt6chrono8durationIT_T0_EEOT1_.exit.i.i.i.i.i
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %137) #37, !noalias !130
-  %315 = getelementptr inbounds %"class.kotlin::gc::GCScheduler", %"class.kotlin::gc::GCScheduler"* %86, i64 0, i32 1
-  %316 = bitcast %"class.std::unique_ptr"* %315 to i64*
-  %317 = getelementptr %"class.std::unique_ptr", %"class.std::unique_ptr"* %315, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %318 = load %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %317, align 8, !tbaa !3, !noalias !130
-  store i64 %169, i64* %316, align 8, !tbaa !3, !noalias !130
-  %319 = icmp eq %"class.kotlin::gc::GC::ThreadData::Impl"* %318, null
-  br i1 %319, label %325, label %320
+_ZN6kotlin11std_support13allocator_newINS_2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEENS0_9allocatorIS6_EEJRNS2_17GCSchedulerConfigESt8functionIFvvEEEEEPT_RKT0_DpOT1_.exit.i.i.i.i: ; preds = %338, %_ZN6kotlin13RepeatedTimerINS_12steady_clockEEC2IlSt5ratioILl1ELl1000000EEZNS_2gc8internal24GCSchedulerDataWithTimerIS1_EC1ERNS6_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EESt17basic_string_viewIcSt11char_traitsIcEENSt6chrono8durationIT_T0_EEOT1_.exit.i.i.i.i.i
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %135) #37, !noalias !128
+  %344 = getelementptr inbounds %"class.kotlin::gc::GCScheduler", %"class.kotlin::gc::GCScheduler"* %86, i64 0, i32 1
+  %345 = bitcast %"class.std::unique_ptr"* %344 to i64*
+  %346 = getelementptr %"class.std::unique_ptr", %"class.std::unique_ptr"* %344, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %347 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %346 unordered, align 8, !tbaa !3, !noalias !128
+  store i64 %167, i64* %345, align 8, !tbaa !3, !noalias !128
+  %348 = icmp eq %"class.kotlin::gc::GC::ThreadData::Impl"* %347, null
+  br i1 %348, label %354, label %349
 
-320:                                              ; preds = %_ZN6kotlin11std_support13allocator_newINS_2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEENS0_9allocatorIS6_EEJRNS2_17GCSchedulerConfigESt8functionIFvvEEEEEPT_RKT0_DpOT1_.exit.i.i.i.i
-  %321 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %318 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*)***
-  %322 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %321, align 8, !tbaa !109, !noalias !130
-  %323 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %322, align 8, !noalias !130
-  call void %323(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %318) #37, !noalias !130
-  %324 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %318 to i8*
-  call void @free(i8* %324) #37, !noalias !130
-  br label %325
+349:                                              ; preds = %_ZN6kotlin11std_support13allocator_newINS_2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEENS0_9allocatorIS6_EEJRNS2_17GCSchedulerConfigESt8functionIFvvEEEEEPT_RKT0_DpOT1_.exit.i.i.i.i
+  %350 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %347 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*)***
+  %351 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %350 unordered, align 8, !tbaa !107, !noalias !128
+  %352 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %351 unordered, align 8, !noalias !128
+  call void %352(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %347) #37, !noalias !128
+  %353 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %347 to i8*
+  call void @free(i8* %353) #37, !noalias !128
+  br label %354
 
-325:                                              ; preds = %320, %_ZN6kotlin11std_support13allocator_newINS_2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEENS0_9allocatorIS6_EEJRNS2_17GCSchedulerConfigESt8functionIFvvEEEEEPT_RKT0_DpOT1_.exit.i.i.i.i
-  %326 = load i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %115, align 8, !tbaa !103, !noalias !130
-  %327 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %326, null
-  br i1 %327, label %_ZN6kotlin2gc11GCScheduler13SetScheduleGCESt8functionIFvvEE.exit.i.i.i, label %328
+354:                                              ; preds = %349, %_ZN6kotlin11std_support13allocator_newINS_2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEENS0_9allocatorIS6_EEJRNS2_17GCSchedulerConfigESt8functionIFvvEEEEEPT_RKT0_DpOT1_.exit.i.i.i.i
+  %355 = load atomic i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %112 unordered, align 8, !tbaa !101, !noalias !128
+  %356 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %355, null
+  br i1 %356, label %_ZN6kotlin2gc11GCScheduler13SetScheduleGCESt8functionIFvvEE.exit.i.i.i, label %357
 
-328:                                              ; preds = %325
-  %329 = getelementptr inbounds %"class.std::function", %"class.std::function"* %8, i64 0, i32 0, i32 0
-  %330 = invoke zeroext i1 %326(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %329, %"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %329, i32 3)
-          to label %_ZN6kotlin2gc11GCScheduler13SetScheduleGCESt8functionIFvvEE.exit.i.i.i unwind label %331, !noalias !130
+357:                                              ; preds = %354
+  %358 = getelementptr inbounds %"class.std::function", %"class.std::function"* %8, i64 0, i32 0, i32 0
+  %359 = invoke zeroext i1 %355(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %358, %"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %358, i32 3)
+          to label %_ZN6kotlin2gc11GCScheduler13SetScheduleGCESt8functionIFvvEE.exit.i.i.i unwind label %360, !noalias !128
 
-331:                                              ; preds = %328
-  %332 = landingpad { i8*, i32 }
+360:                                              ; preds = %357
+  %361 = landingpad { i8*, i32 }
           catch i8* null
-  %333 = extractvalue { i8*, i32 } %332, 0
-  call fastcc void @__clang_call_terminate(i8* %333) #51, !noalias !130
+  %362 = extractvalue { i8*, i32 } %361, 0
+  call fastcc void @__clang_call_terminate(i8* %362) #51, !noalias !128
   unreachable
 
-334:                                              ; preds = %128, %124
-  %335 = extractvalue { i8*, i32 } %125, 0
-  call fastcc void @__clang_call_terminate(i8* %335) #51, !noalias !130
+363:                                              ; preds = %126, %122
+  %364 = extractvalue { i8*, i32 } %123, 0
+  call fastcc void @__clang_call_terminate(i8* %364) #51, !noalias !128
   unreachable
 
-_ZN6kotlin2gc11GCScheduler13SetScheduleGCESt8functionIFvvEE.exit.i.i.i: ; preds = %328, %325
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %90) #37, !noalias !130
-  %336 = load i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %87, align 8, !tbaa !103, !noalias !130
-  %337 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %336, null
-  br i1 %337, label %344, label %338
+_ZN6kotlin2gc11GCScheduler13SetScheduleGCESt8functionIFvvEE.exit.i.i.i: ; preds = %357, %354
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %90) #37, !noalias !128
+  %365 = load atomic i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %87 unordered, align 8, !tbaa !101, !noalias !128
+  %366 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %365, null
+  br i1 %366, label %373, label %367
 
-338:                                              ; preds = %_ZN6kotlin2gc11GCScheduler13SetScheduleGCESt8functionIFvvEE.exit.i.i.i
-  %339 = getelementptr inbounds %"class.std::function", %"class.std::function"* %11, i64 0, i32 0, i32 0
-  %340 = invoke zeroext i1 %336(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %339, %"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %339, i32 3)
-          to label %344 unwind label %341, !noalias !130
+367:                                              ; preds = %_ZN6kotlin2gc11GCScheduler13SetScheduleGCESt8functionIFvvEE.exit.i.i.i
+  %368 = getelementptr inbounds %"class.std::function", %"class.std::function"* %11, i64 0, i32 0, i32 0
+  %369 = invoke zeroext i1 %365(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %368, %"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %368, i32 3)
+          to label %373 unwind label %370, !noalias !128
 
-341:                                              ; preds = %338
-  %342 = landingpad { i8*, i32 }
+370:                                              ; preds = %367
+  %371 = landingpad { i8*, i32 }
           catch i8* null
-  %343 = extractvalue { i8*, i32 } %342, 0
-  call fastcc void @__clang_call_terminate(i8* %343) #51, !noalias !130
+  %372 = extractvalue { i8*, i32 } %371, 0
+  call fastcc void @__clang_call_terminate(i8* %372) #51, !noalias !128
   unreachable
 
-344:                                              ; preds = %338, %_ZN6kotlin2gc11GCScheduler13SetScheduleGCESt8functionIFvvEE.exit.i.i.i
-  %345 = bitcast %"struct.std::chrono::time_point"* %12 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %345) #37, !noalias !130
-  %346 = bitcast %"class.kotlin::ScopedThread::attributes"* %13 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %346) #37, !noalias !130
-  %347 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %13, i64 0, i32 0, i32 0, i32 0, i32 1
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %346, i8 0, i64 40, i1 false) #37, !noalias !130
-  %348 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
-  %349 = bitcast %"class.kotlin::ScopedThread::attributes"* %13 to %union.anon.108**
-  store %union.anon.108* %348, %union.anon.108** %349, align 8, !tbaa !56, !noalias !130
-  %350 = bitcast %union.anon.108* %348 to i8*
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(9) %350, i8* nonnull align 1 dereferenceable(9) getelementptr inbounds ([10 x i8], [10 x i8]* @.str.5.336, i64 0, i64 0), i64 9, i1 false) #37, !noalias !130
-  %351 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  store i64 9, i64* %351, align 8, !tbaa !60, !noalias !130
-  %352 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 1, i64 1
-  store i8 0, i8* %352, align 1, !tbaa !51, !noalias !130
-  store i8 1, i8* %347, align 8, !tbaa !106, !noalias !130
-  %353 = getelementptr inbounds %"struct.std::chrono::time_point", %"struct.std::chrono::time_point"* %12, i64 0, i32 0
-  %354 = bitcast %"class.std::unique_ptr"* %9 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %354) #37, !noalias !130
-  %355 = getelementptr inbounds %"struct.std::chrono::time_point", %"struct.std::chrono::time_point"* %12, i64 0, i32 0, i32 0, i32 0
-  store i64 0, i64* %355, align 8, !tbaa !148, !noalias !130
-  %356 = bitcast %"struct.std::thread::_Invoker.150"* %10 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 56, i8* nonnull %356) #37, !noalias !130
-  %357 = bitcast %"struct.std::thread::_Invoker.150"* %10 to i64*
-  store i64 %61, i64* %357, align 8, !tbaa !3, !alias.scope !189, !noalias !130
-  %358 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1
-  %359 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1
-  store i8 0, i8* %359, align 8, !tbaa !112, !alias.scope !189, !noalias !130
-  %360 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
-  %361 = bitcast %"struct.std::_Head_base.132"* %358 to %union.anon.108**
-  store %union.anon.108* %360, %union.anon.108** %361, align 8, !tbaa !56, !alias.scope !189, !noalias !130
-  %362 = bitcast %union.anon.108* %360 to i8*
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(9) %362, i8* nonnull align 8 dereferenceable(9) %350, i64 9, i1 false) #37, !noalias !130
-  %363 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  store i64 9, i64* %363, align 8, !tbaa !60, !alias.scope !189, !noalias !130
-  %364 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 1, i64 1
-  store i8 0, i8* %364, align 1, !tbaa !51, !noalias !130
-  store i8 1, i8* %359, align 8, !tbaa !112, !alias.scope !189, !noalias !130
-  %365 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 1
-  %366 = bitcast %"struct.std::_Head_base.184"* %365 to i64*
-  store i64 ptrtoint (void (%"class.kotlin::ScopedThread::attributes"*, %class.anon.78*)* @"_ZN6kotlin12ScopedThread3RunIZNS_2gc22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS3_EERNS2_11GCSchedulerEE3$_3JEEENSt13invoke_resultIT_JDpT0_EE4typeENS0_10attributesEOSC_DpOSD_" to i64), i64* %366, align 8, !tbaa !192, !alias.scope !189, !noalias !130
-  %367 = invoke noalias nonnull dereferenceable(64) i8* @_Znwm(i64 64) #53
-          to label %368 unwind label %410, !noalias !130
+373:                                              ; preds = %367, %_ZN6kotlin2gc11GCScheduler13SetScheduleGCESt8functionIFvvEE.exit.i.i.i
+  %374 = bitcast %"struct.std::chrono::time_point"* %12 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %374) #37, !noalias !128
+  %375 = bitcast %"class.kotlin::ScopedThread::attributes"* %13 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %375) #37, !noalias !128
+  %376 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %13, i64 0, i32 0, i32 0, i32 0, i32 1
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %375, i8 0, i64 40, i1 false) #37, !noalias !128
+  %377 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
+  %378 = bitcast %"class.kotlin::ScopedThread::attributes"* %13 to %union.anon.108**
+  store %union.anon.108* %377, %union.anon.108** %378, align 8, !tbaa !45, !noalias !128
+  %379 = bitcast %union.anon.108* %377 to i8*
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(9) %379, i8* nonnull align 1 dereferenceable(9) getelementptr inbounds ([10 x i8], [10 x i8]* @.str.5.336, i64 0, i64 0), i64 9, i1 false) #37, !noalias !128
+  %380 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
+  store i64 9, i64* %380, align 8, !tbaa !51, !noalias !128
+  %381 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 1, i64 1
+  store i8 0, i8* %381, align 1, !tbaa !50, !noalias !128
+  store i8 1, i8* %376, align 8, !tbaa !104, !noalias !128
+  %382 = getelementptr inbounds %"struct.std::chrono::time_point", %"struct.std::chrono::time_point"* %12, i64 0, i32 0
+  %383 = bitcast %"class.std::unique_ptr"* %9 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %383) #37, !noalias !128
+  %384 = getelementptr inbounds %"struct.std::chrono::time_point", %"struct.std::chrono::time_point"* %12, i64 0, i32 0, i32 0, i32 0
+  store i64 0, i64* %384, align 8, !tbaa !146, !noalias !128
+  %385 = bitcast %"struct.std::thread::_Invoker.150"* %10 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 56, i8* nonnull %385) #37, !noalias !128
+  %386 = bitcast %"struct.std::thread::_Invoker.150"* %10 to i64*
+  store i64 %61, i64* %386, align 8, !tbaa !3, !alias.scope !187, !noalias !128
+  %387 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1
+  %388 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1
+  store i8 0, i8* %388, align 8, !tbaa !110, !alias.scope !187, !noalias !128
+  %389 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
+  %390 = bitcast %"struct.std::_Head_base.132"* %387 to %union.anon.108**
+  store %union.anon.108* %389, %union.anon.108** %390, align 8, !tbaa !45, !alias.scope !187, !noalias !128
+  %391 = load atomic i64, i64* %380 unordered, align 8, !tbaa !51, !noalias !190
+  %392 = icmp ugt i64 %391, 15
+  br i1 %392, label %395, label %393
 
-368:                                              ; preds = %344
-  %369 = bitcast i8* %367 to i32 (...)***
-  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @"_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc22ConcurrentMarkAndSweepC1ERNS3_2mm13ObjectFactoryIS7_EERNS6_11GCSchedulerEE3$_3ES5_SE_EEEEEE", i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %369, align 8, !tbaa !109, !noalias !194
-  %370 = getelementptr inbounds i8, i8* %367, i64 8
-  %371 = bitcast i8* %370 to i64*
-  store i64 %61, i64* %371, align 8, !tbaa !3, !noalias !194
-  %372 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0
-  %373 = getelementptr inbounds i8, i8* %367, i64 48
-  store i8 0, i8* %373, align 8, !tbaa !112, !noalias !194
-  %374 = getelementptr inbounds i8, i8* %367, i64 16
-  %375 = getelementptr inbounds i8, i8* %367, i64 32
-  %376 = bitcast i8* %374 to i8**
-  store i8* %375, i8** %376, align 8, !tbaa !56, !noalias !194
-  %377 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %372, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %378 = load i8*, i8** %377, align 8, !tbaa !58, !noalias !194
-  %379 = icmp eq i8* %378, %362
-  br i1 %379, label %380, label %381
+393:                                              ; preds = %373
+  %394 = bitcast %union.anon.108* %389 to i8*
+  br label %403
 
-380:                                              ; preds = %368
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(16) %375, i8* nonnull align 8 dereferenceable(16) %362, i64 16, i1 false) #37, !noalias !194
-  br label %385
+395:                                              ; preds = %373
+  %396 = icmp slt i64 %391, 0
+  br i1 %396, label %397, label %398
 
-381:                                              ; preds = %368
-  store i8* %378, i8** %376, align 8, !tbaa !58, !noalias !194
-  %382 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
-  %383 = load i64, i64* %382, align 8, !tbaa !51, !noalias !194
-  %384 = bitcast i8* %375 to i64*
-  store i64 %383, i64* %384, align 8, !tbaa !51, !noalias !194
-  br label %385
+397:                                              ; preds = %395
+  call fastcc void @_ZSt20__throw_length_errorPKc(i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.14.134.831, i64 0, i64 0)) #51, !noalias !128
+  unreachable
 
-385:                                              ; preds = %381, %380
-  %386 = load i64, i64* %363, align 8, !tbaa !60, !noalias !194
-  %387 = getelementptr inbounds i8, i8* %367, i64 24
-  %388 = bitcast i8* %387 to i64*
-  store i64 %386, i64* %388, align 8, !tbaa !60, !noalias !194
-  %389 = bitcast %"class.kotlin::ScopedThread::attributes"* %372 to %union.anon.108**
-  store %union.anon.108* %360, %union.anon.108** %389, align 8, !tbaa !58, !noalias !194
-  store i64 0, i64* %363, align 8, !tbaa !60, !noalias !194
-  store i8 0, i8* %362, align 8, !tbaa !51, !noalias !194
-  store i8 1, i8* %373, align 8, !tbaa !112, !noalias !194
-  %390 = getelementptr inbounds i8, i8* %367, i64 56
-  %391 = bitcast i8* %390 to i64*
-  store i64 ptrtoint (void (%"class.kotlin::ScopedThread::attributes"*, %class.anon.78*)* @"_ZN6kotlin12ScopedThread3RunIZNS_2gc22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS3_EERNS2_11GCSchedulerEE3$_3JEEENSt13invoke_resultIT_JDpT0_EE4typeENS0_10attributesEOSC_DpOSD_" to i64), i64* %391, align 8, !tbaa !192, !noalias !194
-  %392 = bitcast %"class.std::unique_ptr"* %9 to i8**
-  store i8* %367, i8** %392, align 8, !tbaa !3, !alias.scope !197, !noalias !130
-  invoke void @_ZNSt6thread15_M_start_threadESt10unique_ptrINS_6_StateESt14default_deleteIS1_EEPFvvE(%"struct.std::atomic.0"* nonnull %353, %"class.std::unique_ptr"* nonnull %9, void ()* bitcast (i32 (i64*, %union.pthread_attr_t*, i8* (i8*)*, i8*)* @pthread_create to void ()*))
-          to label %393 unwind label %413, !noalias !130
+398:                                              ; preds = %395
+  %399 = add nuw i64 %391, 1
+  %400 = call noalias i8* @calloc(i64 %399, i64 1) #37, !noalias !128
+  %401 = getelementptr inbounds %"struct.std::_Head_base.132", %"struct.std::_Head_base.132"* %387, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  store i8* %400, i8** %401, align 8, !tbaa !47, !alias.scope !187, !noalias !128
+  %402 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
+  store i64 %391, i64* %402, align 8, !tbaa !50, !alias.scope !187, !noalias !128
+  br label %403
 
-393:                                              ; preds = %385
-  %394 = getelementptr inbounds %"class.std::unique_ptr", %"class.std::unique_ptr"* %9, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %395 = load %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %394, align 8, !tbaa !3, !noalias !130
-  %396 = icmp eq %"class.kotlin::gc::GC::ThreadData::Impl"* %395, null
-  br i1 %396, label %402, label %397
+403:                                              ; preds = %398, %393
+  %404 = phi i8* [ %394, %393 ], [ %400, %398 ]
+  switch i64 %391, label %407 [
+    i64 1, label %405
+    i64 0, label %408
+  ]
 
-397:                                              ; preds = %393
-  %398 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %395 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*)***
-  %399 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %398, align 8, !tbaa !109, !noalias !130
-  %400 = getelementptr inbounds void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %399, i64 1
-  %401 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %400, align 8, !noalias !130
-  call void %401(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %395) #37, !noalias !130
-  br label %402
+405:                                              ; preds = %403
+  %406 = load atomic i8, i8* %379 unordered, align 8, !tbaa !50, !noalias !128
+  store i8 %406, i8* %404, align 1, !tbaa !50, !noalias !128
+  br label %408
 
-402:                                              ; preds = %397, %393
-  store %"class.kotlin::gc::GC::ThreadData::Impl"* null, %"class.kotlin::gc::GC::ThreadData::Impl"** %394, align 8, !tbaa !3, !noalias !130
-  %403 = load i8, i8* %359, align 8, !tbaa !112, !range !72, !noalias !130
-  %404 = icmp eq i8 %403, 0
-  br i1 %404, label %437, label %405
+407:                                              ; preds = %403
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %404, i8* nonnull align 8 %379, i64 %391, i1 false) #37, !noalias !128
+  br label %408
 
-405:                                              ; preds = %402
-  %406 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %407 = load i8*, i8** %406, align 8, !tbaa !58, !noalias !130
-  %408 = icmp eq i8* %407, %362
-  br i1 %408, label %437, label %409
+408:                                              ; preds = %407, %405, %403
+  %409 = getelementptr inbounds %"struct.std::_Head_base.132", %"struct.std::_Head_base.132"* %387, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %410 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
+  store i64 %391, i64* %410, align 8, !tbaa !51, !alias.scope !187, !noalias !128
+  %411 = load atomic i8*, i8** %409 unordered, align 8, !tbaa !47, !alias.scope !187, !noalias !128
+  %412 = getelementptr inbounds i8, i8* %411, i64 %391
+  store i8 0, i8* %412, align 1, !tbaa !50, !noalias !128
+  store i8 1, i8* %388, align 8, !tbaa !110, !alias.scope !187, !noalias !128
+  %413 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 1
+  %414 = bitcast %"struct.std::_Head_base.184"* %413 to i64*
+  store i64 ptrtoint (void (%"class.kotlin::ScopedThread::attributes"*, %class.anon.78*)* @"_ZN6kotlin12ScopedThread3RunIZNS_2gc22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS3_EERNS2_11GCSchedulerEE3$_3JEEENSt13invoke_resultIT_JDpT0_EE4typeENS0_10attributesEOSC_DpOSD_" to i64), i64* %414, align 8, !tbaa !191, !alias.scope !187, !noalias !128
+  %415 = invoke noalias nonnull dereferenceable(64) i8* @_Znwm(i64 64) #53
+          to label %416 unwind label %460, !noalias !128
 
-409:                                              ; preds = %405
-  call void @free(i8* %407) #37, !noalias !130
-  br label %437
+416:                                              ; preds = %408
+  %417 = bitcast i8* %415 to i32 (...)***
+  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @"_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc22ConcurrentMarkAndSweepC1ERNS3_2mm13ObjectFactoryIS7_EERNS6_11GCSchedulerEE3$_3ES5_SE_EEEEEE", i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %417, align 8, !tbaa !107, !noalias !193
+  %418 = getelementptr inbounds i8, i8* %415, i64 8
+  %419 = bitcast i8* %418 to i64*
+  %420 = load atomic i64, i64* %386 unordered, align 8, !tbaa !3, !noalias !193
+  store i64 %420, i64* %419, align 8, !tbaa !3, !noalias !193
+  %421 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0
+  %422 = getelementptr inbounds i8, i8* %415, i64 48
+  store i8 0, i8* %422, align 8, !tbaa !110, !noalias !193
+  %423 = getelementptr inbounds i8, i8* %415, i64 16
+  %424 = getelementptr inbounds i8, i8* %415, i64 32
+  %425 = bitcast i8* %423 to i8**
+  store i8* %424, i8** %425, align 8, !tbaa !45, !noalias !193
+  %426 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %421, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %427 = load atomic i8*, i8** %426 unordered, align 8, !tbaa !47, !noalias !193
+  %428 = bitcast %union.anon.108* %389 to i8*
+  %429 = icmp eq i8* %427, %428
+  br i1 %429, label %430, label %431
 
-410:                                              ; preds = %344
-  %411 = landingpad { i8*, i32 }
+430:                                              ; preds = %416
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(16) %424, i8* nonnull align 8 dereferenceable(16) %428, i64 16, i1 false) #37, !noalias !193
+  br label %435
+
+431:                                              ; preds = %416
+  store i8* %427, i8** %425, align 8, !tbaa !47, !noalias !193
+  %432 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
+  %433 = load atomic i64, i64* %432 unordered, align 8, !tbaa !50, !noalias !193
+  %434 = bitcast i8* %424 to i64*
+  store i64 %433, i64* %434, align 8, !tbaa !50, !noalias !193
+  br label %435
+
+435:                                              ; preds = %431, %430
+  %436 = load atomic i64, i64* %410 unordered, align 8, !tbaa !51, !noalias !193
+  %437 = getelementptr inbounds i8, i8* %415, i64 24
+  %438 = bitcast i8* %437 to i64*
+  store i64 %436, i64* %438, align 8, !tbaa !51, !noalias !193
+  %439 = bitcast %"class.kotlin::ScopedThread::attributes"* %421 to %union.anon.108**
+  store %union.anon.108* %389, %union.anon.108** %439, align 8, !tbaa !47, !noalias !193
+  store i64 0, i64* %410, align 8, !tbaa !51, !noalias !193
+  store i8 0, i8* %428, align 8, !tbaa !50, !noalias !193
+  store i8 1, i8* %422, align 8, !tbaa !110, !noalias !193
+  %440 = getelementptr inbounds i8, i8* %415, i64 56
+  %441 = bitcast i8* %440 to i64*
+  store i64 ptrtoint (void (%"class.kotlin::ScopedThread::attributes"*, %class.anon.78*)* @"_ZN6kotlin12ScopedThread3RunIZNS_2gc22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS3_EERNS2_11GCSchedulerEE3$_3JEEENSt13invoke_resultIT_JDpT0_EE4typeENS0_10attributesEOSC_DpOSD_" to i64), i64* %441, align 8, !tbaa !191, !noalias !193
+  %442 = bitcast %"class.std::unique_ptr"* %9 to i8**
+  store i8* %415, i8** %442, align 8, !tbaa !3, !alias.scope !196, !noalias !128
+  invoke void @_ZNSt6thread15_M_start_threadESt10unique_ptrINS_6_StateESt14default_deleteIS1_EEPFvvE(%"struct.std::atomic.0"* nonnull %382, %"class.std::unique_ptr"* nonnull %9, void ()* bitcast (i32 (i64*, %union.pthread_attr_t*, i8* (i8*)*, i8*)* @pthread_create to void ()*))
+          to label %443 unwind label %463, !noalias !128
+
+443:                                              ; preds = %435
+  %444 = getelementptr inbounds %"class.std::unique_ptr", %"class.std::unique_ptr"* %9, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %445 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %444 unordered, align 8, !tbaa !3, !noalias !128
+  %446 = icmp eq %"class.kotlin::gc::GC::ThreadData::Impl"* %445, null
+  br i1 %446, label %452, label %447
+
+447:                                              ; preds = %443
+  %448 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %445 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*)***
+  %449 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %448 unordered, align 8, !tbaa !107, !noalias !128
+  %450 = getelementptr inbounds void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %449, i64 1
+  %451 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %450 unordered, align 8, !noalias !128
+  call void %451(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %445) #37, !noalias !128
+  br label %452
+
+452:                                              ; preds = %447, %443
+  store %"class.kotlin::gc::GC::ThreadData::Impl"* null, %"class.kotlin::gc::GC::ThreadData::Impl"** %444, align 8, !tbaa !3, !noalias !128
+  %453 = load atomic i8, i8* %388 unordered, align 8, !tbaa !110, !range !70, !noalias !128
+  %454 = icmp eq i8 %453, 0
+  br i1 %454, label %487, label %455
+
+455:                                              ; preds = %452
+  %456 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %457 = load atomic i8*, i8** %456 unordered, align 8, !tbaa !47, !noalias !128
+  %458 = icmp eq i8* %457, %428
+  br i1 %458, label %487, label %459
+
+459:                                              ; preds = %455
+  call void @free(i8* %457) #37, !noalias !128
+  br label %487
+
+460:                                              ; preds = %408
+  %461 = landingpad { i8*, i32 }
           catch i8* null
-  %412 = extractvalue { i8*, i32 } %411, 0
-  br label %427
+  %462 = extractvalue { i8*, i32 } %461, 0
+  %.pre14 = bitcast %union.anon.108* %389 to i8*
+  br label %477
 
-413:                                              ; preds = %385
-  %414 = landingpad { i8*, i32 }
+463:                                              ; preds = %435
+  %464 = landingpad { i8*, i32 }
           catch i8* null
-  %415 = extractvalue { i8*, i32 } %414, 0
-  %416 = getelementptr inbounds %"class.std::unique_ptr", %"class.std::unique_ptr"* %9, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %417 = load %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %416, align 8, !tbaa !3, !noalias !130
-  %418 = icmp eq %"class.kotlin::gc::GC::ThreadData::Impl"* %417, null
-  br i1 %418, label %424, label %419
+  %465 = extractvalue { i8*, i32 } %464, 0
+  %466 = getelementptr inbounds %"class.std::unique_ptr", %"class.std::unique_ptr"* %9, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %467 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %466 unordered, align 8, !tbaa !3, !noalias !128
+  %468 = icmp eq %"class.kotlin::gc::GC::ThreadData::Impl"* %467, null
+  br i1 %468, label %474, label %469
 
-419:                                              ; preds = %413
-  %420 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %417 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*)***
-  %421 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %420, align 8, !tbaa !109, !noalias !130
-  %422 = getelementptr inbounds void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %421, i64 1
-  %423 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %422, align 8, !noalias !130
-  call void %423(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %417) #37, !noalias !130
-  br label %424
+469:                                              ; preds = %463
+  %470 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %467 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*)***
+  %471 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %470 unordered, align 8, !tbaa !107, !noalias !128
+  %472 = getelementptr inbounds void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %471, i64 1
+  %473 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %472 unordered, align 8, !noalias !128
+  call void %473(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %467) #37, !noalias !128
+  br label %474
 
-424:                                              ; preds = %419, %413
-  store %"class.kotlin::gc::GC::ThreadData::Impl"* null, %"class.kotlin::gc::GC::ThreadData::Impl"** %416, align 8, !tbaa !3, !noalias !130
-  %425 = load i8, i8* %359, align 8, !tbaa !112, !range !72, !noalias !130
-  %426 = icmp eq i8 %425, 0
-  br i1 %426, label %433, label %427
+474:                                              ; preds = %469, %463
+  store %"class.kotlin::gc::GC::ThreadData::Impl"* null, %"class.kotlin::gc::GC::ThreadData::Impl"** %466, align 8, !tbaa !3, !noalias !128
+  %475 = load atomic i8, i8* %388 unordered, align 8, !tbaa !110, !range !70, !noalias !128
+  %476 = icmp eq i8 %475, 0
+  br i1 %476, label %483, label %477
 
-427:                                              ; preds = %424, %410
-  %428 = phi i8* [ %412, %410 ], [ %415, %424 ]
-  %429 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %430 = load i8*, i8** %429, align 8, !tbaa !58, !noalias !130
-  %431 = icmp eq i8* %430, %362
-  br i1 %431, label %433, label %432
+477:                                              ; preds = %474, %460
+  %.pre-phi15 = phi i8* [ %428, %474 ], [ %.pre14, %460 ]
+  %478 = phi i8* [ %465, %474 ], [ %462, %460 ]
+  %479 = getelementptr inbounds %"struct.std::thread::_Invoker.150", %"struct.std::thread::_Invoker.150"* %10, i64 0, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %480 = load atomic i8*, i8** %479 unordered, align 8, !tbaa !47, !noalias !128
+  %481 = icmp eq i8* %480, %.pre-phi15
+  br i1 %481, label %483, label %482
 
-432:                                              ; preds = %427
-  call void @free(i8* %430) #37, !noalias !130
-  br label %433
+482:                                              ; preds = %477
+  call void @free(i8* %480) #37, !noalias !128
+  br label %483
 
-433:                                              ; preds = %432, %427, %424
-  %434 = phi i8* [ %428, %432 ], [ %428, %427 ], [ %415, %424 ]
-  call void @llvm.lifetime.end.p0i8(i64 56, i8* nonnull %356) #37, !noalias !130
-  %435 = load i8, i8* %347, align 8, !tbaa !112, !range !72, !noalias !130
-  %436 = icmp eq i8 %435, 0
-  br i1 %436, label %455, label %450
+483:                                              ; preds = %482, %477, %474
+  %484 = phi i8* [ %478, %482 ], [ %478, %477 ], [ %465, %474 ]
+  call void @llvm.lifetime.end.p0i8(i64 56, i8* nonnull %385) #37, !noalias !128
+  %485 = load atomic i8, i8* %376 unordered, align 8, !tbaa !110, !range !70, !noalias !128
+  %486 = icmp eq i8 %485, 0
+  br i1 %486, label %505, label %500
 
-437:                                              ; preds = %409, %405, %402
-  call void @llvm.lifetime.end.p0i8(i64 56, i8* nonnull %356) #37, !noalias !130
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %354) #37, !noalias !130
-  %438 = load i64, i64* %59, align 8, !tbaa.struct !88, !noalias !130
-  %439 = icmp eq i64 %438, 0
-  br i1 %439, label %441, label %440
+487:                                              ; preds = %459, %455, %452
+  call void @llvm.lifetime.end.p0i8(i64 56, i8* nonnull %385) #37, !noalias !128
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %383) #37, !noalias !128
+  %488 = load atomic i64, i64* %59 unordered, align 8, !tbaa.struct !86, !noalias !128
+  %489 = icmp eq i64 %488, 0
+  br i1 %489, label %491, label %490
 
-440:                                              ; preds = %437
-  call void @_ZSt9terminatev() #51, !noalias !130
+490:                                              ; preds = %487
+  call void @_ZSt9terminatev() #51, !noalias !128
   unreachable
 
-441:                                              ; preds = %437
-  %442 = load i64, i64* %355, align 8, !tbaa !89, !noalias !130
-  store i64 %442, i64* %59, align 8, !tbaa !89, !noalias !130
-  store i64 0, i64* %355, align 8, !tbaa !89, !noalias !130
-  %443 = load i8, i8* %347, align 8, !tbaa !112, !range !72, !noalias !130
-  %444 = icmp eq i8 %443, 0
-  br i1 %444, label %_ZN6kotlin2mm10GlobalDataC2Ev.exit, label %445
+491:                                              ; preds = %487
+  %492 = load atomic i64, i64* %384 unordered, align 8, !tbaa !87, !noalias !128
+  store i64 %492, i64* %59, align 8, !tbaa !87, !noalias !128
+  store i64 0, i64* %384, align 8, !tbaa !87, !noalias !128
+  %493 = load atomic i8, i8* %376 unordered, align 8, !tbaa !110, !range !70, !noalias !128
+  %494 = icmp eq i8 %493, 0
+  br i1 %494, label %_ZN6kotlin2mm10GlobalDataC2Ev.exit, label %495
 
-445:                                              ; preds = %441
-  %446 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %447 = load i8*, i8** %446, align 8, !tbaa !58, !noalias !130
-  %448 = icmp eq i8* %447, %350
-  br i1 %448, label %_ZN6kotlin2mm10GlobalDataC2Ev.exit, label %449
+495:                                              ; preds = %491
+  %496 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %497 = load atomic i8*, i8** %496 unordered, align 8, !tbaa !47, !noalias !128
+  %498 = icmp eq i8* %497, %379
+  br i1 %498, label %_ZN6kotlin2mm10GlobalDataC2Ev.exit, label %499
 
-449:                                              ; preds = %445
-  call void @free(i8* %447) #37, !noalias !130
+499:                                              ; preds = %495
+  call void @free(i8* %497) #37, !noalias !128
   br label %_ZN6kotlin2mm10GlobalDataC2Ev.exit
 
-450:                                              ; preds = %433
-  %451 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %452 = load i8*, i8** %451, align 8, !tbaa !58, !noalias !130
-  %453 = icmp eq i8* %452, %350
-  br i1 %453, label %455, label %454
+500:                                              ; preds = %483
+  %501 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %13, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %502 = load atomic i8*, i8** %501 unordered, align 8, !tbaa !47, !noalias !128
+  %503 = icmp eq i8* %502, %379
+  br i1 %503, label %505, label %504
 
-454:                                              ; preds = %450
-  call void @free(i8* %452) #37, !noalias !130
-  br label %455
+504:                                              ; preds = %500
+  call void @free(i8* %502) #37, !noalias !128
+  br label %505
 
-455:                                              ; preds = %454, %450, %433
-  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %346) #37, !noalias !130
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %345) #37, !noalias !130
-  %456 = bitcast i8* %60 to %"class.kotlin::gc::FinalizerProcessor"**
-  %457 = load %"class.kotlin::gc::FinalizerProcessor"*, %"class.kotlin::gc::FinalizerProcessor"** %456, align 8, !tbaa !3, !noalias !130
-  %458 = icmp eq %"class.kotlin::gc::FinalizerProcessor"* %457, null
-  br i1 %458, label %551, label %459
+505:                                              ; preds = %504, %500, %483
+  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %375) #37, !noalias !128
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %374) #37, !noalias !128
+  %506 = bitcast i8* %60 to %"class.kotlin::gc::FinalizerProcessor"**
+  %507 = load atomic %"class.kotlin::gc::FinalizerProcessor"*, %"class.kotlin::gc::FinalizerProcessor"** %506 unordered, align 8, !tbaa !3, !noalias !128
+  %508 = icmp eq %"class.kotlin::gc::FinalizerProcessor"* %507, null
+  br i1 %508, label %601, label %509
 
-459:                                              ; preds = %455
-  %460 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %457, i64 0, i32 3
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %461, label %467
+509:                                              ; preds = %505
+  %510 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %507, i64 0, i32 3
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %511, label %517
 
-461:                                              ; preds = %459
-  %462 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %460, i64 0, i32 0, i32 0
-  %463 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull %462) #37, !noalias !130
-  %464 = icmp eq i32 %463, 0
-  br i1 %464, label %467, label %465
+511:                                              ; preds = %509
+  %512 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %510, i64 0, i32 0, i32 0
+  %513 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull %512) #37, !noalias !128
+  %514 = icmp eq i32 %513, 0
+  br i1 %514, label %517, label %515
 
-465:                                              ; preds = %461
-  invoke void @_ZSt20__throw_system_errori(i32 %463) #50
-          to label %466 unwind label %471, !noalias !130
+515:                                              ; preds = %511
+  invoke void @_ZSt20__throw_system_errori(i32 %513) #50
+          to label %516 unwind label %521, !noalias !128
 
-466:                                              ; preds = %465
+516:                                              ; preds = %515
   unreachable
 
-467:                                              ; preds = %461, %459
-  %468 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %457, i64 0, i32 0, i32 0, i32 0, i32 0
-  %469 = load i64, i64* %468, align 8, !tbaa.struct !88, !noalias !130
-  %470 = icmp eq i64 %469, 0
-  br i1 %470, label %481, label %473
+517:                                              ; preds = %511, %509
+  %518 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %507, i64 0, i32 0, i32 0, i32 0, i32 0
+  %519 = load atomic i64, i64* %518 unordered, align 8, !tbaa.struct !86, !noalias !128
+  %520 = icmp eq i64 %519, 0
+  br i1 %520, label %531, label %523
 
-471:                                              ; preds = %465
-  %472 = landingpad { i8*, i32 }
+521:                                              ; preds = %515
+  %522 = landingpad { i8*, i32 }
           catch i8* null
-  br label %503
+  br label %553
 
-473:                                              ; preds = %467
-  %474 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %457, i64 0, i32 6
-  store i8 1, i8* %474, align 8, !tbaa !163, !noalias !130
-  %475 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %457, i64 0, i32 2
-  call void @_ZNSt18condition_variable10notify_allEv(%"class.std::condition_variable"* nonnull %475) #37, !noalias !130
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %476, label %479
+523:                                              ; preds = %517
+  %524 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %507, i64 0, i32 6
+  store i8 1, i8* %524, align 8, !tbaa !161, !noalias !128
+  %525 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %507, i64 0, i32 2
+  call void @_ZNSt18condition_variable10notify_allEv(%"class.std::condition_variable"* nonnull %525) #37, !noalias !128
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %526, label %529
 
-476:                                              ; preds = %473
-  %477 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %460, i64 0, i32 0, i32 0
-  %478 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %477) #37, !noalias !130
-  br label %479
+526:                                              ; preds = %523
+  %527 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %510, i64 0, i32 0, i32 0
+  %528 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %527) #37, !noalias !128
+  br label %529
 
-479:                                              ; preds = %476, %473
-  %480 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %457, i64 0, i32 0, i32 0
-  invoke void @_ZNSt6thread4joinEv(%"struct.std::atomic.0"* nonnull %480)
-          to label %485 unwind label %500, !noalias !130
+529:                                              ; preds = %526, %523
+  %530 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %507, i64 0, i32 0, i32 0
+  invoke void @_ZNSt6thread4joinEv(%"struct.std::atomic.0"* nonnull %530)
+          to label %535 unwind label %550, !noalias !128
 
-481:                                              ; preds = %467
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %482, label %_ZN6kotlin2gc18FinalizerProcessor19StopFinalizerThreadEv.exit.i.i.i.i
+531:                                              ; preds = %517
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %532, label %_ZN6kotlin2gc18FinalizerProcessor19StopFinalizerThreadEv.exit.i.i.i.i
 
-482:                                              ; preds = %481
-  %483 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %460, i64 0, i32 0, i32 0
-  %484 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %483) #37, !noalias !130
+532:                                              ; preds = %531
+  %533 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %510, i64 0, i32 0, i32 0
+  %534 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %533) #37, !noalias !128
   br label %_ZN6kotlin2gc18FinalizerProcessor19StopFinalizerThreadEv.exit.i.i.i.i
 
-485:                                              ; preds = %479
-  store i8 0, i8* %474, align 8, !tbaa !163, !noalias !130
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %486, label %496
+535:                                              ; preds = %529
+  store i8 0, i8* %524, align 8, !tbaa !161, !noalias !128
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %536, label %546
 
-486:                                              ; preds = %485
-  %487 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %460, i64 0, i32 0, i32 0
-  %488 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull %487) #37, !noalias !130
-  %489 = icmp eq i32 %488, 0
-  br i1 %489, label %492, label %490
+536:                                              ; preds = %535
+  %537 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %510, i64 0, i32 0, i32 0
+  %538 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull %537) #37, !noalias !128
+  %539 = icmp eq i32 %538, 0
+  br i1 %539, label %542, label %540
 
-490:                                              ; preds = %486
-  invoke void @_ZSt20__throw_system_errori(i32 %488) #50
-          to label %491 unwind label %498, !noalias !130
+540:                                              ; preds = %536
+  invoke void @_ZSt20__throw_system_errori(i32 %538) #50
+          to label %541 unwind label %548, !noalias !128
 
-491:                                              ; preds = %490
+541:                                              ; preds = %540
   unreachable
 
-492:                                              ; preds = %486
-  %493 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %457, i64 0, i32 7
-  store i8 1, i8* %493, align 1, !tbaa !164, !noalias !130
-  call void @_ZNSt18condition_variable10notify_allEv(%"class.std::condition_variable"* nonnull %475) #37, !noalias !130
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %494, label %_ZN6kotlin2gc18FinalizerProcessor19StopFinalizerThreadEv.exit.i.i.i.i
+542:                                              ; preds = %536
+  %543 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %507, i64 0, i32 7
+  store i8 1, i8* %543, align 1, !tbaa !162, !noalias !128
+  call void @_ZNSt18condition_variable10notify_allEv(%"class.std::condition_variable"* nonnull %525) #37, !noalias !128
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %544, label %_ZN6kotlin2gc18FinalizerProcessor19StopFinalizerThreadEv.exit.i.i.i.i
 
-494:                                              ; preds = %492
-  %495 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %487) #37, !noalias !130
+544:                                              ; preds = %542
+  %545 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %537) #37, !noalias !128
   br label %_ZN6kotlin2gc18FinalizerProcessor19StopFinalizerThreadEv.exit.i.i.i.i
 
-496:                                              ; preds = %485
-  %497 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %457, i64 0, i32 7
-  store i8 1, i8* %497, align 1, !tbaa !164, !noalias !130
-  call void @_ZNSt18condition_variable10notify_allEv(%"class.std::condition_variable"* nonnull %475) #37, !noalias !130
+546:                                              ; preds = %535
+  %547 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %507, i64 0, i32 7
+  store i8 1, i8* %547, align 1, !tbaa !162, !noalias !128
+  call void @_ZNSt18condition_variable10notify_allEv(%"class.std::condition_variable"* nonnull %525) #37, !noalias !128
   br label %_ZN6kotlin2gc18FinalizerProcessor19StopFinalizerThreadEv.exit.i.i.i.i
 
-498:                                              ; preds = %490
-  %499 = landingpad { i8*, i32 }
+548:                                              ; preds = %540
+  %549 = landingpad { i8*, i32 }
           catch i8* null
-  br label %503
+  br label %553
 
-500:                                              ; preds = %479
-  %501 = landingpad { i8*, i32 }
+550:                                              ; preds = %529
+  %551 = landingpad { i8*, i32 }
           catch i8* null
-  %502 = extractvalue { i8*, i32 } %501, 0
-  call fastcc void @__clang_call_terminate(i8* %502) #51, !noalias !130
+  %552 = extractvalue { i8*, i32 } %551, 0
+  call fastcc void @__clang_call_terminate(i8* %552) #51, !noalias !128
   unreachable
 
-503:                                              ; preds = %498, %471
-  %504 = phi { i8*, i32 } [ %499, %498 ], [ %472, %471 ]
-  %505 = extractvalue { i8*, i32 } %504, 0
-  call fastcc void @__clang_call_terminate(i8* %505) #51, !noalias !130
+553:                                              ; preds = %548, %521
+  %554 = phi { i8*, i32 } [ %549, %548 ], [ %522, %521 ]
+  %555 = extractvalue { i8*, i32 } %554, 0
+  call fastcc void @__clang_call_terminate(i8* %555) #51, !noalias !128
   unreachable
 
-_ZN6kotlin2gc18FinalizerProcessor19StopFinalizerThreadEv.exit.i.i.i.i: ; preds = %496, %494, %492, %482, %481
-  %506 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %457, i64 0, i32 9
-  call void @_ZNSt18condition_variableD1Ev(%"class.std::condition_variable"* nonnull %506) #37, !noalias !130
-  %507 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %457, i64 0, i32 4, i32 0, i32 1
-  %508 = load i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %507, align 8, !tbaa !103, !noalias !130
-  %509 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %508, null
-  br i1 %509, label %516, label %510
+_ZN6kotlin2gc18FinalizerProcessor19StopFinalizerThreadEv.exit.i.i.i.i: ; preds = %546, %544, %542, %532, %531
+  %556 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %507, i64 0, i32 9
+  call void @_ZNSt18condition_variableD1Ev(%"class.std::condition_variable"* nonnull %556) #37, !noalias !128
+  %557 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %507, i64 0, i32 4, i32 0, i32 1
+  %558 = load atomic i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %557 unordered, align 8, !tbaa !101, !noalias !128
+  %559 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %558, null
+  br i1 %559, label %566, label %560
 
-510:                                              ; preds = %_ZN6kotlin2gc18FinalizerProcessor19StopFinalizerThreadEv.exit.i.i.i.i
-  %511 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %457, i64 0, i32 4, i32 0, i32 0
-  %512 = invoke zeroext i1 %508(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %511, %"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %511, i32 3)
-          to label %516 unwind label %513, !noalias !130
+560:                                              ; preds = %_ZN6kotlin2gc18FinalizerProcessor19StopFinalizerThreadEv.exit.i.i.i.i
+  %561 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %507, i64 0, i32 4, i32 0, i32 0
+  %562 = invoke zeroext i1 %558(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %561, %"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %561, i32 3)
+          to label %566 unwind label %563, !noalias !128
 
-513:                                              ; preds = %510
-  %514 = landingpad { i8*, i32 }
+563:                                              ; preds = %560
+  %564 = landingpad { i8*, i32 }
           catch i8* null
-  %515 = extractvalue { i8*, i32 } %514, 0
-  call fastcc void @__clang_call_terminate(i8* %515) #51, !noalias !130
+  %565 = extractvalue { i8*, i32 } %564, 0
+  call fastcc void @__clang_call_terminate(i8* %565) #51, !noalias !128
   unreachable
 
-516:                                              ; preds = %510, %_ZN6kotlin2gc18FinalizerProcessor19StopFinalizerThreadEv.exit.i.i.i.i
-  %517 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %457, i64 0, i32 2
-  call void @_ZNSt18condition_variableD1Ev(%"class.std::condition_variable"* nonnull %517) #37, !noalias !130
-  %518 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %457, i64 0, i32 1, i32 1
-  %519 = bitcast %"class.std::unique_ptr.112"* %1 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %519) #37, !noalias !130
-  %520 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer"* %518, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %521 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer"* %518 to i64*
-  %522 = load i64, i64* %521, align 8, !tbaa !3, !noalias !130
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %520, align 8, !tbaa !3, !noalias !130
-  %523 = bitcast %"class.std::unique_ptr.112"* %1 to i64*
-  store i64 %522, i64* %523, align 8, !tbaa !198, !noalias !130
-  %524 = getelementptr inbounds %"class.std::unique_ptr.112", %"class.std::unique_ptr.112"* %1, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %525 = icmp eq i64 %522, 0
-  br i1 %525, label %.loopexit, label %.preheader
+566:                                              ; preds = %560, %_ZN6kotlin2gc18FinalizerProcessor19StopFinalizerThreadEv.exit.i.i.i.i
+  %567 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %507, i64 0, i32 2
+  call void @_ZNSt18condition_variableD1Ev(%"class.std::condition_variable"* nonnull %567) #37, !noalias !128
+  %568 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %507, i64 0, i32 1, i32 1
+  %569 = bitcast %"class.std::unique_ptr.112"* %1 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %569) #37, !noalias !128
+  %570 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer"* %568, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %571 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer"* %568 to i64*
+  %572 = load atomic i64, i64* %571 unordered, align 8, !tbaa !3, !noalias !128
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %570, align 8, !tbaa !3, !noalias !128
+  %573 = bitcast %"class.std::unique_ptr.112"* %1 to i64*
+  store i64 %572, i64* %573, align 8, !tbaa !197, !noalias !128
+  %574 = getelementptr inbounds %"class.std::unique_ptr.112", %"class.std::unique_ptr.112"* %1, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %575 = icmp eq i64 %572, 0
+  br i1 %575, label %.loopexit, label %.preheader
 
-.preheader:                                       ; preds = %536, %516
-  %526 = phi i64 [ %530, %536 ], [ %522, %516 ]
-  %527 = inttoptr i64 %526 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
-  %528 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %527, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %529 = inttoptr i64 %526 to i64*
-  %530 = load i64, i64* %529, align 8, !tbaa !3, !noalias !130
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %528, align 8, !tbaa !3, !noalias !130
-  %531 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %524, align 8, !tbaa !3, !noalias !130
-  store i64 %530, i64* %523, align 8, !tbaa !3, !noalias !130
-  %532 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %531, null
-  br i1 %532, label %536, label %533
+.preheader:                                       ; preds = %586, %566
+  %576 = phi i64 [ %580, %586 ], [ %572, %566 ]
+  %577 = inttoptr i64 %576 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
+  %578 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %577, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %579 = inttoptr i64 %576 to i64*
+  %580 = load atomic i64, i64* %579 unordered, align 8, !tbaa !3, !noalias !128
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %578, align 8, !tbaa !3, !noalias !128
+  %581 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %574 unordered, align 8, !tbaa !3, !noalias !128
+  store i64 %580, i64* %573, align 8, !tbaa !3, !noalias !128
+  %582 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %581, null
+  br i1 %582, label %586, label %583
 
-533:                                              ; preds = %.preheader
-  %534 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %531, i64 0, i32 0
-  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %534) #37, !noalias !130
-  %535 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %531 to i8*
-  call fastcc void @mi_free(i8* nonnull %535) #37, !noalias !130
-  br label %536
+583:                                              ; preds = %.preheader
+  %584 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %581, i64 0, i32 0
+  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %584) #37, !noalias !128
+  %585 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %581 to i8*
+  call fastcc void @mi_free(i8* nonnull %585) #37, !noalias !128
+  br label %586
 
-536:                                              ; preds = %533, %.preheader
-  %537 = icmp eq i64 %530, 0
-  br i1 %537, label %.loopexit, label %.preheader
+586:                                              ; preds = %583, %.preheader
+  %587 = icmp eq i64 %580, 0
+  br i1 %587, label %.loopexit, label %.preheader
 
-.loopexit:                                        ; preds = %536, %516
-  %538 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer"* %518, i64 0, i32 0
-  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %1) #37, !noalias !130
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %519) #37, !noalias !130
-  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %538) #37, !noalias !130
-  %539 = load i64, i64* %468, align 8, !noalias !130
-  %540 = icmp eq i64 %539, 0
-  br i1 %540, label %_ZN6kotlin2gc18FinalizerProcessorD2Ev.exit.i.i.i, label %541
+.loopexit:                                        ; preds = %586, %566
+  %588 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer"* %568, i64 0, i32 0
+  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %1) #37, !noalias !128
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %569) #37, !noalias !128
+  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %588) #37, !noalias !128
+  %589 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %507, i64 0, i32 0, i32 0
+  %590 = load atomic i64, i64* %518 unordered, align 8, !noalias !128
+  %591 = icmp eq i64 %590, 0
+  br i1 %591, label %_ZN6kotlin2gc18FinalizerProcessorD2Ev.exit.i.i.i, label %592
 
-541:                                              ; preds = %.loopexit
-  %542 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %457, i64 0, i32 0, i32 0
-  invoke void @_ZNSt6thread4joinEv(%"struct.std::atomic.0"* nonnull %542)
-          to label %546 unwind label %543, !noalias !130
+592:                                              ; preds = %.loopexit
+  invoke void @_ZNSt6thread4joinEv(%"struct.std::atomic.0"* nonnull %589)
+          to label %596 unwind label %593, !noalias !128
 
-543:                                              ; preds = %541
-  %544 = landingpad { i8*, i32 }
+593:                                              ; preds = %592
+  %594 = landingpad { i8*, i32 }
           catch i8* null
-  %545 = extractvalue { i8*, i32 } %544, 0
-  %.idx.val = load i64, i64* %468, align 8, !tbaa.struct !88
-  call fastcc void @_ZNSt6threadD2Ev(i64 %.idx.val) #37
-  call fastcc void @__clang_call_terminate(i8* %545) #51, !noalias !130
+  %595 = extractvalue { i8*, i32 } %594, 0
+  call fastcc void @_ZNSt6threadD2Ev(%"struct.std::atomic.0"* nonnull %589) #37, !noalias !128
+  call fastcc void @__clang_call_terminate(i8* %595) #51, !noalias !128
   unreachable
 
-546:                                              ; preds = %541
-  %547 = load i64, i64* %468, align 8, !tbaa.struct !88, !noalias !130
-  %548 = icmp eq i64 %547, 0
-  br i1 %548, label %_ZN6kotlin2gc18FinalizerProcessorD2Ev.exit.i.i.i, label %549
+596:                                              ; preds = %592
+  %597 = load atomic i64, i64* %518 unordered, align 8, !tbaa.struct !86, !noalias !128
+  %598 = icmp eq i64 %597, 0
+  br i1 %598, label %_ZN6kotlin2gc18FinalizerProcessorD2Ev.exit.i.i.i, label %599
 
-549:                                              ; preds = %546
-  call void @_ZSt9terminatev() #51, !noalias !130
+599:                                              ; preds = %596
+  call void @_ZSt9terminatev() #51, !noalias !128
   unreachable
 
-_ZN6kotlin2gc18FinalizerProcessorD2Ev.exit.i.i.i: ; preds = %546, %.loopexit
-  %550 = bitcast %"class.kotlin::gc::FinalizerProcessor"* %457 to i8*
-  call void @free(i8* %550) #37, !noalias !130
-  br label %551
+_ZN6kotlin2gc18FinalizerProcessorD2Ev.exit.i.i.i: ; preds = %596, %.loopexit
+  %600 = bitcast %"class.kotlin::gc::FinalizerProcessor"* %507 to i8*
+  call void @free(i8* %600) #37, !noalias !128
+  br label %601
 
-551:                                              ; preds = %_ZN6kotlin2gc18FinalizerProcessorD2Ev.exit.i.i.i, %455
-  %552 = bitcast i8* %58 to %"struct.std::chrono::time_point"*
-  %553 = bitcast i8* %34 to %class.GCStateHolder*
-  store %"class.kotlin::gc::FinalizerProcessor"* null, %"class.kotlin::gc::FinalizerProcessor"** %456, align 8, !tbaa !3, !noalias !130
-  call fastcc void @_ZN6kotlin12ScopedThreadD2Ev(%"struct.std::chrono::time_point"* nonnull %552) #37, !noalias !130
-  call fastcc void @_ZN13GCStateHolderD2Ev(%class.GCStateHolder* nonnull %553) #37, !noalias !130
-  call fastcc void @__clang_call_terminate(i8* %434) #51, !noalias !130
+601:                                              ; preds = %_ZN6kotlin2gc18FinalizerProcessorD2Ev.exit.i.i.i, %505
+  %602 = bitcast i8* %58 to %"struct.std::chrono::time_point"*
+  %603 = bitcast i8* %34 to %class.GCStateHolder*
+  store %"class.kotlin::gc::FinalizerProcessor"* null, %"class.kotlin::gc::FinalizerProcessor"** %506, align 8, !tbaa !3, !noalias !128
+  call fastcc void @_ZN6kotlin12ScopedThreadD2Ev(%"struct.std::chrono::time_point"* nonnull %602) #37, !noalias !128
+  call fastcc void @_ZN13GCStateHolderD2Ev(%class.GCStateHolder* nonnull %603) #37, !noalias !128
+  call fastcc void @__clang_call_terminate(i8* %484) #51, !noalias !128
   unreachable
 
-_ZN6kotlin2mm10GlobalDataC2Ev.exit:               ; preds = %449, %445, %441
-  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %346) #37, !noalias !130
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %345) #37, !noalias !130
-  %554 = getelementptr inbounds i8, i8* %14, i64 504
-  %555 = bitcast i8* %554 to i32*
-  store i32 0, i32* %555, align 8, !tbaa !200, !noalias !130
+_ZN6kotlin2mm10GlobalDataC2Ev.exit:               ; preds = %499, %495, %491
+  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %375) #37, !noalias !128
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %374) #37, !noalias !128
+  %604 = getelementptr inbounds i8, i8* %14, i64 504
+  %605 = bitcast i8* %604 to i32*
+  store i32 0, i32* %605, align 8, !tbaa !199, !noalias !128
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %29) #37
-  %556 = ptrtoint i8* %14 to i64
-  store i64 %556, i64* bitcast (%"class.kotlin::gc::GC"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 6) to i64*), align 8, !tbaa !201, !alias.scope !130
+  %606 = ptrtoint i8* %14 to i64
+  store i64 %606, i64* bitcast (%"class.kotlin::gc::GC"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 6) to i64*), align 8, !tbaa !200, !alias.scope !128
   ret void
 }
 
 ; Function Attrs: nounwind uwtable
 define internal void @_GLOBAL__sub_I_CallsChecker.cpp() #17 section ".text.startup" personality i32 (...)* @__gxx_personality_v0 {
   %1 = alloca %"class.std::basic_string_view", align 8
-  store %"struct.std::__detail::_Hash_node_base"** getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 0, i32 0, i32 5), %"struct.std::__detail::_Hash_node_base"*** getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 0, i32 0, i32 0), align 8, !tbaa !203
-  store i64 1, i64* getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !208
+  store %"struct.std::__detail::_Hash_node_base"** getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 0, i32 0, i32 5), %"struct.std::__detail::_Hash_node_base"*** getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 0, i32 0, i32 0), align 8, !tbaa !202
+  store i64 1, i64* getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !207
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) bitcast (%"struct.std::__detail::_Hash_node_base"** getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 0, i32 0, i32 2, i32 0) to i8*), i8 0, i64 16, i1 false) #37
-  store float 1.000000e+00, float* getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 0, i32 0, i32 4, i32 0), align 8, !tbaa !209
+  store float 1.000000e+00, float* getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 0, i32 0, i32 4, i32 0), align 8, !tbaa !208
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(3792) bitcast (i64* getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 0, i32 0, i32 4, i32 1) to i8*), i8 0, i64 3792, i1 false)
   br label %2
 
@@ -22772,7 +23256,7 @@
   %3 = phi i64 [ %16, %10 ], [ 236, %0 ]
   %4 = phi %"class.std::basic_string_view"* [ %15, %10 ], [ getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 1, i64 0), %0 ]
   %5 = phi i8** [ %14, %10 ], [ getelementptr inbounds ([236 x i8*], [236 x i8*]* @Kotlin_callsCheckerGoodFunctionNames, i64 0, i64 0), %0 ]
-  %6 = load i8*, i8** %5, align 8, !tbaa !3
+  %6 = load atomic i8*, i8** %5 unordered, align 8, !tbaa !3
   %7 = icmp eq i8* %6, null
   br i1 %7, label %10, label %8
 
@@ -22783,9 +23267,9 @@
 10:                                               ; preds = %8, %2
   %11 = phi i64 [ 0, %2 ], [ %9, %8 ]
   %12 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %4, i64 0, i32 0
-  store i64 %11, i64* %12, align 8, !tbaa.struct !210
+  store i64 %11, i64* %12, align 8, !tbaa.struct !209
   %13 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %4, i64 0, i32 1
-  store i8* %6, i8** %13, align 8, !tbaa.struct !210
+  store i8* %6, i8** %13, align 8, !tbaa.struct !209
   %14 = getelementptr inbounds i8*, i8** %5, i64 1
   %15 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %4, i64 1
   %16 = add nsw i64 %3, -1
@@ -22804,17 +23288,17 @@
   %22 = phi %"class.std::basic_string_view"* [ getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 1, i64 1), %19 ], [ %66, %65 ]
   %23 = phi %"class.std::basic_string_view"* [ getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 1, i64 0), %19 ], [ %22, %65 ]
   %24 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %22, i64 0, i32 0
-  %25 = load i64, i64* %24, align 8, !tbaa.struct !210
-  %26 = load i64, i64* getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 1, i64 0, i32 0), align 8, !tbaa.struct !210
+  %25 = load atomic i64, i64* %24 unordered, align 8, !tbaa.struct !209
+  %26 = load atomic i64, i64* getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 1, i64 0, i32 0) unordered, align 8, !tbaa.struct !209
   %27 = icmp ugt i64 %25, %26
   %28 = select i1 %27, i64 %26, i64 %25
   %29 = icmp eq i64 %28, 0
   br i1 %29, label %36, label %30
 
 30:                                               ; preds = %21
-  %31 = load i8*, i8** getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 1, i64 0, i32 1), align 8, !tbaa.struct !210
+  %31 = load atomic i8*, i8** getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 1, i64 0, i32 1) unordered, align 8, !tbaa.struct !209
   %32 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %23, i64 1, i32 1
-  %33 = load i8*, i8** %32, align 8, !tbaa.struct !210
+  %33 = load atomic i8*, i8** %32 unordered, align 8, !tbaa.struct !209
   %34 = tail call i32 @memcmp(i8* %33, i8* %31, i64 %28) #37
   %35 = icmp eq i32 %34, 0
   br i1 %35, label %36, label %43
@@ -22838,7 +23322,7 @@
 46:                                               ; preds = %43
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %20)
   %47 = bitcast %"class.std::basic_string_view"* %22 to i8*
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %20, i8* nonnull align 8 dereferenceable(16) %47, i64 16, i1 false) #37, !tbaa.struct !210
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %20, i8* nonnull align 8 dereferenceable(16) %47, i64 16, i1 false) #37, !tbaa.struct !209
   %48 = ptrtoint %"class.std::basic_string_view"* %22 to i64
   %49 = sub i64 %48, ptrtoint (%"class.std::basic_string_view"* getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 1, i64 0) to i64)
   %50 = icmp sgt i64 %49, 0
@@ -22857,13 +23341,13 @@
   %59 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %56, i64 -1
   %60 = bitcast %"class.std::basic_string_view"* %59 to i8*
   %61 = bitcast %"class.std::basic_string_view"* %58 to i8*
-  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %60, i8* nonnull align 8 dereferenceable(16) %61, i64 16, i1 false) #37, !tbaa.struct !210
+  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %60, i8* nonnull align 8 dereferenceable(16) %61, i64 16, i1 false) #37, !tbaa.struct !209
   %62 = add nsw i64 %55, -1
   %63 = icmp sgt i64 %55, 1
   br i1 %63, label %54, label %.loopexit9
 
 .loopexit9:                                       ; preds = %54, %46
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) bitcast (%"class.std::basic_string_view"* getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 1, i64 0) to i8*), i8* nonnull align 8 dereferenceable(16) %20, i64 16, i1 false) #37, !tbaa.struct !210
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) bitcast (%"class.std::basic_string_view"* getelementptr inbounds (%"class.(anonymous namespace)::KnownFunctionChecker", %"class.(anonymous namespace)::KnownFunctionChecker"* @_ZN12_GLOBAL__N_17checkerE, i64 0, i32 1, i64 0) to i8*), i8* nonnull align 8 dereferenceable(16) %20, i64 16, i1 false) #37, !tbaa.struct !209
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %20)
   br label %65
 
@@ -22943,9 +23427,9 @@
   %36 = add nsw i64 %35, -2
   %37 = sdiv i64 %36, 2
   %38 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %37, i32 0
-  %39 = load i64, i64* %38, align 8, !tbaa.struct !210
+  %39 = load atomic i64, i64* %38 unordered, align 8, !tbaa.struct !209
   %40 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %37, i32 1
-  %41 = load i8*, i8** %40, align 8, !tbaa.struct !210
+  %41 = load atomic i8*, i8** %40 unordered, align 8, !tbaa.struct !209
   tail call fastcc void @_ZSt13__adjust_heapIPSt17basic_string_viewIcSt11char_traitsIcEElS3_N9__gnu_cxx5__ops15_Iter_less_iterEEvT_T0_S9_T1_T2_(%"class.std::basic_string_view"* %0, i64 %37, i64 %35, i64 %39, i8* %41)
   br label %42
 
@@ -22957,9 +23441,9 @@
 
 .split1:                                          ; preds = %42
   %46 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %45, i32 0
-  %47 = load i64, i64* %46, align 8, !tbaa.struct !210
+  %47 = load atomic i64, i64* %46 unordered, align 8, !tbaa.struct !209
   %48 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %45, i32 1
-  %49 = load i8*, i8** %48, align 8, !tbaa.struct !210
+  %49 = load atomic i8*, i8** %48 unordered, align 8, !tbaa.struct !209
   tail call fastcc void @_ZSt13__adjust_heapIPSt17basic_string_viewIcSt11char_traitsIcEElS3_N9__gnu_cxx5__ops15_Iter_less_iterEEvT_T0_S9_T1_T2_(%"class.std::basic_string_view"* %0, i64 %45, i64 %35, i64 %47, i8* %49)
   br label %42
 
@@ -22967,11 +23451,11 @@
   %51 = phi %"class.std::basic_string_view"* [ %52, %50 ], [ %32, %42 ]
   %52 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %51, i64 -1
   %53 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %52, i64 0, i32 0
-  %54 = load i64, i64* %53, align 8, !tbaa.struct !210
+  %54 = load atomic i64, i64* %53 unordered, align 8, !tbaa.struct !209
   %55 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %51, i64 -1, i32 1
-  %56 = load i8*, i8** %55, align 8, !tbaa.struct !210
+  %56 = load atomic i8*, i8** %55 unordered, align 8, !tbaa.struct !209
   %57 = bitcast %"class.std::basic_string_view"* %52 to i8*
-  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %57, i8* nonnull align 8 dereferenceable(16) %23, i64 16, i1 false), !tbaa.struct !210
+  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %57, i8* nonnull align 8 dereferenceable(16) %23, i64 16, i1 false), !tbaa.struct !209
   %58 = ptrtoint %"class.std::basic_string_view"* %52 to i64
   %59 = sub i64 %58, %12
   %60 = ashr exact i64 %59, 4
@@ -22983,12 +23467,12 @@
   %63 = lshr i64 %31, 5
   %64 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %63
   %65 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %32, i64 -1
-  %66 = load i64, i64* %20, align 8, !tbaa.struct !210
-  %67 = load i8*, i8** %21, align 8, !tbaa.struct !210
+  %66 = load atomic i64, i64* %20 unordered, align 8, !tbaa.struct !209
+  %67 = load atomic i8*, i8** %21 unordered, align 8, !tbaa.struct !209
   %68 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %64, i64 0, i32 0
-  %69 = load i64, i64* %68, align 8, !tbaa.struct !210
+  %69 = load atomic i64, i64* %68 unordered, align 8, !tbaa.struct !209
   %70 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %63, i32 1
-  %71 = load i8*, i8** %70, align 8, !tbaa.struct !210
+  %71 = load atomic i8*, i8** %70 unordered, align 8, !tbaa.struct !209
   %72 = icmp ugt i64 %66, %69
   %73 = select i1 %72, i64 %69, i64 %66
   %74 = icmp eq i64 %73, 0
@@ -23017,9 +23501,9 @@
 
 88:                                               ; preds = %85
   %89 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %65, i64 0, i32 0
-  %90 = load i64, i64* %89, align 8, !tbaa.struct !210
+  %90 = load atomic i64, i64* %89 unordered, align 8, !tbaa.struct !209
   %91 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %32, i64 -1, i32 1
-  %92 = load i8*, i8** %91, align 8, !tbaa.struct !210
+  %92 = load atomic i8*, i8** %91 unordered, align 8, !tbaa.struct !209
   %93 = icmp ugt i64 %69, %90
   %94 = select i1 %93, i64 %90, i64 %69
   %95 = icmp eq i64 %94, 0
@@ -23048,10 +23532,10 @@
 
 109:                                              ; preds = %106
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %22)
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %22, i8* nonnull align 8 dereferenceable(16) %23, i64 16, i1 false) #37, !tbaa.struct !210
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %22, i8* nonnull align 8 dereferenceable(16) %23, i64 16, i1 false) #37, !tbaa.struct !209
   %110 = bitcast %"class.std::basic_string_view"* %64 to i8*
-  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %23, i8* nonnull align 8 dereferenceable(16) %110, i64 16, i1 false) #37, !tbaa.struct !210
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %110, i8* nonnull align 8 dereferenceable(16) %22, i64 16, i1 false) #37, !tbaa.struct !210
+  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %23, i8* nonnull align 8 dereferenceable(16) %110, i64 16, i1 false) #37, !tbaa.struct !209
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %110, i8* nonnull align 8 dereferenceable(16) %22, i64 16, i1 false) #37, !tbaa.struct !209
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %22)
   br label %_ZSt22__move_median_to_firstIPSt17basic_string_viewIcSt11char_traitsIcEEN9__gnu_cxx5__ops15_Iter_less_iterEEvT_S8_S8_S8_T0_.exit
 
@@ -23084,26 +23568,26 @@
 
 128:                                              ; preds = %125
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %24)
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %24, i8* nonnull align 8 dereferenceable(16) %23, i64 16, i1 false) #37, !tbaa.struct !210
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %24, i8* nonnull align 8 dereferenceable(16) %23, i64 16, i1 false) #37, !tbaa.struct !209
   %129 = bitcast %"class.std::basic_string_view"* %65 to i8*
-  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %23, i8* nonnull align 8 dereferenceable(16) %129, i64 16, i1 false) #37, !tbaa.struct !210
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %129, i8* nonnull align 8 dereferenceable(16) %24, i64 16, i1 false) #37, !tbaa.struct !210
+  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %23, i8* nonnull align 8 dereferenceable(16) %129, i64 16, i1 false) #37, !tbaa.struct !209
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %129, i8* nonnull align 8 dereferenceable(16) %24, i64 16, i1 false) #37, !tbaa.struct !209
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %24)
   br label %_ZSt22__move_median_to_firstIPSt17basic_string_viewIcSt11char_traitsIcEEN9__gnu_cxx5__ops15_Iter_less_iterEEvT_S8_S8_S8_T0_.exit
 
 130:                                              ; preds = %125, %118
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %25)
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %25, i8* nonnull align 8 dereferenceable(16) %23, i64 16, i1 false) #37, !tbaa.struct !210
-  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %23, i8* nonnull align 8 dereferenceable(16) %26, i64 16, i1 false) #37, !tbaa.struct !210
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %26, i8* nonnull align 8 dereferenceable(16) %25, i64 16, i1 false) #37, !tbaa.struct !210
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %25, i8* nonnull align 8 dereferenceable(16) %23, i64 16, i1 false) #37, !tbaa.struct !209
+  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %23, i8* nonnull align 8 dereferenceable(16) %26, i64 16, i1 false) #37, !tbaa.struct !209
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %26, i8* nonnull align 8 dereferenceable(16) %25, i64 16, i1 false) #37, !tbaa.struct !209
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %25)
   br label %_ZSt22__move_median_to_firstIPSt17basic_string_viewIcSt11char_traitsIcEEN9__gnu_cxx5__ops15_Iter_less_iterEEvT_S8_S8_S8_T0_.exit
 
 131:                                              ; preds = %85, %78
   %132 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %65, i64 0, i32 0
-  %133 = load i64, i64* %132, align 8, !tbaa.struct !210
+  %133 = load atomic i64, i64* %132 unordered, align 8, !tbaa.struct !209
   %134 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %32, i64 -1, i32 1
-  %135 = load i8*, i8** %134, align 8, !tbaa.struct !210
+  %135 = load atomic i8*, i8** %134 unordered, align 8, !tbaa.struct !209
   %136 = icmp ugt i64 %66, %133
   %137 = select i1 %136, i64 %133, i64 %66
   %138 = icmp eq i64 %137, 0
@@ -23132,9 +23616,9 @@
 
 152:                                              ; preds = %149
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %27)
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %27, i8* nonnull align 8 dereferenceable(16) %23, i64 16, i1 false) #37, !tbaa.struct !210
-  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %23, i8* nonnull align 8 dereferenceable(16) %26, i64 16, i1 false) #37, !tbaa.struct !210
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %26, i8* nonnull align 8 dereferenceable(16) %27, i64 16, i1 false) #37, !tbaa.struct !210
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %27, i8* nonnull align 8 dereferenceable(16) %23, i64 16, i1 false) #37, !tbaa.struct !209
+  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %23, i8* nonnull align 8 dereferenceable(16) %26, i64 16, i1 false) #37, !tbaa.struct !209
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %26, i8* nonnull align 8 dereferenceable(16) %27, i64 16, i1 false) #37, !tbaa.struct !209
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %27)
   br label %_ZSt22__move_median_to_firstIPSt17basic_string_viewIcSt11char_traitsIcEEN9__gnu_cxx5__ops15_Iter_less_iterEEvT_S8_S8_S8_T0_.exit
 
@@ -23167,19 +23651,19 @@
 
 170:                                              ; preds = %167
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %28)
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %28, i8* nonnull align 8 dereferenceable(16) %23, i64 16, i1 false) #37, !tbaa.struct !210
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %28, i8* nonnull align 8 dereferenceable(16) %23, i64 16, i1 false) #37, !tbaa.struct !209
   %171 = bitcast %"class.std::basic_string_view"* %65 to i8*
-  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %23, i8* nonnull align 8 dereferenceable(16) %171, i64 16, i1 false) #37, !tbaa.struct !210
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %171, i8* nonnull align 8 dereferenceable(16) %28, i64 16, i1 false) #37, !tbaa.struct !210
+  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %23, i8* nonnull align 8 dereferenceable(16) %171, i64 16, i1 false) #37, !tbaa.struct !209
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %171, i8* nonnull align 8 dereferenceable(16) %28, i64 16, i1 false) #37, !tbaa.struct !209
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %28)
   br label %_ZSt22__move_median_to_firstIPSt17basic_string_viewIcSt11char_traitsIcEEN9__gnu_cxx5__ops15_Iter_less_iterEEvT_S8_S8_S8_T0_.exit
 
 172:                                              ; preds = %167, %160
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %29)
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %29, i8* nonnull align 8 dereferenceable(16) %23, i64 16, i1 false) #37, !tbaa.struct !210
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %29, i8* nonnull align 8 dereferenceable(16) %23, i64 16, i1 false) #37, !tbaa.struct !209
   %173 = bitcast %"class.std::basic_string_view"* %64 to i8*
-  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %23, i8* nonnull align 8 dereferenceable(16) %173, i64 16, i1 false) #37, !tbaa.struct !210
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %173, i8* nonnull align 8 dereferenceable(16) %29, i64 16, i1 false) #37, !tbaa.struct !210
+  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %23, i8* nonnull align 8 dereferenceable(16) %173, i64 16, i1 false) #37, !tbaa.struct !209
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %173, i8* nonnull align 8 dereferenceable(16) %29, i64 16, i1 false) #37, !tbaa.struct !209
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %29)
   br label %_ZSt22__move_median_to_firstIPSt17basic_string_viewIcSt11char_traitsIcEEN9__gnu_cxx5__ops15_Iter_less_iterEEvT_S8_S8_S8_T0_.exit
 
@@ -23189,14 +23673,14 @@
 174:                                              ; preds = %230, %_ZSt22__move_median_to_firstIPSt17basic_string_viewIcSt11char_traitsIcEEN9__gnu_cxx5__ops15_Iter_less_iterEEvT_S8_S8_S8_T0_.exit
   %175 = phi %"class.std::basic_string_view"* [ %32, %_ZSt22__move_median_to_firstIPSt17basic_string_viewIcSt11char_traitsIcEEN9__gnu_cxx5__ops15_Iter_less_iterEEvT_S8_S8_S8_T0_.exit ], [ %207, %230 ]
   %176 = phi %"class.std::basic_string_view"* [ %16, %_ZSt22__move_median_to_firstIPSt17basic_string_viewIcSt11char_traitsIcEEN9__gnu_cxx5__ops15_Iter_less_iterEEvT_S8_S8_S8_T0_.exit ], [ %204, %230 ]
-  %177 = load i64, i64* %18, align 8, !tbaa.struct !210
-  %178 = load i8*, i8** %19, align 8, !tbaa.struct !210
+  %177 = load atomic i64, i64* %18 unordered, align 8, !tbaa.struct !209
+  %178 = load atomic i8*, i8** %19 unordered, align 8, !tbaa.struct !209
   br label %179
 
 179:                                              ; preds = %200, %174
   %180 = phi %"class.std::basic_string_view"* [ %176, %174 ], [ %203, %200 ]
   %181 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %180, i64 0, i32 0
-  %182 = load i64, i64* %181, align 8, !tbaa.struct !210
+  %182 = load atomic i64, i64* %181 unordered, align 8, !tbaa.struct !209
   %183 = icmp ugt i64 %182, %177
   %184 = select i1 %183, i64 %177, i64 %182
   %185 = icmp eq i64 %184, 0
@@ -23204,7 +23688,7 @@
 
 186:                                              ; preds = %179
   %187 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %180, i64 0, i32 1
-  %188 = load i8*, i8** %187, align 8, !tbaa.struct !210
+  %188 = load atomic i8*, i8** %187 unordered, align 8, !tbaa.struct !209
   %189 = tail call i32 @memcmp(i8* %188, i8* %178, i64 %184) #37
   %190 = icmp eq i32 %189, 0
   br i1 %190, label %191, label %200
@@ -23238,7 +23722,7 @@
   %206 = phi %"class.std::basic_string_view"* [ %207, %225 ], [ %175, %.loopexit25 ]
   %207 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %206, i64 -1
   %208 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %207, i64 0, i32 0
-  %209 = load i64, i64* %208, align 8, !tbaa.struct !210
+  %209 = load atomic i64, i64* %208 unordered, align 8, !tbaa.struct !209
   %210 = icmp ugt i64 %177, %209
   %211 = select i1 %210, i64 %209, i64 %177
   %212 = icmp eq i64 %211, 0
@@ -23246,7 +23730,7 @@
 
 213:                                              ; preds = %205
   %214 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %206, i64 -1, i32 1
-  %215 = load i8*, i8** %214, align 8, !tbaa.struct !210
+  %215 = load atomic i8*, i8** %214 unordered, align 8, !tbaa.struct !209
   %216 = tail call i32 @memcmp(i8* %178, i8* %215, i64 %211) #37
   %217 = icmp eq i32 %216, 0
   br i1 %217, label %218, label %225
@@ -23274,10 +23758,10 @@
 230:                                              ; preds = %228
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %17)
   %231 = bitcast %"class.std::basic_string_view"* %180 to i8*
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %17, i8* nonnull align 8 dereferenceable(16) %231, i64 16, i1 false) #37, !tbaa.struct !210
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %17, i8* nonnull align 8 dereferenceable(16) %231, i64 16, i1 false) #37, !tbaa.struct !209
   %232 = bitcast %"class.std::basic_string_view"* %207 to i8*
-  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %231, i8* nonnull align 8 dereferenceable(16) %232, i64 16, i1 false) #37, !tbaa.struct !210
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %232, i8* nonnull align 8 dereferenceable(16) %17, i64 16, i1 false) #37, !tbaa.struct !210
+  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %231, i8* nonnull align 8 dereferenceable(16) %232, i64 16, i1 false) #37, !tbaa.struct !209
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %232, i8* nonnull align 8 dereferenceable(16) %17, i64 16, i1 false) #37, !tbaa.struct !209
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %17)
   br label %174
 
@@ -23296,16 +23780,16 @@
 ; Function Attrs: nounwind uwtable
 define internal fastcc void @_ZSt25__unguarded_linear_insertIPSt17basic_string_viewIcSt11char_traitsIcEEN9__gnu_cxx5__ops14_Val_less_iterEEvT_T0_(%"class.std::basic_string_view"* nocapture %0) unnamed_addr #17 personality i32 (...)* @__gxx_personality_v0 {
   %2 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 0, i32 0
-  %3 = load i64, i64* %2, align 8, !tbaa.struct !210
+  %3 = load atomic i64, i64* %2 unordered, align 8, !tbaa.struct !209
   %4 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 0, i32 1
-  %5 = load i8*, i8** %4, align 8, !tbaa.struct !210
+  %5 = load atomic i8*, i8** %4 unordered, align 8, !tbaa.struct !209
   br label %6
 
 6:                                                ; preds = %29, %1
   %7 = phi %"class.std::basic_string_view"* [ %0, %1 ], [ %8, %29 ]
   %8 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %7, i64 -1
   %9 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %8, i64 0, i32 0
-  %10 = load i64, i64* %9, align 8, !tbaa.struct !210
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa.struct !209
   %11 = icmp ugt i64 %3, %10
   %12 = select i1 %11, i64 %10, i64 %3
   %13 = icmp eq i64 %12, 0
@@ -23313,7 +23797,7 @@
 
 14:                                               ; preds = %6
   %15 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %7, i64 -1, i32 1
-  %16 = load i8*, i8** %15, align 8, !tbaa.struct !210
+  %16 = load atomic i8*, i8** %15 unordered, align 8, !tbaa.struct !209
   %17 = tail call i32 @memcmp(i8* %5, i8* %16, i64 %12) #37
   %18 = icmp eq i32 %17, 0
   br i1 %18, label %19, label %26
@@ -23337,14 +23821,14 @@
 29:                                               ; preds = %26
   %30 = bitcast %"class.std::basic_string_view"* %7 to i8*
   %31 = bitcast %"class.std::basic_string_view"* %8 to i8*
-  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %30, i8* nonnull align 8 dereferenceable(16) %31, i64 16, i1 false), !tbaa.struct !210
+  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %30, i8* nonnull align 8 dereferenceable(16) %31, i64 16, i1 false), !tbaa.struct !209
   br label %6
 
 32:                                               ; preds = %26, %19
   %33 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %7, i64 0, i32 0
-  store i64 %3, i64* %33, align 8, !tbaa.struct !210
+  store i64 %3, i64* %33, align 8, !tbaa.struct !209
   %34 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %7, i64 0, i32 1
-  store i8* %5, i8** %34, align 8, !tbaa.struct !210
+  store i8* %5, i8** %34, align 8, !tbaa.struct !209
   ret void
 }
 
@@ -23364,9 +23848,9 @@
   %11 = add i64 %10, 2
   %12 = or i64 %10, 1
   %13 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %11, i32 0
-  %14 = load i64, i64* %13, align 8, !tbaa.struct !210
+  %14 = load atomic i64, i64* %13 unordered, align 8, !tbaa.struct !209
   %15 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %12, i32 0
-  %16 = load i64, i64* %15, align 8, !tbaa.struct !210
+  %16 = load atomic i64, i64* %15 unordered, align 8, !tbaa.struct !209
   %17 = icmp ugt i64 %14, %16
   %18 = select i1 %17, i64 %16, i64 %14
   %19 = icmp eq i64 %18, 0
@@ -23374,9 +23858,9 @@
 
 20:                                               ; preds = %.preheader15
   %21 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %12, i32 1
-  %22 = load i8*, i8** %21, align 8, !tbaa.struct !210
+  %22 = load atomic i8*, i8** %21 unordered, align 8, !tbaa.struct !209
   %23 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %11, i32 1
-  %24 = load i8*, i8** %23, align 8, !tbaa.struct !210
+  %24 = load atomic i8*, i8** %23 unordered, align 8, !tbaa.struct !209
   %25 = tail call i32 @memcmp(i8* %24, i8* %22, i64 %18) #37
   %26 = icmp eq i32 %25, 0
   br i1 %26, label %27, label %34
@@ -23404,7 +23888,7 @@
   %41 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %9
   %42 = bitcast %"class.std::basic_string_view"* %41 to i8*
   %43 = bitcast %"class.std::basic_string_view"* %40 to i8*
-  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %42, i8* nonnull align 8 dereferenceable(16) %43, i64 16, i1 false), !tbaa.struct !210
+  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %42, i8* nonnull align 8 dereferenceable(16) %43, i64 16, i1 false), !tbaa.struct !209
   %44 = icmp slt i64 %39, %7
   br i1 %44, label %.preheader15, label %.loopexit16
 
@@ -23427,7 +23911,7 @@
   %56 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %45
   %57 = bitcast %"class.std::basic_string_view"* %56 to i8*
   %58 = bitcast %"class.std::basic_string_view"* %55 to i8*
-  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %57, i8* nonnull align 8 dereferenceable(16) %58, i64 16, i1 false), !tbaa.struct !210
+  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %57, i8* nonnull align 8 dereferenceable(16) %58, i64 16, i1 false), !tbaa.struct !209
   br label %59
 
 59:                                               ; preds = %52, %48, %.loopexit16
@@ -23441,7 +23925,7 @@
   %64 = sdiv i64 %63, 2
   %65 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %64
   %66 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %65, i64 0, i32 0
-  %67 = load i64, i64* %66, align 8, !tbaa.struct !210
+  %67 = load atomic i64, i64* %66 unordered, align 8, !tbaa.struct !209
   %68 = icmp ugt i64 %67, %3
   %69 = select i1 %68, i64 %3, i64 %67
   %70 = icmp eq i64 %69, 0
@@ -23449,7 +23933,7 @@
 
 71:                                               ; preds = %.preheader
   %72 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %64, i32 1
-  %73 = load i8*, i8** %72, align 8, !tbaa.struct !210
+  %73 = load atomic i8*, i8** %72 unordered, align 8, !tbaa.struct !209
   %74 = tail call i32 @memcmp(i8* %73, i8* %4, i64 %69) #37
   %75 = icmp eq i32 %74, 0
   br i1 %75, label %76, label %83
@@ -23474,23 +23958,23 @@
   %87 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %62
   %88 = bitcast %"class.std::basic_string_view"* %87 to i8*
   %89 = bitcast %"class.std::basic_string_view"* %65 to i8*
-  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %88, i8* nonnull align 8 dereferenceable(16) %89, i64 16, i1 false), !tbaa.struct !210
+  tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %88, i8* nonnull align 8 dereferenceable(16) %89, i64 16, i1 false), !tbaa.struct !209
   %90 = icmp sgt i64 %64, %1
   br i1 %90, label %.preheader, label %.loopexit
 
 .loopexit:                                        ; preds = %86, %83, %76, %59
   %91 = phi i64 [ %60, %59 ], [ %64, %86 ], [ %62, %83 ], [ %62, %76 ]
   %92 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %91, i32 0
-  store i64 %3, i64* %92, align 8, !tbaa.struct !210
+  store i64 %3, i64* %92, align 8, !tbaa.struct !209
   %93 = getelementptr inbounds %"class.std::basic_string_view", %"class.std::basic_string_view"* %0, i64 %91, i32 1
-  store i8* %4, i8** %93, align 8, !tbaa.struct !210
+  store i8* %4, i8** %93, align 8, !tbaa.struct !209
   ret void
 }
 
 ; Function Attrs: nounwind uwtable
 define internal fastcc void @_ZNSt16allocator_traitsIN6kotlin11std_support9allocatorINS0_14SingleLockListINS0_2mm10ThreadDataESt15recursive_mutexNS2_IS5_EEE4NodeEEEE10_S_destroyISA_S9_EEvRT_PT0_z(%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %0) unnamed_addr #17 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %2 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
-  %3 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %2, align 8, !tbaa !3
+  %3 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %2 unordered, align 8, !tbaa !3
   %4 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, null
   br i1 %4, label %7, label %5
 
@@ -23510,7 +23994,7 @@
 ; Function Attrs: nounwind uwtable
 define internal fastcc void @_ZN6kotlin2mm10ThreadDataD2Ev(%"class.kotlin::mm::ThreadData.38"* %0) unnamed_addr #17 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %2 = getelementptr inbounds %"class.kotlin::mm::ThreadData.38", %"class.kotlin::mm::ThreadData.38"* %0, i64 0, i32 7, i32 0, i32 0, i32 0
-  %3 = load %"struct.std::pair.57"*, %"struct.std::pair.57"** %2, align 8, !tbaa !211
+  %3 = load atomic %"struct.std::pair.57"*, %"struct.std::pair.57"** %2 unordered, align 8, !tbaa !210
   %4 = icmp eq %"struct.std::pair.57"* %3, null
   br i1 %4, label %7, label %5
 
@@ -23528,14 +24012,14 @@
   %11 = getelementptr inbounds %"class.kotlin::mm::ThreadData.38", %"class.kotlin::mm::ThreadData.38"* %0, i64 0, i32 4, i32 0, i32 2, i32 0
   %12 = getelementptr inbounds %"class.std::__cxx11::_List_base", %"class.std::__cxx11::_List_base"* %11, i64 0, i32 0, i32 0, i32 0
   %13 = getelementptr inbounds %"class.std::__cxx11::_List_base", %"class.std::__cxx11::_List_base"* %11, i64 0, i32 0, i32 0, i32 0, i32 0
-  %14 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %13, align 8, !tbaa !125
+  %14 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %13 unordered, align 8, !tbaa !123
   %15 = icmp eq %"struct.std::__detail::_List_node_base"* %14, %12
   br i1 %15, label %.loopexit21, label %.preheader20
 
 .preheader20:                                     ; preds = %.preheader20, %7
   %16 = phi %"struct.std::__detail::_List_node_base"* [ %18, %.preheader20 ], [ %14, %7 ]
   %17 = getelementptr inbounds %"struct.std::__detail::_List_node_base", %"struct.std::__detail::_List_node_base"* %16, i64 0, i32 0
-  %18 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %17, align 8, !tbaa !125
+  %18 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %17 unordered, align 8, !tbaa !123
   %19 = bitcast %"struct.std::__detail::_List_node_base"* %16 to i8*
   tail call fastcc void @mi_free(i8* %19) #37
   %20 = icmp eq %"struct.std::__detail::_List_node_base"* %18, %12
@@ -23545,14 +24029,14 @@
   %21 = getelementptr inbounds %"class.kotlin::mm::ThreadData.38", %"class.kotlin::mm::ThreadData.38"* %0, i64 0, i32 4, i32 0, i32 1, i32 0
   %22 = getelementptr inbounds %"class.std::__cxx11::_List_base", %"class.std::__cxx11::_List_base"* %21, i64 0, i32 0, i32 0, i32 0
   %23 = getelementptr inbounds %"class.std::__cxx11::_List_base", %"class.std::__cxx11::_List_base"* %21, i64 0, i32 0, i32 0, i32 0, i32 0
-  %24 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %23, align 8, !tbaa !125
+  %24 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %23 unordered, align 8, !tbaa !123
   %25 = icmp eq %"struct.std::__detail::_List_node_base"* %24, %22
   br i1 %25, label %.loopexit19, label %.preheader18
 
 .preheader18:                                     ; preds = %.preheader18, %.loopexit21
   %26 = phi %"struct.std::__detail::_List_node_base"* [ %28, %.preheader18 ], [ %24, %.loopexit21 ]
   %27 = getelementptr inbounds %"struct.std::__detail::_List_node_base", %"struct.std::__detail::_List_node_base"* %26, i64 0, i32 0
-  %28 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %27, align 8, !tbaa !125
+  %28 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %27 unordered, align 8, !tbaa !123
   %29 = bitcast %"struct.std::__detail::_List_node_base"* %26 to i8*
   tail call fastcc void @mi_free(i8* %29) #37
   %30 = icmp eq %"struct.std::__detail::_List_node_base"* %28, %22
@@ -23564,14 +24048,14 @@
   %32 = getelementptr inbounds %"class.kotlin::mm::ThreadData.38", %"class.kotlin::mm::ThreadData.38"* %0, i64 0, i32 3, i32 0, i32 2, i32 0
   %33 = getelementptr inbounds %"class.std::__cxx11::_List_base", %"class.std::__cxx11::_List_base"* %32, i64 0, i32 0, i32 0, i32 0
   %34 = getelementptr inbounds %"class.std::__cxx11::_List_base", %"class.std::__cxx11::_List_base"* %32, i64 0, i32 0, i32 0, i32 0, i32 0
-  %35 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %34, align 8, !tbaa !125
+  %35 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %34 unordered, align 8, !tbaa !123
   %36 = icmp eq %"struct.std::__detail::_List_node_base"* %35, %33
   br i1 %36, label %.loopexit17, label %.preheader16
 
 .preheader16:                                     ; preds = %.preheader16, %.loopexit19
   %37 = phi %"struct.std::__detail::_List_node_base"* [ %39, %.preheader16 ], [ %35, %.loopexit19 ]
   %38 = getelementptr inbounds %"struct.std::__detail::_List_node_base", %"struct.std::__detail::_List_node_base"* %37, i64 0, i32 0
-  %39 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %38, align 8, !tbaa !125
+  %39 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %38 unordered, align 8, !tbaa !123
   %40 = bitcast %"struct.std::__detail::_List_node_base"* %37 to i8*
   tail call void @free(i8* %40) #37
   %41 = icmp eq %"struct.std::__detail::_List_node_base"* %39, %33
@@ -23581,14 +24065,14 @@
   %42 = getelementptr inbounds %"class.kotlin::mm::ThreadData.38", %"class.kotlin::mm::ThreadData.38"* %0, i64 0, i32 3, i32 0, i32 1, i32 0
   %43 = getelementptr inbounds %"class.std::__cxx11::_List_base", %"class.std::__cxx11::_List_base"* %42, i64 0, i32 0, i32 0, i32 0
   %44 = getelementptr inbounds %"class.std::__cxx11::_List_base", %"class.std::__cxx11::_List_base"* %42, i64 0, i32 0, i32 0, i32 0, i32 0
-  %45 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %44, align 8, !tbaa !125
+  %45 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %44 unordered, align 8, !tbaa !123
   %46 = icmp eq %"struct.std::__detail::_List_node_base"* %45, %43
   br i1 %46, label %.loopexit15, label %.preheader14
 
 .preheader14:                                     ; preds = %.preheader14, %.loopexit17
   %47 = phi %"struct.std::__detail::_List_node_base"* [ %49, %.preheader14 ], [ %45, %.loopexit17 ]
   %48 = getelementptr inbounds %"struct.std::__detail::_List_node_base", %"struct.std::__detail::_List_node_base"* %47, i64 0, i32 0
-  %49 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %48, align 8, !tbaa !125
+  %49 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %48 unordered, align 8, !tbaa !123
   %50 = bitcast %"struct.std::__detail::_List_node_base"* %47 to i8*
   tail call void @free(i8* %50) #37
   %51 = icmp eq %"struct.std::__detail::_List_node_base"* %49, %43
@@ -23598,14 +24082,14 @@
   %52 = getelementptr inbounds %"class.kotlin::mm::ThreadData.38", %"class.kotlin::mm::ThreadData.38"* %0, i64 0, i32 2, i32 1
   %53 = getelementptr inbounds %"class.kotlin::mm::ThreadData.38", %"class.kotlin::mm::ThreadData.38"* %0, i64 0, i32 2, i32 1, i32 0, i32 2, i32 0
   %54 = bitcast %"struct.std::__detail::_Hash_node_base"** %53 to %"struct.std::__detail::_Hash_node.203"**
-  %55 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %54, align 8, !tbaa !214
+  %55 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %54 unordered, align 8, !tbaa !213
   %56 = icmp eq %"struct.std::__detail::_Hash_node.203"* %55, null
   br i1 %56, label %.loopexit13, label %.preheader12
 
 .preheader12:                                     ; preds = %.preheader12, %.loopexit15
   %57 = phi %"struct.std::__detail::_Hash_node.203"* [ %59, %.preheader12 ], [ %55, %.loopexit15 ]
   %58 = bitcast %"struct.std::__detail::_Hash_node.203"* %57 to %"struct.std::__detail::_Hash_node.203"**
-  %59 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %58, align 8, !tbaa !216
+  %59 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %58 unordered, align 8, !tbaa !215
   %60 = bitcast %"struct.std::__detail::_Hash_node.203"* %57 to i8*
   tail call void @free(i8* %60) #37
   %61 = icmp eq %"struct.std::__detail::_Hash_node.203"* %59, null
@@ -23613,15 +24097,15 @@
 
 .loopexit13:                                      ; preds = %.preheader12, %.loopexit15
   %62 = bitcast %"class.std::unordered_map"* %52 to i8**
-  %63 = load i8*, i8** %62, align 8, !tbaa !217
+  %63 = load atomic i8*, i8** %62 unordered, align 8, !tbaa !216
   %64 = getelementptr inbounds %"class.kotlin::mm::ThreadData.38", %"class.kotlin::mm::ThreadData.38"* %0, i64 0, i32 2, i32 1, i32 0, i32 1
-  %65 = load i64, i64* %64, align 8, !tbaa !218
+  %65 = load atomic i64, i64* %64 unordered, align 8, !tbaa !217
   %66 = shl i64 %65, 3
   tail call void @llvm.memset.p0i8.i64(i8* align 8 %63, i8 0, i64 %66, i1 false) #37
   %67 = bitcast %"struct.std::__detail::_Hash_node_base"** %53 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %67, i8 0, i64 16, i1 false) #37
   %68 = getelementptr inbounds %"class.std::unordered_map", %"class.std::unordered_map"* %52, i64 0, i32 0, i32 0
-  %69 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %68, align 8, !tbaa !217
+  %69 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %68 unordered, align 8, !tbaa !216
   %70 = getelementptr inbounds %"class.kotlin::mm::ThreadData.38", %"class.kotlin::mm::ThreadData.38"* %0, i64 0, i32 2, i32 1, i32 0, i32 5
   %71 = icmp eq %"struct.std::__detail::_Hash_node_base"** %70, %69
   br i1 %71, label %74, label %72
@@ -23633,7 +24117,7 @@
 
 74:                                               ; preds = %72, %.loopexit13
   %75 = getelementptr inbounds %"class.kotlin::mm::ThreadData.38", %"class.kotlin::mm::ThreadData.38"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0
-  %76 = load %struct.ObjHeader**, %struct.ObjHeader*** %75, align 8, !tbaa !219
+  %76 = load atomic %struct.ObjHeader**, %struct.ObjHeader*** %75 unordered, align 8, !tbaa !218
   %77 = icmp eq %struct.ObjHeader** %76, null
   br i1 %77, label %80, label %78
 
@@ -23648,14 +24132,14 @@
   %82 = getelementptr inbounds %"class.kotlin::mm::ThreadData.38", %"class.kotlin::mm::ThreadData.38"* %0, i64 0, i32 1, i32 0, i32 2, i32 0
   %83 = getelementptr inbounds %"class.std::__cxx11::_List_base", %"class.std::__cxx11::_List_base"* %82, i64 0, i32 0, i32 0, i32 0
   %84 = getelementptr inbounds %"class.std::__cxx11::_List_base", %"class.std::__cxx11::_List_base"* %82, i64 0, i32 0, i32 0, i32 0, i32 0
-  %85 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %84, align 8, !tbaa !125
+  %85 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %84 unordered, align 8, !tbaa !123
   %86 = icmp eq %"struct.std::__detail::_List_node_base"* %85, %83
   br i1 %86, label %.loopexit11, label %.preheader10
 
 .preheader10:                                     ; preds = %.preheader10, %80
   %87 = phi %"struct.std::__detail::_List_node_base"* [ %89, %.preheader10 ], [ %85, %80 ]
   %88 = getelementptr inbounds %"struct.std::__detail::_List_node_base", %"struct.std::__detail::_List_node_base"* %87, i64 0, i32 0
-  %89 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %88, align 8, !tbaa !125
+  %89 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %88 unordered, align 8, !tbaa !123
   %90 = bitcast %"struct.std::__detail::_List_node_base"* %87 to i8*
   tail call void @free(i8* %90) #37
   %91 = icmp eq %"struct.std::__detail::_List_node_base"* %89, %83
@@ -23665,14 +24149,14 @@
   %92 = getelementptr inbounds %"class.kotlin::mm::ThreadData.38", %"class.kotlin::mm::ThreadData.38"* %0, i64 0, i32 1, i32 0, i32 1, i32 0
   %93 = getelementptr inbounds %"class.std::__cxx11::_List_base", %"class.std::__cxx11::_List_base"* %92, i64 0, i32 0, i32 0, i32 0
   %94 = getelementptr inbounds %"class.std::__cxx11::_List_base", %"class.std::__cxx11::_List_base"* %92, i64 0, i32 0, i32 0, i32 0, i32 0
-  %95 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %94, align 8, !tbaa !125
+  %95 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %94 unordered, align 8, !tbaa !123
   %96 = icmp eq %"struct.std::__detail::_List_node_base"* %95, %93
   br i1 %96, label %.loopexit, label %.preheader
 
 .preheader:                                       ; preds = %.preheader, %.loopexit11
   %97 = phi %"struct.std::__detail::_List_node_base"* [ %99, %.preheader ], [ %95, %.loopexit11 ]
   %98 = getelementptr inbounds %"struct.std::__detail::_List_node_base", %"struct.std::__detail::_List_node_base"* %97, i64 0, i32 0
-  %99 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %98, align 8, !tbaa !125
+  %99 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %98 unordered, align 8, !tbaa !123
   %100 = bitcast %"struct.std::__detail::_List_node_base"* %97 to i8*
   tail call void @free(i8* %100) #37
   %101 = icmp eq %"struct.std::__detail::_List_node_base"* %99, %93
@@ -23688,14 +24172,14 @@
   %3 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
   %4 = bitcast %"class.std::__cxx11::list"* %2 to i64*
   %5 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %2, i64 0, i32 0, i32 0, i32 0, i32 0
-  %6 = load i64, i64* %4, align 8, !tbaa !125
+  %6 = load atomic i64, i64* %4 unordered, align 8, !tbaa !123
   %7 = inttoptr i64 %6 to %"struct.std::__detail::_List_node_base"*
   %8 = icmp eq %"struct.std::__detail::_List_node_base"* %5, %7
   br i1 %8, label %.loopexit5, label %.preheader4
 
 .loopexit5:                                       ; preds = %.preheader4, %1
   %9 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer", %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %0, i64 0, i32 0
-  %10 = load %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9, align 8, !tbaa !222
+  %10 = load atomic %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9 unordered, align 8, !tbaa !221
   %11 = getelementptr inbounds %"class.kotlin::MultiSourceQueue", %"class.kotlin::MultiSourceQueue"* %10, i64 0, i32 2, i32 0, i32 0, i32 0
   %12 = atomicrmw xchg i8* %11, i8 1 acquire, align 1
   %13 = icmp eq i8 %12, 0
@@ -23708,8 +24192,8 @@
   br i1 %15, label %.loopexit, label %.preheader
 
 .loopexit:                                        ; preds = %.preheader, %.loopexit5
-  %16 = load %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9, align 8, !tbaa !222
-  %17 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %3, align 8, !tbaa !125
+  %16 = load atomic %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9 unordered, align 8, !tbaa !221
+  %17 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %3 unordered, align 8, !tbaa !123
   %18 = icmp eq %"struct.std::__detail::_List_node_base"* %17, %5
   br i1 %18, label %35, label %27
 
@@ -23720,7 +24204,7 @@
   %22 = bitcast i8* %21 to i64*
   store atomic i64 0, i64* %22 seq_cst, align 8
   %23 = inttoptr i64 %19 to i64*
-  %24 = load i64, i64* %23, align 8, !tbaa !125
+  %24 = load atomic i64, i64* %23 unordered, align 8, !tbaa !123
   %25 = inttoptr i64 %24 to %"struct.std::__detail::_List_node_base"*
   %26 = icmp eq %"struct.std::__detail::_List_node_base"* %5, %25
   br i1 %26, label %.loopexit5, label %.preheader4
@@ -23729,13 +24213,13 @@
   %28 = getelementptr inbounds %"class.kotlin::MultiSourceQueue", %"class.kotlin::MultiSourceQueue"* %16, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
   tail call void @_ZNSt8__detail15_List_node_base11_M_transferEPS0_S1_(%"struct.std::__detail::_List_node_base"* %28, %"struct.std::__detail::_List_node_base"* %17, %"struct.std::__detail::_List_node_base"* nonnull %5) #37
   %29 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer", %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1
-  %30 = load i64, i64* %29, align 8, !tbaa !226
+  %30 = load atomic i64, i64* %29 unordered, align 8, !tbaa !225
   %31 = getelementptr inbounds %"class.kotlin::MultiSourceQueue", %"class.kotlin::MultiSourceQueue"* %16, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  %32 = load i64, i64* %31, align 8, !tbaa !226
+  %32 = load atomic i64, i64* %31 unordered, align 8, !tbaa !225
   %33 = add i64 %32, %30
-  store i64 %33, i64* %31, align 8, !tbaa !226
-  store i64 0, i64* %29, align 8, !tbaa !226
-  %34 = load %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9, align 8, !tbaa !222
+  store i64 %33, i64* %31, align 8, !tbaa !225
+  store i64 0, i64* %29, align 8, !tbaa !225
+  %34 = load atomic %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9 unordered, align 8, !tbaa !221
   br label %35
 
 35:                                               ; preds = %27, %.loopexit
@@ -23743,7 +24227,7 @@
   %37 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer", %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %0, i64 0, i32 2
   %38 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %37, i64 0, i32 0, i32 0, i32 0, i32 0
   %39 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %37, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %40 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %39, align 8, !tbaa !125
+  %40 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %39 unordered, align 8, !tbaa !123
   %41 = icmp eq %"struct.std::__detail::_List_node_base"* %40, %38
   br i1 %41, label %49, label %42
 
@@ -23751,12 +24235,12 @@
   %43 = getelementptr inbounds %"class.kotlin::MultiSourceQueue", %"class.kotlin::MultiSourceQueue"* %36, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0
   tail call void @_ZNSt8__detail15_List_node_base11_M_transferEPS0_S1_(%"struct.std::__detail::_List_node_base"* nonnull %43, %"struct.std::__detail::_List_node_base"* %40, %"struct.std::__detail::_List_node_base"* nonnull %38) #37
   %44 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer", %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 1
-  %45 = load i64, i64* %44, align 8, !tbaa !229
+  %45 = load atomic i64, i64* %44 unordered, align 8, !tbaa !228
   %46 = getelementptr inbounds %"class.kotlin::MultiSourceQueue", %"class.kotlin::MultiSourceQueue"* %36, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1
-  %47 = load i64, i64* %46, align 8, !tbaa !229
+  %47 = load atomic i64, i64* %46 unordered, align 8, !tbaa !228
   %48 = add i64 %47, %45
-  store i64 %48, i64* %46, align 8, !tbaa !229
-  store i64 0, i64* %44, align 8, !tbaa !229
+  store i64 %48, i64* %46, align 8, !tbaa !228
+  store i64 0, i64* %44, align 8, !tbaa !228
   br label %49
 
 49:                                               ; preds = %42, %35
@@ -23770,14 +24254,14 @@
   %3 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
   %4 = bitcast %"class.std::__cxx11::list"* %2 to i64*
   %5 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %2, i64 0, i32 0, i32 0, i32 0, i32 0
-  %6 = load i64, i64* %4, align 8, !tbaa !125
+  %6 = load atomic i64, i64* %4 unordered, align 8, !tbaa !123
   %7 = inttoptr i64 %6 to %"struct.std::__detail::_List_node_base"*
   %8 = icmp eq %"struct.std::__detail::_List_node_base"* %5, %7
   br i1 %8, label %.loopexit5, label %.preheader4
 
 .loopexit5:                                       ; preds = %.preheader4, %1
   %9 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer", %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %0, i64 0, i32 0
-  %10 = load %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9, align 8, !tbaa !232
+  %10 = load atomic %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9 unordered, align 8, !tbaa !231
   %11 = getelementptr inbounds %"class.kotlin::MultiSourceQueue", %"class.kotlin::MultiSourceQueue"* %10, i64 0, i32 2, i32 0, i32 0, i32 0
   %12 = atomicrmw xchg i8* %11, i8 1 acquire, align 1
   %13 = icmp eq i8 %12, 0
@@ -23790,8 +24274,8 @@
   br i1 %15, label %.loopexit, label %.preheader
 
 .loopexit:                                        ; preds = %.preheader, %.loopexit5
-  %16 = load %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9, align 8, !tbaa !232
-  %17 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %3, align 8, !tbaa !125
+  %16 = load atomic %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9 unordered, align 8, !tbaa !231
+  %17 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %3 unordered, align 8, !tbaa !123
   %18 = icmp eq %"struct.std::__detail::_List_node_base"* %17, %5
   br i1 %18, label %35, label %27
 
@@ -23802,7 +24286,7 @@
   %22 = bitcast i8* %21 to i64*
   store atomic i64 0, i64* %22 seq_cst, align 8
   %23 = inttoptr i64 %19 to i64*
-  %24 = load i64, i64* %23, align 8, !tbaa !125
+  %24 = load atomic i64, i64* %23 unordered, align 8, !tbaa !123
   %25 = inttoptr i64 %24 to %"struct.std::__detail::_List_node_base"*
   %26 = icmp eq %"struct.std::__detail::_List_node_base"* %5, %25
   br i1 %26, label %.loopexit5, label %.preheader4
@@ -23811,13 +24295,13 @@
   %28 = getelementptr inbounds %"class.kotlin::MultiSourceQueue", %"class.kotlin::MultiSourceQueue"* %16, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
   tail call void @_ZNSt8__detail15_List_node_base11_M_transferEPS0_S1_(%"struct.std::__detail::_List_node_base"* %28, %"struct.std::__detail::_List_node_base"* %17, %"struct.std::__detail::_List_node_base"* nonnull %5) #37
   %29 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer", %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1
-  %30 = load i64, i64* %29, align 8, !tbaa !236
+  %30 = load atomic i64, i64* %29 unordered, align 8, !tbaa !235
   %31 = getelementptr inbounds %"class.kotlin::MultiSourceQueue", %"class.kotlin::MultiSourceQueue"* %16, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  %32 = load i64, i64* %31, align 8, !tbaa !236
+  %32 = load atomic i64, i64* %31 unordered, align 8, !tbaa !235
   %33 = add i64 %32, %30
-  store i64 %33, i64* %31, align 8, !tbaa !236
-  store i64 0, i64* %29, align 8, !tbaa !236
-  %34 = load %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9, align 8, !tbaa !232
+  store i64 %33, i64* %31, align 8, !tbaa !235
+  store i64 0, i64* %29, align 8, !tbaa !235
+  %34 = load atomic %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9 unordered, align 8, !tbaa !231
   br label %35
 
 35:                                               ; preds = %27, %.loopexit
@@ -23825,7 +24309,7 @@
   %37 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer", %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %0, i64 0, i32 2
   %38 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %37, i64 0, i32 0, i32 0, i32 0, i32 0
   %39 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %37, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %40 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %39, align 8, !tbaa !125
+  %40 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %39 unordered, align 8, !tbaa !123
   %41 = icmp eq %"struct.std::__detail::_List_node_base"* %40, %38
   br i1 %41, label %49, label %42
 
@@ -23833,12 +24317,12 @@
   %43 = getelementptr inbounds %"class.kotlin::MultiSourceQueue", %"class.kotlin::MultiSourceQueue"* %36, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0
   tail call void @_ZNSt8__detail15_List_node_base11_M_transferEPS0_S1_(%"struct.std::__detail::_List_node_base"* nonnull %43, %"struct.std::__detail::_List_node_base"* %40, %"struct.std::__detail::_List_node_base"* nonnull %38) #37
   %44 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer", %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 1
-  %45 = load i64, i64* %44, align 8, !tbaa !239
+  %45 = load atomic i64, i64* %44 unordered, align 8, !tbaa !238
   %46 = getelementptr inbounds %"class.kotlin::MultiSourceQueue", %"class.kotlin::MultiSourceQueue"* %36, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1
-  %47 = load i64, i64* %46, align 8, !tbaa !239
+  %47 = load atomic i64, i64* %46 unordered, align 8, !tbaa !238
   %48 = add i64 %47, %45
-  store i64 %48, i64* %46, align 8, !tbaa !239
-  store i64 0, i64* %44, align 8, !tbaa !239
+  store i64 %48, i64* %46, align 8, !tbaa !238
+  store i64 0, i64* %44, align 8, !tbaa !238
   br label %49
 
 49:                                               ; preds = %42, %35
@@ -23852,14 +24336,14 @@
   %3 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
   %4 = bitcast %"class.std::__cxx11::list"* %2 to i64*
   %5 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %2, i64 0, i32 0, i32 0, i32 0, i32 0
-  %6 = load i64, i64* %4, align 8, !tbaa !125
+  %6 = load atomic i64, i64* %4 unordered, align 8, !tbaa !123
   %7 = inttoptr i64 %6 to %"struct.std::__detail::_List_node_base"*
   %8 = icmp eq %"struct.std::__detail::_List_node_base"* %5, %7
   br i1 %8, label %.loopexit5, label %.preheader4
 
 .loopexit5:                                       ; preds = %.preheader4, %1
   %9 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer", %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %0, i64 0, i32 0
-  %10 = load %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9, align 8, !tbaa !242
+  %10 = load atomic %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9 unordered, align 8, !tbaa !241
   %11 = getelementptr inbounds %"class.kotlin::MultiSourceQueue", %"class.kotlin::MultiSourceQueue"* %10, i64 0, i32 2, i32 0, i32 0, i32 0
   %12 = atomicrmw xchg i8* %11, i8 1 acquire, align 1
   %13 = icmp eq i8 %12, 0
@@ -23872,8 +24356,8 @@
   br i1 %15, label %.loopexit, label %.preheader
 
 .loopexit:                                        ; preds = %.preheader, %.loopexit5
-  %16 = load %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9, align 8, !tbaa !242
-  %17 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %3, align 8, !tbaa !125
+  %16 = load atomic %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9 unordered, align 8, !tbaa !241
+  %17 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %3 unordered, align 8, !tbaa !123
   %18 = icmp eq %"struct.std::__detail::_List_node_base"* %17, %5
   br i1 %18, label %35, label %27
 
@@ -23884,7 +24368,7 @@
   %22 = bitcast i8* %21 to i64*
   store atomic i64 0, i64* %22 seq_cst, align 8
   %23 = inttoptr i64 %19 to i64*
-  %24 = load i64, i64* %23, align 8, !tbaa !125
+  %24 = load atomic i64, i64* %23 unordered, align 8, !tbaa !123
   %25 = inttoptr i64 %24 to %"struct.std::__detail::_List_node_base"*
   %26 = icmp eq %"struct.std::__detail::_List_node_base"* %5, %25
   br i1 %26, label %.loopexit5, label %.preheader4
@@ -23893,13 +24377,13 @@
   %28 = getelementptr inbounds %"class.kotlin::MultiSourceQueue", %"class.kotlin::MultiSourceQueue"* %16, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
   tail call void @_ZNSt8__detail15_List_node_base11_M_transferEPS0_S1_(%"struct.std::__detail::_List_node_base"* %28, %"struct.std::__detail::_List_node_base"* %17, %"struct.std::__detail::_List_node_base"* nonnull %5) #37
   %29 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer", %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1
-  %30 = load i64, i64* %29, align 8, !tbaa !246
+  %30 = load atomic i64, i64* %29 unordered, align 8, !tbaa !245
   %31 = getelementptr inbounds %"class.kotlin::MultiSourceQueue", %"class.kotlin::MultiSourceQueue"* %16, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  %32 = load i64, i64* %31, align 8, !tbaa !246
+  %32 = load atomic i64, i64* %31 unordered, align 8, !tbaa !245
   %33 = add i64 %32, %30
-  store i64 %33, i64* %31, align 8, !tbaa !246
-  store i64 0, i64* %29, align 8, !tbaa !246
-  %34 = load %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9, align 8, !tbaa !242
+  store i64 %33, i64* %31, align 8, !tbaa !245
+  store i64 0, i64* %29, align 8, !tbaa !245
+  %34 = load atomic %"class.kotlin::MultiSourceQueue"*, %"class.kotlin::MultiSourceQueue"** %9 unordered, align 8, !tbaa !241
   br label %35
 
 35:                                               ; preds = %27, %.loopexit
@@ -23907,7 +24391,7 @@
   %37 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer", %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %0, i64 0, i32 2
   %38 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %37, i64 0, i32 0, i32 0, i32 0, i32 0
   %39 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %37, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %40 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %39, align 8, !tbaa !125
+  %40 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %39 unordered, align 8, !tbaa !123
   %41 = icmp eq %"struct.std::__detail::_List_node_base"* %40, %38
   br i1 %41, label %49, label %42
 
@@ -23915,12 +24399,12 @@
   %43 = getelementptr inbounds %"class.kotlin::MultiSourceQueue", %"class.kotlin::MultiSourceQueue"* %36, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0
   tail call void @_ZNSt8__detail15_List_node_base11_M_transferEPS0_S1_(%"struct.std::__detail::_List_node_base"* nonnull %43, %"struct.std::__detail::_List_node_base"* %40, %"struct.std::__detail::_List_node_base"* nonnull %38) #37
   %44 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer", %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 1
-  %45 = load i64, i64* %44, align 8, !tbaa !249
+  %45 = load atomic i64, i64* %44 unordered, align 8, !tbaa !248
   %46 = getelementptr inbounds %"class.kotlin::MultiSourceQueue", %"class.kotlin::MultiSourceQueue"* %36, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1
-  %47 = load i64, i64* %46, align 8, !tbaa !249
+  %47 = load atomic i64, i64* %46 unordered, align 8, !tbaa !248
   %48 = add i64 %47, %45
-  store i64 %48, i64* %46, align 8, !tbaa !249
-  store i64 0, i64* %44, align 8, !tbaa !249
+  store i64 %48, i64* %46, align 8, !tbaa !248
+  store i64 0, i64* %44, align 8, !tbaa !248
   br label %49
 
 49:                                               ; preds = %42, %35
@@ -23956,18 +24440,18 @@
 
 6:                                                ; preds = %1
   %7 = getelementptr inbounds %"class.kotlin::mm::ThreadSuspensionData.37", %"class.kotlin::mm::ThreadSuspensionData.37"* %0, i64 0, i32 2
-  %8 = load %"class.kotlin::mm::ThreadData.38"*, %"class.kotlin::mm::ThreadData.38"** %7, align 8, !tbaa !252
+  %8 = load atomic %"class.kotlin::mm::ThreadData.38"*, %"class.kotlin::mm::ThreadData.38"** %7 unordered, align 8, !tbaa !251
   %9 = getelementptr inbounds %"class.kotlin::mm::ThreadData.38", %"class.kotlin::mm::ThreadData.38"* %8, i64 0, i32 6
   %10 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %9 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %11 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %10, align 8, !tbaa !3
+  %11 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %10 unordered, align 8, !tbaa !3
   %12 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %11, i64 0, i32 1
   tail call void @_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData14OnSuspendForGCEv(%"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData"* nonnull %12) #37
   %13 = bitcast %"class.std::unique_lock.266"* %2 to i8*
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %13) #37
   %14 = getelementptr inbounds %"class.std::unique_lock.266", %"class.std::unique_lock.266"* %2, i64 0, i32 0
-  store %"class.std::recursive_mutex"* bitcast ({ %union.pthread_mutex_t }* @_ZN12_GLOBAL__N_116gSuspensionMutexE to %"class.std::recursive_mutex"*), %"class.std::recursive_mutex"** %14, align 8, !tbaa !257
+  store %"class.std::recursive_mutex"* bitcast ({ %union.pthread_mutex_t }* @_ZN12_GLOBAL__N_116gSuspensionMutexE to %"class.std::recursive_mutex"*), %"class.std::recursive_mutex"** %14, align 8, !tbaa !255
   %15 = getelementptr inbounds %"class.std::unique_lock.266", %"class.std::unique_lock.266"* %2, i64 0, i32 1
-  store i8 0, i8* %15, align 8, !tbaa !259
+  store i8 0, i8* %15, align 8, !tbaa !257
   br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %16, label %21
 
 16:                                               ; preds = %6
@@ -23983,7 +24467,7 @@
   unreachable
 
 21:                                               ; preds = %16, %6
-  store i8 1, i8* %15, align 8, !tbaa !259
+  store i8 1, i8* %15, align 8, !tbaa !257
   %22 = tail call i32 @_ZN5konan6gettidEv() #37
   %23 = tail call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37
   %24 = getelementptr inbounds %"class.kotlin::mm::ThreadSuspensionData.37", %"class.kotlin::mm::ThreadSuspensionData.37"* %0, i64 0, i32 3, i32 0, i32 0
@@ -24005,12 +24489,12 @@
 .loopexit:                                        ; preds = %.preheader, %21
   %33 = call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37
   store atomic i8 %26, i8* %24 seq_cst, align 1
-  %34 = load i8, i8* %15, align 8, !tbaa !259, !range !72
+  %34 = load atomic i8, i8* %15 unordered, align 8, !tbaa !257, !range !70
   %35 = icmp eq i8 %34, 0
   br i1 %35, label %44, label %36
 
 36:                                               ; preds = %.loopexit
-  %37 = load %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %14, align 8, !tbaa !257
+  %37 = load atomic %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %14 unordered, align 8, !tbaa !255
   %38 = icmp eq %"class.std::recursive_mutex"* %37, null
   br i1 %38, label %44, label %39
 
@@ -24023,7 +24507,7 @@
   br label %43
 
 43:                                               ; preds = %40, %39
-  store i8 0, i8* %15, align 8, !tbaa !259
+  store i8 0, i8* %15, align 8, !tbaa !257
   br label %44
 
 44:                                               ; preds = %43, %36, %.loopexit
@@ -24099,11 +24583,11 @@
 
 9:                                                ; preds = %2
   %10 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %1, i64 0, i32 2, i32 0
-  %11 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %10, align 8, !tbaa !260
+  %11 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %10 unordered, align 8, !tbaa !258
   %12 = getelementptr inbounds %"class.kotlin::mm::ThreadData.38", %"class.kotlin::mm::ThreadData.38"* %0, i64 0, i32 3, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1
-  %13 = load i64, i64* %12, align 8, !tbaa !236
+  %13 = load atomic i64, i64* %12 unordered, align 8, !tbaa !235
   %14 = add i64 %13, -1
-  store i64 %14, i64* %12, align 8, !tbaa !236
+  store i64 %14, i64* %12, align 8, !tbaa !235
   tail call void @_ZNSt8__detail15_List_node_base9_M_unhookEv(%"struct.std::__detail::_List_node_base"* %11) #37
   %15 = bitcast %"struct.std::__detail::_List_node_base"* %11 to i8*
   tail call void @free(i8* %15) #37
@@ -24119,9 +24603,9 @@
   %22 = bitcast i8* %19 to %"struct.std::__detail::_List_node_base"*
   tail call void @_ZNSt8__detail15_List_node_base7_M_hookEPS0_(%"struct.std::__detail::_List_node_base"* %22, %"struct.std::__detail::_List_node_base"* nonnull %18) #37
   %23 = getelementptr inbounds %"class.kotlin::mm::ThreadData.38", %"class.kotlin::mm::ThreadData.38"* %0, i64 0, i32 3, i32 0, i32 2, i32 0, i32 0, i32 0, i32 1
-  %24 = load i64, i64* %23, align 8, !tbaa !239
+  %24 = load atomic i64, i64* %23 unordered, align 8, !tbaa !238
   %25 = add i64 %24, 1
-  store i64 %25, i64* %23, align 8, !tbaa !239
+  store i64 %25, i64* %23, align 8, !tbaa !238
   br label %26
 
 26:                                               ; preds = %16, %9
@@ -24133,7 +24617,7 @@
 
 ; Function Attrs: noinline nounwind uwtable
 define internal fastcc void @_ZN6kotlin2mm26SuspendIfRequestedSlowPathEv() unnamed_addr #7 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
-  %1 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %1 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %2 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %1, i64 0, i32 1, i32 8
   tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %2) #37
   ret void
@@ -24154,46 +24638,46 @@
 define internal fastcc void @_ZN12_GLOBAL__N_122ExceptionObjHolderImplC2EP9ObjHeader(%"class.(anonymous namespace)::ExceptionObjHolderImpl"* nocapture %0, %struct.ObjHeader* %1) unnamed_addr #17 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %3 = ptrtoint %struct.ObjHeader* %1 to i64
   %4 = getelementptr %"class.(anonymous namespace)::ExceptionObjHolderImpl", %"class.(anonymous namespace)::ExceptionObjHolderImpl"* %0, i64 0, i32 0, i32 0
-  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [4 x i8*] }, { [4 x i8*] }* @_ZTVN12_GLOBAL__N_122ExceptionObjHolderImplE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %4, align 8, !tbaa !109
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [4 x i8*] }, { [4 x i8*] }* @_ZTVN12_GLOBAL__N_122ExceptionObjHolderImplE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %4, align 8, !tbaa !107
+  %5 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 3, i32 0
   %7 = ptrtoint %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %6 to i64
   %8 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 3, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0
   %9 = tail call noalias dereferenceable_or_null(40) i8* @calloc(i64 1, i64 40) #37
   %10 = getelementptr inbounds i8, i8* %9, i64 16
   %11 = bitcast i8* %10 to i64*
-  store i64 %3, i64* %11, align 8, !tbaa !262
+  store i64 %3, i64* %11, align 8, !tbaa !260
   %12 = getelementptr inbounds i8, i8* %9, i64 24
   %13 = bitcast i8* %12 to i64*
-  store i64 %7, i64* %13, align 8, !tbaa !266
+  store i64 %7, i64* %13, align 8, !tbaa !264
   %14 = bitcast i8* %9 to %"struct.std::__detail::_List_node_base"*
   tail call void @_ZNSt8__detail15_List_node_base7_M_hookEPS0_(%"struct.std::__detail::_List_node_base"* %14, %"struct.std::__detail::_List_node_base"* nonnull %8) #37
   %15 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 3, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1
-  %16 = load i64, i64* %15, align 8, !tbaa !236
+  %16 = load atomic i64, i64* %15 unordered, align 8, !tbaa !235
   %17 = add i64 %16, 1
-  store i64 %17, i64* %15, align 8, !tbaa !236
+  store i64 %17, i64* %15, align 8, !tbaa !235
   %18 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 3, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1
   %19 = bitcast %"struct.std::__detail::_List_node_base"** %18 to %"struct.std::_List_node.67"**
-  %20 = load %"struct.std::_List_node.67"*, %"struct.std::_List_node.67"** %19, align 8, !tbaa !123
+  %20 = load atomic %"struct.std::_List_node.67"*, %"struct.std::_List_node.67"** %19 unordered, align 8, !tbaa !121
   %21 = getelementptr %"struct.std::_List_node.67", %"struct.std::_List_node.67"* %20, i64 0, i32 0
   %22 = getelementptr inbounds %"struct.std::_List_node.67", %"struct.std::_List_node.67"* %20, i64 0, i32 1
   %23 = getelementptr inbounds %"struct.std::_List_node.67", %"struct.std::_List_node.67"* %20, i64 0, i32 1, i32 0, i64 16
   %24 = bitcast i8* %23 to %"struct.std::__detail::_List_node_base"**
-  store %"struct.std::__detail::_List_node_base"* %21, %"struct.std::__detail::_List_node_base"** %24, align 8, !tbaa.struct !267
+  store %"struct.std::__detail::_List_node_base"* %21, %"struct.std::__detail::_List_node_base"** %24, align 8, !tbaa.struct !265
   %25 = getelementptr inbounds %"class.(anonymous namespace)::ExceptionObjHolderImpl", %"class.(anonymous namespace)::ExceptionObjHolderImpl"* %0, i64 0, i32 1
   %26 = bitcast %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %25 to %"struct.__gnu_cxx::__aligned_membuf.68"**
-  store %"struct.__gnu_cxx::__aligned_membuf.68"* %22, %"struct.__gnu_cxx::__aligned_membuf.68"** %26, align 8, !tbaa !65
+  store %"struct.__gnu_cxx::__aligned_membuf.68"* %22, %"struct.__gnu_cxx::__aligned_membuf.68"** %26, align 8, !tbaa !64
   ret void
 }
 
 ; Function Attrs: nounwind uwtable
 define internal void @_ZN12_GLOBAL__N_122ExceptionObjHolderImplD2Ev(%"class.(anonymous namespace)::ExceptionObjHolderImpl"* nocapture %0) unnamed_addr #17 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %2 = getelementptr %"class.(anonymous namespace)::ExceptionObjHolderImpl", %"class.(anonymous namespace)::ExceptionObjHolderImpl"* %0, i64 0, i32 0, i32 0
-  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [4 x i8*] }, { [4 x i8*] }* @_ZTVN12_GLOBAL__N_122ExceptionObjHolderImplE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !109
-  %3 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [4 x i8*] }, { [4 x i8*] }* @_ZTVN12_GLOBAL__N_122ExceptionObjHolderImplE, i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !107
+  %3 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %4 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 3, i32 0
   %5 = getelementptr inbounds %"class.(anonymous namespace)::ExceptionObjHolderImpl", %"class.(anonymous namespace)::ExceptionObjHolderImpl"* %0, i64 0, i32 1
-  %6 = load %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %5, align 8, !tbaa !65
+  %6 = load atomic %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %5 unordered, align 8, !tbaa !64
   %7 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %6, i64 0, i32 1
   %8 = bitcast %"struct.std::atomic.63"* %7 to i64*
   %9 = load atomic i64, i64* %8 seq_cst, align 8
@@ -24203,11 +24687,11 @@
 
 12:                                               ; preds = %1
   %13 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %6, i64 0, i32 2, i32 0
-  %14 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %13, align 8, !tbaa !260
+  %14 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %13 unordered, align 8, !tbaa !258
   %15 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 3, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1
-  %16 = load i64, i64* %15, align 8, !tbaa !236
+  %16 = load atomic i64, i64* %15 unordered, align 8, !tbaa !235
   %17 = add i64 %16, -1
-  store i64 %17, i64* %15, align 8, !tbaa !236
+  store i64 %17, i64* %15, align 8, !tbaa !235
   tail call void @_ZNSt8__detail15_List_node_base9_M_unhookEv(%"struct.std::__detail::_List_node_base"* %14) #37
   %18 = bitcast %"struct.std::__detail::_List_node_base"* %14 to i8*
   tail call void @free(i8* %18) #37
@@ -24223,9 +24707,9 @@
   %25 = bitcast i8* %22 to %"struct.std::__detail::_List_node_base"*
   tail call void @_ZNSt8__detail15_List_node_base7_M_hookEPS0_(%"struct.std::__detail::_List_node_base"* %25, %"struct.std::__detail::_List_node_base"* nonnull %21) #37
   %26 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 3, i32 0, i32 2, i32 0, i32 0, i32 0, i32 1
-  %27 = load i64, i64* %26, align 8, !tbaa !239
+  %27 = load atomic i64, i64* %26 unordered, align 8, !tbaa !238
   %28 = add i64 %27, 1
-  store i64 %28, i64* %26, align 8, !tbaa !239
+  store i64 %28, i64* %26, align 8, !tbaa !238
   br label %29
 
 29:                                               ; preds = %19, %12
@@ -24244,7 +24728,7 @@
 
 ; Function Attrs: nounwind uwtable
 define internal fastcc void @InitAndRegisterGlobal(%struct.ObjHeader** %0, %struct.ObjHeader* %1) unnamed_addr #17 personality i32 (...)* @__gxx_personality_v0 {
-  %3 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %3 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %4 = ptrtoint %struct.ObjHeader** %0 to i64
   %5 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 1, i32 0
   %6 = ptrtoint %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %5 to i64
@@ -24252,23 +24736,23 @@
   %8 = tail call noalias dereferenceable_or_null(40) i8* @calloc(i64 1, i64 40) #37
   %9 = getelementptr inbounds i8, i8* %8, i64 16
   %10 = bitcast i8* %9 to i64*
-  store i64 %4, i64* %10, align 8, !tbaa !268
+  store i64 %4, i64* %10, align 8, !tbaa !266
   %11 = getelementptr inbounds i8, i8* %8, i64 24
   %12 = bitcast i8* %11 to i64*
-  store i64 %6, i64* %12, align 8, !tbaa !273
+  store i64 %6, i64* %12, align 8, !tbaa !271
   %13 = bitcast i8* %8 to %"struct.std::__detail::_List_node_base"*
   tail call void @_ZNSt8__detail15_List_node_base7_M_hookEPS0_(%"struct.std::__detail::_List_node_base"* %13, %"struct.std::__detail::_List_node_base"* nonnull %7) #37
   %14 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 1, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1
-  %15 = load i64, i64* %14, align 8, !tbaa !246
+  %15 = load atomic i64, i64* %14 unordered, align 8, !tbaa !245
   %16 = add i64 %15, 1
-  store i64 %16, i64* %14, align 8, !tbaa !246
+  store i64 %16, i64* %14, align 8, !tbaa !245
   %17 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %3, i64 0, i32 1, i32 1, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1
   %18 = bitcast %"struct.std::__detail::_List_node_base"** %17 to %"struct.std::_List_node.67"**
-  %19 = load %"struct.std::_List_node.67"*, %"struct.std::_List_node.67"** %18, align 8, !tbaa !123
+  %19 = load atomic %"struct.std::_List_node.67"*, %"struct.std::_List_node.67"** %18 unordered, align 8, !tbaa !121
   %20 = getelementptr %"struct.std::_List_node.67", %"struct.std::_List_node.67"* %19, i64 0, i32 0
   %21 = getelementptr inbounds %"struct.std::_List_node.67", %"struct.std::_List_node.67"* %19, i64 0, i32 1, i32 0, i64 16
   %22 = bitcast i8* %21 to %"struct.std::__detail::_List_node_base"**
-  store %"struct.std::__detail::_List_node_base"* %20, %"struct.std::__detail::_List_node_base"** %22, align 8, !tbaa.struct !267
+  store %"struct.std::__detail::_List_node_base"* %20, %"struct.std::__detail::_List_node_base"** %22, align 8, !tbaa.struct !265
   %23 = icmp eq %struct.ObjHeader* %1, null
   br i1 %23, label %25, label %24
 
@@ -24286,22 +24770,22 @@
   %5 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %0, i64 96
   %6 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %0, i64 104
   %7 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %6 to i64*
-  %8 = load i64, i64* %7, align 8, !tbaa !218
+  %8 = load atomic i64, i64* %7 unordered, align 8, !tbaa !217
   %9 = urem i64 %4, %8
   %10 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %5 to %"struct.std::__detail::_Hash_node_base"***
-  %11 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %10, align 8, !tbaa !217
+  %11 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %10 unordered, align 8, !tbaa !216
   %12 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %11, i64 %9
-  %13 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %12, align 8, !tbaa !3
+  %13 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %12 unordered, align 8, !tbaa !3
   %14 = icmp eq %"struct.std::__detail::_Hash_node_base"* %13, null
   %15 = bitcast i8** %1 to i8*
   br i1 %14, label %.loopexit11, label %16
 
 16:                                               ; preds = %3
   %17 = bitcast %"struct.std::__detail::_Hash_node_base"* %13 to %"struct.std::__detail::_Hash_node.203"**
-  %18 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %17, align 8, !tbaa !216
+  %18 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %17 unordered, align 8, !tbaa !215
   %19 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %18, i64 0, i32 0, i32 1
   %20 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %19 to i8**
-  %21 = load i8*, i8** %20, align 8, !tbaa !3
+  %21 = load atomic i8*, i8** %20 unordered, align 8, !tbaa !3
   %22 = icmp eq i8* %21, %15
   br i1 %22, label %39, label %.preheader10
 
@@ -24313,7 +24797,7 @@
 .preheader10:                                     ; preds = %23, %16
   %26 = phi %"struct.std::__detail::_Hash_node.203"* [ %30, %23 ], [ %18, %16 ]
   %27 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %26, i64 0, i32 0, i32 0, i32 0
-  %28 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %27, align 8, !tbaa !216
+  %28 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %27 unordered, align 8, !tbaa !215
   %29 = icmp eq %"struct.std::__detail::_Hash_node_base"* %28, null
   %30 = bitcast %"struct.std::__detail::_Hash_node_base"* %28 to %"struct.std::__detail::_Hash_node.203"*
   br i1 %29, label %.loopexit11, label %31
@@ -24321,7 +24805,7 @@
 31:                                               ; preds = %.preheader10
   %32 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %28, i64 1
   %33 = bitcast %"struct.std::__detail::_Hash_node_base"* %32 to i64*
-  %34 = load i64, i64* %33, align 8, !tbaa !3
+  %34 = load atomic i64, i64* %33 unordered, align 8, !tbaa !3
   %35 = urem i64 %34, %8
   %36 = icmp eq i64 %35, %9
   br i1 %36, label %23, label %.loopexit11
@@ -24337,41 +24821,41 @@
 .loopexit11:                                      ; preds = %39, %37, %31, %.preheader10, %3
   %41 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %0, i64 156
   %42 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %41 to i32*
-  %43 = load i32, i32* %42, align 4, !tbaa !274
+  %43 = load atomic i32, i32* %42 unordered, align 4, !tbaa !272
   %44 = tail call noalias dereferenceable_or_null(24) i8* @calloc(i64 1, i64 24) #37
-  %45 = getelementptr inbounds i8, i8* %44, i64 8
-  %46 = bitcast i8* %45 to i64*
-  store i64 %4, i64* %46, align 8, !tbaa !281
-  %47 = getelementptr inbounds i8, i8* %44, i64 16
-  %48 = bitcast i8* %47 to i64*
+  %45 = bitcast i8* %44 to %"struct.std::__detail::_Hash_node_base"**
+  %46 = getelementptr inbounds i8, i8* %44, i64 8
+  %47 = bitcast i8* %46 to i64*
+  store i64 %4, i64* %47, align 8, !tbaa !279
+  %48 = getelementptr inbounds i8, i8* %44, i64 16
+  %49 = bitcast i8* %48 to i64*
   %.sroa.5.0.insert.ext = zext i32 %2 to i64
   %.sroa.5.0.insert.shift = shl nuw i64 %.sroa.5.0.insert.ext, 32
   %.sroa.0.0.insert.ext = zext i32 %43 to i64
   %.sroa.0.0.insert.insert = or i64 %.sroa.5.0.insert.shift, %.sroa.0.0.insert.ext
-  store i64 %.sroa.0.0.insert.insert, i64* %48, align 8
-  %49 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %12, align 8, !tbaa !3
-  %50 = icmp eq %"struct.std::__detail::_Hash_node_base"* %49, null
-  %51 = bitcast i8** %1 to i8*
-  br i1 %50, label %.loopexit9, label %52
+  store i64 %.sroa.0.0.insert.insert, i64* %49, align 8
+  %50 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %12 unordered, align 8, !tbaa !3
+  %51 = icmp eq %"struct.std::__detail::_Hash_node_base"* %50, null
+  br i1 %51, label %.loopexit9, label %52
 
 52:                                               ; preds = %.loopexit11
-  %53 = bitcast %"struct.std::__detail::_Hash_node_base"* %49 to %"struct.std::__detail::_Hash_node.203"**
-  %54 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %53, align 8, !tbaa !216
+  %53 = bitcast %"struct.std::__detail::_Hash_node_base"* %50 to %"struct.std::__detail::_Hash_node.203"**
+  %54 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %53 unordered, align 8, !tbaa !215
   %55 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %54, i64 0, i32 0, i32 1
   %56 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %55 to i8**
-  %57 = load i8*, i8** %56, align 8, !tbaa !3
-  %58 = icmp eq i8* %57, %51
+  %57 = load atomic i8*, i8** %56 unordered, align 8, !tbaa !3
+  %58 = icmp eq i8* %57, %15
   br i1 %58, label %75, label %.preheader
 
 59:                                               ; preds = %67
   %60 = inttoptr i64 %70 to i8*
-  %61 = icmp eq i8* %51, %60
+  %61 = icmp eq i8* %15, %60
   br i1 %61, label %73, label %.preheader
 
 .preheader:                                       ; preds = %59, %52
   %62 = phi %"struct.std::__detail::_Hash_node.203"* [ %66, %59 ], [ %54, %52 ]
   %63 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %62, i64 0, i32 0, i32 0, i32 0
-  %64 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %63, align 8, !tbaa !216
+  %64 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %63 unordered, align 8, !tbaa !215
   %65 = icmp eq %"struct.std::__detail::_Hash_node_base"* %64, null
   %66 = bitcast %"struct.std::__detail::_Hash_node_base"* %64 to %"struct.std::__detail::_Hash_node.203"*
   br i1 %65, label %.loopexit9, label %67
@@ -24379,7 +24863,7 @@
 67:                                               ; preds = %.preheader
   %68 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %64, i64 1
   %69 = bitcast %"struct.std::__detail::_Hash_node_base"* %68 to i64*
-  %70 = load i64, i64* %69, align 8, !tbaa !3
+  %70 = load atomic i64, i64* %69 unordered, align 8, !tbaa !3
   %71 = urem i64 %70, %8
   %72 = icmp eq i64 %71, %9
   br i1 %72, label %59, label %.loopexit9
@@ -24401,9 +24885,9 @@
   %79 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %78 to %"struct.std::__detail::_Prime_rehash_policy"*
   %80 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %0, i64 120
   %81 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %80 to i64*
-  %82 = load i64, i64* %81, align 8, !tbaa !283
+  %82 = load atomic i64, i64* %81 unordered, align 8, !tbaa !281
   %83 = invoke { i8, i64 } @_ZNKSt8__detail20_Prime_rehash_policy14_M_need_rehashEmmm(%"struct.std::__detail::_Prime_rehash_policy"* nonnull %79, i64 %8, i64 %82, i64 1)
-          to label %.noexc.i unwind label %184
+          to label %.noexc.i unwind label %185
 
 .noexc.i:                                         ; preds = %.loopexit9
   %84 = extractvalue { i8, i64 } %83, 0
@@ -24412,18 +24896,18 @@
   br i1 %86, label %87, label %89
 
 87:                                               ; preds = %.noexc.i
-  %88 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %10, align 8, !tbaa !217
+  %88 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %10 unordered, align 8, !tbaa !216
   br label %148
 
 89:                                               ; preds = %.noexc.i
   %90 = extractvalue { i8, i64 } %83, 1
   %91 = icmp eq i64 %90, 1
-  br i1 %91, label %92, label %95, !prof !284, !misexpect !285
+  br i1 %91, label %92, label %95, !prof !282, !misexpect !283
 
 92:                                               ; preds = %89
   %93 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %0, i64 144
   %94 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %93 to %"struct.std::__detail::_Hash_node_base"**
-  store %"struct.std::__detail::_Hash_node_base"* null, %"struct.std::__detail::_Hash_node_base"** %94, align 8, !tbaa !286
+  store %"struct.std::__detail::_Hash_node_base"* null, %"struct.std::__detail::_Hash_node_base"** %94, align 8, !tbaa !284
   br label %99
 
 95:                                               ; preds = %89
@@ -24437,9 +24921,9 @@
   %100 = phi %"struct.std::__detail::_Hash_node_base"** [ %94, %92 ], [ %97, %95 ]
   %101 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %0, i64 112
   %102 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %101 to %"struct.std::__detail::_Hash_node.203"**
-  %103 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %102, align 8, !tbaa !214
+  %103 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %102 unordered, align 8, !tbaa !213
   %104 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %101 to %"struct.std::__detail::_Hash_node_base"**
-  store %"struct.std::__detail::_Hash_node_base"* null, %"struct.std::__detail::_Hash_node_base"** %104, align 8, !tbaa !214
+  store %"struct.std::__detail::_Hash_node_base"* null, %"struct.std::__detail::_Hash_node_base"** %104, align 8, !tbaa !213
   %105 = icmp eq %"struct.std::__detail::_Hash_node.203"* %103, null
   br i1 %105, label %.loopexit, label %106
 
@@ -24451,26 +24935,26 @@
   %109 = phi %"struct.std::__detail::_Hash_node.203"* [ %103, %106 ], [ %112, %137 ]
   %110 = phi i64 [ 0, %106 ], [ %138, %137 ]
   %111 = bitcast %"struct.std::__detail::_Hash_node.203"* %109 to %"struct.std::__detail::_Hash_node.203"**
-  %112 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %111, align 8, !tbaa !216
+  %112 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %111 unordered, align 8, !tbaa !215
   %113 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %109, i64 0, i32 0, i32 1
   %114 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %113 to i64*
-  %115 = load i64, i64* %114, align 8, !tbaa !3
+  %115 = load atomic i64, i64* %114 unordered, align 8, !tbaa !3
   %116 = urem i64 %115, %90
   %117 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %100, i64 %116
-  %118 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %117, align 8, !tbaa !3
+  %118 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %117 unordered, align 8, !tbaa !3
   %119 = icmp eq %"struct.std::__detail::_Hash_node_base"* %118, null
   br i1 %119, label %120, label %130
 
 120:                                              ; preds = %108
-  %121 = load i64, i64* %107, align 8, !tbaa !214
+  %121 = load atomic i64, i64* %107 unordered, align 8, !tbaa !213
   %122 = getelementptr %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %109, i64 0, i32 0, i32 0
   %123 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %109, i64 0, i32 0, i32 0, i32 0
   %124 = bitcast %"struct.std::__detail::_Hash_node.203"* %109 to i64*
-  store i64 %121, i64* %124, align 8, !tbaa !216
-  store %"struct.std::__detail::_Hash_node_base"* %122, %"struct.std::__detail::_Hash_node_base"** %104, align 8, !tbaa !214
+  store i64 %121, i64* %124, align 8, !tbaa !215
+  store %"struct.std::__detail::_Hash_node_base"* %122, %"struct.std::__detail::_Hash_node_base"** %104, align 8, !tbaa !213
   %125 = bitcast %"struct.std::__detail::_Hash_node_base"** %117 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**
   store %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %101, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %125, align 8, !tbaa !3
-  %126 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %123, align 8, !tbaa !216
+  %126 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %123 unordered, align 8, !tbaa !215
   %127 = icmp eq %"struct.std::__detail::_Hash_node_base"* %126, null
   br i1 %127, label %137, label %128
 
@@ -24481,13 +24965,13 @@
 
 130:                                              ; preds = %108
   %131 = bitcast %"struct.std::__detail::_Hash_node_base"* %118 to i64*
-  %132 = load i64, i64* %131, align 8, !tbaa !216
+  %132 = load atomic i64, i64* %131 unordered, align 8, !tbaa !215
   %133 = getelementptr %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %109, i64 0, i32 0, i32 0
   %134 = bitcast %"struct.std::__detail::_Hash_node.203"* %109 to i64*
-  store i64 %132, i64* %134, align 8, !tbaa !216
-  %135 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %117, align 8, !tbaa !3
+  store i64 %132, i64* %134, align 8, !tbaa !215
+  %135 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %117 unordered, align 8, !tbaa !3
   %136 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %135, i64 0, i32 0
-  store %"struct.std::__detail::_Hash_node_base"* %133, %"struct.std::__detail::_Hash_node_base"** %136, align 8, !tbaa !216
+  store %"struct.std::__detail::_Hash_node_base"* %133, %"struct.std::__detail::_Hash_node_base"** %136, align 8, !tbaa !215
   br label %137
 
 137:                                              ; preds = %130, %128, %120
@@ -24496,7 +24980,7 @@
   br i1 %139, label %.loopexit, label %108
 
 .loopexit:                                        ; preds = %137, %99
-  %140 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %10, align 8, !tbaa !217
+  %140 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %10 unordered, align 8, !tbaa !216
   %141 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %0, i64 144
   %142 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %141 to %"struct.std::__detail::_Hash_node_base"**
   %143 = icmp eq %"struct.std::__detail::_Hash_node_base"** %140, %142
@@ -24508,8 +24992,8 @@
   br label %146
 
 146:                                              ; preds = %144, %.loopexit
-  store i64 %90, i64* %7, align 8, !tbaa !218
-  store %"struct.std::__detail::_Hash_node_base"** %100, %"struct.std::__detail::_Hash_node_base"*** %10, align 8, !tbaa !217
+  store i64 %90, i64* %7, align 8, !tbaa !217
+  store %"struct.std::__detail::_Hash_node_base"** %100, %"struct.std::__detail::_Hash_node_base"*** %10, align 8, !tbaa !216
   %147 = urem i64 %4, %90
   br label %148
 
@@ -24517,68 +25001,68 @@
   %149 = phi %"struct.std::__detail::_Hash_node_base"** [ %88, %87 ], [ %100, %146 ]
   %150 = phi i64 [ %9, %87 ], [ %147, %146 ]
   %151 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %149, i64 %150
-  %152 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %151, align 8, !tbaa !3
+  %152 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %151 unordered, align 8, !tbaa !3
   %153 = icmp eq %"struct.std::__detail::_Hash_node_base"* %152, null
   br i1 %153, label %160, label %154
 
 154:                                              ; preds = %148
   %155 = bitcast %"struct.std::__detail::_Hash_node_base"* %152 to i64*
-  %156 = load i64, i64* %155, align 8, !tbaa !216
+  %156 = load atomic i64, i64* %155 unordered, align 8, !tbaa !215
   %157 = bitcast i8* %44 to i64*
-  store i64 %156, i64* %157, align 8, !tbaa !216
+  store i64 %156, i64* %157, align 8, !tbaa !215
   %158 = bitcast %"struct.std::__detail::_Hash_node_base"** %151 to i8***
-  %159 = load i8**, i8*** %158, align 8, !tbaa !3
-  store i8* %44, i8** %159, align 8, !tbaa !216
+  %159 = load atomic i8**, i8*** %158 unordered, align 8, !tbaa !3
+  store i8* %44, i8** %159, align 8, !tbaa !215
   br label %_ZNSt10_HashtableIPvSt4pairIKS0_N6kotlin2mm18ThreadLocalStorage5EntryEENS3_11std_support9allocatorIS7_EENSt8__detail10_Select1stESt8equal_toIS0_ESt4hashIS0_ENSB_18_Mod_range_hashingENSB_20_Default_ranged_hashENSB_20_Prime_rehash_policyENSB_17_Hashtable_traitsILb0ELb0ELb1EEEE21_M_insert_unique_nodeEmmPNSB_10_Hash_nodeIS7_Lb0EEEm.exit.i.i
 
 160:                                              ; preds = %148
   %161 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %0, i64 112
   %162 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %161 to i64*
-  %163 = load i64, i64* %162, align 8, !tbaa !214
+  %163 = load atomic i64, i64* %162 unordered, align 8, !tbaa !213
   %164 = bitcast i8* %44 to i64*
-  store i64 %163, i64* %164, align 8, !tbaa !216
+  store i64 %163, i64* %164, align 8, !tbaa !215
   %165 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %161 to i8**
-  store i8* %44, i8** %165, align 8, !tbaa !214
-  %166 = icmp eq i64 %163, 0
-  br i1 %166, label %176, label %167
+  store i8* %44, i8** %165, align 8, !tbaa !213
+  %166 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %45 unordered, align 8, !tbaa !215
+  %167 = icmp eq %"struct.std::__detail::_Hash_node_base"* %166, null
+  br i1 %167, label %177, label %168
 
-167:                                              ; preds = %160
-  %.cast2 = inttoptr i64 %163 to %"struct.std::__detail::_Hash_node_base"*
-  %168 = load i64, i64* %7, align 8, !tbaa !218
-  %169 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %.cast2, i64 1
-  %170 = bitcast %"struct.std::__detail::_Hash_node_base"* %169 to i64*
-  %171 = load i64, i64* %170, align 8, !tbaa !3
-  %172 = urem i64 %171, %168
-  %173 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %149, i64 %172
-  %174 = bitcast %"struct.std::__detail::_Hash_node_base"** %173 to i8**
-  store i8* %44, i8** %174, align 8, !tbaa !3
-  %175 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %10, align 8, !tbaa !217
-  br label %176
+168:                                              ; preds = %160
+  %169 = load atomic i64, i64* %7 unordered, align 8, !tbaa !217
+  %170 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %166, i64 1
+  %171 = bitcast %"struct.std::__detail::_Hash_node_base"* %170 to i64*
+  %172 = load atomic i64, i64* %171 unordered, align 8, !tbaa !3
+  %173 = urem i64 %172, %169
+  %174 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %149, i64 %173
+  %175 = bitcast %"struct.std::__detail::_Hash_node_base"** %174 to i8**
+  store i8* %44, i8** %175, align 8, !tbaa !3
+  %176 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %10 unordered, align 8, !tbaa !216
+  br label %177
 
-176:                                              ; preds = %167, %160
-  %177 = phi %"struct.std::__detail::_Hash_node_base"** [ %149, %160 ], [ %175, %167 ]
-  %178 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %177, i64 %150
-  %179 = bitcast %"struct.std::__detail::_Hash_node_base"** %178 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**
-  store %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %161, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %179, align 8, !tbaa !3
+177:                                              ; preds = %168, %160
+  %178 = phi %"struct.std::__detail::_Hash_node_base"** [ %149, %160 ], [ %176, %168 ]
+  %179 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %178, i64 %150
+  %180 = bitcast %"struct.std::__detail::_Hash_node_base"** %179 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**
+  store %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %161, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %180, align 8, !tbaa !3
   br label %_ZNSt10_HashtableIPvSt4pairIKS0_N6kotlin2mm18ThreadLocalStorage5EntryEENS3_11std_support9allocatorIS7_EENSt8__detail10_Select1stESt8equal_toIS0_ESt4hashIS0_ENSB_18_Mod_range_hashingENSB_20_Default_ranged_hashENSB_20_Prime_rehash_policyENSB_17_Hashtable_traitsILb0ELb0ELb1EEEE21_M_insert_unique_nodeEmmPNSB_10_Hash_nodeIS7_Lb0EEEm.exit.i.i
 
-_ZNSt10_HashtableIPvSt4pairIKS0_N6kotlin2mm18ThreadLocalStorage5EntryEENS3_11std_support9allocatorIS7_EENSt8__detail10_Select1stESt8equal_toIS0_ESt4hashIS0_ENSB_18_Mod_range_hashingENSB_20_Default_ranged_hashENSB_20_Prime_rehash_policyENSB_17_Hashtable_traitsILb0ELb0ELb1EEEE21_M_insert_unique_nodeEmmPNSB_10_Hash_nodeIS7_Lb0EEEm.exit.i.i: ; preds = %176, %154
-  %180 = load i64, i64* %81, align 8, !tbaa !283
-  %181 = add i64 %180, 1
-  store i64 %181, i64* %81, align 8, !tbaa !283
+_ZNSt10_HashtableIPvSt4pairIKS0_N6kotlin2mm18ThreadLocalStorage5EntryEENS3_11std_support9allocatorIS7_EENSt8__detail10_Select1stESt8equal_toIS0_ESt4hashIS0_ENSB_18_Mod_range_hashingENSB_20_Default_ranged_hashENSB_20_Prime_rehash_policyENSB_17_Hashtable_traitsILb0ELb0ELb1EEEE21_M_insert_unique_nodeEmmPNSB_10_Hash_nodeIS7_Lb0EEEm.exit.i.i: ; preds = %177, %154
+  %181 = load atomic i64, i64* %81 unordered, align 8, !tbaa !281
+  %182 = add i64 %181, 1
+  store i64 %182, i64* %81, align 8, !tbaa !281
   br label %_ZNSt10_HashtableIPvSt4pairIKS0_N6kotlin2mm18ThreadLocalStorage5EntryEENS3_11std_support9allocatorIS7_EENSt8__detail10_Select1stESt8equal_toIS0_ESt4hashIS0_ENSB_18_Mod_range_hashingENSB_20_Default_ranged_hashENSB_20_Prime_rehash_policyENSB_17_Hashtable_traitsILb0ELb0ELb1EEEE10_M_emplaceIJRS0_S6_EEES1_INSB_14_Node_iteratorIS7_Lb0ELb0EEEbESt17integral_constantIbLb1EEDpOT_.exit.i
 
 _ZNSt10_HashtableIPvSt4pairIKS0_N6kotlin2mm18ThreadLocalStorage5EntryEENS3_11std_support9allocatorIS7_EENSt8__detail10_Select1stESt8equal_toIS0_ESt4hashIS0_ENSB_18_Mod_range_hashingENSB_20_Default_ranged_hashENSB_20_Prime_rehash_policyENSB_17_Hashtable_traitsILb0ELb0ELb1EEEE10_M_emplaceIJRS0_S6_EEES1_INSB_14_Node_iteratorIS7_Lb0ELb0EEEbESt17integral_constantIbLb1EEDpOT_.exit.i: ; preds = %_ZNSt10_HashtableIPvSt4pairIKS0_N6kotlin2mm18ThreadLocalStorage5EntryEENS3_11std_support9allocatorIS7_EENSt8__detail10_Select1stESt8equal_toIS0_ESt4hashIS0_ENSB_18_Mod_range_hashingENSB_20_Default_ranged_hashENSB_20_Prime_rehash_policyENSB_17_Hashtable_traitsILb0ELb0ELb1EEEE21_M_insert_unique_nodeEmmPNSB_10_Hash_nodeIS7_Lb0EEEm.exit.i.i, %77
-  %182 = load i32, i32* %42, align 4, !tbaa !274
-  %183 = add nsw i32 %182, %2
-  store i32 %183, i32* %42, align 4, !tbaa !274
+  %183 = load atomic i32, i32* %42 unordered, align 4, !tbaa !272
+  %184 = add nsw i32 %183, %2
+  store i32 %184, i32* %42, align 4, !tbaa !272
   br label %_ZN6kotlin2mm18ThreadLocalStorage9AddRecordEPvi.exit
 
-184:                                              ; preds = %.loopexit9
-  %185 = landingpad { i8*, i32 }
+185:                                              ; preds = %.loopexit9
+  %186 = landingpad { i8*, i32 }
           catch i8* null
-  %186 = extractvalue { i8*, i32 } %185, 0
-  tail call fastcc void @__clang_call_terminate(i8* %186) #51
+  %187 = extractvalue { i8*, i32 } %186, 0
+  tail call fastcc void @__clang_call_terminate(i8* %187) #51
   unreachable
 
 _ZN6kotlin2mm18ThreadLocalStorage9AddRecordEPvi.exit: ; preds = %_ZNSt10_HashtableIPvSt4pairIKS0_N6kotlin2mm18ThreadLocalStorage5EntryEENS3_11std_support9allocatorIS7_EENSt8__detail10_Select1stESt8equal_toIS0_ESt4hashIS0_ENSB_18_Mod_range_hashingENSB_20_Default_ranged_hashENSB_20_Prime_rehash_policyENSB_17_Hashtable_traitsILb0ELb0ELb1EEEE10_M_emplaceIJRS0_S6_EEES1_INSB_14_Node_iteratorIS7_Lb0ELb0EEEbESt17integral_constantIbLb1EEDpOT_.exit.i, %39, %37
@@ -24587,43 +25071,43 @@
 
 ; Function Attrs: nofree norecurse nounwind uwtable
 define internal fastcc %struct.ObjHeader** @LookupTLS(i32 %0) unnamed_addr #26 personality i32 (...)* @__gxx_personality_v0 {
-  %2 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %2 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %3 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %2, i64 0, i32 1, i32 2
   %4 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %2, i64 0, i32 1, i32 2, i32 4
   %5 = getelementptr inbounds %"struct.std::pair", %"struct.std::pair"* %4, i64 0, i32 0
-  %6 = load i8*, i8** %5, align 8, !tbaa !287
+  %6 = load atomic i8*, i8** %5 unordered, align 8, !tbaa !285
   %7 = icmp eq i8* %6, bitcast (i8** @__KonanTlsKey to i8*)
   br i1 %7, label %8, label %18
 
 8:                                                ; preds = %1
   %9 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %2, i64 0, i32 1, i32 2, i32 4, i32 1
   %10 = bitcast %"struct.kotlin::mm::ThreadLocalStorage::Entry"* %9 to i64*
-  %11 = load i64, i64* %10, align 8, !tbaa.struct !288
+  %11 = load atomic i64, i64* %10 unordered, align 8, !tbaa.struct !286
   %12 = trunc i64 %11 to i32
   %13 = add nsw i32 %12, %0
   %14 = sext i32 %13 to i64
   %15 = getelementptr inbounds %"class.kotlin::mm::ThreadLocalStorage", %"class.kotlin::mm::ThreadLocalStorage"* %3, i64 0, i32 0, i32 0, i32 0, i32 0
-  %16 = load %struct.ObjHeader**, %struct.ObjHeader*** %15, align 8, !tbaa !219
+  %16 = load atomic %struct.ObjHeader**, %struct.ObjHeader*** %15 unordered, align 8, !tbaa !218
   %17 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %16, i64 %14
   br label %_ZN6kotlin2mm18ThreadLocalStorage6LookupEPvi.exit
 
 18:                                               ; preds = %1
   %19 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %2, i64 0, i32 1, i32 2, i32 1, i32 0, i32 1
-  %20 = load i64, i64* %19, align 8, !tbaa !218
+  %20 = load atomic i64, i64* %19 unordered, align 8, !tbaa !217
   %21 = urem i64 ptrtoint (i8** @__KonanTlsKey to i64), %20
   %22 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %2, i64 0, i32 1, i32 2, i32 1, i32 0, i32 0
-  %23 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %22, align 8, !tbaa !217
+  %23 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %22 unordered, align 8, !tbaa !216
   %24 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %23, i64 %21
-  %25 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %24, align 8, !tbaa !3
+  %25 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %24 unordered, align 8, !tbaa !3
   %26 = icmp eq %"struct.std::__detail::_Hash_node_base"* %25, null
   br i1 %26, label %.loopexit, label %27
 
 27:                                               ; preds = %18
   %28 = bitcast %"struct.std::__detail::_Hash_node_base"* %25 to %"struct.std::__detail::_Hash_node.203"**
-  %29 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %28, align 8, !tbaa !216
+  %29 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %28 unordered, align 8, !tbaa !215
   %30 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %29, i64 0, i32 0, i32 1
   %31 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %30 to i8**
-  %32 = load i8*, i8** %31, align 8, !tbaa !3
+  %32 = load atomic i8*, i8** %31 unordered, align 8, !tbaa !3
   %33 = icmp eq i8* %32, bitcast (i8** @__KonanTlsKey to i8*)
   br i1 %33, label %50, label %.preheader
 
@@ -24635,7 +25119,7 @@
 .preheader:                                       ; preds = %34, %27
   %37 = phi %"struct.std::__detail::_Hash_node.203"* [ %41, %34 ], [ %29, %27 ]
   %38 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %37, i64 0, i32 0, i32 0, i32 0
-  %39 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %38, align 8, !tbaa !216
+  %39 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %38 unordered, align 8, !tbaa !215
   %40 = icmp eq %"struct.std::__detail::_Hash_node_base"* %39, null
   %41 = bitcast %"struct.std::__detail::_Hash_node_base"* %39 to %"struct.std::__detail::_Hash_node.203"*
   br i1 %40, label %.loopexit, label %42
@@ -24643,7 +25127,7 @@
 42:                                               ; preds = %.preheader
   %43 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %39, i64 1
   %44 = bitcast %"struct.std::__detail::_Hash_node_base"* %43 to i64*
-  %45 = load i64, i64* %44, align 8, !tbaa !3
+  %45 = load atomic i64, i64* %44 unordered, align 8, !tbaa !3
   %46 = urem i64 %45, %20
   %47 = icmp eq i64 %46, %21
   br i1 %47, label %34, label %.loopexit
@@ -24663,21 +25147,21 @@
   %53 = phi %"struct.std::__detail::_Hash_node.203"* [ null, %.loopexit ], [ %29, %50 ], [ %41, %48 ]
   %54 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %53, i64 0, i32 0, i32 1
   %55 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %54 to i64*
-  %56 = load i64, i64* %55, align 8, !tbaa !281
+  %56 = load atomic i64, i64* %55 unordered, align 8, !tbaa !279
   %57 = bitcast %"struct.std::pair"* %4 to i64*
-  store i64 %56, i64* %57, align 8, !tbaa !289
+  store i64 %56, i64* %57, align 8, !tbaa !287
   %58 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %53, i64 0, i32 0, i32 1, i32 0, i32 0, i64 8
   %59 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %2, i64 0, i32 1, i32 2, i32 4, i32 1
   %60 = bitcast i8* %58 to i64*
   %61 = bitcast %"struct.kotlin::mm::ThreadLocalStorage::Entry"* %59 to i64*
-  %62 = load i64, i64* %60, align 8
+  %62 = load atomic i64, i64* %60 unordered, align 8
   store i64 %62, i64* %61, align 8
-  %63 = load i64, i64* %60, align 8, !tbaa.struct !288
+  %63 = load atomic i64, i64* %60 unordered, align 8, !tbaa.struct !286
   %64 = trunc i64 %63 to i32
   %65 = add nsw i32 %64, %0
   %66 = sext i32 %65 to i64
   %67 = getelementptr inbounds %"class.kotlin::mm::ThreadLocalStorage", %"class.kotlin::mm::ThreadLocalStorage"* %3, i64 0, i32 0, i32 0, i32 0, i32 0
-  %68 = load %struct.ObjHeader**, %struct.ObjHeader*** %67, align 8, !tbaa !219
+  %68 = load atomic %struct.ObjHeader**, %struct.ObjHeader*** %67 unordered, align 8, !tbaa !218
   %69 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %68, i64 %66
   br label %_ZN6kotlin2mm18ThreadLocalStorage6LookupEPvi.exit
 
@@ -24710,7 +25194,7 @@
   %7 = load atomic volatile i64, i64* %6 monotonic, align 8
   %8 = inttoptr i64 %7 to %struct.TypeInfo*
   %9 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %8, i64 0, i32 6
-  %10 = load i32, i32* %9, align 8, !tbaa !290
+  %10 = load atomic i32, i32* %9 unordered, align 8, !tbaa !288
   %11 = icmp sgt i32 %10, 0
   br i1 %11, label %12, label %_ZN6kotlin2gc2GC19processObjectInMarkEPvP9ObjHeader.exit
 
@@ -24723,13 +25207,13 @@
 16:                                               ; preds = %45, %12
   %17 = phi i32 [ %10, %12 ], [ %46, %45 ]
   %18 = phi i64 [ 0, %12 ], [ %47, %45 ]
-  %19 = load i32*, i32** %14, align 8, !tbaa !291
+  %19 = load atomic i32*, i32** %14 unordered, align 8, !tbaa !289
   %20 = getelementptr inbounds i32, i32* %19, i64 %18
-  %21 = load i32, i32* %20, align 4, !tbaa !73
+  %21 = load atomic i32, i32* %20 unordered, align 4, !tbaa !71
   %22 = sext i32 %21 to i64
   %23 = add i64 %22, %13
   %24 = inttoptr i64 %23 to %struct.ObjHeader**
-  %25 = load %struct.ObjHeader*, %struct.ObjHeader** %24, align 8, !tbaa !3
+  %25 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %24 unordered, align 8, !tbaa !3
   %26 = icmp eq %struct.ObjHeader* %25, null
   br i1 %26, label %45, label %27
 
@@ -24758,7 +25242,7 @@
   br label %_ZN6kotlin2gc8internal10MarkTraits10tryEnqueueERNS_22intrusive_forward_listINS0_22ConcurrentMarkAndSweep10ObjectDataENS_33DefaultIntrusiveForwardListTraitsIS5_EEEEP9ObjHeader.exit.i.i
 
 _ZN6kotlin2gc8internal10MarkTraits10tryEnqueueERNS_22intrusive_forward_listINS0_22ConcurrentMarkAndSweep10ObjectDataENS_33DefaultIntrusiveForwardListTraitsIS5_EEEEP9ObjHeader.exit.i.i: ; preds = %42, %32
-  %44 = load i32, i32* %9, align 8, !tbaa !290
+  %44 = load atomic i32, i32* %9 unordered, align 8, !tbaa !288
   br label %45
 
 45:                                               ; preds = %_ZN6kotlin2gc8internal10MarkTraits10tryEnqueueERNS_22intrusive_forward_listINS0_22ConcurrentMarkAndSweep10ObjectDataENS_33DefaultIntrusiveForwardListTraitsIS5_EEEEP9ObjHeader.exit.i.i, %27, %16
@@ -24777,7 +25261,7 @@
   %3 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %1, i64 2
   %4 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %1, i64 1
   %5 = bitcast %struct.ObjHeader* %4 to i32*
-  %6 = load i32, i32* %5, align 8, !tbaa !18
+  %6 = load atomic i32, i32* %5 unordered, align 8, !tbaa !18
   %7 = sext i32 %6 to i64
   %8 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %3, i64 %7
   %9 = bitcast %struct.ObjHeader* %8 to %struct.ObjHeader**
@@ -24794,7 +25278,7 @@
   br i1 %lcmp.mod.not.not, label %.prol.preheader, label %.prol.loopexit
 
 .prol.preheader:                                  ; preds = %11
-  %17 = load %struct.ObjHeader*, %struct.ObjHeader** %12, align 8, !tbaa !3
+  %17 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %12 unordered, align 8, !tbaa !3
   %18 = icmp eq %struct.ObjHeader* %17, null
   br i1 %18, label %_ZN6kotlin2gc8internal10MarkTraits10tryEnqueueERNS_22intrusive_forward_listINS0_22ConcurrentMarkAndSweep10ObjectDataENS_33DefaultIntrusiveForwardListTraitsIS5_EEEEP9ObjHeader.exit.i.i.prol, label %19
 
@@ -24834,7 +25318,7 @@
 
 .new:                                             ; preds = %_ZN6kotlin2gc8internal10MarkTraits10tryEnqueueERNS_22intrusive_forward_listINS0_22ConcurrentMarkAndSweep10ObjectDataENS_33DefaultIntrusiveForwardListTraitsIS5_EEEEP9ObjHeader.exit.i.i.1, %.prol.loopexit
   %39 = phi %struct.ObjHeader** [ %79, %_ZN6kotlin2gc8internal10MarkTraits10tryEnqueueERNS_22intrusive_forward_listINS0_22ConcurrentMarkAndSweep10ObjectDataENS_33DefaultIntrusiveForwardListTraitsIS5_EEEEP9ObjHeader.exit.i.i.1 ], [ %.unr, %.prol.loopexit ]
-  %40 = load %struct.ObjHeader*, %struct.ObjHeader** %39, align 8, !tbaa !3
+  %40 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %39 unordered, align 8, !tbaa !3
   %41 = icmp eq %struct.ObjHeader* %40, null
   br i1 %41, label %_ZN6kotlin2gc8internal10MarkTraits10tryEnqueueERNS_22intrusive_forward_listINS0_22ConcurrentMarkAndSweep10ObjectDataENS_33DefaultIntrusiveForwardListTraitsIS5_EEEEP9ObjHeader.exit.i.i, label %42
 
@@ -24864,7 +25348,7 @@
 
 _ZN6kotlin2gc8internal10MarkTraits10tryEnqueueERNS_22intrusive_forward_listINS0_22ConcurrentMarkAndSweep10ObjectDataENS_33DefaultIntrusiveForwardListTraitsIS5_EEEEP9ObjHeader.exit.i.i: ; preds = %57, %47, %42, %.new
   %59 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %39, i64 1
-  %60 = load %struct.ObjHeader*, %struct.ObjHeader** %59, align 8, !tbaa !3
+  %60 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %59 unordered, align 8, !tbaa !3
   %61 = icmp eq %struct.ObjHeader* %60, null
   br i1 %61, label %_ZN6kotlin2gc8internal10MarkTraits10tryEnqueueERNS_22intrusive_forward_listINS0_22ConcurrentMarkAndSweep10ObjectDataENS_33DefaultIntrusiveForwardListTraitsIS5_EEEEP9ObjHeader.exit.i.i.1, label %62
 
@@ -24920,9 +25404,9 @@
   %5 = bitcast %"class.std::unique_lock.266"* %2 to i8*
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %5) #37
   %6 = getelementptr inbounds %"class.std::unique_lock.266", %"class.std::unique_lock.266"* %2, i64 0, i32 0
-  store %"class.std::recursive_mutex"* bitcast ({ %union.pthread_mutex_t }* @_ZN12_GLOBAL__N_112markingMutexE to %"class.std::recursive_mutex"*), %"class.std::recursive_mutex"** %6, align 8, !tbaa !257
+  store %"class.std::recursive_mutex"* bitcast ({ %union.pthread_mutex_t }* @_ZN12_GLOBAL__N_112markingMutexE to %"class.std::recursive_mutex"*), %"class.std::recursive_mutex"** %6, align 8, !tbaa !255
   %7 = getelementptr inbounds %"class.std::unique_lock.266", %"class.std::unique_lock.266"* %2, i64 0, i32 1
-  store i8 0, i8* %7, align 8, !tbaa !259
+  store i8 0, i8* %7, align 8, !tbaa !257
   br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %8, label %13
 
 8:                                                ; preds = %1
@@ -24938,7 +25422,7 @@
   unreachable
 
 13:                                               ; preds = %8, %1
-  store i8 1, i8* %7, align 8, !tbaa !259
+  store i8 1, i8* %7, align 8, !tbaa !257
   %14 = load atomic i8, i8* @_ZN12_GLOBAL__N_116markingRequestedE.0.0 seq_cst, align 1
   %15 = and i8 %14, 1
   %16 = icmp eq i8 %15, 0
@@ -24956,7 +25440,7 @@
   %23 = and i8 %22, 1
   store atomic i8 1, i8* %21 seq_cst, align 1
   %24 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData", %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData"* %0, i64 0, i32 1
-  %25 = load %"class.kotlin::mm::ThreadData.119"*, %"class.kotlin::mm::ThreadData.119"** %24, align 8, !tbaa !292
+  %25 = load atomic %"class.kotlin::mm::ThreadData.119"*, %"class.kotlin::mm::ThreadData.119"** %24 unordered, align 8, !tbaa !290
   %26 = getelementptr inbounds %"class.kotlin::mm::ThreadData.119", %"class.kotlin::mm::ThreadData.119"* %25, i64 0, i32 1, i32 0
   tail call fastcc void @_ZN6kotlin16MultiSourceQueueIPP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS3_EEE8Producer7PublishEv(%"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* nonnull %26) #37
   %27 = getelementptr inbounds %"class.kotlin::mm::ThreadData.119", %"class.kotlin::mm::ThreadData.119"* %25, i64 0, i32 3, i32 0
@@ -24964,7 +25448,7 @@
   %28 = getelementptr inbounds %"class.kotlin::mm::ThreadData.119", %"class.kotlin::mm::ThreadData.119"* %25, i64 0, i32 4, i32 0
   tail call fastcc void @_ZN6kotlin16MultiSourceQueueINS_2mm15ExtraObjectDataENS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_19ObjectPoolAllocatorIS2_EEE8Producer7PublishEv(%"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* nonnull %28) #37
   %29 = getelementptr inbounds %"class.kotlin::mm::ThreadData.119", %"class.kotlin::mm::ThreadData.119"* %25, i64 0, i32 6, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %30 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %29, align 8, !tbaa !3
+  %30 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %29 unordered, align 8, !tbaa !3
   %31 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %30, i64 0, i32 2, i32 1
   tail call fastcc void @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer7PublishEv(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %31) #37
   %32 = load atomic i8, i8* @_ZN12_GLOBAL__N_116markingRequestedE.0.0 seq_cst, align 1
@@ -24980,7 +25464,7 @@
   br i1 %37, label %.loopexit, label %.preheader
 
 .loopexit:                                        ; preds = %.preheader, %20
-  %38 = load i8, i8* %7, align 8, !tbaa !259, !range !72
+  %38 = load atomic i8, i8* %7 unordered, align 8, !tbaa !257, !range !70
   %39 = icmp eq i8 %38, 0
   br i1 %39, label %40, label %42
 
@@ -24992,7 +25476,7 @@
   unreachable
 
 42:                                               ; preds = %.loopexit
-  %43 = load %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %6, align 8, !tbaa !257
+  %43 = load atomic %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %6 unordered, align 8, !tbaa !255
   %44 = icmp eq %"class.std::recursive_mutex"* %43, null
   br i1 %44, label %50, label %45
 
@@ -25005,7 +25489,7 @@
   br label %49
 
 49:                                               ; preds = %46, %45
-  store i8 0, i8* %7, align 8, !tbaa !259
+  store i8 0, i8* %7, align 8, !tbaa !257
   br label %50
 
 50:                                               ; preds = %49, %42
@@ -25013,7 +25497,7 @@
   %52 = bitcast i64* %3 to i8*
   call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %52) #37
   store atomic i64 ptrtoint ([8 x i8]* @_ZN6kotlin22intrusive_forward_listINS_2gc22ConcurrentMarkAndSweep10ObjectDataENS_33DefaultIntrusiveForwardListTraitsIS3_EEE12tailStorage_E to i64), i64* %3 monotonic, align 8
-  %53 = load %"class.kotlin::mm::ThreadData.119"*, %"class.kotlin::mm::ThreadData.119"** %24, align 8, !tbaa !292
+  %53 = load atomic %"class.kotlin::mm::ThreadData.119"*, %"class.kotlin::mm::ThreadData.119"** %24 unordered, align 8, !tbaa !290
   call fastcc void @_ZN6kotlin2gc23collectRootSetForThreadINS0_8internal10MarkTraitsEEEvNS0_8GCHandleERNT_9MarkQueueERNS_2mm10ThreadDataE(i64 %51, %"union.std::aligned_storage<8, 8>::type"* nonnull align 8 dereferenceable(8) %4, %"class.kotlin::mm::ThreadData.119"* nonnull align 8 dereferenceable(344) %53)
   call fastcc void @_ZN6kotlin2gc4MarkINS0_8internal10MarkTraitsEEEvNS0_8GCHandleERNT_9MarkQueueE(i64 %51, %"union.std::aligned_storage<8, 8>::type"* nonnull align 8 dereferenceable(8) %4) #37
   call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %52) #37
@@ -25021,12 +25505,12 @@
   br label %54
 
 54:                                               ; preds = %50, %13
-  %55 = load i8, i8* %7, align 8, !tbaa !259, !range !72
+  %55 = load atomic i8, i8* %7 unordered, align 8, !tbaa !257, !range !70
   %56 = icmp eq i8 %55, 0
   br i1 %56, label %65, label %57
 
 57:                                               ; preds = %54
-  %58 = load %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %6, align 8, !tbaa !257
+  %58 = load atomic %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %6 unordered, align 8, !tbaa !255
   %59 = icmp eq %"class.std::recursive_mutex"* %58, null
   br i1 %59, label %65, label %60
 
@@ -25039,7 +25523,7 @@
   br label %64
 
 64:                                               ; preds = %61, %60
-  store i8 0, i8* %7, align 8, !tbaa !259
+  store i8 0, i8* %7, align 8, !tbaa !257
   br label %65
 
 65:                                               ; preds = %64, %57, %54
@@ -25051,12 +25535,12 @@
           catch i8* null
   %68 = extractvalue { i8*, i32 } %67, 0
   store atomic i8 %23, i8* %21 seq_cst, align 1
-  %69 = load i8, i8* %7, align 8, !tbaa !259, !range !72
+  %69 = load atomic i8, i8* %7 unordered, align 8, !tbaa !257, !range !70
   %70 = icmp eq i8 %69, 0
   br i1 %70, label %79, label %71
 
 71:                                               ; preds = %66
-  %72 = load %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %6, align 8, !tbaa !257
+  %72 = load atomic %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %6 unordered, align 8, !tbaa !255
   %73 = icmp eq %"class.std::recursive_mutex"* %72, null
   br i1 %73, label %79, label %74
 
@@ -25069,7 +25553,7 @@
   br label %78
 
 78:                                               ; preds = %75, %74
-  store i8 0, i8* %7, align 8, !tbaa !259
+  store i8 0, i8* %7, align 8, !tbaa !257
   br label %79
 
 79:                                               ; preds = %78, %71, %66, %17
@@ -25104,13 +25588,13 @@
   br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %12, label %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit
 
 12:                                               ; preds = %9
-  %13 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0)) #37, !noalias !294
+  %13 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0)) #37, !noalias !292
   %14 = icmp eq i32 %13, 0
   br i1 %14, label %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit, label %15
 
 15:                                               ; preds = %12
   invoke void @_ZSt20__throw_system_errori(i32 %13) #50
-          to label %16 unwind label %17, !noalias !294
+          to label %16 unwind label %17, !noalias !292
 
 16:                                               ; preds = %15
   unreachable
@@ -25119,32 +25603,32 @@
   %18 = landingpad { i8*, i32 }
           catch i8* null
   %19 = extractvalue { i8*, i32 } %18, 0
-  tail call fastcc void @__clang_call_terminate(i8* %19) #51, !noalias !294
+  tail call fastcc void @__clang_call_terminate(i8* %19) #51, !noalias !292
   unreachable
 
 _ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit: ; preds = %12, %9
-  %20 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) to %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"**), align 8, !tbaa !3
+  %20 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) to %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"**) unordered, align 8, !tbaa !3
   %21 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* %20, null
-  br i1 %21, label %.loopexit73, label %.preheader72
+  br i1 %21, label %.loopexit79, label %.preheader78
 
-.loopexit73:                                      ; preds = %38, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit
+.loopexit79:                                      ; preds = %38, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit
   br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %22, label %42
 
-22:                                               ; preds = %.loopexit73
+22:                                               ; preds = %.loopexit79
   %23 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0)) #37
   br label %42
 
-.preheader72:                                     ; preds = %38, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit
+.preheader78:                                     ; preds = %38, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit
   %24 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* [ %40, %38 ], [ %20, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit ]
   %25 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* %24, i64 0, i32 1, i32 6, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %26 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %25, align 8, !tbaa !3
+  %26 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %25 unordered, align 8, !tbaa !3
   %27 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %26, i64 0, i32 1, i32 3, i32 0, i32 0
   %28 = load atomic i8, i8* %27 seq_cst, align 1
   %29 = and i8 %28, 1
   %30 = icmp eq i8 %29, 0
   br i1 %30, label %31, label %38
 
-31:                                               ; preds = %.preheader72
+31:                                               ; preds = %.preheader78
   %32 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* %24, i64 0, i32 1
   %33 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* %24, i64 0, i32 1, i32 1, i32 0
   tail call fastcc void @_ZN6kotlin16MultiSourceQueueIPP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS3_EEE8Producer7PublishEv(%"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* nonnull %33) #37
@@ -25152,54 +25636,54 @@
   tail call fastcc void @_ZN6kotlin16MultiSourceQueueIP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS2_EEE8Producer7PublishEv(%"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* nonnull %34) #37
   %35 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* %24, i64 0, i32 1, i32 4, i32 0
   tail call fastcc void @_ZN6kotlin16MultiSourceQueueINS_2mm15ExtraObjectDataENS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_19ObjectPoolAllocatorIS2_EEE8Producer7PublishEv(%"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* nonnull %35) #37
-  %36 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %25, align 8, !tbaa !3
+  %36 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %25 unordered, align 8, !tbaa !3
   %37 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %36, i64 0, i32 2, i32 1
   tail call fastcc void @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer7PublishEv(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nonnull %37) #37
   tail call fastcc void @_ZN6kotlin2gc23collectRootSetForThreadINS0_8internal10MarkTraitsEEEvNS0_8GCHandleERNT_9MarkQueueERNS_2mm10ThreadDataE(i64 %1, %"union.std::aligned_storage<8, 8>::type"* nonnull align 8 dereferenceable(8) %10, %"class.kotlin::mm::ThreadData.119"* nonnull align 8 dereferenceable(344) %32)
   br label %38
 
-38:                                               ; preds = %31, %.preheader72
+38:                                               ; preds = %31, %.preheader78
   %39 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* %24, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
-  %40 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"** %39, align 8, !tbaa !3
+  %40 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"** %39 unordered, align 8, !tbaa !3
   %41 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* %40, null
-  br i1 %41, label %.loopexit73, label %.preheader72
+  br i1 %41, label %.loopexit79, label %.preheader78
 
-42:                                               ; preds = %22, %.loopexit73
+42:                                               ; preds = %22, %.loopexit79
   %43 = tail call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37
   %44 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1
   %45 = icmp eq i8 %44, 0
-  br i1 %45, label %.loopexit71, label %.preheader70
+  br i1 %45, label %.loopexit77, label %.preheader76
 
-.preheader70:                                     ; preds = %.preheader70, %42
+.preheader76:                                     ; preds = %.preheader76, %42
   tail call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37
   %46 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1
   %47 = icmp eq i8 %46, 0
-  br i1 %47, label %.loopexit71, label %.preheader70
+  br i1 %47, label %.loopexit77, label %.preheader76
 
-.loopexit71:                                      ; preds = %.preheader70, %42
+.loopexit77:                                      ; preds = %.preheader76, %42
   %48 = bitcast %"class.std::__cxx11::list"* %3 to i8*
   call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %48) #37
   %49 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %3, i64 0, i32 0, i32 0, i32 0, i32 0
   %50 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  store %"struct.std::__detail::_List_node_base"* %49, %"struct.std::__detail::_List_node_base"** %50, align 8, !tbaa !123
+  store %"struct.std::__detail::_List_node_base"* %49, %"struct.std::__detail::_List_node_base"** %50, align 8, !tbaa !121
   %51 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %3, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  store %"struct.std::__detail::_List_node_base"* %49, %"struct.std::__detail::_List_node_base"** %51, align 8, !tbaa !125
+  store %"struct.std::__detail::_List_node_base"* %49, %"struct.std::__detail::_List_node_base"** %51, align 8, !tbaa !123
   %52 = getelementptr inbounds %"class.std::__cxx11::list", %"class.std::__cxx11::list"* %3, i64 0, i32 0, i32 0, i32 0, i32 1
-  store i64 0, i64* %52, align 8, !tbaa !126
-  %53 = load i64, i64* bitcast (%"class.std::__cxx11::list"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1) to i64*), align 8, !tbaa !125
+  store i64 0, i64* %52, align 8, !tbaa !124
+  %53 = load atomic i64, i64* bitcast (%"class.std::__cxx11::list"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1) to i64*) unordered, align 8, !tbaa !123
   %54 = inttoptr i64 %53 to %"struct.std::__detail::_List_node_base"*
   %55 = icmp eq %"struct.std::__detail::_List_node_base"* %54, getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0)
-  br i1 %55, label %.loopexit69, label %56
+  br i1 %55, label %.loopexit75, label %56
 
-56:                                               ; preds = %86, %.loopexit71
-  %57 = phi %"struct.std::__detail::_List_node_base"* [ %87, %86 ], [ %54, %.loopexit71 ]
-  %58 = phi i64 [ %60, %86 ], [ %53, %.loopexit71 ]
+56:                                               ; preds = %86, %.loopexit77
+  %57 = phi %"struct.std::__detail::_List_node_base"* [ %87, %86 ], [ %54, %.loopexit77 ]
+  %58 = phi i64 [ %60, %86 ], [ %53, %.loopexit77 ]
   %59 = inttoptr i64 %58 to i64*
-  %60 = load i64, i64* %59, align 8, !tbaa !125
+  %60 = load atomic i64, i64* %59 unordered, align 8, !tbaa !123
   %61 = inttoptr i64 %58 to %"struct.std::_List_node"*
   %62 = getelementptr inbounds %"struct.std::_List_node", %"struct.std::_List_node"* %61, i64 0, i32 1
   %63 = bitcast %"union.std::aligned_storage<8, 8>::type"* %62 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"**
-  %64 = load %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %63, align 8, !tbaa !3
+  %64 = load atomic %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %63 unordered, align 8, !tbaa !3
   %65 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %64, i64 0, i32 1
   %66 = bitcast %"struct.std::atomic.63"* %65 to i64*
   %67 = load atomic i64, i64* %66 seq_cst, align 8
@@ -25212,26 +25696,26 @@
 
 71:                                               ; preds = %69
   %72 = getelementptr %"struct.std::__detail::_List_node_base", %"struct.std::__detail::_List_node_base"* %57, i64 0, i32 0
-  %73 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %72, align 8, !tbaa !125
+  %73 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %72 unordered, align 8, !tbaa !123
   %74 = icmp eq %"struct.std::__detail::_List_node_base"* %73, %49
   br i1 %74, label %86, label %75
 
 75:                                               ; preds = %71
   call void @_ZNSt8__detail15_List_node_base11_M_transferEPS0_S1_(%"struct.std::__detail::_List_node_base"* nonnull %49, %"struct.std::__detail::_List_node_base"* nonnull %57, %"struct.std::__detail::_List_node_base"* %73) #37
-  %76 = load i64, i64* %52, align 8, !tbaa !239
+  %76 = load atomic i64, i64* %52 unordered, align 8, !tbaa !238
   %77 = add i64 %76, 1
-  store i64 %77, i64* %52, align 8, !tbaa !239
-  %78 = load i64, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !239
+  store i64 %77, i64* %52, align 8, !tbaa !238
+  %78 = load atomic i64, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !238
   %79 = add i64 %78, -1
-  store i64 %79, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !239
+  store i64 %79, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !238
   br label %86
 
 80:                                               ; preds = %56
   %81 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %64, i64 0, i32 2, i32 0
-  %82 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %81, align 8, !tbaa !260
-  %83 = load i64, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !236
+  %82 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %81 unordered, align 8, !tbaa !258
+  %83 = load atomic i64, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !235
   %84 = add i64 %83, -1
-  store i64 %84, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !236
+  store i64 %84, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !235
   call void @_ZNSt8__detail15_List_node_base9_M_unhookEv(%"struct.std::__detail::_List_node_base"* %82) #37
   %85 = bitcast %"struct.std::__detail::_List_node_base"* %82 to i8*
   call void @free(i8* %85) #37
@@ -25243,43 +25727,43 @@
   br i1 %88, label %89, label %56
 
 89:                                               ; preds = %86
-  %90 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !125
+  %90 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) unordered, align 8, !tbaa !123
   %91 = icmp eq %"struct.std::__detail::_List_node_base"* %90, getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0)
-  br i1 %91, label %.loopexit69, label %.preheader68
+  br i1 %91, label %.loopexit75, label %.preheader74
 
-.preheader68:                                     ; preds = %.preheader68, %89
-  %92 = phi %"struct.std::__detail::_List_node_base"* [ %94, %.preheader68 ], [ %90, %89 ]
+.preheader74:                                     ; preds = %.preheader74, %89
+  %92 = phi %"struct.std::__detail::_List_node_base"* [ %94, %.preheader74 ], [ %90, %89 ]
   %93 = getelementptr inbounds %"struct.std::__detail::_List_node_base", %"struct.std::__detail::_List_node_base"* %92, i64 0, i32 0
-  %94 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %93, align 8, !tbaa !125
+  %94 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %93 unordered, align 8, !tbaa !123
   %95 = bitcast %"struct.std::__detail::_List_node_base"* %92 to i8*
   call void @free(i8* %95) #37
   %96 = icmp eq %"struct.std::__detail::_List_node_base"* %94, getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0)
-  br i1 %96, label %.loopexit69, label %.preheader68
+  br i1 %96, label %.loopexit75, label %.preheader74
 
-.loopexit69:                                      ; preds = %.preheader68, %89, %.loopexit71
-  %97 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %51, align 8, !tbaa !125
+.loopexit75:                                      ; preds = %.preheader74, %89, %.loopexit77
+  %97 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %51 unordered, align 8, !tbaa !123
   %98 = icmp eq %"struct.std::__detail::_List_node_base"* %97, %49
   br i1 %98, label %99, label %100
 
-99:                                               ; preds = %.loopexit69
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !123
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !125
+99:                                               ; preds = %.loopexit75
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !121
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !123
   br label %_ZN6kotlin2mm17StableRefRegistry16ProcessDeletionsEv.exit.i
 
-100:                                              ; preds = %.loopexit69
+100:                                              ; preds = %.loopexit75
   %101 = ptrtoint %"struct.std::__detail::_List_node_base"* %97 to i64
-  store i64 %101, i64* bitcast (%"class.std::__cxx11::list"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1) to i64*), align 8, !tbaa !125
-  %102 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %50, align 8, !tbaa !123
-  store %"struct.std::__detail::_List_node_base"* %102, %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !123
+  store i64 %101, i64* bitcast (%"class.std::__cxx11::list"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1) to i64*), align 8, !tbaa !123
+  %102 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %50 unordered, align 8, !tbaa !121
+  store %"struct.std::__detail::_List_node_base"* %102, %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !121
   %103 = getelementptr inbounds %"struct.std::__detail::_List_node_base", %"struct.std::__detail::_List_node_base"* %102, i64 0, i32 0
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** %103, align 8, !tbaa !125
-  %104 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !125
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** %103, align 8, !tbaa !123
+  %104 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) unordered, align 8, !tbaa !123
   %105 = getelementptr inbounds %"struct.std::__detail::_List_node_base", %"struct.std::__detail::_List_node_base"* %104, i64 0, i32 1
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** %105, align 8, !tbaa !123
-  %106 = load i64, i64* %52, align 8, !tbaa !126
-  store %"struct.std::__detail::_List_node_base"* %49, %"struct.std::__detail::_List_node_base"** %50, align 8, !tbaa !123
-  store %"struct.std::__detail::_List_node_base"* %49, %"struct.std::__detail::_List_node_base"** %51, align 8, !tbaa !125
-  store i64 0, i64* %52, align 8, !tbaa !126
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** %105, align 8, !tbaa !121
+  %106 = load atomic i64, i64* %52 unordered, align 8, !tbaa !124
+  store %"struct.std::__detail::_List_node_base"* %49, %"struct.std::__detail::_List_node_base"** %50, align 8, !tbaa !121
+  store %"struct.std::__detail::_List_node_base"* %49, %"struct.std::__detail::_List_node_base"** %51, align 8, !tbaa !123
+  store i64 0, i64* %52, align 8, !tbaa !124
   br label %_ZN6kotlin2mm17StableRefRegistry16ProcessDeletionsEv.exit.i
 
 _ZN6kotlin2mm17StableRefRegistry16ProcessDeletionsEv.exit.i: ; preds = %100, %99
@@ -25287,36 +25771,36 @@
   store i64 %107, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1), align 8
   call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %48) #37
   store atomic i8 0, i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 2, i32 0, i32 0, i32 0) release, align 8
-  %108 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1, !noalias !301
+  %108 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1, !noalias !299
   %109 = icmp eq i8 %108, 0
-  br i1 %109, label %.loopexit67, label %.preheader66
+  br i1 %109, label %.loopexit73, label %.preheader72
 
-.preheader66:                                     ; preds = %.preheader66, %_ZN6kotlin2mm17StableRefRegistry16ProcessDeletionsEv.exit.i
-  call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37, !noalias !301
-  %110 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1, !noalias !301
+.preheader72:                                     ; preds = %.preheader72, %_ZN6kotlin2mm17StableRefRegistry16ProcessDeletionsEv.exit.i
+  call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37, !noalias !299
+  %110 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1, !noalias !299
   %111 = icmp eq i8 %110, 0
-  br i1 %111, label %.loopexit67, label %.preheader66
+  br i1 %111, label %.loopexit73, label %.preheader72
 
-.loopexit67:                                      ; preds = %.preheader66, %_ZN6kotlin2mm17StableRefRegistry16ProcessDeletionsEv.exit.i
-  %112 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1, !noalias !306
+.loopexit73:                                      ; preds = %.preheader72, %_ZN6kotlin2mm17StableRefRegistry16ProcessDeletionsEv.exit.i
+  %112 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1, !noalias !304
   %113 = icmp eq i8 %112, 0
-  br i1 %113, label %_ZN6kotlin2mm13GlobalRootSetC2Ev.exit.i, label %.preheader65
+  br i1 %113, label %_ZN6kotlin2mm13GlobalRootSetC2Ev.exit.i, label %.preheader71
 
-.preheader65:                                     ; preds = %.preheader65, %.loopexit67
-  call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37, !noalias !306
-  %114 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1, !noalias !306
+.preheader71:                                     ; preds = %.preheader71, %.loopexit73
+  call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37, !noalias !304
+  %114 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1, !noalias !304
   %115 = icmp eq i8 %114, 0
-  br i1 %115, label %_ZN6kotlin2mm13GlobalRootSetC2Ev.exit.i, label %.preheader65
+  br i1 %115, label %_ZN6kotlin2mm13GlobalRootSetC2Ev.exit.i, label %.preheader71
 
-_ZN6kotlin2mm13GlobalRootSetC2Ev.exit.i:          ; preds = %.preheader65, %.loopexit67
-  %116 = load i64, i64* bitcast (%"class.kotlin::MultiSourceQueue"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0) to i64*), align 8, !tbaa !125
-  %117 = load i64, i64* bitcast (%"class.kotlin::MultiSourceQueue"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0) to i64*), align 8
+_ZN6kotlin2mm13GlobalRootSetC2Ev.exit.i:          ; preds = %.preheader71, %.loopexit73
+  %116 = load atomic i64, i64* bitcast (%"class.kotlin::MultiSourceQueue"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0) to i64*) unordered, align 8, !tbaa !123
+  %117 = load atomic i64, i64* bitcast (%"class.kotlin::MultiSourceQueue"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0) to i64*) unordered, align 8
   br label %118
 
 118:                                              ; preds = %123, %_ZN6kotlin2mm13GlobalRootSetC2Ev.exit.i
   %.sroa.7.0 = phi i32 [ 0, %_ZN6kotlin2mm13GlobalRootSetC2Ev.exit.i ], [ 1, %123 ]
-  %.sroa.1825.0 = phi i64 [ %116, %_ZN6kotlin2mm13GlobalRootSetC2Ev.exit.i ], [ %117, %123 ]
-  %119 = inttoptr i64 %.sroa.1825.0 to %"struct.std::__detail::_List_node_base"*
+  %.sroa.1830.0 = phi i64 [ %116, %_ZN6kotlin2mm13GlobalRootSetC2Ev.exit.i ], [ %117, %123 ]
+  %119 = inttoptr i64 %.sroa.1830.0 to %"struct.std::__detail::_List_node_base"*
   %120 = icmp eq %"struct.std::__detail::_List_node_base"* %119, getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0)
   br label %121
 
@@ -25339,11 +25823,11 @@
   br i1 %120, label %121, label %_ZN6kotlin2mm13GlobalRootSet8IteratorC2ENS2_7begin_tERS1_.exit.i
 
 _ZN6kotlin2mm13GlobalRootSet8IteratorC2ENS2_7begin_tERS1_.exit.i: ; preds = %125, %123
-  %.sroa.7.1106 = phi i32 [ %.sroa.7.0, %125 ], [ %.sroa.7.1, %123 ]
-  br label %_ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i
+  %.sroa.7.1113 = phi i32 [ %.sroa.7.0, %125 ], [ %.sroa.7.1, %123 ]
+  br label %_ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i.thread5
 
 _ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i.thread: ; preds = %193, %181, %122
-  %.sroa.536.0 = phi <2 x i64> [ zeroinitializer, %122 ], [ %.sroa.536.2, %193 ], [ %.sroa.536.2.ph, %181 ]
+  %.sroa.5.0 = phi <2 x i64> [ zeroinitializer, %122 ], [ %.sroa.5.2, %193 ], [ %.sroa.5.2.ph, %181 ]
   store atomic i8 0, i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 2, i32 0, i32 0, i32 0) release, align 8
   store atomic i8 0, i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0, i32 2, i32 0, i32 0, i32 0) release, align 8
   %126 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
@@ -25357,17 +25841,17 @@
   br i1 %129, label %.loopexit, label %.preheader
 
 .loopexit:                                        ; preds = %.preheader, %_ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i.thread
-  %130 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+  %130 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %131 = icmp ne i8 %130, 0
-  %132 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*), align 8
+  %132 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*) unordered, align 8
   %133 = icmp eq i64 %132, %1
   %134 = and i1 %131, %133
   br i1 %134, label %141, label %135
 
 135:                                              ; preds = %.loopexit
-  %136 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+  %136 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %137 = icmp ne i8 %136, 0
-  %138 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*), align 8
+  %138 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*) unordered, align 8
   %139 = icmp eq i64 %138, %1
   %140 = and i1 %137, %139
   br i1 %140, label %141, label %200
@@ -25375,82 +25859,82 @@
 141:                                              ; preds = %135, %.loopexit
   %142 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %135 ]
   %143 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %142, i64 0, i32 6, i32 0, i32 0, i32 1
-  %144 = load i8, i8* %143, align 8, !tbaa !314, !range !72
+  %144 = load atomic i8, i8* %143 unordered, align 8, !tbaa !312, !range !70
   %145 = icmp eq i8 %144, 0
   br i1 %145, label %150, label %146
 
 146:                                              ; preds = %141
   %147 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %142, i64 0, i32 6, i32 0, i32 0, i32 0, i32 0, i32 2
   %148 = bitcast i64* %147 to <2 x i64>*
-  %149 = load <2 x i64>, <2 x i64>* %148, align 8, !tbaa !89
+  %149 = load <2 x i64>, <2 x i64>* %148, align 8, !tbaa !87
   br label %153
 
 150:                                              ; preds = %141
   %151 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %142, i64 0, i32 6, i32 0, i32 0, i32 0, i32 0, i32 0
   %152 = bitcast i64* %151 to i8*
   call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(32) %152, i8 0, i64 32, i1 false) #37
-  store i8 1, i8* %143, align 8, !tbaa !314
+  store i8 1, i8* %143, align 8, !tbaa !312
   br label %153
 
 153:                                              ; preds = %150, %146
   %154 = phi <2 x i64> [ %149, %146 ], [ zeroinitializer, %150 ]
   %155 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %142, i64 0, i32 6, i32 0, i32 0, i32 0, i32 0, i32 2
-  %156 = add nsw <2 x i64> %154, %.sroa.536.0
+  %156 = add nsw <2 x i64> %154, %.sroa.5.0
   %157 = bitcast i64* %155 to <2 x i64>*
-  store <2 x i64> %156, <2 x i64>* %157, align 8, !tbaa !89
+  store <2 x i64> %156, <2 x i64>* %157, align 8, !tbaa !87
   br label %200
 
-_ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i: ; preds = %_ZN6kotlin2mm13GlobalRootSet8IteratorppEv.exit.i, %_ZN6kotlin2mm13GlobalRootSet8IteratorC2ENS2_7begin_tERS1_.exit.i
-  %.sroa.7.2 = phi i32 [ %.sroa.7.1106, %_ZN6kotlin2mm13GlobalRootSet8IteratorC2ENS2_7begin_tERS1_.exit.i ], [ %.sroa.7.7, %_ZN6kotlin2mm13GlobalRootSet8IteratorppEv.exit.i ]
-  %.sroa.1825.1 = phi i64 [ %.sroa.1825.0, %_ZN6kotlin2mm13GlobalRootSet8IteratorC2ENS2_7begin_tERS1_.exit.i ], [ %.sroa.1825.4, %_ZN6kotlin2mm13GlobalRootSet8IteratorppEv.exit.i ]
-  %.sroa.536.1 = phi <2 x i64> [ zeroinitializer, %_ZN6kotlin2mm13GlobalRootSet8IteratorC2ENS2_7begin_tERS1_.exit.i ], [ %.sroa.536.2114, %_ZN6kotlin2mm13GlobalRootSet8IteratorppEv.exit.i ]
+_ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i.thread5: ; preds = %_ZN6kotlin2mm13GlobalRootSet8IteratorppEv.exit.i, %_ZN6kotlin2mm13GlobalRootSet8IteratorC2ENS2_7begin_tERS1_.exit.i
+  %.sroa.7.2 = phi i32 [ %.sroa.7.1113, %_ZN6kotlin2mm13GlobalRootSet8IteratorC2ENS2_7begin_tERS1_.exit.i ], [ %.sroa.7.7, %_ZN6kotlin2mm13GlobalRootSet8IteratorppEv.exit.i ]
+  %.sroa.1830.1 = phi i64 [ %.sroa.1830.0, %_ZN6kotlin2mm13GlobalRootSet8IteratorC2ENS2_7begin_tERS1_.exit.i ], [ %.sroa.1830.4, %_ZN6kotlin2mm13GlobalRootSet8IteratorppEv.exit.i ]
+  %.sroa.5.1 = phi <2 x i64> [ zeroinitializer, %_ZN6kotlin2mm13GlobalRootSet8IteratorC2ENS2_7begin_tERS1_.exit.i ], [ %.sroa.5.2121, %_ZN6kotlin2mm13GlobalRootSet8IteratorppEv.exit.i ]
   switch i32 %.sroa.7.2, label %159 [
     i32 0, label %_ZN6kotlin2mm13GlobalRootSet8IteratordeEv.exit.i
     i32 1, label %_ZN6kotlin2mm13GlobalRootSet8IteratordeEv.exit.i.thread
     i32 2, label %158
   ]
 
-158:                                              ; preds = %_ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i
+158:                                              ; preds = %_ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i.thread5
   call void (i1, i8*, i8*, ...) @_ZN6kotlin8internal24RuntimeAssertFailedPanicEbPKcS2_z(i1 zeroext undef, i8* undef, i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.234, i64 0, i64 0)) #51
   unreachable
 
-159:                                              ; preds = %_ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i
+159:                                              ; preds = %_ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i.thread5
   unreachable
 
-_ZN6kotlin2mm13GlobalRootSet8IteratordeEv.exit.i: ; preds = %_ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i
-  %160 = inttoptr i64 %.sroa.1825.1 to %"struct.std::_List_node.67"*
+_ZN6kotlin2mm13GlobalRootSet8IteratordeEv.exit.i: ; preds = %_ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i.thread5
+  %160 = inttoptr i64 %.sroa.1830.1 to %"struct.std::_List_node.67"*
   %161 = getelementptr inbounds %"struct.std::_List_node.67", %"struct.std::_List_node.67"* %160, i64 0, i32 1
   %162 = bitcast %"struct.__gnu_cxx::__aligned_membuf.68"* %161 to %struct.ObjHeader***
-  %163 = load %struct.ObjHeader**, %struct.ObjHeader*** %162, align 8, !tbaa !3
-  %164 = load %struct.ObjHeader*, %struct.ObjHeader** %163, align 8, !tbaa !3
+  %163 = load atomic %struct.ObjHeader**, %struct.ObjHeader*** %162 unordered, align 8, !tbaa !3
+  %164 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %163 unordered, align 8, !tbaa !3
   %165 = call fastcc zeroext i1 @_ZN6kotlin2gc8internal11collectRootINS1_10MarkTraitsEEEbRNT_9MarkQueueEP9ObjHeader(%"union.std::aligned_storage<8, 8>::type"* nonnull align 8 dereferenceable(8) %10, %struct.ObjHeader* %164) #37
-  %.sroa.536.16.vec.extract = extractelement <2 x i64> %.sroa.536.1, i32 0
-  %166 = add i64 %.sroa.536.16.vec.extract, 1
-  %.sroa.536.16.vec.insert = insertelement <2 x i64> %.sroa.536.1, i64 %166, i32 0
-  %.sroa.536.2.ph = select i1 %165, <2 x i64> %.sroa.536.16.vec.insert, <2 x i64> %.sroa.536.1
-  %167 = inttoptr i64 %.sroa.1825.1 to i64*
-  %168 = load i64, i64* %167, align 8, !tbaa !125
-  %169 = load i64, i64* bitcast (%"class.kotlin::MultiSourceQueue"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0) to i64*), align 8
+  %.sroa.5.16.vec.extract = extractelement <2 x i64> %.sroa.5.1, i32 0
+  %166 = add i64 %.sroa.5.16.vec.extract, 1
+  %.sroa.5.16.vec.insert = insertelement <2 x i64> %.sroa.5.1, i64 %166, i32 0
+  %.sroa.5.2.ph = select i1 %165, <2 x i64> %.sroa.5.16.vec.insert, <2 x i64> %.sroa.5.1
+  %167 = inttoptr i64 %.sroa.1830.1 to i64*
+  %168 = load atomic i64, i64* %167 unordered, align 8, !tbaa !123
+  %169 = load atomic i64, i64* bitcast (%"class.kotlin::MultiSourceQueue"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0) to i64*) unordered, align 8
   br label %177
 
-_ZN6kotlin2mm13GlobalRootSet8IteratordeEv.exit.i.thread: ; preds = %_ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i
-  %170 = inttoptr i64 %.sroa.1825.1 to %"struct.std::_List_node.67"*
+_ZN6kotlin2mm13GlobalRootSet8IteratordeEv.exit.i.thread: ; preds = %_ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i.thread5
+  %170 = inttoptr i64 %.sroa.1830.1 to %"struct.std::_List_node.67"*
   %171 = getelementptr inbounds %"struct.std::_List_node.67", %"struct.std::_List_node.67"* %170, i64 0, i32 1
   %172 = bitcast %"struct.__gnu_cxx::__aligned_membuf.68"* %171 to %struct.ObjHeader**
-  %173 = load %struct.ObjHeader*, %struct.ObjHeader** %172, align 8, !tbaa !3
+  %173 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %172 unordered, align 8, !tbaa !3
   %174 = call fastcc zeroext i1 @_ZN6kotlin2gc8internal11collectRootINS1_10MarkTraitsEEEbRNT_9MarkQueueEP9ObjHeader(%"union.std::aligned_storage<8, 8>::type"* nonnull align 8 dereferenceable(8) %10, %struct.ObjHeader* %173) #37
   br i1 %174, label %175, label %185
 
 175:                                              ; preds = %_ZN6kotlin2mm13GlobalRootSet8IteratordeEv.exit.i.thread
-  %.sroa.536.24.vec.extract = extractelement <2 x i64> %.sroa.536.1, i32 1
-  %176 = add i64 %.sroa.536.24.vec.extract, 1
-  %.sroa.536.24.vec.insert = insertelement <2 x i64> %.sroa.536.1, i64 %176, i32 1
+  %.sroa.5.24.vec.extract = extractelement <2 x i64> %.sroa.5.1, i32 1
+  %176 = add i64 %.sroa.5.24.vec.extract, 1
+  %.sroa.5.24.vec.insert = insertelement <2 x i64> %.sroa.5.1, i64 %176, i32 1
   br label %185
 
 177:                                              ; preds = %182, %_ZN6kotlin2mm13GlobalRootSet8IteratordeEv.exit.i
   %.sroa.7.3 = phi i32 [ 0, %_ZN6kotlin2mm13GlobalRootSet8IteratordeEv.exit.i ], [ 1, %182 ]
-  %.sroa.1825.2 = phi i64 [ %168, %_ZN6kotlin2mm13GlobalRootSet8IteratordeEv.exit.i ], [ %169, %182 ]
-  %178 = inttoptr i64 %.sroa.1825.2 to %"struct.std::__detail::_List_node_base"*
+  %.sroa.1830.2 = phi i64 [ %168, %_ZN6kotlin2mm13GlobalRootSet8IteratordeEv.exit.i ], [ %169, %182 ]
+  %178 = inttoptr i64 %.sroa.1830.2 to %"struct.std::__detail::_List_node_base"*
   %179 = icmp eq %"struct.std::__detail::_List_node_base"* %178, getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0)
   br label %180
 
@@ -25473,15 +25957,15 @@
   br i1 %179, label %180, label %_ZN6kotlin2mm13GlobalRootSet8IteratorppEv.exit.i
 
 185:                                              ; preds = %175, %_ZN6kotlin2mm13GlobalRootSet8IteratordeEv.exit.i.thread
-  %.sroa.536.2 = phi <2 x i64> [ %.sroa.536.24.vec.insert, %175 ], [ %.sroa.536.1, %_ZN6kotlin2mm13GlobalRootSet8IteratordeEv.exit.i.thread ]
-  %186 = inttoptr i64 %.sroa.1825.1 to i64*
-  %187 = load i64, i64* %186, align 8, !tbaa !125
-  %188 = load i64, i64* bitcast (%"class.kotlin::MultiSourceQueue"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0) to i64*), align 8
+  %.sroa.5.2 = phi <2 x i64> [ %.sroa.5.24.vec.insert, %175 ], [ %.sroa.5.1, %_ZN6kotlin2mm13GlobalRootSet8IteratordeEv.exit.i.thread ]
+  %186 = inttoptr i64 %.sroa.1830.1 to i64*
+  %187 = load atomic i64, i64* %186 unordered, align 8, !tbaa !123
+  %188 = load atomic i64, i64* bitcast (%"class.kotlin::MultiSourceQueue"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0) to i64*) unordered, align 8
   br label %189
 
 189:                                              ; preds = %194, %185
-  %.sroa.1825.3 = phi i64 [ %187, %185 ], [ %188, %194 ]
-  %190 = inttoptr i64 %.sroa.1825.3 to %"struct.std::__detail::_List_node_base"*
+  %.sroa.1830.3 = phi i64 [ %187, %185 ], [ %188, %194 ]
+  %190 = inttoptr i64 %.sroa.1830.3 to %"struct.std::__detail::_List_node_base"*
   %191 = icmp eq %"struct.std::__detail::_List_node_base"* %190, getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0)
   br label %192
 
@@ -25504,10 +25988,10 @@
   br i1 %191, label %192, label %_ZN6kotlin2mm13GlobalRootSet8IteratorppEv.exit.i
 
 _ZN6kotlin2mm13GlobalRootSet8IteratorppEv.exit.i: ; preds = %196, %194, %184, %182
-  %.sroa.536.2114 = phi <2 x i64> [ %.sroa.536.2.ph, %184 ], [ %.sroa.536.2, %196 ], [ %.sroa.536.2.ph, %182 ], [ %.sroa.536.2, %194 ]
+  %.sroa.5.2121 = phi <2 x i64> [ %.sroa.5.2.ph, %184 ], [ %.sroa.5.2, %196 ], [ %.sroa.5.2.ph, %182 ], [ %.sroa.5.2, %194 ]
   %.sroa.7.7 = phi i32 [ %.sroa.7.3, %184 ], [ 1, %196 ], [ %.sroa.7.4, %182 ], [ %.sroa.7.6, %194 ]
-  %.sroa.1825.4 = phi i64 [ %.sroa.1825.2, %184 ], [ %.sroa.1825.3, %196 ], [ %.sroa.1825.2, %182 ], [ %.sroa.1825.3, %194 ]
-  br label %_ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i
+  %.sroa.1830.4 = phi i64 [ %.sroa.1830.2, %184 ], [ %.sroa.1830.3, %196 ], [ %.sroa.1830.2, %182 ], [ %.sroa.1830.3, %194 ]
+  br label %_ZNK6kotlin2mm13GlobalRootSet8IteratoreqERKS2_.exit.i.thread5
 
 197:                                              ; preds = %7
   %198 = landingpad { i8*, i32 }
@@ -25531,329 +26015,394 @@
 
 ; Function Attrs: nounwind uwtable
 define internal fastcc void @_ZN6kotlin2gc23collectRootSetForThreadINS0_8internal10MarkTraitsEEEvNS0_8GCHandleERNT_9MarkQueueERNS_2mm10ThreadDataE(i64 %0, %"union.std::aligned_storage<8, 8>::type"* nonnull align 8 dereferenceable(8) %1, %"class.kotlin::mm::ThreadData.119"* nocapture nonnull readonly align 8 dereferenceable(344) %2) unnamed_addr #17 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
+  %.sroa.2231 = alloca i64, align 8
+  %.sroa.44 = alloca <2 x %struct.ObjHeader**>, align 16
   %4 = tail call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37
   %5 = getelementptr inbounds %"class.kotlin::mm::ThreadData.119", %"class.kotlin::mm::ThreadData.119"* %2, i64 0, i32 6, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %6 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %5, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %5 unordered, align 8, !tbaa !3
   %7 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %6, i64 0, i32 0, i32 2
-  store i64 0, i64* %7, align 8, !tbaa !113
+  store i64 0, i64* %7, align 8, !tbaa !111
   %8 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %6, i64 0, i32 0, i32 4
-  store i64 0, i64* %8, align 8, !tbaa !317
+  store i64 0, i64* %8, align 8, !tbaa !315
   %9 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %6, i64 0, i32 0, i32 0
-  %10 = load %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %9, align 8, !tbaa !318
+  %10 = load atomic %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %9 unordered, align 8, !tbaa !316
   %11 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %10, i64 0, i32 1, i32 0, i32 0
   %12 = load atomic i64, i64* %11 seq_cst, align 8
   %13 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %6, i64 0, i32 0, i32 3
-  store i64 %12, i64* %13, align 8, !tbaa !319
-  %14 = load %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %9, align 8, !tbaa !318
+  store i64 %12, i64* %13, align 8, !tbaa !317
+  %14 = load atomic %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %9 unordered, align 8, !tbaa !316
   %15 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %14, i64 0, i32 0, i32 0, i32 0
   %16 = load atomic i32, i32* %15 seq_cst, align 4
   %17 = sext i32 %16 to i64
   %18 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %6, i64 0, i32 0, i32 5
-  store i64 %17, i64* %18, align 8, !tbaa !320
+  store i64 %17, i64* %18, align 8, !tbaa !318
   %19 = getelementptr inbounds %"class.kotlin::mm::ThreadData.119", %"class.kotlin::mm::ThreadData.119"* %2, i64 0, i32 2
+  %.sroa.2231.0.sroa_cast88 = bitcast i64* %.sroa.2231 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %.sroa.2231.0.sroa_cast88)
+  %.sroa.44.0.sroa_cast81 = bitcast <2 x %struct.ObjHeader**>* %.sroa.44 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %.sroa.44.0.sroa_cast81)
   %20 = getelementptr inbounds %"class.kotlin::mm::ThreadData.119", %"class.kotlin::mm::ThreadData.119"* %2, i64 0, i32 5, i32 0
-  %21 = load %struct.FrameOverlay.6*, %struct.FrameOverlay.6** %20, align 8, !tbaa !7, !noalias !321
+  %21 = load atomic %struct.FrameOverlay.6*, %struct.FrameOverlay.6** %20 unordered, align 8, !tbaa !7, !noalias !319
   %22 = ptrtoint %struct.FrameOverlay.6* %21 to i64
+  store i64 %22, i64* %.sroa.2231, align 8, !tbaa !322, !alias.scope !319
   %23 = icmp eq %struct.FrameOverlay.6* %21, null
-  br i1 %23, label %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1, label %24
+  br i1 %23, label %.thread, label %25
 
-24:                                               ; preds = %3
-  %25 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %21, i64 1
-  %26 = bitcast %struct.FrameOverlay.6* %25 to %struct.ObjHeader**
-  %27 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %21, i64 0, i32 2
-  %28 = load i32, i32* %27, align 8, !tbaa !12
-  %29 = sext i32 %28 to i64
-  %30 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %26, i64 %29
-  %31 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %21, i64 0, i32 3
-  %32 = load i32, i32* %31, align 4, !tbaa !13
-  %33 = sext i32 %32 to i64
-  %34 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %30, i64 %33
-  %35 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %34, i64 -3
-  %36 = sub nsw i64 0, %29
-  %37 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %35, i64 %36
-  %38 = icmp ult %struct.ObjHeader** %30, %37
-  %or.cond = or i1 %23, %38
-  br i1 %or.cond, label %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1, label %.preheader166
+.thread:                                          ; preds = %3
+  %24 = getelementptr inbounds <2 x %struct.ObjHeader**>, <2 x %struct.ObjHeader**>* %.sroa.44, i64 0, i64 0
+  store %struct.ObjHeader** null, %struct.ObjHeader*** %24, align 16
+  %.sroa.44.8.sroa_idx299 = getelementptr inbounds <2 x %struct.ObjHeader**>, <2 x %struct.ObjHeader**>* %.sroa.44, i64 0, i64 1
+  store %struct.ObjHeader** null, %struct.ObjHeader*** %.sroa.44.8.sroa_idx299, align 8, !tbaa !324, !alias.scope !319
+  br label %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1
 
-.preheader166:                                    ; preds = %45, %24
-  %39 = phi %struct.FrameOverlay.6* [ %43, %45 ], [ %21, %24 ]
-  %40 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %39, i64 0, i32 1
-  %41 = bitcast %struct.FrameOverlay.6** %40 to i64*
-  %42 = load i64, i64* %41, align 8, !tbaa !9
-  %43 = inttoptr i64 %42 to %struct.FrameOverlay.6*
-  %44 = icmp eq i64 %42, 0
-  br i1 %44, label %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1, label %45
+25:                                               ; preds = %3
+  %26 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %21, i64 1
+  %27 = bitcast %struct.FrameOverlay.6* %26 to %struct.ObjHeader**
+  %28 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %21, i64 0, i32 2
+  %29 = load atomic i32, i32* %28 unordered, align 8, !tbaa !12
+  %30 = sext i32 %29 to i64
+  %31 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %27, i64 %30
+  %32 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %21, i64 0, i32 3
+  %33 = load atomic i32, i32* %32 unordered, align 4, !tbaa !13
+  %34 = sext i32 %33 to i64
+  %35 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %31, i64 %34
+  %36 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %35, i64 -3
+  %37 = sub nsw i64 0, %30
+  %38 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %36, i64 %37
+  %39 = getelementptr inbounds <2 x %struct.ObjHeader**>, <2 x %struct.ObjHeader**>* %.sroa.44, i64 0, i64 0
+  store %struct.ObjHeader** %31, %struct.ObjHeader*** %39, align 16
+  %.sroa.44.8.sroa_idx = getelementptr inbounds <2 x %struct.ObjHeader**>, <2 x %struct.ObjHeader**>* %.sroa.44, i64 0, i64 1
+  store %struct.ObjHeader** %38, %struct.ObjHeader*** %.sroa.44.8.sroa_idx, align 8, !tbaa !324, !alias.scope !319
+  %40 = icmp ult %struct.ObjHeader** %31, %38
+  %or.cond = or i1 %23, %40
+  br i1 %or.cond, label %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1, label %.preheader164
 
-45:                                               ; preds = %.preheader166
-  %46 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %43, i64 1
-  %47 = bitcast %struct.FrameOverlay.6* %46 to %struct.ObjHeader**
-  %48 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %43, i64 0, i32 2
-  %49 = load i32, i32* %48, align 8, !tbaa !12
-  %50 = sext i32 %49 to i64
-  %51 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %47, i64 %50
-  %52 = inttoptr i64 %42 to %struct.ObjHeader**
-  %53 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %43, i64 0, i32 3
-  %54 = load i32, i32* %53, align 4, !tbaa !13
-  %55 = sext i32 %54 to i64
-  %56 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %52, i64 %50
-  %57 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %56, i64 %55
-  %58 = sub nsw i64 0, %50
-  %59 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %57, i64 %58
-  %60 = icmp ult %struct.ObjHeader** %51, %59
-  br i1 %60, label %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1, label %.preheader166
+.preheader164:                                    ; preds = %48, %25
+  %41 = phi %struct.FrameOverlay.6* [ %45, %48 ], [ %21, %25 ]
+  %42 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %41, i64 0, i32 1
+  %43 = bitcast %struct.FrameOverlay.6** %42 to i64*
+  %44 = load atomic i64, i64* %43 unordered, align 8, !tbaa !9
+  %45 = inttoptr i64 %44 to %struct.FrameOverlay.6*
+  %46 = icmp eq i64 %44, 0
+  br i1 %46, label %47, label %48
 
-_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1: ; preds = %45, %.preheader166, %24, %3
-  %.sroa.42.8..sroa.42.32.59212 = phi %struct.ObjHeader** [ %37, %24 ], [ null, %.preheader166 ], [ %59, %45 ], [ null, %3 ]
-  %.sroa.42.0..sroa.42.24.46 = phi %struct.ObjHeader** [ %30, %24 ], [ null, %.preheader166 ], [ %51, %45 ], [ null, %3 ]
-  %.sroa.2226.0 = phi i64 [ %22, %24 ], [ 0, %.preheader166 ], [ %42, %45 ], [ %22, %3 ]
-  %61 = getelementptr inbounds %"class.kotlin::mm::ThreadData.119", %"class.kotlin::mm::ThreadData.119"* %2, i64 0, i32 2, i32 0, i32 0, i32 0, i32 1
-  %62 = load %struct.ObjHeader**, %struct.ObjHeader*** %61, align 8
-  %63 = bitcast %"class.kotlin::mm::ThreadLocalStorage"* %19 to i64*
-  %64 = load i64, i64* %63, align 8
-  br label %65
+47:                                               ; preds = %.preheader164
+  store i64 0, i64* %.sroa.2231, align 8, !tbaa !322
+  store <2 x %struct.ObjHeader**> zeroinitializer, <2 x %struct.ObjHeader**>* %.sroa.44, align 16, !tbaa !3
+  br label %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1
 
-65:                                               ; preds = %72, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1
-  %.sroa.2226.1 = phi i64 [ %.sroa.2226.0, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1 ], [ %.sroa.2226.2, %72 ]
-  %.sroa.9.0 = phi i32 [ 0, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1 ], [ %.sroa.9.1, %72 ]
-  br label %66
+48:                                               ; preds = %.preheader164
+  %49 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %45, i64 1
+  %50 = bitcast %struct.FrameOverlay.6* %49 to %struct.ObjHeader**
+  %51 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %45, i64 0, i32 2
+  %52 = load atomic i32, i32* %51 unordered, align 8, !tbaa !12
+  %53 = sext i32 %52 to i64
+  %54 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %50, i64 %53
+  store %struct.ObjHeader** %54, %struct.ObjHeader*** %39, align 16, !tbaa !325
+  %55 = inttoptr i64 %44 to %struct.ObjHeader**
+  %56 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %45, i64 0, i32 3
+  %57 = load atomic i32, i32* %56 unordered, align 4, !tbaa !13
+  %58 = sext i32 %57 to i64
+  %59 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %55, i64 %53
+  %60 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %59, i64 %58
+  %61 = sub nsw i64 0, %53
+  %62 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %60, i64 %61
+  store %struct.ObjHeader** %62, %struct.ObjHeader*** %.sroa.44.8.sroa_idx, align 8, !tbaa !324
+  %63 = icmp ult %struct.ObjHeader** %54, %62
+  br i1 %63, label %64, label %.preheader164
 
-66:                                               ; preds = %66, %65
-  switch i32 %.sroa.9.0, label %66 [
-    i32 1, label %69
+64:                                               ; preds = %48
+  store i64 %44, i64* %.sroa.2231, align 8, !tbaa !322
+  br label %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1
+
+_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1: ; preds = %64, %47, %25, %.thread
+  %.sroa.44.8.sroa_idx301 = phi %struct.ObjHeader*** [ %.sroa.44.8.sroa_idx, %64 ], [ %.sroa.44.8.sroa_idx, %47 ], [ %.sroa.44.8.sroa_idx, %25 ], [ %.sroa.44.8.sroa_idx299, %.thread ]
+  %65 = phi %struct.ObjHeader*** [ %39, %64 ], [ %39, %47 ], [ %39, %25 ], [ %24, %.thread ]
+  %.sroa.44.8..sroa.44.32.68217 = phi %struct.ObjHeader** [ %62, %64 ], [ null, %47 ], [ %38, %25 ], [ null, %.thread ]
+  %.sroa.2231.0..sroa.2231.16.40195 = phi i64 [ %44, %64 ], [ 0, %47 ], [ %22, %25 ], [ %22, %.thread ]
+  %.sroa.44.0..sroa.44.24.56 = phi %struct.ObjHeader** [ %54, %64 ], [ null, %47 ], [ %31, %25 ], [ null, %.thread ]
+  %66 = getelementptr inbounds %"class.kotlin::mm::ThreadData.119", %"class.kotlin::mm::ThreadData.119"* %2, i64 0, i32 2, i32 0, i32 0, i32 0, i32 1
+  %67 = load atomic %struct.ObjHeader**, %struct.ObjHeader*** %66 unordered, align 8
+  %68 = bitcast %"class.kotlin::mm::ThreadLocalStorage"* %19 to i64*
+  %69 = load atomic i64, i64* %68 unordered, align 8
+  br label %70
+
+70:                                               ; preds = %78, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1
+  %.sroa.2231.0..sroa.2231.16.43 = phi i64 [ %.sroa.2231.0..sroa.2231.16.40195, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1 ], [ %.sroa.2231.0..sroa.2231.16.40194, %78 ]
+  %.sroa.9.0 = phi i32 [ 0, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i1 ], [ %.sroa.9.1, %78 ]
+  br label %71
+
+71:                                               ; preds = %71, %70
+  switch i32 %.sroa.9.0, label %71 [
+    i32 1, label %75
     i32 0, label %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i2
-    i32 2, label %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread
+    i32 2, label %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread4
   ]
 
-_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i2: ; preds = %66
-  %67 = icmp eq i64 %.sroa.2226.1, 0
-  %68 = icmp eq %struct.ObjHeader** %.sroa.42.0..sroa.42.24.46, null
-  %or.cond252 = and i1 %67, %68
-  br i1 %or.cond252, label %72, label %_ZN6kotlin2mm13ThreadRootSet8IteratorC2ENS2_7begin_tERS1_.exit
+_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i2: ; preds = %71
+  %72 = icmp eq i64 %.sroa.2231.0..sroa.2231.16.43, 0
+  %73 = icmp eq %struct.ObjHeader** %.sroa.44.0..sroa.44.24.56, null
+  %or.cond294 = and i1 %72, %73
+  br i1 %or.cond294, label %74, label %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread
 
-69:                                               ; preds = %66
-  %70 = inttoptr i64 %.sroa.2226.1 to %struct.ObjHeader**
-  %71 = icmp eq %struct.ObjHeader** %62, %70
-  br i1 %71, label %72, label %_ZN6kotlin2mm13ThreadRootSet8IteratorC2ENS2_7begin_tERS1_.exit
+74:                                               ; preds = %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i2
+  store i64 %69, i64* %.sroa.2231, align 8, !tbaa.struct !265
+  br label %78
 
-72:                                               ; preds = %69, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i2
-  %.sroa.2226.2 = phi i64 [ %.sroa.2226.1, %69 ], [ %64, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i2 ]
-  %.sroa.9.1 = phi i32 [ 2, %69 ], [ 1, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i2 ]
-  br label %65
+75:                                               ; preds = %71
+  %76 = inttoptr i64 %.sroa.2231.0..sroa.2231.16.43 to %struct.ObjHeader**
+  %77 = icmp eq %struct.ObjHeader** %67, %76
+  br i1 %77, label %78, label %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread
 
-_ZN6kotlin2mm13ThreadRootSet8IteratorC2ENS2_7begin_tERS1_.exit: ; preds = %69, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i2
-  br label %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3
+78:                                               ; preds = %75, %74
+  %.sroa.2231.0..sroa.2231.16.40194 = phi i64 [ %69, %74 ], [ %.sroa.2231.0..sroa.2231.16.43, %75 ]
+  %.sroa.9.1 = phi i32 [ 1, %74 ], [ 2, %75 ]
+  br label %70
 
-_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread: ; preds = %160, %142, %66
-  %.sroa.6.0 = phi <2 x i64> [ zeroinitializer, %66 ], [ %.sroa.6.2.ph, %142 ], [ %.sroa.6.2, %160 ]
-  %73 = shufflevector <2 x i64> %.sroa.6.0, <2 x i64> undef, <2 x i32> <i32 1, i32 0>
-  %74 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
-  %75 = icmp eq i8 %74, 0
-  br i1 %75, label %.loopexit, label %.preheader
+_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread: ; preds = %75, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i2
+  %.sroa.2231.0.sroa_cast87 = bitcast i64* %.sroa.2231 to %struct.ObjHeader***
+  br label %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit
 
-.preheader:                                       ; preds = %.preheader, %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread
-  tail call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37
-  %76 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
-  %77 = icmp eq i8 %76, 0
-  br i1 %77, label %.loopexit, label %.preheader
+_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread4: ; preds = %170, %151, %71
+  %.sroa.695.0 = phi <2 x i64> [ zeroinitializer, %71 ], [ %.sroa.695.2.ph, %151 ], [ %.sroa.695.2, %170 ]
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %.sroa.2231.0.sroa_cast88)
+  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %.sroa.44.0.sroa_cast81)
+  %79 = shufflevector <2 x i64> %.sroa.695.0, <2 x i64> undef, <2 x i32> <i32 1, i32 0>
+  %80 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
+  %81 = icmp eq i8 %80, 0
+  br i1 %81, label %.loopexit, label %.preheader
 
-.loopexit:                                        ; preds = %.preheader, %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread
-  %78 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
-  %79 = icmp ne i8 %78, 0
-  %80 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*), align 8
-  %81 = icmp eq i64 %80, %0
-  %82 = and i1 %79, %81
-  br i1 %82, label %89, label %83
+.preheader:                                       ; preds = %.preheader, %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread4
+  tail call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37
+  %82 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
+  %83 = icmp eq i8 %82, 0
+  br i1 %83, label %.loopexit, label %.preheader
 
-83:                                               ; preds = %.loopexit
-  %84 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+.loopexit:                                        ; preds = %.preheader, %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread4
+  %84 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %85 = icmp ne i8 %84, 0
-  %86 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*), align 8
+  %86 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*) unordered, align 8
   %87 = icmp eq i64 %86, %0
   %88 = and i1 %85, %87
-  br i1 %88, label %89, label %_ZN6kotlin2gc8GCHandle20GCThreadRootSetScopeD2Ev.exit
+  br i1 %88, label %95, label %89
 
-89:                                               ; preds = %83, %.loopexit
-  %90 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %83 ]
-  %91 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %90, i64 0, i32 6, i32 0, i32 0, i32 1
-  %92 = load i8, i8* %91, align 8, !tbaa !314, !range !72
-  %93 = icmp eq i8 %92, 0
-  %94 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %90, i64 0, i32 6, i32 0, i32 0, i32 0, i32 0, i32 0
-  br i1 %93, label %98, label %95
+89:                                               ; preds = %.loopexit
+  %90 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
+  %91 = icmp ne i8 %90, 0
+  %92 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*) unordered, align 8
+  %93 = icmp eq i64 %92, %0
+  %94 = and i1 %91, %93
+  br i1 %94, label %95, label %_ZN6kotlin2gc8GCHandle20GCThreadRootSetScopeD2Ev.exit
 
-95:                                               ; preds = %89
-  %96 = bitcast i64* %94 to <2 x i64>*
-  %97 = load <2 x i64>, <2 x i64>* %96, align 8, !tbaa !89
-  br label %100
+95:                                               ; preds = %89, %.loopexit
+  %96 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %89 ]
+  %97 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %96, i64 0, i32 6, i32 0, i32 0, i32 1
+  %98 = load atomic i8, i8* %97 unordered, align 8, !tbaa !312, !range !70
+  %99 = icmp eq i8 %98, 0
+  %100 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %96, i64 0, i32 6, i32 0, i32 0, i32 0, i32 0, i32 0
+  br i1 %99, label %104, label %101
 
-98:                                               ; preds = %89
-  %99 = bitcast i64* %94 to i8*
-  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(32) %99, i8 0, i64 32, i1 false) #37
-  store i8 1, i8* %91, align 8, !tbaa !314
-  %.pre = bitcast i64* %94 to <2 x i64>*
-  br label %100
+101:                                              ; preds = %95
+  %102 = bitcast i64* %100 to <2 x i64>*
+  %103 = load <2 x i64>, <2 x i64>* %102, align 8, !tbaa !87
+  br label %106
 
-100:                                              ; preds = %98, %95
-  %.pre-phi = phi <2 x i64>* [ %.pre, %98 ], [ %96, %95 ]
-  %101 = phi <2 x i64> [ zeroinitializer, %98 ], [ %97, %95 ]
-  %102 = add nsw <2 x i64> %101, %73
-  store <2 x i64> %102, <2 x i64>* %.pre-phi, align 8, !tbaa !89
+104:                                              ; preds = %95
+  %105 = bitcast i64* %100 to i8*
+  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(32) %105, i8 0, i64 32, i1 false) #37
+  store i8 1, i8* %97, align 8, !tbaa !312
+  %.pre = bitcast i64* %100 to <2 x i64>*
+  br label %106
+
+106:                                              ; preds = %104, %101
+  %.pre-phi = phi <2 x i64>* [ %.pre, %104 ], [ %102, %101 ]
+  %107 = phi <2 x i64> [ zeroinitializer, %104 ], [ %103, %101 ]
+  %108 = add nsw <2 x i64> %107, %79
+  store <2 x i64> %108, <2 x i64>* %.pre-phi, align 8, !tbaa !87
   br label %_ZN6kotlin2gc8GCHandle20GCThreadRootSetScopeD2Ev.exit
 
-_ZN6kotlin2gc8GCHandle20GCThreadRootSetScopeD2Ev.exit: ; preds = %100, %83
+_ZN6kotlin2gc8GCHandle20GCThreadRootSetScopeD2Ev.exit: ; preds = %106, %89
   store atomic i8 0, i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0) release, align 1
   ret void
 
-_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3: ; preds = %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit, %_ZN6kotlin2mm13ThreadRootSet8IteratorC2ENS2_7begin_tERS1_.exit
-  %.sroa.42.8..sroa.42.32.59 = phi %struct.ObjHeader** [ %.sroa.42.8..sroa.42.32.59212, %_ZN6kotlin2mm13ThreadRootSet8IteratorC2ENS2_7begin_tERS1_.exit ], [ %.sroa.42.8..sroa.42.32.59210, %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit ]
-  %.sroa.42.0..sroa.42.24.54 = phi %struct.ObjHeader** [ %.sroa.42.0..sroa.42.24.46, %_ZN6kotlin2mm13ThreadRootSet8IteratorC2ENS2_7begin_tERS1_.exit ], [ %.sroa.42.0..sroa.42.24.40206, %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit ]
-  %.sroa.2226.3 = phi i64 [ %.sroa.2226.1, %_ZN6kotlin2mm13ThreadRootSet8IteratorC2ENS2_7begin_tERS1_.exit ], [ %.sroa.2226.8, %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit ]
-  %.sroa.6.1 = phi <2 x i64> [ zeroinitializer, %_ZN6kotlin2mm13ThreadRootSet8IteratorC2ENS2_7begin_tERS1_.exit ], [ %.sroa.6.2262, %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit ]
-  %.sroa.9.2 = phi i32 [ %.sroa.9.0, %_ZN6kotlin2mm13ThreadRootSet8IteratorC2ENS2_7begin_tERS1_.exit ], [ %.sroa.9.7, %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit ]
-  switch i32 %.sroa.9.2, label %104 [
+_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit: ; preds = %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit, %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread
+  %.sroa.2231.0..sroa.2231.16.38228 = phi i64 [ %.sroa.2231.0..sroa.2231.16.43, %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread ], [ %.sroa.2231.0..sroa.2231.16.38231, %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit ]
+  %.sroa.2231.0..sroa.2231.16.37220 = phi i64 [ %.sroa.2231.0..sroa.2231.16.43, %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread ], [ %.sroa.2231.0..sroa.2231.16.37223, %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit ]
+  %.sroa.44.8..sroa.44.32.68 = phi %struct.ObjHeader** [ %.sroa.44.8..sroa.44.32.68217, %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread ], [ %.sroa.44.8..sroa.44.32.68215, %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit ]
+  %.sroa.44.0..sroa.44.24.63 = phi %struct.ObjHeader** [ %.sroa.44.0..sroa.44.24.56, %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread ], [ %.sroa.44.0..sroa.44.24.47205, %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit ]
+  %.sroa.695.1 = phi <2 x i64> [ zeroinitializer, %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread ], [ %.sroa.695.2305, %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit ]
+  %.sroa.9.2 = phi i32 [ %.sroa.9.0, %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread ], [ %.sroa.9.7, %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit ]
+  switch i32 %.sroa.9.2, label %110 [
     i32 0, label %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit
     i32 1, label %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit.thread
-    i32 2, label %103
+    i32 2, label %109
   ]
 
-103:                                              ; preds = %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3
+109:                                              ; preds = %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit
   tail call void (i1, i8*, i8*, ...) @_ZN6kotlin8internal24RuntimeAssertFailedPanicEbPKcS2_z(i1 zeroext undef, i8* undef, i8* getelementptr inbounds ([19 x i8], [19 x i8]* @.str.234, i64 0, i64 0)) #51
   unreachable
 
-104:                                              ; preds = %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3
+110:                                              ; preds = %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit
   unreachable
 
-_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit:   ; preds = %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3
-  %105 = load %struct.ObjHeader*, %struct.ObjHeader** %.sroa.42.0..sroa.42.24.54, align 8, !tbaa !3
-  %106 = tail call fastcc zeroext i1 @_ZN6kotlin2gc8internal11collectRootINS1_10MarkTraitsEEEbRNT_9MarkQueueEP9ObjHeader(%"union.std::aligned_storage<8, 8>::type"* nonnull align 8 dereferenceable(8) %1, %struct.ObjHeader* %105) #37
-  %.sroa.6.24.vec.extract = extractelement <2 x i64> %.sroa.6.1, i32 0
-  %107 = add i64 %.sroa.6.24.vec.extract, 1
-  %.sroa.6.24.vec.insert = insertelement <2 x i64> %.sroa.6.1, i64 %107, i32 0
-  %.sroa.6.2.ph = select i1 %106, <2 x i64> %.sroa.6.24.vec.insert, <2 x i64> %.sroa.6.1
-  %108 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %.sroa.42.0..sroa.42.24.54, i64 1
-  %109 = inttoptr i64 %.sroa.2226.3 to %struct.FrameOverlay.6*
-  %110 = icmp eq i64 %.sroa.2226.3, 0
-  %111 = icmp ult %struct.ObjHeader** %108, %.sroa.42.8..sroa.42.32.59
-  %or.cond251 = or i1 %110, %111
-  br i1 %or.cond251, label %_ZN6kotlin2mm11ShadowStack8IteratorppEv.exit.i, label %.preheader162
+_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit:   ; preds = %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit
+  %111 = load atomic %struct.ObjHeader**, %struct.ObjHeader*** %65 unordered, align 8, !tbaa !3
+  %112 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %111 unordered, align 8, !tbaa !3
+  %113 = tail call fastcc zeroext i1 @_ZN6kotlin2gc8internal11collectRootINS1_10MarkTraitsEEEbRNT_9MarkQueueEP9ObjHeader(%"union.std::aligned_storage<8, 8>::type"* nonnull align 8 dereferenceable(8) %1, %struct.ObjHeader* %112) #37
+  %.sroa.695.24.vec.extract = extractelement <2 x i64> %.sroa.695.1, i32 0
+  %114 = add i64 %.sroa.695.24.vec.extract, 1
+  %.sroa.695.24.vec.insert = insertelement <2 x i64> %.sroa.695.1, i64 %114, i32 0
+  %.sroa.695.2.ph = select i1 %113, <2 x i64> %.sroa.695.24.vec.insert, <2 x i64> %.sroa.695.1
+  %115 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %.sroa.44.0..sroa.44.24.63, i64 1
+  store %struct.ObjHeader** %115, %struct.ObjHeader*** %65, align 16, !tbaa !325
+  %116 = inttoptr i64 %.sroa.2231.0..sroa.2231.16.37220 to %struct.FrameOverlay.6*
+  %117 = icmp eq i64 %.sroa.2231.0..sroa.2231.16.37220, 0
+  %118 = icmp ult %struct.ObjHeader** %115, %.sroa.44.8..sroa.44.32.68
+  %or.cond293 = or i1 %117, %118
+  br i1 %or.cond293, label %_ZN6kotlin2mm11ShadowStack8IteratorppEv.exit.i, label %.preheader160
 
-_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit.thread: ; preds = %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3
-  %112 = inttoptr i64 %.sroa.2226.3 to %struct.ObjHeader**
-  %113 = load %struct.ObjHeader*, %struct.ObjHeader** %112, align 8, !tbaa !3
-  %114 = tail call fastcc zeroext i1 @_ZN6kotlin2gc8internal11collectRootINS1_10MarkTraitsEEEbRNT_9MarkQueueEP9ObjHeader(%"union.std::aligned_storage<8, 8>::type"* nonnull align 8 dereferenceable(8) %1, %struct.ObjHeader* %113) #37
-  br i1 %114, label %115, label %149
+_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit.thread: ; preds = %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit
+  %119 = load atomic %struct.ObjHeader**, %struct.ObjHeader*** %.sroa.2231.0.sroa_cast87 unordered, align 8, !tbaa !3
+  %120 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %119 unordered, align 8, !tbaa !3
+  %121 = tail call fastcc zeroext i1 @_ZN6kotlin2gc8internal11collectRootINS1_10MarkTraitsEEEbRNT_9MarkQueueEP9ObjHeader(%"union.std::aligned_storage<8, 8>::type"* nonnull align 8 dereferenceable(8) %1, %struct.ObjHeader* %120) #37
+  br i1 %121, label %122, label %159
 
-115:                                              ; preds = %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit.thread
-  %.sroa.6.32.vec.extract = extractelement <2 x i64> %.sroa.6.1, i32 1
-  %116 = add i64 %.sroa.6.32.vec.extract, 1
-  %.sroa.6.32.vec.insert = insertelement <2 x i64> %.sroa.6.1, i64 %116, i32 1
-  br label %149
+122:                                              ; preds = %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit.thread
+  %.sroa.695.32.vec.extract = extractelement <2 x i64> %.sroa.695.1, i32 1
+  %123 = add i64 %.sroa.695.32.vec.extract, 1
+  %.sroa.695.32.vec.insert = insertelement <2 x i64> %.sroa.695.1, i64 %123, i32 1
+  br label %159
 
-.preheader162:                                    ; preds = %123, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit
-  %117 = phi %struct.FrameOverlay.6* [ %121, %123 ], [ %109, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit ]
-  %118 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %117, i64 0, i32 1
-  %119 = bitcast %struct.FrameOverlay.6** %118 to i64*
-  %120 = load i64, i64* %119, align 8, !tbaa !9
-  %121 = inttoptr i64 %120 to %struct.FrameOverlay.6*
-  %122 = icmp eq i64 %120, 0
-  br i1 %122, label %_ZN6kotlin2mm11ShadowStack8IteratorppEv.exit.i, label %123
+.preheader160:                                    ; preds = %131, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit
+  %124 = phi %struct.FrameOverlay.6* [ %128, %131 ], [ %116, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit ]
+  %125 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %124, i64 0, i32 1
+  %126 = bitcast %struct.FrameOverlay.6** %125 to i64*
+  %127 = load atomic i64, i64* %126 unordered, align 8, !tbaa !9
+  %128 = inttoptr i64 %127 to %struct.FrameOverlay.6*
+  %129 = icmp eq i64 %127, 0
+  br i1 %129, label %130, label %131
 
-123:                                              ; preds = %.preheader162
-  %124 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %121, i64 1
-  %125 = bitcast %struct.FrameOverlay.6* %124 to %struct.ObjHeader**
-  %126 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %121, i64 0, i32 2
-  %127 = load i32, i32* %126, align 8, !tbaa !12
-  %128 = sext i32 %127 to i64
-  %129 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %125, i64 %128
-  %130 = inttoptr i64 %120 to %struct.ObjHeader**
-  %131 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %121, i64 0, i32 3
-  %132 = load i32, i32* %131, align 4, !tbaa !13
-  %133 = sext i32 %132 to i64
-  %134 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %130, i64 %128
-  %135 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %134, i64 %133
-  %136 = sub nsw i64 0, %128
-  %137 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %135, i64 %136
-  %138 = icmp ult %struct.ObjHeader** %129, %137
-  br i1 %138, label %_ZN6kotlin2mm11ShadowStack8IteratorppEv.exit.i, label %.preheader162
+130:                                              ; preds = %.preheader160
+  store i64 0, i64* %.sroa.2231, align 8
+  store <2 x %struct.ObjHeader**> zeroinitializer, <2 x %struct.ObjHeader**>* %.sroa.44, align 16
+  br label %_ZN6kotlin2mm11ShadowStack8IteratorppEv.exit.i
 
-_ZN6kotlin2mm11ShadowStack8IteratorppEv.exit.i:   ; preds = %123, %.preheader162, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit
-  %.sroa.42.0..sroa.42.24.42 = phi %struct.ObjHeader** [ %108, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit ], [ null, %.preheader162 ], [ %129, %123 ]
-  %.sroa.42.8..sroa.42.32.59211 = phi %struct.ObjHeader** [ %.sroa.42.8..sroa.42.32.59, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit ], [ null, %.preheader162 ], [ %137, %123 ]
-  %.sroa.2226.4 = phi i64 [ %.sroa.2226.3, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit ], [ 0, %.preheader162 ], [ %120, %123 ]
-  %139 = load %struct.ObjHeader**, %struct.ObjHeader*** %61, align 8
-  %140 = load i64, i64* %63, align 8
-  br label %141
+131:                                              ; preds = %.preheader160
+  %132 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %128, i64 1
+  %133 = bitcast %struct.FrameOverlay.6* %132 to %struct.ObjHeader**
+  %134 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %128, i64 0, i32 2
+  %135 = load atomic i32, i32* %134 unordered, align 8, !tbaa !12
+  %136 = sext i32 %135 to i64
+  %137 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %133, i64 %136
+  store %struct.ObjHeader** %137, %struct.ObjHeader*** %65, align 16, !tbaa !325
+  %138 = inttoptr i64 %127 to %struct.ObjHeader**
+  %139 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %128, i64 0, i32 3
+  %140 = load atomic i32, i32* %139 unordered, align 4, !tbaa !13
+  %141 = sext i32 %140 to i64
+  %142 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %138, i64 %136
+  %143 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %142, i64 %141
+  %144 = sub nsw i64 0, %136
+  %145 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %143, i64 %144
+  store %struct.ObjHeader** %145, %struct.ObjHeader*** %.sroa.44.8.sroa_idx301, align 8, !tbaa !324
+  %146 = icmp ult %struct.ObjHeader** %137, %145
+  br i1 %146, label %147, label %.preheader160
 
-141:                                              ; preds = %148, %_ZN6kotlin2mm11ShadowStack8IteratorppEv.exit.i
-  %.sroa.2226.5 = phi i64 [ %.sroa.2226.4, %_ZN6kotlin2mm11ShadowStack8IteratorppEv.exit.i ], [ %.sroa.2226.6, %148 ]
-  %.sroa.9.3 = phi i32 [ 0, %_ZN6kotlin2mm11ShadowStack8IteratorppEv.exit.i ], [ %.sroa.9.4, %148 ]
-  br label %142
+147:                                              ; preds = %131
+  store i64 %127, i64* %.sroa.2231, align 8, !tbaa !322
+  br label %_ZN6kotlin2mm11ShadowStack8IteratorppEv.exit.i
 
-142:                                              ; preds = %142, %141
-  switch i32 %.sroa.9.3, label %142 [
-    i32 2, label %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread
+_ZN6kotlin2mm11ShadowStack8IteratorppEv.exit.i:   ; preds = %147, %130, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit
+  %.sroa.2231.0..sroa.2231.16.38227 = phi i64 [ %127, %147 ], [ 0, %130 ], [ %.sroa.2231.0..sroa.2231.16.38228, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit ]
+  %.sroa.2231.0..sroa.2231.16.37219 = phi i64 [ %127, %147 ], [ 0, %130 ], [ %.sroa.2231.0..sroa.2231.16.37220, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit ]
+  %.sroa.44.0..sroa.44.24.49 = phi %struct.ObjHeader** [ %137, %147 ], [ null, %130 ], [ %115, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit ]
+  %.sroa.44.8..sroa.44.32.68216 = phi %struct.ObjHeader** [ %145, %147 ], [ null, %130 ], [ %.sroa.44.8..sroa.44.32.68, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit ]
+  %148 = load atomic %struct.ObjHeader**, %struct.ObjHeader*** %66 unordered, align 8
+  %149 = load atomic i64, i64* %68 unordered, align 8
+  br label %150
+
+150:                                              ; preds = %158, %_ZN6kotlin2mm11ShadowStack8IteratorppEv.exit.i
+  %.sroa.2231.0..sroa.2231.16.38 = phi i64 [ %.sroa.2231.0..sroa.2231.16.38227, %_ZN6kotlin2mm11ShadowStack8IteratorppEv.exit.i ], [ %.sroa.2231.0..sroa.2231.16.38233, %158 ]
+  %.sroa.2231.0..sroa.2231.16.37 = phi i64 [ %.sroa.2231.0..sroa.2231.16.37219, %_ZN6kotlin2mm11ShadowStack8IteratorppEv.exit.i ], [ %.sroa.2231.0..sroa.2231.16.37226, %158 ]
+  %.sroa.9.3 = phi i32 [ 0, %_ZN6kotlin2mm11ShadowStack8IteratorppEv.exit.i ], [ %.sroa.9.4, %158 ]
+  br label %151
+
+151:                                              ; preds = %151, %150
+  switch i32 %.sroa.9.3, label %151 [
+    i32 2, label %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread4
     i32 0, label %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i
-    i32 1, label %145
+    i32 1, label %155
   ]
 
-_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i: ; preds = %142
-  %143 = icmp eq i64 %.sroa.2226.5, 0
-  %144 = icmp eq %struct.ObjHeader** %.sroa.42.0..sroa.42.24.42, null
-  %or.cond253 = and i1 %143, %144
-  br i1 %or.cond253, label %148, label %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit
+_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i: ; preds = %151
+  %152 = icmp eq i64 %.sroa.2231.0..sroa.2231.16.38, 0
+  %153 = icmp eq %struct.ObjHeader** %.sroa.44.0..sroa.44.24.49, null
+  %or.cond295 = and i1 %152, %153
+  br i1 %or.cond295, label %154, label %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit
 
-145:                                              ; preds = %142
-  %146 = inttoptr i64 %.sroa.2226.5 to %struct.ObjHeader**
-  %147 = icmp eq %struct.ObjHeader** %139, %146
-  br i1 %147, label %148, label %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit
+154:                                              ; preds = %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i
+  store i64 %149, i64* %.sroa.2231, align 8, !tbaa.struct !265
+  br label %158
 
-148:                                              ; preds = %145, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i
-  %.sroa.2226.6 = phi i64 [ %.sroa.2226.5, %145 ], [ %140, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i ]
-  %.sroa.9.4 = phi i32 [ 2, %145 ], [ 1, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i ]
-  br label %141
+155:                                              ; preds = %151
+  %156 = inttoptr i64 %.sroa.2231.0..sroa.2231.16.37 to %struct.ObjHeader**
+  %157 = icmp eq %struct.ObjHeader** %148, %156
+  br i1 %157, label %158, label %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit
 
-149:                                              ; preds = %115, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit.thread
-  %.sroa.6.2 = phi <2 x i64> [ %.sroa.6.32.vec.insert, %115 ], [ %.sroa.6.1, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit.thread ]
-  %150 = inttoptr i64 %.sroa.2226.3 to %struct.ObjHeader**
-  %151 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %150, i64 1
-  %152 = ptrtoint %struct.ObjHeader** %151 to i64
-  %153 = load %struct.ObjHeader**, %struct.ObjHeader*** %61, align 8
-  %154 = load i64, i64* %63, align 8
-  %155 = inttoptr i64 %154 to %struct.ObjHeader**
-  br label %156
+158:                                              ; preds = %155, %154
+  %.sroa.2231.0..sroa.2231.16.38233 = phi i64 [ %149, %154 ], [ %.sroa.2231.0..sroa.2231.16.38, %155 ]
+  %.sroa.2231.0..sroa.2231.16.37226 = phi i64 [ %149, %154 ], [ %.sroa.2231.0..sroa.2231.16.37, %155 ]
+  %.sroa.9.4 = phi i32 [ 1, %154 ], [ 2, %155 ]
+  br label %150
 
-156:                                              ; preds = %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i, %149
-  %.sroa.2226.7 = phi i64 [ %152, %149 ], [ %154, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i ]
-  %157 = phi %struct.ObjHeader** [ %151, %149 ], [ %155, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i ]
-  %158 = icmp eq %struct.ObjHeader** %157, %153
-  br label %159
+159:                                              ; preds = %122, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit.thread
+  %.sroa.695.2 = phi <2 x i64> [ %.sroa.695.32.vec.insert, %122 ], [ %.sroa.695.1, %_ZN6kotlin2mm13ThreadRootSet8IteratordeEv.exit.thread ]
+  %160 = inttoptr i64 %.sroa.2231.0..sroa.2231.16.37220 to %struct.ObjHeader**
+  %161 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %160, i64 1
+  %162 = ptrtoint %struct.ObjHeader** %161 to i64
+  store i64 %162, i64* %.sroa.2231, align 8, !tbaa !326
+  %163 = load atomic %struct.ObjHeader**, %struct.ObjHeader*** %66 unordered, align 8
+  %164 = load atomic i64, i64* %68 unordered, align 8
+  %165 = inttoptr i64 %164 to %struct.ObjHeader**
+  br label %166
 
-159:                                              ; preds = %163, %156
-  %.sroa.9.6 = phi i32 [ 1, %156 ], [ 2, %163 ]
-  br label %160
+166:                                              ; preds = %173, %159
+  %.sroa.2231.0..sroa.2231.16.35 = phi i64 [ %162, %159 ], [ %164, %173 ]
+  %167 = phi %struct.ObjHeader** [ %161, %159 ], [ %165, %173 ]
+  %168 = icmp eq %struct.ObjHeader** %167, %163
+  br label %169
 
-160:                                              ; preds = %160, %159
-  switch i32 %.sroa.9.6, label %160 [
-    i32 2, label %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread
+169:                                              ; preds = %174, %166
+  %.sroa.9.6 = phi i32 [ 1, %166 ], [ 2, %174 ]
+  br label %170
+
+170:                                              ; preds = %170, %169
+  switch i32 %.sroa.9.6, label %170 [
+    i32 2, label %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3.thread4
     i32 0, label %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i
-    i32 1, label %163
+    i32 1, label %174
   ]
 
-_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i: ; preds = %160
-  %161 = icmp eq i64 %.sroa.2226.7, 0
-  %162 = icmp eq %struct.ObjHeader** %.sroa.42.0..sroa.42.24.54, null
-  %or.cond254 = and i1 %161, %162
-  br i1 %or.cond254, label %156, label %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit
+_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i: ; preds = %170
+  %171 = icmp eq i64 %.sroa.2231.0..sroa.2231.16.35, 0
+  %172 = icmp eq %struct.ObjHeader** %.sroa.44.0..sroa.44.24.63, null
+  %or.cond296 = and i1 %171, %172
+  br i1 %or.cond296, label %173, label %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit
 
-163:                                              ; preds = %160
-  br i1 %158, label %159, label %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit
+173:                                              ; preds = %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i
+  store i64 %164, i64* %.sroa.2231, align 8, !tbaa.struct !265
+  br label %166
 
-_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit:   ; preds = %163, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i, %145, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i
-  %.sroa.6.2262 = phi <2 x i64> [ %.sroa.6.2.ph, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i ], [ %.sroa.6.2, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i ], [ %.sroa.6.2, %163 ], [ %.sroa.6.2.ph, %145 ]
-  %.sroa.42.8..sroa.42.32.59210 = phi %struct.ObjHeader** [ %.sroa.42.8..sroa.42.32.59211, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i ], [ %.sroa.42.8..sroa.42.32.59, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i ], [ %.sroa.42.8..sroa.42.32.59, %163 ], [ %.sroa.42.8..sroa.42.32.59211, %145 ]
-  %.sroa.42.0..sroa.42.24.40206 = phi %struct.ObjHeader** [ %.sroa.42.0..sroa.42.24.42, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i ], [ %.sroa.42.0..sroa.42.24.54, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i ], [ %.sroa.42.0..sroa.42.24.54, %163 ], [ %.sroa.42.0..sroa.42.24.42, %145 ]
-  %.sroa.2226.8 = phi i64 [ %.sroa.2226.5, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i ], [ %.sroa.2226.7, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i ], [ %.sroa.2226.7, %163 ], [ %.sroa.2226.5, %145 ]
-  %.sroa.9.7 = phi i32 [ %.sroa.9.3, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i ], [ %.sroa.9.6, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i ], [ 1, %163 ], [ %.sroa.9.3, %145 ]
-  br label %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit3
+174:                                              ; preds = %170
+  br i1 %168, label %169, label %_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit
+
+_ZN6kotlin2mm13ThreadRootSet8IteratorppEv.exit:   ; preds = %174, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i, %155, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i
+  %.sroa.695.2305 = phi <2 x i64> [ %.sroa.695.2.ph, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i ], [ %.sroa.695.2, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i ], [ %.sroa.695.2, %174 ], [ %.sroa.695.2.ph, %155 ]
+  %.sroa.2231.0..sroa.2231.16.38231 = phi i64 [ %.sroa.2231.0..sroa.2231.16.38, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i ], [ %.sroa.2231.0..sroa.2231.16.35, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i ], [ %.sroa.2231.0..sroa.2231.16.35, %174 ], [ %.sroa.2231.0..sroa.2231.16.38, %155 ]
+  %.sroa.2231.0..sroa.2231.16.37223 = phi i64 [ %.sroa.2231.0..sroa.2231.16.38, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i ], [ %.sroa.2231.0..sroa.2231.16.35, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i ], [ %.sroa.2231.0..sroa.2231.16.35, %174 ], [ %.sroa.2231.0..sroa.2231.16.37, %155 ]
+  %.sroa.44.8..sroa.44.32.68215 = phi %struct.ObjHeader** [ %.sroa.44.8..sroa.44.32.68216, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i ], [ %.sroa.44.8..sroa.44.32.68, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i ], [ %.sroa.44.8..sroa.44.32.68, %174 ], [ %.sroa.44.8..sroa.44.32.68216, %155 ]
+  %.sroa.44.0..sroa.44.24.47205 = phi %struct.ObjHeader** [ %.sroa.44.0..sroa.44.24.49, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i ], [ %.sroa.44.0..sroa.44.24.63, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i ], [ %.sroa.44.0..sroa.44.24.63, %174 ], [ %.sroa.44.0..sroa.44.24.49, %155 ]
+  %.sroa.9.7 = phi i32 [ %.sroa.9.3, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit1.i ], [ %.sroa.9.6, %_ZN6kotlin2mm11ShadowStack8Iterator4InitEv.exit.i ], [ 1, %174 ], [ %.sroa.9.3, %155 ]
+  br label %_ZNK6kotlin2mm13ThreadRootSet8IteratoreqERKS2_.exit
 }
 
 ; Function Attrs: nounwind uwtable
@@ -25900,7 +26449,7 @@
   %29 = load atomic volatile i64, i64* %28 monotonic, align 8
   %30 = inttoptr i64 %29 to %struct.TypeInfo*
   %31 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %30, i64 0, i32 16
-  %32 = load void (i8*, %struct.ObjHeader*)*, void (i8*, %struct.ObjHeader*)** %31, align 8, !tbaa !324
+  %32 = load atomic void (i8*, %struct.ObjHeader*)*, void (i8*, %struct.ObjHeader*)** %31 unordered, align 8, !tbaa !328
   %33 = getelementptr inbounds %"union.std::aligned_storage<8, 8>::type", %"union.std::aligned_storage<8, 8>::type"* %0, i64 0, i32 0, i64 0
   invoke void %32(i8* nonnull %33, %struct.ObjHeader* nonnull %1)
           to label %_ZN6kotlin2gc8internal10MarkTraits10tryEnqueueERNS_22intrusive_forward_listINS0_22ConcurrentMarkAndSweep10ObjectDataENS_33DefaultIntrusiveForwardListTraitsIS5_EEEEP9ObjHeader.exit unwind label %22
@@ -25913,7 +26462,7 @@
 ; Function Attrs: nounwind uwtable
 define internal fastcc void @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer7PublishEv(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nocapture %0) unnamed_addr #17 align 2 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
   %2 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
-  %3 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %2, align 8, !tbaa !3
+  %3 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %2 unordered, align 8, !tbaa !3
   %4 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %3, null
   %5 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 2
   %6 = getelementptr inbounds %"class.std::unique_ptr.112", %"class.std::unique_ptr.112"* %5, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
@@ -25921,7 +26470,7 @@
 
 7:                                                ; preds = %1
   %8 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 0
-  %9 = load %"class.kotlin::mm::internal::ObjectFactoryStorage"*, %"class.kotlin::mm::internal::ObjectFactoryStorage"** %8, align 8, !tbaa !325
+  %9 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage"*, %"class.kotlin::mm::internal::ObjectFactoryStorage"** %8 unordered, align 8, !tbaa !329
   %10 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage", %"class.kotlin::mm::internal::ObjectFactoryStorage"* %9, i64 0, i32 4, i32 0, i32 0, i32 0
   %11 = atomicrmw xchg i8* %10, i8 1 acquire, align 1
   %12 = icmp eq i8 %11, 0
@@ -25934,18 +26483,18 @@
   br i1 %14, label %.loopexit, label %.preheader
 
 .loopexit:                                        ; preds = %.preheader, %7
-  %15 = load %"class.kotlin::mm::internal::ObjectFactoryStorage"*, %"class.kotlin::mm::internal::ObjectFactoryStorage"** %8, align 8, !tbaa !325
+  %15 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage"*, %"class.kotlin::mm::internal::ObjectFactoryStorage"** %8 unordered, align 8, !tbaa !329
   %16 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage", %"class.kotlin::mm::internal::ObjectFactoryStorage"* %15, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %17 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %16, align 8, !tbaa !3
+  %17 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %16 unordered, align 8, !tbaa !3
   %18 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %17, null
   br i1 %18, label %19, label %28
 
 19:                                               ; preds = %.loopexit
   %20 = bitcast %"class.std::unique_ptr.112"* %5 to i64*
-  %21 = load i64, i64* %20, align 8, !tbaa !3
+  %21 = load atomic i64, i64* %20 unordered, align 8, !tbaa !3
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %6, align 8, !tbaa !3
   %22 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage"* %15 to i64*
-  %23 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %16, align 8, !tbaa !3
+  %23 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %16 unordered, align 8, !tbaa !3
   store i64 %21, i64* %22, align 8, !tbaa !3
   %24 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %23, null
   br i1 %24, label %40, label %25
@@ -25959,13 +26508,13 @@
 
 28:                                               ; preds = %.loopexit
   %29 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage", %"class.kotlin::mm::internal::ObjectFactoryStorage"* %15, i64 0, i32 1
-  %30 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %29, align 8, !tbaa !329
+  %30 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %29 unordered, align 8, !tbaa !333
   %31 = bitcast %"class.std::unique_ptr.112"* %5 to i64*
-  %32 = load i64, i64* %31, align 8, !tbaa !3
+  %32 = load atomic i64, i64* %31 unordered, align 8, !tbaa !3
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %6, align 8, !tbaa !3
   %33 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %30 to i64*
   %34 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %30, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %35 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %34, align 8, !tbaa !3
+  %35 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %34 unordered, align 8, !tbaa !3
   store i64 %32, i64* %33, align 8, !tbaa !3
   %36 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %35, null
   br i1 %36, label %40, label %37
@@ -25980,20 +26529,20 @@
 40:                                               ; preds = %37, %28, %25, %19
   %41 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 3
   %42 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %41 to i64*
-  %43 = load i64, i64* %42, align 8, !tbaa !333
-  %44 = load %"class.kotlin::mm::internal::ObjectFactoryStorage"*, %"class.kotlin::mm::internal::ObjectFactoryStorage"** %8, align 8, !tbaa !325
+  %43 = load atomic i64, i64* %42 unordered, align 8, !tbaa !337
+  %44 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage"*, %"class.kotlin::mm::internal::ObjectFactoryStorage"** %8 unordered, align 8, !tbaa !329
   %45 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage", %"class.kotlin::mm::internal::ObjectFactoryStorage"* %44, i64 0, i32 1
   %46 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %45 to i64*
-  store i64 %43, i64* %46, align 8, !tbaa !329
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %41, align 8, !tbaa !333
+  store i64 %43, i64* %46, align 8, !tbaa !333
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %41, align 8, !tbaa !337
   %47 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 4
   %48 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage", %"class.kotlin::mm::internal::ObjectFactoryStorage"* %44, i64 0, i32 2
   %49 = bitcast i64* %47 to <2 x i64>*
-  %50 = load <2 x i64>, <2 x i64>* %49, align 8, !tbaa !89
+  %50 = load <2 x i64>, <2 x i64>* %49, align 8, !tbaa !87
   %51 = bitcast i64* %48 to <2 x i64>*
-  %52 = load <2 x i64>, <2 x i64>* %51, align 8, !tbaa !89
+  %52 = load <2 x i64>, <2 x i64>* %51, align 8, !tbaa !87
   %53 = add <2 x i64> %52, %50
-  store <2 x i64> %53, <2 x i64>* %51, align 8, !tbaa !89
+  store <2 x i64> %53, <2 x i64>* %51, align 8, !tbaa !87
   %54 = bitcast i64* %47 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %54, i8 0, i64 16, i1 false)
   store atomic i8 0, i8* %10 release, align 1
@@ -26006,7 +26555,7 @@
 ; Function Attrs: nounwind uwtable
 define internal fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nocapture %0) unnamed_addr #17 align 2 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
   %2 = getelementptr inbounds %"class.std::unique_ptr.112", %"class.std::unique_ptr.112"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %3 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %2, align 8, !tbaa !3
+  %3 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %2 unordered, align 8, !tbaa !3
   %4 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %3, null
   br i1 %4, label %8, label %5
 
@@ -26056,14 +26605,14 @@
   %24 = load atomic volatile i64, i64* %23 monotonic, align 8
   %25 = inttoptr i64 %24 to %struct.TypeInfo*
   %26 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %25, i64 0, i32 3
-  %27 = load i32, i32* %26, align 4, !tbaa !334
+  %27 = load atomic i32, i32* %26 unordered, align 4, !tbaa !338
   %28 = icmp slt i32 %27, 0
   br i1 %28, label %29, label %38
 
 29:                                               ; preds = %15
   %30 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %17, i64 3
   %31 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %30 to i32*
-  %32 = load i32, i32* %31, align 8, !tbaa !18
+  %32 = load atomic i32, i32* %31 unordered, align 8, !tbaa !18
   %33 = sub nsw i32 0, %27
   %34 = sext i32 %33 to i64
   %35 = zext i32 %32 to i64
@@ -26100,7 +26649,7 @@
   %54 = load atomic volatile i64, i64* %53 monotonic, align 8
   %55 = inttoptr i64 %54 to %struct.TypeInfo*
   %56 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %55, i64 0, i32 16
-  %57 = load void (i8*, %struct.ObjHeader*)*, void (i8*, %struct.ObjHeader*)** %56, align 8, !tbaa !324
+  %57 = load atomic void (i8*, %struct.ObjHeader*)*, void (i8*, %struct.ObjHeader*)** %56 unordered, align 8, !tbaa !328
   invoke void %57(i8* nonnull %9, %struct.ObjHeader* nonnull %19)
           to label %58 unwind label %41
 
@@ -26109,7 +26658,7 @@
   %60 = and i64 %59, -4
   %61 = inttoptr i64 %60 to %struct.TypeInfo*
   %62 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %61, i64 0, i32 0
-  %63 = load %struct.TypeInfo*, %struct.TypeInfo** %62, align 8, !tbaa !335
+  %63 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %62 unordered, align 8, !tbaa !339
   %64 = icmp eq %struct.TypeInfo* %63, %61
   %65 = icmp eq i64 %60, 0
   %66 = or i1 %65, %64
@@ -26148,14 +26697,14 @@
   %93 = load atomic volatile i64, i64* %92 monotonic, align 8
   %94 = inttoptr i64 %93 to %struct.TypeInfo*
   %95 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %94, i64 0, i32 3
-  %96 = load i32, i32* %95, align 4, !tbaa !334
+  %96 = load atomic i32, i32* %95 unordered, align 4, !tbaa !338
   %97 = icmp slt i32 %96, 0
   br i1 %97, label %98, label %107
 
 98:                                               ; preds = %88
   %99 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %76, i64 1
   %100 = bitcast %struct.ObjHeader* %99 to i32*
-  %101 = load i32, i32* %100, align 8, !tbaa !18
+  %101 = load atomic i32, i32* %100 unordered, align 8, !tbaa !18
   %102 = sub nsw i32 0, %96
   %103 = sext i32 %102 to i64
   %104 = zext i32 %101 to i64
@@ -26183,7 +26732,7 @@
   %119 = load atomic volatile i64, i64* %118 monotonic, align 8
   %120 = inttoptr i64 %119 to %struct.TypeInfo*
   %121 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %120, i64 0, i32 16
-  %122 = load void (i8*, %struct.ObjHeader*)*, void (i8*, %struct.ObjHeader*)** %121, align 8, !tbaa !324
+  %122 = load atomic void (i8*, %struct.ObjHeader*)*, void (i8*, %struct.ObjHeader*)** %121 unordered, align 8, !tbaa !328
   invoke void %122(i8* nonnull %9, %struct.ObjHeader* nonnull %76)
           to label %_ZN6kotlin2gc8internal22processExtraObjectDataINS1_10MarkTraitsEEEvRNS0_8GCHandle11GCMarkScopeERNT_9MarkQueueERNS_2mm15ExtraObjectDataEP9ObjHeader.exit unwind label %123
 
@@ -26214,17 +26763,17 @@
   br i1 %132, label %.loopexit, label %.preheader
 
 .loopexit:                                        ; preds = %.preheader, %.loopexit16
-  %133 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+  %133 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %134 = icmp ne i8 %133, 0
-  %135 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*), align 8
+  %135 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*) unordered, align 8
   %136 = icmp eq i64 %135, %0
   %137 = and i1 %134, %136
   br i1 %137, label %144, label %138
 
 138:                                              ; preds = %.loopexit
-  %139 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+  %139 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %140 = icmp ne i8 %139, 0
-  %141 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*), align 8
+  %141 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*) unordered, align 8
   %142 = icmp eq i64 %141, %0
   %143 = and i1 %140, %142
   br i1 %143, label %144, label %_ZN6kotlin2gc8GCHandle11GCMarkScopeD2Ev.exit
@@ -26232,20 +26781,20 @@
 144:                                              ; preds = %138, %.loopexit
   %145 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %138 ]
   %146 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %145, i64 0, i32 7, i32 0, i32 0, i32 1
-  %147 = load i8, i8* %146, align 8, !tbaa !336, !range !72
+  %147 = load atomic i8, i8* %146 unordered, align 8, !tbaa !340, !range !70
   %148 = icmp eq i8 %147, 0
   %149 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %145, i64 0, i32 7, i32 0, i32 0, i32 0, i32 0, i32 0
   br i1 %148, label %153, label %150
 
 150:                                              ; preds = %144
   %151 = bitcast i64* %149 to <2 x i64>*
-  %152 = load <2 x i64>, <2 x i64>* %151, align 8, !tbaa !89
+  %152 = load <2 x i64>, <2 x i64>* %151, align 8, !tbaa !87
   br label %155
 
 153:                                              ; preds = %144
   %154 = bitcast i64* %149 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %154, i8 0, i64 16, i1 false) #37
-  store i8 1, i8* %146, align 8, !tbaa !336
+  store i8 1, i8* %146, align 8, !tbaa !340
   %.pre = bitcast i64* %149 to <2 x i64>*
   br label %155
 
@@ -26253,7 +26802,7 @@
   %.pre-phi = phi <2 x i64>* [ %.pre, %153 ], [ %151, %150 ]
   %156 = phi <2 x i64> [ zeroinitializer, %153 ], [ %152, %150 ]
   %157 = add <2 x i64> %156, %.sroa.5.2
-  store <2 x i64> %157, <2 x i64>* %.pre-phi, align 8, !tbaa !89
+  store <2 x i64> %157, <2 x i64>* %.pre-phi, align 8, !tbaa !87
   br label %_ZN6kotlin2gc8GCHandle11GCMarkScopeD2Ev.exit
 
 _ZN6kotlin2gc8GCHandle11GCMarkScopeD2Ev.exit:     ; preds = %155, %138
@@ -26277,18 +26826,18 @@
 
 7:                                                ; preds = %2, %1
   %8 = getelementptr inbounds %class.GCStateHolder, %class.GCStateHolder* %0, i64 0, i32 3, i32 0
-  %9 = load i64, i64* %8, align 8, !tbaa !89
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !87
   %10 = getelementptr inbounds %class.GCStateHolder, %class.GCStateHolder* %0, i64 0, i32 1, i32 0
-  %11 = load i64, i64* %10, align 8, !tbaa !89
+  %11 = load atomic i64, i64* %10 unordered, align 8, !tbaa !87
   %12 = icmp sgt i64 %9, %11
   br i1 %12, label %17, label %13
 
 13:                                               ; preds = %7
   %14 = add nsw i64 %11, 1
-  store i64 %14, i64* %8, align 8, !tbaa !144
+  store i64 %14, i64* %8, align 8, !tbaa !142
   %15 = getelementptr inbounds %class.GCStateHolder, %class.GCStateHolder* %0, i64 0, i32 3, i32 2
   tail call void @_ZNSt18condition_variable10notify_allEv(%"class.std::condition_variable"* nonnull %15) #37
-  %16 = load i64, i64* %8, align 8, !tbaa !89
+  %16 = load atomic i64, i64* %8 unordered, align 8, !tbaa !87
   br label %17
 
 17:                                               ; preds = %13, %7
@@ -26305,31 +26854,35 @@
 }
 
 ; Function Attrs: nounwind uwtable
-define internal fastcc void @_ZN6kotlin16ThreadStateGuardD2Ev(%"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %.0.0.val, i32 %.0.1.val) unnamed_addr #17 align 2 personality i32 (...)* @__gxx_personality_v0 {
-  %1 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %.0.0.val, null
-  br i1 %1, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %2
+define internal fastcc void @_ZN6kotlin16ThreadStateGuardD2Ev(%"class.kotlin::CalledFromNativeGuard"* nocapture readonly %0) unnamed_addr #17 align 2 personality i32 (...)* @__gxx_personality_v0 {
+  %2 = getelementptr inbounds %"class.kotlin::CalledFromNativeGuard", %"class.kotlin::CalledFromNativeGuard"* %0, i64 0, i32 0
+  %3 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %2 unordered, align 8, !tbaa !34
+  %4 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %3, null
+  br i1 %4, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %5
 
-2:                                                ; preds = %0
-  %3 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %.0.0.val, i64 328
-  %4 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %3 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %5 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %3 to i32*
-  %6 = atomicrmw xchg i32* %5, i32 %.0.1.val seq_cst, align 4
-  %7 = icmp eq i32 %6, 1
-  %8 = icmp eq i32 %.0.1.val, 0
-  %9 = and i1 %8, %7
-  br i1 %9, label %10, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
+5:                                                ; preds = %1
+  %6 = getelementptr inbounds %"class.kotlin::CalledFromNativeGuard", %"class.kotlin::CalledFromNativeGuard"* %0, i64 0, i32 1
+  %7 = load atomic i32, i32* %6 unordered, align 8, !tbaa !38
+  %8 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %3, i64 328
+  %9 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %8 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %10 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %8 to i32*
+  %11 = atomicrmw xchg i32* %10, i32 %7 seq_cst, align 4
+  %12 = icmp eq i32 %11, 1
+  %13 = icmp eq i32 %7, 0
+  %14 = and i1 %13, %12
+  br i1 %14, label %15, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-10:                                               ; preds = %2
-  %11 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %12 = and i8 %11, 1
-  %13 = icmp eq i8 %12, 0
-  br i1 %13, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %14
+15:                                               ; preds = %5
+  %16 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %17 = and i8 %16, 1
+  %18 = icmp eq i8 %17, 0
+  br i1 %18, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %19
 
-14:                                               ; preds = %10
-  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %4) #37
+19:                                               ; preds = %15
+  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %9) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %14, %10, %2, %0
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %19, %15, %5, %1
   ret void
 }
 
@@ -26354,7 +26907,7 @@
 8:                                                ; preds = %3
   %9 = getelementptr inbounds %"union.std::_Any_data", %"union.std::_Any_data"* %1, i64 0, i32 0, i32 0, i32 0
   %10 = getelementptr inbounds %"union.std::_Any_data", %"union.std::_Any_data"* %0, i64 0, i32 0, i32 0, i32 0
-  %11 = load i64, i64* %9, align 8, !tbaa !3
+  %11 = load atomic i64, i64* %9 unordered, align 8, !tbaa !3
   store i64 %11, i64* %10, align 8, !tbaa !3
   br label %12
 
@@ -26364,9 +26917,9 @@
 
 ; Function Attrs: uwtable
 define internal void @"_ZNSt17_Function_handlerIFvlEZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS1_2mm13ObjectFactoryIS3_EERNS2_11GCSchedulerEE3$_1E9_M_invokeERKSt9_Any_dataOl"(%"union.std::_Any_data"* nocapture nonnull readonly align 8 dereferenceable(16) %0, i64* nocapture nonnull readonly align 8 dereferenceable(8) %1) #20 align 2 personality i32 (...)* @__gxx_personality_v0 {
-  %3 = load i64, i64* %1, align 8, !tbaa !89
+  %3 = load atomic i64, i64* %1 unordered, align 8, !tbaa !87
   %4 = bitcast %"union.std::_Any_data"* %0 to %"class.kotlin::gc::ConcurrentMarkAndSweep"**
-  %5 = load %"class.kotlin::gc::ConcurrentMarkAndSweep"*, %"class.kotlin::gc::ConcurrentMarkAndSweep"** %4, align 8, !tbaa !339
+  %5 = load atomic %"class.kotlin::gc::ConcurrentMarkAndSweep"*, %"class.kotlin::gc::ConcurrentMarkAndSweep"** %4 unordered, align 8, !tbaa !343
   %6 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %5, i64 0, i32 2, i32 4
   tail call fastcc void @_ZN13GCStateHolder16ValueWithCondVarIlE3setEl(%"struct.GCStateHolder::ValueWithCondVar"* nonnull %6, i64 %3)
   %7 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
@@ -26380,17 +26933,17 @@
   br i1 %10, label %.loopexit, label %.preheader
 
 .loopexit:                                        ; preds = %.preheader, %2
-  %11 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+  %11 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %12 = icmp ne i8 %11, 0
-  %13 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*), align 8
+  %13 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*) unordered, align 8
   %14 = icmp eq i64 %13, %3
   %15 = and i1 %12, %14
   br i1 %15, label %22, label %16
 
 16:                                               ; preds = %.loopexit
-  %17 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+  %17 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %18 = icmp ne i8 %17, 0
-  %19 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*), align 8
+  %19 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*) unordered, align 8
   %20 = icmp eq i64 %19, %3
   %21 = and i1 %18, %20
   br i1 %21, label %22, label %_ZN6kotlin2gc8GCHandle14finalizersDoneEv.exit
@@ -26411,9 +26964,8 @@
 
 ; Function Attrs: uwtable
 define internal void @"_ZNSt17_Function_handlerIFvvEZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS1_2mm13ObjectFactoryIS3_EERNS2_11GCSchedulerEE3$_2E9_M_invokeERKSt9_Any_data"(%"union.std::_Any_data"* nocapture nonnull readonly align 8 dereferenceable(16) %0) #20 align 2 {
-  %.idx = bitcast %"union.std::_Any_data"* %0 to %"class.kotlin::gc::ConcurrentMarkAndSweep"**
-  %.idx.val = load %"class.kotlin::gc::ConcurrentMarkAndSweep"*, %"class.kotlin::gc::ConcurrentMarkAndSweep"** %.idx, align 8, !tbaa !341
-  tail call fastcc void @"_ZZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS1_EERNS0_11GCSchedulerEENK3$_2clEv"(%"class.kotlin::gc::ConcurrentMarkAndSweep"* %.idx.val)
+  %2 = bitcast %"union.std::_Any_data"* %0 to %class.anon.78*
+  tail call fastcc void @"_ZZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS1_EERNS0_11GCSchedulerEENK3$_2clEv"(%class.anon.78* nonnull %2)
   ret void
 }
 
@@ -26438,7 +26990,7 @@
 8:                                                ; preds = %3
   %9 = getelementptr inbounds %"union.std::_Any_data", %"union.std::_Any_data"* %1, i64 0, i32 0, i32 0, i32 0
   %10 = getelementptr inbounds %"union.std::_Any_data", %"union.std::_Any_data"* %0, i64 0, i32 0, i32 0, i32 0
-  %11 = load i64, i64* %9, align 8, !tbaa !3
+  %11 = load atomic i64, i64* %9 unordered, align 8, !tbaa !3
   store i64 %11, i64* %10, align 8, !tbaa !3
   br label %12
 
@@ -26462,29 +27014,29 @@
   %14 = alloca %"class.std::unique_ptr.112", align 8
   %15 = alloca %"class.kotlin::mm::ObjectFactory<kotlin::gc::ConcurrentMarkAndSweep>::FinalizerQueue", align 8
   %16 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
-  %17 = load i8, i8* %16, align 8, !tbaa !106, !range !72
+  %17 = load atomic i8, i8* %16 unordered, align 8, !tbaa !104, !range !70
   %18 = icmp eq i8 %17, 0
   br i1 %18, label %_ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit, label %19
 
 19:                                               ; preds = %2
   %20 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %21 = load i8*, i8** %20, align 8, !tbaa !58
+  %21 = load atomic i8*, i8** %20 unordered, align 8, !tbaa !47
   %22 = tail call i64 @pthread_self() #1
   %23 = tail call i32 @pthread_setname_np(i64 %22, i8* %21) #37
   br label %_ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit
 
 _ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit: ; preds = %19, %2
   %24 = getelementptr inbounds %class.anon.78, %class.anon.78* %1, i64 0, i32 0
-  %25 = load %"class.kotlin::gc::ConcurrentMarkAndSweep"*, %"class.kotlin::gc::ConcurrentMarkAndSweep"** %24, align 8, !tbaa !343
+  %25 = load atomic %"class.kotlin::gc::ConcurrentMarkAndSweep"*, %"class.kotlin::gc::ConcurrentMarkAndSweep"** %24 unordered, align 8, !tbaa !345
   %26 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %25, i64 0, i32 2
   %27 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %25, i64 0, i32 2, i32 3
   %28 = tail call fastcc nonnull align 8 dereferenceable(8) i64* @_ZN13GCStateHolder16ValueWithCondVarIlE4waitIZNS_13waitScheduledEvEUlvE_EERKlT_(%"struct.GCStateHolder::ValueWithCondVar"* nonnull %27, %class.GCStateHolder* nonnull %26)
   %29 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %25, i64 0, i32 2, i32 5
-  %30 = load i8, i8* %29, align 8, !tbaa !146, !range !72
+  %30 = load atomic i8, i8* %29 unordered, align 8, !tbaa !144, !range !70
   %31 = icmp eq i8 %30, 1
-  br i1 %31, label %.loopexit108, label %.preheader106
+  br i1 %31, label %.loopexit102, label %.preheader100
 
-.preheader106:                                    ; preds = %_ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit
+.preheader100:                                    ; preds = %_ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit
   %32 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %25, i64 0, i32 6
   %33 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %25, i64 0, i32 1
   %34 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %25, i64 0, i32 2, i32 1
@@ -26556,37 +27108,37 @@
   %100 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer"* %43, i64 0, i32 0
   br label %101
 
-101:                                              ; preds = %.loopexit72, %.preheader106
-  %102 = phi i64* [ %910, %.loopexit72 ], [ %28, %.preheader106 ]
-  %103 = load i64, i64* %102, align 8, !tbaa !89
+101:                                              ; preds = %.loopexit66, %.preheader100
+  %102 = phi i64* [ %923, %.loopexit66 ], [ %28, %.preheader100 ]
+  %103 = load atomic i64, i64* %102 unordered, align 8, !tbaa !87
   %104 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %105 = icmp eq i8 %104, 0
-  br i1 %105, label %.loopexit105, label %.preheader104
+  br i1 %105, label %.loopexit99, label %.preheader98
 
-.preheader104:                                    ; preds = %.preheader104, %101
+.preheader98:                                     ; preds = %.preheader98, %101
   call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37
   %106 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %107 = icmp eq i8 %106, 0
-  br i1 %107, label %.loopexit105, label %.preheader104
+  br i1 %107, label %.loopexit99, label %.preheader98
 
-.loopexit105:                                     ; preds = %.preheader104, %101
-  %108 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+.loopexit99:                                      ; preds = %.preheader98, %101
+  %108 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %109 = icmp eq i8 %108, 0
   br i1 %109, label %_ZN6kotlin2gc8GCHandle6createEm.exit.i, label %110
 
-110:                                              ; preds = %.loopexit105
+110:                                              ; preds = %.loopexit99
   call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(256) getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0), i8* nonnull align 8 dereferenceable(256) getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0), i64 256, i1 false) #37
   call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(256) getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0), i8 0, i64 256, i1 false) #37
   br label %_ZN6kotlin2gc8GCHandle6createEm.exit.i
 
-_ZN6kotlin2gc8GCHandle6createEm.exit.i:           ; preds = %110, %.loopexit105
-  store i64 %103, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*), align 8, !tbaa !89
-  store i8 1, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311
+_ZN6kotlin2gc8GCHandle6createEm.exit.i:           ; preds = %110, %.loopexit99
+  store i64 %103, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*), align 8, !tbaa !87
+  store i8 1, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !309
   %111 = call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37
   store i64 %111, i64* bitcast ({ { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 1) to i64*), align 8
   store i8 1, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 1, i32 0, i32 1), align 8
   store atomic i8 0, i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0) release, align 1
-  %112 = load i32, i32* %32, align 8, !tbaa !200
+  %112 = load atomic i32, i32* %32 unordered, align 8, !tbaa !199
   %113 = icmp eq i32 %112, 0
   %114 = zext i1 %113 to i8
   store atomic i8 %114, i8* @_ZN12_GLOBAL__N_116markingRequestedE.0.0 seq_cst, align 1
@@ -26594,32 +27146,32 @@
   %115 = tail call zeroext i1 @_ZN6kotlin2mm24RequestThreadsSuspensionEv() #37
   %116 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %117 = icmp eq i8 %116, 0
-  br i1 %117, label %.loopexit103, label %.preheader102
+  br i1 %117, label %.loopexit97, label %.preheader96
 
-.preheader102:                                    ; preds = %.preheader102, %_ZN6kotlin2gc8GCHandle6createEm.exit.i
+.preheader96:                                     ; preds = %.preheader96, %_ZN6kotlin2gc8GCHandle6createEm.exit.i
   call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37
   %118 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %119 = icmp eq i8 %118, 0
-  br i1 %119, label %.loopexit103, label %.preheader102
+  br i1 %119, label %.loopexit97, label %.preheader96
 
-.loopexit103:                                     ; preds = %.preheader102, %_ZN6kotlin2gc8GCHandle6createEm.exit.i
-  %120 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+.loopexit97:                                      ; preds = %.preheader96, %_ZN6kotlin2gc8GCHandle6createEm.exit.i
+  %120 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %121 = icmp ne i8 %120, 0
-  %122 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*), align 8
+  %122 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*) unordered, align 8
   %123 = icmp eq i64 %122, %103
   %124 = and i1 %121, %123
   br i1 %124, label %131, label %125
 
-125:                                              ; preds = %.loopexit103
-  %126 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+125:                                              ; preds = %.loopexit97
+  %126 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %127 = icmp ne i8 %126, 0
-  %128 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*), align 8
+  %128 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*) unordered, align 8
   %129 = icmp eq i64 %128, %103
   %130 = and i1 %127, %129
   br i1 %130, label %131, label %_ZN6kotlin2gc8GCHandle19suspensionRequestedEv.exit.i
 
-131:                                              ; preds = %125, %.loopexit103
-  %132 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit103 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %125 ]
+131:                                              ; preds = %125, %.loopexit97
+  %132 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit97 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %125 ]
   %133 = call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37
   %134 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %132, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0
   store i64 %133, i64* %134, align 8
@@ -26632,20 +27184,20 @@
   br label %136
 
 136:                                              ; preds = %177, %_ZN6kotlin2gc8GCHandle19suspensionRequestedEv.exit.i
-  %137 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"**), align 8, !tbaa !3
+  %137 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"**) unordered, align 8, !tbaa !3
   %138 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* %137, null
   %139 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* %137, i64 0, i32 1
   %spec.select = select i1 %138, %"class.kotlin::mm::ThreadData.119"* null, %"class.kotlin::mm::ThreadData.119"* %139
   br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %140, label %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i.i
 
 140:                                              ; preds = %136
-  %141 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0)) #37, !noalias !345
+  %141 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0)) #37, !noalias !347
   %142 = icmp eq i32 %141, 0
   br i1 %142, label %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i.i, label %143
 
 143:                                              ; preds = %140
   invoke void @_ZSt20__throw_system_errori(i32 %141) #50
-          to label %144 unwind label %145, !noalias !345
+          to label %144 unwind label %145, !noalias !347
 
 144:                                              ; preds = %143
   unreachable
@@ -26654,21 +27206,21 @@
   %146 = landingpad { i8*, i32 }
           catch i8* null
   %147 = extractvalue { i8*, i32 } %146, 0
-  call fastcc void @__clang_call_terminate(i8* %147) #51, !noalias !345
+  call fastcc void @__clang_call_terminate(i8* %147) #51, !noalias !347
   unreachable
 
 _ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i.i: ; preds = %140, %136
-  %148 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) to %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"**), align 8, !tbaa !3
+  %148 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) to %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"**) unordered, align 8, !tbaa !3
   %149 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* %148, null
-  br i1 %149, label %.thread, label %.preheader70
+  br i1 %149, label %.loopexit63, label %.preheader62
 
-.preheader70:                                     ; preds = %169, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i.i
+.preheader62:                                     ; preds = %169, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i.i
   %150 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* [ %171, %169 ], [ %148, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i.i ]
   %151 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* %150, i64 0, i32 1
   %152 = icmp eq %"class.kotlin::mm::ThreadData.119"* %151, %spec.select
   br i1 %152, label %169, label %153
 
-153:                                              ; preds = %.preheader70
+153:                                              ; preds = %.preheader62
   %154 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* %150, i64 0, i32 1, i32 8, i32 3, i32 0, i32 0
   %155 = load atomic i8, i8* %154 seq_cst, align 8
   %156 = and i8 %155, 1
@@ -26683,28 +27235,28 @@
 
 162:                                              ; preds = %158
   %163 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* %150, i64 0, i32 1, i32 6, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %164 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %163, align 8, !tbaa !3
+  %164 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %163 unordered, align 8, !tbaa !3
   %165 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %164, i64 0, i32 1, i32 3, i32 0, i32 0
   %166 = load atomic i8, i8* %165 seq_cst, align 1
   %167 = and i8 %166, 1
   %168 = icmp eq i8 %167, 0
-  br i1 %168, label %.thread, label %169
+  br i1 %168, label %.loopexit63, label %169
 
-169:                                              ; preds = %162, %158, %153, %.preheader70
+169:                                              ; preds = %162, %158, %153, %.preheader62
   %170 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* %150, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
-  %171 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"** %170, align 8, !tbaa !3
+  %171 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"** %170 unordered, align 8, !tbaa !3
   %172 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node.120"* %171, null
-  br i1 %172, label %.thread, label %.preheader70
+  br i1 %172, label %.loopexit63, label %.preheader62
 
-.thread:                                          ; preds = %169, %162, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i.i
+.loopexit63:                                      ; preds = %169, %162, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i.i
   %173 = phi i1 [ true, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i.i ], [ false, %162 ], [ true, %169 ]
   br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %174, label %176
 
-174:                                              ; preds = %.thread
+174:                                              ; preds = %.loopexit63
   %175 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0)) #37
   br label %176
 
-176:                                              ; preds = %174, %.thread
+176:                                              ; preds = %174, %.loopexit63
   br i1 %173, label %_ZN6kotlin2gc22ConcurrentMarkAndSweep25WaitForThreadsReadyToMarkEv.exit.i, label %177
 
 177:                                              ; preds = %176
@@ -26714,34 +27266,34 @@
 _ZN6kotlin2gc22ConcurrentMarkAndSweep25WaitForThreadsReadyToMarkEv.exit.i: ; preds = %176
   %179 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %180 = icmp eq i8 %179, 0
-  br i1 %180, label %.loopexit101, label %.preheader100
+  br i1 %180, label %.loopexit95, label %.preheader94
 
-.preheader100:                                    ; preds = %.preheader100, %_ZN6kotlin2gc22ConcurrentMarkAndSweep25WaitForThreadsReadyToMarkEv.exit.i
+.preheader94:                                     ; preds = %.preheader94, %_ZN6kotlin2gc22ConcurrentMarkAndSweep25WaitForThreadsReadyToMarkEv.exit.i
   call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37
   %181 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %182 = icmp eq i8 %181, 0
-  br i1 %182, label %.loopexit101, label %.preheader100
+  br i1 %182, label %.loopexit95, label %.preheader94
 
-.loopexit101:                                     ; preds = %.preheader100, %_ZN6kotlin2gc22ConcurrentMarkAndSweep25WaitForThreadsReadyToMarkEv.exit.i
-  %183 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+.loopexit95:                                      ; preds = %.preheader94, %_ZN6kotlin2gc22ConcurrentMarkAndSweep25WaitForThreadsReadyToMarkEv.exit.i
+  %183 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %184 = icmp ne i8 %183, 0
-  %185 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*), align 8
+  %185 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*) unordered, align 8
   %186 = icmp eq i64 %185, %103
   %187 = and i1 %184, %186
   br i1 %187, label %194, label %188
 
-188:                                              ; preds = %.loopexit101
-  %189 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+188:                                              ; preds = %.loopexit95
+  %189 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %190 = icmp ne i8 %189, 0
-  %191 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*), align 8
+  %191 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*) unordered, align 8
   %192 = icmp eq i64 %191, %103
   %193 = and i1 %190, %192
   br i1 %193, label %194, label %_ZN6kotlin2gc8GCHandle19threadsAreSuspendedEv.exit.i
 
-194:                                              ; preds = %188, %.loopexit101
-  %195 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit101 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %188 ]
+194:                                              ; preds = %188, %.loopexit95
+  %195 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit95 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %188 ]
   %196 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %195, i64 0, i32 3, i32 0, i32 0, i32 1
-  %197 = load i8, i8* %196, align 8, !tbaa !352, !range !72
+  %197 = load atomic i8, i8* %196 unordered, align 8, !tbaa !354, !range !70
   %198 = icmp eq i8 %197, 0
   br i1 %198, label %_ZN6kotlin2gc8GCHandle19threadsAreSuspendedEv.exit.i, label %199
 
@@ -26751,16 +27303,16 @@
 
 _ZN6kotlin2gc8GCHandle19threadsAreSuspendedEv.exit.i: ; preds = %199, %194, %188
   store atomic i8 0, i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0) release, align 1
-  %201 = load %"class.kotlin::gc::GCScheduler"*, %"class.kotlin::gc::GCScheduler"** %33, align 8, !tbaa !169
+  %201 = load atomic %"class.kotlin::gc::GCScheduler"*, %"class.kotlin::gc::GCScheduler"** %33 unordered, align 8, !tbaa !167
   %202 = getelementptr inbounds %"class.kotlin::gc::GCScheduler", %"class.kotlin::gc::GCScheduler"* %201, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
-  %203 = load %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %202, align 8, !tbaa !3
+  %203 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %202 unordered, align 8, !tbaa !3
   %204 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %203 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*)***
-  %205 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %204, align 8, !tbaa !109
+  %205 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %204 unordered, align 8, !tbaa !107
   %206 = getelementptr inbounds void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %205, i64 3
-  %207 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %206, align 8
+  %207 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %206 unordered, align 8
   call void %207(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %203) #37
   invoke fastcc void @_ZN13GCStateHolder16ValueWithCondVarIlE3setEl(%"struct.GCStateHolder::ValueWithCondVar"* nonnull %34, i64 %103)
-          to label %208 unwind label %913
+          to label %208 unwind label %926
 
 208:                                              ; preds = %_ZN6kotlin2gc8GCHandle19threadsAreSuspendedEv.exit.i
   call void @_ZN6kotlin2gc22ConcurrentMarkAndSweep29CollectRootSetAndStartMarkingENS0_8GCHandleE(%"class.kotlin::gc::ConcurrentMarkAndSweep"* nonnull %25, i64 %103) #37
@@ -26768,20 +27320,20 @@
   br label %209
 
 209:                                              ; preds = %243, %208
-  %210 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %210 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %211 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %210, null
   %212 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %210, i64 0, i32 1
-  %spec.select214 = select i1 %211, %"class.kotlin::mm::ThreadData.38"* null, %"class.kotlin::mm::ThreadData.38"* %212
+  %spec.select210 = select i1 %211, %"class.kotlin::mm::ThreadData.38"* null, %"class.kotlin::mm::ThreadData.38"* %212
   br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %213, label %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i1.i
 
 213:                                              ; preds = %209
-  %214 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0)) #37, !noalias !355
+  %214 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0)) #37, !noalias !357
   %215 = icmp eq i32 %214, 0
   br i1 %215, label %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i1.i, label %216
 
 216:                                              ; preds = %213
   invoke void @_ZSt20__throw_system_errori(i32 %214) #50
-          to label %217 unwind label %218, !noalias !355
+          to label %217 unwind label %218, !noalias !357
 
 217:                                              ; preds = %216
   unreachable
@@ -26790,21 +27342,21 @@
   %219 = landingpad { i8*, i32 }
           catch i8* null
   %220 = extractvalue { i8*, i32 } %219, 0
-  call fastcc void @__clang_call_terminate(i8* %220) #51, !noalias !355
+  call fastcc void @__clang_call_terminate(i8* %220) #51, !noalias !357
   unreachable
 
 _ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i1.i: ; preds = %213, %209
-  %221 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !3
+  %221 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) unordered, align 8, !tbaa !3
   %222 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %221, null
-  br i1 %222, label %.thread4, label %.preheader69
+  br i1 %222, label %.loopexit61, label %.preheader60
 
-.preheader69:                                     ; preds = %235, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i1.i
+.preheader60:                                     ; preds = %235, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i1.i
   %223 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %237, %235 ], [ %221, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i1.i ]
   %224 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %223, i64 0, i32 1
-  %225 = icmp eq %"class.kotlin::mm::ThreadData.38"* %224, %spec.select214
+  %225 = icmp eq %"class.kotlin::mm::ThreadData.38"* %224, %spec.select210
   br i1 %225, label %235, label %226
 
-226:                                              ; preds = %.preheader69
+226:                                              ; preds = %.preheader60
   %227 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %223, i64 0, i32 1, i32 8, i32 3, i32 0, i32 0
   %228 = load atomic i8, i8* %227 seq_cst, align 8
   %229 = and i8 %228, 1
@@ -26815,23 +27367,23 @@
   %232 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %223, i64 0, i32 1, i32 8, i32 0, i32 0
   %233 = load atomic i32, i32* %232 seq_cst, align 8
   %234 = icmp eq i32 %233, 1
-  br i1 %234, label %235, label %.thread4
+  br i1 %234, label %235, label %.loopexit61
 
-235:                                              ; preds = %231, %226, %.preheader69
+235:                                              ; preds = %231, %226, %.preheader60
   %236 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %223, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
-  %237 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %236, align 8, !tbaa !3
+  %237 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %236 unordered, align 8, !tbaa !3
   %238 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %237, null
-  br i1 %238, label %.thread4, label %.preheader69
+  br i1 %238, label %.loopexit61, label %.preheader60
 
-.thread4:                                         ; preds = %235, %231, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i1.i
+.loopexit61:                                      ; preds = %235, %231, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i1.i
   %239 = phi i1 [ true, %_ZN6kotlin2mm14ThreadRegistry11LockForIterEv.exit.i1.i ], [ true, %235 ], [ false, %231 ]
   br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %240, label %242
 
-240:                                              ; preds = %.thread4
+240:                                              ; preds = %.loopexit61
   %241 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0)) #37
   br label %242
 
-242:                                              ; preds = %240, %.thread4
+242:                                              ; preds = %240, %.loopexit61
   br i1 %239, label %_ZN6kotlin2mm24WaitForThreadsSuspensionEv.exit.i, label %243
 
 243:                                              ; preds = %242
@@ -26841,80 +27393,80 @@
 _ZN6kotlin2mm24WaitForThreadsSuspensionEv.exit.i: ; preds = %242
   %245 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %246 = icmp eq i8 %245, 0
-  br i1 %246, label %.loopexit99, label %.preheader98
+  br i1 %246, label %.loopexit93, label %.preheader92
 
-.preheader98:                                     ; preds = %.preheader98, %_ZN6kotlin2mm24WaitForThreadsSuspensionEv.exit.i
+.preheader92:                                     ; preds = %.preheader92, %_ZN6kotlin2mm24WaitForThreadsSuspensionEv.exit.i
   call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37
   %247 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %248 = icmp eq i8 %247, 0
-  br i1 %248, label %.loopexit99, label %.preheader98
+  br i1 %248, label %.loopexit93, label %.preheader92
 
-.loopexit99:                                      ; preds = %.preheader98, %_ZN6kotlin2mm24WaitForThreadsSuspensionEv.exit.i
-  %249 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+.loopexit93:                                      ; preds = %.preheader92, %_ZN6kotlin2mm24WaitForThreadsSuspensionEv.exit.i
+  %249 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %250 = icmp ne i8 %249, 0
-  %251 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*), align 8
+  %251 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*) unordered, align 8
   %252 = icmp eq i64 %251, %103
   %253 = and i1 %250, %252
   br i1 %253, label %260, label %254
 
-254:                                              ; preds = %.loopexit99
-  %255 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+254:                                              ; preds = %.loopexit93
+  %255 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %256 = icmp ne i8 %255, 0
-  %257 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*), align 8
+  %257 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*) unordered, align 8
   %258 = icmp eq i64 %257, %103
   %259 = and i1 %256, %258
   br i1 %259, label %260, label %_ZN6kotlin2gc8GCHandle9getMarkedEv.exit.i
 
-260:                                              ; preds = %254, %.loopexit99
-  %261 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit99 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %254 ]
+260:                                              ; preds = %254, %.loopexit93
+  %261 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit93 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %254 ]
   %262 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %261, i64 0, i32 7, i32 0, i32 0, i32 1
-  %263 = load i8, i8* %262, align 8, !tbaa !336, !range !72
+  %263 = load atomic i8, i8* %262 unordered, align 8, !tbaa !340, !range !70
   %264 = icmp eq i8 %263, 0
   br i1 %264, label %_ZN6kotlin2gc8GCHandle9getMarkedEv.exit.i, label %265
 
 265:                                              ; preds = %260
   %266 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %261, i64 0, i32 7, i32 0, i32 0, i32 0, i32 0, i32 1
-  %267 = load i64, i64* %266, align 8, !tbaa.struct !362
+  %267 = load atomic i64, i64* %266 unordered, align 8, !tbaa.struct !364
   br label %_ZN6kotlin2gc8GCHandle9getMarkedEv.exit.i
 
 _ZN6kotlin2gc8GCHandle9getMarkedEv.exit.i:        ; preds = %265, %260, %254
   %268 = phi i64 [ %267, %265 ], [ 0, %260 ], [ 0, %254 ]
   store atomic i8 0, i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0) release, align 1
-  %269 = load %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %202, align 8, !tbaa !3
+  %269 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %202 unordered, align 8, !tbaa !3
   %270 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %269 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*, i64)***
-  %271 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*, i64)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*, i64)*** %270, align 8, !tbaa !109
+  %271 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*, i64)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*, i64)*** %270 unordered, align 8, !tbaa !107
   %272 = getelementptr inbounds void (%"class.kotlin::gc::GC::ThreadData::Impl"*, i64)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*, i64)** %271, i64 4
-  %273 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*, i64)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*, i64)** %272, align 8
+  %273 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*, i64)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*, i64)** %272 unordered, align 8
   call void %273(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %269, i64 %268) #37
   %274 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1
   %275 = icmp eq i8 %274, 0
-  br i1 %275, label %.loopexit97, label %.preheader96
+  br i1 %275, label %.loopexit91, label %.preheader90
 
-.preheader96:                                     ; preds = %.preheader96, %_ZN6kotlin2gc8GCHandle9getMarkedEv.exit.i
+.preheader90:                                     ; preds = %.preheader90, %_ZN6kotlin2gc8GCHandle9getMarkedEv.exit.i
   call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37
   %276 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1
   %277 = icmp eq i8 %276, 0
-  br i1 %277, label %.loopexit97, label %.preheader96
+  br i1 %277, label %.loopexit91, label %.preheader90
 
-.loopexit97:                                      ; preds = %.preheader96, %_ZN6kotlin2gc8GCHandle9getMarkedEv.exit.i
+.loopexit91:                                      ; preds = %.preheader90, %_ZN6kotlin2gc8GCHandle9getMarkedEv.exit.i
   call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %36) #37
-  store %"struct.std::__detail::_List_node_base"* %37, %"struct.std::__detail::_List_node_base"** %38, align 8, !tbaa !123
-  store %"struct.std::__detail::_List_node_base"* %37, %"struct.std::__detail::_List_node_base"** %39, align 8, !tbaa !125
-  store i64 0, i64* %40, align 8, !tbaa !126
-  %278 = load i64, i64* bitcast (%"class.std::__cxx11::list"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1) to i64*), align 8, !tbaa !125
+  store %"struct.std::__detail::_List_node_base"* %37, %"struct.std::__detail::_List_node_base"** %38, align 8, !tbaa !121
+  store %"struct.std::__detail::_List_node_base"* %37, %"struct.std::__detail::_List_node_base"** %39, align 8, !tbaa !123
+  store i64 0, i64* %40, align 8, !tbaa !124
+  %278 = load atomic i64, i64* bitcast (%"class.std::__cxx11::list"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1) to i64*) unordered, align 8, !tbaa !123
   %279 = inttoptr i64 %278 to %"struct.std::__detail::_List_node_base"*
   %280 = icmp eq %"struct.std::__detail::_List_node_base"* %279, getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0)
-  br i1 %280, label %.loopexit95, label %281
+  br i1 %280, label %.loopexit89, label %281
 
-281:                                              ; preds = %311, %.loopexit97
-  %282 = phi %"struct.std::__detail::_List_node_base"* [ %312, %311 ], [ %279, %.loopexit97 ]
-  %283 = phi i64 [ %285, %311 ], [ %278, %.loopexit97 ]
+281:                                              ; preds = %311, %.loopexit91
+  %282 = phi %"struct.std::__detail::_List_node_base"* [ %312, %311 ], [ %279, %.loopexit91 ]
+  %283 = phi i64 [ %285, %311 ], [ %278, %.loopexit91 ]
   %284 = inttoptr i64 %283 to i64*
-  %285 = load i64, i64* %284, align 8, !tbaa !125
+  %285 = load atomic i64, i64* %284 unordered, align 8, !tbaa !123
   %286 = inttoptr i64 %283 to %"struct.std::_List_node"*
   %287 = getelementptr inbounds %"struct.std::_List_node", %"struct.std::_List_node"* %286, i64 0, i32 1
   %288 = bitcast %"union.std::aligned_storage<8, 8>::type"* %287 to %"class.kotlin::MultiSourceQueue<kotlin::mm::ExtraObjectData, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::ObjectPoolAllocator<kotlin::mm::ExtraObjectData>>::Node"**
-  %289 = load %"class.kotlin::MultiSourceQueue<kotlin::mm::ExtraObjectData, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::ObjectPoolAllocator<kotlin::mm::ExtraObjectData>>::Node"*, %"class.kotlin::MultiSourceQueue<kotlin::mm::ExtraObjectData, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::ObjectPoolAllocator<kotlin::mm::ExtraObjectData>>::Node"** %288, align 8, !tbaa !3
+  %289 = load atomic %"class.kotlin::MultiSourceQueue<kotlin::mm::ExtraObjectData, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::ObjectPoolAllocator<kotlin::mm::ExtraObjectData>>::Node"*, %"class.kotlin::MultiSourceQueue<kotlin::mm::ExtraObjectData, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::ObjectPoolAllocator<kotlin::mm::ExtraObjectData>>::Node"** %288 unordered, align 8, !tbaa !3
   %290 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<kotlin::mm::ExtraObjectData, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::ObjectPoolAllocator<kotlin::mm::ExtraObjectData>>::Node", %"class.kotlin::MultiSourceQueue<kotlin::mm::ExtraObjectData, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::ObjectPoolAllocator<kotlin::mm::ExtraObjectData>>::Node"* %289, i64 0, i32 2
   %291 = bitcast %"struct.std::atomic.63"* %290 to i64*
   %292 = load atomic i64, i64* %291 seq_cst, align 8
@@ -26927,26 +27479,26 @@
 
 296:                                              ; preds = %294
   %297 = getelementptr %"struct.std::__detail::_List_node_base", %"struct.std::__detail::_List_node_base"* %282, i64 0, i32 0
-  %298 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %297, align 8, !tbaa !125
+  %298 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %297 unordered, align 8, !tbaa !123
   %299 = icmp eq %"struct.std::__detail::_List_node_base"* %298, %37
   br i1 %299, label %311, label %300
 
 300:                                              ; preds = %296
   call void @_ZNSt8__detail15_List_node_base11_M_transferEPS0_S1_(%"struct.std::__detail::_List_node_base"* nonnull %37, %"struct.std::__detail::_List_node_base"* nonnull %282, %"struct.std::__detail::_List_node_base"* %298) #37
-  %301 = load i64, i64* %40, align 8, !tbaa !229
+  %301 = load atomic i64, i64* %40 unordered, align 8, !tbaa !228
   %302 = add i64 %301, 1
-  store i64 %302, i64* %40, align 8, !tbaa !229
-  %303 = load i64, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !229
+  store i64 %302, i64* %40, align 8, !tbaa !228
+  %303 = load atomic i64, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !228
   %304 = add i64 %303, -1
-  store i64 %304, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !229
+  store i64 %304, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !228
   br label %311
 
 305:                                              ; preds = %281
   %306 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<kotlin::mm::ExtraObjectData, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::ObjectPoolAllocator<kotlin::mm::ExtraObjectData>>::Node", %"class.kotlin::MultiSourceQueue<kotlin::mm::ExtraObjectData, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::ObjectPoolAllocator<kotlin::mm::ExtraObjectData>>::Node"* %289, i64 0, i32 3, i32 0
-  %307 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %306, align 8, !tbaa !363
-  %308 = load i64, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !226
+  %307 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %306 unordered, align 8, !tbaa !365
+  %308 = load atomic i64, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !225
   %309 = add i64 %308, -1
-  store i64 %309, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !226
+  store i64 %309, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !225
   call void @_ZNSt8__detail15_List_node_base9_M_unhookEv(%"struct.std::__detail::_List_node_base"* %307) #37
   %310 = bitcast %"struct.std::__detail::_List_node_base"* %307 to i8*
   call fastcc void @mi_free(i8* %310) #37
@@ -26958,43 +27510,43 @@
   br i1 %313, label %314, label %281
 
 314:                                              ; preds = %311
-  %315 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !125
+  %315 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) unordered, align 8, !tbaa !123
   %316 = icmp eq %"struct.std::__detail::_List_node_base"* %315, getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0)
-  br i1 %316, label %.loopexit95, label %.preheader94
+  br i1 %316, label %.loopexit89, label %.preheader88
 
-.preheader94:                                     ; preds = %.preheader94, %314
-  %317 = phi %"struct.std::__detail::_List_node_base"* [ %319, %.preheader94 ], [ %315, %314 ]
+.preheader88:                                     ; preds = %.preheader88, %314
+  %317 = phi %"struct.std::__detail::_List_node_base"* [ %319, %.preheader88 ], [ %315, %314 ]
   %318 = getelementptr inbounds %"struct.std::__detail::_List_node_base", %"struct.std::__detail::_List_node_base"* %317, i64 0, i32 0
-  %319 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %318, align 8, !tbaa !125
+  %319 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %318 unordered, align 8, !tbaa !123
   %320 = bitcast %"struct.std::__detail::_List_node_base"* %317 to i8*
   call fastcc void @mi_free(i8* %320) #37
   %321 = icmp eq %"struct.std::__detail::_List_node_base"* %319, getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0)
-  br i1 %321, label %.loopexit95, label %.preheader94
+  br i1 %321, label %.loopexit89, label %.preheader88
 
-.loopexit95:                                      ; preds = %.preheader94, %314, %.loopexit97
-  %322 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %39, align 8, !tbaa !125
+.loopexit89:                                      ; preds = %.preheader88, %314, %.loopexit91
+  %322 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %39 unordered, align 8, !tbaa !123
   %323 = icmp eq %"struct.std::__detail::_List_node_base"* %322, %37
   br i1 %323, label %324, label %325
 
-324:                                              ; preds = %.loopexit95
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !123
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !125
+324:                                              ; preds = %.loopexit89
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !121
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !123
   br label %_ZN6kotlin2mm22ExtraObjectDataFactory16ProcessDeletionsEv.exit.i
 
-325:                                              ; preds = %.loopexit95
+325:                                              ; preds = %.loopexit89
   %326 = ptrtoint %"struct.std::__detail::_List_node_base"* %322 to i64
-  store i64 %326, i64* bitcast (%"class.std::__cxx11::list"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1) to i64*), align 8, !tbaa !125
-  %327 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %38, align 8, !tbaa !123
-  store %"struct.std::__detail::_List_node_base"* %327, %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !123
+  store i64 %326, i64* bitcast (%"class.std::__cxx11::list"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1) to i64*), align 8, !tbaa !123
+  %327 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %38 unordered, align 8, !tbaa !121
+  store %"struct.std::__detail::_List_node_base"* %327, %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !121
   %328 = getelementptr inbounds %"struct.std::__detail::_List_node_base", %"struct.std::__detail::_List_node_base"* %327, i64 0, i32 0
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** %328, align 8, !tbaa !125
-  %329 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !125
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** %328, align 8, !tbaa !123
+  %329 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) unordered, align 8, !tbaa !123
   %330 = getelementptr inbounds %"struct.std::__detail::_List_node_base", %"struct.std::__detail::_List_node_base"* %329, i64 0, i32 1
-  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** %330, align 8, !tbaa !123
-  %331 = load i64, i64* %40, align 8, !tbaa !126
-  store %"struct.std::__detail::_List_node_base"* %37, %"struct.std::__detail::_List_node_base"** %38, align 8, !tbaa !123
-  store %"struct.std::__detail::_List_node_base"* %37, %"struct.std::__detail::_List_node_base"** %39, align 8, !tbaa !125
-  store i64 0, i64* %40, align 8, !tbaa !126
+  store %"struct.std::__detail::_List_node_base"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0), %"struct.std::__detail::_List_node_base"** %330, align 8, !tbaa !121
+  %331 = load atomic i64, i64* %40 unordered, align 8, !tbaa !124
+  store %"struct.std::__detail::_List_node_base"* %37, %"struct.std::__detail::_List_node_base"** %38, align 8, !tbaa !121
+  store %"struct.std::__detail::_List_node_base"* %37, %"struct.std::__detail::_List_node_base"** %39, align 8, !tbaa !123
+  store i64 0, i64* %40, align 8, !tbaa !124
   br label %_ZN6kotlin2mm22ExtraObjectDataFactory16ProcessDeletionsEv.exit.i
 
 _ZN6kotlin2mm22ExtraObjectDataFactory16ProcessDeletionsEv.exit.i: ; preds = %325, %324
@@ -27003,38 +27555,38 @@
   call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %36) #37
   store atomic i8 0, i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 2, i32 0, i32 0, i32 0) release, align 8
   %333 = call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37
-  %334 = load i64, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !226
+  %334 = load atomic i64, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !225
   %335 = mul i64 %334, 24
   %336 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %337 = icmp eq i8 %336, 0
-  br i1 %337, label %.loopexit93, label %.preheader92
+  br i1 %337, label %.loopexit87, label %.preheader86
 
-.preheader92:                                     ; preds = %.preheader92, %_ZN6kotlin2mm22ExtraObjectDataFactory16ProcessDeletionsEv.exit.i
+.preheader86:                                     ; preds = %.preheader86, %_ZN6kotlin2mm22ExtraObjectDataFactory16ProcessDeletionsEv.exit.i
   call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37
   %338 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %339 = icmp eq i8 %338, 0
-  br i1 %339, label %.loopexit93, label %.preheader92
+  br i1 %339, label %.loopexit87, label %.preheader86
 
-.loopexit93:                                      ; preds = %.preheader92, %_ZN6kotlin2mm22ExtraObjectDataFactory16ProcessDeletionsEv.exit.i
-  %340 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+.loopexit87:                                      ; preds = %.preheader86, %_ZN6kotlin2mm22ExtraObjectDataFactory16ProcessDeletionsEv.exit.i
+  %340 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %341 = icmp ne i8 %340, 0
-  %342 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*), align 8
+  %342 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*) unordered, align 8
   %343 = icmp eq i64 %342, %103
   %344 = and i1 %341, %343
   br i1 %344, label %351, label %345
 
-345:                                              ; preds = %.loopexit93
-  %346 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+345:                                              ; preds = %.loopexit87
+  %346 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %347 = icmp ne i8 %346, 0
-  %348 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*), align 8
+  %348 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*) unordered, align 8
   %349 = icmp eq i64 %348, %103
   %350 = and i1 %347, %349
   br i1 %350, label %351, label %_ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeC2ERS1_.exit.i
 
-351:                                              ; preds = %345, %.loopexit93
-  %352 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit93 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %345 ]
+351:                                              ; preds = %345, %.loopexit87
+  %352 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit87 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %345 ]
   %353 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %352, i64 0, i32 8, i32 1, i32 0, i32 0, i32 1
-  %354 = load i8, i8* %353, align 8, !tbaa !336, !range !72
+  %354 = load atomic i8, i8* %353 unordered, align 8, !tbaa !340, !range !70
   %355 = icmp eq i8 %354, 0
   %356 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %352, i64 0, i32 8, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
   store i64 %334, i64* %356, align 8
@@ -27043,30 +27595,30 @@
   br i1 %355, label %358, label %_ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeC2ERS1_.exit.i
 
 358:                                              ; preds = %351
-  store i8 1, i8* %353, align 8, !tbaa !336
+  store i8 1, i8* %353, align 8, !tbaa !340
   br label %_ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeC2ERS1_.exit.i
 
 _ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeC2ERS1_.exit.i: ; preds = %358, %351, %345
   store atomic i8 0, i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0) release, align 1
-  %359 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1, !noalias !365
+  %359 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1, !noalias !367
   %360 = icmp eq i8 %359, 0
-  br i1 %360, label %.loopexit91, label %.preheader90
+  br i1 %360, label %.loopexit85, label %.preheader84
 
-.preheader90:                                     ; preds = %.preheader90, %_ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeC2ERS1_.exit.i
-  call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37, !noalias !365
-  %361 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1, !noalias !365
+.preheader84:                                     ; preds = %.preheader84, %_ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeC2ERS1_.exit.i
+  call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37, !noalias !367
+  %361 = atomicrmw xchg i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 2, i32 0, i32 0, i32 0), i8 1 acquire, align 1, !noalias !367
   %362 = icmp eq i8 %361, 0
-  br i1 %362, label %.loopexit91, label %.preheader90
+  br i1 %362, label %.loopexit85, label %.preheader84
 
-.loopexit91:                                      ; preds = %.preheader90, %_ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeC2ERS1_.exit.i
-  %363 = load i64, i64* bitcast (%"class.kotlin::mm::GlobalsRegistry"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5) to i64*), align 8, !tbaa !125
+.loopexit85:                                      ; preds = %.preheader84, %_ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeC2ERS1_.exit.i
+  %363 = load atomic i64, i64* bitcast (%"class.kotlin::mm::GlobalsRegistry"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5) to i64*) unordered, align 8, !tbaa !123
   %364 = inttoptr i64 %363 to %"struct.std::__detail::_List_node_base"*
   %365 = icmp eq %"struct.std::__detail::_List_node_base"* %364, getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0)
-  br i1 %365, label %.loopexit89, label %.preheader88
+  br i1 %365, label %.loopexit83, label %.preheader82
 
-.preheader88:                                     ; preds = %458, %.loopexit91
-  %366 = phi %"struct.std::__detail::_List_node_base"* [ %460, %458 ], [ %364, %.loopexit91 ]
-  %367 = phi i64 [ %459, %458 ], [ %363, %.loopexit91 ]
+.preheader82:                                     ; preds = %458, %.loopexit85
+  %366 = phi %"struct.std::__detail::_List_node_base"* [ %460, %458 ], [ %364, %.loopexit85 ]
+  %367 = phi i64 [ %459, %458 ], [ %363, %.loopexit85 ]
   %368 = inttoptr i64 %367 to %"struct.std::_List_node.113"*
   %369 = getelementptr inbounds %"struct.std::_List_node.113", %"struct.std::_List_node.113"* %368, i64 0, i32 1, i32 0, i64 8
   %370 = getelementptr inbounds %"struct.std::_List_node.113", %"struct.std::_List_node.113"* %368, i64 0, i32 1, i32 0, i64 16
@@ -27076,7 +27628,7 @@
   %374 = icmp eq i32 %373, 0
   br i1 %374, label %375, label %455
 
-375:                                              ; preds = %.preheader88
+375:                                              ; preds = %.preheader82
   %376 = getelementptr inbounds %"struct.std::_List_node.113", %"struct.std::_List_node.113"* %368, i64 0, i32 1, i32 0, i64 24
   %377 = bitcast i8* %376 to i64*
   %378 = load atomic i64, i64* %377 seq_cst, align 8
@@ -27090,7 +27642,7 @@
   %384 = inttoptr i64 %383 to %struct.ObjHeader*
   %385 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %384, i64 1
   %386 = bitcast %struct.ObjHeader* %385 to %struct.ObjHeader**
-  %387 = load %struct.ObjHeader*, %struct.ObjHeader** %386, align 8, !tbaa !370
+  %387 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %386 unordered, align 8, !tbaa !372
   br label %388
 
 388:                                              ; preds = %382, %375
@@ -27130,7 +27682,7 @@
   %414 = inttoptr i64 %413 to %struct.ObjHeader*
   %415 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %414, i64 1
   %416 = bitcast %struct.ObjHeader* %415 to %struct.ObjHeader**
-  %417 = load %struct.ObjHeader*, %struct.ObjHeader** %416, align 8, !tbaa !370
+  %417 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %416 unordered, align 8, !tbaa !372
   br label %418
 
 418:                                              ; preds = %412, %407
@@ -27172,70 +27724,70 @@
   %442 = inttoptr i64 %441 to %struct.ObjHeader*
   %443 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %442, i64 1
   %444 = bitcast %struct.ObjHeader* %443 to %struct.ObjHeader**
-  %445 = load %struct.ObjHeader*, %struct.ObjHeader** %444, align 8, !tbaa !370
+  %445 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %444 unordered, align 8, !tbaa !372
   br label %_ZN6kotlin2mm15ExtraObjectData9UninstallEv.exit.i
 
 _ZN6kotlin2mm15ExtraObjectData9UninstallEv.exit.i: ; preds = %440, %_ZN6kotlin2mm15ExtraObjectData25ClearWeakReferenceCounterEv.exit.i
   %446 = phi %struct.ObjHeader* [ %445, %440 ], [ %437, %_ZN6kotlin2mm15ExtraObjectData25ClearWeakReferenceCounterEv.exit.i ]
   %447 = bitcast i8* %369 to i64*
-  %448 = load i64, i64* %447, align 8, !tbaa !372
+  %448 = load atomic i64, i64* %447 unordered, align 8, !tbaa !374
   %449 = bitcast %struct.ObjHeader* %446 to i64*
   store atomic volatile i64 %448, i64* %449 release, align 8
   %450 = inttoptr i64 %367 to i64*
-  %451 = load i64, i64* %450, align 8, !tbaa !125
-  %452 = load i64, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !226
+  %451 = load atomic i64, i64* %450 unordered, align 8, !tbaa !123
+  %452 = load atomic i64, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !225
   %453 = add i64 %452, -1
-  store i64 %453, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !226
+  store i64 %453, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !225
   call void @_ZNSt8__detail15_List_node_base9_M_unhookEv(%"struct.std::__detail::_List_node_base"* %366) #37
   %454 = inttoptr i64 %367 to i8*
   call fastcc void @mi_free(i8* %454) #37
   br label %458
 
-455:                                              ; preds = %394, %388, %.preheader88
+455:                                              ; preds = %394, %388, %.preheader82
   %456 = inttoptr i64 %367 to i64*
-  %457 = load i64, i64* %456, align 8, !tbaa !125
+  %457 = load atomic i64, i64* %456 unordered, align 8, !tbaa !123
   br label %458
 
 458:                                              ; preds = %455, %_ZN6kotlin2mm15ExtraObjectData9UninstallEv.exit.i
   %459 = phi i64 [ %457, %455 ], [ %451, %_ZN6kotlin2mm15ExtraObjectData9UninstallEv.exit.i ]
   %460 = inttoptr i64 %459 to %"struct.std::__detail::_List_node_base"*
   %461 = icmp eq %"struct.std::__detail::_List_node_base"* %460, getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0)
-  br i1 %461, label %.loopexit89, label %.preheader88
+  br i1 %461, label %.loopexit83, label %.preheader82
 
-.loopexit89:                                      ; preds = %458, %.loopexit91
+.loopexit83:                                      ; preds = %458, %.loopexit85
   store atomic i8 0, i8* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 2, i32 0, i32 0, i32 0) release, align 8
-  %462 = load i64, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1), align 8, !tbaa !226
+  %462 = load atomic i64, i64* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !225
   %463 = mul i64 %462, 24
   %464 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %465 = icmp eq i8 %464, 0
-  br i1 %465, label %.loopexit87, label %.preheader86
+  br i1 %465, label %.loopexit81, label %.preheader80
 
-.preheader86:                                     ; preds = %.preheader86, %.loopexit89
+.preheader80:                                     ; preds = %.preheader80, %.loopexit83
   call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37
   %466 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %467 = icmp eq i8 %466, 0
-  br i1 %467, label %.loopexit87, label %.preheader86
+  br i1 %467, label %.loopexit81, label %.preheader80
 
-.loopexit87:                                      ; preds = %.preheader86, %.loopexit89
-  %468 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+.loopexit81:                                      ; preds = %.preheader80, %.loopexit83
+  %468 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %469 = icmp ne i8 %468, 0
-  %470 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*), align 8
+  %470 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*) unordered, align 8
   %471 = icmp eq i64 %470, %103
   %472 = and i1 %469, %471
   br i1 %472, label %479, label %473
 
-473:                                              ; preds = %.loopexit87
-  %474 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+473:                                              ; preds = %.loopexit81
+  %474 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %475 = icmp ne i8 %474, 0
-  %476 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*), align 8
+  %476 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*) unordered, align 8
   %477 = icmp eq i64 %476, %103
   %478 = and i1 %475, %477
   br i1 %478, label %479, label %_ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeD2Ev.exit.i
 
-479:                                              ; preds = %473, %.loopexit87
-  %480 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit87 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %473 ]
+479:                                              ; preds = %473, %.loopexit81
+  %480 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit81 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %473 ]
   %481 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %480, i64 0, i32 9, i32 1, i32 0, i32 0, i32 1
-  %482 = load i8, i8* %481, align 8, !tbaa !336, !range !72
+  %482 = load atomic i8, i8* %481 unordered, align 8, !tbaa !340, !range !70
   %483 = icmp eq i8 %482, 0
   %484 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %480, i64 0, i32 9, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
   store i64 %462, i64* %484, align 8
@@ -27244,28 +27796,28 @@
   br i1 %483, label %486, label %_ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeD2Ev.exit.i
 
 486:                                              ; preds = %479
-  store i8 1, i8* %481, align 8, !tbaa !336
+  store i8 1, i8* %481, align 8, !tbaa !340
   br label %_ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeD2Ev.exit.i
 
 _ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeD2Ev.exit.i: ; preds = %486, %479, %473
   store atomic i8 0, i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0) release, align 1
-  %487 = load %"class.kotlin::mm::ObjectFactory"*, %"class.kotlin::mm::ObjectFactory"** %41, align 8, !tbaa !377
+  %487 = load atomic %"class.kotlin::mm::ObjectFactory"*, %"class.kotlin::mm::ObjectFactory"** %41 unordered, align 8, !tbaa !379
   %488 = getelementptr inbounds %"class.kotlin::mm::ObjectFactory", %"class.kotlin::mm::ObjectFactory"* %487, i64 0, i32 1
   %489 = getelementptr inbounds %"class.kotlin::mm::ObjectFactory", %"class.kotlin::mm::ObjectFactory"* %487, i64 0, i32 1, i32 4, i32 0, i32 0, i32 0
-  %490 = atomicrmw xchg i8* %489, i8 1 acquire, align 1, !noalias !378
+  %490 = atomicrmw xchg i8* %489, i8 1 acquire, align 1, !noalias !380
   %491 = icmp eq i8 %490, 0
-  br i1 %491, label %.loopexit85, label %.preheader84
+  br i1 %491, label %.loopexit79, label %.preheader78
 
-.preheader84:                                     ; preds = %.preheader84, %_ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeD2Ev.exit.i
-  call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37, !noalias !378
-  %492 = atomicrmw xchg i8* %489, i8 1 acquire, align 1, !noalias !378
+.preheader78:                                     ; preds = %.preheader78, %_ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeD2Ev.exit.i
+  call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37, !noalias !380
+  %492 = atomicrmw xchg i8* %489, i8 1 acquire, align 1, !noalias !380
   %493 = icmp eq i8 %492, 0
-  br i1 %493, label %.loopexit85, label %.preheader84
+  br i1 %493, label %.loopexit79, label %.preheader78
 
-.loopexit85:                                      ; preds = %.preheader84, %_ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeD2Ev.exit.i
+.loopexit79:                                      ; preds = %.preheader78, %_ZN6kotlin2gc8GCHandle24GCSweepExtraObjectsScopeD2Ev.exit.i
   br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %494, label %502
 
-494:                                              ; preds = %.loopexit85
+494:                                              ; preds = %.loopexit79
   %495 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull getelementptr inbounds ({ %union.pthread_mutex_t }, { %union.pthread_mutex_t }* @_ZN12_GLOBAL__N_116gSuspensionMutexE, i64 0, i32 0)) #37
   %496 = icmp eq i32 %495, 0
   br i1 %496, label %499, label %497
@@ -27285,7 +27837,7 @@
   %501 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull getelementptr inbounds ({ %union.pthread_mutex_t }, { %union.pthread_mutex_t }* @_ZN12_GLOBAL__N_116gSuspensionMutexE, i64 0, i32 0)) #37
   br label %_ZN6kotlin2mm13ResumeThreadsEv.exit.i
 
-502:                                              ; preds = %.loopexit85
+502:                                              ; preds = %.loopexit79
   store atomic i8 0, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
   br label %_ZN6kotlin2mm13ResumeThreadsEv.exit.i
 
@@ -27300,32 +27852,32 @@
   call void @_ZNSt18condition_variable10notify_allEv(%"class.std::condition_variable"* nonnull @_ZN12_GLOBAL__N_118gSuspensionCondVarE) #37
   %506 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %507 = icmp eq i8 %506, 0
-  br i1 %507, label %.loopexit83, label %.preheader82
+  br i1 %507, label %.loopexit77, label %.preheader76
 
-.preheader82:                                     ; preds = %.preheader82, %_ZN6kotlin2mm13ResumeThreadsEv.exit.i
+.preheader76:                                     ; preds = %.preheader76, %_ZN6kotlin2mm13ResumeThreadsEv.exit.i
   call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37
   %508 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %509 = icmp eq i8 %508, 0
-  br i1 %509, label %.loopexit83, label %.preheader82
+  br i1 %509, label %.loopexit77, label %.preheader76
 
-.loopexit83:                                      ; preds = %.preheader82, %_ZN6kotlin2mm13ResumeThreadsEv.exit.i
-  %510 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+.loopexit77:                                      ; preds = %.preheader76, %_ZN6kotlin2mm13ResumeThreadsEv.exit.i
+  %510 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %511 = icmp ne i8 %510, 0
-  %512 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*), align 8
+  %512 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*) unordered, align 8
   %513 = icmp eq i64 %512, %103
   %514 = and i1 %511, %513
   br i1 %514, label %521, label %515
 
-515:                                              ; preds = %.loopexit83
-  %516 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+515:                                              ; preds = %.loopexit77
+  %516 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %517 = icmp ne i8 %516, 0
-  %518 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*), align 8
+  %518 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*) unordered, align 8
   %519 = icmp eq i64 %518, %103
   %520 = and i1 %517, %519
   br i1 %520, label %521, label %_ZN6kotlin2gc8GCHandle17threadsAreResumedEv.exit.i
 
-521:                                              ; preds = %515, %.loopexit83
-  %522 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit83 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %515 ]
+521:                                              ; preds = %515, %.loopexit77
+  %522 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit77 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %515 ]
   %523 = call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37
   %524 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %522, i64 0, i32 4, i32 0, i32 0, i32 0, i32 0
   store i64 %523, i64* %524, align 8
@@ -27336,43 +27888,43 @@
 _ZN6kotlin2gc8GCHandle17threadsAreResumedEv.exit.i: ; preds = %521, %515
   store atomic i8 0, i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0) release, align 1
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %42) #37
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %44, i8 0, i64 24, i1 false) #37, !alias.scope !383
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %44, i8 0, i64 24, i1 false) #37, !alias.scope !385
   %526 = call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37
-  %527 = load %"class.kotlin::gc::GC::Impl"*, %"class.kotlin::gc::GC::Impl"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 6, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !3
+  %527 = load atomic %"class.kotlin::gc::GC::Impl"*, %"class.kotlin::gc::GC::Impl"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 6, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0) unordered, align 8, !tbaa !3
   %528 = getelementptr inbounds %"class.kotlin::gc::GC::Impl", %"class.kotlin::gc::GC::Impl"* %527, i64 0, i32 1, i32 1, i32 2
-  %529 = load i64, i64* %528, align 8, !tbaa !386
+  %529 = load atomic i64, i64* %528 unordered, align 8, !tbaa !388
   %530 = getelementptr inbounds %"class.kotlin::gc::GC::Impl", %"class.kotlin::gc::GC::Impl"* %527, i64 0, i32 1, i32 1, i32 3
-  %531 = load i64, i64* %530, align 8, !tbaa !387
+  %531 = load atomic i64, i64* %530 unordered, align 8, !tbaa !389
   %532 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %533 = icmp eq i8 %532, 0
-  br i1 %533, label %.loopexit81, label %.preheader80
+  br i1 %533, label %.loopexit75, label %.preheader74
 
-.preheader80:                                     ; preds = %.preheader80, %_ZN6kotlin2gc8GCHandle17threadsAreResumedEv.exit.i
+.preheader74:                                     ; preds = %.preheader74, %_ZN6kotlin2gc8GCHandle17threadsAreResumedEv.exit.i
   call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37
   %534 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
   %535 = icmp eq i8 %534, 0
-  br i1 %535, label %.loopexit81, label %.preheader80
+  br i1 %535, label %.loopexit75, label %.preheader74
 
-.loopexit81:                                      ; preds = %.preheader80, %_ZN6kotlin2gc8GCHandle17threadsAreResumedEv.exit.i
-  %536 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+.loopexit75:                                      ; preds = %.preheader74, %_ZN6kotlin2gc8GCHandle17threadsAreResumedEv.exit.i
+  %536 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %537 = icmp ne i8 %536, 0
-  %538 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*), align 8
+  %538 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*) unordered, align 8
   %539 = icmp eq i64 %538, %103
   %540 = and i1 %537, %539
   br i1 %540, label %547, label %541
 
-541:                                              ; preds = %.loopexit81
-  %542 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
+541:                                              ; preds = %.loopexit75
+  %542 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
   %543 = icmp ne i8 %542, 0
-  %544 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*), align 8
+  %544 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*) unordered, align 8
   %545 = icmp eq i64 %544, %103
   %546 = and i1 %543, %545
   br i1 %546, label %547, label %_ZN6kotlin2gc8GCHandle12GCSweepScopeC2ERS1_.exit.i
 
-547:                                              ; preds = %541, %.loopexit81
-  %548 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit81 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %541 ]
+547:                                              ; preds = %541, %.loopexit75
+  %548 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit75 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %541 ]
   %549 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %548, i64 0, i32 8, i32 0, i32 0, i32 0, i32 1
-  %550 = load i8, i8* %549, align 8, !tbaa !336, !range !72
+  %550 = load atomic i8, i8* %549 unordered, align 8, !tbaa !340, !range !70
   %551 = icmp eq i8 %550, 0
   %552 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %548, i64 0, i32 8, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
   store i64 %529, i64* %552, align 8
@@ -27381,22 +27933,22 @@
   br i1 %551, label %554, label %_ZN6kotlin2gc8GCHandle12GCSweepScopeC2ERS1_.exit.i
 
 554:                                              ; preds = %547
-  store i8 1, i8* %549, align 8, !tbaa !336
+  store i8 1, i8* %549, align 8, !tbaa !340
   br label %_ZN6kotlin2gc8GCHandle12GCSweepScopeC2ERS1_.exit.i
 
 _ZN6kotlin2gc8GCHandle12GCSweepScopeC2ERS1_.exit.i: ; preds = %554, %547, %541
   store atomic i8 0, i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0) release, align 1
   %555 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage", %"class.kotlin::mm::internal::ObjectFactoryStorage"* %488, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %556 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %555, align 8, !tbaa !3
+  %556 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %555 unordered, align 8, !tbaa !3
   %557 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %556, null
-  br i1 %557, label %.loopexit79, label %558
+  br i1 %557, label %.loopexit73, label %558
 
 558:                                              ; preds = %_ZN6kotlin2gc8GCHandle12GCSweepScopeC2ERS1_.exit.i
   %559 = ptrtoint %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %556 to i64
   br label %560
 
 560:                                              ; preds = %569, %558
-  %.sroa.028.0 = phi i64 [ 0, %558 ], [ %.sroa.028.1, %569 ]
+  %.sroa.024.0 = phi i64 [ 0, %558 ], [ %.sroa.024.1, %569 ]
   %.sroa.6.0 = phi i64 [ %559, %558 ], [ %.sroa.6.1, %569 ]
   %561 = phi %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* [ %556, %558 ], [ %570, %569 ]
   %562 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %561, i64 1
@@ -27408,15 +27960,15 @@
 566:                                              ; preds = %560
   store atomic i64 0, i64* %563 monotonic, align 8
   %567 = inttoptr i64 %.sroa.6.0 to i64*
-  %568 = load i64, i64* %567, align 8, !tbaa !3
+  %568 = load atomic i64, i64* %567 unordered, align 8, !tbaa !3
   br label %569
 
 569:                                              ; preds = %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable15EraseAndAdvanceERNS4_8IteratorE.exit.i, %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable14MoveAndAdvanceERNS4_14FinalizerQueueERNS4_8IteratorE.exit.i, %566
-  %.sroa.028.1 = phi i64 [ %.sroa.6.0, %566 ], [ %.sroa.028.0, %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable15EraseAndAdvanceERNS4_8IteratorE.exit.i ], [ %.sroa.028.0, %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable14MoveAndAdvanceERNS4_14FinalizerQueueERNS4_8IteratorE.exit.i ]
-  %.sroa.6.1 = phi i64 [ %568, %566 ], [ %660, %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable15EraseAndAdvanceERNS4_8IteratorE.exit.i ], [ %617, %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable14MoveAndAdvanceERNS4_14FinalizerQueueERNS4_8IteratorE.exit.i ]
+  %.sroa.024.1 = phi i64 [ %.sroa.6.0, %566 ], [ %.sroa.024.0, %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable15EraseAndAdvanceERNS4_8IteratorE.exit.i ], [ %.sroa.024.0, %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable14MoveAndAdvanceERNS4_14FinalizerQueueERNS4_8IteratorE.exit.i ]
+  %.sroa.6.1 = phi i64 [ %568, %566 ], [ %661, %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable15EraseAndAdvanceERNS4_8IteratorE.exit.i ], [ %617, %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable14MoveAndAdvanceERNS4_14FinalizerQueueERNS4_8IteratorE.exit.i ]
   %570 = inttoptr i64 %.sroa.6.1 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
   %571 = icmp eq i64 %.sroa.6.1, 0
-  br i1 %571, label %.loopexit79, label %560
+  br i1 %571, label %.loopexit73, label %560
 
 572:                                              ; preds = %560
   %573 = inttoptr i64 %.sroa.6.0 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
@@ -27426,7 +27978,7 @@
   %577 = and i64 %576, -4
   %578 = inttoptr i64 %577 to %struct.TypeInfo*
   %579 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %578, i64 0, i32 0
-  %580 = load %struct.TypeInfo*, %struct.TypeInfo** %579, align 8, !tbaa !335
+  %580 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %579 unordered, align 8, !tbaa !339
   %581 = icmp ne %struct.TypeInfo* %580, %578
   %582 = icmp ne i64 %577, 0
   %583 = and i1 %582, %581
@@ -27439,10 +27991,10 @@
   %587 = load atomic volatile i64, i64* %586 monotonic, align 8
   %588 = inttoptr i64 %587 to %struct.TypeInfo*
   %589 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %588, i64 0, i32 13
-  %590 = load i32, i32* %589, align 8, !tbaa !67
+  %590 = load atomic i32, i32* %589 unordered, align 8, !tbaa !66
   %591 = and i32 %590, 64
   %.not = icmp eq i32 %591, 0
-  br i1 %.not, label %634, label %_ZN6kotlin13HasFinalizersEP9ObjHeader.exit.i.thread
+  br i1 %.not, label %635, label %_ZN6kotlin13HasFinalizersEP9ObjHeader.exit.i.thread
 
 _ZN6kotlin13HasFinalizersEP9ObjHeader.exit.i.thread: ; preds = %_ZN6kotlin13HasFinalizersEP9ObjHeader.exit.i, %572
   %592 = load atomic volatile i64, i64* %575 monotonic, align 8
@@ -27451,14 +28003,14 @@
   %595 = load atomic volatile i64, i64* %594 monotonic, align 8
   %596 = inttoptr i64 %595 to %struct.TypeInfo*
   %597 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %596, i64 0, i32 3
-  %598 = load i32, i32* %597, align 4, !tbaa !334
+  %598 = load atomic i32, i32* %597 unordered, align 4, !tbaa !338
   %599 = icmp slt i32 %598, 0
   br i1 %599, label %600, label %609
 
 600:                                              ; preds = %_ZN6kotlin13HasFinalizersEP9ObjHeader.exit.i.thread
   %601 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %573, i64 3
   %602 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %601 to i32*
-  %603 = load i32, i32* %602, align 8, !tbaa !18
+  %603 = load atomic i32, i32* %602 unordered, align 8, !tbaa !18
   %604 = sub nsw i32 0, %598
   %605 = sext i32 %604 to i64
   %606 = zext i32 %603 to i64
@@ -27478,701 +28030,727 @@
   %615 = and i64 %614, -8
   call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %49) #37
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %50) #37
-  %616 = inttoptr i64 %.sroa.028.0 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
+  %616 = inttoptr i64 %.sroa.024.0 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
   call fastcc void @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE13ExtractUnsafeEPNS9_4NodeEm(%"struct.std::pair.185"* noalias nonnull align 8 %10, %"class.kotlin::mm::internal::ObjectFactoryStorage"* nonnull %488, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %616, i64 %615) #37
-  %617 = load i64, i64* %52, align 8, !tbaa !388
-  %618 = load i64, i64* %55, align 8, !tbaa !3
+  %617 = load atomic i64, i64* %52 unordered, align 8, !tbaa !390
+  %618 = load atomic i64, i64* %55 unordered, align 8, !tbaa !3
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %54, align 8, !tbaa !3
-  store i64 %618, i64* %56, align 8, !tbaa !198
-  %619 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %57, align 8, !tbaa !3
+  store i64 %618, i64* %56, align 8, !tbaa !197
+  %619 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %57 unordered, align 8, !tbaa !3
   %620 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %619, null
-  %621 = inttoptr i64 %618 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
-  br i1 %620, label %622, label %623
+  %621 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %58 unordered, align 8, !tbaa !3
+  %622 = ptrtoint %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %621 to i64
+  br i1 %620, label %623, label %624
 
-622:                                              ; preds = %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE20GetAllocatedHeapSizeEP9ObjHeader.exit.i.i
+623:                                              ; preds = %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE20GetAllocatedHeapSizeEP9ObjHeader.exit.i.i
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %58, align 8, !tbaa !3
-  store i64 %618, i64* %60, align 8, !tbaa !3
+  store i64 %622, i64* %60, align 8, !tbaa !3
   br label %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable14MoveAndAdvanceERNS4_14FinalizerQueueERNS4_8IteratorE.exit.i
 
-623:                                              ; preds = %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE20GetAllocatedHeapSizeEP9ObjHeader.exit.i.i
-  %624 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %59, align 8, !tbaa !390
+624:                                              ; preds = %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE20GetAllocatedHeapSizeEP9ObjHeader.exit.i.i
+  %625 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %59 unordered, align 8, !tbaa !392
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %58, align 8, !tbaa !3
-  %625 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %624 to i64*
-  %626 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %624, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %627 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %626, align 8, !tbaa !3
-  store i64 %618, i64* %625, align 8, !tbaa !3
-  %628 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %627, null
-  br i1 %628, label %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable14MoveAndAdvanceERNS4_14FinalizerQueueERNS4_8IteratorE.exit.i, label %629
+  %626 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %625 to i64*
+  %627 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %625, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %628 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %627 unordered, align 8, !tbaa !3
+  store i64 %622, i64* %626, align 8, !tbaa !3
+  %629 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %628, null
+  br i1 %629, label %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable14MoveAndAdvanceERNS4_14FinalizerQueueERNS4_8IteratorE.exit.i, label %630
 
-629:                                              ; preds = %623
-  %630 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %627, i64 0, i32 0
-  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %630) #37
-  %631 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %627 to i8*
-  call fastcc void @mi_free(i8* nonnull %631) #37
+630:                                              ; preds = %624
+  %631 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %628, i64 0, i32 0
+  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %631) #37
+  %632 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %628 to i8*
+  call fastcc void @mi_free(i8* nonnull %632) #37
   br label %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable14MoveAndAdvanceERNS4_14FinalizerQueueERNS4_8IteratorE.exit.i
 
-_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable14MoveAndAdvanceERNS4_14FinalizerQueueERNS4_8IteratorE.exit.i: ; preds = %629, %623, %622
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %621, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %59, align 8, !tbaa !390
-  %632 = load i64, i64* %61, align 8, !tbaa !391
-  %633 = add i64 %632, 1
-  store i64 %633, i64* %61, align 8, !tbaa !391
+_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable14MoveAndAdvanceERNS4_14FinalizerQueueERNS4_8IteratorE.exit.i: ; preds = %630, %624, %623
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %621, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %59, align 8, !tbaa !392
+  %633 = load atomic i64, i64* %61 unordered, align 8, !tbaa !393
+  %634 = add i64 %633, 1
+  store i64 %634, i64* %61, align 8, !tbaa !393
   call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %11) #37
   call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %53) #37
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %50) #37
   call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %49) #37
   br label %569
 
-634:                                              ; preds = %_ZN6kotlin13HasFinalizersEP9ObjHeader.exit.i
-  %635 = load atomic volatile i64, i64* %575 monotonic, align 8
-  %636 = and i64 %635, -4
-  %637 = inttoptr i64 %636 to i64*
-  %638 = load atomic volatile i64, i64* %637 monotonic, align 8
-  %639 = inttoptr i64 %638 to %struct.TypeInfo*
-  %640 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %639, i64 0, i32 3
-  %641 = load i32, i32* %640, align 4, !tbaa !334
-  %642 = icmp slt i32 %641, 0
-  br i1 %642, label %643, label %652
+635:                                              ; preds = %_ZN6kotlin13HasFinalizersEP9ObjHeader.exit.i
+  %636 = load atomic volatile i64, i64* %575 monotonic, align 8
+  %637 = and i64 %636, -4
+  %638 = inttoptr i64 %637 to i64*
+  %639 = load atomic volatile i64, i64* %638 monotonic, align 8
+  %640 = inttoptr i64 %639 to %struct.TypeInfo*
+  %641 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %640, i64 0, i32 3
+  %642 = load atomic i32, i32* %641 unordered, align 4, !tbaa !338
+  %643 = icmp slt i32 %642, 0
+  br i1 %643, label %644, label %653
 
-643:                                              ; preds = %634
-  %644 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %573, i64 3
-  %645 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %644 to i32*
-  %646 = load i32, i32* %645, align 8, !tbaa !18
-  %647 = sub nsw i32 0, %641
-  %648 = sext i32 %647 to i64
-  %649 = zext i32 %646 to i64
-  %650 = mul nuw nsw i64 %648, %649
-  %651 = add nuw nsw i64 %650, 31
+644:                                              ; preds = %635
+  %645 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %573, i64 3
+  %646 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %645 to i32*
+  %647 = load atomic i32, i32* %646 unordered, align 8, !tbaa !18
+  %648 = sub nsw i32 0, %642
+  %649 = sext i32 %648 to i64
+  %650 = zext i32 %647 to i64
+  %651 = mul nuw nsw i64 %649, %650
+  %652 = add nuw nsw i64 %651, 31
   br label %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable15EraseAndAdvanceERNS4_8IteratorE.exit.i
 
-652:                                              ; preds = %634
-  %653 = zext i32 %641 to i64
-  %654 = add nuw nsw i64 %653, 15
+653:                                              ; preds = %635
+  %654 = zext i32 %642 to i64
+  %655 = add nuw nsw i64 %654, 15
   br label %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable15EraseAndAdvanceERNS4_8IteratorE.exit.i
 
-_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable15EraseAndAdvanceERNS4_8IteratorE.exit.i: ; preds = %652, %643
-  %655 = phi i64 [ %651, %643 ], [ %654, %652 ]
-  %656 = and i64 %655, -8
-  %657 = add nuw nsw i64 %656, 15
-  %658 = and i64 %657, -8
+_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE8Iterable15EraseAndAdvanceERNS4_8IteratorE.exit.i: ; preds = %653, %644
+  %656 = phi i64 [ %652, %644 ], [ %655, %653 ]
+  %657 = and i64 %656, -8
+  %658 = add nuw nsw i64 %657, 15
+  %659 = and i64 %658, -8
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %45) #37
-  %659 = inttoptr i64 %.sroa.028.0 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
-  call fastcc void @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE13ExtractUnsafeEPNS9_4NodeEm(%"struct.std::pair.185"* noalias nonnull align 8 %9, %"class.kotlin::mm::internal::ObjectFactoryStorage"* nonnull %488, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %659, i64 %658) #37
-  %660 = load i64, i64* %47, align 8, !tbaa !388
+  %660 = inttoptr i64 %.sroa.024.0 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
+  call fastcc void @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE13ExtractUnsafeEPNS9_4NodeEm(%"struct.std::pair.185"* noalias nonnull align 8 %9, %"class.kotlin::mm::internal::ObjectFactoryStorage"* nonnull %488, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %660, i64 %659) #37
+  %661 = load atomic i64, i64* %47 unordered, align 8, !tbaa !390
   call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %48) #37
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %45) #37
   br label %569
 
-.loopexit79:                                      ; preds = %569, %_ZN6kotlin2gc8GCHandle12GCSweepScopeC2ERS1_.exit.i
-  %661 = load %"class.kotlin::gc::GC::Impl"*, %"class.kotlin::gc::GC::Impl"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 6, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !3
-  %662 = getelementptr inbounds %"class.kotlin::gc::GC::Impl", %"class.kotlin::gc::GC::Impl"* %661, i64 0, i32 1, i32 1, i32 2
-  %663 = load i64, i64* %662, align 8, !tbaa !386
-  %664 = getelementptr inbounds %"class.kotlin::gc::GC::Impl", %"class.kotlin::gc::GC::Impl"* %661, i64 0, i32 1, i32 1, i32 3
-  %665 = load i64, i64* %664, align 8, !tbaa !387
-  %666 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
-  %667 = icmp eq i8 %666, 0
-  br i1 %667, label %.loopexit78, label %.preheader77
+.loopexit73:                                      ; preds = %569, %_ZN6kotlin2gc8GCHandle12GCSweepScopeC2ERS1_.exit.i
+  %662 = load atomic %"class.kotlin::gc::GC::Impl"*, %"class.kotlin::gc::GC::Impl"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 6, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0) unordered, align 8, !tbaa !3
+  %663 = getelementptr inbounds %"class.kotlin::gc::GC::Impl", %"class.kotlin::gc::GC::Impl"* %662, i64 0, i32 1, i32 1, i32 2
+  %664 = load atomic i64, i64* %663 unordered, align 8, !tbaa !388
+  %665 = getelementptr inbounds %"class.kotlin::gc::GC::Impl", %"class.kotlin::gc::GC::Impl"* %662, i64 0, i32 1, i32 1, i32 3
+  %666 = load atomic i64, i64* %665 unordered, align 8, !tbaa !389
+  %667 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
+  %668 = icmp eq i8 %667, 0
+  br i1 %668, label %.loopexit72, label %.preheader71
 
-.preheader77:                                     ; preds = %.preheader77, %.loopexit79
+.preheader71:                                     ; preds = %.preheader71, %.loopexit73
   call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37
-  %668 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
-  %669 = icmp eq i8 %668, 0
-  br i1 %669, label %.loopexit78, label %.preheader77
+  %669 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
+  %670 = icmp eq i8 %669, 0
+  br i1 %670, label %.loopexit72, label %.preheader71
 
-.loopexit78:                                      ; preds = %.preheader77, %.loopexit79
-  %670 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
-  %671 = icmp ne i8 %670, 0
-  %672 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*), align 8
-  %673 = icmp eq i64 %672, %103
-  %674 = and i1 %671, %673
-  br i1 %674, label %681, label %675
+.loopexit72:                                      ; preds = %.preheader71, %.loopexit73
+  %671 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
+  %672 = icmp ne i8 %671, 0
+  %673 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*) unordered, align 8
+  %674 = icmp eq i64 %673, %103
+  %675 = and i1 %672, %674
+  br i1 %675, label %682, label %676
 
-675:                                              ; preds = %.loopexit78
-  %676 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
-  %677 = icmp ne i8 %676, 0
-  %678 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*), align 8
-  %679 = icmp eq i64 %678, %103
-  %680 = and i1 %677, %679
-  br i1 %680, label %681, label %_ZN6kotlin2gc8GCHandle12GCSweepScopeD2Ev.exit.i
+676:                                              ; preds = %.loopexit72
+  %677 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
+  %678 = icmp ne i8 %677, 0
+  %679 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*) unordered, align 8
+  %680 = icmp eq i64 %679, %103
+  %681 = and i1 %678, %680
+  br i1 %681, label %682, label %_ZN6kotlin2gc8GCHandle12GCSweepScopeD2Ev.exit.i
 
-681:                                              ; preds = %675, %.loopexit78
-  %682 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit78 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %675 ]
-  %683 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %682, i64 0, i32 9, i32 0, i32 0, i32 0, i32 1
-  %684 = load i8, i8* %683, align 8, !tbaa !336, !range !72
-  %685 = icmp eq i8 %684, 0
-  %686 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %682, i64 0, i32 9, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  store i64 %663, i64* %686, align 8
-  %687 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %682, i64 0, i32 9, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  store i64 %665, i64* %687, align 8
-  br i1 %685, label %688, label %_ZN6kotlin2gc8GCHandle12GCSweepScopeD2Ev.exit.i
+682:                                              ; preds = %676, %.loopexit72
+  %683 = phi %"struct.(anonymous namespace)::GCInfo"* [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to %"struct.(anonymous namespace)::GCInfo"*), %.loopexit72 ], [ bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to %"struct.(anonymous namespace)::GCInfo"*), %676 ]
+  %684 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %683, i64 0, i32 9, i32 0, i32 0, i32 0, i32 1
+  %685 = load atomic i8, i8* %684 unordered, align 8, !tbaa !340, !range !70
+  %686 = icmp eq i8 %685, 0
+  %687 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %683, i64 0, i32 9, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  store i64 %664, i64* %687, align 8
+  %688 = getelementptr inbounds %"struct.(anonymous namespace)::GCInfo", %"struct.(anonymous namespace)::GCInfo"* %683, i64 0, i32 9, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
+  store i64 %666, i64* %688, align 8
+  br i1 %686, label %689, label %_ZN6kotlin2gc8GCHandle12GCSweepScopeD2Ev.exit.i
 
-688:                                              ; preds = %681
-  store i8 1, i8* %683, align 8, !tbaa !336
+689:                                              ; preds = %682
+  store i8 1, i8* %684, align 8, !tbaa !340
   br label %_ZN6kotlin2gc8GCHandle12GCSweepScopeD2Ev.exit.i
 
-_ZN6kotlin2gc8GCHandle12GCSweepScopeD2Ev.exit.i:  ; preds = %688, %681, %675
+_ZN6kotlin2gc8GCHandle12GCSweepScopeD2Ev.exit.i:  ; preds = %689, %682, %676
   store atomic i8 0, i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0) release, align 1
   invoke fastcc void @_ZN13GCStateHolder16ValueWithCondVarIlE3setEl(%"struct.GCStateHolder::ValueWithCondVar"* nonnull %62, i64 %103)
-          to label %689 unwind label %916
+          to label %690 unwind label %929
 
-689:                                              ; preds = %_ZN6kotlin2gc8GCHandle12GCSweepScopeD2Ev.exit.i
-  %690 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
-  %691 = icmp eq i8 %690, 0
-  br i1 %691, label %.loopexit76, label %.preheader75
+690:                                              ; preds = %_ZN6kotlin2gc8GCHandle12GCSweepScopeD2Ev.exit.i
+  %691 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
+  %692 = icmp eq i8 %691, 0
+  br i1 %692, label %.loopexit70, label %.preheader69
 
-.preheader75:                                     ; preds = %.preheader75, %689
+.preheader69:                                     ; preds = %.preheader69, %690
   call void @_ZN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EE5yieldEv() #37
-  %692 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
-  %693 = icmp eq i8 %692, 0
-  br i1 %693, label %.loopexit76, label %.preheader75
+  %693 = atomicrmw xchg i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0), i8 1 acquire, align 1
+  %694 = icmp eq i8 %693, 0
+  br i1 %694, label %.loopexit70, label %.preheader69
 
-.loopexit76:                                      ; preds = %.preheader75, %689
-  %694 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
-  %695 = icmp ne i8 %694, 0
-  %696 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*), align 8
-  %697 = icmp eq i64 %696, %103
-  %698 = and i1 %695, %697
-  br i1 %698, label %705, label %699
+.loopexit70:                                      ; preds = %.preheader69, %690
+  %695 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
+  %696 = icmp ne i8 %695, 0
+  %697 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE to i64*) unordered, align 8
+  %698 = icmp eq i64 %697, %103
+  %699 = and i1 %696, %698
+  br i1 %699, label %706, label %700
 
-699:                                              ; preds = %.loopexit76
-  %700 = load i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1), align 8, !tbaa !311, !range !72
-  %701 = icmp ne i8 %700, 0
-  %702 = load i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*), align 8
-  %703 = icmp eq i64 %702, %103
-  %704 = and i1 %701, %703
-  br i1 %704, label %_ZN6kotlin2gc8GCHandle8finishedEv.exit.i.critedge, label %_ZN6kotlin2gc8GCHandle8finishedEv.exit.i
+700:                                              ; preds = %.loopexit70
+  %701 = load atomic i8, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 1) unordered, align 8, !tbaa !309, !range !70
+  %702 = icmp ne i8 %701, 0
+  %703 = load atomic i64, i64* bitcast ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE to i64*) unordered, align 8
+  %704 = icmp eq i64 %703, %103
+  %705 = and i1 %702, %704
+  br i1 %705, label %_ZN6kotlin2gc8GCHandle8finishedEv.exit.i.critedge, label %_ZN6kotlin2gc8GCHandle8finishedEv.exit.i
 
-705:                                              ; preds = %.loopexit76
-  %706 = call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37
-  store i64 %706, i64* bitcast (i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0) to i64*), align 8
+706:                                              ; preds = %.loopexit70
+  %707 = call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37
+  store i64 %707, i64* bitcast (i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0) to i64*), align 8
   store i8 1, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 2, i32 0, i32 1), align 8
   call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(256) getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0), i8* nonnull align 8 dereferenceable(256) getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0), i64 256, i1 false) #37
   call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(256) getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_17currentE, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0), i8 0, i64 256, i1 false) #37
   br label %_ZN6kotlin2gc8GCHandle8finishedEv.exit.i
 
-_ZN6kotlin2gc8GCHandle8finishedEv.exit.i.critedge: ; preds = %699
-  %707 = call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37
-  store i64 %707, i64* bitcast (i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0) to i64*), align 8
+_ZN6kotlin2gc8GCHandle8finishedEv.exit.i.critedge: ; preds = %700
+  %708 = call i64 @_ZNSt6chrono3_V212steady_clock3nowEv() #37
+  store i64 %708, i64* bitcast (i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0) to i64*), align 8
   store i8 1, i8* getelementptr inbounds ({ { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [7 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [31 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } }, { { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } }, { { { %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", [15 x i8] }, i8, [7 x i8] } } } }* @_ZN12_GLOBAL__N_14lastE, i64 0, i32 2, i32 0, i32 1), align 8
   br label %_ZN6kotlin2gc8GCHandle8finishedEv.exit.i
 
-_ZN6kotlin2gc8GCHandle8finishedEv.exit.i:         ; preds = %_ZN6kotlin2gc8GCHandle8finishedEv.exit.i.critedge, %705, %699
+_ZN6kotlin2gc8GCHandle8finishedEv.exit.i:         ; preds = %_ZN6kotlin2gc8GCHandle8finishedEv.exit.i.critedge, %706, %700
   store atomic i8 0, i8* getelementptr inbounds ({ { i8 } }, { { i8 } }* @_ZN12_GLOBAL__N_14lockE, i64 0, i32 0, i32 0) release, align 1
-  %708 = load %"class.kotlin::gc::FinalizerProcessor"*, %"class.kotlin::gc::FinalizerProcessor"** %63, align 8, !tbaa !3
+  %709 = load atomic %"class.kotlin::gc::FinalizerProcessor"*, %"class.kotlin::gc::FinalizerProcessor"** %63 unordered, align 8, !tbaa !3
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %64) #37
-  %709 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %708, i64 0, i32 3
-  store %"class.std::recursive_mutex"* %709, %"class.std::recursive_mutex"** %65, align 8, !tbaa !257
-  store i8 0, i8* %66, align 8, !tbaa !259
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %710, label %716
+  %710 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %709, i64 0, i32 3
+  store %"class.std::recursive_mutex"* %710, %"class.std::recursive_mutex"** %65, align 8, !tbaa !255
+  store i8 0, i8* %66, align 8, !tbaa !257
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %711, label %717
 
-710:                                              ; preds = %_ZN6kotlin2gc8GCHandle8finishedEv.exit.i
-  %711 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %709, i64 0, i32 0, i32 0
-  %712 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull %711) #37
-  %713 = icmp eq i32 %712, 0
-  br i1 %713, label %716, label %714
+711:                                              ; preds = %_ZN6kotlin2gc8GCHandle8finishedEv.exit.i
+  %712 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %710, i64 0, i32 0, i32 0
+  %713 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull %712) #37
+  %714 = icmp eq i32 %713, 0
+  br i1 %714, label %717, label %715
 
-714:                                              ; preds = %710
-  invoke void @_ZSt20__throw_system_errori(i32 %712) #50
-          to label %715 unwind label %734
+715:                                              ; preds = %711
+  invoke void @_ZSt20__throw_system_errori(i32 %713) #50
+          to label %716 unwind label %735
 
-715:                                              ; preds = %714
+716:                                              ; preds = %715
   unreachable
 
-716:                                              ; preds = %710, %_ZN6kotlin2gc8GCHandle8finishedEv.exit.i
-  store i8 1, i8* %66, align 8, !tbaa !259
-  %717 = load i64, i64* %61, align 8, !tbaa !391
-  %718 = icmp eq i64 %717, 0
-  br i1 %718, label %719, label %749
+717:                                              ; preds = %711, %_ZN6kotlin2gc8GCHandle8finishedEv.exit.i
+  store i8 1, i8* %66, align 8, !tbaa !257
+  %718 = load atomic i64, i64* %61 unordered, align 8, !tbaa !393
+  %719 = icmp eq i64 %718, 0
+  br i1 %719, label %720, label %750
 
-719:                                              ; preds = %716
-  %720 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %708, i64 0, i32 0, i32 0, i32 0, i32 0
-  %721 = load i64, i64* %720, align 8, !tbaa.struct !88
-  %722 = icmp eq i64 %721, 0
-  br i1 %722, label %723, label %749
+720:                                              ; preds = %717
+  %721 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %709, i64 0, i32 0, i32 0, i32 0, i32 0
+  %722 = load atomic i64, i64* %721 unordered, align 8, !tbaa.struct !86
+  %723 = icmp eq i64 %722, 0
+  br i1 %723, label %724, label %750
 
-723:                                              ; preds = %719
+724:                                              ; preds = %720
   call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %96) #37
-  store i64 %103, i64* %7, align 8, !tbaa !89
-  %724 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %708, i64 0, i32 4, i32 0, i32 1
-  %725 = load i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %724, align 8, !tbaa !103
-  %726 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %725, null
-  br i1 %726, label %727, label %729
+  store i64 %103, i64* %7, align 8, !tbaa !87
+  %725 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %709, i64 0, i32 4, i32 0, i32 1
+  %726 = load atomic i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %725 unordered, align 8, !tbaa !101
+  %727 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %726, null
+  br i1 %727, label %728, label %730
 
-727:                                              ; preds = %723
+728:                                              ; preds = %724
   invoke void @_ZSt25__throw_bad_function_callv() #50
-          to label %728 unwind label %.loopexit.split-lp
+          to label %729 unwind label %.loopexit.split-lp
 
-728:                                              ; preds = %727
+729:                                              ; preds = %728
   unreachable
 
-729:                                              ; preds = %723
-  %730 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %708, i64 0, i32 4, i32 1
-  %731 = load void (%"union.std::_Any_data"*, i64*)*, void (%"union.std::_Any_data"*, i64*)** %730, align 8, !tbaa !392
-  %732 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %708, i64 0, i32 4, i32 0, i32 0
-  invoke void %731(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %732, i64* nonnull align 8 dereferenceable(8) %7)
-          to label %733 unwind label %.loopexit107
+730:                                              ; preds = %724
+  %731 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %709, i64 0, i32 4, i32 1
+  %732 = load atomic void (%"union.std::_Any_data"*, i64*)*, void (%"union.std::_Any_data"*, i64*)** %731 unordered, align 8, !tbaa !394
+  %733 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %709, i64 0, i32 4, i32 0, i32 0
+  invoke void %732(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %733, i64* nonnull align 8 dereferenceable(8) %7)
+          to label %734 unwind label %.loopexit101
 
-733:                                              ; preds = %729
+734:                                              ; preds = %730
   call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %96) #37
-  br label %883
+  br label %896
 
-734:                                              ; preds = %714
-  %735 = landingpad { i8*, i32 }
+735:                                              ; preds = %715
+  %736 = landingpad { i8*, i32 }
           catch i8* null
-  %736 = extractvalue { i8*, i32 } %735, 0
-  br label %894
+  %737 = extractvalue { i8*, i32 } %736, 0
+  br label %907
 
-.loopexit107:                                     ; preds = %729
+.loopexit101:                                     ; preds = %730
   %lpad.loopexit = landingpad { i8*, i32 }
           catch i8* null
-  br label %737
+  br label %738
 
-.loopexit.split-lp:                               ; preds = %727
+.loopexit.split-lp:                               ; preds = %728
   %lpad.loopexit.split-lp = landingpad { i8*, i32 }
           catch i8* null
-  br label %737
+  br label %738
 
-737:                                              ; preds = %.loopexit.split-lp, %.loopexit107
-  %lpad.phi = phi { i8*, i32 } [ %lpad.loopexit, %.loopexit107 ], [ %lpad.loopexit.split-lp, %.loopexit.split-lp ]
-  %738 = extractvalue { i8*, i32 } %lpad.phi, 0
-  %739 = load i8, i8* %66, align 8, !tbaa !259, !range !72
-  %740 = icmp eq i8 %739, 0
-  br i1 %740, label %894, label %741
+738:                                              ; preds = %.loopexit.split-lp, %.loopexit101
+  %lpad.phi = phi { i8*, i32 } [ %lpad.loopexit, %.loopexit101 ], [ %lpad.loopexit.split-lp, %.loopexit.split-lp ]
+  %739 = extractvalue { i8*, i32 } %lpad.phi, 0
+  %740 = load atomic i8, i8* %66 unordered, align 8, !tbaa !257, !range !70
+  %741 = icmp eq i8 %740, 0
+  br i1 %741, label %907, label %742
 
-741:                                              ; preds = %737
-  %742 = load %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %65, align 8, !tbaa !257
-  %743 = icmp eq %"class.std::recursive_mutex"* %742, null
-  br i1 %743, label %894, label %744
+742:                                              ; preds = %738
+  %743 = load atomic %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %65 unordered, align 8, !tbaa !255
+  %744 = icmp eq %"class.std::recursive_mutex"* %743, null
+  br i1 %744, label %907, label %745
 
-744:                                              ; preds = %741
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %745, label %748
+745:                                              ; preds = %742
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %746, label %749
 
-745:                                              ; preds = %744
-  %746 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %742, i64 0, i32 0, i32 0
-  %747 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %746) #37
-  br label %748
+746:                                              ; preds = %745
+  %747 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %743, i64 0, i32 0, i32 0
+  %748 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %747) #37
+  br label %749
 
-748:                                              ; preds = %745, %744
-  store i8 0, i8* %66, align 8, !tbaa !259
-  br label %894
+749:                                              ; preds = %746, %745
+  store i8 0, i8* %66, align 8, !tbaa !257
+  br label %907
 
-749:                                              ; preds = %719, %716
-  %750 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %708, i64 0, i32 2
-  %751 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %708, i64 0, i32 7
-  %752 = load i8, i8* %751, align 1, !tbaa !164, !range !72
-  %753 = icmp eq i8 %752, 0
-  br i1 %753, label %.preheader73, label %.loopexit74
+750:                                              ; preds = %720, %717
+  %751 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %709, i64 0, i32 2
+  %752 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %709, i64 0, i32 7
+  %753 = load atomic i8, i8* %752 unordered, align 1, !tbaa !162, !range !70
+  %754 = icmp eq i8 %753, 0
+  br i1 %754, label %.preheader67, label %.loopexit68
 
-.preheader73:                                     ; preds = %.preheader73, %749
-  call void @_ZNSt18condition_variable4waitERSt11unique_lockISt5mutexE(%"class.std::condition_variable"* nonnull %750, %"class.std::unique_lock.266"* nonnull align 8 dereferenceable(9) %8) #37
-  %754 = load i8, i8* %751, align 1, !tbaa !164, !range !72
-  %755 = icmp eq i8 %754, 0
-  br i1 %755, label %.preheader73, label %.loopexit74
+.preheader67:                                     ; preds = %.preheader67, %750
+  call void @_ZNSt18condition_variable4waitERSt11unique_lockISt5mutexE(%"class.std::condition_variable"* nonnull %751, %"class.std::unique_lock.266"* nonnull align 8 dereferenceable(9) %8) #37
+  %755 = load atomic i8, i8* %752 unordered, align 1, !tbaa !162, !range !70
+  %756 = icmp eq i8 %755, 0
+  br i1 %756, label %.preheader67, label %.loopexit68
 
-.loopexit74:                                      ; preds = %.preheader73, %749
-  %756 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %708, i64 0, i32 11
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %757, label %763
+.loopexit68:                                      ; preds = %.preheader67, %750
+  %757 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %709, i64 0, i32 11
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %758, label %764
 
-757:                                              ; preds = %.loopexit74
-  %758 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %756, i64 0, i32 0, i32 0
-  %759 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull %758) #37
-  %760 = icmp eq i32 %759, 0
-  br i1 %760, label %763, label %761
+758:                                              ; preds = %.loopexit68
+  %759 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %757, i64 0, i32 0, i32 0
+  %760 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull %759) #37
+  %761 = icmp eq i32 %760, 0
+  br i1 %761, label %764, label %762
 
-761:                                              ; preds = %757
-  invoke void @_ZSt20__throw_system_errori(i32 %759) #50
-          to label %762 unwind label %767
+762:                                              ; preds = %758
+  invoke void @_ZSt20__throw_system_errori(i32 %760) #50
+          to label %763 unwind label %768
 
-762:                                              ; preds = %761
+763:                                              ; preds = %762
   unreachable
 
-763:                                              ; preds = %757, %.loopexit74
-  %764 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %708, i64 0, i32 0, i32 0, i32 0, i32 0
-  %765 = load i64, i64* %764, align 8, !tbaa.struct !88
-  %766 = icmp eq i64 %765, 0
-  br i1 %766, label %770, label %841
+764:                                              ; preds = %758, %.loopexit68
+  %765 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %709, i64 0, i32 0, i32 0, i32 0, i32 0
+  %766 = load atomic i64, i64* %765 unordered, align 8, !tbaa.struct !86
+  %767 = icmp eq i64 %766, 0
+  br i1 %767, label %771, label %854
 
-767:                                              ; preds = %761
-  %768 = landingpad { i8*, i32 }
+768:                                              ; preds = %762
+  %769 = landingpad { i8*, i32 }
           catch i8* null
-  %769 = extractvalue { i8*, i32 } %768, 0
-  br label %853
+  %770 = extractvalue { i8*, i32 } %769, 0
+  br label %866
 
-770:                                              ; preds = %763
+771:                                              ; preds = %764
   call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %67) #37
   call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %68) #37
-  %771 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %6, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 1, i64 0
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %771, i8 0, i64 16, i1 false) #37
-  %772 = call noalias dereferenceable_or_null(23) i8* @calloc(i64 23, i64 1) #37
-  store i8* %772, i8** %71, align 8, !tbaa !58
-  store i64 22, i64* %72, align 8, !tbaa !51
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(22) %772, i8* nonnull align 1 dereferenceable(22) getelementptr inbounds ([23 x i8], [23 x i8]* @.str.14.346, i64 0, i64 0), i64 22, i1 false) #37
-  store i64 22, i64* %73, align 8, !tbaa !60
-  store i8 1, i8* %69, align 8, !tbaa !106
-  %773 = ptrtoint %"class.kotlin::gc::FinalizerProcessor"* %708 to i64
+  %772 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %6, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 1, i64 0
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %772, i8 0, i64 16, i1 false) #37
+  %773 = call noalias dereferenceable_or_null(23) i8* @calloc(i64 23, i64 1) #37
+  store i8* %773, i8** %71, align 8, !tbaa !47
+  store i64 22, i64* %72, align 8, !tbaa !50
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(22) %773, i8* nonnull align 1 dereferenceable(22) getelementptr inbounds ([23 x i8], [23 x i8]* @.str.14.346, i64 0, i64 0), i64 22, i1 false) #37
+  store i64 22, i64* %73, align 8, !tbaa !51
+  %774 = load atomic i8*, i8** %71 unordered, align 8, !tbaa !47
+  %775 = getelementptr inbounds i8, i8* %774, i64 22
+  store i8 0, i8* %775, align 1, !tbaa !50
+  store i8 1, i8* %69, align 8, !tbaa !104
+  %776 = ptrtoint %"class.kotlin::gc::FinalizerProcessor"* %709 to i64
   call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %75) #37
-  store i64 0, i64* %76, align 8, !tbaa !148
+  store i64 0, i64* %76, align 8, !tbaa !146
   call void @llvm.lifetime.start.p0i8(i64 56, i8* nonnull %77) #37
-  store i64 %773, i64* %78, align 8, !tbaa !3, !alias.scope !393
-  %774 = call noalias dereferenceable_or_null(23) i8* @calloc(i64 23, i64 1) #37
-  store i8* %774, i8** %81, align 8, !tbaa !58, !alias.scope !393
-  store i64 22, i64* %82, align 8, !tbaa !51, !alias.scope !393
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(22) %774, i8* nonnull align 1 dereferenceable(22) getelementptr inbounds ([23 x i8], [23 x i8]* @.str.14.346, i64 0, i64 0), i64 22, i1 false)
-  store i64 22, i64* %83, align 8, !tbaa !60, !alias.scope !393
-  store i8 1, i8* %79, align 8, !tbaa !112, !alias.scope !393
-  store i64 ptrtoint (void (%"class.kotlin::ScopedThread::attributes"*, %"struct.std::_Head_base.21"*)* @"_ZN6kotlin12ScopedThread3RunIZNS_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0JEEENSt13invoke_resultIT_JDpT0_EE4typeENS0_10attributesEOS6_DpOS7_" to i64), i64* %85, align 8, !tbaa !396, !alias.scope !393
-  %775 = invoke noalias nonnull dereferenceable(64) i8* @_Znwm(i64 64) #53
-          to label %776 unwind label %.thread215
+  store i64 %776, i64* %78, align 8, !tbaa !3, !alias.scope !395
+  store i8 0, i8* %79, align 8, !tbaa !110, !alias.scope !395
+  %777 = call noalias dereferenceable_or_null(23) i8* @calloc(i64 23, i64 1) #37
+  store i8* %777, i8** %81, align 8, !tbaa !47, !alias.scope !395
+  store i64 22, i64* %82, align 8, !tbaa !50, !alias.scope !395
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(22) %777, i8* nonnull align 1 dereferenceable(22) %774, i64 22, i1 false) #37
+  store i64 22, i64* %83, align 8, !tbaa !51, !alias.scope !395
+  %778 = load atomic i8*, i8** %81 unordered, align 8, !tbaa !47, !alias.scope !395
+  %779 = getelementptr inbounds i8, i8* %778, i64 22
+  store i8 0, i8* %779, align 1, !tbaa !50
+  store i8 1, i8* %79, align 8, !tbaa !110, !alias.scope !395
+  store i64 ptrtoint (void (%"class.kotlin::ScopedThread::attributes"*, %"struct.std::_Head_base.21"*)* @"_ZN6kotlin12ScopedThread3RunIZNS_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0JEEENSt13invoke_resultIT_JDpT0_EE4typeENS0_10attributesEOS6_DpOS7_" to i64), i64* %85, align 8, !tbaa !398, !alias.scope !395
+  %780 = invoke noalias nonnull dereferenceable(64) i8* @_Znwm(i64 64) #53
+          to label %781 unwind label %816
 
-776:                                              ; preds = %770
-  %777 = bitcast i8* %775 to i32 (...)***
-  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @"_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0ES5_S8_EEEEEE", i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %777, align 8, !tbaa !109, !noalias !398
-  %778 = getelementptr inbounds i8, i8* %775, i64 8
-  %779 = bitcast i8* %778 to i64*
-  store i64 %773, i64* %779, align 8, !tbaa !3, !noalias !398
-  %780 = getelementptr inbounds i8, i8* %775, i64 48
-  store i8 0, i8* %780, align 8, !tbaa !112, !noalias !398
-  %781 = getelementptr inbounds i8, i8* %775, i64 16
-  %782 = getelementptr inbounds i8, i8* %775, i64 32
-  %783 = bitcast i8* %781 to i8**
-  store i8* %774, i8** %783, align 8, !tbaa !58, !noalias !398
-  %784 = bitcast i8* %782 to i64*
-  store i64 22, i64* %784, align 8, !tbaa !51, !noalias !398
-  %785 = getelementptr inbounds i8, i8* %775, i64 24
-  %786 = bitcast i8* %785 to i64*
-  store i64 22, i64* %786, align 8, !tbaa !60, !noalias !398
-  store %union.anon.108* %80, %union.anon.108** %88, align 8, !tbaa !58, !noalias !398
-  store i64 0, i64* %83, align 8, !tbaa !60, !noalias !398
-  store i8 0, i8* %87, align 8, !tbaa !51, !noalias !398
-  store i8 1, i8* %780, align 8, !tbaa !112, !noalias !398
-  %787 = getelementptr inbounds i8, i8* %775, i64 56
-  %788 = bitcast i8* %787 to i64*
-  store i64 ptrtoint (void (%"class.kotlin::ScopedThread::attributes"*, %"struct.std::_Head_base.21"*)* @"_ZN6kotlin12ScopedThread3RunIZNS_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0JEEENSt13invoke_resultIT_JDpT0_EE4typeENS0_10attributesEOS6_DpOS7_" to i64), i64* %788, align 8, !tbaa !396, !noalias !398
-  store i8* %775, i8** %89, align 8, !tbaa !3, !alias.scope !398
+781:                                              ; preds = %771
+  %782 = bitcast i8* %780 to i32 (...)***
+  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @"_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0ES5_S8_EEEEEE", i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %782, align 8, !tbaa !107, !noalias !400
+  %783 = getelementptr inbounds i8, i8* %780, i64 8
+  %784 = bitcast i8* %783 to i64*
+  %785 = load atomic i64, i64* %78 unordered, align 8, !tbaa !3, !noalias !400
+  store i64 %785, i64* %784, align 8, !tbaa !3, !noalias !400
+  %786 = getelementptr inbounds i8, i8* %780, i64 48
+  store i8 0, i8* %786, align 8, !tbaa !110, !noalias !400
+  %787 = getelementptr inbounds i8, i8* %780, i64 16
+  %788 = getelementptr inbounds i8, i8* %780, i64 32
+  %789 = bitcast i8* %787 to i8**
+  store i8* %788, i8** %789, align 8, !tbaa !45, !noalias !400
+  %790 = icmp eq i8* %778, %87
+  br i1 %790, label %791, label %792
+
+791:                                              ; preds = %781
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 1 dereferenceable(16) %788, i8* nonnull align 8 dereferenceable(16) %87, i64 16, i1 false) #37, !noalias !400
+  br label %795
+
+792:                                              ; preds = %781
+  store i8* %778, i8** %789, align 8, !tbaa !47, !noalias !400
+  %793 = load atomic i64, i64* %82 unordered, align 8, !tbaa !50, !noalias !400
+  %794 = bitcast i8* %788 to i64*
+  store i64 %793, i64* %794, align 8, !tbaa !50, !noalias !400
+  br label %795
+
+795:                                              ; preds = %792, %791
+  %796 = load atomic i64, i64* %83 unordered, align 8, !tbaa !51, !noalias !400
+  %797 = getelementptr inbounds i8, i8* %780, i64 24
+  %798 = bitcast i8* %797 to i64*
+  store i64 %796, i64* %798, align 8, !tbaa !51, !noalias !400
+  store %union.anon.108* %80, %union.anon.108** %88, align 8, !tbaa !47, !noalias !400
+  store i64 0, i64* %83, align 8, !tbaa !51, !noalias !400
+  store i8 0, i8* %87, align 8, !tbaa !50, !noalias !400
+  store i8 1, i8* %786, align 8, !tbaa !110, !noalias !400
+  %799 = getelementptr inbounds i8, i8* %780, i64 56
+  %800 = bitcast i8* %799 to i64*
+  store i64 ptrtoint (void (%"class.kotlin::ScopedThread::attributes"*, %"struct.std::_Head_base.21"*)* @"_ZN6kotlin12ScopedThread3RunIZNS_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0JEEENSt13invoke_resultIT_JDpT0_EE4typeENS0_10attributesEOS6_DpOS7_" to i64), i64* %800, align 8, !tbaa !398, !noalias !400
+  store i8* %780, i8** %89, align 8, !tbaa !3, !alias.scope !400
   invoke void @_ZNSt6thread15_M_start_threadESt10unique_ptrINS_6_StateESt14default_deleteIS1_EEPFvvE(%"struct.std::atomic.0"* nonnull %74, %"class.std::unique_ptr"* nonnull %3, void ()* bitcast (i32 (i64*, %union.pthread_attr_t*, i8* (i8*)*, i8*)* @pthread_create to void ()*))
-          to label %789 unwind label %806
+          to label %801 unwind label %819
 
-789:                                              ; preds = %776
-  %790 = load %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %90, align 8, !tbaa !3
-  %791 = icmp eq %"class.kotlin::gc::GC::ThreadData::Impl"* %790, null
-  br i1 %791, label %797, label %792
+801:                                              ; preds = %795
+  %802 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %90 unordered, align 8, !tbaa !3
+  %803 = icmp eq %"class.kotlin::gc::GC::ThreadData::Impl"* %802, null
+  br i1 %803, label %809, label %804
 
-792:                                              ; preds = %789
-  %793 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %790 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*)***
-  %794 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %793, align 8, !tbaa !109
-  %795 = getelementptr inbounds void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %794, i64 1
-  %796 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %795, align 8
-  call void %796(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %790) #37
-  br label %797
+804:                                              ; preds = %801
+  %805 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %802 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*)***
+  %806 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %805 unordered, align 8, !tbaa !107
+  %807 = getelementptr inbounds void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %806, i64 1
+  %808 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %807 unordered, align 8
+  call void %808(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %802) #37
+  br label %809
 
-797:                                              ; preds = %792, %789
+809:                                              ; preds = %804, %801
   store %"class.kotlin::gc::GC::ThreadData::Impl"* null, %"class.kotlin::gc::GC::ThreadData::Impl"** %90, align 8, !tbaa !3
-  %798 = load i8, i8* %79, align 8, !tbaa !112, !range !72
-  %799 = icmp eq i8 %798, 0
-  br i1 %799, label %828, label %800
+  %810 = load atomic i8, i8* %79 unordered, align 8, !tbaa !110, !range !70
+  %811 = icmp eq i8 %810, 0
+  br i1 %811, label %841, label %812
 
-800:                                              ; preds = %797
-  %801 = load i8*, i8** %91, align 8, !tbaa !58
-  %802 = icmp eq i8* %801, %87
-  br i1 %802, label %828, label %803
+812:                                              ; preds = %809
+  %813 = load atomic i8*, i8** %91 unordered, align 8, !tbaa !47
+  %814 = icmp eq i8* %813, %87
+  br i1 %814, label %841, label %815
 
-803:                                              ; preds = %800
-  call void @free(i8* %801) #37
-  br label %828
+815:                                              ; preds = %812
+  call void @free(i8* %813) #37
+  br label %841
 
-.thread215:                                       ; preds = %770
-  %804 = landingpad { i8*, i32 }
+816:                                              ; preds = %771
+  %817 = landingpad { i8*, i32 }
           catch i8* null
-  %805 = extractvalue { i8*, i32 } %804, 0
-  br label %821
+  %818 = extractvalue { i8*, i32 } %817, 0
+  br label %832
 
-806:                                              ; preds = %776
-  %807 = landingpad { i8*, i32 }
+819:                                              ; preds = %795
+  %820 = landingpad { i8*, i32 }
           catch i8* null
-  %808 = extractvalue { i8*, i32 } %807, 0
-  %809 = load %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %90, align 8, !tbaa !3
-  %810 = icmp eq %"class.kotlin::gc::GC::ThreadData::Impl"* %809, null
-  br i1 %810, label %816, label %811
+  %821 = extractvalue { i8*, i32 } %820, 0
+  %822 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %90 unordered, align 8, !tbaa !3
+  %823 = icmp eq %"class.kotlin::gc::GC::ThreadData::Impl"* %822, null
+  br i1 %823, label %829, label %824
 
-811:                                              ; preds = %806
-  %812 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %809 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*)***
-  %813 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %812, align 8, !tbaa !109
-  %814 = getelementptr inbounds void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %813, i64 1
-  %815 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %814, align 8
-  call void %815(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %809) #37
-  br label %816
+824:                                              ; preds = %819
+  %825 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %822 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*)***
+  %826 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*** %825 unordered, align 8, !tbaa !107
+  %827 = getelementptr inbounds void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %826, i64 1
+  %828 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*)** %827 unordered, align 8
+  call void %828(%"class.kotlin::gc::GC::ThreadData::Impl"* nonnull %822) #37
+  br label %829
 
-816:                                              ; preds = %811, %806
+829:                                              ; preds = %824, %819
   store %"class.kotlin::gc::GC::ThreadData::Impl"* null, %"class.kotlin::gc::GC::ThreadData::Impl"** %90, align 8, !tbaa !3
-  %817 = load i8, i8* %79, align 8, !tbaa !112, !range !72
-  %818 = icmp eq i8 %817, 0
-  br i1 %818, label %824, label %819
+  %830 = load atomic i8, i8* %79 unordered, align 8, !tbaa !110, !range !70
+  %831 = icmp eq i8 %830, 0
+  br i1 %831, label %837, label %._crit_edge184
 
-819:                                              ; preds = %816
-  %.pre = load i8*, i8** %91, align 8, !tbaa !58
-  %820 = icmp eq i8* %.pre, %87
-  br i1 %820, label %824, label %821
+._crit_edge184:                                   ; preds = %829
+  %.pre185 = load atomic i8*, i8** %91 unordered, align 8, !tbaa !47
+  br label %832
 
-821:                                              ; preds = %819, %.thread215
-  %822 = phi i8* [ %805, %.thread215 ], [ %808, %819 ]
-  %823 = phi i8* [ %774, %.thread215 ], [ %.pre, %819 ]
-  call void @free(i8* %823) #37
-  br label %824
+832:                                              ; preds = %._crit_edge184, %816
+  %833 = phi i8* [ %778, %816 ], [ %.pre185, %._crit_edge184 ]
+  %834 = phi i8* [ %818, %816 ], [ %821, %._crit_edge184 ]
+  %835 = icmp eq i8* %833, %87
+  br i1 %835, label %837, label %836
 
-824:                                              ; preds = %821, %819, %816
-  %825 = phi i8* [ %822, %821 ], [ %808, %819 ], [ %808, %816 ]
+836:                                              ; preds = %832
+  call void @free(i8* %833) #37
+  br label %837
+
+837:                                              ; preds = %836, %832, %829
+  %838 = phi i8* [ %834, %836 ], [ %834, %832 ], [ %821, %829 ]
   call void @llvm.lifetime.end.p0i8(i64 56, i8* nonnull %77) #37
-  %826 = load i8, i8* %69, align 8, !tbaa !112, !range !72
-  %827 = icmp eq i8 %826, 0
-  br i1 %827, label %849, label %845
+  %839 = load atomic i8, i8* %69 unordered, align 8, !tbaa !110, !range !70
+  %840 = icmp eq i8 %839, 0
+  br i1 %840, label %862, label %858
 
-828:                                              ; preds = %803, %800, %797
+841:                                              ; preds = %815, %812, %809
   call void @llvm.lifetime.end.p0i8(i64 56, i8* nonnull %77) #37
   call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %75) #37
-  %829 = load i64, i64* %764, align 8, !tbaa.struct !88
-  %830 = icmp eq i64 %829, 0
-  br i1 %830, label %832, label %831
+  %842 = load atomic i64, i64* %765 unordered, align 8, !tbaa.struct !86
+  %843 = icmp eq i64 %842, 0
+  br i1 %843, label %845, label %844
 
-831:                                              ; preds = %828
+844:                                              ; preds = %841
   call void @_ZSt9terminatev() #51
   unreachable
 
-832:                                              ; preds = %828
-  %833 = load i64, i64* %76, align 8, !tbaa !89
-  store i64 %833, i64* %764, align 8, !tbaa !89
-  store i64 0, i64* %76, align 8, !tbaa !89
-  %834 = load i8, i8* %69, align 8, !tbaa !112, !range !72
-  %835 = icmp eq i8 %834, 0
-  br i1 %835, label %840, label %836
+845:                                              ; preds = %841
+  %846 = load atomic i64, i64* %76 unordered, align 8, !tbaa !87
+  store i64 %846, i64* %765, align 8, !tbaa !87
+  store i64 0, i64* %76, align 8, !tbaa !87
+  %847 = load atomic i8, i8* %69 unordered, align 8, !tbaa !110, !range !70
+  %848 = icmp eq i8 %847, 0
+  br i1 %848, label %853, label %849
 
-836:                                              ; preds = %832
-  %837 = load i8*, i8** %71, align 8, !tbaa !58
-  %838 = icmp eq i8* %837, %92
-  br i1 %838, label %840, label %839
+849:                                              ; preds = %845
+  %850 = load atomic i8*, i8** %71 unordered, align 8, !tbaa !47
+  %851 = icmp eq i8* %850, %92
+  br i1 %851, label %853, label %852
 
-839:                                              ; preds = %836
-  call void @free(i8* %837) #37
-  br label %840
+852:                                              ; preds = %849
+  call void @free(i8* %850) #37
+  br label %853
 
-840:                                              ; preds = %839, %836, %832
+853:                                              ; preds = %852, %849, %845
   call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %68) #37
   call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %67) #37
-  br label %841
+  br label %854
 
-841:                                              ; preds = %840, %763
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %842, label %_ZN6kotlin2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEv.exit.i.i
+854:                                              ; preds = %853, %764
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %855, label %_ZN6kotlin2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEv.exit.i.i
 
-842:                                              ; preds = %841
-  %843 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %756, i64 0, i32 0, i32 0
-  %844 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %843) #37
+855:                                              ; preds = %854
+  %856 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %757, i64 0, i32 0, i32 0
+  %857 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %856) #37
   br label %_ZN6kotlin2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEv.exit.i.i
 
-845:                                              ; preds = %824
-  %846 = load i8*, i8** %71, align 8, !tbaa !58
-  %847 = icmp eq i8* %846, %92
-  br i1 %847, label %849, label %848
+858:                                              ; preds = %837
+  %859 = load atomic i8*, i8** %71 unordered, align 8, !tbaa !47
+  %860 = icmp eq i8* %859, %92
+  br i1 %860, label %862, label %861
 
-848:                                              ; preds = %845
-  call void @free(i8* %846) #37
-  br label %849
+861:                                              ; preds = %858
+  call void @free(i8* %859) #37
+  br label %862
 
-849:                                              ; preds = %848, %845, %824
+862:                                              ; preds = %861, %858, %837
   call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %68) #37
   call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %67) #37
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %850, label %853
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %863, label %866
 
-850:                                              ; preds = %849
-  %851 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %756, i64 0, i32 0, i32 0
-  %852 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %851) #37
-  br label %853
+863:                                              ; preds = %862
+  %864 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %757, i64 0, i32 0, i32 0
+  %865 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %864) #37
+  br label %866
 
-853:                                              ; preds = %850, %849, %767
-  %854 = phi i8* [ %769, %767 ], [ %825, %849 ], [ %825, %850 ]
-  call fastcc void @__clang_call_terminate(i8* %854) #51
+866:                                              ; preds = %863, %862, %768
+  %867 = phi i8* [ %770, %768 ], [ %838, %862 ], [ %838, %863 ]
+  call fastcc void @__clang_call_terminate(i8* %867) #51
   unreachable
 
-_ZN6kotlin2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEv.exit.i.i: ; preds = %842, %841
-  %855 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %708, i64 0, i32 1, i32 1
-  %856 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %93, align 8, !tbaa !3
-  %857 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %856, null
-  %858 = ptrtoint %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %856 to i64
-  br i1 %857, label %_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Consumer9MergeWithEOSA_.exit.i.i, label %859
+_ZN6kotlin2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEv.exit.i.i: ; preds = %855, %854
+  %868 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %709, i64 0, i32 1, i32 1
+  %869 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %93 unordered, align 8, !tbaa !3
+  %870 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %869, null
+  %871 = ptrtoint %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %869 to i64
+  br i1 %870, label %_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Consumer9MergeWithEOSA_.exit.i.i, label %872
 
-859:                                              ; preds = %_ZN6kotlin2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEv.exit.i.i
-  %860 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer"* %855, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %861 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %860, align 8, !tbaa !3
-  %862 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %861, null
-  br i1 %862, label %863, label %865
+872:                                              ; preds = %_ZN6kotlin2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEv.exit.i.i
+  %873 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer"* %868, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %874 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %873 unordered, align 8, !tbaa !3
+  %875 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %874, null
+  br i1 %875, label %876, label %878
 
-863:                                              ; preds = %859
+876:                                              ; preds = %872
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %93, align 8, !tbaa !3
-  %864 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer"* %855 to i64*
-  store i64 %858, i64* %864, align 8, !tbaa !3
-  br label %875
+  %877 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Consumer"* %868 to i64*
+  store i64 %871, i64* %877, align 8, !tbaa !3
+  br label %888
 
-865:                                              ; preds = %859
-  %866 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %708, i64 0, i32 1, i32 1, i32 1
-  %867 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %866, align 8, !tbaa !390
+878:                                              ; preds = %872
+  %879 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %709, i64 0, i32 1, i32 1, i32 1
+  %880 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %879 unordered, align 8, !tbaa !392
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %93, align 8, !tbaa !3
-  %868 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %867 to i64*
-  %869 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %867, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %870 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %869, align 8, !tbaa !3
-  store i64 %858, i64* %868, align 8, !tbaa !3
-  %871 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %870, null
-  br i1 %871, label %875, label %872
+  %881 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %880 to i64*
+  %882 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %880, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %883 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %882 unordered, align 8, !tbaa !3
+  store i64 %871, i64* %881, align 8, !tbaa !3
+  %884 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %883, null
+  br i1 %884, label %888, label %885
 
-872:                                              ; preds = %865
-  %873 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %870, i64 0, i32 0
-  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %873) #37
-  %874 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %870 to i8*
-  call fastcc void @mi_free(i8* nonnull %874) #37
-  br label %875
+885:                                              ; preds = %878
+  %886 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %883, i64 0, i32 0
+  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %886) #37
+  %887 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %883 to i8*
+  call fastcc void @mi_free(i8* nonnull %887) #37
+  br label %888
 
-875:                                              ; preds = %872, %865, %863
-  %876 = load i64, i64* %94, align 8, !tbaa !390
-  %877 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %708, i64 0, i32 1, i32 1, i32 1
-  %878 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %877 to i64*
-  store i64 %876, i64* %878, align 8, !tbaa !390
-  %879 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %708, i64 0, i32 1, i32 1, i32 2
-  %880 = load i64, i64* %879, align 8, !tbaa !391
-  %881 = add i64 %880, %717
-  store i64 %881, i64* %879, align 8, !tbaa !391
+888:                                              ; preds = %885, %878, %876
+  %889 = load atomic i64, i64* %94 unordered, align 8, !tbaa !392
+  %890 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %709, i64 0, i32 1, i32 1, i32 1
+  %891 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %890 to i64*
+  store i64 %889, i64* %891, align 8, !tbaa !392
+  %892 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %709, i64 0, i32 1, i32 1, i32 2
+  %893 = load atomic i64, i64* %892 unordered, align 8, !tbaa !393
+  %894 = add i64 %893, %718
+  store i64 %894, i64* %892, align 8, !tbaa !393
   call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %95, i8 0, i64 16, i1 false) #37
   br label %_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Consumer9MergeWithEOSA_.exit.i.i
 
-_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Consumer9MergeWithEOSA_.exit.i.i: ; preds = %875, %_ZN6kotlin2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEv.exit.i.i
-  %882 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %708, i64 0, i32 5
-  store i64 %103, i64* %882, align 8, !tbaa !155
-  call void @_ZNSt18condition_variable10notify_allEv(%"class.std::condition_variable"* nonnull %750) #37
-  br label %883
+_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Consumer9MergeWithEOSA_.exit.i.i: ; preds = %888, %_ZN6kotlin2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEv.exit.i.i
+  %895 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %709, i64 0, i32 5
+  store i64 %103, i64* %895, align 8, !tbaa !153
+  call void @_ZNSt18condition_variable10notify_allEv(%"class.std::condition_variable"* nonnull %751) #37
+  br label %896
 
-883:                                              ; preds = %_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Consumer9MergeWithEOSA_.exit.i.i, %733
-  %884 = load i8, i8* %66, align 8, !tbaa !259, !range !72
-  %885 = icmp eq i8 %884, 0
-  br i1 %885, label %_ZN6kotlin2gc18FinalizerProcessor13ScheduleTasksEONS_2mm13ObjectFactoryINS0_22ConcurrentMarkAndSweepEE14FinalizerQueueEl.exit.i, label %886
+896:                                              ; preds = %_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Consumer9MergeWithEOSA_.exit.i.i, %734
+  %897 = load atomic i8, i8* %66 unordered, align 8, !tbaa !257, !range !70
+  %898 = icmp eq i8 %897, 0
+  br i1 %898, label %_ZN6kotlin2gc18FinalizerProcessor13ScheduleTasksEONS_2mm13ObjectFactoryINS0_22ConcurrentMarkAndSweepEE14FinalizerQueueEl.exit.i, label %899
 
-886:                                              ; preds = %883
-  %887 = load %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %65, align 8, !tbaa !257
-  %888 = icmp eq %"class.std::recursive_mutex"* %887, null
-  br i1 %888, label %_ZN6kotlin2gc18FinalizerProcessor13ScheduleTasksEONS_2mm13ObjectFactoryINS0_22ConcurrentMarkAndSweepEE14FinalizerQueueEl.exit.i, label %889
+899:                                              ; preds = %896
+  %900 = load atomic %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %65 unordered, align 8, !tbaa !255
+  %901 = icmp eq %"class.std::recursive_mutex"* %900, null
+  br i1 %901, label %_ZN6kotlin2gc18FinalizerProcessor13ScheduleTasksEONS_2mm13ObjectFactoryINS0_22ConcurrentMarkAndSweepEE14FinalizerQueueEl.exit.i, label %902
 
-889:                                              ; preds = %886
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %890, label %893
+902:                                              ; preds = %899
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %903, label %906
 
-890:                                              ; preds = %889
-  %891 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %887, i64 0, i32 0, i32 0
-  %892 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %891) #37
-  br label %893
+903:                                              ; preds = %902
+  %904 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %900, i64 0, i32 0, i32 0
+  %905 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %904) #37
+  br label %906
 
-893:                                              ; preds = %890, %889
-  store i8 0, i8* %66, align 8, !tbaa !259
+906:                                              ; preds = %903, %902
+  store i8 0, i8* %66, align 8, !tbaa !257
   br label %_ZN6kotlin2gc18FinalizerProcessor13ScheduleTasksEONS_2mm13ObjectFactoryINS0_22ConcurrentMarkAndSweepEE14FinalizerQueueEl.exit.i
 
-894:                                              ; preds = %748, %741, %737, %734
-  %895 = phi i8* [ %736, %734 ], [ %738, %737 ], [ %738, %741 ], [ %738, %748 ]
+907:                                              ; preds = %749, %742, %738, %735
+  %908 = phi i8* [ %737, %735 ], [ %739, %738 ], [ %739, %742 ], [ %739, %749 ]
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %64) #37
-  call fastcc void @__clang_call_terminate(i8* %895) #51
+  call fastcc void @__clang_call_terminate(i8* %908) #51
   unreachable
 
-_ZN6kotlin2gc18FinalizerProcessor13ScheduleTasksEONS_2mm13ObjectFactoryINS0_22ConcurrentMarkAndSweepEE14FinalizerQueueEl.exit.i: ; preds = %893, %886, %883
+_ZN6kotlin2gc18FinalizerProcessor13ScheduleTasksEONS_2mm13ObjectFactoryINS0_22ConcurrentMarkAndSweepEE14FinalizerQueueEl.exit.i: ; preds = %906, %899, %896
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %64) #37
   call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %97) #37
-  %896 = load i64, i64* %60, align 8, !tbaa !3
+  %909 = load atomic i64, i64* %60 unordered, align 8, !tbaa !3
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %57, align 8, !tbaa !3
-  store i64 %896, i64* %98, align 8, !tbaa !198
-  %897 = icmp eq i64 %896, 0
-  br i1 %897, label %.loopexit72, label %.preheader71
+  store i64 %909, i64* %98, align 8, !tbaa !197
+  %910 = icmp eq i64 %909, 0
+  br i1 %910, label %.loopexit66, label %.preheader65
 
-.preheader71:                                     ; preds = %908, %_ZN6kotlin2gc18FinalizerProcessor13ScheduleTasksEONS_2mm13ObjectFactoryINS0_22ConcurrentMarkAndSweepEE14FinalizerQueueEl.exit.i
-  %898 = phi i64 [ %902, %908 ], [ %896, %_ZN6kotlin2gc18FinalizerProcessor13ScheduleTasksEONS_2mm13ObjectFactoryINS0_22ConcurrentMarkAndSweepEE14FinalizerQueueEl.exit.i ]
-  %899 = inttoptr i64 %898 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
-  %900 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %899, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %901 = inttoptr i64 %898 to i64*
-  %902 = load i64, i64* %901, align 8, !tbaa !3
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %900, align 8, !tbaa !3
-  %903 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %99, align 8, !tbaa !3
-  store i64 %902, i64* %98, align 8, !tbaa !3
-  %904 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %903, null
-  br i1 %904, label %908, label %905
+.preheader65:                                     ; preds = %921, %_ZN6kotlin2gc18FinalizerProcessor13ScheduleTasksEONS_2mm13ObjectFactoryINS0_22ConcurrentMarkAndSweepEE14FinalizerQueueEl.exit.i
+  %911 = phi i64 [ %915, %921 ], [ %909, %_ZN6kotlin2gc18FinalizerProcessor13ScheduleTasksEONS_2mm13ObjectFactoryINS0_22ConcurrentMarkAndSweepEE14FinalizerQueueEl.exit.i ]
+  %912 = inttoptr i64 %911 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
+  %913 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %912, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %914 = inttoptr i64 %911 to i64*
+  %915 = load atomic i64, i64* %914 unordered, align 8, !tbaa !3
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %913, align 8, !tbaa !3
+  %916 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %99 unordered, align 8, !tbaa !3
+  store i64 %915, i64* %98, align 8, !tbaa !3
+  %917 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %916, null
+  br i1 %917, label %921, label %918
 
-905:                                              ; preds = %.preheader71
-  %906 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %903, i64 0, i32 0
-  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %906) #37
-  %907 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %903 to i8*
-  call fastcc void @mi_free(i8* nonnull %907) #37
-  br label %908
+918:                                              ; preds = %.preheader65
+  %919 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %916, i64 0, i32 0
+  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %919) #37
+  %920 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %916 to i8*
+  call fastcc void @mi_free(i8* nonnull %920) #37
+  br label %921
 
-908:                                              ; preds = %905, %.preheader71
-  %909 = icmp eq i64 %902, 0
-  br i1 %909, label %.loopexit72, label %.preheader71
+921:                                              ; preds = %918, %.preheader65
+  %922 = icmp eq i64 %915, 0
+  br i1 %922, label %.loopexit66, label %.preheader65
 
-.loopexit72:                                      ; preds = %908, %_ZN6kotlin2gc18FinalizerProcessor13ScheduleTasksEONS_2mm13ObjectFactoryINS0_22ConcurrentMarkAndSweepEE14FinalizerQueueEl.exit.i
+.loopexit66:                                      ; preds = %921, %_ZN6kotlin2gc18FinalizerProcessor13ScheduleTasksEONS_2mm13ObjectFactoryINS0_22ConcurrentMarkAndSweepEE14FinalizerQueueEl.exit.i
   call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %13) #37
   call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %97) #37
   call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %100) #37
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %42) #37
   store atomic i8 0, i8* %489 release, align 1
-  %910 = tail call fastcc nonnull align 8 dereferenceable(8) i64* @_ZN13GCStateHolder16ValueWithCondVarIlE4waitIZNS_13waitScheduledEvEUlvE_EERKlT_(%"struct.GCStateHolder::ValueWithCondVar"* nonnull %27, %class.GCStateHolder* nonnull %26)
-  %911 = load i8, i8* %29, align 8, !tbaa !146, !range !72
-  %912 = icmp eq i8 %911, 1
-  br i1 %912, label %.loopexit108, label %101
+  %923 = tail call fastcc nonnull align 8 dereferenceable(8) i64* @_ZN13GCStateHolder16ValueWithCondVarIlE4waitIZNS_13waitScheduledEvEUlvE_EERKlT_(%"struct.GCStateHolder::ValueWithCondVar"* nonnull %27, %class.GCStateHolder* nonnull %26)
+  %924 = load atomic i8, i8* %29 unordered, align 8, !tbaa !144, !range !70
+  %925 = icmp eq i8 %924, 1
+  br i1 %925, label %.loopexit102, label %101
 
-913:                                              ; preds = %_ZN6kotlin2gc8GCHandle19threadsAreSuspendedEv.exit.i
-  %914 = landingpad { i8*, i32 }
+926:                                              ; preds = %_ZN6kotlin2gc8GCHandle19threadsAreSuspendedEv.exit.i
+  %927 = landingpad { i8*, i32 }
           catch i8* null
-  %915 = extractvalue { i8*, i32 } %914, 0
-  br label %936
+  %928 = extractvalue { i8*, i32 } %927, 0
+  br label %949
 
-916:                                              ; preds = %_ZN6kotlin2gc8GCHandle12GCSweepScopeD2Ev.exit.i
-  %917 = landingpad { i8*, i32 }
+929:                                              ; preds = %_ZN6kotlin2gc8GCHandle12GCSweepScopeD2Ev.exit.i
+  %930 = landingpad { i8*, i32 }
           catch i8* null
-  %918 = extractvalue { i8*, i32 } %917, 0
-  %919 = bitcast %"class.std::unique_ptr.112"* %14 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %919) #37
-  %920 = load i64, i64* %60, align 8, !tbaa !3
+  %931 = extractvalue { i8*, i32 } %930, 0
+  %932 = bitcast %"class.std::unique_ptr.112"* %14 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %932) #37
+  %933 = load atomic i64, i64* %60 unordered, align 8, !tbaa !3
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %57, align 8, !tbaa !3
-  %921 = bitcast %"class.std::unique_ptr.112"* %14 to i64*
-  store i64 %920, i64* %921, align 8, !tbaa !198
-  %922 = getelementptr inbounds %"class.std::unique_ptr.112", %"class.std::unique_ptr.112"* %14, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %923 = icmp eq i64 %920, 0
-  br i1 %923, label %.loopexit, label %.preheader
+  %934 = bitcast %"class.std::unique_ptr.112"* %14 to i64*
+  store i64 %933, i64* %934, align 8, !tbaa !197
+  %935 = getelementptr inbounds %"class.std::unique_ptr.112", %"class.std::unique_ptr.112"* %14, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %936 = icmp eq i64 %933, 0
+  br i1 %936, label %.loopexit, label %.preheader
 
-.preheader:                                       ; preds = %934, %916
-  %924 = phi i64 [ %928, %934 ], [ %920, %916 ]
-  %925 = inttoptr i64 %924 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
-  %926 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %925, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %927 = inttoptr i64 %924 to i64*
-  %928 = load i64, i64* %927, align 8, !tbaa !3
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %926, align 8, !tbaa !3
-  %929 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %922, align 8, !tbaa !3
-  store i64 %928, i64* %921, align 8, !tbaa !3
-  %930 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %929, null
-  br i1 %930, label %934, label %931
+.preheader:                                       ; preds = %947, %929
+  %937 = phi i64 [ %941, %947 ], [ %933, %929 ]
+  %938 = inttoptr i64 %937 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
+  %939 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %938, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %940 = inttoptr i64 %937 to i64*
+  %941 = load atomic i64, i64* %940 unordered, align 8, !tbaa !3
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %939, align 8, !tbaa !3
+  %942 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %935 unordered, align 8, !tbaa !3
+  store i64 %941, i64* %934, align 8, !tbaa !3
+  %943 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %942, null
+  br i1 %943, label %947, label %944
 
-931:                                              ; preds = %.preheader
-  %932 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %929, i64 0, i32 0
-  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %932) #37
-  %933 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %929 to i8*
-  call fastcc void @mi_free(i8* nonnull %933) #37
-  br label %934
+944:                                              ; preds = %.preheader
+  %945 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %942, i64 0, i32 0
+  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %945) #37
+  %946 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %942 to i8*
+  call fastcc void @mi_free(i8* nonnull %946) #37
+  br label %947
 
-934:                                              ; preds = %931, %.preheader
-  %935 = icmp eq i64 %928, 0
-  br i1 %935, label %.loopexit, label %.preheader
+947:                                              ; preds = %944, %.preheader
+  %948 = icmp eq i64 %941, 0
+  br i1 %948, label %.loopexit, label %.preheader
 
-.loopexit:                                        ; preds = %934, %916
+.loopexit:                                        ; preds = %947, %929
   call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %14) #37
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %919) #37
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %932) #37
   call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %100) #37
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %42) #37
   store atomic i8 0, i8* %489 release, align 1
-  br label %936
+  br label %949
 
-936:                                              ; preds = %.loopexit, %913
-  %937 = phi i8* [ %915, %913 ], [ %918, %.loopexit ]
-  call fastcc void @__clang_call_terminate(i8* %937) #51
+949:                                              ; preds = %.loopexit, %926
+  %950 = phi i8* [ %928, %926 ], [ %931, %.loopexit ]
+  call fastcc void @__clang_call_terminate(i8* %950) #51
   unreachable
 
-.loopexit108:                                     ; preds = %.loopexit72, %_ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit
+.loopexit102:                                     ; preds = %.loopexit66, %_ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit
   ret void
 }
 
@@ -28192,15 +28770,15 @@
 ; Function Attrs: inlinehint nounwind uwtable
 define internal void @"_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc22ConcurrentMarkAndSweepC1ERNS3_2mm13ObjectFactoryIS7_EERNS6_11GCSchedulerEE3$_3ES5_SE_EEEEED2Ev"(%"struct.std::thread::_State_impl.151"* %0) unnamed_addr #19 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %2 = getelementptr %"struct.std::thread::_State_impl.151", %"struct.std::thread::_State_impl.151"* %0, i64 0, i32 0, i32 0
-  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @"_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc22ConcurrentMarkAndSweepC1ERNS3_2mm13ObjectFactoryIS7_EERNS6_11GCSchedulerEE3$_3ES5_SE_EEEEEE", i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !109
+  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @"_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc22ConcurrentMarkAndSweepC1ERNS3_2mm13ObjectFactoryIS7_EERNS6_11GCSchedulerEE3$_3ES5_SE_EEEEEE", i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !107
   %3 = getelementptr inbounds %"struct.std::thread::_State_impl.151", %"struct.std::thread::_State_impl.151"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1
-  %4 = load i8, i8* %3, align 8, !tbaa !112, !range !72
+  %4 = load atomic i8, i8* %3 unordered, align 8, !tbaa !110, !range !70
   %5 = icmp eq i8 %4, 0
   br i1 %5, label %13, label %6
 
 6:                                                ; preds = %1
   %7 = getelementptr inbounds %"struct.std::thread::_State_impl.151", %"struct.std::thread::_State_impl.151"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %8 = load i8*, i8** %7, align 8, !tbaa !58
+  %8 = load atomic i8*, i8** %7 unordered, align 8, !tbaa !47
   %9 = getelementptr inbounds %"struct.std::thread::_State_impl.151", %"struct.std::thread::_State_impl.151"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %10 = bitcast %union.anon.108* %9 to i8*
   %11 = icmp eq i8* %8, %10
@@ -28219,15 +28797,15 @@
 ; Function Attrs: inlinehint nounwind uwtable
 define internal void @"_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc22ConcurrentMarkAndSweepC1ERNS3_2mm13ObjectFactoryIS7_EERNS6_11GCSchedulerEE3$_3ES5_SE_EEEEED0Ev"(%"struct.std::thread::_State_impl.151"* %0) unnamed_addr #19 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %2 = getelementptr %"struct.std::thread::_State_impl.151", %"struct.std::thread::_State_impl.151"* %0, i64 0, i32 0, i32 0
-  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @"_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc22ConcurrentMarkAndSweepC1ERNS3_2mm13ObjectFactoryIS7_EERNS6_11GCSchedulerEE3$_3ES5_SE_EEEEEE", i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !109
+  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @"_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc22ConcurrentMarkAndSweepC1ERNS3_2mm13ObjectFactoryIS7_EERNS6_11GCSchedulerEE3$_3ES5_SE_EEEEEE", i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !107
   %3 = getelementptr inbounds %"struct.std::thread::_State_impl.151", %"struct.std::thread::_State_impl.151"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1
-  %4 = load i8, i8* %3, align 8, !tbaa !112, !range !72
+  %4 = load atomic i8, i8* %3 unordered, align 8, !tbaa !110, !range !70
   %5 = icmp eq i8 %4, 0
   br i1 %5, label %13, label %6
 
 6:                                                ; preds = %1
   %7 = getelementptr inbounds %"struct.std::thread::_State_impl.151", %"struct.std::thread::_State_impl.151"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %8 = load i8*, i8** %7, align 8, !tbaa !58
+  %8 = load atomic i8*, i8** %7 unordered, align 8, !tbaa !47
   %9 = getelementptr inbounds %"struct.std::thread::_State_impl.151", %"struct.std::thread::_State_impl.151"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %10 = bitcast %union.anon.108* %9 to i8*
   %11 = icmp eq i8* %8, %10
@@ -28253,20 +28831,20 @@
   %5 = getelementptr inbounds %"struct.std::thread::_State_impl.151", %"struct.std::thread::_State_impl.151"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
   %6 = bitcast %"class.kotlin::ScopedThread::attributes"* %2 to i8*
   call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %6)
-  %7 = load void (%"class.kotlin::ScopedThread::attributes"*, %class.anon.78*)*, void (%"class.kotlin::ScopedThread::attributes"*, %class.anon.78*)** %3, align 8, !tbaa !3
+  %7 = load atomic void (%"class.kotlin::ScopedThread::attributes"*, %class.anon.78*)*, void (%"class.kotlin::ScopedThread::attributes"*, %class.anon.78*)** %3 unordered, align 8, !tbaa !3
   %8 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 1
-  store i8 0, i8* %8, align 8, !tbaa !112
+  store i8 0, i8* %8, align 8, !tbaa !110
   %9 = getelementptr inbounds %"struct.std::thread::_State_impl.151", %"struct.std::thread::_State_impl.151"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1
-  %10 = load i8, i8* %9, align 8, !tbaa !112, !range !72
+  %10 = load atomic i8, i8* %9 unordered, align 8, !tbaa !110, !range !70
   %11 = icmp eq i8 %10, 0
   br i1 %11, label %32, label %12
 
 12:                                               ; preds = %1
   %13 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %14 = bitcast %"class.kotlin::ScopedThread::attributes"* %2 to %union.anon.108**
-  store %union.anon.108* %13, %union.anon.108** %14, align 8, !tbaa !56
+  store %union.anon.108* %13, %union.anon.108** %14, align 8, !tbaa !45
   %15 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %16 = load i8*, i8** %15, align 8, !tbaa !58
+  %16 = load atomic i8*, i8** %15 unordered, align 8, !tbaa !47
   %17 = getelementptr inbounds %"struct.std::thread::_State_impl.151", %"struct.std::thread::_State_impl.151"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %18 = bitcast %union.anon.108* %17 to i8*
   %19 = icmp eq i8* %16, %18
@@ -28279,23 +28857,23 @@
 
 22:                                               ; preds = %12
   %23 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  store i8* %16, i8** %23, align 8, !tbaa !58
+  store i8* %16, i8** %23, align 8, !tbaa !47
   %24 = getelementptr inbounds %"struct.std::thread::_State_impl.151", %"struct.std::thread::_State_impl.151"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
-  %25 = load i64, i64* %24, align 8, !tbaa !51
+  %25 = load atomic i64, i64* %24 unordered, align 8, !tbaa !50
   %26 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
-  store i64 %25, i64* %26, align 8, !tbaa !51
+  store i64 %25, i64* %26, align 8, !tbaa !50
   br label %27
 
 27:                                               ; preds = %22, %20
   %28 = getelementptr inbounds %"struct.std::thread::_State_impl.151", %"struct.std::thread::_State_impl.151"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  %29 = load i64, i64* %28, align 8, !tbaa !60
+  %29 = load atomic i64, i64* %28 unordered, align 8, !tbaa !51
   %30 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  store i64 %29, i64* %30, align 8, !tbaa !60
+  store i64 %29, i64* %30, align 8, !tbaa !51
   %31 = bitcast %"class.kotlin::ScopedThread::attributes"* %4 to %union.anon.108**
-  store %union.anon.108* %17, %union.anon.108** %31, align 8, !tbaa !58
-  store i64 0, i64* %28, align 8, !tbaa !60
-  store i8 0, i8* %18, align 8, !tbaa !51
-  store i8 1, i8* %8, align 8, !tbaa !112
+  store %union.anon.108* %17, %union.anon.108** %31, align 8, !tbaa !47
+  store i64 0, i64* %28, align 8, !tbaa !51
+  store i8 0, i8* %18, align 8, !tbaa !50
+  store i8 1, i8* %8, align 8, !tbaa !110
   br label %32
 
 32:                                               ; preds = %27, %1
@@ -28303,13 +28881,13 @@
           to label %33 unwind label %43
 
 33:                                               ; preds = %32
-  %34 = load i8, i8* %8, align 8, !tbaa !112, !range !72
+  %34 = load atomic i8, i8* %8 unordered, align 8, !tbaa !110, !range !70
   %35 = icmp eq i8 %34, 0
   br i1 %35, label %55, label %36
 
 36:                                               ; preds = %33
   %37 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %38 = load i8*, i8** %37, align 8, !tbaa !58
+  %38 = load atomic i8*, i8** %37 unordered, align 8, !tbaa !47
   %39 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %40 = bitcast %union.anon.108* %39 to i8*
   %41 = icmp eq i8* %38, %40
@@ -28322,13 +28900,13 @@
 43:                                               ; preds = %32
   %44 = landingpad { i8*, i32 }
           cleanup
-  %45 = load i8, i8* %8, align 8, !tbaa !112, !range !72
+  %45 = load atomic i8, i8* %8 unordered, align 8, !tbaa !110, !range !70
   %46 = icmp eq i8 %45, 0
   br i1 %46, label %54, label %47
 
 47:                                               ; preds = %43
   %48 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %49 = load i8*, i8** %48, align 8, !tbaa !58
+  %49 = load atomic i8*, i8** %48 unordered, align 8, !tbaa !47
   %50 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %51 = bitcast %union.anon.108* %50 to i8*
   %52 = icmp eq i8* %49, %51
@@ -28352,11 +28930,11 @@
   %4 = bitcast %"class.std::unique_lock.266"* %3 to i8*
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %4) #37
   %5 = getelementptr inbounds %"struct.GCStateHolder::ValueWithCondVar", %"struct.GCStateHolder::ValueWithCondVar"* %0, i64 0, i32 1
-  %6 = load %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %5, align 8, !tbaa !401
+  %6 = load atomic %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %5 unordered, align 8, !tbaa !403
   %7 = getelementptr inbounds %"class.std::unique_lock.266", %"class.std::unique_lock.266"* %3, i64 0, i32 0
-  store %"class.std::recursive_mutex"* %6, %"class.std::recursive_mutex"** %7, align 8, !tbaa !257
+  store %"class.std::recursive_mutex"* %6, %"class.std::recursive_mutex"** %7, align 8, !tbaa !255
   %8 = getelementptr inbounds %"class.std::unique_lock.266", %"class.std::unique_lock.266"* %3, i64 0, i32 1
-  store i8 0, i8* %8, align 8, !tbaa !259
+  store i8 0, i8* %8, align 8, !tbaa !257
   br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %9, label %14
 
 9:                                                ; preds = %2
@@ -28370,39 +28948,35 @@
   unreachable
 
 14:                                               ; preds = %9, %2
-  store i8 1, i8* %8, align 8, !tbaa !259
+  store i8 1, i8* %8, align 8, !tbaa !257
   %15 = getelementptr inbounds %"struct.GCStateHolder::ValueWithCondVar", %"struct.GCStateHolder::ValueWithCondVar"* %0, i64 0, i32 2
   %16 = getelementptr inbounds %class.GCStateHolder, %class.GCStateHolder* %1, i64 0, i32 5
   %17 = getelementptr inbounds %class.GCStateHolder, %class.GCStateHolder* %1, i64 0, i32 3, i32 0
-  %18 = load i64, i64* %17, align 8, !tbaa !89
+  %18 = load atomic i64, i64* %17 unordered, align 8, !tbaa !87
   %19 = getelementptr inbounds %class.GCStateHolder, %class.GCStateHolder* %1, i64 0, i32 2, i32 0
-  %20 = load i64, i64* %19, align 8, !tbaa !89
+  %20 = load atomic i64, i64* %19 unordered, align 8, !tbaa !87
   %21 = icmp sgt i64 %18, %20
   br i1 %21, label %31, label %.preheader
 
 .preheader:                                       ; preds = %24, %14
-  %22 = load i8, i8* %16, align 8, !tbaa !146, !range !72
+  %22 = load atomic i8, i8* %16 unordered, align 8, !tbaa !144, !range !70
   %23 = icmp eq i8 %22, 0
   br i1 %23, label %24, label %28
 
 24:                                               ; preds = %.preheader
   call void @_ZNSt18condition_variable4waitERSt11unique_lockISt5mutexE(%"class.std::condition_variable"* nonnull %15, %"class.std::unique_lock.266"* nonnull align 8 dereferenceable(9) %3) #37
-  %25 = load i64, i64* %17, align 8, !tbaa !89
-  %26 = load i64, i64* %19, align 8, !tbaa !89
+  %25 = load atomic i64, i64* %17 unordered, align 8, !tbaa !87
+  %26 = load atomic i64, i64* %19 unordered, align 8, !tbaa !87
   %27 = icmp sgt i64 %25, %26
   br i1 %27, label %28, label %.preheader
 
 28:                                               ; preds = %24, %.preheader
-  %29 = load i8, i8* %8, align 8, !tbaa !259, !range !72
+  %29 = load atomic i8, i8* %8 unordered, align 8, !tbaa !257, !range !70
   %30 = icmp eq i8 %29, 0
-  br i1 %30, label %39, label %._crit_edge
-
-._crit_edge:                                      ; preds = %28
-  %.pre = load %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %7, align 8, !tbaa !257
-  br label %31
+  br i1 %30, label %39, label %31
 
-31:                                               ; preds = %._crit_edge, %14
-  %32 = phi %"class.std::recursive_mutex"* [ %.pre, %._crit_edge ], [ %6, %14 ]
+31:                                               ; preds = %28, %14
+  %32 = load atomic %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %7 unordered, align 8, !tbaa !255
   %33 = icmp eq %"class.std::recursive_mutex"* %32, null
   br i1 %33, label %39, label %34
 
@@ -28415,7 +28989,7 @@
   br label %38
 
 38:                                               ; preds = %35, %34
-  store i8 0, i8* %8, align 8, !tbaa !259
+  store i8 0, i8* %8, align 8, !tbaa !257
   br label %39
 
 39:                                               ; preds = %38, %31, %28
@@ -28427,7 +29001,7 @@
 ; Function Attrs: uwtable
 define internal fastcc void @_ZN13GCStateHolder16ValueWithCondVarIlE3setEl(%"struct.GCStateHolder::ValueWithCondVar"* %0, i64 %1) unnamed_addr #20 align 2 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
   %3 = getelementptr inbounds %"struct.GCStateHolder::ValueWithCondVar", %"struct.GCStateHolder::ValueWithCondVar"* %0, i64 0, i32 1
-  %4 = load %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %3, align 8, !tbaa !401
+  %4 = load atomic %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %3 unordered, align 8, !tbaa !403
   br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %5, label %10
 
 5:                                                ; preds = %2
@@ -28442,7 +29016,7 @@
 
 10:                                               ; preds = %5, %2
   %11 = getelementptr inbounds %"struct.GCStateHolder::ValueWithCondVar", %"struct.GCStateHolder::ValueWithCondVar"* %0, i64 0, i32 0
-  store i64 %1, i64* %11, align 8, !tbaa !144
+  store i64 %1, i64* %11, align 8, !tbaa !142
   %12 = getelementptr inbounds %"struct.GCStateHolder::ValueWithCondVar", %"struct.GCStateHolder::ValueWithCondVar"* %0, i64 0, i32 2
   tail call void @_ZNSt18condition_variable10notify_allEv(%"class.std::condition_variable"* nonnull %12) #37
   %13 = icmp eq %"class.std::recursive_mutex"* %4, null
@@ -28466,20 +29040,20 @@
   %6 = alloca %"class.std::unique_lock.266", align 8
   %7 = alloca %"class.kotlin::mm::ObjectFactory<kotlin::gc::ConcurrentMarkAndSweep>::FinalizerQueue", align 8
   %8 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
-  %9 = load i8, i8* %8, align 8, !tbaa !106, !range !72
+  %9 = load atomic i8, i8* %8 unordered, align 8, !tbaa !104, !range !70
   %10 = icmp eq i8 %9, 0
   br i1 %10, label %_ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit, label %11
 
 11:                                               ; preds = %2
   %12 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %13 = load i8*, i8** %12, align 8, !tbaa !58
+  %13 = load atomic i8*, i8** %12 unordered, align 8, !tbaa !47
   %14 = tail call i64 @pthread_self() #1
   %15 = tail call i32 @pthread_setname_np(i64 %14, i8* %13) #37
   br label %_ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit
 
 _ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit: ; preds = %11, %2
   %16 = getelementptr inbounds %"struct.std::_Head_base.21", %"struct.std::_Head_base.21"* %1, i64 0, i32 0
-  %17 = load %"class.kotlin::gc::FinalizerProcessor"*, %"class.kotlin::gc::FinalizerProcessor"** %16, align 8, !tbaa !402
+  %17 = load atomic %"class.kotlin::gc::FinalizerProcessor"*, %"class.kotlin::gc::FinalizerProcessor"** %16 unordered, align 8, !tbaa !404
   tail call fastcc void @Kotlin_initRuntimeIfNeeded() #37
   %18 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %17, i64 0, i32 8
   br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %19, label %24
@@ -28496,7 +29070,7 @@
 
 24:                                               ; preds = %19, %_ZN6kotlin8internal20setCurrentThreadNameESt17basic_string_viewIcSt11char_traitsIcEE.exit
   %25 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %17, i64 0, i32 10
-  store i8 1, i8* %25, align 8, !tbaa !165
+  store i8 1, i8* %25, align 8, !tbaa !163
   br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %26, label %29
 
 26:                                               ; preds = %24
@@ -28541,11 +29115,11 @@
   %62 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %61 to i64*
   br label %63
 
-63:                                               ; preds = %265, %29
-  %64 = phi i64 [ 0, %29 ], [ %92, %265 ]
+63:                                               ; preds = %266, %29
+  %64 = phi i64 [ 0, %29 ], [ %92, %266 ]
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %31) #37
-  store %"class.std::recursive_mutex"* %32, %"class.std::recursive_mutex"** %33, align 8, !tbaa !257
-  store i8 0, i8* %34, align 8, !tbaa !259
+  store %"class.std::recursive_mutex"* %32, %"class.std::recursive_mutex"** %33, align 8, !tbaa !255
+  store i8 0, i8* %34, align 8, !tbaa !257
   br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %65, label %69
 
 65:                                               ; preds = %63
@@ -28558,63 +29132,63 @@
   unreachable
 
 69:                                               ; preds = %65, %63
-  store i8 1, i8* %34, align 8, !tbaa !259
-  %70 = load i64, i64* %39, align 8, !tbaa !391
+  store i8 1, i8* %34, align 8, !tbaa !257
+  %70 = load atomic i64, i64* %39 unordered, align 8, !tbaa !393
   %71 = icmp eq i64 %70, 0
   br i1 %71, label %.preheader19, label %87
 
 .preheader19:                                     ; preds = %77, %69
-  %72 = load i64, i64* %37, align 8, !tbaa !155
+  %72 = load atomic i64, i64* %37 unordered, align 8, !tbaa !153
   %73 = icmp eq i64 %72, %64
   br i1 %73, label %74, label %84
 
 74:                                               ; preds = %.preheader19
-  %75 = load i8, i8* %38, align 8, !tbaa !163, !range !72
+  %75 = load atomic i8, i8* %38 unordered, align 8, !tbaa !161, !range !70
   %76 = icmp eq i8 %75, 0
   br i1 %76, label %77, label %80
 
 77:                                               ; preds = %74
   call void @_ZNSt18condition_variable4waitERSt11unique_lockISt5mutexE(%"class.std::condition_variable"* nonnull %36, %"class.std::unique_lock.266"* nonnull align 8 dereferenceable(9) %6) #37
-  %78 = load i64, i64* %39, align 8, !tbaa !391
+  %78 = load atomic i64, i64* %39 unordered, align 8, !tbaa !393
   %79 = icmp eq i64 %78, 0
   br i1 %79, label %.preheader19, label %84
 
 80:                                               ; preds = %74
   %81 = getelementptr inbounds %"class.kotlin::gc::FinalizerProcessor", %"class.kotlin::gc::FinalizerProcessor"* %17, i64 0, i32 7
-  store i8 0, i8* %81, align 1, !tbaa !164
-  %82 = load i8, i8* %34, align 8, !tbaa !259, !range !72
+  store i8 0, i8* %81, align 1, !tbaa !162
+  %82 = load atomic i8, i8* %34 unordered, align 8, !tbaa !257, !range !70
   %83 = icmp eq i8 %82, 0
-  br i1 %83, label %274, label %266
+  br i1 %83, label %275, label %267
 
 84:                                               ; preds = %77, %.preheader19
   %85 = phi i64 [ %78, %77 ], [ 0, %.preheader19 ]
-  %86 = load i8, i8* %34, align 8, !tbaa !259, !range !72
+  %86 = load atomic i8, i8* %34 unordered, align 8, !tbaa !257, !range !70
   br label %87
 
 87:                                               ; preds = %84, %69
   %88 = phi i8 [ 1, %69 ], [ %86, %84 ]
   %89 = phi i64 [ %70, %69 ], [ %85, %84 ]
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %40) #37
-  %90 = load i64, i64* %45, align 8, !tbaa !3
+  %90 = load atomic i64, i64* %45 unordered, align 8, !tbaa !3
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %44, align 8, !tbaa !3
   store i64 %90, i64* %46, align 8, !tbaa !3
-  %91 = load i64, i64* %50, align 8, !tbaa !390
-  %92 = load i64, i64* %37, align 8, !tbaa !155
-  store i64 %89, i64* %47, align 8, !tbaa !391
-  store i64 %91, i64* %51, align 8, !tbaa !390
+  %91 = load atomic i64, i64* %50 unordered, align 8, !tbaa !392
+  %92 = load atomic i64, i64* %37 unordered, align 8, !tbaa !153
+  store i64 %89, i64* %47, align 8, !tbaa !393
+  store i64 %91, i64* %51, align 8, !tbaa !392
   call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %52, i8 0, i64 16, i1 false) #37
   %93 = icmp eq i8 %88, 0
   br i1 %93, label %94, label %96
 
 94:                                               ; preds = %87
   invoke void @_ZSt20__throw_system_errori(i32 1) #50
-          to label %95 unwind label %213
+          to label %95 unwind label %214
 
 95:                                               ; preds = %94
   unreachable
 
 96:                                               ; preds = %87
-  %97 = load %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %33, align 8, !tbaa !257
+  %97 = load atomic %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %33 unordered, align 8, !tbaa !255
   %98 = icmp eq %"class.std::recursive_mutex"* %97, null
   br i1 %98, label %104, label %99
 
@@ -28627,366 +29201,367 @@
   br label %103
 
 103:                                              ; preds = %100, %99
-  store i8 0, i8* %34, align 8, !tbaa !259
+  store i8 0, i8* %34, align 8, !tbaa !257
   br label %104
 
 104:                                              ; preds = %103, %96
-  %105 = icmp eq i64 %89, 0
-  br i1 %105, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit16, label %106
+  %105 = load atomic i64, i64* %47 unordered, align 8, !tbaa !393
+  %106 = icmp eq i64 %105, 0
+  br i1 %106, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit16, label %107
 
-106:                                              ; preds = %104
-  %107 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
-  %108 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %107, i64 328
-  %109 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %108 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %110 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %108 to i32*
-  %111 = atomicrmw xchg i32* %110, i32 0 seq_cst, align 4
-  %112 = icmp eq i32 %111, 1
-  br i1 %112, label %113, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
+107:                                              ; preds = %104
+  %108 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
+  %109 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %108, i64 328
+  %110 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %109 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %111 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %109 to i32*
+  %112 = atomicrmw xchg i32* %111, i32 0 seq_cst, align 4
+  %113 = icmp eq i32 %112, 1
+  br i1 %113, label %114, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-113:                                              ; preds = %106
-  %114 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %115 = and i8 %114, 1
-  %116 = icmp eq i8 %115, 0
-  br i1 %116, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %117
+114:                                              ; preds = %107
+  %115 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %116 = and i8 %115, 1
+  %117 = icmp eq i8 %116, 0
+  br i1 %117, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %118
 
-117:                                              ; preds = %113
-  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %109) #37
+118:                                              ; preds = %114
+  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %110) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %117, %113, %106
-  %118 = load i64, i64* %62, align 8, !tbaa !3
-  %119 = icmp eq i64 %118, 0
-  br i1 %119, label %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE14FinalizerQueue8FinalizeEv.exit, label %120
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %118, %114, %107
+  %119 = load atomic i64, i64* %62 unordered, align 8, !tbaa !3
+  %120 = icmp eq i64 %119, 0
+  br i1 %120, label %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE14FinalizerQueue8FinalizeEv.exit, label %121
 
-120:                                              ; preds = %_ZN6kotlin13RunFinalizersEP9ObjHeader.exit.i, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
-  %121 = phi i64 [ %198, %_ZN6kotlin13RunFinalizersEP9ObjHeader.exit.i ], [ %118, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit ]
-  %122 = inttoptr i64 %121 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
-  %123 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %122, i64 2
-  %124 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %123 to i64*
-  %125 = load atomic volatile i64, i64* %124 monotonic, align 8
-  %126 = and i64 %125, -4
-  %127 = inttoptr i64 %126 to i64*
-  %128 = load atomic volatile i64, i64* %127 monotonic, align 8
-  %129 = inttoptr i64 %128 to %struct.TypeInfo*
-  %130 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %129, i64 0, i32 13
-  %131 = load i32, i32* %130, align 8, !tbaa !67
-  %132 = and i32 %131, 64
-  %133 = icmp eq i32 %132, 0
-  br i1 %133, label %136, label %134
+121:                                              ; preds = %_ZN6kotlin13RunFinalizersEP9ObjHeader.exit.i, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
+  %122 = phi i64 [ %199, %_ZN6kotlin13RunFinalizersEP9ObjHeader.exit.i ], [ %119, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit ]
+  %123 = inttoptr i64 %122 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
+  %124 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %123, i64 2
+  %125 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %124 to i64*
+  %126 = load atomic volatile i64, i64* %125 monotonic, align 8
+  %127 = and i64 %126, -4
+  %128 = inttoptr i64 %127 to i64*
+  %129 = load atomic volatile i64, i64* %128 monotonic, align 8
+  %130 = inttoptr i64 %129 to %struct.TypeInfo*
+  %131 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %130, i64 0, i32 13
+  %132 = load atomic i32, i32* %131 unordered, align 8, !tbaa !66
+  %133 = and i32 %132, 64
+  %134 = icmp eq i32 %133, 0
+  br i1 %134, label %137, label %135
 
-134:                                              ; preds = %120
-  %135 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %123 to %struct.ObjHeader*
-  call fastcc void @_ZN12_GLOBAL__N_121RunFinalizerHooksImplEP9ObjHeaderPK8TypeInfo(%struct.ObjHeader* nonnull %135, %struct.TypeInfo* %129) #37
-  br label %136
+135:                                              ; preds = %121
+  %136 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %124 to %struct.ObjHeader*
+  call fastcc void @_ZN12_GLOBAL__N_121RunFinalizerHooksImplEP9ObjHeaderPK8TypeInfo(%struct.ObjHeader* nonnull %136, %struct.TypeInfo* %130) #37
+  br label %137
 
-136:                                              ; preds = %134, %120
-  %137 = load atomic volatile i64, i64* %124 acquire, align 8
-  %138 = and i64 %137, -4
-  %139 = inttoptr i64 %138 to %struct.TypeInfo*
-  %140 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %139, i64 0, i32 0
-  %141 = load %struct.TypeInfo*, %struct.TypeInfo** %140, align 8, !tbaa !335
-  %142 = icmp ne %struct.TypeInfo* %141, %139
-  %143 = icmp ne i64 %138, 0
-  %144 = and i1 %143, %142
-  br i1 %144, label %145, label %_ZN6kotlin13RunFinalizersEP9ObjHeader.exit.i
+137:                                              ; preds = %135, %121
+  %138 = load atomic volatile i64, i64* %125 acquire, align 8
+  %139 = and i64 %138, -4
+  %140 = inttoptr i64 %139 to %struct.TypeInfo*
+  %141 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %140, i64 0, i32 0
+  %142 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %141 unordered, align 8, !tbaa !339
+  %143 = icmp ne %struct.TypeInfo* %142, %140
+  %144 = icmp ne i64 %139, 0
+  %145 = and i1 %144, %143
+  br i1 %145, label %146, label %_ZN6kotlin13RunFinalizersEP9ObjHeader.exit.i
 
-145:                                              ; preds = %136
-  %146 = load atomic volatile i64, i64* %124 acquire, align 8
-  %147 = and i64 %146, -4
-  %148 = inttoptr i64 %147 to %struct.TypeInfo*
-  %149 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %148, i64 0, i32 0
-  %150 = load %struct.TypeInfo*, %struct.TypeInfo** %149, align 8, !tbaa !335
-  %151 = icmp eq %struct.TypeInfo* %150, %148
-  %152 = inttoptr i64 %147 to %struct.MetaObjHeader*
-  %153 = select i1 %151, %struct.MetaObjHeader* null, %struct.MetaObjHeader* %152
-  %154 = bitcast %struct.MetaObjHeader* %153 to %"class.kotlin::mm::ExtraObjectData"*
-  %155 = getelementptr inbounds %"class.kotlin::mm::ExtraObjectData", %"class.kotlin::mm::ExtraObjectData"* %154, i64 0, i32 2
-  %156 = bitcast %"struct.std::atomic.0.62"* %155 to i64*
-  %157 = load atomic i64, i64* %156 seq_cst, align 8
-  %158 = inttoptr i64 %157 to %struct.ObjHeader*
-  %159 = and i64 %157, 1
-  %160 = icmp eq i64 %159, 0
-  br i1 %160, label %_ZN6kotlin2mm15ExtraObjectData9UninstallEv.exit.i.i.i, label %161
+146:                                              ; preds = %137
+  %147 = load atomic volatile i64, i64* %125 acquire, align 8
+  %148 = and i64 %147, -4
+  %149 = inttoptr i64 %148 to %struct.TypeInfo*
+  %150 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %149, i64 0, i32 0
+  %151 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %150 unordered, align 8, !tbaa !339
+  %152 = icmp eq %struct.TypeInfo* %151, %149
+  %153 = inttoptr i64 %148 to %struct.MetaObjHeader*
+  %154 = select i1 %152, %struct.MetaObjHeader* null, %struct.MetaObjHeader* %153
+  %155 = bitcast %struct.MetaObjHeader* %154 to %"class.kotlin::mm::ExtraObjectData"*
+  %156 = getelementptr inbounds %"class.kotlin::mm::ExtraObjectData", %"class.kotlin::mm::ExtraObjectData"* %155, i64 0, i32 2
+  %157 = bitcast %"struct.std::atomic.0.62"* %156 to i64*
+  %158 = load atomic i64, i64* %157 seq_cst, align 8
+  %159 = inttoptr i64 %158 to %struct.ObjHeader*
+  %160 = and i64 %158, 1
+  %161 = icmp eq i64 %160, 0
+  br i1 %161, label %_ZN6kotlin2mm15ExtraObjectData9UninstallEv.exit.i.i.i, label %162
 
-161:                                              ; preds = %145
-  %162 = and i64 %157, -2
-  %163 = inttoptr i64 %162 to %struct.ObjHeader*
-  %164 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %163, i64 1
-  %165 = bitcast %struct.ObjHeader* %164 to %struct.ObjHeader**
-  %166 = load %struct.ObjHeader*, %struct.ObjHeader** %165, align 8, !tbaa !370
+162:                                              ; preds = %146
+  %163 = and i64 %158, -2
+  %164 = inttoptr i64 %163 to %struct.ObjHeader*
+  %165 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %164, i64 1
+  %166 = bitcast %struct.ObjHeader* %165 to %struct.ObjHeader**
+  %167 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %166 unordered, align 8, !tbaa !372
   br label %_ZN6kotlin2mm15ExtraObjectData9UninstallEv.exit.i.i.i
 
-_ZN6kotlin2mm15ExtraObjectData9UninstallEv.exit.i.i.i: ; preds = %161, %145
-  %167 = phi %struct.ObjHeader* [ %166, %161 ], [ %158, %145 ]
-  %168 = bitcast %struct.MetaObjHeader* %153 to i64*
-  %169 = load i64, i64* %168, align 8, !tbaa !372
-  %170 = bitcast %struct.ObjHeader* %167 to i64*
-  store atomic volatile i64 %169, i64* %170 release, align 8
-  %171 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %172 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %171, i64 0, i32 1, i32 4, i32 0
-  %173 = getelementptr inbounds %"class.kotlin::mm::ExtraObjectData", %"class.kotlin::mm::ExtraObjectData"* %154, i64 -1, i32 2
-  %174 = getelementptr inbounds %"struct.std::atomic.0.62", %"struct.std::atomic.0.62"* %173, i64 4
-  %175 = bitcast %"struct.std::atomic.0.62"* %174 to i64*
-  %176 = load atomic i64, i64* %175 seq_cst, align 8
-  %177 = inttoptr i64 %176 to %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"*
-  %178 = icmp eq %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %172, %177
-  br i1 %178, label %179, label %187
+_ZN6kotlin2mm15ExtraObjectData9UninstallEv.exit.i.i.i: ; preds = %162, %146
+  %168 = phi %struct.ObjHeader* [ %167, %162 ], [ %159, %146 ]
+  %169 = bitcast %struct.MetaObjHeader* %154 to i64*
+  %170 = load atomic i64, i64* %169 unordered, align 8, !tbaa !374
+  %171 = bitcast %struct.ObjHeader* %168 to i64*
+  store atomic volatile i64 %170, i64* %171 release, align 8
+  %172 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %173 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %172, i64 0, i32 1, i32 4, i32 0
+  %174 = getelementptr inbounds %"class.kotlin::mm::ExtraObjectData", %"class.kotlin::mm::ExtraObjectData"* %155, i64 -1, i32 2
+  %175 = getelementptr inbounds %"struct.std::atomic.0.62", %"struct.std::atomic.0.62"* %174, i64 4
+  %176 = bitcast %"struct.std::atomic.0.62"* %175 to i64*
+  %177 = load atomic i64, i64* %176 seq_cst, align 8
+  %178 = inttoptr i64 %177 to %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"*
+  %179 = icmp eq %"class.kotlin::MultiSourceQueue<ObjHeader **, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader **>>::Producer"* %173, %178
+  br i1 %179, label %180, label %188
 
-179:                                              ; preds = %_ZN6kotlin2mm15ExtraObjectData9UninstallEv.exit.i.i.i
-  %180 = getelementptr inbounds %"struct.std::atomic.0.62", %"struct.std::atomic.0.62"* %173, i64 5
-  %181 = bitcast %"struct.std::atomic.0.62"* %180 to %"struct.std::__detail::_List_node_base"**
-  %182 = load %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %181, align 8, !tbaa !363
-  %183 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %171, i64 0, i32 1, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1
-  %184 = load i64, i64* %183, align 8, !tbaa !226
-  %185 = add i64 %184, -1
-  store i64 %185, i64* %183, align 8, !tbaa !226
-  call void @_ZNSt8__detail15_List_node_base9_M_unhookEv(%"struct.std::__detail::_List_node_base"* %182) #37
-  %186 = bitcast %"struct.std::__detail::_List_node_base"* %182 to i8*
-  call fastcc void @mi_free(i8* %186) #37
+180:                                              ; preds = %_ZN6kotlin2mm15ExtraObjectData9UninstallEv.exit.i.i.i
+  %181 = getelementptr inbounds %"struct.std::atomic.0.62", %"struct.std::atomic.0.62"* %174, i64 5
+  %182 = bitcast %"struct.std::atomic.0.62"* %181 to %"struct.std::__detail::_List_node_base"**
+  %183 = load atomic %"struct.std::__detail::_List_node_base"*, %"struct.std::__detail::_List_node_base"** %182 unordered, align 8, !tbaa !365
+  %184 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %172, i64 0, i32 1, i32 4, i32 0, i32 1, i32 0, i32 0, i32 0, i32 1
+  %185 = load atomic i64, i64* %184 unordered, align 8, !tbaa !225
+  %186 = add i64 %185, -1
+  store i64 %186, i64* %184, align 8, !tbaa !225
+  call void @_ZNSt8__detail15_List_node_base9_M_unhookEv(%"struct.std::__detail::_List_node_base"* %183) #37
+  %187 = bitcast %"struct.std::__detail::_List_node_base"* %183 to i8*
+  call fastcc void @mi_free(i8* %187) #37
   br label %_ZN6kotlin13RunFinalizersEP9ObjHeader.exit.i
 
-187:                                              ; preds = %_ZN6kotlin2mm15ExtraObjectData9UninstallEv.exit.i.i.i
-  %188 = ptrtoint %"struct.std::atomic.0.62"* %173 to i64
-  %189 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %171, i64 0, i32 1, i32 4, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0
-  %190 = call fastcc i8* @_ZN6kotlin20allocateInObjectPoolEm(i64 24) #37
-  %191 = getelementptr inbounds i8, i8* %190, i64 16
-  %192 = bitcast i8* %191 to i64*
-  store i64 %188, i64* %192, align 8, !tbaa !3
-  %193 = bitcast i8* %190 to %"struct.std::__detail::_List_node_base"*
-  call void @_ZNSt8__detail15_List_node_base7_M_hookEPS0_(%"struct.std::__detail::_List_node_base"* %193, %"struct.std::__detail::_List_node_base"* nonnull %189) #37
-  %194 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %171, i64 0, i32 1, i32 4, i32 0, i32 2, i32 0, i32 0, i32 0, i32 1
-  %195 = load i64, i64* %194, align 8, !tbaa !229
-  %196 = add i64 %195, 1
-  store i64 %196, i64* %194, align 8, !tbaa !229
+188:                                              ; preds = %_ZN6kotlin2mm15ExtraObjectData9UninstallEv.exit.i.i.i
+  %189 = ptrtoint %"struct.std::atomic.0.62"* %174 to i64
+  %190 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %172, i64 0, i32 1, i32 4, i32 0, i32 2, i32 0, i32 0, i32 0, i32 0
+  %191 = call fastcc i8* @_ZN6kotlin20allocateInObjectPoolEm(i64 24) #37
+  %192 = getelementptr inbounds i8, i8* %191, i64 16
+  %193 = bitcast i8* %192 to i64*
+  store i64 %189, i64* %193, align 8, !tbaa !3
+  %194 = bitcast i8* %191 to %"struct.std::__detail::_List_node_base"*
+  call void @_ZNSt8__detail15_List_node_base7_M_hookEPS0_(%"struct.std::__detail::_List_node_base"* %194, %"struct.std::__detail::_List_node_base"* nonnull %190) #37
+  %195 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %172, i64 0, i32 1, i32 4, i32 0, i32 2, i32 0, i32 0, i32 0, i32 1
+  %196 = load atomic i64, i64* %195 unordered, align 8, !tbaa !228
+  %197 = add i64 %196, 1
+  store i64 %197, i64* %195, align 8, !tbaa !228
   br label %_ZN6kotlin13RunFinalizersEP9ObjHeader.exit.i
 
-_ZN6kotlin13RunFinalizersEP9ObjHeader.exit.i:     ; preds = %187, %179, %136
-  %197 = inttoptr i64 %121 to i64*
-  %198 = load i64, i64* %197, align 8, !tbaa !3
-  %199 = icmp eq i64 %198, 0
-  br i1 %199, label %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE14FinalizerQueue8FinalizeEv.exit, label %120
+_ZN6kotlin13RunFinalizersEP9ObjHeader.exit.i:     ; preds = %188, %180, %137
+  %198 = inttoptr i64 %122 to i64*
+  %199 = load atomic i64, i64* %198 unordered, align 8, !tbaa !3
+  %200 = icmp eq i64 %199, 0
+  br i1 %200, label %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE14FinalizerQueue8FinalizeEv.exit, label %121
 
 _ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE14FinalizerQueue8FinalizeEv.exit: ; preds = %_ZN6kotlin13RunFinalizersEP9ObjHeader.exit.i, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
-  %200 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %107, null
-  br i1 %200, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit16, label %201
+  %201 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %108, null
+  br i1 %201, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit16, label %202
 
-201:                                              ; preds = %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE14FinalizerQueue8FinalizeEv.exit
-  %202 = atomicrmw xchg i32* %110, i32 %111 seq_cst, align 4
-  %203 = icmp eq i32 %202, 1
-  %204 = icmp eq i32 %111, 0
-  %205 = and i1 %204, %203
-  br i1 %205, label %206, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit16
+202:                                              ; preds = %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE14FinalizerQueue8FinalizeEv.exit
+  %203 = atomicrmw xchg i32* %111, i32 %112 seq_cst, align 4
+  %204 = icmp eq i32 %203, 1
+  %205 = icmp eq i32 %112, 0
+  %206 = and i1 %205, %204
+  br i1 %206, label %207, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit16
 
-206:                                              ; preds = %201
-  %207 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %208 = and i8 %207, 1
-  %209 = icmp eq i8 %208, 0
-  br i1 %209, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit16, label %210
+207:                                              ; preds = %202
+  %208 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %209 = and i8 %208, 1
+  %210 = icmp eq i8 %209, 0
+  br i1 %210, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit16, label %211
 
-210:                                              ; preds = %206
-  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %109) #37
+211:                                              ; preds = %207
+  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %110) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit16
 
-211:                                              ; preds = %238
-  %212 = landingpad { i8*, i32 }
+212:                                              ; preds = %239
+  %213 = landingpad { i8*, i32 }
           cleanup
-  br label %215
+  br label %216
 
-213:                                              ; preds = %236, %94
-  %214 = landingpad { i8*, i32 }
+214:                                              ; preds = %237, %94
+  %215 = landingpad { i8*, i32 }
           cleanup
-  br label %215
+  br label %216
 
-215:                                              ; preds = %213, %211
-  %216 = phi { i8*, i32 } [ %212, %211 ], [ %214, %213 ]
-  %217 = bitcast %"class.std::unique_ptr.112"* %5 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %217) #37
-  %218 = load i64, i64* %46, align 8, !tbaa !3
+216:                                              ; preds = %214, %212
+  %217 = phi { i8*, i32 } [ %213, %212 ], [ %215, %214 ]
+  %218 = bitcast %"class.std::unique_ptr.112"* %5 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %218) #37
+  %219 = load atomic i64, i64* %46 unordered, align 8, !tbaa !3
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %43, align 8, !tbaa !3
-  %219 = bitcast %"class.std::unique_ptr.112"* %5 to i64*
-  store i64 %218, i64* %219, align 8, !tbaa !198
-  %220 = getelementptr inbounds %"class.std::unique_ptr.112", %"class.std::unique_ptr.112"* %5, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %221 = icmp eq i64 %218, 0
-  br i1 %221, label %.loopexit, label %.preheader
+  %220 = bitcast %"class.std::unique_ptr.112"* %5 to i64*
+  store i64 %219, i64* %220, align 8, !tbaa !197
+  %221 = getelementptr inbounds %"class.std::unique_ptr.112", %"class.std::unique_ptr.112"* %5, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %222 = icmp eq i64 %219, 0
+  br i1 %222, label %.loopexit, label %.preheader
 
-.preheader:                                       ; preds = %232, %215
-  %222 = phi i64 [ %226, %232 ], [ %218, %215 ]
-  %223 = inttoptr i64 %222 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
-  %224 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %223, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %225 = inttoptr i64 %222 to i64*
-  %226 = load i64, i64* %225, align 8, !tbaa !3
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %224, align 8, !tbaa !3
-  %227 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %220, align 8, !tbaa !3
-  store i64 %226, i64* %219, align 8, !tbaa !3
-  %228 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %227, null
-  br i1 %228, label %232, label %229
+.preheader:                                       ; preds = %233, %216
+  %223 = phi i64 [ %227, %233 ], [ %219, %216 ]
+  %224 = inttoptr i64 %223 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
+  %225 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %224, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %226 = inttoptr i64 %223 to i64*
+  %227 = load atomic i64, i64* %226 unordered, align 8, !tbaa !3
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %225, align 8, !tbaa !3
+  %228 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %221 unordered, align 8, !tbaa !3
+  store i64 %227, i64* %220, align 8, !tbaa !3
+  %229 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %228, null
+  br i1 %229, label %233, label %230
 
-229:                                              ; preds = %.preheader
-  %230 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %227, i64 0, i32 0
-  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %230) #37
-  %231 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %227 to i8*
-  call fastcc void @mi_free(i8* nonnull %231) #37
-  br label %232
+230:                                              ; preds = %.preheader
+  %231 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %228, i64 0, i32 0
+  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %231) #37
+  %232 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %228 to i8*
+  call fastcc void @mi_free(i8* nonnull %232) #37
+  br label %233
 
-232:                                              ; preds = %229, %.preheader
-  %233 = icmp eq i64 %226, 0
-  br i1 %233, label %.loopexit, label %.preheader
+233:                                              ; preds = %230, %.preheader
+  %234 = icmp eq i64 %227, 0
+  br i1 %234, label %.loopexit, label %.preheader
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit16: ; preds = %210, %206, %201, %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE14FinalizerQueue8FinalizeEv.exit, %104
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit16: ; preds = %211, %207, %202, %_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE14FinalizerQueue8FinalizeEv.exit, %104
   call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %53)
-  store i64 %92, i64* %4, align 8, !tbaa !89
-  %234 = load i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %54, align 8, !tbaa !103
-  %235 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %234, null
-  br i1 %235, label %236, label %238
+  store i64 %92, i64* %4, align 8, !tbaa !87
+  %235 = load atomic i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %54 unordered, align 8, !tbaa !101
+  %236 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %235, null
+  br i1 %236, label %237, label %239
 
-236:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit16
+237:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit16
   invoke void @_ZSt25__throw_bad_function_callv() #50
-          to label %237 unwind label %213
+          to label %238 unwind label %214
 
-237:                                              ; preds = %236
+238:                                              ; preds = %237
   unreachable
 
-238:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit16
-  %239 = load void (%"union.std::_Any_data"*, i64*)*, void (%"union.std::_Any_data"*, i64*)** %55, align 8, !tbaa !392
-  invoke void %239(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %56, i64* nonnull align 8 dereferenceable(8) %4)
-          to label %240 unwind label %211
+239:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit16
+  %240 = load atomic void (%"union.std::_Any_data"*, i64*)*, void (%"union.std::_Any_data"*, i64*)** %55 unordered, align 8, !tbaa !394
+  invoke void %240(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %56, i64* nonnull align 8 dereferenceable(8) %4)
+          to label %241 unwind label %212
 
-240:                                              ; preds = %238
+241:                                              ; preds = %239
   call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %53)
   call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %57) #37
-  %241 = load i64, i64* %46, align 8, !tbaa !3
+  %242 = load atomic i64, i64* %46 unordered, align 8, !tbaa !3
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %43, align 8, !tbaa !3
-  store i64 %241, i64* %58, align 8, !tbaa !198
-  %242 = icmp eq i64 %241, 0
-  br i1 %242, label %.loopexit18, label %.preheader17
+  store i64 %242, i64* %58, align 8, !tbaa !197
+  %243 = icmp eq i64 %242, 0
+  br i1 %243, label %.loopexit18, label %.preheader17
 
-.preheader17:                                     ; preds = %253, %240
-  %243 = phi i64 [ %247, %253 ], [ %241, %240 ]
-  %244 = inttoptr i64 %243 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
-  %245 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %244, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %246 = inttoptr i64 %243 to i64*
-  %247 = load i64, i64* %246, align 8, !tbaa !3
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %245, align 8, !tbaa !3
-  %248 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %59, align 8, !tbaa !3
-  store i64 %247, i64* %58, align 8, !tbaa !3
-  %249 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %248, null
-  br i1 %249, label %253, label %250
+.preheader17:                                     ; preds = %254, %241
+  %244 = phi i64 [ %248, %254 ], [ %242, %241 ]
+  %245 = inttoptr i64 %244 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
+  %246 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %245, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %247 = inttoptr i64 %244 to i64*
+  %248 = load atomic i64, i64* %247 unordered, align 8, !tbaa !3
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %246, align 8, !tbaa !3
+  %249 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %59 unordered, align 8, !tbaa !3
+  store i64 %248, i64* %58, align 8, !tbaa !3
+  %250 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %249, null
+  br i1 %250, label %254, label %251
 
-250:                                              ; preds = %.preheader17
-  %251 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %248, i64 0, i32 0
-  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %251) #37
-  %252 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %248 to i8*
-  call fastcc void @mi_free(i8* nonnull %252) #37
-  br label %253
+251:                                              ; preds = %.preheader17
+  %252 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %249, i64 0, i32 0
+  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %252) #37
+  %253 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %249 to i8*
+  call fastcc void @mi_free(i8* nonnull %253) #37
+  br label %254
 
-253:                                              ; preds = %250, %.preheader17
-  %254 = icmp eq i64 %247, 0
-  br i1 %254, label %.loopexit18, label %.preheader17
+254:                                              ; preds = %251, %.preheader17
+  %255 = icmp eq i64 %248, 0
+  br i1 %255, label %.loopexit18, label %.preheader17
 
-.loopexit18:                                      ; preds = %253, %240
+.loopexit18:                                      ; preds = %254, %241
   call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %3) #37
   call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %57) #37
   call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %60) #37
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %40) #37
-  %255 = load i8, i8* %34, align 8, !tbaa !259, !range !72
-  %256 = icmp eq i8 %255, 0
-  br i1 %256, label %265, label %257
-
-257:                                              ; preds = %.loopexit18
-  %258 = load %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %33, align 8, !tbaa !257
-  %259 = icmp eq %"class.std::recursive_mutex"* %258, null
-  br i1 %259, label %265, label %260
+  %256 = load atomic i8, i8* %34 unordered, align 8, !tbaa !257, !range !70
+  %257 = icmp eq i8 %256, 0
+  br i1 %257, label %266, label %258
 
-260:                                              ; preds = %257
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %261, label %264
+258:                                              ; preds = %.loopexit18
+  %259 = load atomic %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %33 unordered, align 8, !tbaa !255
+  %260 = icmp eq %"class.std::recursive_mutex"* %259, null
+  br i1 %260, label %266, label %261
 
-261:                                              ; preds = %260
-  %262 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %258, i64 0, i32 0, i32 0
-  %263 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %262) #37
-  br label %264
+261:                                              ; preds = %258
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %262, label %265
 
-264:                                              ; preds = %261, %260
-  store i8 0, i8* %34, align 8, !tbaa !259
+262:                                              ; preds = %261
+  %263 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %259, i64 0, i32 0, i32 0
+  %264 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %263) #37
   br label %265
 
-265:                                              ; preds = %264, %257, %.loopexit18
+265:                                              ; preds = %262, %261
+  store i8 0, i8* %34, align 8, !tbaa !257
+  br label %266
+
+266:                                              ; preds = %265, %258, %.loopexit18
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %31) #37
   br label %63
 
-266:                                              ; preds = %80
-  %267 = load %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %33, align 8, !tbaa !257
-  %268 = icmp eq %"class.std::recursive_mutex"* %267, null
-  br i1 %268, label %274, label %269
-
-269:                                              ; preds = %266
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %270, label %273
+267:                                              ; preds = %80
+  %268 = load atomic %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %33 unordered, align 8, !tbaa !255
+  %269 = icmp eq %"class.std::recursive_mutex"* %268, null
+  br i1 %269, label %275, label %270
 
-270:                                              ; preds = %269
-  %271 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %267, i64 0, i32 0, i32 0
-  %272 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %271) #37
-  br label %273
+270:                                              ; preds = %267
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %271, label %274
 
-273:                                              ; preds = %270, %269
-  store i8 0, i8* %34, align 8, !tbaa !259
+271:                                              ; preds = %270
+  %272 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %268, i64 0, i32 0, i32 0
+  %273 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %272) #37
   br label %274
 
-274:                                              ; preds = %273, %266, %80
+274:                                              ; preds = %271, %270
+  store i8 0, i8* %34, align 8, !tbaa !257
+  br label %275
+
+275:                                              ; preds = %274, %267, %80
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %31) #37
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %275, label %283
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %276, label %284
 
-275:                                              ; preds = %274
-  %276 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %18, i64 0, i32 0, i32 0
-  %277 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull %276) #37
-  %278 = icmp eq i32 %277, 0
-  br i1 %278, label %280, label %279
+276:                                              ; preds = %275
+  %277 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %18, i64 0, i32 0, i32 0
+  %278 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull %277) #37
+  %279 = icmp eq i32 %278, 0
+  br i1 %279, label %281, label %280
 
-279:                                              ; preds = %275
-  call void @_ZSt20__throw_system_errori(i32 %277) #50
+280:                                              ; preds = %276
+  call void @_ZSt20__throw_system_errori(i32 %278) #50
   unreachable
 
-280:                                              ; preds = %275
-  store i8 0, i8* %25, align 8, !tbaa !165
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %281, label %295
+281:                                              ; preds = %276
+  store i8 0, i8* %25, align 8, !tbaa !163
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %282, label %296
 
-281:                                              ; preds = %280
-  %282 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %276) #37
-  br label %295
+282:                                              ; preds = %281
+  %283 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %277) #37
+  br label %296
 
-283:                                              ; preds = %274
-  store i8 0, i8* %25, align 8, !tbaa !165
-  br label %295
+284:                                              ; preds = %275
+  store i8 0, i8* %25, align 8, !tbaa !163
+  br label %296
 
-.loopexit:                                        ; preds = %232, %215
+.loopexit:                                        ; preds = %233, %216
   call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %5) #37
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %217) #37
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %218) #37
   call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %60) #37
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %40) #37
-  %284 = load i8, i8* %34, align 8, !tbaa !259, !range !72
-  %285 = icmp eq i8 %284, 0
-  br i1 %285, label %294, label %286
-
-286:                                              ; preds = %.loopexit
-  %287 = load %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %33, align 8, !tbaa !257
-  %288 = icmp eq %"class.std::recursive_mutex"* %287, null
-  br i1 %288, label %294, label %289
+  %285 = load atomic i8, i8* %34 unordered, align 8, !tbaa !257, !range !70
+  %286 = icmp eq i8 %285, 0
+  br i1 %286, label %295, label %287
 
-289:                                              ; preds = %286
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %290, label %293
+287:                                              ; preds = %.loopexit
+  %288 = load atomic %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %33 unordered, align 8, !tbaa !255
+  %289 = icmp eq %"class.std::recursive_mutex"* %288, null
+  br i1 %289, label %295, label %290
 
-290:                                              ; preds = %289
-  %291 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %287, i64 0, i32 0, i32 0
-  %292 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %291) #37
-  br label %293
+290:                                              ; preds = %287
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %291, label %294
 
-293:                                              ; preds = %290, %289
-  store i8 0, i8* %34, align 8, !tbaa !259
+291:                                              ; preds = %290
+  %292 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %288, i64 0, i32 0, i32 0
+  %293 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %292) #37
   br label %294
 
-294:                                              ; preds = %293, %286, %.loopexit
+294:                                              ; preds = %291, %290
+  store i8 0, i8* %34, align 8, !tbaa !257
+  br label %295
+
+295:                                              ; preds = %294, %287, %.loopexit
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %31) #37
-  resume { i8*, i32 } %216
+  resume { i8*, i32 } %217
 
-295:                                              ; preds = %283, %281, %280
+296:                                              ; preds = %284, %282, %281
   call void @_ZNSt18condition_variable10notify_allEv(%"class.std::condition_variable"* nonnull %30) #37
   ret void
 }
@@ -28994,15 +29569,15 @@
 ; Function Attrs: inlinehint nounwind uwtable
 define internal void @"_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0ES5_S8_EEEEED2Ev"(%"struct.std::thread::_State_impl.38"* %0) unnamed_addr #19 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %2 = getelementptr %"struct.std::thread::_State_impl.38", %"struct.std::thread::_State_impl.38"* %0, i64 0, i32 0, i32 0
-  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @"_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0ES5_S8_EEEEEE", i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !109
+  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @"_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0ES5_S8_EEEEEE", i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !107
   %3 = getelementptr inbounds %"struct.std::thread::_State_impl.38", %"struct.std::thread::_State_impl.38"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1
-  %4 = load i8, i8* %3, align 8, !tbaa !112, !range !72
+  %4 = load atomic i8, i8* %3 unordered, align 8, !tbaa !110, !range !70
   %5 = icmp eq i8 %4, 0
   br i1 %5, label %13, label %6
 
 6:                                                ; preds = %1
   %7 = getelementptr inbounds %"struct.std::thread::_State_impl.38", %"struct.std::thread::_State_impl.38"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %8 = load i8*, i8** %7, align 8, !tbaa !58
+  %8 = load atomic i8*, i8** %7 unordered, align 8, !tbaa !47
   %9 = getelementptr inbounds %"struct.std::thread::_State_impl.38", %"struct.std::thread::_State_impl.38"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %10 = bitcast %union.anon.108* %9 to i8*
   %11 = icmp eq i8* %8, %10
@@ -29021,15 +29596,15 @@
 ; Function Attrs: inlinehint nounwind uwtable
 define internal void @"_ZNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0ES5_S8_EEEEED0Ev"(%"struct.std::thread::_State_impl.38"* %0) unnamed_addr #19 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %2 = getelementptr %"struct.std::thread::_State_impl.38", %"struct.std::thread::_State_impl.38"* %0, i64 0, i32 0, i32 0
-  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @"_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0ES5_S8_EEEEEE", i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !109
+  store i32 (...)** bitcast (i8** getelementptr inbounds ({ [5 x i8*] }, { [5 x i8*] }* @"_ZTVNSt6thread11_State_implINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0ES5_S8_EEEEEE", i64 0, inrange i32 0, i64 2) to i32 (...)**), i32 (...)*** %2, align 8, !tbaa !107
   %3 = getelementptr inbounds %"struct.std::thread::_State_impl.38", %"struct.std::thread::_State_impl.38"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1
-  %4 = load i8, i8* %3, align 8, !tbaa !112, !range !72
+  %4 = load atomic i8, i8* %3 unordered, align 8, !tbaa !110, !range !70
   %5 = icmp eq i8 %4, 0
   br i1 %5, label %13, label %6
 
 6:                                                ; preds = %1
   %7 = getelementptr inbounds %"struct.std::thread::_State_impl.38", %"struct.std::thread::_State_impl.38"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %8 = load i8*, i8** %7, align 8, !tbaa !58
+  %8 = load atomic i8*, i8** %7 unordered, align 8, !tbaa !47
   %9 = getelementptr inbounds %"struct.std::thread::_State_impl.38", %"struct.std::thread::_State_impl.38"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %10 = bitcast %union.anon.108* %9 to i8*
   %11 = icmp eq i8* %8, %10
@@ -29055,20 +29630,20 @@
   %5 = getelementptr inbounds %"struct.std::thread::_State_impl.38", %"struct.std::thread::_State_impl.38"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
   %6 = bitcast %"class.kotlin::ScopedThread::attributes"* %2 to i8*
   call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %6)
-  %7 = load void (%"class.kotlin::ScopedThread::attributes"*, %"struct.std::_Head_base.21"*)*, void (%"class.kotlin::ScopedThread::attributes"*, %"struct.std::_Head_base.21"*)** %3, align 8, !tbaa !3
+  %7 = load atomic void (%"class.kotlin::ScopedThread::attributes"*, %"struct.std::_Head_base.21"*)*, void (%"class.kotlin::ScopedThread::attributes"*, %"struct.std::_Head_base.21"*)** %3 unordered, align 8, !tbaa !3
   %8 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 1
-  store i8 0, i8* %8, align 8, !tbaa !112
+  store i8 0, i8* %8, align 8, !tbaa !110
   %9 = getelementptr inbounds %"struct.std::thread::_State_impl.38", %"struct.std::thread::_State_impl.38"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 1
-  %10 = load i8, i8* %9, align 8, !tbaa !112, !range !72
+  %10 = load atomic i8, i8* %9 unordered, align 8, !tbaa !110, !range !70
   %11 = icmp eq i8 %10, 0
   br i1 %11, label %32, label %12
 
 12:                                               ; preds = %1
   %13 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %14 = bitcast %"class.kotlin::ScopedThread::attributes"* %2 to %union.anon.108**
-  store %union.anon.108* %13, %union.anon.108** %14, align 8, !tbaa !56
+  store %union.anon.108* %13, %union.anon.108** %14, align 8, !tbaa !45
   %15 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %16 = load i8*, i8** %15, align 8, !tbaa !58
+  %16 = load atomic i8*, i8** %15 unordered, align 8, !tbaa !47
   %17 = getelementptr inbounds %"struct.std::thread::_State_impl.38", %"struct.std::thread::_State_impl.38"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %18 = bitcast %union.anon.108* %17 to i8*
   %19 = icmp eq i8* %16, %18
@@ -29081,23 +29656,23 @@
 
 22:                                               ; preds = %12
   %23 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  store i8* %16, i8** %23, align 8, !tbaa !58
+  store i8* %16, i8** %23, align 8, !tbaa !47
   %24 = getelementptr inbounds %"struct.std::thread::_State_impl.38", %"struct.std::thread::_State_impl.38"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
-  %25 = load i64, i64* %24, align 8, !tbaa !51
+  %25 = load atomic i64, i64* %24 unordered, align 8, !tbaa !50
   %26 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2, i32 0
-  store i64 %25, i64* %26, align 8, !tbaa !51
+  store i64 %25, i64* %26, align 8, !tbaa !50
   br label %27
 
 27:                                               ; preds = %22, %20
   %28 = getelementptr inbounds %"struct.std::thread::_State_impl.38", %"struct.std::thread::_State_impl.38"* %0, i64 0, i32 1, i32 0, i32 0, i32 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  %29 = load i64, i64* %28, align 8, !tbaa !60
+  %29 = load atomic i64, i64* %28 unordered, align 8, !tbaa !51
   %30 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 1
-  store i64 %29, i64* %30, align 8, !tbaa !60
+  store i64 %29, i64* %30, align 8, !tbaa !51
   %31 = bitcast %"class.kotlin::ScopedThread::attributes"* %4 to %union.anon.108**
-  store %union.anon.108* %17, %union.anon.108** %31, align 8, !tbaa !58
-  store i64 0, i64* %28, align 8, !tbaa !60
-  store i8 0, i8* %18, align 8, !tbaa !51
-  store i8 1, i8* %8, align 8, !tbaa !112
+  store %union.anon.108* %17, %union.anon.108** %31, align 8, !tbaa !47
+  store i64 0, i64* %28, align 8, !tbaa !51
+  store i8 0, i8* %18, align 8, !tbaa !50
+  store i8 1, i8* %8, align 8, !tbaa !110
   br label %32
 
 32:                                               ; preds = %27, %1
@@ -29105,13 +29680,13 @@
           to label %33 unwind label %43
 
 33:                                               ; preds = %32
-  %34 = load i8, i8* %8, align 8, !tbaa !112, !range !72
+  %34 = load atomic i8, i8* %8 unordered, align 8, !tbaa !110, !range !70
   %35 = icmp eq i8 %34, 0
   br i1 %35, label %55, label %36
 
 36:                                               ; preds = %33
   %37 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %38 = load i8*, i8** %37, align 8, !tbaa !58
+  %38 = load atomic i8*, i8** %37 unordered, align 8, !tbaa !47
   %39 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %40 = bitcast %union.anon.108* %39 to i8*
   %41 = icmp eq i8* %38, %40
@@ -29124,13 +29699,13 @@
 43:                                               ; preds = %32
   %44 = landingpad { i8*, i32 }
           cleanup
-  %45 = load i8, i8* %8, align 8, !tbaa !112, !range !72
+  %45 = load atomic i8, i8* %8 unordered, align 8, !tbaa !110, !range !70
   %46 = icmp eq i8 %45, 0
   br i1 %46, label %54, label %47
 
 47:                                               ; preds = %43
   %48 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %49 = load i8*, i8** %48, align 8, !tbaa !58
+  %49 = load atomic i8*, i8** %48 unordered, align 8, !tbaa !47
   %50 = getelementptr inbounds %"class.kotlin::ScopedThread::attributes", %"class.kotlin::ScopedThread::attributes"* %2, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 2
   %51 = bitcast %union.anon.108* %50 to i8*
   %52 = icmp eq i8* %49, %51
@@ -29159,139 +29734,138 @@
   call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %10) #37
   %11 = getelementptr %"class.std::unique_ptr.112", %"class.std::unique_ptr.112"* %9, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
   %12 = bitcast %"class.std::unique_ptr.112"* %9 to i64*
-  %13 = load i64, i64* %12, align 8, !tbaa !3
+  %13 = load atomic i64, i64* %12 unordered, align 8, !tbaa !3
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %11, align 8, !tbaa !3
   %14 = bitcast %"class.std::unique_ptr.112"* %5 to i64*
-  store i64 %13, i64* %14, align 8, !tbaa !198
+  store i64 %13, i64* %14, align 8, !tbaa !197
   %15 = inttoptr i64 %13 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
   %16 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %15, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
   %17 = inttoptr i64 %13 to i64*
-  %18 = load i64, i64* %17, align 8, !tbaa !3
+  %18 = load atomic i64, i64* %17 unordered, align 8, !tbaa !3
   store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %16, align 8, !tbaa !3
-  %19 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %11, align 8, !tbaa !3
+  %19 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %11 unordered, align 8, !tbaa !3
   store i64 %18, i64* %12, align 8, !tbaa !3
   %20 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %19, null
   %21 = inttoptr i64 %18 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
-  br i1 %20, label %27, label %22
+  br i1 %20, label %26, label %22
 
 22:                                               ; preds = %4
   %23 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %19, i64 0, i32 0
   tail call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %23) #37
   %24 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %19 to i8*
   tail call fastcc void @mi_free(i8* nonnull %24) #37
-  %25 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %11, align 8, !tbaa !3
-  %26 = ptrtoint %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %25 to i64
-  br label %27
+  %25 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %11 unordered, align 8, !tbaa !3
+  br label %26
 
-27:                                               ; preds = %22, %4
-  %28 = phi i64 [ %18, %4 ], [ %26, %22 ]
-  %29 = phi %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* [ %21, %4 ], [ %25, %22 ]
-  %30 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %29, null
-  br i1 %30, label %31, label %33
+26:                                               ; preds = %22, %4
+  %27 = phi %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* [ %21, %4 ], [ %25, %22 ]
+  %28 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %27, null
+  br i1 %28, label %29, label %31
 
-31:                                               ; preds = %27
-  %32 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage", %"class.kotlin::mm::internal::ObjectFactoryStorage"* %1, i64 0, i32 1
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %2, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %32, align 8, !tbaa !329
-  %.pre = load i64, i64* %12, align 8, !tbaa !3
-  br label %33
+29:                                               ; preds = %26
+  %30 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage", %"class.kotlin::mm::internal::ObjectFactoryStorage"* %1, i64 0, i32 1
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %2, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %30, align 8, !tbaa !333
+  br label %31
 
-33:                                               ; preds = %31, %27
-  %34 = phi i64 [ %28, %27 ], [ %.pre, %31 ]
-  %35 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage", %"class.kotlin::mm::internal::ObjectFactoryStorage"* %1, i64 0, i32 2
-  %36 = load i64, i64* %35, align 8, !tbaa !386
-  %37 = add i64 %36, -1
-  store i64 %37, i64* %35, align 8, !tbaa !386
-  %38 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage", %"class.kotlin::mm::internal::ObjectFactoryStorage"* %1, i64 0, i32 3
-  %39 = load i64, i64* %38, align 8, !tbaa !387
-  %40 = sub i64 %39, %3
-  store i64 %40, i64* %38, align 8, !tbaa !387
-  %41 = getelementptr inbounds %"class.std::unique_ptr.112", %"class.std::unique_ptr.112"* %5, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %42 = load i64, i64* %14, align 8, !tbaa !3
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %41, align 8, !tbaa !3
-  %43 = bitcast %"struct.std::pair.185"* %0 to i64*
-  store i64 %42, i64* %43, align 8, !tbaa !198
-  %44 = getelementptr inbounds %"struct.std::pair.185", %"struct.std::pair.185"* %0, i64 0, i32 1
-  %45 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %44 to i64*
-  store i64 %34, i64* %45, align 8, !tbaa !388
+31:                                               ; preds = %29, %26
+  %32 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage", %"class.kotlin::mm::internal::ObjectFactoryStorage"* %1, i64 0, i32 2
+  %33 = load atomic i64, i64* %32 unordered, align 8, !tbaa !388
+  %34 = add i64 %33, -1
+  store i64 %34, i64* %32, align 8, !tbaa !388
+  %35 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage", %"class.kotlin::mm::internal::ObjectFactoryStorage"* %1, i64 0, i32 3
+  %36 = load atomic i64, i64* %35 unordered, align 8, !tbaa !389
+  %37 = sub i64 %36, %3
+  store i64 %37, i64* %35, align 8, !tbaa !389
+  %38 = getelementptr inbounds %"class.std::unique_ptr.112", %"class.std::unique_ptr.112"* %5, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %39 = load atomic i64, i64* %12 unordered, align 8, !tbaa !3
+  %40 = load atomic i64, i64* %14 unordered, align 8, !tbaa !3
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %38, align 8, !tbaa !3
+  %41 = bitcast %"struct.std::pair.185"* %0 to i64*
+  store i64 %40, i64* %41, align 8, !tbaa !197
+  %42 = getelementptr inbounds %"struct.std::pair.185", %"struct.std::pair.185"* %0, i64 0, i32 1
+  %43 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %42 to i64*
+  store i64 %39, i64* %43, align 8, !tbaa !390
   call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %5) #37
   call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %10) #37
   ret void
 }
 
 ; Function Attrs: noinline uwtable
-define internal fastcc void @"_ZZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS1_EERNS0_11GCSchedulerEENK3$_2clEv"(%"class.kotlin::gc::ConcurrentMarkAndSweep"* %.0.0.val) unnamed_addr #29 align 2 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
-  %1 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %.not = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %1, null
-  br i1 %.not, label %6, label %2
+define internal fastcc void @"_ZZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS1_EERNS0_11GCSchedulerEENK3$_2clEv"(%class.anon.78* nocapture readonly %0) unnamed_addr #29 align 2 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
+  %2 = getelementptr inbounds %class.anon.78, %class.anon.78* %0, i64 0, i32 0
+  %3 = load atomic %"class.kotlin::gc::ConcurrentMarkAndSweep"*, %"class.kotlin::gc::ConcurrentMarkAndSweep"** %2 unordered, align 8, !tbaa !406
+  %4 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %.not = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, null
+  br i1 %.not, label %9, label %5
 
-2:                                                ; preds = %0
-  %3 = bitcast %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %1 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*
-  %4 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %1, i64 0, i32 1, i32 8, i32 0, i32 0
-  %5 = atomicrmw xchg i32* %4, i32 1 seq_cst, align 4
-  br label %6
+5:                                                ; preds = %1
+  %6 = bitcast %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*
+  %7 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 8, i32 0, i32 0
+  %8 = atomicrmw xchg i32* %7, i32 1 seq_cst, align 4
+  br label %9
 
-6:                                                ; preds = %2, %0
-  %7 = phi i32 [ %5, %2 ], [ 1, %0 ]
-  %8 = phi %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* [ %3, %2 ], [ null, %0 ]
-  %9 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %.0.0.val, i64 0, i32 2
-  %10 = invoke fastcc i64 @_ZN13GCStateHolder8scheduleEv(%class.GCStateHolder* nonnull %9)
-          to label %11 unwind label %26
+9:                                                ; preds = %5, %1
+  %10 = phi i32 [ %8, %5 ], [ 1, %1 ]
+  %11 = phi %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* [ %6, %5 ], [ null, %1 ]
+  %12 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %3, i64 0, i32 2
+  %13 = invoke fastcc i64 @_ZN13GCStateHolder8scheduleEv(%class.GCStateHolder* nonnull %12)
+          to label %14 unwind label %29
 
-11:                                               ; preds = %6
-  %12 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %8, null
-  br i1 %12, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2, label %13
+14:                                               ; preds = %9
+  %15 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %11, null
+  br i1 %15, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2, label %16
 
-13:                                               ; preds = %11
-  %14 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %8, i64 328
-  %15 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %14 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %16 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %14 to i32*
-  %17 = atomicrmw xchg i32* %16, i32 %7 seq_cst, align 4
-  %18 = icmp eq i32 %17, 1
-  %19 = icmp eq i32 %7, 0
-  %20 = and i1 %19, %18
-  br i1 %20, label %21, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2
+16:                                               ; preds = %14
+  %17 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %11, i64 328
+  %18 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %17 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %19 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %17 to i32*
+  %20 = atomicrmw xchg i32* %19, i32 %10 seq_cst, align 4
+  %21 = icmp eq i32 %20, 1
+  %22 = icmp eq i32 %10, 0
+  %23 = and i1 %22, %21
+  br i1 %23, label %24, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2
 
-21:                                               ; preds = %13
-  %22 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %23 = and i8 %22, 1
-  %24 = icmp eq i8 %23, 0
-  br i1 %24, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2, label %25
+24:                                               ; preds = %16
+  %25 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %26 = and i8 %25, 1
+  %27 = icmp eq i8 %26, 0
+  br i1 %27, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2, label %28
 
-25:                                               ; preds = %21
-  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %15) #37
+28:                                               ; preds = %24
+  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %18) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2: ; preds = %25, %21, %13, %11
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2: ; preds = %28, %24, %16, %14
   ret void
 
-26:                                               ; preds = %6
-  %27 = landingpad { i8*, i32 }
+29:                                               ; preds = %9
+  %30 = landingpad { i8*, i32 }
           cleanup
-  %28 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %8, null
-  br i1 %28, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %29
+  %31 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %11, null
+  br i1 %31, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %32
 
-29:                                               ; preds = %26
-  %30 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %8, i64 328
-  %31 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %30 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %32 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %30 to i32*
-  %33 = atomicrmw xchg i32* %32, i32 %7 seq_cst, align 4
-  %34 = icmp eq i32 %33, 1
-  %35 = icmp eq i32 %7, 0
-  %36 = and i1 %35, %34
-  br i1 %36, label %37, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
+32:                                               ; preds = %29
+  %33 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %11, i64 328
+  %34 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %33 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %35 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %33 to i32*
+  %36 = atomicrmw xchg i32* %35, i32 %10 seq_cst, align 4
+  %37 = icmp eq i32 %36, 1
+  %38 = icmp eq i32 %10, 0
+  %39 = and i1 %38, %37
+  br i1 %39, label %40, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-37:                                               ; preds = %29
-  %38 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %39 = and i8 %38, 1
-  %40 = icmp eq i8 %39, 0
-  br i1 %40, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %41
+40:                                               ; preds = %32
+  %41 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %42 = and i8 %41, 1
+  %43 = icmp eq i8 %42, 0
+  br i1 %43, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %44
 
-41:                                               ; preds = %37
-  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %31) #37
+44:                                               ; preds = %40
+  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %34) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %41, %37, %29, %26
-  resume { i8*, i32 } %27
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %44, %40, %32, %29
+  resume { i8*, i32 } %30
 }
 
 ; Function Attrs: nounwind uwtable
@@ -29300,90 +29874,90 @@
   %5 = alloca %"class.std::function.57", align 8
   %6 = tail call noalias dereferenceable_or_null(168) i8* @calloc(i64 1, i64 168) #37
   %7 = getelementptr inbounds %"class.kotlin::gc::GC", %"class.kotlin::gc::GC"* %1, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %8 = load %"class.kotlin::gc::GC::Impl"*, %"class.kotlin::gc::GC::Impl"** %7, align 8, !tbaa !3, !noalias !404
+  %8 = load atomic %"class.kotlin::gc::GC::Impl"*, %"class.kotlin::gc::GC::Impl"** %7 unordered, align 8, !tbaa !3, !noalias !408
   %9 = getelementptr inbounds %"class.kotlin::gc::GC::Impl", %"class.kotlin::gc::GC::Impl"* %8, i64 0, i32 2
   %10 = bitcast %"class.std::function.57"* %5 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %10) #37, !noalias !404
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %10) #37, !noalias !408
   %11 = ptrtoint %"class.kotlin::gc::GCScheduler"* %9 to i64
   %12 = getelementptr inbounds %"class.std::function.57", %"class.std::function.57"* %5, i64 0, i32 0, i32 1
   %13 = getelementptr inbounds %"class.std::function.57", %"class.std::function.57"* %5, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  store i64 %11, i64* %13, align 8, !tbaa !3, !noalias !409
+  store i64 %11, i64* %13, align 8, !tbaa !3, !noalias !413
   %14 = getelementptr inbounds %"class.std::function.57", %"class.std::function.57"* %5, i64 0, i32 1
   %15 = getelementptr inbounds %"class.kotlin::gc::GCScheduler", %"class.kotlin::gc::GCScheduler"* %9, i64 0, i32 0
   %16 = bitcast i8* %6 to %"struct.kotlin::gc::GCSchedulerConfig"**
-  store %"struct.kotlin::gc::GCSchedulerConfig"* %15, %"struct.kotlin::gc::GCSchedulerConfig"** %16, align 8, !tbaa !3, !alias.scope !412, !noalias !404
+  store %"struct.kotlin::gc::GCSchedulerConfig"* %15, %"struct.kotlin::gc::GCSchedulerConfig"** %16, align 8, !tbaa !3, !alias.scope !416, !noalias !408
   %17 = getelementptr inbounds i8, i8* %6, i64 8
   %18 = getelementptr inbounds i8, i8* %6, i64 24
   %19 = bitcast { i64, i64 }* %4 to i8*
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %19)
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %19, i8* nonnull align 8 dereferenceable(16) %10, i64 16, i1 false) #37, !tbaa.struct !154, !noalias !409
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %10, i8* nonnull align 8 dereferenceable(16) %17, i64 16, i1 false) #37, !tbaa.struct !154, !noalias !404
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %17, i8* nonnull align 8 dereferenceable(16) %19, i64 16, i1 false) #37, !tbaa.struct !154, !noalias !404
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %19, i8* nonnull align 8 dereferenceable(16) %10, i64 16, i1 false) #37, !tbaa.struct !152, !noalias !413
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %10, i8* nonnull align 8 dereferenceable(16) %17, i64 16, i1 false) #37, !tbaa.struct !152, !noalias !408
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %17, i8* nonnull align 8 dereferenceable(16) %19, i64 16, i1 false) #37, !tbaa.struct !152, !noalias !408
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %19)
   %20 = bitcast i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %12 to i64*
   %21 = bitcast i8* %18 to i64*
-  store i64 0, i64* %20, align 8, !tbaa !3, !noalias !409
-  store i64 ptrtoint (i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* @_ZNSt14_Function_base13_Base_managerIZN6kotlin2gc11GCScheduler13NewThreadDataEvEUlRT_E_E10_M_managerERSt9_Any_dataRKS8_St18_Manager_operation to i64), i64* %21, align 8, !tbaa !3, !alias.scope !412, !noalias !404
+  store i64 0, i64* %20, align 8, !tbaa !3, !noalias !413
+  store i64 ptrtoint (i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* @_ZNSt14_Function_base13_Base_managerIZN6kotlin2gc11GCScheduler13NewThreadDataEvEUlRT_E_E10_M_managerERSt9_Any_dataRKS8_St18_Manager_operation to i64), i64* %21, align 8, !tbaa !3, !alias.scope !416, !noalias !408
   %22 = getelementptr inbounds i8, i8* %6, i64 32
   %23 = bitcast void (%"union.std::_Any_data"*, %"class.kotlin::gc::GCSchedulerThreadData"*)** %14 to i64*
   %24 = bitcast i8* %22 to i64*
-  store i64 0, i64* %23, align 8, !tbaa !3, !noalias !409
-  store i64 ptrtoint (void (%"union.std::_Any_data"*, %"class.kotlin::gc::GCSchedulerThreadData"*)* @_ZNSt17_Function_handlerIFvRN6kotlin2gc21GCSchedulerThreadDataEEZNS1_11GCScheduler13NewThreadDataEvEUlRT_E_E9_M_invokeERKSt9_Any_dataS3_ to i64), i64* %24, align 8, !tbaa !3, !alias.scope !412, !noalias !404
+  store i64 0, i64* %23, align 8, !tbaa !3, !noalias !413
+  store i64 ptrtoint (void (%"union.std::_Any_data"*, %"class.kotlin::gc::GCSchedulerThreadData"*)* @_ZNSt17_Function_handlerIFvRN6kotlin2gc21GCSchedulerThreadDataEEZNS1_11GCScheduler13NewThreadDataEvEUlRT_E_E9_M_invokeERKSt9_Any_dataS3_ to i64), i64* %24, align 8, !tbaa !3, !alias.scope !416, !noalias !408
   %25 = getelementptr inbounds i8, i8* %6, i64 40
   %26 = getelementptr inbounds i8, i8* %6, i64 48
   %27 = bitcast i8* %26 to i64*
   %28 = getelementptr inbounds i8, i8* %6, i64 64
   %29 = bitcast i8* %28 to i64*
-  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(32) %25, i8 0, i64 32, i1 false) #37, !alias.scope !412, !noalias !404
+  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(32) %25, i8 0, i64 32, i1 false) #37, !alias.scope !416, !noalias !408
   %30 = getelementptr inbounds %"class.kotlin::gc::GC::Impl", %"class.kotlin::gc::GC::Impl"* %8, i64 0, i32 2, i32 0, i32 1, i32 0, i32 0
-  %31 = load atomic i64, i64* %30 seq_cst, align 8, !noalias !409
-  store i64 %31, i64* %27, align 8, !tbaa !319, !alias.scope !412, !noalias !404
-  %32 = load %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %16, align 8, !tbaa !318, !alias.scope !412, !noalias !404
+  %31 = load atomic i64, i64* %30 seq_cst, align 8, !noalias !413
+  store i64 %31, i64* %27, align 8, !tbaa !317, !alias.scope !416, !noalias !408
+  %32 = load atomic %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %16 unordered, align 8, !tbaa !316, !alias.scope !416, !noalias !408
   %33 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %32, i64 0, i32 0, i32 0, i32 0
-  %34 = load atomic i32, i32* %33 seq_cst, align 4, !noalias !409
+  %34 = load atomic i32, i32* %33 seq_cst, align 4, !noalias !413
   %35 = sext i32 %34 to i64
-  store i64 %35, i64* %29, align 8, !tbaa !320, !alias.scope !412, !noalias !404
-  %36 = load i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %12, align 8, !tbaa !103, !noalias !409
+  store i64 %35, i64* %29, align 8, !tbaa !318, !alias.scope !416, !noalias !408
+  %36 = load atomic i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %12 unordered, align 8, !tbaa !101, !noalias !413
   %37 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %36, null
   br i1 %37, label %44, label %38
 
 38:                                               ; preds = %3
   %39 = getelementptr inbounds %"class.std::function.57", %"class.std::function.57"* %5, i64 0, i32 0, i32 0
   %40 = invoke zeroext i1 %36(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %39, %"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %39, i32 3)
-          to label %44 unwind label %41, !noalias !409
+          to label %44 unwind label %41, !noalias !413
 
 41:                                               ; preds = %38
   %42 = landingpad { i8*, i32 }
           catch i8* null
   %43 = extractvalue { i8*, i32 } %42, 0
-  call fastcc void @__clang_call_terminate(i8* %43) #51, !noalias !409
+  call fastcc void @__clang_call_terminate(i8* %43) #51, !noalias !413
   unreachable
 
 44:                                               ; preds = %38, %3
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %10) #37, !noalias !404
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %10) #37, !noalias !408
   %45 = getelementptr inbounds i8, i8* %6, i64 72
-  %46 = load %"class.kotlin::gc::GC::Impl"*, %"class.kotlin::gc::GC::Impl"** %7, align 8, !tbaa !3, !noalias !404
+  %46 = load atomic %"class.kotlin::gc::GC::Impl"*, %"class.kotlin::gc::GC::Impl"** %7 unordered, align 8, !tbaa !3, !noalias !408
   %47 = getelementptr inbounds %"class.kotlin::gc::GC::Impl", %"class.kotlin::gc::GC::Impl"* %46, i64 0, i32 3
   %48 = bitcast i8* %45 to %"class.kotlin::gc::ConcurrentMarkAndSweep"**
-  store %"class.kotlin::gc::ConcurrentMarkAndSweep"* %47, %"class.kotlin::gc::ConcurrentMarkAndSweep"** %48, align 8, !tbaa !3, !noalias !404
+  store %"class.kotlin::gc::ConcurrentMarkAndSweep"* %47, %"class.kotlin::gc::ConcurrentMarkAndSweep"** %48, align 8, !tbaa !3, !noalias !408
   %49 = getelementptr inbounds i8, i8* %6, i64 80
   %50 = bitcast i8* %49 to %"class.kotlin::mm::ThreadData.119"**
-  store %"class.kotlin::mm::ThreadData.119"* %2, %"class.kotlin::mm::ThreadData.119"** %50, align 8, !tbaa !3, !noalias !404
+  store %"class.kotlin::mm::ThreadData.119"* %2, %"class.kotlin::mm::ThreadData.119"** %50, align 8, !tbaa !3, !noalias !408
   %51 = getelementptr inbounds i8, i8* %6, i64 88
   %52 = bitcast i8* %51 to i8**
-  store i8* %6, i8** %52, align 8, !tbaa !3, !noalias !404
+  store i8* %6, i8** %52, align 8, !tbaa !3, !noalias !408
   %53 = getelementptr inbounds %"class.kotlin::gc::GC::Impl", %"class.kotlin::gc::GC::Impl"* %46, i64 0, i32 1, i32 1
   %54 = getelementptr inbounds i8, i8* %6, i64 112
   %55 = bitcast i8* %54 to %"class.kotlin::mm::internal::ObjectFactoryStorage"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage"* %53, %"class.kotlin::mm::internal::ObjectFactoryStorage"** %55, align 8, !tbaa !3, !noalias !404
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage"* %53, %"class.kotlin::mm::internal::ObjectFactoryStorage"** %55, align 8, !tbaa !3, !noalias !408
   %56 = getelementptr inbounds i8, i8* %6, i64 128
   %57 = bitcast i8* %56 to i8**
-  store i8* %45, i8** %57, align 8, !tbaa.struct !413, !noalias !404
+  store i8* %45, i8** %57, align 8, !tbaa.struct !417, !noalias !408
   %58 = getelementptr inbounds i8, i8* %6, i64 136
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(32) %58, i8 0, i64 32, i1 false) #37, !noalias !404
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(32) %58, i8 0, i64 32, i1 false) #37, !noalias !408
   %59 = ptrtoint i8* %6 to i64
   %60 = bitcast %"class.kotlin::gc::GC::ThreadData.116"* %0 to i64*
-  store i64 %59, i64* %60, align 8, !tbaa !414, !alias.scope !404
+  store i64 %59, i64* %60, align 8, !tbaa !418, !alias.scope !408
   ret void
 }
 
@@ -29408,7 +29982,7 @@
 8:                                                ; preds = %3
   %9 = getelementptr inbounds %"union.std::_Any_data", %"union.std::_Any_data"* %1, i64 0, i32 0, i32 0, i32 0
   %10 = getelementptr inbounds %"union.std::_Any_data", %"union.std::_Any_data"* %0, i64 0, i32 0, i32 0, i32 0
-  %11 = load i64, i64* %9, align 8, !tbaa !3
+  %11 = load atomic i64, i64* %9 unordered, align 8, !tbaa !3
   store i64 %11, i64* %10, align 8, !tbaa !3
   br label %12
 
@@ -29419,13 +29993,13 @@
 ; Function Attrs: nounwind uwtable
 define internal void @_ZNSt17_Function_handlerIFvRN6kotlin2gc21GCSchedulerThreadDataEEZNS1_11GCScheduler13NewThreadDataEvEUlRT_E_E9_M_invokeERKSt9_Any_dataS3_(%"union.std::_Any_data"* nocapture nonnull readonly align 8 dereferenceable(16) %0, %"class.kotlin::gc::GCSchedulerThreadData"* nonnull align 8 dereferenceable(72) %1) #17 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %3 = bitcast %"union.std::_Any_data"* %0 to %"class.kotlin::gc::GCScheduler"**
-  %4 = load %"class.kotlin::gc::GCScheduler"*, %"class.kotlin::gc::GCScheduler"** %3, align 8, !tbaa !416
+  %4 = load atomic %"class.kotlin::gc::GCScheduler"*, %"class.kotlin::gc::GCScheduler"** %3 unordered, align 8, !tbaa !420
   %5 = getelementptr inbounds %"class.kotlin::gc::GCScheduler", %"class.kotlin::gc::GCScheduler"* %4, i64 0, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0
-  %6 = load %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %5, align 8, !tbaa !3
+  %6 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GC::ThreadData::Impl"** %5 unordered, align 8, !tbaa !3
   %7 = bitcast %"class.kotlin::gc::GC::ThreadData::Impl"* %6 to void (%"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GCSchedulerThreadData"*)***
-  %8 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GCSchedulerThreadData"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GCSchedulerThreadData"*)*** %7, align 8, !tbaa !109
+  %8 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GCSchedulerThreadData"*)**, void (%"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GCSchedulerThreadData"*)*** %7 unordered, align 8, !tbaa !107
   %9 = getelementptr inbounds void (%"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GCSchedulerThreadData"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GCSchedulerThreadData"*)** %8, i64 2
-  %10 = load void (%"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GCSchedulerThreadData"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GCSchedulerThreadData"*)** %9, align 8
+  %10 = load atomic void (%"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GCSchedulerThreadData"*)*, void (%"class.kotlin::gc::GC::ThreadData::Impl"*, %"class.kotlin::gc::GCSchedulerThreadData"*)** %9 unordered, align 8
   tail call void %10(%"class.kotlin::gc::GC::ThreadData::Impl"* %6, %"class.kotlin::gc::GCSchedulerThreadData"* nonnull align 8 dereferenceable(72) %1) #37
   ret void
 }
@@ -29433,7 +30007,7 @@
 ; Function Attrs: nounwind uwtable
 define internal fastcc void @_ZN6kotlin2gc2GC10ThreadDataD2Ev(%"class.kotlin::gc::GC::ThreadData.116"* nocapture %0) unnamed_addr #17 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %2 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData.116", %"class.kotlin::gc::GC::ThreadData.116"* %0, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %3 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %2, align 8, !tbaa !3
+  %3 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %2 unordered, align 8, !tbaa !3
   %4 = icmp eq %"class.kotlin::gc::GC::ThreadData::Impl.115"* %3, null
   br i1 %4, label %19, label %5
 
@@ -29443,7 +30017,7 @@
   %7 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %3, i64 0, i32 2, i32 1, i32 2
   tail call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %7) #37
   %8 = getelementptr inbounds %"class.kotlin::gc::GC::ThreadData::Impl.115", %"class.kotlin::gc::GC::ThreadData::Impl.115"* %3, i64 0, i32 0, i32 1, i32 0, i32 1
-  %9 = load i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %8, align 8, !tbaa !103
+  %9 = load atomic i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %8 unordered, align 8, !tbaa !101
   %10 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %9, null
   br i1 %10, label %17, label %11
 
@@ -29472,271 +30046,281 @@
 ; Function Attrs: nounwind uwtable
 define internal fastcc nonnull align 8 dereferenceable(8) %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* @_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8Producer6InsertEm(%"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* nocapture %0, i64 %1) unnamed_addr #17 align 2 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
   %3 = alloca %"class.std::unique_lock.266", align 8
-  %4 = alloca %"class.std::unique_ptr.112", align 8
-  %5 = bitcast %"class.std::unique_ptr.112"* %4 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %5) #37
-  %6 = add i64 %1, 15
-  %7 = and i64 %6, -8
-  %8 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 1, i32 1
-  %9 = load %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData"*, %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData"** %8, align 8, !tbaa !418, !noalias !419
-  %10 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData", %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData"* %9, i64 0, i32 2
-  %11 = load %"class.kotlin::gc::GCSchedulerThreadData"*, %"class.kotlin::gc::GCSchedulerThreadData"** %10, align 8, !tbaa !422, !noalias !419
-  %12 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %11, i64 0, i32 2
-  %13 = load i64, i64* %12, align 8, !tbaa !113, !noalias !419
-  %14 = add i64 %13, %7
-  store i64 %14, i64* %12, align 8, !tbaa !113, !noalias !419
-  %15 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %11, i64 0, i32 3
-  %16 = load i64, i64* %15, align 8, !tbaa !319, !noalias !419
-  %17 = icmp ult i64 %14, %16
-  br i1 %17, label %45, label %21
+  %4 = alloca %"class.kotlin::CalledFromNativeGuard", align 8
+  %5 = alloca %"class.std::unique_ptr.112", align 8
+  %6 = bitcast %"class.std::unique_ptr.112"* %5 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %6) #37
+  %7 = add i64 %1, 15
+  %8 = and i64 %7, -8
+  %9 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 1, i32 1
+  %10 = load atomic %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData"*, %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData"** %9 unordered, align 8, !tbaa !422, !noalias !423
+  %11 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData", %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData"* %10, i64 0, i32 2
+  %12 = load atomic %"class.kotlin::gc::GCSchedulerThreadData"*, %"class.kotlin::gc::GCSchedulerThreadData"** %11 unordered, align 8, !tbaa !426, !noalias !423
+  %13 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %12, i64 0, i32 2
+  %14 = load atomic i64, i64* %13 unordered, align 8, !tbaa !111, !noalias !423
+  %15 = add i64 %14, %8
+  store i64 %15, i64* %13, align 8, !tbaa !111, !noalias !423
+  %16 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %12, i64 0, i32 3
+  %17 = load atomic i64, i64* %16 unordered, align 8, !tbaa !317, !noalias !423
+  %18 = icmp ult i64 %15, %17
+  br i1 %18, label %46, label %22
 
-18:                                               ; preds = %113
-  %19 = landingpad { i8*, i32 }
+19:                                               ; preds = %122
+  %20 = landingpad { i8*, i32 }
           catch i8* null
-  %20 = extractvalue { i8*, i32 } %19, 0
-  call fastcc void @__clang_call_terminate(i8* %20) #51, !noalias !419
+  %21 = extractvalue { i8*, i32 } %20, 0
+  call fastcc void @__clang_call_terminate(i8* %21) #51, !noalias !423
   unreachable
 
-21:                                               ; preds = %2
-  %22 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %11, i64 0, i32 1, i32 0, i32 1
-  %23 = load i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %22, align 8, !tbaa !103, !noalias !419
-  %24 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %23, null
-  br i1 %24, label %25, label %27
+22:                                               ; preds = %2
+  %23 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %12, i64 0, i32 1, i32 0, i32 1
+  %24 = load atomic i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)*, i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)** %23 unordered, align 8, !tbaa !101, !noalias !423
+  %25 = icmp eq i1 (%"union.std::_Any_data"*, %"union.std::_Any_data"*, i32)* %24, null
+  br i1 %25, label %26, label %28
 
-25:                                               ; preds = %21
+26:                                               ; preds = %22
   invoke void @_ZSt25__throw_bad_function_callv() #50
-          to label %26 unwind label %31, !noalias !419
+          to label %27 unwind label %32, !noalias !423
 
-26:                                               ; preds = %25
+27:                                               ; preds = %26
   unreachable
 
-27:                                               ; preds = %21
-  %28 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %11, i64 0, i32 1, i32 1
-  %29 = load void (%"union.std::_Any_data"*, %"class.kotlin::gc::GCSchedulerThreadData"*)*, void (%"union.std::_Any_data"*, %"class.kotlin::gc::GCSchedulerThreadData"*)** %28, align 8, !tbaa !423, !noalias !419
-  %30 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %11, i64 0, i32 1, i32 0, i32 0
-  invoke void %29(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %30, %"class.kotlin::gc::GCSchedulerThreadData"* nonnull align 8 dereferenceable(72) %11)
-          to label %34 unwind label %31, !noalias !419
+28:                                               ; preds = %22
+  %29 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %12, i64 0, i32 1, i32 1
+  %30 = load atomic void (%"union.std::_Any_data"*, %"class.kotlin::gc::GCSchedulerThreadData"*)*, void (%"union.std::_Any_data"*, %"class.kotlin::gc::GCSchedulerThreadData"*)** %29 unordered, align 8, !tbaa !427, !noalias !423
+  %31 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %12, i64 0, i32 1, i32 0, i32 0
+  invoke void %30(%"union.std::_Any_data"* nonnull align 8 dereferenceable(16) %31, %"class.kotlin::gc::GCSchedulerThreadData"* nonnull align 8 dereferenceable(72) %12)
+          to label %35 unwind label %32, !noalias !423
 
-31:                                               ; preds = %27, %25
-  %32 = landingpad { i8*, i32 }
+32:                                               ; preds = %28, %26
+  %33 = landingpad { i8*, i32 }
           catch i8* null
-  %33 = extractvalue { i8*, i32 } %32, 0
-  tail call fastcc void @__clang_call_terminate(i8* %33) #51, !noalias !419
+  %34 = extractvalue { i8*, i32 } %33, 0
+  tail call fastcc void @__clang_call_terminate(i8* %34) #51, !noalias !423
   unreachable
 
-34:                                               ; preds = %27
-  store i64 0, i64* %12, align 8, !tbaa !113, !noalias !419
-  %35 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %11, i64 0, i32 4
-  store i64 0, i64* %35, align 8, !tbaa !317, !noalias !419
-  %36 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %11, i64 0, i32 0
-  %37 = load %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %36, align 8, !tbaa !318, !noalias !419
-  %38 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %37, i64 0, i32 1, i32 0, i32 0
-  %39 = load atomic i64, i64* %38 seq_cst, align 8, !noalias !419
-  store i64 %39, i64* %15, align 8, !tbaa !319, !noalias !419
-  %40 = load %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %36, align 8, !tbaa !318, !noalias !419
-  %41 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %40, i64 0, i32 0, i32 0, i32 0
-  %42 = load atomic i32, i32* %41 seq_cst, align 4, !noalias !419
-  %43 = sext i32 %42 to i64
-  %44 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %11, i64 0, i32 5
-  store i64 %43, i64* %44, align 8, !tbaa !320, !noalias !419
-  br label %45
+35:                                               ; preds = %28
+  store i64 0, i64* %13, align 8, !tbaa !111, !noalias !423
+  %36 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %12, i64 0, i32 4
+  store i64 0, i64* %36, align 8, !tbaa !315, !noalias !423
+  %37 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %12, i64 0, i32 0
+  %38 = load atomic %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %37 unordered, align 8, !tbaa !316, !noalias !423
+  %39 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %38, i64 0, i32 1, i32 0, i32 0
+  %40 = load atomic i64, i64* %39 seq_cst, align 8, !noalias !423
+  store i64 %40, i64* %16, align 8, !tbaa !317, !noalias !423
+  %41 = load atomic %"struct.kotlin::gc::GCSchedulerConfig"*, %"struct.kotlin::gc::GCSchedulerConfig"** %37 unordered, align 8, !tbaa !316, !noalias !423
+  %42 = getelementptr inbounds %"struct.kotlin::gc::GCSchedulerConfig", %"struct.kotlin::gc::GCSchedulerConfig"* %41, i64 0, i32 0, i32 0, i32 0
+  %43 = load atomic i32, i32* %42 seq_cst, align 4, !noalias !423
+  %44 = sext i32 %43 to i64
+  %45 = getelementptr inbounds %"class.kotlin::gc::GCSchedulerThreadData", %"class.kotlin::gc::GCSchedulerThreadData"* %12, i64 0, i32 5
+  store i64 %44, i64* %45, align 8, !tbaa !318, !noalias !423
+  br label %46
 
-45:                                               ; preds = %34, %2
-  %46 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1, !noalias !419
-  %47 = and i8 %46, 1
-  %48 = icmp eq i8 %47, 0
-  br i1 %48, label %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData19SafePointAllocationEm.exit.i, label %49
+46:                                               ; preds = %35, %2
+  %47 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1, !noalias !423
+  %48 = and i8 %47, 1
+  %49 = icmp eq i8 %48, 0
+  br i1 %49, label %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData19SafePointAllocationEm.exit.i, label %50
 
-49:                                               ; preds = %45
-  tail call fastcc void @_ZN6kotlin2mm26SuspendIfRequestedSlowPathEv() #37, !noalias !419
+50:                                               ; preds = %46
+  tail call fastcc void @_ZN6kotlin2mm26SuspendIfRequestedSlowPathEv() #37, !noalias !423
   br label %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData19SafePointAllocationEm.exit.i
 
-_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData19SafePointAllocationEm.exit.i: ; preds = %49, %45
-  %50 = tail call fastcc i8* @_ZN6kotlin20allocateInObjectPoolEm(i64 %7) #37, !noalias !419
-  %51 = icmp eq i8* %50, null
-  br i1 %51, label %52, label %_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE4Node6CreateERS8_m.exit
+_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData19SafePointAllocationEm.exit.i: ; preds = %50, %46
+  %51 = tail call fastcc i8* @_ZN6kotlin20allocateInObjectPoolEm(i64 %8) #37, !noalias !423
+  %52 = icmp eq i8* %51, null
+  br i1 %52, label %53, label %_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE4Node6CreateERS8_m.exit
 
-52:                                               ; preds = %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData19SafePointAllocationEm.exit.i
-  %53 = load %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData"*, %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData"** %8, align 8, !tbaa !418, !noalias !419
-  %54 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3, !noalias !419
-  %55 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %54, i64 328
-  %56 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %55 to i32*
-  %57 = atomicrmw xchg i32* %56, i32 1 seq_cst, align 4, !noalias !419
-  %58 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData", %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData"* %53, i64 0, i32 0
-  %59 = load %"class.kotlin::gc::ConcurrentMarkAndSweep"*, %"class.kotlin::gc::ConcurrentMarkAndSweep"** %58, align 8, !tbaa !424, !noalias !419
-  %60 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %59, i64 0, i32 2
-  %61 = invoke fastcc i64 @_ZN13GCStateHolder8scheduleEv(%class.GCStateHolder* nonnull %60)
-          to label %62 unwind label %108, !noalias !419
+53:                                               ; preds = %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData19SafePointAllocationEm.exit.i
+  %54 = load atomic %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData"*, %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData"** %9 unordered, align 8, !tbaa !422, !noalias !423
+  %55 = bitcast %"class.kotlin::CalledFromNativeGuard"* %4 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %55) #37, !noalias !423
+  %56 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3, !noalias !423
+  %57 = getelementptr inbounds %"class.kotlin::CalledFromNativeGuard", %"class.kotlin::CalledFromNativeGuard"* %4, i64 0, i32 0
+  store %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %56, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %57, align 8, !tbaa !34, !noalias !423
+  %58 = getelementptr inbounds %"class.kotlin::CalledFromNativeGuard", %"class.kotlin::CalledFromNativeGuard"* %4, i64 0, i32 2
+  store i8 0, i8* %58, align 4, !tbaa !39, !noalias !423
+  %59 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %56, i64 328
+  %60 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %59 to i32*
+  %61 = atomicrmw xchg i32* %60, i32 1 seq_cst, align 4, !noalias !423
+  %62 = getelementptr inbounds %"class.kotlin::CalledFromNativeGuard", %"class.kotlin::CalledFromNativeGuard"* %4, i64 0, i32 1
+  store i32 %61, i32* %62, align 8, !tbaa !38, !noalias !423
+  %63 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData", %"class.kotlin::gc::ConcurrentMarkAndSweep::ThreadData"* %54, i64 0, i32 0
+  %64 = load atomic %"class.kotlin::gc::ConcurrentMarkAndSweep"*, %"class.kotlin::gc::ConcurrentMarkAndSweep"** %63 unordered, align 8, !tbaa !428, !noalias !423
+  %65 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %64, i64 0, i32 2
+  %66 = invoke fastcc i64 @_ZN13GCStateHolder8scheduleEv(%class.GCStateHolder* nonnull %65)
+          to label %67 unwind label %117, !noalias !423
 
-62:                                               ; preds = %52
-  %63 = load %"class.kotlin::gc::ConcurrentMarkAndSweep"*, %"class.kotlin::gc::ConcurrentMarkAndSweep"** %58, align 8, !tbaa !424, !noalias !419
-  %64 = bitcast %"class.std::unique_lock.266"* %3 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %64) #37, !noalias !419
-  %65 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %63, i64 0, i32 2, i32 2, i32 1
-  %66 = load %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %65, align 8, !tbaa !401, !noalias !419
-  %67 = getelementptr inbounds %"class.std::unique_lock.266", %"class.std::unique_lock.266"* %3, i64 0, i32 0
-  store %"class.std::recursive_mutex"* %66, %"class.std::recursive_mutex"** %67, align 8, !tbaa !257, !noalias !419
-  %68 = getelementptr inbounds %"class.std::unique_lock.266", %"class.std::unique_lock.266"* %3, i64 0, i32 1
-  store i8 0, i8* %68, align 8, !tbaa !259, !noalias !419
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %69, label %74
+67:                                               ; preds = %53
+  %68 = load atomic %"class.kotlin::gc::ConcurrentMarkAndSweep"*, %"class.kotlin::gc::ConcurrentMarkAndSweep"** %63 unordered, align 8, !tbaa !428, !noalias !423
+  %69 = bitcast %"class.std::unique_lock.266"* %3 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %69) #37, !noalias !423
+  %70 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %68, i64 0, i32 2, i32 2, i32 1
+  %71 = load atomic %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %70 unordered, align 8, !tbaa !403, !noalias !423
+  %72 = getelementptr inbounds %"class.std::unique_lock.266", %"class.std::unique_lock.266"* %3, i64 0, i32 0
+  store %"class.std::recursive_mutex"* %71, %"class.std::recursive_mutex"** %72, align 8, !tbaa !255, !noalias !423
+  %73 = getelementptr inbounds %"class.std::unique_lock.266", %"class.std::unique_lock.266"* %3, i64 0, i32 1
+  store i8 0, i8* %73, align 8, !tbaa !257, !noalias !423
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %74, label %79
 
-69:                                               ; preds = %62
-  %70 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %66, i64 0, i32 0, i32 0
-  %71 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull %70) #37, !noalias !419
-  %72 = icmp eq i32 %71, 0
-  br i1 %72, label %74, label %73
+74:                                               ; preds = %67
+  %75 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %71, i64 0, i32 0, i32 0
+  %76 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* nonnull %75) #37, !noalias !423
+  %77 = icmp eq i32 %76, 0
+  br i1 %77, label %79, label %78
 
-73:                                               ; preds = %69
-  invoke void @_ZSt20__throw_system_errori(i32 %71) #50
-          to label %.noexc.i.i.i unwind label %108, !noalias !419
+78:                                               ; preds = %74
+  invoke void @_ZSt20__throw_system_errori(i32 %76) #50
+          to label %.noexc.i.i.i unwind label %117, !noalias !423
 
-.noexc.i.i.i:                                     ; preds = %73
+.noexc.i.i.i:                                     ; preds = %78
   unreachable
 
-74:                                               ; preds = %69, %62
-  store i8 1, i8* %68, align 8, !tbaa !259, !noalias !419
-  %75 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %63, i64 0, i32 2, i32 2, i32 2
-  %76 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %63, i64 0, i32 2, i32 5
-  %77 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %63, i64 0, i32 2, i32 2, i32 0
-  %78 = load i64, i64* %77, align 8, !tbaa !89, !noalias !419
-  %79 = icmp slt i64 %78, %61
-  br i1 %79, label %.preheader, label %88
-
-.preheader:                                       ; preds = %82, %74
-  %80 = load i8, i8* %76, align 8, !tbaa !146, !range !72, !noalias !419
-  %81 = icmp eq i8 %80, 0
-  br i1 %81, label %82, label %85
+79:                                               ; preds = %74, %67
+  store i8 1, i8* %73, align 8, !tbaa !257, !noalias !423
+  %80 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %68, i64 0, i32 2, i32 2, i32 2
+  %81 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %68, i64 0, i32 2, i32 5
+  %82 = getelementptr inbounds %"class.kotlin::gc::ConcurrentMarkAndSweep", %"class.kotlin::gc::ConcurrentMarkAndSweep"* %68, i64 0, i32 2, i32 2, i32 0
+  %83 = load atomic i64, i64* %82 unordered, align 8, !tbaa !87, !noalias !423
+  %84 = icmp slt i64 %83, %66
+  br i1 %84, label %.preheader, label %93
 
-82:                                               ; preds = %.preheader
-  call void @_ZNSt18condition_variable4waitERSt11unique_lockISt5mutexE(%"class.std::condition_variable"* nonnull %75, %"class.std::unique_lock.266"* nonnull align 8 dereferenceable(9) %3) #37, !noalias !419
-  %83 = load i64, i64* %77, align 8, !tbaa !89, !noalias !419
-  %84 = icmp slt i64 %83, %61
-  br i1 %84, label %.preheader, label %85
+.preheader:                                       ; preds = %87, %79
+  %85 = load atomic i8, i8* %81 unordered, align 8, !tbaa !144, !range !70, !noalias !423
+  %86 = icmp eq i8 %85, 0
+  br i1 %86, label %87, label %90
 
-85:                                               ; preds = %82, %.preheader
-  %86 = load i8, i8* %68, align 8, !tbaa !259, !range !72, !noalias !419
-  %87 = icmp eq i8 %86, 0
-  br i1 %87, label %_ZN13GCStateHolder16ValueWithCondVarIlE4waitIZNS_17waitEpochFinishedElEUlvE_EERKlT_.exit.i.i.i, label %._crit_edge
+87:                                               ; preds = %.preheader
+  call void @_ZNSt18condition_variable4waitERSt11unique_lockISt5mutexE(%"class.std::condition_variable"* nonnull %80, %"class.std::unique_lock.266"* nonnull align 8 dereferenceable(9) %3) #37, !noalias !423
+  %88 = load atomic i64, i64* %82 unordered, align 8, !tbaa !87, !noalias !423
+  %89 = icmp slt i64 %88, %66
+  br i1 %89, label %.preheader, label %90
 
-._crit_edge:                                      ; preds = %85
-  %.pre = load %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %67, align 8, !tbaa !257, !noalias !419
-  br label %88
+90:                                               ; preds = %87, %.preheader
+  %91 = load atomic i8, i8* %73 unordered, align 8, !tbaa !257, !range !70, !noalias !423
+  %92 = icmp eq i8 %91, 0
+  br i1 %92, label %_ZN13GCStateHolder16ValueWithCondVarIlE4waitIZNS_17waitEpochFinishedElEUlvE_EERKlT_.exit.i.i.i, label %93
 
-88:                                               ; preds = %._crit_edge, %74
-  %89 = phi %"class.std::recursive_mutex"* [ %.pre, %._crit_edge ], [ %66, %74 ]
-  %90 = icmp eq %"class.std::recursive_mutex"* %89, null
-  br i1 %90, label %_ZN13GCStateHolder16ValueWithCondVarIlE4waitIZNS_17waitEpochFinishedElEUlvE_EERKlT_.exit.i.i.i, label %91
+93:                                               ; preds = %90, %79
+  %94 = load atomic %"class.std::recursive_mutex"*, %"class.std::recursive_mutex"** %72 unordered, align 8, !tbaa !255, !noalias !423
+  %95 = icmp eq %"class.std::recursive_mutex"* %94, null
+  br i1 %95, label %_ZN13GCStateHolder16ValueWithCondVarIlE4waitIZNS_17waitEpochFinishedElEUlvE_EERKlT_.exit.i.i.i, label %96
 
-91:                                               ; preds = %88
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %92, label %95
+96:                                               ; preds = %93
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %97, label %100
 
-92:                                               ; preds = %91
-  %93 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %89, i64 0, i32 0, i32 0
-  %94 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %93) #37, !noalias !419
-  br label %95
+97:                                               ; preds = %96
+  %98 = getelementptr inbounds %"class.std::recursive_mutex", %"class.std::recursive_mutex"* %94, i64 0, i32 0, i32 0
+  %99 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %98) #37, !noalias !423
+  br label %100
 
-95:                                               ; preds = %92, %91
-  store i8 0, i8* %68, align 8, !tbaa !259, !noalias !419
+100:                                              ; preds = %97, %96
+  store i8 0, i8* %73, align 8, !tbaa !257, !noalias !423
   br label %_ZN13GCStateHolder16ValueWithCondVarIlE4waitIZNS_17waitEpochFinishedElEUlvE_EERKlT_.exit.i.i.i
 
-_ZN13GCStateHolder16ValueWithCondVarIlE4waitIZNS_17waitEpochFinishedElEUlvE_EERKlT_.exit.i.i.i: ; preds = %95, %88, %85
-  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %64) #37, !noalias !419
-  %96 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %54, null
-  br i1 %96, label %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData5OnOOMEm.exit.i, label %97
+_ZN13GCStateHolder16ValueWithCondVarIlE4waitIZNS_17waitEpochFinishedElEUlvE_EERKlT_.exit.i.i.i: ; preds = %100, %93, %90
+  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %69) #37, !noalias !423
+  %101 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %57 unordered, align 8, !tbaa !34, !noalias !423
+  %102 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %101, null
+  br i1 %102, label %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData5OnOOMEm.exit.i, label %103
 
-97:                                               ; preds = %_ZN13GCStateHolder16ValueWithCondVarIlE4waitIZNS_17waitEpochFinishedElEUlvE_EERKlT_.exit.i.i.i
-  %98 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %55 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %99 = atomicrmw xchg i32* %56, i32 %57 seq_cst, align 4, !noalias !419
-  %100 = icmp eq i32 %99, 1
-  %101 = icmp eq i32 %57, 0
-  %102 = and i1 %101, %100
-  br i1 %102, label %103, label %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData5OnOOMEm.exit.i
+103:                                              ; preds = %_ZN13GCStateHolder16ValueWithCondVarIlE4waitIZNS_17waitEpochFinishedElEUlvE_EERKlT_.exit.i.i.i
+  %104 = load atomic i32, i32* %62 unordered, align 8, !tbaa !38, !noalias !423
+  %105 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %101, i64 328
+  %106 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %105 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %107 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %105 to i32*
+  %108 = atomicrmw xchg i32* %107, i32 %104 seq_cst, align 4, !noalias !423
+  %109 = icmp eq i32 %108, 1
+  %110 = icmp eq i32 %104, 0
+  %111 = and i1 %110, %109
+  br i1 %111, label %112, label %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData5OnOOMEm.exit.i
 
-103:                                              ; preds = %97
-  %104 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1, !noalias !419
-  %105 = and i8 %104, 1
-  %106 = icmp eq i8 %105, 0
-  br i1 %106, label %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData5OnOOMEm.exit.i, label %107
+112:                                              ; preds = %103
+  %113 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1, !noalias !423
+  %114 = and i8 %113, 1
+  %115 = icmp eq i8 %114, 0
+  br i1 %115, label %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData5OnOOMEm.exit.i, label %116
 
-107:                                              ; preds = %103
-  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %98) #37, !noalias !419
+116:                                              ; preds = %112
+  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %106) #37, !noalias !423
   br label %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData5OnOOMEm.exit.i
 
-108:                                              ; preds = %73, %52
-  %109 = landingpad { i8*, i32 }
+117:                                              ; preds = %78, %53
+  %118 = landingpad { i8*, i32 }
           catch i8* null
-  %110 = extractvalue { i8*, i32 } %109, 0
-  tail call fastcc void @_ZN6kotlin16ThreadStateGuardD2Ev(%"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %54, i32 %57) #37
-  tail call fastcc void @__clang_call_terminate(i8* %110) #51, !noalias !419
+  %119 = extractvalue { i8*, i32 } %118, 0
+  call fastcc void @_ZN6kotlin16ThreadStateGuardD2Ev(%"class.kotlin::CalledFromNativeGuard"* nonnull %4) #37, !noalias !423
+  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %55) #37, !noalias !423
+  tail call fastcc void @__clang_call_terminate(i8* %119) #51, !noalias !423
   unreachable
 
-_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData5OnOOMEm.exit.i: ; preds = %107, %103, %97, %_ZN13GCStateHolder16ValueWithCondVarIlE4waitIZNS_17waitEpochFinishedElEUlvE_EERKlT_.exit.i.i.i
-  %111 = call fastcc i8* @_ZN6kotlin20allocateInObjectPoolEm(i64 %7) #37, !noalias !419
-  %112 = icmp eq i8* %111, null
-  br i1 %112, label %113, label %_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE4Node6CreateERS8_m.exit
+_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData5OnOOMEm.exit.i: ; preds = %116, %112, %103, %_ZN13GCStateHolder16ValueWithCondVarIlE4waitIZNS_17waitEpochFinishedElEUlvE_EERKlT_.exit.i.i.i
+  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %55) #37, !noalias !423
+  %120 = call fastcc i8* @_ZN6kotlin20allocateInObjectPoolEm(i64 %8) #37, !noalias !423
+  %121 = icmp eq i8* %120, null
+  br i1 %121, label %122, label %_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE4Node6CreateERS8_m.exit
 
-113:                                              ; preds = %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData5OnOOMEm.exit.i
-  invoke void (i8*, ...) @_ZN5konan13consoleErrorfEPKcz(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.20.376, i64 0, i64 0), i64 %7)
-          to label %114 unwind label %18, !noalias !419
+122:                                              ; preds = %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData5OnOOMEm.exit.i
+  invoke void (i8*, ...) @_ZN5konan13consoleErrorfEPKcz(i8* getelementptr inbounds ([55 x i8], [55 x i8]* @.str.20.376, i64 0, i64 0), i64 %8)
+          to label %123 unwind label %19, !noalias !423
 
-114:                                              ; preds = %113
-  call fastcc void @_ZN5konan5abortEv() #51, !noalias !419
+123:                                              ; preds = %122
+  call fastcc void @_ZN5konan5abortEv() #51, !noalias !423
   unreachable
 
 _ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE4Node6CreateERS8_m.exit: ; preds = %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData5OnOOMEm.exit.i, %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData19SafePointAllocationEm.exit.i
-  %115 = phi i8* [ %111, %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData5OnOOMEm.exit.i ], [ %50, %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData19SafePointAllocationEm.exit.i ]
-  %116 = bitcast i8* %115 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %116, align 8, !tbaa !198, !noalias !419
-  %117 = bitcast %"class.std::unique_ptr.112"* %4 to i8**
-  store i8* %115, i8** %117, align 8, !tbaa !3, !alias.scope !419
-  %118 = getelementptr inbounds %"class.std::unique_ptr.112", %"class.std::unique_ptr.112"* %4, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %119 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 2
-  %120 = getelementptr %"class.std::unique_ptr.112", %"class.std::unique_ptr.112"* %119, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %121 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %120, align 8, !tbaa !3
-  %122 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %121, null
-  %123 = ptrtoint i8* %115 to i64
-  br i1 %122, label %124, label %126
-
-124:                                              ; preds = %_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE4Node6CreateERS8_m.exit
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %118, align 8, !tbaa !3
-  %125 = bitcast %"class.std::unique_ptr.112"* %119 to i64*
-  store i64 %123, i64* %125, align 8, !tbaa !3
-  br label %136
-
-126:                                              ; preds = %_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE4Node6CreateERS8_m.exit
-  %127 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 3
-  %128 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %127, align 8, !tbaa !333
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %118, align 8, !tbaa !3
-  %129 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %128 to i64*
-  %130 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %128, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %131 = load %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %130, align 8, !tbaa !3
-  store i64 %123, i64* %129, align 8, !tbaa !3
+  %124 = phi i8* [ %120, %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData5OnOOMEm.exit.i ], [ %51, %_ZN6kotlin2gc22ConcurrentMarkAndSweep10ThreadData19SafePointAllocationEm.exit.i ]
+  %125 = bitcast i8* %124 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %125, align 8, !tbaa !197, !noalias !423
+  %126 = bitcast %"class.std::unique_ptr.112"* %5 to i8**
+  store i8* %124, i8** %126, align 8, !tbaa !3, !alias.scope !423
+  %127 = getelementptr inbounds %"class.std::unique_ptr.112", %"class.std::unique_ptr.112"* %5, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %128 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %127 unordered, align 8, !tbaa !3
+  %129 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 2
+  %130 = getelementptr %"class.std::unique_ptr.112", %"class.std::unique_ptr.112"* %129, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %131 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %130 unordered, align 8, !tbaa !3
   %132 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %131, null
-  br i1 %132, label %136, label %133
+  %133 = ptrtoint %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %128 to i64
+  br i1 %132, label %134, label %136
 
-133:                                              ; preds = %126
-  %134 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %131, i64 0, i32 0
-  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %134) #37
-  %135 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %131 to i8*
-  call fastcc void @mi_free(i8* nonnull %135) #37
-  br label %136
+134:                                              ; preds = %_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE4Node6CreateERS8_m.exit
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %127, align 8, !tbaa !3
+  %135 = bitcast %"class.std::unique_ptr.112"* %129 to i64*
+  store i64 %133, i64* %135, align 8, !tbaa !3
+  br label %146
 
-136:                                              ; preds = %133, %126, %124
+136:                                              ; preds = %_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE4Node6CreateERS8_m.exit
   %137 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 3
-  %138 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %137 to i8**
-  store i8* %115, i8** %138, align 8, !tbaa !333
-  %139 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 4
-  %140 = load i64, i64* %139, align 8, !tbaa !425
-  %141 = add i64 %140, 1
-  store i64 %141, i64* %139, align 8, !tbaa !425
-  %142 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 5
-  %143 = load i64, i64* %142, align 8, !tbaa !426
-  %144 = add i64 %143, %7
-  store i64 %144, i64* %142, align 8, !tbaa !426
-  %.cast = bitcast i8* %115 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*
-  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %4) #37
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %5) #37
-  ret %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %.cast
+  %138 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %137 unordered, align 8, !tbaa !337
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* null, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %127, align 8, !tbaa !3
+  %139 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %138 to i64*
+  %140 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %138, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %141 = load atomic %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"*, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %140 unordered, align 8, !tbaa !3
+  store i64 %133, i64* %139, align 8, !tbaa !3
+  %142 = icmp eq %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %141, null
+  br i1 %142, label %146, label %143
+
+143:                                              ; preds = %136
+  %144 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %141, i64 0, i32 0
+  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %144) #37
+  %145 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %141 to i8*
+  call fastcc void @mi_free(i8* nonnull %145) #37
+  br label %146
+
+146:                                              ; preds = %143, %136, %134
+  %147 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 3
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %128, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %147, align 8, !tbaa !337
+  %148 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 4
+  %149 = load atomic i64, i64* %148 unordered, align 8, !tbaa !429
+  %150 = add i64 %149, 1
+  store i64 %150, i64* %148, align 8, !tbaa !429
+  %151 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Producer"* %0, i64 0, i32 5
+  %152 = load atomic i64, i64* %151 unordered, align 8, !tbaa !430
+  %153 = add i64 %152, %8
+  store i64 %153, i64* %151, align 8, !tbaa !430
+  call fastcc void @_ZNSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEED2Ev(%"class.std::unique_ptr.112"* nonnull %5) #37
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %6) #37
+  ret %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %128
 }
 
 ; Function Attrs: nofree nounwind
@@ -29779,8 +30363,8 @@
 
 ; Function Attrs: inlinehint nofree norecurse nounwind uwtable writeonly
 define internal void @"_ZZSt9call_onceIZN6kotlin14initObjectPoolEvE3$_0JEEvRSt9once_flagOT_DpOT0_ENUlvE0_8__invokeEv"() #35 align 2 {
-  store i64 1, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 5, i32 0), align 8, !tbaa !427
-  store i32 2, i32* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 5, i32 1), align 8, !tbaa !433
+  store i64 1, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 5, i32 0), align 8, !tbaa !431
+  store i32 2, i32* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 5, i32 1), align 8, !tbaa !437
   ret void
 }
 
@@ -29790,40 +30374,40 @@
 
 ; Function Attrs: nounwind uwtable
 define internal fastcc noalias i8* @_ZN6kotlin20allocateInObjectPoolEm(i64 %0) unnamed_addr #17 {
-  %2 = load %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !434
+  %2 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default unordered, align 8, !tbaa !438
   %3 = icmp sgt i64 %0, -1
-  br i1 %3, label %4, label %mi_calloc_aligned.exit, !prof !435, !misexpect !285
+  br i1 %3, label %4, label %mi_calloc_aligned.exit, !prof !439, !misexpect !283
 
 4:                                                ; preds = %1
   %5 = icmp ult i64 %0, 1025
-  br i1 %5, label %6, label %31, !prof !436, !misexpect !437
+  br i1 %5, label %6, label %31, !prof !440, !misexpect !441
 
 6:                                                ; preds = %4
   %7 = add nuw nsw i64 %0, 7
   %8 = lshr i64 %7, 3
   %9 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %2, i64 0, i32 1, i64 %8
-  %10 = load %struct.mi_page_s*, %struct.mi_page_s** %9, align 8, !tbaa !434
+  %10 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %9 unordered, align 8, !tbaa !438
   %11 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %10, i64 0, i32 6
-  %12 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %11, align 8, !tbaa !438
+  %12 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %11 unordered, align 8, !tbaa !442
   %13 = ptrtoint %"class.kotlin::gc::GCHandle"* %12 to i64
   %14 = and i64 %13, 7
   %15 = icmp eq i64 %14, 0
   %16 = icmp ne %"class.kotlin::gc::GCHandle"* %12, null
   %17 = and i1 %16, %15
-  br i1 %17, label %_mi_page_malloc.exit.i.i, label %31, !prof !436, !misexpect !437
+  br i1 %17, label %_mi_page_malloc.exit.i.i, label %31, !prof !440, !misexpect !441
 
 _mi_page_malloc.exit.i.i:                         ; preds = %6
   %18 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %10, i64 0, i32 7
-  %19 = load i32, i32* %18, align 8, !tbaa !442
+  %19 = load atomic i32, i32* %18 unordered, align 8, !tbaa !446
   %20 = add i32 %19, 1
-  store i32 %20, i32* %18, align 8, !tbaa !442
+  store i32 %20, i32* %18, align 8, !tbaa !446
   %21 = getelementptr %"class.kotlin::gc::GCHandle", %"class.kotlin::gc::GCHandle"* %12, i64 0, i32 0
-  %22 = load i64, i64* %21, align 8, !tbaa !443
+  %22 = load atomic i64, i64* %21 unordered, align 8, !tbaa !447
   %23 = bitcast %"class.kotlin::gc::GCHandle"** %11 to i64*
-  store i64 %22, i64* %23, align 8, !tbaa !438
+  store i64 %22, i64* %23, align 8, !tbaa !442
   %24 = bitcast %"class.kotlin::gc::GCHandle"* %12 to i8*
   %.phi.trans.insert = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %10, i64 0, i32 5
-  %.pre = load i8, i8* %.phi.trans.insert, align 1
+  %.pre = load atomic i8, i8* %.phi.trans.insert unordered, align 1
   %phi.bo = and i8 %.pre, 1
   %phi.cmp = icmp ne i8 %phi.bo, 0
   %25 = icmp ugt i64 %0, 8
@@ -29832,7 +30416,7 @@
 
 27:                                               ; preds = %_mi_page_malloc.exit.i.i
   %28 = getelementptr %"class.kotlin::gc::GCHandle", %"class.kotlin::gc::GCHandle"* %12, i64 0, i32 0
-  store i64 0, i64* %28, align 8, !tbaa !443
+  store i64 0, i64* %28, align 8, !tbaa !447
   br label %mi_calloc_aligned.exit
 
 29:                                               ; preds = %_mi_page_malloc.exit.i.i
@@ -29874,10 +30458,10 @@
   %53 = inttoptr i64 %52 to %struct.mi_segment_s*
   %54 = and i64 %43, 4194303
   %55 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %53, i64 0, i32 13
-  %56 = load i64, i64* %55, align 32, !tbaa !445
+  %56 = load atomic i64, i64* %55 unordered, align 32, !tbaa !449
   %57 = lshr i64 %54, %56
   %58 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %53, i64 0, i32 16, i64 %57, i32 4, i32 0
-  %59 = load i8, i8* %58, align 2
+  %59 = load atomic i8, i8* %58 unordered, align 2
   %60 = or i8 %59, 2
   store i8 %60, i8* %58, align 2
   br label %mi_calloc_aligned.exit
@@ -29889,21 +30473,21 @@
 
 ; Function Attrs: nounwind uwtable
 define internal void @_mi_process_init() #17 {
-  %1 = load i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5), align 8, !tbaa !448
+  %1 = load atomic i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5) unordered, align 8, !tbaa !452
   %2 = icmp eq i64 %1, 0
   br i1 %2, label %3, label %9
 
 3:                                                ; preds = %0
-  %4 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !451
+  %4 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !455
   %5 = ptrtoint i8* %4 to i64
-  store i64 %5, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4), align 8, !tbaa !452
+  store i64 %5, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4), align 8, !tbaa !456
   %6 = tail call i64 @_os_random_weak(i64 ptrtoint (void ()* @mi_heap_main_init to i64)) #37
-  store i64 %6, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5), align 8, !tbaa !448
+  store i64 %6, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5), align 8, !tbaa !452
   tail call fastcc void @_mi_random_init(%struct.mi_random_cxt_s* bitcast (i32* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 7, i32 0, i32 0) to %struct.mi_random_cxt_s*)) #37
   %7 = tail call fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*)) #37
-  store i64 %7, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 0), align 8, !tbaa !453
+  store i64 %7, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 0), align 8, !tbaa !457
   %8 = tail call fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*)) #37
-  store i64 %8, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 1), align 8, !tbaa !453
+  store i64 %8, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 1), align 8, !tbaa !457
   br label %9
 
 9:                                                ; preds = %3, %0
@@ -29913,113 +30497,113 @@
   %12 = icmp ult i64 %11, 32768
   %13 = select i1 %12, i64 %11, i64 32768
   %14 = getelementptr inbounds [32769 x i8], [32769 x i8]* @out_buf, i64 0, i64 %13
-  store i8 0, i8* %14, align 1, !tbaa !454
-  %15 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8, !tbaa !434
+  store i8 0, i8* %14, align 1, !tbaa !458
+  %15 = load atomic %struct._IO_FILE*, %struct._IO_FILE** @stderr unordered, align 8, !tbaa !438
   %16 = tail call i32 @fputs(i8* getelementptr inbounds ([32769 x i8], [32769 x i8]* @out_buf, i64 0, i64 0), %struct._IO_FILE* %15) #55
-  store i8 10, i8* %14, align 1, !tbaa !454
-  store volatile void (i8*, i8*)* @mi_out_buf_stderr, void (i8*, i8*)** @mi_out_default, align 8, !tbaa !434
+  store i8 10, i8* %14, align 1, !tbaa !458
+  store volatile void (i8*, i8*)* @mi_out_buf_stderr, void (i8*, i8*)** @mi_out_default, align 8, !tbaa !438
   %17 = tail call fastcc i64 @mi_option_get(i32 0) #37
-  %18 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 0, i32 3), align 16, !tbaa !455
-  %19 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 0, i32 0), align 16, !tbaa !427
+  %18 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 0, i32 3) unordered, align 16, !tbaa !459
+  %19 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 0, i32 0) unordered, align 16, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %18, i64 %19) #37
   %20 = tail call fastcc i64 @mi_option_get(i32 1) #37
-  %21 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 1, i32 3), align 8, !tbaa !455
-  %22 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 1, i32 0), align 8, !tbaa !427
+  %21 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 1, i32 3) unordered, align 8, !tbaa !459
+  %22 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 1, i32 0) unordered, align 8, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %21, i64 %22) #37
   %23 = tail call fastcc i64 @mi_option_get(i32 2) #37
   %24 = tail call fastcc i64 @mi_option_get(i32 3) #37
-  %25 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 3, i32 3), align 8, !tbaa !455
-  %26 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 3, i32 0), align 8, !tbaa !427
+  %25 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 3, i32 3) unordered, align 8, !tbaa !459
+  %26 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 3, i32 0) unordered, align 8, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %25, i64 %26) #37
   %27 = tail call fastcc i64 @mi_option_get(i32 4) #37
-  %28 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 4, i32 3), align 16, !tbaa !455
-  %29 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 4, i32 0), align 16, !tbaa !427
+  %28 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 4, i32 3) unordered, align 16, !tbaa !459
+  %29 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 4, i32 0) unordered, align 16, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %28, i64 %29) #37
   %30 = tail call fastcc i64 @mi_option_get(i32 5) #37
-  %31 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 5, i32 3), align 8, !tbaa !455
-  %32 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 5, i32 0), align 8, !tbaa !427
+  %31 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 5, i32 3) unordered, align 8, !tbaa !459
+  %32 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 5, i32 0) unordered, align 8, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %31, i64 %32) #37
   %33 = tail call fastcc i64 @mi_option_get(i32 6) #37
-  %34 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 6, i32 3), align 16, !tbaa !455
-  %35 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 6, i32 0), align 16, !tbaa !427
+  %34 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 6, i32 3) unordered, align 16, !tbaa !459
+  %35 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 6, i32 0) unordered, align 16, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %34, i64 %35) #37
   %36 = tail call fastcc i64 @mi_option_get(i32 7) #37
-  %37 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 7, i32 3), align 8, !tbaa !455
-  %38 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 7, i32 0), align 8, !tbaa !427
+  %37 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 7, i32 3) unordered, align 8, !tbaa !459
+  %38 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 7, i32 0) unordered, align 8, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %37, i64 %38) #37
   %39 = tail call fastcc i64 @mi_option_get(i32 8) #37
-  %40 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 8, i32 3), align 16, !tbaa !455
-  %41 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 8, i32 0), align 16, !tbaa !427
+  %40 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 8, i32 3) unordered, align 16, !tbaa !459
+  %41 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 8, i32 0) unordered, align 16, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %40, i64 %41) #37
   %42 = tail call fastcc i64 @mi_option_get(i32 9) #37
-  %43 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 9, i32 3), align 8, !tbaa !455
-  %44 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 9, i32 0), align 8, !tbaa !427
+  %43 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 9, i32 3) unordered, align 8, !tbaa !459
+  %44 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 9, i32 0) unordered, align 8, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %43, i64 %44) #37
   %45 = tail call fastcc i64 @mi_option_get(i32 10) #37
-  %46 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 10, i32 3), align 16, !tbaa !455
-  %47 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 10, i32 0), align 16, !tbaa !427
+  %46 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 10, i32 3) unordered, align 16, !tbaa !459
+  %47 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 10, i32 0) unordered, align 16, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %46, i64 %47) #37
   %48 = tail call fastcc i64 @mi_option_get(i32 11) #37
-  %49 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 11, i32 3), align 8, !tbaa !455
-  %50 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 11, i32 0), align 8, !tbaa !427
+  %49 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 11, i32 3) unordered, align 8, !tbaa !459
+  %50 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 11, i32 0) unordered, align 8, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %49, i64 %50) #37
   %51 = tail call fastcc i64 @mi_option_get(i32 12) #37
-  %52 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 12, i32 3), align 16, !tbaa !455
-  %53 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 12, i32 0), align 16, !tbaa !427
+  %52 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 12, i32 3) unordered, align 16, !tbaa !459
+  %53 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 12, i32 0) unordered, align 16, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %52, i64 %53) #37
   %54 = tail call fastcc i64 @mi_option_get(i32 13) #37
-  %55 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 13, i32 3), align 8, !tbaa !455
-  %56 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 13, i32 0), align 8, !tbaa !427
+  %55 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 13, i32 3) unordered, align 8, !tbaa !459
+  %56 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 13, i32 0) unordered, align 8, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %55, i64 %56) #37
   %57 = tail call fastcc i64 @mi_option_get(i32 14) #37
-  %58 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 14, i32 3), align 16, !tbaa !455
-  %59 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 14, i32 0), align 16, !tbaa !427
+  %58 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 14, i32 3) unordered, align 16, !tbaa !459
+  %59 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 14, i32 0) unordered, align 16, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %58, i64 %59) #37
   %60 = tail call fastcc i64 @mi_option_get(i32 15) #37
-  %61 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 15, i32 3), align 8, !tbaa !455
-  %62 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 15, i32 0), align 8, !tbaa !427
+  %61 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 15, i32 3) unordered, align 8, !tbaa !459
+  %62 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 15, i32 0) unordered, align 8, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %61, i64 %62) #37
   %63 = tail call fastcc i64 @mi_option_get(i32 16) #37
-  %64 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 16, i32 3), align 16, !tbaa !455
-  %65 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 16, i32 0), align 16, !tbaa !427
+  %64 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 16, i32 3) unordered, align 16, !tbaa !459
+  %65 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 16, i32 0) unordered, align 16, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %64, i64 %65) #37
   %66 = tail call fastcc i64 @mi_option_get(i32 17) #37
-  %67 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 17, i32 3), align 8, !tbaa !455
-  %68 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 17, i32 0), align 8, !tbaa !427
+  %67 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 17, i32 3) unordered, align 8, !tbaa !459
+  %68 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 17, i32 0) unordered, align 8, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %67, i64 %68) #37
   %69 = tail call fastcc i64 @mi_option_get(i32 18) #37
-  %70 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 18, i32 3), align 16, !tbaa !455
-  %71 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 18, i32 0), align 16, !tbaa !427
+  %70 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 18, i32 3) unordered, align 16, !tbaa !459
+  %71 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 18, i32 0) unordered, align 16, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %70, i64 %71) #37
   %72 = tail call fastcc i64 @mi_option_get(i32 19) #37
-  %73 = load i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 19, i32 3), align 8, !tbaa !455
-  %74 = load i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 19, i32 0), align 8, !tbaa !427
+  %73 = load atomic i8*, i8** getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 19, i32 3) unordered, align 8, !tbaa !459
+  %74 = load atomic i64, i64* getelementptr inbounds ([20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 19, i32 0) unordered, align 8, !tbaa !431
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.119.473, i64 0, i64 0), i8* %73, i64 %74) #37
   %75 = tail call fastcc i64 @mi_option_get(i32 18) #37
-  store i64 %75, i64* @mi_max_error_count, align 8, !tbaa !453
+  store i64 %75, i64* @mi_max_error_count, align 8, !tbaa !457
   %76 = tail call fastcc i64 @mi_option_get(i32 19) #37
-  store i64 %76, i64* @mi_max_warning_count, align 8, !tbaa !453
+  store i64 %76, i64* @mi_max_warning_count, align 8, !tbaa !457
   tail call fastcc void @mi_process_init() #37
   ret void
 }
 
 ; Function Attrs: nounwind uwtable
 define internal void @mi_heap_main_init() #17 {
-  %1 = load i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5), align 8, !tbaa !448
+  %1 = load atomic i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5) unordered, align 8, !tbaa !452
   %2 = icmp eq i64 %1, 0
   br i1 %2, label %3, label %9
 
 3:                                                ; preds = %0
-  %4 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !451
+  %4 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !455
   %5 = ptrtoint i8* %4 to i64
-  store i64 %5, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4), align 8, !tbaa !452
+  store i64 %5, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4), align 8, !tbaa !456
   %6 = tail call i64 @_os_random_weak(i64 ptrtoint (void ()* @mi_heap_main_init to i64)) #37
-  store i64 %6, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5), align 8, !tbaa !448
+  store i64 %6, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5), align 8, !tbaa !452
   tail call fastcc void @_mi_random_init(%struct.mi_random_cxt_s* bitcast (i32* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 7, i32 0, i32 0) to %struct.mi_random_cxt_s*)) #37
   %7 = tail call fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*)) #37
-  store i64 %7, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 0), align 8, !tbaa !453
+  store i64 %7, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 0), align 8, !tbaa !457
   %8 = tail call fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*)) #37
-  store i64 %8, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 1), align 8, !tbaa !453
+  store i64 %8, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 1), align 8, !tbaa !457
   br label %9
 
 9:                                                ; preds = %3, %0
@@ -30034,10 +30618,10 @@
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %4) #37
   %5 = call i32 @clock_gettime(i32 1, { i64, i64 }* nonnull %2) #37
   %6 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %2, i64 0, i32 0
-  %7 = load i64, i64* %6, align 8, !tbaa !456
+  %7 = load atomic i64, i64* %6 unordered, align 8, !tbaa !460
   %8 = xor i64 %3, %7
   %9 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %2, i64 0, i32 1
-  %10 = load i64, i64* %9, align 8, !tbaa !458
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa !462
   %11 = xor i64 %8, %10
   %12 = lshr i64 %11, 17
   %13 = xor i64 %12, %11
@@ -30114,60 +30698,44 @@
   br i1 %6, label %7, label %45
 
 7:                                                ; preds = %1
-  %8 = load i8, i8* %4, align 16, !tbaa !454
+  %8 = load atomic i8, i8* %4 unordered, align 16, !tbaa !458
   %9 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 1
-  %10 = load i8, i8* %9, align 1, !tbaa !454
+  %10 = load atomic i8, i8* %9 unordered, align 1, !tbaa !458
   %11 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 2
-  %12 = load i8, i8* %11, align 2, !tbaa !454
+  %12 = load atomic i8, i8* %11 unordered, align 2, !tbaa !458
   %13 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 3
-  %14 = load i8, i8* %13, align 1, !tbaa !454
+  %14 = load atomic i8, i8* %13 unordered, align 1, !tbaa !458
   %15 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 4
-  %16 = load i8, i8* %15, align 4, !tbaa !454
+  %16 = load atomic i8, i8* %15 unordered, align 4, !tbaa !458
   %17 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 5
-  %18 = load i8, i8* %17, align 1, !tbaa !454
+  %18 = load atomic i8, i8* %17 unordered, align 1, !tbaa !458
   %19 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 6
-  %20 = load i8, i8* %19, align 2, !tbaa !454
+  %20 = load atomic i8, i8* %19 unordered, align 2, !tbaa !458
   %21 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 7
-  %22 = load i8, i8* %21, align 1, !tbaa !454
+  %22 = load atomic i8, i8* %21 unordered, align 1, !tbaa !458
   %23 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 8
-  %24 = load i8, i8* %23, align 8, !tbaa !454
+  %24 = load atomic i8, i8* %23 unordered, align 8, !tbaa !458
   %25 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 9
-  %26 = load i8, i8* %25, align 1, !tbaa !454
+  %26 = load atomic i8, i8* %25 unordered, align 1, !tbaa !458
   %27 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 10
-  %28 = load i8, i8* %27, align 2, !tbaa !454
+  %28 = load atomic i8, i8* %27 unordered, align 2, !tbaa !458
   %29 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 11
-  %30 = load i8, i8* %29, align 1, !tbaa !454
+  %30 = load atomic i8, i8* %29 unordered, align 1, !tbaa !458
   %31 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 12
-  %32 = load i8, i8* %31, align 4, !tbaa !454
+  %32 = load atomic i8, i8* %31 unordered, align 4, !tbaa !458
   %33 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 13
-  %34 = load i8, i8* %33, align 1, !tbaa !454
+  %34 = load atomic i8, i8* %33 unordered, align 1, !tbaa !458
   %35 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 14
-  %36 = load i8, i8* %35, align 2, !tbaa !454
+  %36 = load atomic i8, i8* %35 unordered, align 2, !tbaa !458
   %37 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 15
-  %38 = load i8, i8* %37, align 1, !tbaa !454
+  %38 = load atomic i8, i8* %37 unordered, align 1, !tbaa !458
   %39 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 16
-  %40 = load i8, i8* %39, align 16, !tbaa !454
+  %40 = load atomic i8, i8* %39 unordered, align 16, !tbaa !458
   %41 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 17
-  %42 = load i8, i8* %41, align 1, !tbaa !454
+  %42 = load atomic i8, i8* %41 unordered, align 1, !tbaa !458
   %43 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 18
-  %44 = load i8, i8* %43, align 2, !tbaa !454
-  %.phi.trans.insert = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 19
-  %.pre = load i8, i8* %.phi.trans.insert, align 1, !tbaa !454
-  %.phi.trans.insert1 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 20
-  %.pre2 = load i8, i8* %.phi.trans.insert1, align 4, !tbaa !454
-  %.phi.trans.insert3 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 21
-  %.pre4 = load i8, i8* %.phi.trans.insert3, align 1, !tbaa !454
-  %.phi.trans.insert5 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 22
-  %.pre6 = load i8, i8* %.phi.trans.insert5, align 2, !tbaa !454
-  %.phi.trans.insert7 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 23
-  %.pre8 = load i8, i8* %.phi.trans.insert7, align 1, !tbaa !454
-  %.phi.trans.insert9 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 24
-  %.pre10 = load i8, i8* %.phi.trans.insert9, align 8, !tbaa !454
-  %.phi.trans.insert11 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 25
-  %.pre12 = load i8, i8* %.phi.trans.insert11, align 1, !tbaa !454
-  %.phi.trans.insert13 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 26
-  %.pre14 = load i8, i8* %.phi.trans.insert13, align 2, !tbaa !454
-  br label %253
+  %44 = load atomic i8, i8* %43 unordered, align 2, !tbaa !458
+  br label %239
 
 45:                                               ; preds = %1
   call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([33 x i8], [33 x i8]* @.str.185.518, i64 0, i64 0)) #37
@@ -30175,10 +30743,10 @@
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %46) #37
   %47 = call i32 @clock_gettime(i32 1, { i64, i64 }* nonnull %2) #37
   %48 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %2, i64 0, i32 0
-  %49 = load i64, i64* %48, align 8, !tbaa !456
+  %49 = load atomic i64, i64* %48 unordered, align 8, !tbaa !460
   %50 = xor i64 %49, ptrtoint (i64 (i64)* @_os_random_weak to i64)
   %51 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %2, i64 0, i32 1
-  %52 = load i64, i64* %51, align 8, !tbaa !458
+  %52 = load atomic i64, i64* %51 unordered, align 8, !tbaa !462
   %53 = xor i64 %50, %52
   %54 = lshr i64 %53, 17
   %55 = xor i64 %54, %53
@@ -30253,7 +30821,7 @@
   %112 = lshr i64 %111, 31
   %113 = xor i64 %112, %111
   %114 = trunc i64 %113 to i32
-  store i32 %114, i32* %103, align 16, !tbaa !459
+  store i32 %114, i32* %103, align 16, !tbaa !463
   %115 = icmp eq i64 %113, 0
   %116 = select i1 %115, i64 17, i64 %113
   %117 = lshr i64 %116, 30
@@ -30267,7 +30835,7 @@
   %125 = trunc i64 %124 to i32
   %126 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 4
   %127 = bitcast i8* %126 to i32*
-  store i32 %125, i32* %127, align 4, !tbaa !459
+  store i32 %125, i32* %127, align 4, !tbaa !463
   %128 = icmp eq i64 %124, 0
   %129 = select i1 %128, i64 17, i64 %124
   %130 = lshr i64 %129, 30
@@ -30281,7 +30849,7 @@
   %138 = trunc i64 %137 to i32
   %139 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 8
   %140 = bitcast i8* %139 to i32*
-  store i32 %138, i32* %140, align 8, !tbaa !459
+  store i32 %138, i32* %140, align 8, !tbaa !463
   %141 = icmp eq i64 %137, 0
   %142 = select i1 %141, i64 17, i64 %137
   %143 = lshr i64 %142, 30
@@ -30295,7 +30863,7 @@
   %151 = trunc i64 %150 to i32
   %152 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 12
   %153 = bitcast i8* %152 to i32*
-  store i32 %151, i32* %153, align 4, !tbaa !459
+  store i32 %151, i32* %153, align 4, !tbaa !463
   %154 = icmp eq i64 %150, 0
   %155 = select i1 %154, i64 17, i64 %150
   %156 = lshr i64 %155, 30
@@ -30309,7 +30877,7 @@
   %164 = trunc i64 %163 to i32
   %165 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 16
   %166 = bitcast i8* %165 to i32*
-  store i32 %164, i32* %166, align 16, !tbaa !459
+  store i32 %164, i32* %166, align 16, !tbaa !463
   %167 = icmp eq i64 %163, 0
   %168 = select i1 %167, i64 17, i64 %163
   %169 = lshr i64 %168, 30
@@ -30323,7 +30891,7 @@
   %177 = trunc i64 %176 to i32
   %178 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 20
   %179 = bitcast i8* %178 to i32*
-  store i32 %177, i32* %179, align 4, !tbaa !459
+  store i32 %177, i32* %179, align 4, !tbaa !463
   %180 = icmp eq i64 %176, 0
   %181 = select i1 %180, i64 17, i64 %176
   %182 = lshr i64 %181, 30
@@ -30337,7 +30905,7 @@
   %190 = trunc i64 %189 to i32
   %191 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 24
   %192 = bitcast i8* %191 to i32*
-  store i32 %190, i32* %192, align 8, !tbaa !459
+  store i32 %190, i32* %192, align 8, !tbaa !463
   %193 = icmp eq i64 %189, 0
   %194 = select i1 %193, i64 17, i64 %189
   %195 = lshr i64 %194, 30
@@ -30351,7 +30919,7 @@
   %203 = trunc i64 %202 to i32
   %204 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 28
   %205 = bitcast i8* %204 to i32*
-  store i32 %203, i32* %205, align 4, !tbaa !459
+  store i32 %203, i32* %205, align 4, !tbaa !463
   %206 = trunc i64 %113 to i8
   %207 = lshr i32 %114, 8
   %208 = trunc i32 %207 to i8
@@ -30385,154 +30953,148 @@
   %236 = trunc i32 %235 to i8
   %237 = lshr i32 %164, 16
   %238 = trunc i32 %237 to i8
-  %239 = lshr i32 %164, 24
-  %240 = trunc i32 %239 to i8
-  %241 = trunc i64 %176 to i8
-  %242 = lshr i32 %177, 8
-  %243 = trunc i32 %242 to i8
-  %244 = lshr i32 %177, 16
-  %245 = trunc i32 %244 to i8
-  %246 = lshr i32 %177, 24
-  %247 = trunc i32 %246 to i8
-  %248 = trunc i64 %189 to i8
-  %249 = lshr i32 %190, 8
-  %250 = trunc i32 %249 to i8
-  %251 = lshr i32 %190, 16
-  %252 = trunc i32 %251 to i8
-  br label %253
+  br label %239
 
-253:                                              ; preds = %101, %7
-  %254 = phi i8 [ %.pre14, %7 ], [ %252, %101 ]
-  %255 = phi i8 [ %.pre12, %7 ], [ %250, %101 ]
-  %256 = phi i8 [ %.pre10, %7 ], [ %248, %101 ]
-  %257 = phi i8 [ %.pre8, %7 ], [ %247, %101 ]
-  %258 = phi i8 [ %.pre6, %7 ], [ %245, %101 ]
-  %259 = phi i8 [ %.pre4, %7 ], [ %243, %101 ]
-  %260 = phi i8 [ %.pre2, %7 ], [ %241, %101 ]
-  %261 = phi i8 [ %.pre, %7 ], [ %240, %101 ]
-  %262 = phi i8 [ %44, %7 ], [ %238, %101 ]
-  %263 = phi i8 [ %42, %7 ], [ %236, %101 ]
-  %264 = phi i8 [ %40, %7 ], [ %234, %101 ]
-  %265 = phi i8 [ %38, %7 ], [ %233, %101 ]
-  %266 = phi i8 [ %36, %7 ], [ %231, %101 ]
-  %267 = phi i8 [ %34, %7 ], [ %229, %101 ]
-  %268 = phi i8 [ %32, %7 ], [ %227, %101 ]
-  %269 = phi i8 [ %30, %7 ], [ %226, %101 ]
-  %270 = phi i8 [ %28, %7 ], [ %224, %101 ]
-  %271 = phi i8 [ %26, %7 ], [ %222, %101 ]
-  %272 = phi i8 [ %24, %7 ], [ %220, %101 ]
-  %273 = phi i8 [ %22, %7 ], [ %219, %101 ]
-  %274 = phi i8 [ %20, %7 ], [ %217, %101 ]
-  %275 = phi i8 [ %18, %7 ], [ %215, %101 ]
-  %276 = phi i8 [ %16, %7 ], [ %213, %101 ]
-  %277 = phi i8 [ %14, %7 ], [ %212, %101 ]
-  %278 = phi i8 [ %12, %7 ], [ %210, %101 ]
-  %279 = phi i8 [ %10, %7 ], [ %208, %101 ]
-  %280 = phi i8 [ %8, %7 ], [ %206, %101 ]
-  %281 = ptrtoint %struct.mi_random_cxt_s* %0 to i64
-  %282 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 4
-  %283 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 10
-  %284 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 14
-  %285 = bitcast i32* %284 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(132) %285, i8 0, i64 76, i1 false) #37
-  %286 = bitcast %struct.mi_random_cxt_s* %0 to <4 x i32>*
-  store <4 x i32> <i32 1634760805, i32 857760878, i32 2036477234, i32 1797285236>, <4 x i32>* %286, align 4, !tbaa !459
-  %287 = zext i8 %280 to i32
-  %288 = zext i8 %279 to i32
-  %289 = shl nuw nsw i32 %288, 8
-  %290 = or i32 %289, %287
-  %291 = zext i8 %278 to i32
-  %292 = shl nuw nsw i32 %291, 16
-  %293 = or i32 %290, %292
-  %294 = zext i8 %277 to i32
-  %295 = shl nuw i32 %294, 24
-  %296 = or i32 %293, %295
-  store i32 %296, i32* %282, align 4, !tbaa !459
-  %297 = zext i8 %276 to i32
-  %298 = zext i8 %275 to i32
-  %299 = shl nuw nsw i32 %298, 8
-  %300 = or i32 %299, %297
-  %301 = zext i8 %274 to i32
-  %302 = shl nuw nsw i32 %301, 16
-  %303 = or i32 %300, %302
-  %304 = zext i8 %273 to i32
-  %305 = shl nuw i32 %304, 24
-  %306 = or i32 %303, %305
-  %307 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 5
-  store i32 %306, i32* %307, align 4, !tbaa !459
-  %308 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 6
-  %309 = insertelement <4 x i8> undef, i8 %272, i32 0
-  %310 = insertelement <4 x i8> %309, i8 %268, i32 1
-  %311 = insertelement <4 x i8> %310, i8 %264, i32 2
-  %312 = insertelement <4 x i8> %311, i8 %260, i32 3
-  %313 = zext <4 x i8> %312 to <4 x i32>
-  %314 = insertelement <4 x i8> undef, i8 %271, i32 0
-  %315 = insertelement <4 x i8> %314, i8 %267, i32 1
-  %316 = insertelement <4 x i8> %315, i8 %263, i32 2
-  %317 = insertelement <4 x i8> %316, i8 %259, i32 3
-  %318 = zext <4 x i8> %317 to <4 x i32>
-  %319 = shl nuw nsw <4 x i32> %318, <i32 8, i32 8, i32 8, i32 8>
-  %320 = or <4 x i32> %319, %313
-  %321 = insertelement <4 x i8> undef, i8 %270, i32 0
-  %322 = insertelement <4 x i8> %321, i8 %266, i32 1
-  %323 = insertelement <4 x i8> %322, i8 %262, i32 2
-  %324 = insertelement <4 x i8> %323, i8 %258, i32 3
-  %325 = zext <4 x i8> %324 to <4 x i32>
-  %326 = shl nuw nsw <4 x i32> %325, <i32 16, i32 16, i32 16, i32 16>
-  %327 = or <4 x i32> %320, %326
-  %328 = insertelement <4 x i8> undef, i8 %269, i32 0
-  %329 = insertelement <4 x i8> %328, i8 %265, i32 1
-  %330 = insertelement <4 x i8> %329, i8 %261, i32 2
-  %331 = insertelement <4 x i8> %330, i8 %257, i32 3
-  %332 = zext <4 x i8> %331 to <4 x i32>
-  %333 = shl nuw <4 x i32> %332, <i32 24, i32 24, i32 24, i32 24>
-  %334 = or <4 x i32> %327, %333
-  %335 = bitcast i32* %308 to <4 x i32>*
-  store <4 x i32> %334, <4 x i32>* %335, align 4, !tbaa !459
-  %336 = zext i8 %256 to i32
-  %337 = zext i8 %255 to i32
-  %338 = shl nuw nsw i32 %337, 8
-  %339 = or i32 %338, %336
-  %340 = zext i8 %254 to i32
-  %341 = shl nuw nsw i32 %340, 16
-  %342 = or i32 %339, %341
-  %343 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 27
-  %344 = load i8, i8* %343, align 1, !tbaa !454
-  %345 = zext i8 %344 to i32
-  %346 = shl nuw i32 %345, 24
-  %347 = or i32 %342, %346
-  store i32 %347, i32* %283, align 4, !tbaa !459
-  %348 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 28
-  %349 = load i8, i8* %348, align 4, !tbaa !454
-  %350 = zext i8 %349 to i32
-  %351 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 29
-  %352 = load i8, i8* %351, align 1, !tbaa !454
-  %353 = zext i8 %352 to i32
-  %354 = shl nuw nsw i32 %353, 8
-  %355 = or i32 %354, %350
-  %356 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 30
-  %357 = load i8, i8* %356, align 2, !tbaa !454
-  %358 = zext i8 %357 to i32
-  %359 = shl nuw nsw i32 %358, 16
-  %360 = or i32 %355, %359
-  %361 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 31
-  %362 = load i8, i8* %361, align 1, !tbaa !454
-  %363 = zext i8 %362 to i32
-  %364 = shl nuw i32 %363, 24
-  %365 = or i32 %360, %364
-  %366 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 11
-  store i32 %365, i32* %366, align 4, !tbaa !459
-  %367 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 12
-  store i32 0, i32* %367, align 4, !tbaa !459
-  %368 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 13
-  store i32 0, i32* %368, align 4, !tbaa !459
-  %369 = trunc i64 %281 to i32
-  %370 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 14
-  store i32 %369, i32* %370, align 4, !tbaa !459
-  %371 = lshr i64 %281, 32
-  %372 = trunc i64 %371 to i32
-  %373 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 15
-  store i32 %372, i32* %373, align 4, !tbaa !459
+239:                                              ; preds = %101, %7
+  %240 = phi i8 [ %44, %7 ], [ %238, %101 ]
+  %241 = phi i8 [ %42, %7 ], [ %236, %101 ]
+  %242 = phi i8 [ %40, %7 ], [ %234, %101 ]
+  %243 = phi i8 [ %38, %7 ], [ %233, %101 ]
+  %244 = phi i8 [ %36, %7 ], [ %231, %101 ]
+  %245 = phi i8 [ %34, %7 ], [ %229, %101 ]
+  %246 = phi i8 [ %32, %7 ], [ %227, %101 ]
+  %247 = phi i8 [ %30, %7 ], [ %226, %101 ]
+  %248 = phi i8 [ %28, %7 ], [ %224, %101 ]
+  %249 = phi i8 [ %26, %7 ], [ %222, %101 ]
+  %250 = phi i8 [ %24, %7 ], [ %220, %101 ]
+  %251 = phi i8 [ %22, %7 ], [ %219, %101 ]
+  %252 = phi i8 [ %20, %7 ], [ %217, %101 ]
+  %253 = phi i8 [ %18, %7 ], [ %215, %101 ]
+  %254 = phi i8 [ %16, %7 ], [ %213, %101 ]
+  %255 = phi i8 [ %14, %7 ], [ %212, %101 ]
+  %256 = phi i8 [ %12, %7 ], [ %210, %101 ]
+  %257 = phi i8 [ %10, %7 ], [ %208, %101 ]
+  %258 = phi i8 [ %8, %7 ], [ %206, %101 ]
+  %259 = ptrtoint %struct.mi_random_cxt_s* %0 to i64
+  %260 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 4
+  %261 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 10
+  %262 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 11
+  %263 = bitcast i32* %262 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 4 dereferenceable(132) %263, i8 0, i64 88, i1 false) #37
+  %264 = bitcast %struct.mi_random_cxt_s* %0 to <4 x i32>*
+  store <4 x i32> <i32 1634760805, i32 857760878, i32 2036477234, i32 1797285236>, <4 x i32>* %264, align 4, !tbaa !463
+  %265 = zext i8 %258 to i32
+  %266 = zext i8 %257 to i32
+  %267 = shl nuw nsw i32 %266, 8
+  %268 = or i32 %267, %265
+  %269 = zext i8 %256 to i32
+  %270 = shl nuw nsw i32 %269, 16
+  %271 = or i32 %268, %270
+  %272 = zext i8 %255 to i32
+  %273 = shl nuw i32 %272, 24
+  %274 = or i32 %271, %273
+  store i32 %274, i32* %260, align 4, !tbaa !463
+  %275 = zext i8 %254 to i32
+  %276 = zext i8 %253 to i32
+  %277 = shl nuw nsw i32 %276, 8
+  %278 = or i32 %277, %275
+  %279 = zext i8 %252 to i32
+  %280 = shl nuw nsw i32 %279, 16
+  %281 = or i32 %278, %280
+  %282 = zext i8 %251 to i32
+  %283 = shl nuw i32 %282, 24
+  %284 = or i32 %281, %283
+  %285 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 5
+  store i32 %284, i32* %285, align 4, !tbaa !463
+  %286 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 6
+  %287 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 19
+  %288 = load atomic i8, i8* %287 unordered, align 1, !tbaa !458
+  %289 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 20
+  %290 = load atomic i8, i8* %289 unordered, align 4, !tbaa !458
+  %291 = insertelement <4 x i8> undef, i8 %250, i32 0
+  %292 = insertelement <4 x i8> %291, i8 %246, i32 1
+  %293 = insertelement <4 x i8> %292, i8 %242, i32 2
+  %294 = insertelement <4 x i8> %293, i8 %290, i32 3
+  %295 = zext <4 x i8> %294 to <4 x i32>
+  %296 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 21
+  %297 = load atomic i8, i8* %296 unordered, align 1, !tbaa !458
+  %298 = insertelement <4 x i8> undef, i8 %249, i32 0
+  %299 = insertelement <4 x i8> %298, i8 %245, i32 1
+  %300 = insertelement <4 x i8> %299, i8 %241, i32 2
+  %301 = insertelement <4 x i8> %300, i8 %297, i32 3
+  %302 = zext <4 x i8> %301 to <4 x i32>
+  %303 = shl nuw nsw <4 x i32> %302, <i32 8, i32 8, i32 8, i32 8>
+  %304 = or <4 x i32> %303, %295
+  %305 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 22
+  %306 = load atomic i8, i8* %305 unordered, align 2, !tbaa !458
+  %307 = insertelement <4 x i8> undef, i8 %248, i32 0
+  %308 = insertelement <4 x i8> %307, i8 %244, i32 1
+  %309 = insertelement <4 x i8> %308, i8 %240, i32 2
+  %310 = insertelement <4 x i8> %309, i8 %306, i32 3
+  %311 = zext <4 x i8> %310 to <4 x i32>
+  %312 = shl nuw nsw <4 x i32> %311, <i32 16, i32 16, i32 16, i32 16>
+  %313 = or <4 x i32> %304, %312
+  %314 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 23
+  %315 = load atomic i8, i8* %314 unordered, align 1, !tbaa !458
+  %316 = insertelement <4 x i8> undef, i8 %247, i32 0
+  %317 = insertelement <4 x i8> %316, i8 %243, i32 1
+  %318 = insertelement <4 x i8> %317, i8 %288, i32 2
+  %319 = insertelement <4 x i8> %318, i8 %315, i32 3
+  %320 = zext <4 x i8> %319 to <4 x i32>
+  %321 = shl nuw <4 x i32> %320, <i32 24, i32 24, i32 24, i32 24>
+  %322 = or <4 x i32> %313, %321
+  %323 = bitcast i32* %286 to <4 x i32>*
+  store <4 x i32> %322, <4 x i32>* %323, align 4, !tbaa !463
+  %324 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 24
+  %325 = load atomic i8, i8* %324 unordered, align 8, !tbaa !458
+  %326 = zext i8 %325 to i32
+  %327 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 25
+  %328 = load atomic i8, i8* %327 unordered, align 1, !tbaa !458
+  %329 = zext i8 %328 to i32
+  %330 = shl nuw nsw i32 %329, 8
+  %331 = or i32 %330, %326
+  %332 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 26
+  %333 = load atomic i8, i8* %332 unordered, align 2, !tbaa !458
+  %334 = zext i8 %333 to i32
+  %335 = shl nuw nsw i32 %334, 16
+  %336 = or i32 %331, %335
+  %337 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 27
+  %338 = load atomic i8, i8* %337 unordered, align 1, !tbaa !458
+  %339 = zext i8 %338 to i32
+  %340 = shl nuw i32 %339, 24
+  %341 = or i32 %336, %340
+  store i32 %341, i32* %261, align 4, !tbaa !463
+  %342 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 28
+  %343 = load atomic i8, i8* %342 unordered, align 4, !tbaa !458
+  %344 = zext i8 %343 to i32
+  %345 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 29
+  %346 = load atomic i8, i8* %345 unordered, align 1, !tbaa !458
+  %347 = zext i8 %346 to i32
+  %348 = shl nuw nsw i32 %347, 8
+  %349 = or i32 %348, %344
+  %350 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 30
+  %351 = load atomic i8, i8* %350 unordered, align 2, !tbaa !458
+  %352 = zext i8 %351 to i32
+  %353 = shl nuw nsw i32 %352, 16
+  %354 = or i32 %349, %353
+  %355 = getelementptr inbounds [32 x i8], [32 x i8]* %3, i64 0, i64 31
+  %356 = load atomic i8, i8* %355 unordered, align 1, !tbaa !458
+  %357 = zext i8 %356 to i32
+  %358 = shl nuw i32 %357, 24
+  %359 = or i32 %354, %358
+  %360 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 11
+  store i32 %359, i32* %360, align 4, !tbaa !463
+  %361 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 12
+  store i32 0, i32* %361, align 4, !tbaa !463
+  %362 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 13
+  store i32 0, i32* %362, align 4, !tbaa !463
+  %363 = trunc i64 %259 to i32
+  %364 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 14
+  store i32 %363, i32* %364, align 4, !tbaa !463
+  %365 = lshr i64 %259, 32
+  %366 = trunc i64 %365 to i32
+  %367 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 0, i64 15
+  store i32 %366, i32* %367, align 4, !tbaa !463
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %4) #37
   ret void
 }
@@ -30541,13 +31103,13 @@
 define internal fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* nocapture %0) unnamed_addr #26 {
   %2 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 7
   %3 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 7, i32 2
-  %4 = load i32, i32* %3, align 4, !tbaa !460
+  %4 = load atomic i32, i32* %3 unordered, align 4, !tbaa !464
   %5 = icmp slt i32 %4, 1
   br i1 %5, label %6, label %7
 
 6:                                                ; preds = %1
   tail call fastcc void @chacha_block(%struct.mi_random_cxt_s* nonnull %2) #37
-  store i32 16, i32* %3, align 4, !tbaa !460
+  store i32 16, i32* %3, align 4, !tbaa !464
   br label %7
 
 7:                                                ; preds = %6, %1
@@ -30555,17 +31117,17 @@
   %9 = sub nsw i32 16, %8
   %10 = sext i32 %9 to i64
   %11 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 7, i32 1, i64 %10
-  %12 = load i32, i32* %11, align 4, !tbaa !459
-  store i32 0, i32* %11, align 4, !tbaa !459
-  %13 = load i32, i32* %3, align 4, !tbaa !460
+  %12 = load atomic i32, i32* %11 unordered, align 4, !tbaa !463
+  store i32 0, i32* %11, align 4, !tbaa !463
+  %13 = load atomic i32, i32* %3 unordered, align 4, !tbaa !464
   %14 = add nsw i32 %13, -1
-  store i32 %14, i32* %3, align 4, !tbaa !460
+  store i32 %14, i32* %3, align 4, !tbaa !464
   %15 = icmp slt i32 %13, 2
   br i1 %15, label %16, label %_mi_random_next.exit
 
 16:                                               ; preds = %7
   tail call fastcc void @chacha_block(%struct.mi_random_cxt_s* nonnull %2) #37
-  store i32 16, i32* %3, align 4, !tbaa !460
+  store i32 16, i32* %3, align 4, !tbaa !464
   br label %_mi_random_next.exit
 
 _mi_random_next.exit:                             ; preds = %16, %7
@@ -30575,11 +31137,11 @@
   %20 = sub nsw i32 16, %17
   %21 = sext i32 %20 to i64
   %22 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 7, i32 1, i64 %21
-  %23 = load i32, i32* %22, align 4, !tbaa !459
-  store i32 0, i32* %22, align 4, !tbaa !459
-  %24 = load i32, i32* %3, align 4, !tbaa !460
+  %23 = load atomic i32, i32* %22 unordered, align 4, !tbaa !463
+  store i32 0, i32* %22, align 4, !tbaa !463
+  %24 = load atomic i32, i32* %3 unordered, align 4, !tbaa !464
   %25 = add nsw i32 %24, -1
-  store i32 %25, i32* %3, align 4, !tbaa !460
+  store i32 %25, i32* %3, align 4, !tbaa !464
   %26 = zext i32 %23 to i64
   %27 = or i64 %19, %26
   ret i64 %27
@@ -30592,224 +31154,225 @@
   %3 = alloca %struct.rusage, align 8
   %4 = alloca [256 x i8], align 16
   %5 = alloca %struct.buffered_s, align 8
-  %.b = load i1, i1* @_mi_process_is_initialized, align 1
-  br i1 %.b, label %6, label %139
+  %6 = load atomic i8, i8* @_mi_process_is_initialized unordered, align 1, !tbaa !465, !range !70
+  %7 = icmp eq i8 %6, 0
+  br i1 %7, label %141, label %8
 
-6:                                                ; preds = %0
-  %7 = load i1, i1* @mi_process_done.process_done, align 1
-  br i1 %7, label %139, label %8
+8:                                                ; preds = %0
+  %9 = load i1, i1* @mi_process_done.process_done, align 1
+  br i1 %9, label %141, label %10
 
-8:                                                ; preds = %6
+10:                                               ; preds = %8
   store i1 true, i1* @mi_process_done.process_done, align 1
-  %9 = load %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !434
-  tail call fastcc void @mi_heap_collect_ex(%struct.mi_heap_s* %9, i32 1) #37
-  %10 = tail call fastcc i64 @mi_option_get(i32 1) #37
-  %.not = icmp eq i64 %10, 0
-  br i1 %.not, label %11, label %13
+  %11 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default unordered, align 8, !tbaa !438
+  tail call fastcc void @mi_heap_collect_ex(%struct.mi_heap_s* %11, i32 1) #37
+  %12 = tail call fastcc i64 @mi_option_get(i32 1) #37
+  %.not = icmp eq i64 %12, 0
+  br i1 %.not, label %13, label %15
 
-11:                                               ; preds = %8
-  %12 = tail call fastcc i64 @mi_option_get(i32 2) #37
-  %.not1 = icmp eq i64 %12, 0
-  br i1 %.not1, label %137, label %13
+13:                                               ; preds = %10
+  %14 = tail call fastcc i64 @mi_option_get(i32 2) #37
+  %.not1 = icmp eq i64 %14, 0
+  br i1 %.not1, label %139, label %15
 
-13:                                               ; preds = %11, %8
+15:                                               ; preds = %13, %10
   tail call fastcc void @mi_thread_init() #37
-  %14 = load %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !434
-  %15 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %14, i64 0, i32 0
-  %16 = load %struct.mi_tld_s*, %struct.mi_tld_s** %15, align 8, !tbaa !461
-  %17 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %16, i64 0, i32 6
-  tail call fastcc void @mi_stats_merge_from(%struct.mi_stats_s* nonnull %17) #37
-  %18 = getelementptr inbounds [256 x i8], [256 x i8]* %4, i64 0, i64 0
-  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %18) #37
-  %19 = bitcast %struct.buffered_s* %5 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %19) #37
-  %20 = getelementptr inbounds %struct.buffered_s, %struct.buffered_s* %5, i64 0, i32 2
-  %21 = getelementptr inbounds i8*, i8** %20, i64 1
-  %22 = bitcast i8** %21 to <2 x i64>*
-  %23 = bitcast %struct.buffered_s* %5 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %23, i8 0, i64 16, i1 false)
-  store <2 x i64> <i64 0, i64 255>, <2 x i64>* %22, align 8
-  store i8* %18, i8** %20, align 8, !tbaa !462
-  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %19, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.23.476, i64 0, i64 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.24.477, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.25.478, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.26.479, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.27.480, i64 0, i64 0), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.28.481, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.29.482, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.30.483, i64 0, i64 0)) #37
-  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.5.484, i64 0, i64 0), i64 1, i8* nonnull %19) #37
-  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.1.6, i64 0, i64 0), i64 1, i8* nonnull %19) #37
-  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 4), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.2.7, i64 0, i64 0), i64 1, i8* nonnull %19) #37
-  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 5), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.3.485, i64 0, i64 0), i64 1, i8* nonnull %19) #37
-  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.4.486, i64 0, i64 0), i64 -1, i8* nonnull %19) #37
-  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 6), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.5.8, i64 0, i64 0), i64 -1, i8* nonnull %19) #37
-  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 13), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.6.487, i64 0, i64 0), i64 -1, i8* nonnull %19) #37
-  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 1), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.7.488, i64 0, i64 0), i64 -1, i8* nonnull %19) #37
-  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 7), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.5.8, i64 0, i64 0), i64 -1, i8* nonnull %19) #37
-  call fastcc void @mi_stat_counter_print({ i64, i64 }* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 14), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.8.489, i64 0, i64 0), i8* nonnull %19) #37
-  call fastcc void @mi_stat_counter_print({ i64, i64 }* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 17), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.9.490, i64 0, i64 0), i8* nonnull %19) #37
-  call fastcc void @mi_stat_counter_print({ i64, i64 }* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 15), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.10.491, i64 0, i64 0), i8* nonnull %19) #37
-  call fastcc void @mi_stat_counter_print({ i64, i64 }* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 16), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.11.492, i64 0, i64 0), i8* nonnull %19) #37
-  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 8), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.12.493, i64 0, i64 0), i64 -1, i8* nonnull %19) #37
-  %24 = load i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 18, i32 1), align 8, !tbaa !464
-  %25 = icmp eq i64 %24, 0
-  br i1 %25, label %30, label %26
+  %16 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default unordered, align 8, !tbaa !438
+  %17 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %16, i64 0, i32 0
+  %18 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %17 unordered, align 8, !tbaa !466
+  %19 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %18, i64 0, i32 6
+  tail call fastcc void @mi_stats_merge_from(%struct.mi_stats_s* nonnull %19) #37
+  %20 = getelementptr inbounds [256 x i8], [256 x i8]* %4, i64 0, i64 0
+  call void @llvm.lifetime.start.p0i8(i64 256, i8* nonnull %20) #37
+  %21 = bitcast %struct.buffered_s* %5 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 40, i8* nonnull %21) #37
+  %22 = getelementptr inbounds %struct.buffered_s, %struct.buffered_s* %5, i64 0, i32 2
+  %23 = getelementptr inbounds i8*, i8** %22, i64 1
+  %24 = bitcast i8** %23 to <2 x i64>*
+  %25 = bitcast %struct.buffered_s* %5 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %25, i8 0, i64 16, i1 false)
+  store <2 x i64> <i64 0, i64 255>, <2 x i64>* %24, align 8
+  store i8* %20, i8** %22, align 8, !tbaa !467
+  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %21, i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.23.476, i64 0, i64 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.24.477, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.25.478, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.26.479, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.27.480, i64 0, i64 0), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.28.481, i64 0, i64 0), i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.29.482, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.30.483, i64 0, i64 0)) #37
+  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.5.484, i64 0, i64 0), i64 1, i8* nonnull %21) #37
+  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.1.6, i64 0, i64 0), i64 1, i8* nonnull %21) #37
+  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 4), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.2.7, i64 0, i64 0), i64 1, i8* nonnull %21) #37
+  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 5), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.3.485, i64 0, i64 0), i64 1, i8* nonnull %21) #37
+  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.4.486, i64 0, i64 0), i64 -1, i8* nonnull %21) #37
+  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 6), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.5.8, i64 0, i64 0), i64 -1, i8* nonnull %21) #37
+  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 13), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.6.487, i64 0, i64 0), i64 -1, i8* nonnull %21) #37
+  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 1), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.7.488, i64 0, i64 0), i64 -1, i8* nonnull %21) #37
+  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 7), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.5.8, i64 0, i64 0), i64 -1, i8* nonnull %21) #37
+  call fastcc void @mi_stat_counter_print({ i64, i64 }* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 14), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.8.489, i64 0, i64 0), i8* nonnull %21) #37
+  call fastcc void @mi_stat_counter_print({ i64, i64 }* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 17), i8* getelementptr inbounds ([10 x i8], [10 x i8]* @.str.9.490, i64 0, i64 0), i8* nonnull %21) #37
+  call fastcc void @mi_stat_counter_print({ i64, i64 }* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 15), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.10.491, i64 0, i64 0), i8* nonnull %21) #37
+  call fastcc void @mi_stat_counter_print({ i64, i64 }* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 16), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.11.492, i64 0, i64 0), i8* nonnull %21) #37
+  call fastcc void @mi_stat_print(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 8), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.12.493, i64 0, i64 0), i64 -1, i8* nonnull %21) #37
+  %26 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 18, i32 1) unordered, align 8, !tbaa !469
+  %27 = icmp eq i64 %26, 0
+  br i1 %27, label %32, label %28
 
-26:                                               ; preds = %13
-  %27 = load i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 18, i32 0), align 64, !tbaa !466
-  %28 = mul nsw i64 %27, 10
-  %29 = sdiv i64 %28, %24
-  br label %30
+28:                                               ; preds = %15
+  %29 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 18, i32 0) unordered, align 64, !tbaa !471
+  %30 = mul nsw i64 %29, 10
+  %31 = sdiv i64 %30, %26
+  br label %32
 
-30:                                               ; preds = %26, %13
-  %31 = phi i64 [ %29, %26 ], [ 0, %13 ]
-  %32 = sdiv i64 %31, 10
-  %33 = srem i64 %31, 10
-  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %19, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.38.494, i64 0, i64 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.13.495, i64 0, i64 0), i64 %32, i64 %33) #37
-  %34 = load atomic i64, i64* @_mi_numa_node_count monotonic, align 8
-  %35 = icmp eq i64 %34, 0
-  br i1 %35, label %36, label %38, !prof !284, !misexpect !437
+32:                                               ; preds = %28, %15
+  %33 = phi i64 [ %31, %28 ], [ 0, %15 ]
+  %34 = sdiv i64 %33, 10
+  %35 = srem i64 %33, 10
+  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %21, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.38.494, i64 0, i64 0), i8* getelementptr inbounds ([9 x i8], [9 x i8]* @.str.13.495, i64 0, i64 0), i64 %34, i64 %35) #37
+  %36 = load atomic i64, i64* @_mi_numa_node_count monotonic, align 8
+  %37 = icmp eq i64 %36, 0
+  br i1 %37, label %38, label %40, !prof !282, !misexpect !441
 
-36:                                               ; preds = %30
-  %37 = call i64 @_mi_os_numa_node_count_get() #37
-  br label %38
+38:                                               ; preds = %32
+  %39 = call i64 @_mi_os_numa_node_count_get() #37
+  br label %40
 
-38:                                               ; preds = %36, %30
-  %39 = phi i64 [ %37, %36 ], [ %34, %30 ]
-  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %19, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.14.496, i64 0, i64 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.15.497, i64 0, i64 0), i64 %39) #37
-  %40 = load i64, i64* @mi_process_start, align 8, !tbaa !453
-  %41 = bitcast { i64, i64 }* %2 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %41) #37
-  %42 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %2) #37
-  %43 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %2, i64 0, i32 0
-  %44 = load i64, i64* %43, align 8, !tbaa !456
-  %45 = mul nsw i64 %44, 1000
-  %46 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %2, i64 0, i32 1
-  %47 = load i64, i64* %46, align 8, !tbaa !458
-  %48 = sdiv i64 %47, 1000000
-  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %41) #37
-  %49 = load i64, i64* @mi_clock_diff, align 8, !tbaa !453
-  %50 = add i64 %45, %48
-  %51 = add i64 %40, %49
-  %52 = sub i64 %50, %51
-  %53 = bitcast %struct.rusage* %3 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 144, i8* nonnull %53) #37
-  %54 = call i32 @getrusage(i32 0, %struct.rusage* nonnull %3) #37
-  %55 = getelementptr inbounds %struct.rusage, %struct.rusage* %3, i64 0, i32 0, i32 0
-  %56 = load i64, i64* %55, align 8, !tbaa !467
-  %57 = getelementptr inbounds %struct.rusage, %struct.rusage* %3, i64 0, i32 0, i32 1
-  %58 = load i64, i64* %57, align 8, !tbaa !469
-  %59 = mul nsw i64 %56, 1000
-  %60 = sdiv i64 %58, 1000
-  %61 = add nsw i64 %60, %59
-  %62 = getelementptr inbounds %struct.rusage, %struct.rusage* %3, i64 0, i32 1, i32 0
-  %63 = load i64, i64* %62, align 8, !tbaa !467
-  %64 = getelementptr inbounds %struct.rusage, %struct.rusage* %3, i64 0, i32 1, i32 1
-  %65 = load i64, i64* %64, align 8, !tbaa !469
-  %66 = mul nsw i64 %63, 1000
-  %67 = sdiv i64 %65, 1000
-  %68 = add nsw i64 %67, %66
-  %69 = getelementptr inbounds %struct.rusage, %struct.rusage* %3, i64 0, i32 7, i32 0
-  %70 = load i64, i64* %69, align 8, !tbaa !454
-  %71 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2) monotonic, align 16
-  %72 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 3) monotonic, align 8
-  %73 = getelementptr inbounds %struct.rusage, %struct.rusage* %3, i64 0, i32 2, i32 0
-  %74 = load i64, i64* %73, align 8, !tbaa !454
-  %75 = shl nsw i64 %74, 10
-  call void @llvm.lifetime.end.p0i8(i64 144, i8* nonnull %53) #37
-  %76 = sdiv i64 %52, 1000
-  %77 = srem i64 %52, 1000
-  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %19, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.16.498, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.17.499, i64 0, i64 0), i64 %76, i64 %77) #37
-  %78 = sdiv i64 %61, 1000
-  %79 = srem i64 %61, 1000
-  %80 = sdiv i64 %68, 1000
-  %81 = srem i64 %68, 1000
-  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %19, i8* getelementptr inbounds ([65 x i8], [65 x i8]* @.str.18.500, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.19.501, i64 0, i64 0), i64 %78, i64 %79, i64 %80, i64 %81, i64 %70) #37
-  %82 = getelementptr inbounds [32 x i8], [32 x i8]* %1, i64 0, i64 0
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %82) #37
-  %83 = icmp slt i64 %75, 0
-  %84 = sub nsw i64 0, %75
-  %85 = select i1 %83, i64 %84, i64 %75
-  %86 = icmp slt i64 %85, 1024
-  br i1 %86, label %87, label %90
+40:                                               ; preds = %38, %32
+  %41 = phi i64 [ %39, %38 ], [ %36, %32 ]
+  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %21, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.14.496, i64 0, i64 0), i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.15.497, i64 0, i64 0), i64 %41) #37
+  %42 = load atomic i64, i64* @mi_process_start unordered, align 8, !tbaa !457
+  %43 = bitcast { i64, i64 }* %2 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %43) #37
+  %44 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %2) #37
+  %45 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %2, i64 0, i32 0
+  %46 = load atomic i64, i64* %45 unordered, align 8, !tbaa !460
+  %47 = mul nsw i64 %46, 1000
+  %48 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %2, i64 0, i32 1
+  %49 = load atomic i64, i64* %48 unordered, align 8, !tbaa !462
+  %50 = sdiv i64 %49, 1000000
+  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %43) #37
+  %51 = load atomic i64, i64* @mi_clock_diff unordered, align 8, !tbaa !457
+  %52 = add i64 %47, %50
+  %53 = add i64 %42, %51
+  %54 = sub i64 %52, %53
+  %55 = bitcast %struct.rusage* %3 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 144, i8* nonnull %55) #37
+  %56 = call i32 @getrusage(i32 0, %struct.rusage* nonnull %3) #37
+  %57 = getelementptr inbounds %struct.rusage, %struct.rusage* %3, i64 0, i32 0, i32 0
+  %58 = load atomic i64, i64* %57 unordered, align 8, !tbaa !472
+  %59 = getelementptr inbounds %struct.rusage, %struct.rusage* %3, i64 0, i32 0, i32 1
+  %60 = load atomic i64, i64* %59 unordered, align 8, !tbaa !474
+  %61 = mul nsw i64 %58, 1000
+  %62 = sdiv i64 %60, 1000
+  %63 = add nsw i64 %62, %61
+  %64 = getelementptr inbounds %struct.rusage, %struct.rusage* %3, i64 0, i32 1, i32 0
+  %65 = load atomic i64, i64* %64 unordered, align 8, !tbaa !472
+  %66 = getelementptr inbounds %struct.rusage, %struct.rusage* %3, i64 0, i32 1, i32 1
+  %67 = load atomic i64, i64* %66 unordered, align 8, !tbaa !474
+  %68 = mul nsw i64 %65, 1000
+  %69 = sdiv i64 %67, 1000
+  %70 = add nsw i64 %69, %68
+  %71 = getelementptr inbounds %struct.rusage, %struct.rusage* %3, i64 0, i32 7, i32 0
+  %72 = load atomic i64, i64* %71 unordered, align 8, !tbaa !458
+  %73 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2) monotonic, align 16
+  %74 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 3) monotonic, align 8
+  %75 = getelementptr inbounds %struct.rusage, %struct.rusage* %3, i64 0, i32 2, i32 0
+  %76 = load atomic i64, i64* %75 unordered, align 8, !tbaa !458
+  %77 = shl nsw i64 %76, 10
+  call void @llvm.lifetime.end.p0i8(i64 144, i8* nonnull %55) #37
+  %78 = sdiv i64 %54, 1000
+  %79 = srem i64 %54, 1000
+  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %21, i8* getelementptr inbounds ([20 x i8], [20 x i8]* @.str.16.498, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.17.499, i64 0, i64 0), i64 %78, i64 %79) #37
+  %80 = sdiv i64 %63, 1000
+  %81 = srem i64 %63, 1000
+  %82 = sdiv i64 %70, 1000
+  %83 = srem i64 %70, 1000
+  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %21, i8* getelementptr inbounds ([65 x i8], [65 x i8]* @.str.18.500, i64 0, i64 0), i8* getelementptr inbounds ([8 x i8], [8 x i8]* @.str.19.501, i64 0, i64 0), i64 %80, i64 %81, i64 %82, i64 %83, i64 %72) #37
+  %84 = getelementptr inbounds [32 x i8], [32 x i8]* %1, i64 0, i64 0
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %84) #37
+  %85 = icmp slt i64 %77, 0
+  %86 = sub nsw i64 0, %77
+  %87 = select i1 %85, i64 %86, i64 %77
+  %88 = icmp slt i64 %87, 1024
+  br i1 %88, label %89, label %92
 
-87:                                               ; preds = %38
-  %88 = trunc i64 %75 to i32
-  %89 = call i32 (i8*, i64, i8*, ...) @snprintf(i8* nonnull %82, i64 32, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.40.502, i64 0, i64 0), i32 %88, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39.503, i64 0, i64 0)) #37
-  br label %108
+89:                                               ; preds = %40
+  %90 = trunc i64 %77 to i32
+  %91 = call i32 (i8*, i64, i8*, ...) @snprintf(i8* nonnull %84, i64 32, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.40.502, i64 0, i64 0), i32 %90, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39.503, i64 0, i64 0)) #37
+  br label %110
 
-90:                                               ; preds = %38
-  %91 = icmp slt i64 %85, 1048576
-  %92 = select i1 %91, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.41.504, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.42.505, i64 0, i64 0)
-  %93 = select i1 %91, i64 1024, i64 1048576
-  %94 = shl nuw nsw i64 %93, 10
-  %95 = icmp slt i64 %85, %94
-  %96 = select i1 %95, i8* %92, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.43.506, i64 0, i64 0)
-  %97 = select i1 %95, i64 %93, i64 %94
-  %98 = trunc i64 %97 to i32
-  %99 = udiv i32 %98, 10
-  %100 = zext i32 %99 to i64
-  %101 = sdiv i64 %75, %100
-  %102 = sdiv i64 %101, 10
-  %103 = srem i64 %101, 10
-  %104 = icmp slt i64 %103, 0
-  %105 = sub nsw i64 0, %103
-  %106 = select i1 %104, i64 %105, i64 %103
-  %107 = call i32 (i8*, i64, i8*, ...) @snprintf(i8* nonnull %82, i64 32, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.44.507, i64 0, i64 0), i64 %102, i64 %106, i8* %96, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39.503, i64 0, i64 0)) #37
-  br label %108
+92:                                               ; preds = %40
+  %93 = icmp slt i64 %87, 1048576
+  %94 = select i1 %93, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.41.504, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.42.505, i64 0, i64 0)
+  %95 = select i1 %93, i64 1024, i64 1048576
+  %96 = shl nuw nsw i64 %95, 10
+  %97 = icmp slt i64 %87, %96
+  %98 = select i1 %97, i8* %94, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.43.506, i64 0, i64 0)
+  %99 = select i1 %97, i64 %95, i64 %96
+  %100 = trunc i64 %99 to i32
+  %101 = udiv i32 %100, 10
+  %102 = zext i32 %101 to i64
+  %103 = sdiv i64 %77, %102
+  %104 = sdiv i64 %103, 10
+  %105 = srem i64 %103, 10
+  %106 = icmp slt i64 %105, 0
+  %107 = sub nsw i64 0, %105
+  %108 = select i1 %106, i64 %107, i64 %105
+  %109 = call i32 (i8*, i64, i8*, ...) @snprintf(i8* nonnull %84, i64 32, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.44.507, i64 0, i64 0), i64 %104, i64 %108, i8* %98, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39.503, i64 0, i64 0)) #37
+  br label %110
 
-108:                                              ; preds = %90, %87
-  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %19, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.69.559, i64 0, i64 0), i8* nonnull %82) #37
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %82) #37
-  %109 = icmp eq i64 %71, 0
-  br i1 %109, label %mi_stats_print.exit, label %110
+110:                                              ; preds = %92, %89
+  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %21, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.69.559, i64 0, i64 0), i8* nonnull %84) #37
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %84) #37
+  %111 = icmp eq i64 %73, 0
+  br i1 %111, label %mi_stats_print.exit, label %112
 
-110:                                              ; preds = %108
-  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %19, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.21.509, i64 0, i64 0)) #37
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %82) #37
-  %111 = icmp slt i64 %71, 0
-  %112 = sub nsw i64 0, %71
-  %113 = select i1 %111, i64 %112, i64 %71
-  %114 = icmp slt i64 %113, 1024
-  br i1 %114, label %115, label %118
+112:                                              ; preds = %110
+  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %21, i8* getelementptr inbounds ([11 x i8], [11 x i8]* @.str.21.509, i64 0, i64 0)) #37
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %84) #37
+  %113 = icmp slt i64 %73, 0
+  %114 = sub nsw i64 0, %73
+  %115 = select i1 %113, i64 %114, i64 %73
+  %116 = icmp slt i64 %115, 1024
+  br i1 %116, label %117, label %120
 
-115:                                              ; preds = %110
-  %116 = trunc i64 %71 to i32
-  %117 = call i32 (i8*, i64, i8*, ...) @snprintf(i8* nonnull %82, i64 32, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.40.502, i64 0, i64 0), i32 %116, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39.503, i64 0, i64 0)) #37
-  br label %136
+117:                                              ; preds = %112
+  %118 = trunc i64 %73 to i32
+  %119 = call i32 (i8*, i64, i8*, ...) @snprintf(i8* nonnull %84, i64 32, i8* getelementptr inbounds ([7 x i8], [7 x i8]* @.str.40.502, i64 0, i64 0), i32 %118, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39.503, i64 0, i64 0)) #37
+  br label %138
 
-118:                                              ; preds = %110
-  %119 = icmp slt i64 %113, 1048576
-  %120 = select i1 %119, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.41.504, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.42.505, i64 0, i64 0)
-  %121 = select i1 %119, i64 1024, i64 1048576
-  %122 = shl nuw nsw i64 %121, 10
-  %123 = icmp slt i64 %113, %122
-  %124 = select i1 %123, i8* %120, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.43.506, i64 0, i64 0)
-  %125 = select i1 %123, i64 %121, i64 %122
-  %126 = trunc i64 %125 to i32
-  %127 = udiv i32 %126, 10
-  %128 = zext i32 %127 to i64
-  %129 = sdiv i64 %71, %128
-  %130 = sdiv i64 %129, 10
-  %131 = srem i64 %129, 10
-  %132 = icmp slt i64 %131, 0
-  %133 = sub nsw i64 0, %131
-  %134 = select i1 %132, i64 %133, i64 %131
-  %135 = call i32 (i8*, i64, i8*, ...) @snprintf(i8* nonnull %82, i64 32, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.44.507, i64 0, i64 0), i64 %130, i64 %134, i8* %124, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39.503, i64 0, i64 0)) #37
-  br label %136
+120:                                              ; preds = %112
+  %121 = icmp slt i64 %115, 1048576
+  %122 = select i1 %121, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.41.504, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.42.505, i64 0, i64 0)
+  %123 = select i1 %121, i64 1024, i64 1048576
+  %124 = shl nuw nsw i64 %123, 10
+  %125 = icmp slt i64 %115, %124
+  %126 = select i1 %125, i8* %122, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.43.506, i64 0, i64 0)
+  %127 = select i1 %125, i64 %123, i64 %124
+  %128 = trunc i64 %127 to i32
+  %129 = udiv i32 %128, 10
+  %130 = zext i32 %129 to i64
+  %131 = sdiv i64 %73, %130
+  %132 = sdiv i64 %131, 10
+  %133 = srem i64 %131, 10
+  %134 = icmp slt i64 %133, 0
+  %135 = sub nsw i64 0, %133
+  %136 = select i1 %134, i64 %135, i64 %133
+  %137 = call i32 (i8*, i64, i8*, ...) @snprintf(i8* nonnull %84, i64 32, i8* getelementptr inbounds ([13 x i8], [13 x i8]* @.str.44.507, i64 0, i64 0), i64 %132, i64 %136, i8* %126, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.39.503, i64 0, i64 0)) #37
+  br label %138
 
-136:                                              ; preds = %118, %115
-  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %19, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.69.559, i64 0, i64 0), i8* nonnull %82) #37
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %82) #37
+138:                                              ; preds = %120, %117
+  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %21, i8* getelementptr inbounds ([3 x i8], [3 x i8]* @.str.69.559, i64 0, i64 0), i8* nonnull %84) #37
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %84) #37
   br label %mi_stats_print.exit
 
-mi_stats_print.exit:                              ; preds = %136, %108
-  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %19, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.261, i64 0, i64 0)) #37
-  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %19) #37
-  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %18) #37
-  br label %137
+mi_stats_print.exit:                              ; preds = %138, %110
+  call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* nonnull %21, i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.261, i64 0, i64 0)) #37
+  call void @llvm.lifetime.end.p0i8(i64 40, i8* nonnull %21) #37
+  call void @llvm.lifetime.end.p0i8(i64 256, i8* nonnull %20) #37
+  br label %139
 
-137:                                              ; preds = %mi_stats_print.exit, %11
-  %138 = load i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4), align 8, !tbaa !452
-  tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.4.50, i64 0, i64 0), i64 %138) #37
+139:                                              ; preds = %mi_stats_print.exit, %13
+  %140 = load atomic i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4) unordered, align 8, !tbaa !456
+  tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.4.50, i64 0, i64 0), i64 %140) #37
   store i1 false, i1* @os_preloading, align 1
-  br label %139
+  br label %141
 
-139:                                              ; preds = %137, %6, %0
+141:                                              ; preds = %139, %8, %0
   ret void
 }
 
@@ -30828,871 +31391,872 @@
   %8 = alloca { i64, i64 }, align 8
   %9 = alloca { i64, i64 }, align 8
   %10 = alloca i64, align 8
-  %.b = load i1, i1* @_mi_process_is_initialized, align 1
-  br i1 %.b, label %532, label %11
+  %11 = load atomic i8, i8* @_mi_process_is_initialized unordered, align 1, !tbaa !465, !range !70
+  %12 = icmp eq i8 %11, 0
+  br i1 %12, label %13, label %534
 
-11:                                               ; preds = %0
-  store i1 true, i1* @_mi_process_is_initialized, align 1
-  %12 = load i1, i1* @mi_process_setup_auto_thread_done.tls_initialized, align 1
-  br i1 %12, label %19, label %13
+13:                                               ; preds = %0
+  store i8 1, i8* @_mi_process_is_initialized, align 1, !tbaa !465
+  %14 = load i1, i1* @mi_process_setup_auto_thread_done.tls_initialized, align 1
+  br i1 %14, label %21, label %15
 
-13:                                               ; preds = %11
+15:                                               ; preds = %13
   store i1 true, i1* @mi_process_setup_auto_thread_done.tls_initialized, align 1
-  %14 = tail call i32 @pthread_key_create(i32* nonnull @_mi_heap_default_key, void (i8*)* nonnull @mi_pthread_done) #37
-  store %struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*), %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !434
-  %15 = load i32, i32* @_mi_heap_default_key, align 4, !tbaa !459
-  %16 = icmp eq i32 %15, -1
-  br i1 %16, label %19, label %17
+  %16 = tail call i32 @pthread_key_create(i32* nonnull @_mi_heap_default_key, void (i8*)* nonnull @mi_pthread_done) #37
+  store %struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*), %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !438
+  %17 = load atomic i32, i32* @_mi_heap_default_key unordered, align 4, !tbaa !463
+  %18 = icmp eq i32 %17, -1
+  br i1 %18, label %21, label %19
 
-17:                                               ; preds = %13
-  %18 = tail call i32 @pthread_setspecific(i32 %15, i8* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to i8*)) #37
-  br label %19
+19:                                               ; preds = %15
+  %20 = tail call i32 @pthread_setspecific(i32 %17, i8* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to i8*)) #37
+  br label %21
 
-19:                                               ; preds = %17, %13, %11
-  %20 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !451
-  %21 = ptrtoint i8* %20 to i64
-  tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.45.465, i64 0, i64 0), i64 %21) #37
-  %22 = tail call i64 @sysconf(i32 30) #37
-  %23 = icmp sgt i64 %22, 0
-  br i1 %23, label %24, label %_mi_os_init.exit
+21:                                               ; preds = %19, %15, %13
+  %22 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !455
+  %23 = ptrtoint i8* %22 to i64
+  tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.45.465, i64 0, i64 0), i64 %23) #37
+  %24 = tail call i64 @sysconf(i32 30) #37
+  %25 = icmp sgt i64 %24, 0
+  br i1 %25, label %26, label %_mi_os_init.exit
 
-24:                                               ; preds = %19
-  store i64 %22, i64* @os_page_size, align 8, !tbaa !453
+26:                                               ; preds = %21
+  store i64 %24, i64* @os_page_size, align 8, !tbaa !457
   br label %_mi_os_init.exit
 
-_mi_os_init.exit:                                 ; preds = %24, %19
+_mi_os_init.exit:                                 ; preds = %26, %21
   store i1 true, i1* @large_os_page_size, align 8
-  %25 = load i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5), align 8, !tbaa !448
-  %26 = icmp eq i64 %25, 0
-  br i1 %26, label %27, label %33
+  %27 = load atomic i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5) unordered, align 8, !tbaa !452
+  %28 = icmp eq i64 %27, 0
+  br i1 %28, label %29, label %35
 
-27:                                               ; preds = %_mi_os_init.exit
-  %28 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !451
-  %29 = ptrtoint i8* %28 to i64
-  store i64 %29, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4), align 8, !tbaa !452
-  %30 = tail call i64 @_os_random_weak(i64 ptrtoint (void ()* @mi_heap_main_init to i64)) #37
-  store i64 %30, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5), align 8, !tbaa !448
+29:                                               ; preds = %_mi_os_init.exit
+  %30 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !455
+  %31 = ptrtoint i8* %30 to i64
+  store i64 %31, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4), align 8, !tbaa !456
+  %32 = tail call i64 @_os_random_weak(i64 ptrtoint (void ()* @mi_heap_main_init to i64)) #37
+  store i64 %32, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5), align 8, !tbaa !452
   tail call fastcc void @_mi_random_init(%struct.mi_random_cxt_s* bitcast (i32* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 7, i32 0, i32 0) to %struct.mi_random_cxt_s*)) #37
-  %31 = tail call fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*)) #37
-  store i64 %31, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 0), align 8, !tbaa !453
-  %32 = tail call fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*)) #37
-  store i64 %32, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 1), align 8, !tbaa !453
-  br label %33
+  %33 = tail call fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*)) #37
+  store i64 %33, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 0), align 8, !tbaa !457
+  %34 = tail call fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*)) #37
+  store i64 %34, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 1), align 8, !tbaa !457
+  br label %35
 
-33:                                               ; preds = %27, %_mi_os_init.exit
+35:                                               ; preds = %29, %_mi_os_init.exit
   tail call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.1.46, i64 0, i64 0), i32 0) #37
   tail call fastcc void @mi_thread_init()
   tail call fastcc void @mi_thread_init() #37
-  %34 = load %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !434
-  %35 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %34, i64 0, i32 0
-  %36 = load %struct.mi_tld_s*, %struct.mi_tld_s** %35, align 8, !tbaa !461
-  %37 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %36, i64 0, i32 6
-  %38 = icmp eq %struct.mi_stats_s* %37, @_mi_stats_main
-  br i1 %38, label %41, label %39
+  %36 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default unordered, align 8, !tbaa !438
+  %37 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %36, i64 0, i32 0
+  %38 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %37 unordered, align 8, !tbaa !466
+  %39 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %38, i64 0, i32 6
+  %40 = icmp eq %struct.mi_stats_s* %39, @_mi_stats_main
+  br i1 %40, label %43, label %41
 
-39:                                               ; preds = %33
-  %40 = bitcast %struct.mi_stats_s* %37 to i8*
-  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(576) %40, i8 0, i64 576, i1 false) #37
-  br label %41
+41:                                               ; preds = %35
+  %42 = bitcast %struct.mi_stats_s* %39 to i8*
+  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(576) %42, i8 0, i64 576, i1 false) #37
+  br label %43
 
-41:                                               ; preds = %39, %33
+43:                                               ; preds = %41, %35
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 64 dereferenceable(576) bitcast (%struct.mi_stats_s* @_mi_stats_main to i8*), i8 0, i64 576, i1 false) #37
-  %42 = load i64, i64* @mi_process_start, align 8, !tbaa !453
-  %43 = icmp eq i64 %42, 0
-  br i1 %43, label %44, label %mi_stats_reset.exit
+  %44 = load atomic i64, i64* @mi_process_start unordered, align 8, !tbaa !457
+  %45 = icmp eq i64 %44, 0
+  br i1 %45, label %46, label %mi_stats_reset.exit
 
-44:                                               ; preds = %41
-  %45 = load i64, i64* @mi_clock_diff, align 8, !tbaa !453
-  %46 = icmp eq i64 %45, 0
-  br i1 %46, label %47, label %66
+46:                                               ; preds = %43
+  %47 = load atomic i64, i64* @mi_clock_diff unordered, align 8, !tbaa !457
+  %48 = icmp eq i64 %47, 0
+  br i1 %48, label %49, label %68
 
-47:                                               ; preds = %44
-  %48 = bitcast { i64, i64 }* %3 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %48) #37
-  %49 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %3) #37
-  %50 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %3, i64 0, i32 0
-  %51 = load i64, i64* %50, align 8, !tbaa !456
-  %52 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %3, i64 0, i32 1
-  %53 = load i64, i64* %52, align 8, !tbaa !458
-  %54 = sdiv i64 %53, -1000000
-  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %48) #37
-  %55 = bitcast { i64, i64 }* %2 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %55) #37
-  %56 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %2) #37
-  %57 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %2, i64 0, i32 0
-  %58 = load i64, i64* %57, align 8, !tbaa !456
-  %59 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %2, i64 0, i32 1
-  %60 = load i64, i64* %59, align 8, !tbaa !458
-  %61 = sdiv i64 %60, 1000000
-  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %55) #37
-  %62 = sub i64 %58, %51
-  %63 = mul i64 %62, 1000
-  %64 = add nsw i64 %61, %54
-  %65 = add i64 %64, %63
-  store i64 %65, i64* @mi_clock_diff, align 8, !tbaa !453
-  br label %66
+49:                                               ; preds = %46
+  %50 = bitcast { i64, i64 }* %3 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %50) #37
+  %51 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %3) #37
+  %52 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %3, i64 0, i32 0
+  %53 = load atomic i64, i64* %52 unordered, align 8, !tbaa !460
+  %54 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %3, i64 0, i32 1
+  %55 = load atomic i64, i64* %54 unordered, align 8, !tbaa !462
+  %56 = sdiv i64 %55, -1000000
+  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %50) #37
+  %57 = bitcast { i64, i64 }* %2 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %57) #37
+  %58 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %2) #37
+  %59 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %2, i64 0, i32 0
+  %60 = load atomic i64, i64* %59 unordered, align 8, !tbaa !460
+  %61 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %2, i64 0, i32 1
+  %62 = load atomic i64, i64* %61 unordered, align 8, !tbaa !462
+  %63 = sdiv i64 %62, 1000000
+  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %57) #37
+  %64 = sub i64 %60, %53
+  %65 = mul i64 %64, 1000
+  %66 = add nsw i64 %63, %56
+  %67 = add i64 %66, %65
+  store i64 %67, i64* @mi_clock_diff, align 8, !tbaa !457
+  br label %68
 
-66:                                               ; preds = %47, %44
-  %67 = bitcast { i64, i64 }* %1 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %67) #37
-  %68 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %1) #37
-  %69 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %1, i64 0, i32 0
-  %70 = load i64, i64* %69, align 8, !tbaa !456
-  %71 = mul nsw i64 %70, 1000
-  %72 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %1, i64 0, i32 1
-  %73 = load i64, i64* %72, align 8, !tbaa !458
-  %74 = sdiv i64 %73, 1000000
-  %75 = add nsw i64 %74, %71
-  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %67) #37
-  store i64 %75, i64* @mi_process_start, align 8, !tbaa !453
+68:                                               ; preds = %49, %46
+  %69 = bitcast { i64, i64 }* %1 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %69) #37
+  %70 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %1) #37
+  %71 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %1, i64 0, i32 0
+  %72 = load atomic i64, i64* %71 unordered, align 8, !tbaa !460
+  %73 = mul nsw i64 %72, 1000
+  %74 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %1, i64 0, i32 1
+  %75 = load atomic i64, i64* %74 unordered, align 8, !tbaa !462
+  %76 = sdiv i64 %75, 1000000
+  %77 = add nsw i64 %76, %73
+  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %69) #37
+  store i64 %77, i64* @mi_process_start, align 8, !tbaa !457
   br label %mi_stats_reset.exit
 
-mi_stats_reset.exit:                              ; preds = %66, %41
-  %76 = tail call fastcc i64 @mi_option_get(i32 7) #37
-  %.not = icmp eq i64 %76, 0
-  br i1 %.not, label %mi_reserve_huge_os_pages_interleave.exit, label %77
-
-77:                                               ; preds = %mi_stats_reset.exit
+mi_stats_reset.exit:                              ; preds = %68, %43
   %78 = tail call fastcc i64 @mi_option_get(i32 7) #37
-  %79 = mul i64 %78, 500
-  %80 = icmp eq i64 %78, 0
-  br i1 %80, label %mi_reserve_huge_os_pages_interleave.exit, label %81
+  %.not = icmp eq i64 %78, 0
+  br i1 %.not, label %mi_reserve_huge_os_pages_interleave.exit, label %79
 
-81:                                               ; preds = %77
-  %82 = load atomic i64, i64* @_mi_numa_node_count monotonic, align 8
-  %83 = icmp eq i64 %82, 0
-  br i1 %83, label %84, label %86, !prof !284, !misexpect !437
+79:                                               ; preds = %mi_stats_reset.exit
+  %80 = tail call fastcc i64 @mi_option_get(i32 7) #37
+  %81 = mul i64 %80, 500
+  %82 = icmp eq i64 %80, 0
+  br i1 %82, label %mi_reserve_huge_os_pages_interleave.exit, label %83
 
-84:                                               ; preds = %81
-  %85 = tail call i64 @_mi_os_numa_node_count_get() #37
-  br label %86
+83:                                               ; preds = %79
+  %84 = load atomic i64, i64* @_mi_numa_node_count monotonic, align 8
+  %85 = icmp eq i64 %84, 0
+  br i1 %85, label %86, label %88, !prof !282, !misexpect !441
 
-86:                                               ; preds = %84, %81
-  %87 = phi i64 [ %85, %84 ], [ %82, %81 ]
-  %88 = icmp eq i64 %87, 0
-  %89 = select i1 %88, i64 1, i64 %87
-  %90 = udiv i64 %78, %89
-  %91 = urem i64 %78, %89
-  %92 = icmp eq i64 %79, 0
-  br i1 %92, label %96, label %93
+86:                                               ; preds = %83
+  %87 = tail call i64 @_mi_os_numa_node_count_get() #37
+  br label %88
 
-93:                                               ; preds = %86
-  %94 = udiv i64 %79, %89
-  %95 = add i64 %94, 50
-  br label %96
+88:                                               ; preds = %86, %83
+  %89 = phi i64 [ %87, %86 ], [ %84, %83 ]
+  %90 = icmp eq i64 %89, 0
+  %91 = select i1 %90, i64 1, i64 %89
+  %92 = udiv i64 %80, %91
+  %93 = urem i64 %80, %91
+  %94 = icmp eq i64 %81, 0
+  br i1 %94, label %98, label %95
 
-96:                                               ; preds = %93, %86
-  %97 = phi i64 [ %95, %93 ], [ 0, %86 ]
-  %98 = bitcast { i64, i64 }* %9 to i8*
-  %99 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %9, i64 0, i32 0
-  %100 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %9, i64 0, i32 1
-  %101 = bitcast { i64, i64 }* %8 to i8*
-  %102 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %8, i64 0, i32 0
-  %103 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %8, i64 0, i32 1
-  %104 = bitcast { i64, i64 }* %7 to i8*
-  %105 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %7, i64 0, i32 0
-  %106 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %7, i64 0, i32 1
-  %107 = bitcast i64* %10 to i8*
-  %108 = icmp sgt i64 %97, 0
-  %109 = shl nuw nsw i64 %97, 1
-  %110 = add nuw nsw i64 %97, 1
-  %111 = bitcast { i64, i64 }* %5 to i8*
-  %112 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %5, i64 0, i32 0
-  %113 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %5, i64 0, i32 1
-  %114 = bitcast { i64, i64 }* %6 to i8*
-  %115 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %6, i64 0, i32 0
-  %116 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %6, i64 0, i32 1
-  br label %117
+95:                                               ; preds = %88
+  %96 = udiv i64 %81, %91
+  %97 = add i64 %96, 50
+  br label %98
 
-117:                                              ; preds = %mi_reserve_huge_os_pages_at.exit.i.thread, %96
-  %118 = phi i64 [ %432, %mi_reserve_huge_os_pages_at.exit.i.thread ], [ 0, %96 ]
-  %119 = phi i64 [ %431, %mi_reserve_huge_os_pages_at.exit.i.thread ], [ %78, %96 ]
-  %120 = icmp ult i64 %118, %91
-  %121 = zext i1 %120 to i64
-  %122 = add i64 %90, %121
-  %123 = icmp eq i64 %122, 0
-  br i1 %123, label %mi_reserve_huge_os_pages_at.exit.i.thread, label %124
+98:                                               ; preds = %95, %88
+  %99 = phi i64 [ %97, %95 ], [ 0, %88 ]
+  %100 = bitcast { i64, i64 }* %9 to i8*
+  %101 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %9, i64 0, i32 0
+  %102 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %9, i64 0, i32 1
+  %103 = bitcast { i64, i64 }* %8 to i8*
+  %104 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %8, i64 0, i32 0
+  %105 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %8, i64 0, i32 1
+  %106 = bitcast { i64, i64 }* %7 to i8*
+  %107 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %7, i64 0, i32 0
+  %108 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %7, i64 0, i32 1
+  %109 = bitcast i64* %10 to i8*
+  %110 = icmp sgt i64 %99, 0
+  %111 = shl nuw nsw i64 %99, 1
+  %112 = add nuw nsw i64 %99, 1
+  %113 = bitcast { i64, i64 }* %5 to i8*
+  %114 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %5, i64 0, i32 0
+  %115 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %5, i64 0, i32 1
+  %116 = bitcast { i64, i64 }* %6 to i8*
+  %117 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %6, i64 0, i32 0
+  %118 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %6, i64 0, i32 1
+  br label %119
 
-124:                                              ; preds = %117
-  %125 = trunc i64 %118 to i32
-  %126 = icmp sgt i32 %125, -1
-  br i1 %126, label %127, label %137
+119:                                              ; preds = %mi_reserve_huge_os_pages_at.exit.i.thread, %98
+  %120 = phi i64 [ %434, %mi_reserve_huge_os_pages_at.exit.i.thread ], [ 0, %98 ]
+  %121 = phi i64 [ %433, %mi_reserve_huge_os_pages_at.exit.i.thread ], [ %80, %98 ]
+  %122 = icmp ult i64 %120, %93
+  %123 = zext i1 %122 to i64
+  %124 = add i64 %92, %123
+  %125 = icmp eq i64 %124, 0
+  br i1 %125, label %mi_reserve_huge_os_pages_at.exit.i.thread, label %126
 
-127:                                              ; preds = %124
-  %128 = and i64 %118, 4294967295
-  %129 = load atomic i64, i64* @_mi_numa_node_count monotonic, align 8
-  %130 = icmp eq i64 %129, 0
-  br i1 %130, label %131, label %133, !prof !284, !misexpect !437
+126:                                              ; preds = %119
+  %127 = trunc i64 %120 to i32
+  %128 = icmp sgt i32 %127, -1
+  br i1 %128, label %129, label %139
 
-131:                                              ; preds = %127
-  %132 = tail call i64 @_mi_os_numa_node_count_get() #37
-  br label %133
+129:                                              ; preds = %126
+  %130 = and i64 %120, 4294967295
+  %131 = load atomic i64, i64* @_mi_numa_node_count monotonic, align 8
+  %132 = icmp eq i64 %131, 0
+  br i1 %132, label %133, label %135, !prof !282, !misexpect !441
 
-133:                                              ; preds = %131, %127
-  %134 = phi i64 [ %132, %131 ], [ %129, %127 ]
-  %135 = urem i64 %128, %134
-  %136 = trunc i64 %135 to i32
-  br label %137
+133:                                              ; preds = %129
+  %134 = tail call i64 @_mi_os_numa_node_count_get() #37
+  br label %135
 
-137:                                              ; preds = %133, %124
-  %138 = phi i32 [ %136, %133 ], [ -1, %124 ]
-  %139 = shl i64 %122, 30
-  %140 = load atomic i64, i64* @mi_huge_start monotonic, align 64
-  br label %141
+135:                                              ; preds = %133, %129
+  %136 = phi i64 [ %134, %133 ], [ %131, %129 ]
+  %137 = urem i64 %130, %136
+  %138 = trunc i64 %137 to i32
+  br label %139
 
-141:                                              ; preds = %150, %137
-  %142 = phi i64 [ %140, %137 ], [ %155, %150 ]
-  %143 = icmp eq i64 %142, 0
-  br i1 %143, label %144, label %150
+139:                                              ; preds = %135, %126
+  %140 = phi i32 [ %138, %135 ], [ -1, %126 ]
+  %141 = shl i64 %124, 30
+  %142 = load atomic i64, i64* @mi_huge_start monotonic, align 64
+  br label %143
 
-144:                                              ; preds = %141
-  %145 = load %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !434
-  %146 = call fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* %145) #37
-  %147 = shl i64 %146, 13
-  %148 = and i64 %147, 4396972769280
-  %149 = or i64 %148, 35184372088832
-  br label %150
+143:                                              ; preds = %152, %139
+  %144 = phi i64 [ %142, %139 ], [ %157, %152 ]
+  %145 = icmp eq i64 %144, 0
+  br i1 %145, label %146, label %152
 
-150:                                              ; preds = %144, %141
-  %151 = phi i64 [ %149, %144 ], [ %142, %141 ]
-  %152 = add i64 %151, %139
-  %153 = cmpxchg i64* @mi_huge_start, i64 %142, i64 %152 acq_rel acquire, align 8
-  %154 = extractvalue { i64, i1 } %153, 1
-  %155 = extractvalue { i64, i1 } %153, 0
-  br i1 %154, label %156, label %141
+146:                                              ; preds = %143
+  %147 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default unordered, align 8, !tbaa !438
+  %148 = call fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* %147) #37
+  %149 = shl i64 %148, 13
+  %150 = and i64 %149, 4396972769280
+  %151 = or i64 %150, 35184372088832
+  br label %152
 
-156:                                              ; preds = %150
-  %157 = inttoptr i64 %151 to i8*
-  %158 = load i64, i64* @mi_clock_diff, align 8, !tbaa !453
-  %159 = icmp eq i64 %158, 0
-  br i1 %159, label %160, label %_mi_clock_start.exit.i.i.i
+152:                                              ; preds = %146, %143
+  %153 = phi i64 [ %151, %146 ], [ %144, %143 ]
+  %154 = add i64 %153, %141
+  %155 = cmpxchg i64* @mi_huge_start, i64 %144, i64 %154 acq_rel acquire, align 8
+  %156 = extractvalue { i64, i1 } %155, 1
+  %157 = extractvalue { i64, i1 } %155, 0
+  br i1 %156, label %158, label %143
 
-160:                                              ; preds = %156
-  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %98) #37
-  %161 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %9) #37
-  %162 = load i64, i64* %99, align 8, !tbaa !456
-  %163 = load i64, i64* %100, align 8, !tbaa !458
-  %164 = sdiv i64 %163, -1000000
-  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %98) #37
-  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %101) #37
-  %165 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %8) #37
-  %166 = load i64, i64* %102, align 8, !tbaa !456
-  %167 = load i64, i64* %103, align 8, !tbaa !458
-  %168 = sdiv i64 %167, 1000000
-  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %101) #37
-  %169 = sub i64 %166, %162
-  %170 = mul i64 %169, 1000
-  %171 = add nsw i64 %168, %164
-  %172 = add i64 %171, %170
-  store i64 %172, i64* @mi_clock_diff, align 8, !tbaa !453
+158:                                              ; preds = %152
+  %159 = inttoptr i64 %153 to i8*
+  %160 = load atomic i64, i64* @mi_clock_diff unordered, align 8, !tbaa !457
+  %161 = icmp eq i64 %160, 0
+  br i1 %161, label %162, label %_mi_clock_start.exit.i.i.i
+
+162:                                              ; preds = %158
+  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %100) #37
+  %163 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %9) #37
+  %164 = load atomic i64, i64* %101 unordered, align 8, !tbaa !460
+  %165 = load atomic i64, i64* %102 unordered, align 8, !tbaa !462
+  %166 = sdiv i64 %165, -1000000
+  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %100) #37
+  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %103) #37
+  %167 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %8) #37
+  %168 = load atomic i64, i64* %104 unordered, align 8, !tbaa !460
+  %169 = load atomic i64, i64* %105 unordered, align 8, !tbaa !462
+  %170 = sdiv i64 %169, 1000000
+  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %103) #37
+  %171 = sub i64 %168, %164
+  %172 = mul i64 %171, 1000
+  %173 = add nsw i64 %170, %166
+  %174 = add i64 %173, %172
+  store i64 %174, i64* @mi_clock_diff, align 8, !tbaa !457
   br label %_mi_clock_start.exit.i.i.i
 
-_mi_clock_start.exit.i.i.i:                       ; preds = %160, %156
-  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %104) #37
-  %173 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %7) #37
-  %174 = load i64, i64* %105, align 8, !tbaa !456
-  %175 = mul nsw i64 %174, 1000
-  %176 = load i64, i64* %106, align 8, !tbaa !458
-  %177 = sdiv i64 %176, 1000000
-  %178 = add nsw i64 %177, %175
-  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %104) #37
-  %179 = icmp ult i32 %138, 64
-  %180 = zext i32 %138 to i64
-  %181 = shl nuw i64 1, %180
-  br i1 %179, label %.preheader, label %.preheader8
+_mi_clock_start.exit.i.i.i:                       ; preds = %162, %158
+  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %106) #37
+  %175 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %7) #37
+  %176 = load atomic i64, i64* %107 unordered, align 8, !tbaa !460
+  %177 = mul nsw i64 %176, 1000
+  %178 = load atomic i64, i64* %108 unordered, align 8, !tbaa !462
+  %179 = sdiv i64 %178, 1000000
+  %180 = add nsw i64 %179, %177
+  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %106) #37
+  %181 = icmp ult i32 %140, 64
+  %182 = zext i32 %140 to i64
+  %183 = shl nuw i64 1, %182
+  br i1 %181, label %.preheader, label %.preheader12
 
-.preheader:                                       ; preds = %250, %_mi_clock_start.exit.i.i.i
-  %182 = phi i64 [ %251, %250 ], [ 0, %_mi_clock_start.exit.i.i.i ]
-  %183 = shl i64 %182, 30
-  %184 = getelementptr inbounds i8, i8* %157, i64 %183
-  %185 = load atomic i64, i64* @mi_unix_mmap.large_page_try_ok acquire, align 8
-  %186 = load i1, i1* @mi_unix_mmap.mi_huge_pages_available, align 1
-  %187 = select i1 %186, i32 1409548322, i32 2013528098
-  %188 = call i8* @mmap(i8* nonnull %184, i64 1073741824, i32 3, i32 %187, i32 -1, i64 0) #37
-  %189 = ptrtoint i8* %188 to i64
-  switch i64 %189, label %195 [
-    i64 -1, label %190
-    i64 0, label %190
+.preheader:                                       ; preds = %252, %_mi_clock_start.exit.i.i.i
+  %184 = phi i64 [ %253, %252 ], [ 0, %_mi_clock_start.exit.i.i.i ]
+  %185 = shl i64 %184, 30
+  %186 = getelementptr inbounds i8, i8* %159, i64 %185
+  %187 = load atomic i64, i64* @mi_unix_mmap.large_page_try_ok acquire, align 8
+  %188 = load i1, i1* @mi_unix_mmap.mi_huge_pages_available, align 1
+  %189 = select i1 %188, i32 1409548322, i32 2013528098
+  %190 = call i8* @mmap(i8* nonnull %186, i64 1073741824, i32 3, i32 %189, i32 -1, i64 0) #37
+  %191 = ptrtoint i8* %190 to i64
+  switch i64 %191, label %197 [
+    i64 -1, label %192
+    i64 0, label %192
   ]
 
-190:                                              ; preds = %.preheader, %.preheader
+192:                                              ; preds = %.preheader, %.preheader
   store i1 true, i1* @mi_unix_mmap.mi_huge_pages_available, align 1
-  %191 = tail call i32* @__errno_location() #1
-  %192 = load i32, i32* %191, align 4, !tbaa !459
-  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([83 x i8], [83 x i8]* @.str.5.71, i64 0, i64 0), i32 %192) #37
-  %193 = call i8* @mmap(i8* nonnull %184, i64 1073741824, i32 3, i32 1409548322, i32 -1, i64 0) #37
-  %194 = ptrtoint i8* %193 to i64
-  switch i64 %194, label %195 [
-    i64 -1, label %204
-    i64 0, label %204
+  %193 = tail call i32* @__errno_location() #1
+  %194 = load atomic i32, i32* %193 unordered, align 4, !tbaa !463
+  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([83 x i8], [83 x i8]* @.str.5.71, i64 0, i64 0), i32 %194) #37
+  %195 = call i8* @mmap(i8* nonnull %186, i64 1073741824, i32 3, i32 1409548322, i32 -1, i64 0) #37
+  %196 = ptrtoint i8* %195 to i64
+  switch i64 %196, label %197 [
+    i64 -1, label %206
+    i64 0, label %206
   ]
 
-195:                                              ; preds = %190, %.preheader
-  %196 = phi i8* [ %188, %.preheader ], [ %193, %190 ]
-  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %107) #37
-  store i64 %181, i64* %10, align 8, !tbaa !453
-  %197 = call i64 (i64, ...) @syscall(i64 237, i8* nonnull %196, i64 1073741824, i64 1, i64* nonnull %10, i64 64, i32 0) #37
-  %198 = icmp eq i64 %197, 0
-  br i1 %198, label %203, label %199
+197:                                              ; preds = %192, %.preheader
+  %198 = phi i8* [ %190, %.preheader ], [ %195, %192 ]
+  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %109) #37
+  store i64 %183, i64* %10, align 8, !tbaa !457
+  %199 = call i64 (i64, ...) @syscall(i64 237, i8* nonnull %198, i64 1073741824, i64 1, i64* nonnull %10, i64 64, i32 0) #37
+  %200 = icmp eq i64 %199, 0
+  br i1 %200, label %205, label %201
 
-199:                                              ; preds = %195
-  %200 = tail call i32* @__errno_location() #1
-  %201 = load i32, i32* %200, align 4, !tbaa !459
-  %202 = call i8* @strerror(i32 %201) #37
-  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @.str.13.77, i64 0, i64 0), i32 %138, i8* %202) #37
-  br label %203
+201:                                              ; preds = %197
+  %202 = tail call i32* @__errno_location() #1
+  %203 = load atomic i32, i32* %202 unordered, align 4, !tbaa !463
+  %204 = call i8* @strerror(i32 %203) #37
+  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([53 x i8], [53 x i8]* @.str.13.77, i64 0, i64 0), i32 %140, i8* %204) #37
+  br label %205
 
-203:                                              ; preds = %199, %195
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %107) #37
-  br label %204
+205:                                              ; preds = %201, %197
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %109) #37
+  br label %206
 
-204:                                              ; preds = %203, %190, %190
-  %205 = phi i8* [ %196, %203 ], [ null, %190 ], [ null, %190 ]
-  %206 = icmp eq i8* %205, %184
-  br i1 %206, label %207, label %.loopexit
+206:                                              ; preds = %205, %192, %192
+  %207 = phi i8* [ %198, %205 ], [ null, %192 ], [ null, %192 ]
+  %208 = icmp eq i8* %207, %186
+  br i1 %208, label %209, label %.loopexit
 
-207:                                              ; preds = %204
-  %208 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 3), i64 1073741824 monotonic, align 8
-  %209 = add nsw i64 %208, 1073741824
-  %210 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2) monotonic, align 16
-  br label %211
+209:                                              ; preds = %206
+  %210 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 3), i64 1073741824 monotonic, align 8
+  %211 = add nsw i64 %210, 1073741824
+  %212 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2) monotonic, align 16
+  br label %213
 
-211:                                              ; preds = %214, %207
-  %212 = phi i64 [ %210, %207 ], [ %217, %214 ]
-  %213 = icmp slt i64 %212, %209
-  br i1 %213, label %214, label %_mi_stat_increase.exit.i.i.i
+213:                                              ; preds = %216, %209
+  %214 = phi i64 [ %212, %209 ], [ %219, %216 ]
+  %215 = icmp slt i64 %214, %211
+  br i1 %215, label %216, label %_mi_stat_increase.exit.i.i.i
 
-214:                                              ; preds = %211
-  %215 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2), i64 %212, i64 %209 release monotonic, align 8
-  %216 = extractvalue { i64, i1 } %215, 1
-  %217 = extractvalue { i64, i1 } %215, 0
-  br i1 %216, label %_mi_stat_increase.exit.i.i.i, label %211
+216:                                              ; preds = %213
+  %217 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2), i64 %214, i64 %211 release monotonic, align 8
+  %218 = extractvalue { i64, i1 } %217, 1
+  %219 = extractvalue { i64, i1 } %217, 0
+  br i1 %218, label %_mi_stat_increase.exit.i.i.i, label %213
 
-_mi_stat_increase.exit.i.i.i:                     ; preds = %214, %211
-  %218 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 0), i64 1073741824 monotonic, align 8
-  %219 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 3), i64 1073741824 monotonic, align 8
-  %220 = add nsw i64 %219, 1073741824
-  %221 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2) monotonic, align 16
-  br label %222
+_mi_stat_increase.exit.i.i.i:                     ; preds = %216, %213
+  %220 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 0), i64 1073741824 monotonic, align 8
+  %221 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 3), i64 1073741824 monotonic, align 8
+  %222 = add nsw i64 %221, 1073741824
+  %223 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2) monotonic, align 16
+  br label %224
 
-222:                                              ; preds = %225, %_mi_stat_increase.exit.i.i.i
-  %223 = phi i64 [ %221, %_mi_stat_increase.exit.i.i.i ], [ %228, %225 ]
-  %224 = icmp slt i64 %223, %220
-  br i1 %224, label %225, label %_mi_stat_increase.exit16.i.i.i
+224:                                              ; preds = %227, %_mi_stat_increase.exit.i.i.i
+  %225 = phi i64 [ %223, %_mi_stat_increase.exit.i.i.i ], [ %230, %227 ]
+  %226 = icmp slt i64 %225, %222
+  br i1 %226, label %227, label %_mi_stat_increase.exit16.i.i.i
 
-225:                                              ; preds = %222
-  %226 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2), i64 %223, i64 %220 release monotonic, align 8
-  %227 = extractvalue { i64, i1 } %226, 1
-  %228 = extractvalue { i64, i1 } %226, 0
-  br i1 %227, label %_mi_stat_increase.exit16.i.i.i, label %222
+227:                                              ; preds = %224
+  %228 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2), i64 %225, i64 %222 release monotonic, align 8
+  %229 = extractvalue { i64, i1 } %228, 1
+  %230 = extractvalue { i64, i1 } %228, 0
+  br i1 %229, label %_mi_stat_increase.exit16.i.i.i, label %224
 
-_mi_stat_increase.exit16.i.i.i:                   ; preds = %225, %222
-  %229 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 0), i64 1073741824 monotonic, align 8
-  br i1 %108, label %230, label %250
+_mi_stat_increase.exit16.i.i.i:                   ; preds = %227, %224
+  %231 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 0), i64 1073741824 monotonic, align 8
+  br i1 %110, label %232, label %252
 
-230:                                              ; preds = %_mi_stat_increase.exit16.i.i.i
-  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %114) #37
-  %231 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %6) #37
-  %232 = load i64, i64* %115, align 8, !tbaa !456
-  %233 = mul nsw i64 %232, 1000
-  %234 = load i64, i64* %116, align 8, !tbaa !458
-  %235 = sdiv i64 %234, 1000000
-  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %114) #37
-  %236 = load i64, i64* @mi_clock_diff, align 8, !tbaa !453
-  %237 = add i64 %233, %235
-  %238 = add i64 %236, %178
-  %239 = sub i64 %237, %238
-  %240 = icmp eq i64 %182, 0
-  br i1 %240, label %247, label %241
+232:                                              ; preds = %_mi_stat_increase.exit16.i.i.i
+  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %116) #37
+  %233 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %6) #37
+  %234 = load atomic i64, i64* %117 unordered, align 8, !tbaa !460
+  %235 = mul nsw i64 %234, 1000
+  %236 = load atomic i64, i64* %118 unordered, align 8, !tbaa !462
+  %237 = sdiv i64 %236, 1000000
+  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %116) #37
+  %238 = load atomic i64, i64* @mi_clock_diff unordered, align 8, !tbaa !457
+  %239 = add i64 %235, %237
+  %240 = add i64 %238, %180
+  %241 = sub i64 %239, %240
+  %242 = icmp eq i64 %184, 0
+  br i1 %242, label %249, label %243
 
-241:                                              ; preds = %230
-  %242 = add nuw i64 %182, 1
-  %243 = udiv i64 %239, %242
-  %244 = mul i64 %243, %122
-  %245 = icmp sgt i64 %244, %109
-  %246 = select i1 %245, i64 %110, i64 %239
-  br label %247
+243:                                              ; preds = %232
+  %244 = add nuw i64 %184, 1
+  %245 = udiv i64 %241, %244
+  %246 = mul i64 %245, %124
+  %247 = icmp sgt i64 %246, %111
+  %248 = select i1 %247, i64 %112, i64 %241
+  br label %249
 
-247:                                              ; preds = %241, %230
-  %248 = phi i64 [ %246, %241 ], [ %239, %230 ]
-  %249 = icmp sgt i64 %248, %97
-  br i1 %249, label %.loopexit7, label %250
+249:                                              ; preds = %243, %232
+  %250 = phi i64 [ %248, %243 ], [ %241, %232 ]
+  %251 = icmp sgt i64 %250, %99
+  br i1 %251, label %.loopexit11, label %252
 
-250:                                              ; preds = %247, %_mi_stat_increase.exit16.i.i.i
-  %251 = add nuw i64 %182, 1
-  %252 = icmp eq i64 %251, %122
-  br i1 %252, label %_mi_os_alloc_huge_os_pages.exit.i.i, label %.preheader
+252:                                              ; preds = %249, %_mi_stat_increase.exit16.i.i.i
+  %253 = add nuw i64 %184, 1
+  %254 = icmp eq i64 %253, %124
+  br i1 %254, label %_mi_os_alloc_huge_os_pages.exit.i.i, label %.preheader
 
-.preheader8:                                      ; preds = %349, %_mi_clock_start.exit.i.i.i
-  %253 = phi i64 [ %350, %349 ], [ 0, %_mi_clock_start.exit.i.i.i ]
-  %254 = shl i64 %253, 30
-  %255 = getelementptr inbounds i8, i8* %157, i64 %254
-  %256 = load atomic i64, i64* @mi_unix_mmap.large_page_try_ok acquire, align 8
-  %257 = load i1, i1* @mi_unix_mmap.mi_huge_pages_available, align 1
-  %258 = select i1 %257, i32 1409548322, i32 2013528098
-  %259 = call i8* @mmap(i8* nonnull %255, i64 1073741824, i32 3, i32 %258, i32 -1, i64 0) #37
-  %260 = ptrtoint i8* %259 to i64
-  switch i64 %260, label %266 [
-    i64 -1, label %261
-    i64 0, label %261
+.preheader12:                                     ; preds = %351, %_mi_clock_start.exit.i.i.i
+  %255 = phi i64 [ %352, %351 ], [ 0, %_mi_clock_start.exit.i.i.i ]
+  %256 = shl i64 %255, 30
+  %257 = getelementptr inbounds i8, i8* %159, i64 %256
+  %258 = load atomic i64, i64* @mi_unix_mmap.large_page_try_ok acquire, align 8
+  %259 = load i1, i1* @mi_unix_mmap.mi_huge_pages_available, align 1
+  %260 = select i1 %259, i32 1409548322, i32 2013528098
+  %261 = call i8* @mmap(i8* nonnull %257, i64 1073741824, i32 3, i32 %260, i32 -1, i64 0) #37
+  %262 = ptrtoint i8* %261 to i64
+  switch i64 %262, label %268 [
+    i64 -1, label %263
+    i64 0, label %263
   ]
 
-261:                                              ; preds = %.preheader8, %.preheader8
+263:                                              ; preds = %.preheader12, %.preheader12
   store i1 true, i1* @mi_unix_mmap.mi_huge_pages_available, align 1
-  %262 = tail call i32* @__errno_location() #1
-  %263 = load i32, i32* %262, align 4, !tbaa !459
-  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([83 x i8], [83 x i8]* @.str.5.71, i64 0, i64 0), i32 %263) #37
-  %264 = call i8* @mmap(i8* nonnull %255, i64 1073741824, i32 3, i32 1409548322, i32 -1, i64 0) #37
-  %265 = ptrtoint i8* %264 to i64
-  switch i64 %265, label %266 [
-    i64 -1, label %268
-    i64 0, label %268
+  %264 = tail call i32* @__errno_location() #1
+  %265 = load atomic i32, i32* %264 unordered, align 4, !tbaa !463
+  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([83 x i8], [83 x i8]* @.str.5.71, i64 0, i64 0), i32 %265) #37
+  %266 = call i8* @mmap(i8* nonnull %257, i64 1073741824, i32 3, i32 1409548322, i32 -1, i64 0) #37
+  %267 = ptrtoint i8* %266 to i64
+  switch i64 %267, label %268 [
+    i64 -1, label %270
+    i64 0, label %270
   ]
 
-266:                                              ; preds = %261, %.preheader8
-  %267 = phi i8* [ %259, %.preheader8 ], [ %264, %261 ]
-  br label %268
+268:                                              ; preds = %263, %.preheader12
+  %269 = phi i8* [ %261, %.preheader12 ], [ %266, %263 ]
+  br label %270
 
-268:                                              ; preds = %266, %261, %261
-  %269 = phi i8* [ %267, %266 ], [ null, %261 ], [ null, %261 ]
-  %270 = icmp eq i8* %269, %255
-  br i1 %270, label %305, label %.loopexit
+270:                                              ; preds = %268, %263, %263
+  %271 = phi i8* [ %269, %268 ], [ null, %263 ], [ null, %263 ]
+  %272 = icmp eq i8* %271, %257
+  br i1 %272, label %307, label %.loopexit
 
-.loopexit:                                        ; preds = %268, %204
-  %271 = phi i8* [ %205, %204 ], [ %269, %268 ]
-  %272 = phi i8* [ %184, %204 ], [ %255, %268 ]
-  %273 = phi i64 [ %182, %204 ], [ %253, %268 ]
-  %274 = icmp eq i8* %271, null
-  br i1 %274, label %_mi_os_alloc_huge_os_pages.exit.i.i, label %275
+.loopexit:                                        ; preds = %270, %206
+  %273 = phi i8* [ %207, %206 ], [ %271, %270 ]
+  %274 = phi i8* [ %186, %206 ], [ %257, %270 ]
+  %275 = phi i64 [ %184, %206 ], [ %255, %270 ]
+  %276 = icmp eq i8* %273, null
+  br i1 %276, label %_mi_os_alloc_huge_os_pages.exit.i.i, label %277
 
-275:                                              ; preds = %.loopexit
-  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([51 x i8], [51 x i8]* @.str.78.468, i64 0, i64 0), i64 %273, i8* nonnull %272) #37
-  %276 = call i32 @munmap(i8* nonnull %271, i64 1073741824) #37
-  %277 = icmp eq i32 %276, -1
-  %278 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 3), i64 -1073741824 monotonic, align 8
-  %279 = add i64 %278, -1073741824
-  %280 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2) monotonic, align 16
-  br label %281
+277:                                              ; preds = %.loopexit
+  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([51 x i8], [51 x i8]* @.str.78.468, i64 0, i64 0), i64 %275, i8* nonnull %274) #37
+  %278 = call i32 @munmap(i8* nonnull %273, i64 1073741824) #37
+  %279 = icmp eq i32 %278, -1
+  %280 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 3), i64 -1073741824 monotonic, align 8
+  %281 = add i64 %280, -1073741824
+  %282 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2) monotonic, align 16
+  br label %283
 
-281:                                              ; preds = %284, %275
-  %282 = phi i64 [ %280, %275 ], [ %287, %284 ]
-  %283 = icmp slt i64 %282, %279
-  br i1 %283, label %284, label %_mi_stat_decrease.exit.i.i.i
+283:                                              ; preds = %286, %277
+  %284 = phi i64 [ %282, %277 ], [ %289, %286 ]
+  %285 = icmp slt i64 %284, %281
+  br i1 %285, label %286, label %_mi_stat_decrease.exit.i.i.i
 
-284:                                              ; preds = %281
-  %285 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2), i64 %282, i64 %279 release monotonic, align 8
-  %286 = extractvalue { i64, i1 } %285, 1
-  %287 = extractvalue { i64, i1 } %285, 0
-  br i1 %286, label %_mi_stat_decrease.exit.i.i.i, label %281
+286:                                              ; preds = %283
+  %287 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2), i64 %284, i64 %281 release monotonic, align 8
+  %288 = extractvalue { i64, i1 } %287, 1
+  %289 = extractvalue { i64, i1 } %287, 0
+  br i1 %288, label %_mi_stat_decrease.exit.i.i.i, label %283
 
-_mi_stat_decrease.exit.i.i.i:                     ; preds = %284, %281
-  %288 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 1), i64 1073741824 monotonic, align 8
-  %289 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 3), i64 -1073741824 monotonic, align 8
-  %290 = add i64 %289, -1073741824
-  %291 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2) monotonic, align 16
-  br label %292
+_mi_stat_decrease.exit.i.i.i:                     ; preds = %286, %283
+  %290 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 1), i64 1073741824 monotonic, align 8
+  %291 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 3), i64 -1073741824 monotonic, align 8
+  %292 = add i64 %291, -1073741824
+  %293 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2) monotonic, align 16
+  br label %294
 
-292:                                              ; preds = %295, %_mi_stat_decrease.exit.i.i.i
-  %293 = phi i64 [ %291, %_mi_stat_decrease.exit.i.i.i ], [ %298, %295 ]
-  %294 = icmp slt i64 %293, %290
-  br i1 %294, label %295, label %_mi_stat_decrease.exit17.i.i.i
+294:                                              ; preds = %297, %_mi_stat_decrease.exit.i.i.i
+  %295 = phi i64 [ %293, %_mi_stat_decrease.exit.i.i.i ], [ %300, %297 ]
+  %296 = icmp slt i64 %295, %292
+  br i1 %296, label %297, label %_mi_stat_decrease.exit17.i.i.i
 
-295:                                              ; preds = %292
-  %296 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2), i64 %293, i64 %290 release monotonic, align 8
-  %297 = extractvalue { i64, i1 } %296, 1
-  %298 = extractvalue { i64, i1 } %296, 0
-  br i1 %297, label %_mi_stat_decrease.exit17.i.i.i, label %292
+297:                                              ; preds = %294
+  %298 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2), i64 %295, i64 %292 release monotonic, align 8
+  %299 = extractvalue { i64, i1 } %298, 1
+  %300 = extractvalue { i64, i1 } %298, 0
+  br i1 %299, label %_mi_stat_decrease.exit17.i.i.i, label %294
 
-_mi_stat_decrease.exit17.i.i.i:                   ; preds = %295, %292
-  %299 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 1), i64 1073741824 monotonic, align 8
-  br i1 %277, label %300, label %_mi_os_alloc_huge_os_pages.exit.i.i
+_mi_stat_decrease.exit17.i.i.i:                   ; preds = %297, %294
+  %301 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 1), i64 1073741824 monotonic, align 8
+  br i1 %279, label %302, label %_mi_os_alloc_huge_os_pages.exit.i.i
 
-300:                                              ; preds = %_mi_stat_decrease.exit17.i.i.i
-  %301 = tail call i32* @__errno_location() #1
-  %302 = load i32, i32* %301, align 4, !tbaa !459
-  %303 = call i8* @strerror(i32 %302) #37
-  %304 = ptrtoint i8* %271 to i64
-  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.7.68, i64 0, i64 0), i8* %303, i64 %304, i64 1073741824) #37
+302:                                              ; preds = %_mi_stat_decrease.exit17.i.i.i
+  %303 = tail call i32* @__errno_location() #1
+  %304 = load atomic i32, i32* %303 unordered, align 4, !tbaa !463
+  %305 = call i8* @strerror(i32 %304) #37
+  %306 = ptrtoint i8* %273 to i64
+  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.7.68, i64 0, i64 0), i8* %305, i64 %306, i64 1073741824) #37
   br label %_mi_os_alloc_huge_os_pages.exit.i.i
 
-305:                                              ; preds = %268
-  %306 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 3), i64 1073741824 monotonic, align 8
-  %307 = add nsw i64 %306, 1073741824
-  %308 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2) monotonic, align 16
-  br label %309
+307:                                              ; preds = %270
+  %308 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 3), i64 1073741824 monotonic, align 8
+  %309 = add nsw i64 %308, 1073741824
+  %310 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2) monotonic, align 16
+  br label %311
 
-309:                                              ; preds = %312, %305
-  %310 = phi i64 [ %308, %305 ], [ %315, %312 ]
-  %311 = icmp slt i64 %310, %307
-  br i1 %311, label %312, label %_mi_stat_increase.exit18.i.i.i
+311:                                              ; preds = %314, %307
+  %312 = phi i64 [ %310, %307 ], [ %317, %314 ]
+  %313 = icmp slt i64 %312, %309
+  br i1 %313, label %314, label %_mi_stat_increase.exit18.i.i.i
 
-312:                                              ; preds = %309
-  %313 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2), i64 %310, i64 %307 release monotonic, align 8
-  %314 = extractvalue { i64, i1 } %313, 1
-  %315 = extractvalue { i64, i1 } %313, 0
-  br i1 %314, label %_mi_stat_increase.exit18.i.i.i, label %309
+314:                                              ; preds = %311
+  %315 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2), i64 %312, i64 %309 release monotonic, align 8
+  %316 = extractvalue { i64, i1 } %315, 1
+  %317 = extractvalue { i64, i1 } %315, 0
+  br i1 %316, label %_mi_stat_increase.exit18.i.i.i, label %311
 
-_mi_stat_increase.exit18.i.i.i:                   ; preds = %312, %309
-  %316 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 0), i64 1073741824 monotonic, align 8
-  %317 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 3), i64 1073741824 monotonic, align 8
-  %318 = add nsw i64 %317, 1073741824
-  %319 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2) monotonic, align 16
-  br label %320
+_mi_stat_increase.exit18.i.i.i:                   ; preds = %314, %311
+  %318 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 0), i64 1073741824 monotonic, align 8
+  %319 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 3), i64 1073741824 monotonic, align 8
+  %320 = add nsw i64 %319, 1073741824
+  %321 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2) monotonic, align 16
+  br label %322
 
-320:                                              ; preds = %323, %_mi_stat_increase.exit18.i.i.i
-  %321 = phi i64 [ %319, %_mi_stat_increase.exit18.i.i.i ], [ %326, %323 ]
-  %322 = icmp slt i64 %321, %318
-  br i1 %322, label %323, label %_mi_stat_increase.exit19.i.i.i
+322:                                              ; preds = %325, %_mi_stat_increase.exit18.i.i.i
+  %323 = phi i64 [ %321, %_mi_stat_increase.exit18.i.i.i ], [ %328, %325 ]
+  %324 = icmp slt i64 %323, %320
+  br i1 %324, label %325, label %_mi_stat_increase.exit19.i.i.i
 
-323:                                              ; preds = %320
-  %324 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2), i64 %321, i64 %318 release monotonic, align 8
-  %325 = extractvalue { i64, i1 } %324, 1
-  %326 = extractvalue { i64, i1 } %324, 0
-  br i1 %325, label %_mi_stat_increase.exit19.i.i.i, label %320
+325:                                              ; preds = %322
+  %326 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2), i64 %323, i64 %320 release monotonic, align 8
+  %327 = extractvalue { i64, i1 } %326, 1
+  %328 = extractvalue { i64, i1 } %326, 0
+  br i1 %327, label %_mi_stat_increase.exit19.i.i.i, label %322
 
-_mi_stat_increase.exit19.i.i.i:                   ; preds = %323, %320
-  %327 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 0), i64 1073741824 monotonic, align 8
-  br i1 %108, label %328, label %349
+_mi_stat_increase.exit19.i.i.i:                   ; preds = %325, %322
+  %329 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 0), i64 1073741824 monotonic, align 8
+  br i1 %110, label %330, label %351
 
-328:                                              ; preds = %_mi_stat_increase.exit19.i.i.i
-  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %111) #37
-  %329 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %5) #37
-  %330 = load i64, i64* %112, align 8, !tbaa !456
-  %331 = mul nsw i64 %330, 1000
-  %332 = load i64, i64* %113, align 8, !tbaa !458
-  %333 = sdiv i64 %332, 1000000
-  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %111) #37
-  %334 = load i64, i64* @mi_clock_diff, align 8, !tbaa !453
-  %335 = add i64 %331, %333
-  %336 = add i64 %334, %178
-  %337 = sub i64 %335, %336
-  %338 = icmp eq i64 %253, 0
-  br i1 %338, label %345, label %339
+330:                                              ; preds = %_mi_stat_increase.exit19.i.i.i
+  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %113) #37
+  %331 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %5) #37
+  %332 = load atomic i64, i64* %114 unordered, align 8, !tbaa !460
+  %333 = mul nsw i64 %332, 1000
+  %334 = load atomic i64, i64* %115 unordered, align 8, !tbaa !462
+  %335 = sdiv i64 %334, 1000000
+  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %113) #37
+  %336 = load atomic i64, i64* @mi_clock_diff unordered, align 8, !tbaa !457
+  %337 = add i64 %333, %335
+  %338 = add i64 %336, %180
+  %339 = sub i64 %337, %338
+  %340 = icmp eq i64 %255, 0
+  br i1 %340, label %347, label %341
 
-339:                                              ; preds = %328
-  %340 = add nuw i64 %253, 1
-  %341 = udiv i64 %337, %340
-  %342 = mul i64 %341, %122
-  %343 = icmp sgt i64 %342, %109
-  %344 = select i1 %343, i64 %110, i64 %337
-  br label %345
+341:                                              ; preds = %330
+  %342 = add nuw i64 %255, 1
+  %343 = udiv i64 %339, %342
+  %344 = mul i64 %343, %124
+  %345 = icmp sgt i64 %344, %111
+  %346 = select i1 %345, i64 %112, i64 %339
+  br label %347
 
-345:                                              ; preds = %339, %328
-  %346 = phi i64 [ %344, %339 ], [ %337, %328 ]
-  %347 = icmp sgt i64 %346, %97
-  br i1 %347, label %.loopexit7, label %349
+347:                                              ; preds = %341, %330
+  %348 = phi i64 [ %346, %341 ], [ %339, %330 ]
+  %349 = icmp sgt i64 %348, %99
+  br i1 %349, label %.loopexit11, label %351
 
-.loopexit7:                                       ; preds = %345, %247
-  %348 = phi i64 [ %182, %247 ], [ %253, %345 ]
+.loopexit11:                                      ; preds = %347, %249
+  %350 = phi i64 [ %184, %249 ], [ %255, %347 ]
   call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.1.79, i64 0, i64 0)) #37
   br label %_mi_os_alloc_huge_os_pages.exit.i.i
 
-349:                                              ; preds = %345, %_mi_stat_increase.exit19.i.i.i
-  %350 = add nuw i64 %253, 1
-  %351 = icmp eq i64 %350, %122
-  br i1 %351, label %_mi_os_alloc_huge_os_pages.exit.i.i, label %.preheader8
+351:                                              ; preds = %347, %_mi_stat_increase.exit19.i.i.i
+  %352 = add nuw i64 %255, 1
+  %353 = icmp eq i64 %352, %124
+  br i1 %353, label %_mi_os_alloc_huge_os_pages.exit.i.i, label %.preheader12
 
-_mi_os_alloc_huge_os_pages.exit.i.i:              ; preds = %349, %.loopexit7, %300, %_mi_stat_decrease.exit17.i.i.i, %.loopexit, %250
-  %352 = phi i64 [ %273, %300 ], [ %273, %_mi_stat_decrease.exit17.i.i.i ], [ %273, %.loopexit ], [ %348, %.loopexit7 ], [ %122, %250 ], [ %122, %349 ]
-  %353 = icmp eq i64 %352, 0
-  %354 = select i1 %353, i8* null, i8* %157
-  %355 = icmp eq i8* %354, null
-  %356 = or i1 %355, %353
-  br i1 %356, label %357, label %358
+_mi_os_alloc_huge_os_pages.exit.i.i:              ; preds = %351, %.loopexit11, %302, %_mi_stat_decrease.exit17.i.i.i, %.loopexit, %252
+  %354 = phi i64 [ %275, %302 ], [ %275, %_mi_stat_decrease.exit17.i.i.i ], [ %275, %.loopexit ], [ %350, %.loopexit11 ], [ %124, %252 ], [ %124, %351 ]
+  %355 = icmp eq i64 %354, 0
+  %356 = select i1 %355, i8* null, i8* %159
+  %357 = icmp eq i8* %356, null
+  %358 = or i1 %357, %355
+  br i1 %358, label %359, label %360
 
-357:                                              ; preds = %_mi_os_alloc_huge_os_pages.exit.i.i
-  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.7.172, i64 0, i64 0), i64 %122) #37
+359:                                              ; preds = %_mi_os_alloc_huge_os_pages.exit.i.i
+  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([37 x i8], [37 x i8]* @.str.7.172, i64 0, i64 0), i64 %124) #37
   br label %mi_reserve_huge_os_pages_interleave.exit
 
-358:                                              ; preds = %_mi_os_alloc_huge_os_pages.exit.i.i
-  %359 = shl i64 %352, 30
-  call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([68 x i8], [68 x i8]* @.str.8.173, i64 0, i64 0), i32 %138, i64 %352, i64 %122) #37
-  %360 = shl i64 %352, 6
-  %361 = and i64 %360, 1099511627712
-  %362 = lshr exact i64 %361, 6
-  %363 = lshr exact i64 %361, 2
-  %364 = add nuw nsw i64 %363, 64
-  %365 = call fastcc i8* @_mi_os_alloc(i64 %364) #37
-  %366 = icmp eq i8* %365, null
-  br i1 %366, label %396, label %367
+360:                                              ; preds = %_mi_os_alloc_huge_os_pages.exit.i.i
+  %361 = shl i64 %354, 30
+  call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([68 x i8], [68 x i8]* @.str.8.173, i64 0, i64 0), i32 %140, i64 %354, i64 %124) #37
+  %362 = shl i64 %354, 6
+  %363 = and i64 %362, 1099511627712
+  %364 = lshr exact i64 %363, 6
+  %365 = lshr exact i64 %363, 2
+  %366 = add nuw nsw i64 %365, 64
+  %367 = call fastcc i8* @_mi_os_alloc(i64 %366) #37
+  %368 = icmp eq i8* %367, null
+  br i1 %368, label %398, label %369
 
-367:                                              ; preds = %358
-  %368 = getelementptr inbounds i8, i8* %365, i64 8
-  %369 = bitcast i8* %368 to i64*
-  store i64 %361, i64* %369, align 8, !tbaa !470
-  %370 = getelementptr inbounds i8, i8* %365, i64 16
+369:                                              ; preds = %360
+  %370 = getelementptr inbounds i8, i8* %367, i64 8
   %371 = bitcast i8* %370 to i64*
-  store i64 %362, i64* %371, align 8, !tbaa !472
-  %372 = ptrtoint i8* %354 to i64
-  %373 = bitcast i8* %365 to i64*
-  store atomic i64 %372, i64* %373 seq_cst, align 8, !tbaa !473
-  %374 = getelementptr inbounds i8, i8* %365, i64 24
-  %375 = bitcast i8* %374 to i32*
-  store i32 %138, i32* %375, align 8, !tbaa !474
-  %376 = getelementptr inbounds i8, i8* %365, i64 30
-  store i8 1, i8* %376, align 2, !tbaa !475
-  %377 = getelementptr inbounds i8, i8* %365, i64 28
-  store i8 1, i8* %377, align 4, !tbaa !476
-  %378 = getelementptr inbounds i8, i8* %365, i64 29
-  store i8 1, i8* %378, align 1, !tbaa !477
-  %379 = getelementptr inbounds i8, i8* %365, i64 32
-  %380 = bitcast i8* %379 to i64*
-  store atomic i64 0, i64* %380 seq_cst, align 8, !tbaa !478
-  %381 = getelementptr inbounds i8, i8* %365, i64 56
-  %382 = bitcast i8* %381 to [1 x i64]*
-  %383 = getelementptr inbounds [1 x i64], [1 x i64]* %382, i64 0, i64 %362
-  %384 = getelementptr inbounds i8, i8* %365, i64 40
-  %385 = bitcast i8* %384 to i64**
-  store i64* %383, i64** %385, align 8, !tbaa !479
-  %386 = getelementptr inbounds i8, i8* %365, i64 48
+  store i64 %363, i64* %371, align 8, !tbaa !475
+  %372 = getelementptr inbounds i8, i8* %367, i64 16
+  %373 = bitcast i8* %372 to i64*
+  store i64 %364, i64* %373, align 8, !tbaa !477
+  %374 = ptrtoint i8* %356 to i64
+  %375 = bitcast i8* %367 to i64*
+  store atomic i64 %374, i64* %375 seq_cst, align 8, !tbaa !478
+  %376 = getelementptr inbounds i8, i8* %367, i64 24
+  %377 = bitcast i8* %376 to i32*
+  store i32 %140, i32* %377, align 8, !tbaa !479
+  %378 = getelementptr inbounds i8, i8* %367, i64 30
+  store i8 1, i8* %378, align 2, !tbaa !480
+  %379 = getelementptr inbounds i8, i8* %367, i64 28
+  store i8 1, i8* %379, align 4, !tbaa !481
+  %380 = getelementptr inbounds i8, i8* %367, i64 29
+  store i8 1, i8* %380, align 1, !tbaa !482
+  %381 = getelementptr inbounds i8, i8* %367, i64 32
+  %382 = bitcast i8* %381 to i64*
+  store atomic i64 0, i64* %382 seq_cst, align 8, !tbaa !483
+  %383 = getelementptr inbounds i8, i8* %367, i64 56
+  %384 = bitcast i8* %383 to [1 x i64]*
+  %385 = getelementptr inbounds [1 x i64], [1 x i64]* %384, i64 0, i64 %364
+  %386 = getelementptr inbounds i8, i8* %367, i64 40
   %387 = bitcast i8* %386 to i64**
-  store i64* null, i64** %387, align 8, !tbaa !480
-  %388 = atomicrmw add i64* @mi_arena_count, i64 1 acq_rel, align 8
-  %389 = icmp ugt i64 %388, 63
-  br i1 %389, label %390, label %392
+  store i64* %385, i64** %387, align 8, !tbaa !484
+  %388 = getelementptr inbounds i8, i8* %367, i64 48
+  %389 = bitcast i8* %388 to i64**
+  store i64* null, i64** %389, align 8, !tbaa !485
+  %390 = atomicrmw add i64* @mi_arena_count, i64 1 acq_rel, align 8
+  %391 = icmp ugt i64 %390, 63
+  br i1 %391, label %392, label %394
 
-390:                                              ; preds = %367
-  %391 = atomicrmw sub i64* @mi_arena_count, i64 1 acq_rel, align 8
+392:                                              ; preds = %369
+  %393 = atomicrmw sub i64* @mi_arena_count, i64 1 acq_rel, align 8
   br label %mi_reserve_huge_os_pages_at.exit.i.thread
 
-392:                                              ; preds = %367
-  %393 = getelementptr inbounds [64 x %struct.mi_arena_s*], [64 x %struct.mi_arena_s*]* @mi_arenas, i64 0, i64 %388
-  %394 = ptrtoint i8* %365 to i64
-  %395 = bitcast %struct.mi_arena_s** %393 to i64*
-  store atomic i64 %394, i64* %395 release, align 8
+394:                                              ; preds = %369
+  %395 = getelementptr inbounds [64 x %struct.mi_arena_s*], [64 x %struct.mi_arena_s*]* @mi_arenas, i64 0, i64 %390
+  %396 = ptrtoint i8* %367 to i64
+  %397 = bitcast %struct.mi_arena_s** %395 to i64*
+  store atomic i64 %396, i64* %397 release, align 8
   br label %mi_reserve_huge_os_pages_at.exit.i.thread
 
-396:                                              ; preds = %358
-  %.not62 = icmp eq i64 %359, 0
-  br i1 %.not62, label %mi_reserve_huge_os_pages_interleave.exit, label %397
-
-397:                                              ; preds = %396
-  %398 = ptrtoint i8* %354 to i64
-  br label %399
+398:                                              ; preds = %360
+  %.not66 = icmp eq i64 %361, 0
+  br i1 %.not66, label %mi_reserve_huge_os_pages_interleave.exit, label %399
 
-399:                                              ; preds = %429, %397
-  %400 = phi i64 [ %430, %429 ], [ %359, %397 ]
-  %401 = call i32 @munmap(i8* nonnull %354, i64 1073741824) #37
-  %402 = icmp eq i32 %401, -1
-  %403 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 3), i64 -1073741824 monotonic, align 8
-  %404 = add i64 %403, -1073741824
-  %405 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2) monotonic, align 16
-  br label %406
+399:                                              ; preds = %398
+  %400 = ptrtoint i8* %356 to i64
+  br label %401
 
-406:                                              ; preds = %409, %399
-  %407 = phi i64 [ %405, %399 ], [ %412, %409 ]
-  %408 = icmp slt i64 %407, %404
-  br i1 %408, label %409, label %_mi_stat_decrease.exit.i8.i.i
+401:                                              ; preds = %431, %399
+  %402 = phi i64 [ %432, %431 ], [ %361, %399 ]
+  %403 = call i32 @munmap(i8* nonnull %356, i64 1073741824) #37
+  %404 = icmp eq i32 %403, -1
+  %405 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 3), i64 -1073741824 monotonic, align 8
+  %406 = add i64 %405, -1073741824
+  %407 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2) monotonic, align 16
+  br label %408
 
-409:                                              ; preds = %406
-  %410 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2), i64 %407, i64 %404 release monotonic, align 8
-  %411 = extractvalue { i64, i1 } %410, 1
-  %412 = extractvalue { i64, i1 } %410, 0
-  br i1 %411, label %_mi_stat_decrease.exit.i8.i.i, label %406
+408:                                              ; preds = %411, %401
+  %409 = phi i64 [ %407, %401 ], [ %414, %411 ]
+  %410 = icmp slt i64 %409, %406
+  br i1 %410, label %411, label %_mi_stat_decrease.exit.i8.i.i
 
-_mi_stat_decrease.exit.i8.i.i:                    ; preds = %409, %406
-  %413 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 1), i64 1073741824 monotonic, align 8
-  %414 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 3), i64 -1073741824 monotonic, align 8
-  %415 = add i64 %414, -1073741824
-  %416 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2) monotonic, align 16
-  br label %417
+411:                                              ; preds = %408
+  %412 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2), i64 %409, i64 %406 release monotonic, align 8
+  %413 = extractvalue { i64, i1 } %412, 1
+  %414 = extractvalue { i64, i1 } %412, 0
+  br i1 %413, label %_mi_stat_decrease.exit.i8.i.i, label %408
 
-417:                                              ; preds = %420, %_mi_stat_decrease.exit.i8.i.i
-  %418 = phi i64 [ %416, %_mi_stat_decrease.exit.i8.i.i ], [ %423, %420 ]
-  %419 = icmp slt i64 %418, %415
-  br i1 %419, label %420, label %_mi_stat_decrease.exit1.i.i.i
+_mi_stat_decrease.exit.i8.i.i:                    ; preds = %411, %408
+  %415 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 1), i64 1073741824 monotonic, align 8
+  %416 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 3), i64 -1073741824 monotonic, align 8
+  %417 = add i64 %416, -1073741824
+  %418 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2) monotonic, align 16
+  br label %419
 
-420:                                              ; preds = %417
-  %421 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2), i64 %418, i64 %415 release monotonic, align 8
-  %422 = extractvalue { i64, i1 } %421, 1
-  %423 = extractvalue { i64, i1 } %421, 0
-  br i1 %422, label %_mi_stat_decrease.exit1.i.i.i, label %417
+419:                                              ; preds = %422, %_mi_stat_decrease.exit.i8.i.i
+  %420 = phi i64 [ %418, %_mi_stat_decrease.exit.i8.i.i ], [ %425, %422 ]
+  %421 = icmp slt i64 %420, %417
+  br i1 %421, label %422, label %_mi_stat_decrease.exit1.i.i.i
 
-_mi_stat_decrease.exit1.i.i.i:                    ; preds = %420, %417
-  %424 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 1), i64 1073741824 monotonic, align 8
-  br i1 %402, label %425, label %429
+422:                                              ; preds = %419
+  %423 = cmpxchg weak i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2), i64 %420, i64 %417 release monotonic, align 8
+  %424 = extractvalue { i64, i1 } %423, 1
+  %425 = extractvalue { i64, i1 } %423, 0
+  br i1 %424, label %_mi_stat_decrease.exit1.i.i.i, label %419
 
-425:                                              ; preds = %_mi_stat_decrease.exit1.i.i.i
-  %426 = tail call i32* @__errno_location() #1
-  %427 = load i32, i32* %426, align 4, !tbaa !459
-  %428 = call i8* @strerror(i32 %427) #37
-  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.7.68, i64 0, i64 0), i8* %428, i64 %398, i64 1073741824) #37
-  br label %429
+_mi_stat_decrease.exit1.i.i.i:                    ; preds = %422, %419
+  %426 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 1), i64 1073741824 monotonic, align 8
+  br i1 %404, label %427, label %431
 
-429:                                              ; preds = %425, %_mi_stat_decrease.exit1.i.i.i
-  %430 = add i64 %400, -1073741824
-  %.not63 = icmp eq i64 %430, 0
-  br i1 %.not63, label %mi_reserve_huge_os_pages_interleave.exit, label %399
+427:                                              ; preds = %_mi_stat_decrease.exit1.i.i.i
+  %428 = tail call i32* @__errno_location() #1
+  %429 = load atomic i32, i32* %428 unordered, align 4, !tbaa !463
+  %430 = call i8* @strerror(i32 %429) #37
+  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.7.68, i64 0, i64 0), i8* %430, i64 %400, i64 1073741824) #37
+  br label %431
 
-mi_reserve_huge_os_pages_at.exit.i.thread:        ; preds = %392, %390, %117
-  %431 = tail call i64 @llvm.usub.sat.i64(i64 %119, i64 %122) #37
-  %432 = add nuw i64 %118, 1
-  %433 = icmp ult i64 %432, %89
-  %434 = icmp ugt i64 %119, %122
-  %435 = and i1 %434, %433
-  br i1 %435, label %117, label %mi_reserve_huge_os_pages_interleave.exit
+431:                                              ; preds = %427, %_mi_stat_decrease.exit1.i.i.i
+  %432 = add i64 %402, -1073741824
+  %.not67 = icmp eq i64 %432, 0
+  br i1 %.not67, label %mi_reserve_huge_os_pages_interleave.exit, label %401
 
-mi_reserve_huge_os_pages_interleave.exit:         ; preds = %mi_reserve_huge_os_pages_at.exit.i.thread, %429, %396, %357, %77, %mi_stats_reset.exit
-  %436 = tail call fastcc i64 @mi_option_get(i32 8) #37
-  %.not2 = icmp eq i64 %436, 0
-  br i1 %.not2, label %532, label %437
+mi_reserve_huge_os_pages_at.exit.i.thread:        ; preds = %394, %392, %119
+  %433 = tail call i64 @llvm.usub.sat.i64(i64 %121, i64 %124) #37
+  %434 = add nuw i64 %120, 1
+  %435 = icmp ult i64 %434, %91
+  %436 = icmp ugt i64 %121, %124
+  %437 = and i1 %436, %435
+  br i1 %437, label %119, label %mi_reserve_huge_os_pages_interleave.exit
 
-437:                                              ; preds = %mi_reserve_huge_os_pages_interleave.exit
+mi_reserve_huge_os_pages_interleave.exit:         ; preds = %mi_reserve_huge_os_pages_at.exit.i.thread, %431, %398, %359, %79, %mi_stats_reset.exit
   %438 = tail call fastcc i64 @mi_option_get(i32 8) #37
-  %439 = icmp sgt i64 %438, 0
-  br i1 %439, label %440, label %532
+  %.not2 = icmp eq i64 %438, 0
+  br i1 %.not2, label %534, label %439
 
-440:                                              ; preds = %437
-  %441 = shl i64 %438, 10
-  %442 = icmp ult i64 %441, 524288
-  br i1 %442, label %443, label %445
+439:                                              ; preds = %mi_reserve_huge_os_pages_interleave.exit
+  %440 = tail call fastcc i64 @mi_option_get(i32 8) #37
+  %441 = icmp sgt i64 %440, 0
+  br i1 %441, label %442, label %534
 
-443:                                              ; preds = %440
-  %444 = load i64, i64* @os_page_size, align 8, !tbaa !453
-  br label %452
+442:                                              ; preds = %439
+  %443 = shl i64 %440, 10
+  %444 = icmp ult i64 %443, 524288
+  br i1 %444, label %445, label %447
 
-445:                                              ; preds = %440
-  %446 = icmp ult i64 %441, 2097152
-  br i1 %446, label %452, label %447
+445:                                              ; preds = %442
+  %446 = load atomic i64, i64* @os_page_size unordered, align 8, !tbaa !457
+  br label %454
 
-447:                                              ; preds = %445
-  %448 = icmp ult i64 %441, 8388608
-  br i1 %448, label %452, label %449
+447:                                              ; preds = %442
+  %448 = icmp ult i64 %443, 2097152
+  br i1 %448, label %454, label %449
 
 449:                                              ; preds = %447
-  %450 = icmp ult i64 %441, 33554432
-  %451 = select i1 %450, i64 1048576, i64 4194304
-  br label %452
+  %450 = icmp ult i64 %443, 8388608
+  br i1 %450, label %454, label %451
 
-452:                                              ; preds = %449, %447, %445, %443
-  %453 = phi i64 [ %444, %443 ], [ 65536, %445 ], [ 262144, %447 ], [ %451, %449 ]
-  %454 = xor i64 %453, -1
-  %455 = icmp ult i64 %441, %454
-  br i1 %455, label %456, label %_mi_os_good_alloc_size.exit.i, !prof !436, !misexpect !285
+451:                                              ; preds = %449
+  %452 = icmp ult i64 %443, 33554432
+  %453 = select i1 %452, i64 1048576, i64 4194304
+  br label %454
 
-456:                                              ; preds = %452
-  %457 = tail call i64 @llvm.ctpop.i64(i64 %453) #37, !range !481
-  %458 = icmp ult i64 %457, 2
-  %459 = add i64 %441, -1
-  %460 = add i64 %459, %453
-  br i1 %458, label %461, label %464
+454:                                              ; preds = %451, %449, %447, %445
+  %455 = phi i64 [ %446, %445 ], [ 65536, %447 ], [ 262144, %449 ], [ %453, %451 ]
+  %456 = xor i64 %455, -1
+  %457 = icmp ult i64 %443, %456
+  br i1 %457, label %458, label %_mi_os_good_alloc_size.exit.i, !prof !440, !misexpect !283
 
-461:                                              ; preds = %456
-  %462 = sub i64 0, %453
-  %463 = and i64 %460, %462
+458:                                              ; preds = %454
+  %459 = tail call i64 @llvm.ctpop.i64(i64 %455) #37, !range !486
+  %460 = icmp ult i64 %459, 2
+  %461 = add i64 %443, -1
+  %462 = add i64 %461, %455
+  br i1 %460, label %463, label %466
+
+463:                                              ; preds = %458
+  %464 = sub i64 0, %455
+  %465 = and i64 %462, %464
   br label %_mi_os_good_alloc_size.exit.i
 
-464:                                              ; preds = %456
-  %465 = urem i64 %460, %453
-  %466 = sub i64 %460, %465
+466:                                              ; preds = %458
+  %467 = urem i64 %462, %455
+  %468 = sub i64 %462, %467
   br label %_mi_os_good_alloc_size.exit.i
 
-_mi_os_good_alloc_size.exit.i:                    ; preds = %464, %461, %452
-  %467 = phi i64 [ %441, %452 ], [ %463, %461 ], [ %466, %464 ]
+_mi_os_good_alloc_size.exit.i:                    ; preds = %466, %463, %454
+  %469 = phi i64 [ %443, %454 ], [ %465, %463 ], [ %468, %466 ]
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %4) #37
-  store i8 1, i8* %4, align 1, !tbaa !482
-  %468 = call fastcc i8* @_mi_os_alloc_aligned(i64 %467, i1 zeroext true, i8* nonnull %4) #37
-  %469 = icmp eq i8* %468, null
-  br i1 %469, label %mi_reserve_os_memory.exit, label %470
+  store i8 1, i8* %4, align 1, !tbaa !465
+  %470 = call fastcc i8* @_mi_os_alloc_aligned(i64 %469, i1 zeroext true, i8* nonnull %4) #37
+  %471 = icmp eq i8* %470, null
+  br i1 %471, label %mi_reserve_os_memory.exit, label %472
 
-470:                                              ; preds = %_mi_os_good_alloc_size.exit.i
-  %471 = load i8, i8* %4, align 1, !tbaa !482, !range !72
-  %472 = add i64 %467, 16777215
-  %473 = lshr i64 %472, 24
-  %474 = add nuw nsw i64 %473, 63
-  %475 = lshr i64 %474, 6
-  %476 = shl nuw nsw i64 %475, 4
-  %477 = add nuw nsw i64 %476, 64
-  %478 = call fastcc i8* @_mi_os_alloc(i64 %477) #37
-  %479 = icmp eq i8* %478, null
-  br i1 %479, label %523, label %480
+472:                                              ; preds = %_mi_os_good_alloc_size.exit.i
+  %473 = load atomic i8, i8* %4 unordered, align 1, !tbaa !465, !range !70
+  %474 = add i64 %469, 16777215
+  %475 = lshr i64 %474, 24
+  %476 = add nuw nsw i64 %475, 63
+  %477 = lshr i64 %476, 6
+  %478 = shl nuw nsw i64 %477, 4
+  %479 = add nuw nsw i64 %478, 64
+  %480 = call fastcc i8* @_mi_os_alloc(i64 %479) #37
+  %481 = icmp eq i8* %480, null
+  br i1 %481, label %525, label %482
 
-480:                                              ; preds = %470
-  %481 = getelementptr inbounds i8, i8* %478, i64 8
-  %482 = bitcast i8* %481 to i64*
-  store i64 %473, i64* %482, align 8, !tbaa !470
-  %483 = getelementptr inbounds i8, i8* %478, i64 16
+482:                                              ; preds = %472
+  %483 = getelementptr inbounds i8, i8* %480, i64 8
   %484 = bitcast i8* %483 to i64*
-  store i64 %475, i64* %484, align 8, !tbaa !472
-  %485 = ptrtoint i8* %468 to i64
-  %486 = bitcast i8* %478 to i64*
-  store atomic i64 %485, i64* %486 seq_cst, align 8, !tbaa !473
-  %487 = getelementptr inbounds i8, i8* %478, i64 24
-  %488 = bitcast i8* %487 to i32*
-  store i32 -1, i32* %488, align 8, !tbaa !474
-  %489 = getelementptr inbounds i8, i8* %478, i64 30
-  store i8 %471, i8* %489, align 2, !tbaa !475
-  %490 = getelementptr inbounds i8, i8* %478, i64 28
-  store i8 1, i8* %490, align 4, !tbaa !476
-  %491 = getelementptr inbounds i8, i8* %478, i64 29
-  store i8 1, i8* %491, align 1, !tbaa !477
-  %492 = getelementptr inbounds i8, i8* %478, i64 32
-  %493 = bitcast i8* %492 to i64*
-  store atomic i64 0, i64* %493 seq_cst, align 8, !tbaa !478
-  %494 = getelementptr inbounds i8, i8* %478, i64 56
-  %495 = bitcast i8* %494 to [1 x i64]*
-  %496 = getelementptr inbounds [1 x i64], [1 x i64]* %495, i64 0, i64 %475
-  %497 = getelementptr inbounds i8, i8* %478, i64 40
-  %498 = bitcast i8* %497 to i64**
-  store i64* %496, i64** %498, align 8, !tbaa !479
-  %499 = getelementptr inbounds i8, i8* %478, i64 48
+  store i64 %475, i64* %484, align 8, !tbaa !475
+  %485 = getelementptr inbounds i8, i8* %480, i64 16
+  %486 = bitcast i8* %485 to i64*
+  store i64 %477, i64* %486, align 8, !tbaa !477
+  %487 = ptrtoint i8* %470 to i64
+  %488 = bitcast i8* %480 to i64*
+  store atomic i64 %487, i64* %488 seq_cst, align 8, !tbaa !478
+  %489 = getelementptr inbounds i8, i8* %480, i64 24
+  %490 = bitcast i8* %489 to i32*
+  store i32 -1, i32* %490, align 8, !tbaa !479
+  %491 = getelementptr inbounds i8, i8* %480, i64 30
+  store i8 %473, i8* %491, align 2, !tbaa !480
+  %492 = getelementptr inbounds i8, i8* %480, i64 28
+  store i8 1, i8* %492, align 4, !tbaa !481
+  %493 = getelementptr inbounds i8, i8* %480, i64 29
+  store i8 1, i8* %493, align 1, !tbaa !482
+  %494 = getelementptr inbounds i8, i8* %480, i64 32
+  %495 = bitcast i8* %494 to i64*
+  store atomic i64 0, i64* %495 seq_cst, align 8, !tbaa !483
+  %496 = getelementptr inbounds i8, i8* %480, i64 56
+  %497 = bitcast i8* %496 to [1 x i64]*
+  %498 = getelementptr inbounds [1 x i64], [1 x i64]* %497, i64 0, i64 %477
+  %499 = getelementptr inbounds i8, i8* %480, i64 40
   %500 = bitcast i8* %499 to i64**
-  store i64* null, i64** %500, align 8, !tbaa !480
-  %501 = and i64 %474, 2199023255488
-  %502 = sub nsw i64 %501, %473
-  %503 = icmp sgt i64 %502, 0
-  br i1 %503, label %_mi_bitmap_claim.exit.i, label %514
+  store i64* %498, i64** %500, align 8, !tbaa !484
+  %501 = getelementptr inbounds i8, i8* %480, i64 48
+  %502 = bitcast i8* %501 to i64**
+  store i64* null, i64** %502, align 8, !tbaa !485
+  %503 = and i64 %476, 2199023255488
+  %504 = sub nsw i64 %503, %475
+  %505 = icmp sgt i64 %504, 0
+  br i1 %505, label %_mi_bitmap_claim.exit.i, label %516
 
-_mi_bitmap_claim.exit.i:                          ; preds = %480
-  %504 = bitcast i8* %494 to i64*
-  %505 = lshr i64 %472, 30
-  %506 = icmp ugt i64 %502, 63
-  %507 = and i64 %473, 63
-  %508 = shl nsw i64 -1, %502
-  %509 = xor i64 %508, -1
-  %510 = shl i64 %509, %507
-  %511 = select i1 %506, i64 -1, i64 %510
-  %512 = getelementptr inbounds i64, i64* %504, i64 %505
-  %513 = atomicrmw or i64* %512, i64 %511 acq_rel, align 8
-  br label %514
+_mi_bitmap_claim.exit.i:                          ; preds = %482
+  %506 = bitcast i8* %496 to i64*
+  %507 = lshr i64 %474, 30
+  %508 = icmp ugt i64 %504, 63
+  %509 = and i64 %475, 63
+  %510 = shl nsw i64 -1, %504
+  %511 = xor i64 %510, -1
+  %512 = shl i64 %511, %509
+  %513 = select i1 %508, i64 -1, i64 %512
+  %514 = getelementptr inbounds i64, i64* %506, i64 %507
+  %515 = atomicrmw or i64* %514, i64 %513 acq_rel, align 8
+  br label %516
 
-514:                                              ; preds = %_mi_bitmap_claim.exit.i, %480
-  %515 = atomicrmw add i64* @mi_arena_count, i64 1 acq_rel, align 8
-  %516 = icmp ugt i64 %515, 63
-  br i1 %516, label %517, label %519
+516:                                              ; preds = %_mi_bitmap_claim.exit.i, %482
+  %517 = atomicrmw add i64* @mi_arena_count, i64 1 acq_rel, align 8
+  %518 = icmp ugt i64 %517, 63
+  br i1 %518, label %519, label %521
 
-517:                                              ; preds = %514
-  %518 = atomicrmw sub i64* @mi_arena_count, i64 1 acq_rel, align 8
-  br label %526
+519:                                              ; preds = %516
+  %520 = atomicrmw sub i64* @mi_arena_count, i64 1 acq_rel, align 8
+  br label %528
 
-519:                                              ; preds = %514
-  %520 = getelementptr inbounds [64 x %struct.mi_arena_s*], [64 x %struct.mi_arena_s*]* @mi_arenas, i64 0, i64 %515
-  %521 = ptrtoint i8* %478 to i64
-  %522 = bitcast %struct.mi_arena_s** %520 to i64*
-  store atomic i64 %521, i64* %522 release, align 8
-  br label %526
+521:                                              ; preds = %516
+  %522 = getelementptr inbounds [64 x %struct.mi_arena_s*], [64 x %struct.mi_arena_s*]* @mi_arenas, i64 0, i64 %517
+  %523 = ptrtoint i8* %480 to i64
+  %524 = bitcast %struct.mi_arena_s** %522 to i64*
+  store atomic i64 %523, i64* %524 release, align 8
+  br label %528
 
-523:                                              ; preds = %470
-  call fastcc void @_mi_os_free_ex(i8* nonnull %468, i64 %467, i1 zeroext true) #37
-  %524 = add i64 %467, 1023
-  %525 = lshr i64 %524, 10
-  call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.3.168, i64 0, i64 0), i64 %525) #37
+525:                                              ; preds = %472
+  call fastcc void @_mi_os_free_ex(i8* nonnull %470, i64 %469, i1 zeroext true) #37
+  %526 = add i64 %469, 1023
+  %527 = lshr i64 %526, 10
+  call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([32 x i8], [32 x i8]* @.str.3.168, i64 0, i64 0), i64 %527) #37
   br label %mi_reserve_os_memory.exit
 
-526:                                              ; preds = %519, %517
-  %527 = add i64 %467, 1023
-  %528 = lshr i64 %527, 10
-  %529 = load i8, i8* %4, align 1, !tbaa !482, !range !72
-  %530 = icmp eq i8 %529, 0
-  %531 = select i1 %530, i8* getelementptr inbounds ([1 x i8], [1 x i8]* @.str.7.558, i64 0, i64 0), i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.5.170, i64 0, i64 0)
-  call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.4.171, i64 0, i64 0), i64 %528, i8* %531) #37
+528:                                              ; preds = %521, %519
+  %529 = add i64 %469, 1023
+  %530 = lshr i64 %529, 10
+  %531 = load atomic i8, i8* %4 unordered, align 1, !tbaa !465, !range !70
+  %532 = icmp eq i8 %531, 0
+  %533 = select i1 %532, i8* getelementptr inbounds ([1 x i8], [1 x i8]* @.str.7.558, i64 0, i64 0), i8* getelementptr inbounds ([21 x i8], [21 x i8]* @.str.5.170, i64 0, i64 0)
+  call void (i8*, ...) @_mi_verbose_message(i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.4.171, i64 0, i64 0), i64 %530, i8* %533) #37
   br label %mi_reserve_os_memory.exit
 
-mi_reserve_os_memory.exit:                        ; preds = %526, %523, %_mi_os_good_alloc_size.exit.i
+mi_reserve_os_memory.exit:                        ; preds = %528, %525, %_mi_os_good_alloc_size.exit.i
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %4) #37
-  br label %532
+  br label %534
 
-532:                                              ; preds = %mi_reserve_os_memory.exit, %437, %mi_reserve_huge_os_pages_interleave.exit, %0
+534:                                              ; preds = %mi_reserve_os_memory.exit, %439, %mi_reserve_huge_os_pages_interleave.exit, %0
   ret void
 }
 
@@ -31722,8 +32286,8 @@
   %14 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 8, i32 1), i64 1 monotonic, align 8
   %15 = getelementptr inbounds i8, i8* %0, i64 2848
   %16 = bitcast i8* %15 to i64*
-  %17 = load i64, i64* %16, align 8, !tbaa !452
-  %18 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !451
+  %17 = load atomic i64, i64* %16 unordered, align 8, !tbaa !456
+  %18 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !455
   %19 = ptrtoint i8* %18 to i64
   %20 = icmp ne i64 %17, %19
   %21 = icmp eq i8* %0, bitcast (%struct.mi_heap_s* @_mi_heap_empty to i8*)
@@ -31731,13 +32295,13 @@
   br i1 %22, label %_mi_thread_done.exit, label %23
 
 23:                                               ; preds = %_mi_stat_decrease.exit.i
-  %24 = load i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4), align 8, !tbaa !452
+  %24 = load atomic i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4) unordered, align 8, !tbaa !456
   %25 = icmp eq i64 %24, 0
   %26 = icmp eq i64 %24, %17
   %27 = or i1 %25, %26
   %28 = select i1 %27, i8* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to i8*), i8* bitcast (%struct.mi_heap_s* @_mi_heap_empty to i8*)
-  store i8* %28, i8** bitcast (%struct.mi_heap_s** @_mi_heap_default to i8**), align 8, !tbaa !434
-  %29 = load i32, i32* @_mi_heap_default_key, align 4, !tbaa !459
+  store i8* %28, i8** bitcast (%struct.mi_heap_s** @_mi_heap_default to i8**), align 8, !tbaa !438
+  %29 = load atomic i32, i32* @_mi_heap_default_key unordered, align 4, !tbaa !463
   %30 = icmp eq i32 %29, -1
   br i1 %30, label %33, label %31
 
@@ -31747,24 +32311,24 @@
 
 33:                                               ; preds = %31, %23
   %34 = bitcast i8* %0 to %struct.mi_tld_s**
-  %35 = load %struct.mi_tld_s*, %struct.mi_tld_s** %34, align 8, !tbaa !461
+  %35 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %34 unordered, align 8, !tbaa !466
   %36 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %35, i64 0, i32 2
-  %37 = load %struct.mi_heap_s*, %struct.mi_heap_s** %36, align 8, !tbaa !483
+  %37 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** %36 unordered, align 8, !tbaa !487
   %38 = icmp eq %struct.mi_heap_s* %37, @_mi_heap_empty
   br i1 %38, label %_mi_thread_done.exit, label %39
 
 39:                                               ; preds = %33
   %40 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %37, i64 0, i32 0
-  %41 = load %struct.mi_tld_s*, %struct.mi_tld_s** %40, align 8, !tbaa !461
+  %41 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %40 unordered, align 8, !tbaa !466
   %42 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %41, i64 0, i32 3
-  %43 = load %struct.mi_heap_s*, %struct.mi_heap_s** %42, align 8, !tbaa !492
+  %43 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** %42 unordered, align 8, !tbaa !496
   %44 = icmp eq %struct.mi_heap_s* %43, null
   br i1 %44, label %.loopexit7, label %.preheader6
 
 .preheader6:                                      ; preds = %mi_heap_delete.exit.i, %39
   %45 = phi %struct.mi_heap_s* [ %47, %mi_heap_delete.exit.i ], [ %43, %39 ]
   %46 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 11
-  %47 = load %struct.mi_heap_s*, %struct.mi_heap_s** %46, align 8, !tbaa !493
+  %47 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** %46 unordered, align 8, !tbaa !497
   %48 = icmp eq %struct.mi_heap_s* %45, %37
   br i1 %48, label %mi_heap_delete.exit.i, label %49
 
@@ -31776,15 +32340,15 @@
 
 53:                                               ; preds = %49
   %54 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 0
-  %55 = load %struct.mi_tld_s*, %struct.mi_tld_s** %54, align 8, !tbaa !461
+  %55 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %54 unordered, align 8, !tbaa !466
   %56 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %55, i64 0, i32 2
-  %57 = load %struct.mi_heap_s*, %struct.mi_heap_s** %56, align 8, !tbaa !483
+  %57 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** %56 unordered, align 8, !tbaa !487
   %58 = icmp eq %struct.mi_heap_s* %57, %45
   br i1 %58, label %301, label %59
 
 59:                                               ; preds = %53
   %60 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 8
-  %61 = load i64, i64* %60, align 8, !tbaa !494
+  %61 = load atomic i64, i64* %60 unordered, align 8, !tbaa !498
   %62 = icmp eq i64 %61, 0
   br i1 %62, label %302, label %63
 
@@ -31809,7 +32373,7 @@
   %74 = phi i64 [ %77, %.preheader4 ], [ %68, %70 ]
   %75 = inttoptr i64 %74 to %"class.kotlin::gc::GCHandle"*
   %76 = inttoptr i64 %74 to i64*
-  %77 = load i64, i64* %76, align 8, !tbaa !443
+  %77 = load atomic i64, i64* %76 unordered, align 8, !tbaa !447
   tail call fastcc void @_mi_free_delayed_block(%"class.kotlin::gc::GCHandle"* nonnull %75) #37
   %78 = icmp eq i64 %77, 0
   br i1 %78, label %_mi_heap_delayed_free.exit.i.i, label %.preheader4
@@ -31839,7 +32403,7 @@
   %91 = phi i64 [ %94, %.preheader2 ], [ %85, %87 ]
   %92 = inttoptr i64 %91 to %"class.kotlin::gc::GCHandle"*
   %93 = inttoptr i64 %91 to i64*
-  %94 = load i64, i64* %93, align 8, !tbaa !443
+  %94 = load atomic i64, i64* %93 unordered, align 8, !tbaa !447
   tail call fastcc void @_mi_free_delayed_block(%"class.kotlin::gc::GCHandle"* nonnull %92) #37
   %95 = icmp eq i64 %94, 0
   br i1 %95, label %_mi_heap_delayed_free.exit3.i.i, label %.preheader2
@@ -31855,8 +32419,8 @@
   %102 = icmp eq i64 %101, 0
   tail call void @llvm.assume(i1 %102) #37
   tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(1800) %99, i8* nonnull align 16 dereferenceable(1800) bitcast ([75 x %struct.mi_page_queue_s]* getelementptr inbounds (%struct.mi_heap_s, %struct.mi_heap_s* @_mi_heap_empty, i64 0, i32 2) to i8*), i64 1800, i1 false) #37
-  store atomic i64 0, i64* %65 seq_cst, align 8, !tbaa !495
-  store i64 0, i64* %60, align 8, !tbaa !494
+  store atomic i64 0, i64* %65 seq_cst, align 8, !tbaa !499
+  store i64 0, i64* %60, align 8, !tbaa !498
   br label %302
 
 103:                                              ; preds = %_mi_page_queue_append.exit.i.i, %_mi_heap_delayed_free.exit.i.i
@@ -31864,16 +32428,16 @@
   %105 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %57, i64 0, i32 2, i64 %104
   %106 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 2, i64 %104
   %107 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %106, i64 0, i32 0
-  %108 = load %struct.mi_page_s*, %struct.mi_page_s** %107, align 8, !tbaa !496
+  %108 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %107 unordered, align 8, !tbaa !500
   %109 = icmp eq %struct.mi_page_s* %108, null
   br i1 %109, label %_mi_page_queue_append.exit.i.i, label %117
 
 110:                                              ; preds = %132
   %111 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %57, i64 0, i32 2, i64 %104, i32 1
-  %112 = load %struct.mi_page_s*, %struct.mi_page_s** %111, align 8, !tbaa !497
+  %112 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %111 unordered, align 8, !tbaa !501
   %113 = icmp eq %struct.mi_page_s* %112, null
   %114 = bitcast %struct.mi_page_queue_s* %106 to i64*
-  %115 = load i64, i64* %114, align 8, !tbaa !496
+  %115 = load atomic i64, i64* %114 unordered, align 8, !tbaa !500
   %116 = inttoptr i64 %115 to %struct.mi_page_s*
   br i1 %113, label %137, label %284
 
@@ -31893,7 +32457,7 @@
     i32 1, label %130
     i32 3, label %132
     i32 0, label %132
-  ], !prof !498
+  ], !prof !502
 
 126:                                              ; preds = %122
   %127 = and i64 %123, -4
@@ -31911,20 +32475,20 @@
 132:                                              ; preds = %126, %122, %122
   %133 = add i64 %119, 1
   %134 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %118, i64 0, i32 12
-  %135 = load %struct.mi_page_s*, %struct.mi_page_s** %134, align 8, !tbaa !499
+  %135 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %134 unordered, align 8, !tbaa !503
   %136 = icmp eq %struct.mi_page_s* %135, null
   br i1 %136, label %110, label %117
 
 137:                                              ; preds = %110
   %138 = bitcast %struct.mi_page_queue_s* %105 to i64*
-  store i64 %115, i64* %138, align 8, !tbaa !496
+  store i64 %115, i64* %138, align 8, !tbaa !500
   %139 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 2, i64 %104, i32 1
   %140 = bitcast %struct.mi_page_s** %139 to i64*
-  %141 = load i64, i64* %140, align 8, !tbaa !497
+  %141 = load atomic i64, i64* %140 unordered, align 8, !tbaa !501
   %142 = bitcast %struct.mi_page_s** %111 to i64*
-  store i64 %141, i64* %142, align 8, !tbaa !497
+  store i64 %141, i64* %142, align 8, !tbaa !501
   %143 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %57, i64 0, i32 2, i64 %104, i32 2
-  %144 = load i64, i64* %143, align 8, !tbaa !500
+  %144 = load atomic i64, i64* %143 unordered, align 8, !tbaa !504
   %145 = icmp ugt i64 %144, 1024
   br i1 %145, label %_mi_page_queue_append.exit.i.i, label %146
 
@@ -31934,7 +32498,7 @@
   %149 = add nuw nsw i64 %144, 7
   %150 = lshr i64 %149, 3
   %151 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %57, i64 0, i32 1, i64 %150
-  %152 = load %struct.mi_page_s*, %struct.mi_page_s** %151, align 8, !tbaa !434
+  %152 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %151 unordered, align 8, !tbaa !438
   %153 = icmp eq %struct.mi_page_s* %152, %148
   br i1 %153, label %_mi_page_queue_append.exit.i.i, label %154
 
@@ -31954,7 +32518,7 @@
 
 162:                                              ; preds = %156
   %163 = add nsw i64 %150, -1
-  %164 = tail call i64 @llvm.ctlz.i64(i64 %163, i1 true) #37, !range !481
+  %164 = tail call i64 @llvm.ctlz.i64(i64 %163, i1 true) #37, !range !486
   %165 = trunc i64 %164 to i32
   %166 = xor i32 %165, 63
   %167 = shl nuw nsw i32 %166, 2
@@ -31976,7 +32540,7 @@
   %179 = phi %struct.mi_page_queue_s* [ %105, %176 ], [ %180, %208 ]
   %180 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %179, i64 -1
   %181 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %179, i64 -1, i32 2
-  %182 = load i64, i64* %181, align 8, !tbaa !500
+  %182 = load atomic i64, i64* %181 unordered, align 8, !tbaa !504
   %183 = add i64 %182, 7
   %184 = lshr i64 %183, 3
   %185 = icmp ult i64 %183, 16
@@ -31998,7 +32562,7 @@
 
 194:                                              ; preds = %192
   %195 = add nsw i64 %184, -1
-  %196 = tail call i64 @llvm.ctlz.i64(i64 %195, i1 true) #37, !range !481
+  %196 = tail call i64 @llvm.ctlz.i64(i64 %195, i1 true) #37, !range !486
   %197 = trunc i64 %196 to i32
   %198 = xor i32 %197, 63
   %199 = shl nuw nsw i32 %198, 2
@@ -32055,38 +32619,38 @@
   %238 = add i64 %219, %236
   %239 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %57, i64 0, i32 1, i64 %238
   %240 = bitcast %struct.mi_page_s** %239 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %240, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %240, align 8, !tbaa !438
   %241 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %239, i64 2
   %242 = bitcast %struct.mi_page_s** %241 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %242, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %242, align 8, !tbaa !438
   %243 = or i64 %236, 4
   %244 = add i64 %219, %243
   %245 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %57, i64 0, i32 1, i64 %244
   %246 = bitcast %struct.mi_page_s** %245 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %246, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %246, align 8, !tbaa !438
   %247 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %245, i64 2
   %248 = bitcast %struct.mi_page_s** %247 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %248, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %248, align 8, !tbaa !438
   %249 = or i64 %236, 8
   %250 = add i64 %219, %249
   %251 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %57, i64 0, i32 1, i64 %250
   %252 = bitcast %struct.mi_page_s** %251 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %252, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %252, align 8, !tbaa !438
   %253 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %251, i64 2
   %254 = bitcast %struct.mi_page_s** %253 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %254, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %254, align 8, !tbaa !438
   %255 = or i64 %236, 12
   %256 = add i64 %219, %255
   %257 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %57, i64 0, i32 1, i64 %256
   %258 = bitcast %struct.mi_page_s** %257 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %258, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %258, align 8, !tbaa !438
   %259 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %257, i64 2
   %260 = bitcast %struct.mi_page_s** %259 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %260, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %260, align 8, !tbaa !438
   %261 = add i64 %236, 16
   %262 = add i64 %237, -4
   %263 = icmp eq i64 %262, 0
-  br i1 %263, label %.loopexit1, label %235, !llvm.loop !501
+  br i1 %263, label %.loopexit1, label %235, !llvm.loop !505
 
 .loopexit1:                                       ; preds = %235, %223
   %264 = phi i64 [ 0, %223 ], [ %261, %235 ]
@@ -32099,14 +32663,14 @@
   %268 = add i64 %219, %266
   %269 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %57, i64 0, i32 1, i64 %268
   %270 = bitcast %struct.mi_page_s** %269 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %270, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %270, align 8, !tbaa !438
   %271 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %269, i64 2
   %272 = bitcast %struct.mi_page_s** %271 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %272, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %227, <2 x %struct.mi_page_s*>* %272, align 8, !tbaa !438
   %273 = add nuw i64 %266, 4
   %274 = add nsw i64 %267, -1
   %275 = icmp eq i64 %274, 0
-  br i1 %275, label %.loopexit, label %.preheader, !llvm.loop !502
+  br i1 %275, label %.loopexit, label %.preheader, !llvm.loop !506
 
 .loopexit:                                        ; preds = %.preheader, %.loopexit1
   %276 = icmp eq i64 %221, %224
@@ -32119,34 +32683,34 @@
 279:                                              ; preds = %279, %277
   %280 = phi i64 [ %282, %279 ], [ %278, %277 ]
   %281 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %57, i64 0, i32 1, i64 %280
-  store %struct.mi_page_s* %148, %struct.mi_page_s** %281, align 8, !tbaa !434
+  store %struct.mi_page_s* %148, %struct.mi_page_s** %281, align 8, !tbaa !438
   %282 = add nuw nsw i64 %280, 1
   %283 = icmp eq i64 %280, %150
-  br i1 %283, label %_mi_page_queue_append.exit.i.i, label %279, !llvm.loop !503
+  br i1 %283, label %_mi_page_queue_append.exit.i.i, label %279, !llvm.loop !507
 
 284:                                              ; preds = %110
   %285 = ptrtoint %struct.mi_page_s* %112 to i64
   %286 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %112, i64 0, i32 12
   %287 = bitcast %struct.mi_page_s** %286 to i64*
-  store i64 %115, i64* %287, align 8, !tbaa !499
+  store i64 %115, i64* %287, align 8, !tbaa !503
   %288 = bitcast %struct.mi_page_s** %111 to i64*
   %289 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %116, i64 0, i32 13
   %290 = bitcast %struct.mi_page_s** %289 to i64*
-  store i64 %285, i64* %290, align 8, !tbaa !504
+  store i64 %285, i64* %290, align 8, !tbaa !508
   %291 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 2, i64 %104, i32 1
   %292 = bitcast %struct.mi_page_s** %291 to i64*
-  %293 = load i64, i64* %292, align 8, !tbaa !497
-  store i64 %293, i64* %288, align 8, !tbaa !497
+  %293 = load atomic i64, i64* %292 unordered, align 8, !tbaa !501
+  store i64 %293, i64* %288, align 8, !tbaa !501
   br label %_mi_page_queue_append.exit.i.i
 
 _mi_page_queue_append.exit.i.i:                   ; preds = %284, %279, %.loopexit, %213, %146, %137, %103
   %294 = phi i64 [ 0, %103 ], [ %133, %284 ], [ %133, %137 ], [ %133, %146 ], [ %133, %213 ], [ %133, %.loopexit ], [ %133, %279 ]
-  %295 = load i64, i64* %79, align 8, !tbaa !494
+  %295 = load atomic i64, i64* %79 unordered, align 8, !tbaa !498
   %296 = add i64 %295, %294
-  store i64 %296, i64* %79, align 8, !tbaa !494
-  %297 = load i64, i64* %60, align 8, !tbaa !494
+  store i64 %296, i64* %79, align 8, !tbaa !498
+  %297 = load atomic i64, i64* %60 unordered, align 8, !tbaa !498
   %298 = sub i64 %297, %294
-  store i64 %298, i64* %60, align 8, !tbaa !494
+  store i64 %298, i64* %60, align 8, !tbaa !498
   %299 = add nuw nsw i64 %104, 1
   %300 = icmp eq i64 %299, 75
   br i1 %300, label %82, label %103
@@ -32156,20 +32720,20 @@
   br label %302
 
 302:                                              ; preds = %301, %_mi_heap_delayed_free.exit3.i.i, %59
-  %303 = load %struct.mi_tld_s*, %struct.mi_tld_s** %54, align 8, !tbaa !461
+  %303 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %54 unordered, align 8, !tbaa !466
   %304 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %303, i64 0, i32 2
-  %305 = load %struct.mi_heap_s*, %struct.mi_heap_s** %304, align 8, !tbaa !483
+  %305 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** %304 unordered, align 8, !tbaa !487
   %306 = icmp eq %struct.mi_heap_s* %305, %45
   br i1 %306, label %mi_heap_delete.exit.i, label %307
 
 307:                                              ; preds = %302
-  %308 = load %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !434
+  %308 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default unordered, align 8, !tbaa !438
   %309 = icmp eq %struct.mi_heap_s* %308, %45
   br i1 %309, label %310, label %317
 
 310:                                              ; preds = %307
-  store %struct.mi_heap_s* %305, %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !434
-  %311 = load i32, i32* @_mi_heap_default_key, align 4, !tbaa !459
+  store %struct.mi_heap_s* %305, %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !438
+  %311 = load atomic i32, i32* @_mi_heap_default_key unordered, align 4, !tbaa !463
   %312 = icmp eq i32 %311, -1
   br i1 %312, label %_mi_heap_set_default_direct.exit.i.i, label %313
 
@@ -32179,7 +32743,7 @@
   br label %_mi_heap_set_default_direct.exit.i.i
 
 _mi_heap_set_default_direct.exit.i.i:             ; preds = %313, %310
-  %316 = load %struct.mi_tld_s*, %struct.mi_tld_s** %54, align 8, !tbaa !461
+  %316 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %54 unordered, align 8, !tbaa !466
   br label %317
 
 317:                                              ; preds = %_mi_heap_set_default_direct.exit.i.i, %307
@@ -32190,7 +32754,7 @@
 320:                                              ; preds = %320, %317
   %321 = phi %struct.mi_heap_s* [ null, %317 ], [ %323, %320 ]
   %322 = phi %struct.mi_heap_s** [ %319, %317 ], [ %327, %320 ]
-  %323 = load %struct.mi_heap_s*, %struct.mi_heap_s** %322, align 8, !tbaa !434
+  %323 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** %322 unordered, align 8, !tbaa !438
   %324 = icmp ne %struct.mi_heap_s* %323, %45
   %325 = icmp ne %struct.mi_heap_s* %323, null
   %326 = and i1 %324, %325
@@ -32204,11 +32768,11 @@
 330:                                              ; preds = %328
   %331 = icmp eq %struct.mi_heap_s* %321, null
   %332 = bitcast %struct.mi_heap_s** %46 to i64*
-  %333 = load i64, i64* %332, align 8, !tbaa !493
+  %333 = load atomic i64, i64* %332 unordered, align 8, !tbaa !497
   %334 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %321, i64 0, i32 11
   %335 = select i1 %331, %struct.mi_heap_s** %319, %struct.mi_heap_s** %334
   %336 = bitcast %struct.mi_heap_s** %335 to i64*
-  store i64 %333, i64* %336, align 8, !tbaa !434
+  store i64 %333, i64* %336, align 8, !tbaa !438
   br label %337
 
 337:                                              ; preds = %330, %328
@@ -32226,7 +32790,7 @@
 
 341:                                              ; preds = %.loopexit7
   tail call fastcc void @mi_heap_collect_ex(%struct.mi_heap_s* %37, i32 2) #37
-  %342 = load %struct.mi_tld_s*, %struct.mi_tld_s** %40, align 8, !tbaa !461
+  %342 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %40 unordered, align 8, !tbaa !466
   %343 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %342, i64 0, i32 6
   tail call fastcc void @mi_stats_merge_from(%struct.mi_stats_s* nonnull %343) #37
   %344 = bitcast %struct.mi_heap_s* %37 to i8*
@@ -32234,7 +32798,7 @@
   br label %_mi_thread_done.exit
 
 345:                                              ; preds = %.loopexit7
-  %346 = load %struct.mi_tld_s*, %struct.mi_tld_s** %40, align 8, !tbaa !461
+  %346 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %40 unordered, align 8, !tbaa !466
   %347 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %346, i64 0, i32 6
   tail call fastcc void @mi_stats_merge_from(%struct.mi_stats_s* nonnull %347) #37
   br label %_mi_thread_done.exit
@@ -32277,7 +32841,7 @@
   store i1 true, i1* @recurse, align 1
   %15 = load atomic i64, i64* bitcast (i8** @mi_out_arg to i64*) acquire, align 8
   %16 = inttoptr i64 %15 to i8*
-  %17 = load volatile void (i8*, i8*)*, void (i8*, i8*)** @mi_out_default, align 8, !tbaa !434
+  %17 = load atomic volatile void (i8*, i8*)*, void (i8*, i8*)** @mi_out_default unordered, align 8, !tbaa !438
   %18 = icmp eq void (i8*, i8*)* %17, null
   %19 = select i1 %18, void (i8*, i8*)* @mi_out_buf, void (i8*, i8*)* %17
   call void %19(i8* nonnull getelementptr inbounds ([11 x i8], [11 x i8]* @.str.1.122, i64 0, i64 0), i8* %16) #37
@@ -32298,42 +32862,42 @@
 ; Function Attrs: nounwind uwtable
 define internal fastcc void @mi_thread_init() unnamed_addr #17 {
   tail call fastcc void @mi_process_init()
-  %1 = load %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !434
+  %1 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default unordered, align 8, !tbaa !438
   %2 = icmp eq %struct.mi_heap_s* %1, @_mi_heap_empty
   br i1 %2, label %3, label %82
 
 3:                                                ; preds = %0
-  %4 = load i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4), align 8, !tbaa !452
+  %4 = load atomic i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4) unordered, align 8, !tbaa !456
   %5 = icmp eq i64 %4, 0
   br i1 %5, label %10, label %6
 
 6:                                                ; preds = %3
-  %7 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !451
+  %7 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !455
   %8 = ptrtoint i8* %7 to i64
   %9 = icmp eq i64 %4, %8
   br i1 %9, label %10, label %24
 
 10:                                               ; preds = %6, %3
-  %11 = load i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5), align 8, !tbaa !448
+  %11 = load atomic i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5) unordered, align 8, !tbaa !452
   %12 = icmp eq i64 %11, 0
   br i1 %12, label %13, label %19
 
 13:                                               ; preds = %10
-  %14 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !451
+  %14 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !455
   %15 = ptrtoint i8* %14 to i64
-  store i64 %15, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4), align 8, !tbaa !452
+  store i64 %15, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4), align 8, !tbaa !456
   %16 = tail call i64 @_os_random_weak(i64 ptrtoint (void ()* @mi_heap_main_init to i64)) #37
-  store i64 %16, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5), align 8, !tbaa !448
+  store i64 %16, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5), align 8, !tbaa !452
   tail call fastcc void @_mi_random_init(%struct.mi_random_cxt_s* bitcast (i32* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 7, i32 0, i32 0) to %struct.mi_random_cxt_s*)) #37
   %17 = tail call fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*)) #37
-  store i64 %17, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 0), align 8, !tbaa !453
+  store i64 %17, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 0), align 8, !tbaa !457
   %18 = tail call fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*)) #37
-  store i64 %18, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 1), align 8, !tbaa !453
+  store i64 %18, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 6, i64 1), align 8, !tbaa !457
   br label %19
 
 19:                                               ; preds = %13, %10
-  store %struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*), %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !434
-  %20 = load i32, i32* @_mi_heap_default_key, align 4, !tbaa !459
+  store %struct.mi_heap_s* bitcast ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main to %struct.mi_heap_s*), %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !438
+  %20 = load atomic i32, i32* @_mi_heap_default_key unordered, align 4, !tbaa !463
   %21 = icmp eq i32 %20, -1
   br i1 %21, label %71, label %22
 
@@ -32364,11 +32928,11 @@
   %37 = icmp eq i64 %36, 0
   tail call void @llvm.assume(i1 %37) #37
   tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(3056) %32, i8* nonnull align 64 dereferenceable(3056) bitcast (%struct.mi_heap_s* @_mi_heap_empty to i8*), i64 3056, i1 false) #37
-  %38 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !451
+  %38 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !455
   %39 = ptrtoint i8* %38 to i64
   %40 = getelementptr inbounds i8, i8* %32, i64 2848
   %41 = bitcast i8* %40 to i64*
-  store i64 %39, i64* %41, align 8, !tbaa !452
+  store i64 %39, i64* %41, align 8, !tbaa !456
   %42 = getelementptr inbounds i8, i8* %32, i64 2880
   %43 = bitcast i8* %42 to %struct.mi_random_cxt_s*
   tail call fastcc void @_mi_random_init(%struct.mi_random_cxt_s* nonnull %43) #37
@@ -32376,36 +32940,36 @@
   %45 = or i64 %44, 1
   %46 = getelementptr inbounds i8, i8* %32, i64 2856
   %47 = bitcast i8* %46 to i64*
-  store i64 %45, i64* %47, align 8, !tbaa !448
+  store i64 %45, i64* %47, align 8, !tbaa !452
   %48 = tail call fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* %34) #37
   %49 = getelementptr inbounds i8, i8* %32, i64 2864
   %50 = bitcast i8* %49 to i64*
-  store i64 %48, i64* %50, align 8, !tbaa !453
+  store i64 %48, i64* %50, align 8, !tbaa !457
   %51 = tail call fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* %34) #37
   %52 = getelementptr inbounds i8, i8* %32, i64 2872
   %53 = bitcast i8* %52 to i64*
-  store i64 %51, i64* %53, align 8, !tbaa !453
+  store i64 %51, i64* %53, align 8, !tbaa !457
   %54 = bitcast i8* %32 to i8**
-  store i8* %33, i8** %54, align 8, !tbaa !461
+  store i8* %33, i8** %54, align 8, !tbaa !466
   %55 = getelementptr inbounds i8, i8* %32, i64 3072
   %56 = bitcast i8* %55 to i8**
-  store i8* %32, i8** %56, align 8, !tbaa !483
+  store i8* %32, i8** %56, align 8, !tbaa !487
   %57 = getelementptr inbounds i8, i8* %32, i64 3080
   %58 = bitcast i8* %57 to i8**
-  store i8* %32, i8** %58, align 8, !tbaa !492
+  store i8* %32, i8** %58, align 8, !tbaa !496
   %59 = getelementptr inbounds i8, i8* %32, i64 3232
   %60 = getelementptr inbounds i8, i8* %32, i64 3200
   %61 = bitcast i8* %60 to i8**
-  store i8* %59, i8** %61, align 8, !tbaa !505
+  store i8* %59, i8** %61, align 8, !tbaa !509
   %62 = getelementptr inbounds i8, i8* %32, i64 3216
   %63 = getelementptr inbounds i8, i8* %32, i64 3208
   %64 = bitcast i8* %63 to i8**
-  store i8* %62, i8** %64, align 8, !tbaa !506
+  store i8* %62, i8** %64, align 8, !tbaa !510
   %65 = getelementptr inbounds i8, i8* %32, i64 3224
   %66 = bitcast i8* %65 to i8**
-  store i8* %59, i8** %66, align 8, !tbaa !507
-  store i8* %32, i8** bitcast (%struct.mi_heap_s** @_mi_heap_default to i8**), align 8, !tbaa !434
-  %67 = load i32, i32* @_mi_heap_default_key, align 4, !tbaa !459
+  store i8* %59, i8** %66, align 8, !tbaa !511
+  store i8* %32, i8** bitcast (%struct.mi_heap_s** @_mi_heap_default to i8**), align 8, !tbaa !438
+  %67 = load atomic i32, i32* @_mi_heap_default_key unordered, align 4, !tbaa !463
   %68 = icmp eq i32 %67, -1
   br i1 %68, label %71, label %69
 
@@ -32446,21 +33010,21 @@
   %5 = zext i32 %0 to i64
   %6 = getelementptr inbounds [20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 %5
   %7 = getelementptr inbounds [20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 %5, i32 1
-  %8 = load i32, i32* %7, align 8, !tbaa !433
+  %8 = load atomic i32, i32* %7 unordered, align 8, !tbaa !437
   %9 = icmp eq i32 %8, 0
-  br i1 %9, label %10, label %217, !prof !284, !misexpect !285
+  br i1 %9, label %10, label %217, !prof !282, !misexpect !283
 
 10:                                               ; preds = %1
   %11 = getelementptr inbounds [65 x i8], [65 x i8]* %2, i64 0, i64 0
   call void @llvm.lifetime.start.p0i8(i64 65, i8* nonnull %11) #37
-  store i8 0, i8* %11, align 16, !tbaa !454
+  store i8 0, i8* %11, align 16, !tbaa !458
   %12 = call i8* @strncpy(i8* nonnull %11, i8* nonnull dereferenceable(10) getelementptr inbounds ([10 x i8], [10 x i8]* @.str.24.143, i64 0, i64 0), i64 64) #37
   %13 = getelementptr inbounds [65 x i8], [65 x i8]* %2, i64 0, i64 64
-  store i8 0, i8* %13, align 16, !tbaa !454
+  store i8 0, i8* %13, align 16, !tbaa !458
   %14 = getelementptr inbounds [20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 %5, i32 3
-  %15 = load i8*, i8** %14, align 8, !tbaa !455
+  %15 = load atomic i8*, i8** %14 unordered, align 8, !tbaa !459
   %16 = call i8* @strncat(i8* nonnull dereferenceable(1) %11, i8* nonnull dereferenceable(1) %15, i64 64) #37
-  store i8 0, i8* %13, align 16, !tbaa !454
+  store i8 0, i8* %13, align 16, !tbaa !458
   %17 = getelementptr inbounds [65 x i8], [65 x i8]* %3, i64 0, i64 0
   call void @llvm.lifetime.start.p0i8(i64 65, i8* nonnull %17) #37
   %18 = call i64 @strlen(i8* nonnull %11) #54
@@ -32468,44 +33032,44 @@
   br i1 %19, label %.loopexit14, label %20
 
 20:                                               ; preds = %10
-  %21 = load i8**, i8*** @environ, align 8, !tbaa !434
+  %21 = load atomic i8**, i8*** @environ unordered, align 8, !tbaa !438
   %22 = icmp eq i8** %21, null
   br i1 %22, label %.loopexit14, label %23
 
 23:                                               ; preds = %20
-  %24 = load i8, i8* %11, align 16
+  %24 = load atomic i8, i8* %11 unordered, align 16
   %25 = icmp eq i8 %24, 0
   br i1 %25, label %.preheader13, label %.preheader18
 
 .preheader13:                                     ; preds = %227, %23
   %26 = phi i64 [ %228, %227 ], [ 0, %23 ]
   %27 = getelementptr inbounds i8*, i8** %21, i64 %26
-  %28 = load i8*, i8** %27, align 8, !tbaa !434
+  %28 = load atomic i8*, i8** %27 unordered, align 8, !tbaa !438
   %29 = icmp eq i8* %28, null
   br i1 %29, label %.loopexit14, label %30
 
 30:                                               ; preds = %.preheader13
-  %31 = load i8, i8* %28, align 1, !tbaa !454
+  %31 = load atomic i8, i8* %28 unordered, align 1, !tbaa !458
   %32 = icmp eq i8 %31, 0
   br i1 %32, label %33, label %37
 
 33:                                               ; preds = %30
   %34 = getelementptr inbounds i8, i8* %28, i64 %18
-  %35 = load i8, i8* %34, align 1, !tbaa !454
+  %35 = load atomic i8, i8* %34 unordered, align 1, !tbaa !458
   %36 = icmp eq i8 %35, 61
   br i1 %36, label %.loopexit15, label %37
 
 37:                                               ; preds = %33, %30
   %38 = or i64 %26, 1
   %39 = getelementptr inbounds i8*, i8** %21, i64 %38
-  %40 = load i8*, i8** %39, align 8, !tbaa !434
+  %40 = load atomic i8*, i8** %39 unordered, align 8, !tbaa !438
   %41 = icmp eq i8* %40, null
   br i1 %41, label %.loopexit14, label %220
 
 .preheader18:                                     ; preds = %84, %23
   %42 = phi i64 [ %85, %84 ], [ 0, %23 ]
   %43 = getelementptr inbounds i8*, i8** %21, i64 %42
-  %44 = load i8*, i8** %43, align 8, !tbaa !434
+  %44 = load atomic i8*, i8** %43 unordered, align 8, !tbaa !438
   %45 = icmp eq i8* %44, null
   br i1 %45, label %.loopexit14, label %.preheader16
 
@@ -32514,7 +33078,7 @@
   %47 = phi i8* [ %65, %64 ], [ %11, %.preheader18 ]
   %48 = phi i8* [ %66, %64 ], [ %44, %.preheader18 ]
   %49 = phi i64 [ %67, %64 ], [ %18, %.preheader18 ]
-  %50 = load i8, i8* %48, align 1, !tbaa !454
+  %50 = load atomic i8, i8* %48 unordered, align 1, !tbaa !458
   %51 = icmp ne i8 %50, 0
   %52 = icmp ne i64 %49, 0
   %53 = and i1 %52, %51
@@ -32522,13 +33086,13 @@
 
 54:                                               ; preds = %.preheader16
   %55 = tail call i32** @__ctype_toupper_loc() #1
-  %56 = load i32*, i32** %55, align 8, !tbaa !434
+  %56 = load atomic i32*, i32** %55 unordered, align 8, !tbaa !438
   %57 = sext i8 %46 to i64
   %58 = getelementptr inbounds i32, i32* %56, i64 %57
-  %59 = load i32, i32* %58, align 4, !tbaa !459
+  %59 = load atomic i32, i32* %58 unordered, align 4, !tbaa !463
   %60 = sext i8 %50 to i64
   %61 = getelementptr inbounds i32, i32* %56, i64 %60
-  %62 = load i32, i32* %61, align 4, !tbaa !459
+  %62 = load atomic i32, i32* %61 unordered, align 4, !tbaa !463
   %63 = icmp eq i32 %59, %62
   br i1 %63, label %64, label %.loopexit17
 
@@ -32536,7 +33100,7 @@
   %65 = getelementptr inbounds i8, i8* %47, i64 1
   %66 = getelementptr inbounds i8, i8* %48, i64 1
   %67 = add i64 %49, -1
-  %68 = load i8, i8* %65, align 1, !tbaa !454
+  %68 = load atomic i8, i8* %65 unordered, align 1, !tbaa !458
   %69 = icmp eq i8 %68, 0
   br i1 %69, label %70, label %.preheader16
 
@@ -32548,7 +33112,7 @@
   br i1 %74, label %80, label %75
 
 75:                                               ; preds = %70
-  %76 = load i8, i8* %72, align 1, !tbaa !454
+  %76 = load atomic i8, i8* %72 unordered, align 1, !tbaa !458
   br label %.loopexit17
 
 .loopexit17:                                      ; preds = %75, %54
@@ -32559,7 +33123,7 @@
 
 80:                                               ; preds = %.loopexit17, %70
   %81 = getelementptr inbounds i8, i8* %44, i64 %18
-  %82 = load i8, i8* %81, align 1, !tbaa !454
+  %82 = load atomic i8, i8* %81 unordered, align 1, !tbaa !458
   %83 = icmp eq i8 %82, 61
   br i1 %83, label %.loopexit15, label %84
 
@@ -32572,10 +33136,10 @@
   %87 = phi i8* [ %40, %223 ], [ %28, %33 ], [ %44, %80 ]
   %88 = getelementptr inbounds i8, i8* %87, i64 %18
   %89 = getelementptr inbounds i8, i8* %88, i64 1
-  store i8 0, i8* %17, align 16, !tbaa !454
+  store i8 0, i8* %17, align 16, !tbaa !458
   %90 = call i8* @strncpy(i8* nonnull %17, i8* nonnull dereferenceable(1) %89, i64 64) #37
   %91 = getelementptr inbounds [65 x i8], [65 x i8]* %3, i64 0, i64 64
-  store i8 0, i8* %91, align 16, !tbaa !454
+  store i8 0, i8* %91, align 16, !tbaa !458
   %92 = call i64 @strlen(i8* nonnull %17) #54
   %93 = icmp ult i64 %92, 64
   %94 = select i1 %93, i64 %92, i64 64
@@ -32601,69 +33165,69 @@
 .preheader:                                       ; preds = %.preheader, %.loopexit12
   %105 = phi i64 [ %115, %.preheader ], [ %103, %.loopexit12 ]
   %106 = phi i64 [ %116, %.preheader ], [ %99, %.loopexit12 ]
-  %107 = load i32*, i32** %97, align 8, !tbaa !434
+  %107 = load atomic i32*, i32** %97 unordered, align 8, !tbaa !438
   %108 = getelementptr inbounds [65 x i8], [65 x i8]* %3, i64 0, i64 %105
-  %109 = load i8, i8* %108, align 1, !tbaa !454
+  %109 = load atomic i8, i8* %108 unordered, align 1, !tbaa !458
   %110 = sext i8 %109 to i64
   %111 = getelementptr inbounds i32, i32* %107, i64 %110
-  %112 = load i32, i32* %111, align 4, !tbaa !459
+  %112 = load atomic i32, i32* %111 unordered, align 4, !tbaa !463
   %113 = trunc i32 %112 to i8
   %114 = getelementptr inbounds [65 x i8], [65 x i8]* %2, i64 0, i64 %105
-  store i8 %113, i8* %114, align 1, !tbaa !454
+  store i8 %113, i8* %114, align 1, !tbaa !458
   %115 = add nuw nsw i64 %105, 1
   %116 = add nsw i64 %106, -1
   %117 = icmp eq i64 %116, 0
-  br i1 %117, label %.loopexit, label %.preheader, !llvm.loop !508
+  br i1 %117, label %.loopexit, label %.preheader, !llvm.loop !512
 
 .loopexit:                                        ; preds = %.preheader, %.loopexit12, %.loopexit15
   %118 = getelementptr inbounds [65 x i8], [65 x i8]* %2, i64 0, i64 %94
-  store i8 0, i8* %118, align 1, !tbaa !454
-  %119 = load i8, i8* %11, align 16, !tbaa !454
+  store i8 0, i8* %118, align 1, !tbaa !458
+  %119 = load atomic i8, i8* %11 unordered, align 16, !tbaa !458
   %120 = icmp eq i8 %119, 0
   br i1 %120, label %165, label %162
 
 121:                                              ; preds = %121, %101
   %122 = phi i64 [ 0, %101 ], [ %159, %121 ]
   %123 = phi i64 [ %102, %101 ], [ %160, %121 ]
-  %124 = load i32*, i32** %97, align 8, !tbaa !434
+  %124 = load atomic i32*, i32** %97 unordered, align 8, !tbaa !438
   %125 = getelementptr inbounds [65 x i8], [65 x i8]* %3, i64 0, i64 %122
-  %126 = load i8, i8* %125, align 4, !tbaa !454
+  %126 = load atomic i8, i8* %125 unordered, align 4, !tbaa !458
   %127 = sext i8 %126 to i64
   %128 = getelementptr inbounds i32, i32* %124, i64 %127
-  %129 = load i32, i32* %128, align 4, !tbaa !459
+  %129 = load atomic i32, i32* %128 unordered, align 4, !tbaa !463
   %130 = trunc i32 %129 to i8
   %131 = getelementptr inbounds [65 x i8], [65 x i8]* %2, i64 0, i64 %122
-  store i8 %130, i8* %131, align 4, !tbaa !454
+  store i8 %130, i8* %131, align 4, !tbaa !458
   %132 = or i64 %122, 1
-  %133 = load i32*, i32** %97, align 8, !tbaa !434
+  %133 = load atomic i32*, i32** %97 unordered, align 8, !tbaa !438
   %134 = getelementptr inbounds [65 x i8], [65 x i8]* %3, i64 0, i64 %132
-  %135 = load i8, i8* %134, align 1, !tbaa !454
+  %135 = load atomic i8, i8* %134 unordered, align 1, !tbaa !458
   %136 = sext i8 %135 to i64
   %137 = getelementptr inbounds i32, i32* %133, i64 %136
-  %138 = load i32, i32* %137, align 4, !tbaa !459
+  %138 = load atomic i32, i32* %137 unordered, align 4, !tbaa !463
   %139 = trunc i32 %138 to i8
   %140 = getelementptr inbounds [65 x i8], [65 x i8]* %2, i64 0, i64 %132
-  store i8 %139, i8* %140, align 1, !tbaa !454
+  store i8 %139, i8* %140, align 1, !tbaa !458
   %141 = or i64 %122, 2
-  %142 = load i32*, i32** %97, align 8, !tbaa !434
+  %142 = load atomic i32*, i32** %97 unordered, align 8, !tbaa !438
   %143 = getelementptr inbounds [65 x i8], [65 x i8]* %3, i64 0, i64 %141
-  %144 = load i8, i8* %143, align 2, !tbaa !454
+  %144 = load atomic i8, i8* %143 unordered, align 2, !tbaa !458
   %145 = sext i8 %144 to i64
   %146 = getelementptr inbounds i32, i32* %142, i64 %145
-  %147 = load i32, i32* %146, align 4, !tbaa !459
+  %147 = load atomic i32, i32* %146 unordered, align 4, !tbaa !463
   %148 = trunc i32 %147 to i8
   %149 = getelementptr inbounds [65 x i8], [65 x i8]* %2, i64 0, i64 %141
-  store i8 %148, i8* %149, align 2, !tbaa !454
+  store i8 %148, i8* %149, align 2, !tbaa !458
   %150 = or i64 %122, 3
-  %151 = load i32*, i32** %97, align 8, !tbaa !434
+  %151 = load atomic i32*, i32** %97 unordered, align 8, !tbaa !438
   %152 = getelementptr inbounds [65 x i8], [65 x i8]* %3, i64 0, i64 %150
-  %153 = load i8, i8* %152, align 1, !tbaa !454
+  %153 = load atomic i8, i8* %152 unordered, align 1, !tbaa !458
   %154 = sext i8 %153 to i64
   %155 = getelementptr inbounds i32, i32* %151, i64 %154
-  %156 = load i32, i32* %155, align 4, !tbaa !459
+  %156 = load atomic i32, i32* %155 unordered, align 4, !tbaa !463
   %157 = trunc i32 %156 to i8
   %158 = getelementptr inbounds [65 x i8], [65 x i8]* %2, i64 0, i64 %150
-  store i8 %157, i8* %158, align 1, !tbaa !454
+  store i8 %157, i8* %158, align 1, !tbaa !458
   %159 = add nuw nsw i64 %122, 4
   %160 = add i64 %123, -4
   %161 = icmp eq i64 %160, 0
@@ -32676,8 +33240,8 @@
 
 165:                                              ; preds = %162, %.loopexit
   %166 = getelementptr inbounds %struct.mi_option_desc_s, %struct.mi_option_desc_s* %6, i64 0, i32 0
-  store i64 1, i64* %166, align 8, !tbaa !427
-  store i32 2, i32* %7, align 8, !tbaa !433
+  store i64 1, i64* %166, align 8, !tbaa !431
+  store i32 2, i32* %7, align 8, !tbaa !437
   br label %216
 
 167:                                              ; preds = %162
@@ -32687,23 +33251,23 @@
 
 170:                                              ; preds = %167
   %171 = getelementptr inbounds %struct.mi_option_desc_s, %struct.mi_option_desc_s* %6, i64 0, i32 0
-  store i64 0, i64* %171, align 8, !tbaa !427
-  store i32 2, i32* %7, align 8, !tbaa !433
+  store i64 0, i64* %171, align 8, !tbaa !431
+  store i32 2, i32* %7, align 8, !tbaa !437
   br label %216
 
 172:                                              ; preds = %167
   %173 = bitcast i8** %4 to i8*
   call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %173) #37
-  store i8* %11, i8** %4, align 8, !tbaa !434
+  store i8* %11, i8** %4, align 8, !tbaa !438
   %174 = call i64 @strtol(i8* nonnull %11, i8** nonnull %4, i32 10) #37
   %175 = getelementptr inbounds [20 x %struct.mi_option_desc_s], [20 x %struct.mi_option_desc_s]* @options, i64 0, i64 %5, i32 2
-  %176 = load i32, i32* %175, align 4, !tbaa !509
+  %176 = load atomic i32, i32* %175 unordered, align 4, !tbaa !513
   %177 = icmp eq i32 %176, 8
-  %178 = load i8*, i8** %4, align 8, !tbaa !434
+  %178 = load atomic i8*, i8** %4 unordered, align 8, !tbaa !438
   br i1 %177, label %179, label %203
 
 179:                                              ; preds = %172
-  %180 = load i8, i8* %178, align 1, !tbaa !454
+  %180 = load atomic i8, i8* %178 unordered, align 1, !tbaa !458
   switch i8 %180, label %189 [
     i8 75, label %181
     i8 77, label %183
@@ -32712,19 +33276,19 @@
 
 181:                                              ; preds = %179
   %182 = getelementptr inbounds i8, i8* %178, i64 1
-  store i8* %182, i8** %4, align 8, !tbaa !434
+  store i8* %182, i8** %4, align 8, !tbaa !438
   br label %192
 
 183:                                              ; preds = %179
   %184 = shl i64 %174, 10
   %185 = getelementptr inbounds i8, i8* %178, i64 1
-  store i8* %185, i8** %4, align 8, !tbaa !434
+  store i8* %185, i8** %4, align 8, !tbaa !438
   br label %192
 
 186:                                              ; preds = %179
   %187 = shl i64 %174, 20
   %188 = getelementptr inbounds i8, i8* %178, i64 1
-  store i8* %188, i8** %4, align 8, !tbaa !434
+  store i8* %188, i8** %4, align 8, !tbaa !438
   br label %192
 
 189:                                              ; preds = %179
@@ -32735,7 +33299,7 @@
 192:                                              ; preds = %186, %183, %181
   %193 = phi i8* [ %188, %186 ], [ %185, %183 ], [ %182, %181 ]
   %194 = phi i64 [ %187, %186 ], [ %184, %183 ], [ %174, %181 ]
-  %195 = load i8, i8* %193, align 1, !tbaa !454
+  %195 = load atomic i8, i8* %193 unordered, align 1, !tbaa !458
   br label %196
 
 196:                                              ; preds = %192, %189
@@ -32747,23 +33311,23 @@
 
 201:                                              ; preds = %196
   %202 = getelementptr inbounds i8, i8* %198, i64 1
-  store i8* %202, i8** %4, align 8, !tbaa !434
+  store i8* %202, i8** %4, align 8, !tbaa !438
   br label %203
 
 203:                                              ; preds = %201, %196, %172
   %204 = phi i8* [ %202, %201 ], [ %198, %196 ], [ %178, %172 ]
   %205 = phi i64 [ %199, %201 ], [ %199, %196 ], [ %174, %172 ]
-  %206 = load i8, i8* %204, align 1, !tbaa !454
+  %206 = load atomic i8, i8* %204 unordered, align 1, !tbaa !458
   %207 = icmp eq i8 %206, 0
   br i1 %207, label %208, label %210
 
 208:                                              ; preds = %203
   %209 = getelementptr inbounds %struct.mi_option_desc_s, %struct.mi_option_desc_s* %6, i64 0, i32 0
-  store i64 %205, i64* %209, align 8, !tbaa !427
+  store i64 %205, i64* %209, align 8, !tbaa !431
   br label %212
 
 210:                                              ; preds = %203
-  %211 = load i8*, i8** %14, align 8, !tbaa !455
+  %211 = load atomic i8*, i8** %14 unordered, align 8, !tbaa !459
   call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([57 x i8], [57 x i8]* @.str.27.146, i64 0, i64 0), i8* %211, i8* nonnull %11) #37
   br label %212
 
@@ -32778,7 +33342,7 @@
   br i1 %214, label %215, label %216
 
 215:                                              ; preds = %.loopexit14
-  store i32 1, i32* %7, align 8, !tbaa !433
+  store i32 1, i32* %7, align 8, !tbaa !437
   br label %216
 
 216:                                              ; preds = %215, %.loopexit14, %212, %170, %165
@@ -32788,17 +33352,17 @@
 
 217:                                              ; preds = %216, %1
   %218 = getelementptr inbounds %struct.mi_option_desc_s, %struct.mi_option_desc_s* %6, i64 0, i32 0
-  %219 = load i64, i64* %218, align 8, !tbaa !427
+  %219 = load atomic i64, i64* %218 unordered, align 8, !tbaa !431
   ret i64 %219
 
 220:                                              ; preds = %37
-  %221 = load i8, i8* %40, align 1, !tbaa !454
+  %221 = load atomic i8, i8* %40 unordered, align 1, !tbaa !458
   %222 = icmp eq i8 %221, 0
   br i1 %222, label %223, label %227
 
 223:                                              ; preds = %220
   %224 = getelementptr inbounds i8, i8* %40, i64 %18
-  %225 = load i8, i8* %224, align 1, !tbaa !454
+  %225 = load atomic i8, i8* %224 unordered, align 1, !tbaa !458
   %226 = icmp eq i8 %225, 61
   br i1 %226, label %.loopexit15, label %227
 
@@ -32819,7 +33383,7 @@
   br i1 %7, label %8, label %10
 
 8:                                                ; preds = %6
-  %9 = load i64, i64* @os_page_size, align 8, !tbaa !453
+  %9 = load atomic i64, i64* @os_page_size unordered, align 8, !tbaa !457
   br label %17
 
 10:                                               ; preds = %6
@@ -32839,10 +33403,10 @@
   %18 = phi i64 [ %9, %8 ], [ 65536, %10 ], [ 262144, %12 ], [ %16, %14 ]
   %19 = xor i64 %18, -1
   %20 = icmp ugt i64 %19, %0
-  br i1 %20, label %21, label %32, !prof !436, !misexpect !285
+  br i1 %20, label %21, label %32, !prof !440, !misexpect !283
 
 21:                                               ; preds = %17
-  %22 = tail call i64 @llvm.ctpop.i64(i64 %18) #37, !range !481
+  %22 = tail call i64 @llvm.ctpop.i64(i64 %18) #37, !range !486
   %23 = icmp ult i64 %22, 2
   %24 = add i64 %0, -1
   %25 = add i64 %24, %18
@@ -32860,8 +33424,8 @@
 
 32:                                               ; preds = %29, %26, %17
   %33 = phi i64 [ %0, %17 ], [ %28, %26 ], [ %31, %29 ]
-  %34 = load i64, i64* @os_page_size, align 8, !tbaa !453
-  %35 = tail call i64 @llvm.ctpop.i64(i64 %34) #37, !range !481
+  %34 = load atomic i64, i64* @os_page_size unordered, align 8, !tbaa !457
+  %35 = tail call i64 @llvm.ctpop.i64(i64 %34) #37, !range !486
   %36 = icmp ult i64 %35, 2
   %37 = add i64 %34, -1
   %38 = add i64 %34, 4194303
@@ -32880,14 +33444,14 @@
 45:                                               ; preds = %42, %39
   %46 = phi i64 [ %41, %39 ], [ %44, %42 ]
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %4)
-  store i8 0, i8* %4, align 1, !tbaa !482
+  store i8 0, i8* %4, align 1, !tbaa !465
   %47 = icmp eq i8* %2, null
   br i1 %47, label %50, label %48
 
 48:                                               ; preds = %45
-  %49 = load i8, i8* %2, align 1, !tbaa !482, !range !72
-  store i8 %49, i8* %4, align 1, !tbaa !482
-  store i8 0, i8* %2, align 1, !tbaa !482
+  %49 = load atomic i8, i8* %2 unordered, align 1, !tbaa !465, !range !70
+  store i8 %49, i8* %4, align 1, !tbaa !465
+  store i8 0, i8* %2, align 1, !tbaa !465
   br label %50
 
 50:                                               ; preds = %48, %45
@@ -32896,7 +33460,7 @@
   %53 = icmp ne i8 %51, 0
   %54 = and i1 %53, %1
   %55 = icmp ule i64 %34, %46
-  %56 = tail call i64 @llvm.ctpop.i64(i64 %46) #37, !range !481
+  %56 = tail call i64 @llvm.ctpop.i64(i64 %46) #37, !range !486
   %57 = icmp ult i64 %56, 2
   %58 = and i1 %55, %57
   br i1 %58, label %59, label %362
@@ -32962,7 +33526,7 @@
 
 93:                                               ; preds = %92, %90
   %94 = phi i32 [ 1409548322, %92 ], [ 2013528098, %90 ]
-  store i8 1, i8* %52, align 1, !tbaa !482
+  store i8 1, i8* %52, align 1, !tbaa !465
   %95 = tail call fastcc i8* @mi_unix_mmapx(i64 %68, i64 %46, i32 %71, i32 %94) #37
   %96 = icmp eq i8* %95, null
   br i1 %96, label %97, label %122
@@ -32970,7 +33534,7 @@
 97:                                               ; preds = %93
   store i1 true, i1* @mi_unix_mmap.mi_huge_pages_available, align 1
   %98 = tail call i32* @__errno_location() #1
-  %99 = load i32, i32* %98, align 4, !tbaa !459
+  %99 = load atomic i32, i32* %98 unordered, align 4, !tbaa !463
   tail call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([83 x i8], [83 x i8]* @.str.5.71, i64 0, i64 0), i32 %99) #37
   %100 = tail call fastcc i8* @mi_unix_mmapx(i64 %68, i64 %46, i32 %71, i32 1409548322) #37
   %101 = icmp eq i8* %100, null
@@ -32981,7 +33545,7 @@
   br label %103
 
 103:                                              ; preds = %102, %84, %75, %73, %70
-  store i8 0, i8* %52, align 1, !tbaa !482
+  store i8 0, i8* %52, align 1, !tbaa !465
   %104 = tail call fastcc i8* @mi_unix_mmapx(i64 %68, i64 %46, i32 %71, i32 16418) #37
   br i1 %54, label %105, label %117
 
@@ -33006,7 +33570,7 @@
   br i1 %115, label %116, label %117
 
 116:                                              ; preds = %113
-  store i8 1, i8* %52, align 1, !tbaa !482
+  store i8 1, i8* %52, align 1, !tbaa !465
   br label %117
 
 117:                                              ; preds = %116, %113, %109, %107, %105, %103
@@ -33015,7 +33579,7 @@
 
 mi_unix_mmap.exit:                                ; preds = %117
   %119 = tail call i32* @__errno_location() #1
-  %120 = load i32, i32* %119, align 4, !tbaa !459
+  %120 = load atomic i32, i32* %119 unordered, align 4, !tbaa !463
   %121 = zext i1 %54 to i32
   tail call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([104 x i8], [104 x i8]* @.str.6.67, i64 0, i64 0), i64 %68, i32 %120, i8* null, i32 0, i32 %121) #37
   br label %362
@@ -33158,7 +33722,7 @@
 
 196:                                              ; preds = %_mi_stat_decrease.exit2
   %197 = tail call i32* @__errno_location() #1
-  %198 = load i32, i32* %197, align 4, !tbaa !459
+  %198 = load atomic i32, i32* %197 unordered, align 4, !tbaa !463
   %199 = tail call i8* @strerror(i32 %198) #37
   tail call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.7.68, i64 0, i64 0), i8* %199, i64 %157, i64 %68) #37
   br label %200
@@ -33182,14 +33746,14 @@
   br label %210
 
 210:                                              ; preds = %208, %206
-  store i8 0, i8* %52, align 1, !tbaa !482
+  store i8 0, i8* %52, align 1, !tbaa !465
   %211 = tail call fastcc i8* @mi_unix_mmapx(i64 %204, i64 %46, i32 %71, i32 16418) #37
   %212 = icmp eq i8* %211, null
   br i1 %212, label %213, label %216
 
 213:                                              ; preds = %210
   %214 = tail call i32* @__errno_location() #1
-  %215 = load i32, i32* %214, align 4, !tbaa !459
+  %215 = load atomic i32, i32* %214 unordered, align 4, !tbaa !463
   tail call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([104 x i8], [104 x i8]* @.str.6.67, i64 0, i64 0), i64 %204, i32 %215, i8* null, i32 0, i32 0) #37
   br label %362
 
@@ -33263,8 +33827,8 @@
   %255 = and i64 %253, %254
   %256 = inttoptr i64 %255 to i8*
   %257 = sub i64 %255, %251
-  %258 = load i64, i64* @os_page_size, align 8, !tbaa !453
-  %259 = tail call i64 @llvm.ctpop.i64(i64 %258) #37, !range !481
+  %258 = load atomic i64, i64* @os_page_size unordered, align 8, !tbaa !457
+  %259 = tail call i64 @llvm.ctpop.i64(i64 %258) #37, !range !486
   %260 = icmp ult i64 %259, 2
   %261 = add i64 %68, -1
   %262 = add i64 %261, %258
@@ -33356,7 +33920,7 @@
 
 311:                                              ; preds = %_mi_stat_decrease.exit6
   %312 = tail call i32* @__errno_location() #1
-  %313 = load i32, i32* %312, align 4, !tbaa !459
+  %313 = load atomic i32, i32* %312 unordered, align 4, !tbaa !463
   %314 = tail call i8* @strerror(i32 %313) #37
   tail call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.7.68, i64 0, i64 0), i8* %314, i64 %251, i64 %257) #37
   br label %315
@@ -33439,7 +34003,7 @@
 
 357:                                              ; preds = %_mi_stat_decrease.exit8
   %358 = tail call i32* @__errno_location() #1
-  %359 = load i32, i32* %358, align 4, !tbaa !459
+  %359 = load atomic i32, i32* %358 unordered, align 4, !tbaa !463
   %360 = tail call i8* @strerror(i32 %359) #37
   %361 = ptrtoint i8* %318 to i64
   tail call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.7.68, i64 0, i64 0), i8* %360, i64 %361, i64 %272) #37
@@ -33461,7 +34025,7 @@
   br i1 %2, label %3, label %5
 
 3:                                                ; preds = %1
-  %4 = load i64, i64* @os_page_size, align 8, !tbaa !453
+  %4 = load atomic i64, i64* @os_page_size unordered, align 8, !tbaa !457
   br label %12
 
 5:                                                ; preds = %1
@@ -33481,10 +34045,10 @@
   %13 = phi i64 [ %4, %3 ], [ 65536, %5 ], [ 262144, %7 ], [ %11, %9 ]
   %14 = xor i64 %13, -1
   %15 = icmp ugt i64 %14, %0
-  br i1 %15, label %16, label %30, !prof !436, !misexpect !285
+  br i1 %15, label %16, label %30, !prof !440, !misexpect !283
 
 16:                                               ; preds = %12
-  %17 = tail call i64 @llvm.ctpop.i64(i64 %13) #37, !range !481
+  %17 = tail call i64 @llvm.ctpop.i64(i64 %13) #37, !range !486
   %18 = icmp ult i64 %17, 2
   %19 = add i64 %0, -1
   %20 = add i64 %19, %13
@@ -33523,7 +34087,7 @@
 
 40:                                               ; preds = %35
   %41 = tail call i32* @__errno_location() #1
-  %42 = load i32, i32* %41, align 4, !tbaa !459
+  %42 = load atomic i32, i32* %41 unordered, align 4, !tbaa !463
   tail call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([104 x i8], [104 x i8]* @.str.6.67, i64 0, i64 0), i64 %31, i32 %42, i8* null, i32 0, i32 0) #37
   br label %_mi_stat_increase.exit1
 
@@ -33607,7 +34171,7 @@
   br i1 %8, label %9, label %11
 
 9:                                                ; preds = %7
-  %10 = load i64, i64* @os_page_size, align 8, !tbaa !453
+  %10 = load atomic i64, i64* @os_page_size unordered, align 8, !tbaa !457
   br label %18
 
 11:                                               ; preds = %7
@@ -33627,10 +34191,10 @@
   %19 = phi i64 [ %10, %9 ], [ 65536, %11 ], [ 262144, %13 ], [ %17, %15 ]
   %20 = xor i64 %19, -1
   %21 = icmp ugt i64 %20, %1
-  br i1 %21, label %22, label %36, !prof !436, !misexpect !285
+  br i1 %21, label %22, label %36, !prof !440, !misexpect !283
 
 22:                                               ; preds = %18
-  %23 = tail call i64 @llvm.ctpop.i64(i64 %19) #37, !range !481
+  %23 = tail call i64 @llvm.ctpop.i64(i64 %19) #37, !range !486
   %24 = icmp ult i64 %23, 2
   %25 = add i64 %1, -1
   %26 = add i64 %25, %19
@@ -33722,7 +34286,7 @@
 
 74:                                               ; preds = %_mi_stat_decrease.exit1
   %75 = tail call i32* @__errno_location() #1
-  %76 = load i32, i32* %75, align 4, !tbaa !459
+  %76 = load atomic i32, i32* %75 unordered, align 4, !tbaa !463
   %77 = tail call i8* @strerror(i32 %76) #37
   %78 = ptrtoint i8* %0 to i64
   tail call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.7.68, i64 0, i64 0), i8* %77, i64 %78, i64 %37) #37
@@ -33781,16 +34345,16 @@
   br label %47
 
 30:                                               ; preds = %5
-  %31 = load i64, i64* %9, align 8, !tbaa !510
+  %31 = load atomic i64, i64* %9 unordered, align 8, !tbaa !514
   %32 = sub i64 %31, %1
-  store i64 %32, i64* %9, align 8, !tbaa !510
+  store i64 %32, i64* %9, align 8, !tbaa !514
   %33 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 2
-  %34 = load i64, i64* %33, align 8, !tbaa !511
+  %34 = load atomic i64, i64* %33 unordered, align 8, !tbaa !515
   %35 = icmp sgt i64 %32, %34
   br i1 %35, label %36, label %37
 
 36:                                               ; preds = %30
-  store i64 %32, i64* %33, align 8, !tbaa !511
+  store i64 %32, i64* %33, align 8, !tbaa !515
   br label %37
 
 37:                                               ; preds = %36, %30
@@ -33799,16 +34363,16 @@
 
 39:                                               ; preds = %37
   %40 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 0
-  %41 = load i64, i64* %40, align 8, !tbaa !512
+  %41 = load atomic i64, i64* %40 unordered, align 8, !tbaa !516
   %42 = sub i64 %41, %1
-  store i64 %42, i64* %40, align 8, !tbaa !512
+  store i64 %42, i64* %40, align 8, !tbaa !516
   br label %47
 
 43:                                               ; preds = %37
   %44 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 1
-  %45 = load i64, i64* %44, align 8, !tbaa !513
+  %45 = load atomic i64, i64* %44 unordered, align 8, !tbaa !517
   %46 = add i64 %45, %1
-  store i64 %46, i64* %44, align 8, !tbaa !513
+  store i64 %46, i64* %44, align 8, !tbaa !517
   br label %47
 
 47:                                               ; preds = %43, %39, %27, %24, %2
@@ -33830,7 +34394,7 @@
 
 9:                                                ; preds = %6, %1
   %10 = atomicrmw add i64* @warning_count, i64 1 acq_rel, align 8
-  %11 = load i64, i64* @mi_max_warning_count, align 8, !tbaa !453
+  %11 = load atomic i64, i64* @mi_max_warning_count unordered, align 8, !tbaa !457
   %12 = icmp ugt i64 %10, %11
   br i1 %12, label %28, label %13
 
@@ -33854,7 +34418,7 @@
   store i1 true, i1* @recurse, align 1
   %22 = load atomic i64, i64* bitcast (i8** @mi_out_arg to i64*) acquire, align 8
   %23 = inttoptr i64 %22 to i8*
-  %24 = load volatile void (i8*, i8*)*, void (i8*, i8*)** @mi_out_default, align 8, !tbaa !434
+  %24 = load atomic volatile void (i8*, i8*)*, void (i8*, i8*)** @mi_out_default unordered, align 8, !tbaa !438
   %25 = icmp eq void (i8*, i8*)* %24, null
   %26 = select i1 %25, void (i8*, i8*)* @mi_out_buf, void (i8*, i8*)* %24
   call void %26(i8* nonnull getelementptr inbounds ([20 x i8], [20 x i8]* @.str.2.149, i64 0, i64 0), i8* %23) #37
@@ -33960,16 +34524,16 @@
   br label %47
 
 30:                                               ; preds = %4
-  %31 = load i64, i64* %8, align 8, !tbaa !510
+  %31 = load atomic i64, i64* %8 unordered, align 8, !tbaa !514
   %32 = add nsw i64 %31, %1
-  store i64 %32, i64* %8, align 8, !tbaa !510
+  store i64 %32, i64* %8, align 8, !tbaa !514
   %33 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 2
-  %34 = load i64, i64* %33, align 8, !tbaa !511
+  %34 = load atomic i64, i64* %33 unordered, align 8, !tbaa !515
   %35 = icmp sgt i64 %32, %34
   br i1 %35, label %36, label %37
 
 36:                                               ; preds = %30
-  store i64 %32, i64* %33, align 8, !tbaa !511
+  store i64 %32, i64* %33, align 8, !tbaa !515
   br label %37
 
 37:                                               ; preds = %36, %30
@@ -33978,16 +34542,16 @@
 
 39:                                               ; preds = %37
   %40 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 0
-  %41 = load i64, i64* %40, align 8, !tbaa !512
+  %41 = load atomic i64, i64* %40 unordered, align 8, !tbaa !516
   %42 = add nsw i64 %41, %1
-  store i64 %42, i64* %40, align 8, !tbaa !512
+  store i64 %42, i64* %40, align 8, !tbaa !516
   br label %47
 
 43:                                               ; preds = %37
   %44 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 1
-  %45 = load i64, i64* %44, align 8, !tbaa !513
+  %45 = load atomic i64, i64* %44 unordered, align 8, !tbaa !517
   %46 = sub i64 %45, %1
-  store i64 %46, i64* %44, align 8, !tbaa !513
+  store i64 %46, i64* %44, align 8, !tbaa !517
   br label %47
 
 47:                                               ; preds = %43, %39, %26, %23, %2
@@ -34012,7 +34576,7 @@
   br i1 %15, label %16, label %25
 
 16:                                               ; preds = %12
-  %17 = load %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !434
+  %17 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default unordered, align 8, !tbaa !438
   %18 = tail call fastcc i64 @_mi_heap_random_next(%struct.mi_heap_s* %17) #37
   %19 = shl i64 %18, 5
   %20 = and i64 %19, 4398042316800
@@ -34146,7 +34710,7 @@
 
 12:                                               ; preds = %9, %2
   %13 = atomicrmw add i64* @error_count, i64 1 acq_rel, align 8
-  %14 = load i64, i64* @mi_max_error_count, align 8, !tbaa !453
+  %14 = load atomic i64, i64* @mi_max_error_count unordered, align 8, !tbaa !457
   %15 = icmp ugt i64 %13, %14
   br i1 %15, label %29, label %16
 
@@ -34166,7 +34730,7 @@
   store i1 true, i1* @recurse, align 1
   %23 = load atomic i64, i64* bitcast (i8** @mi_out_arg to i64*) acquire, align 8
   %24 = inttoptr i64 %23 to i8*
-  %25 = load volatile void (i8*, i8*)*, void (i8*, i8*)** @mi_out_default, align 8, !tbaa !434
+  %25 = load atomic volatile void (i8*, i8*)*, void (i8*, i8*)** @mi_out_default unordered, align 8, !tbaa !438
   %26 = icmp eq void (i8*, i8*)* %25, null
   %27 = select i1 %26, void (i8*, i8*)* @mi_out_buf, void (i8*, i8*)* %25
   call void %27(i8* nonnull getelementptr inbounds ([18 x i8], [18 x i8]* @.str.23.158, i64 0, i64 0), i8* %24) #37
@@ -34180,12 +34744,12 @@
 
 29:                                               ; preds = %28, %12, %9
   call void @llvm.va_end(i8* nonnull %5)
-  %30 = load volatile void (i32, i8*)*, void (i32, i8*)** @mi_error_handler, align 8, !tbaa !434
+  %30 = load atomic volatile void (i32, i8*)*, void (i32, i8*)** @mi_error_handler unordered, align 8, !tbaa !438
   %31 = icmp eq void (i32, i8*)* %30, null
   br i1 %31, label %36, label %32
 
 32:                                               ; preds = %29
-  %33 = load volatile void (i32, i8*)*, void (i32, i8*)** @mi_error_handler, align 8, !tbaa !434
+  %33 = load atomic volatile void (i32, i8*)*, void (i32, i8*)** @mi_error_handler unordered, align 8, !tbaa !438
   %34 = load atomic i64, i64* bitcast (i8** @mi_error_arg to i64*) acquire, align 8
   %35 = inttoptr i64 %34 to i8*
   call void %33(i32 %0, i8* %35) #37
@@ -34206,402 +34770,402 @@
 
 3:                                                ; preds = %1
   %4 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 0, i32 0
-  %5 = load i64, i64* %4, align 8, !tbaa !512
+  %5 = load atomic i64, i64* %4 unordered, align 8, !tbaa !516
   %6 = icmp eq i64 %5, 0
   br i1 %6, label %7, label %11
 
 7:                                                ; preds = %3
   %8 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 0, i32 1
-  %9 = load i64, i64* %8, align 8, !tbaa !513
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !517
   %10 = icmp eq i64 %9, 0
   br i1 %10, label %22, label %11
 
 11:                                               ; preds = %7, %3
   %12 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0, i32 0), i64 %5 monotonic, align 8
   %13 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 0, i32 3
-  %14 = load i64, i64* %13, align 8, !tbaa !510
+  %14 = load atomic i64, i64* %13 unordered, align 8, !tbaa !514
   %15 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0, i32 3), i64 %14 monotonic, align 8
   %16 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 0, i32 1
-  %17 = load i64, i64* %16, align 8, !tbaa !513
+  %17 = load atomic i64, i64* %16 unordered, align 8, !tbaa !517
   %18 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0, i32 1), i64 %17 monotonic, align 8
   %19 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 0, i32 2
-  %20 = load i64, i64* %19, align 8, !tbaa !511
+  %20 = load atomic i64, i64* %19 unordered, align 8, !tbaa !515
   %21 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0, i32 2), i64 %20 monotonic, align 8
   br label %22
 
 22:                                               ; preds = %11, %7
   %23 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 1, i32 0
-  %24 = load i64, i64* %23, align 8, !tbaa !512
+  %24 = load atomic i64, i64* %23 unordered, align 8, !tbaa !516
   %25 = icmp eq i64 %24, 0
   br i1 %25, label %26, label %30
 
 26:                                               ; preds = %22
   %27 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 1, i32 1
-  %28 = load i64, i64* %27, align 8, !tbaa !513
+  %28 = load atomic i64, i64* %27 unordered, align 8, !tbaa !517
   %29 = icmp eq i64 %28, 0
   br i1 %29, label %41, label %30
 
 30:                                               ; preds = %26, %22
   %31 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 1, i32 0), i64 %24 monotonic, align 8
   %32 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 1, i32 3
-  %33 = load i64, i64* %32, align 8, !tbaa !510
+  %33 = load atomic i64, i64* %32 unordered, align 8, !tbaa !514
   %34 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 1, i32 3), i64 %33 monotonic, align 8
   %35 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 1, i32 1
-  %36 = load i64, i64* %35, align 8, !tbaa !513
+  %36 = load atomic i64, i64* %35 unordered, align 8, !tbaa !517
   %37 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 1, i32 1), i64 %36 monotonic, align 8
   %38 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 1, i32 2
-  %39 = load i64, i64* %38, align 8, !tbaa !511
+  %39 = load atomic i64, i64* %38 unordered, align 8, !tbaa !515
   %40 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 1, i32 2), i64 %39 monotonic, align 8
   br label %41
 
 41:                                               ; preds = %30, %26
   %42 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 2, i32 0
-  %43 = load i64, i64* %42, align 8, !tbaa !512
+  %43 = load atomic i64, i64* %42 unordered, align 8, !tbaa !516
   %44 = icmp eq i64 %43, 0
   br i1 %44, label %45, label %49
 
 45:                                               ; preds = %41
   %46 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 2, i32 1
-  %47 = load i64, i64* %46, align 8, !tbaa !513
+  %47 = load atomic i64, i64* %46 unordered, align 8, !tbaa !517
   %48 = icmp eq i64 %47, 0
   br i1 %48, label %60, label %49
 
 49:                                               ; preds = %45, %41
   %50 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 0), i64 %43 monotonic, align 8
   %51 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 2, i32 3
-  %52 = load i64, i64* %51, align 8, !tbaa !510
+  %52 = load atomic i64, i64* %51 unordered, align 8, !tbaa !514
   %53 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 3), i64 %52 monotonic, align 8
   %54 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 2, i32 1
-  %55 = load i64, i64* %54, align 8, !tbaa !513
+  %55 = load atomic i64, i64* %54 unordered, align 8, !tbaa !517
   %56 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 1), i64 %55 monotonic, align 8
   %57 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 2, i32 2
-  %58 = load i64, i64* %57, align 8, !tbaa !511
+  %58 = load atomic i64, i64* %57 unordered, align 8, !tbaa !515
   %59 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 2, i32 2), i64 %58 monotonic, align 8
   br label %60
 
 60:                                               ; preds = %49, %45
   %61 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 3, i32 0
-  %62 = load i64, i64* %61, align 8, !tbaa !512
+  %62 = load atomic i64, i64* %61 unordered, align 8, !tbaa !516
   %63 = icmp eq i64 %62, 0
   br i1 %63, label %64, label %68
 
 64:                                               ; preds = %60
   %65 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 3, i32 1
-  %66 = load i64, i64* %65, align 8, !tbaa !513
+  %66 = load atomic i64, i64* %65 unordered, align 8, !tbaa !517
   %67 = icmp eq i64 %66, 0
   br i1 %67, label %79, label %68
 
 68:                                               ; preds = %64, %60
   %69 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 0), i64 %62 monotonic, align 8
   %70 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 3, i32 3
-  %71 = load i64, i64* %70, align 8, !tbaa !510
+  %71 = load atomic i64, i64* %70 unordered, align 8, !tbaa !514
   %72 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 3), i64 %71 monotonic, align 8
   %73 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 3, i32 1
-  %74 = load i64, i64* %73, align 8, !tbaa !513
+  %74 = load atomic i64, i64* %73 unordered, align 8, !tbaa !517
   %75 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 1), i64 %74 monotonic, align 8
   %76 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 3, i32 2
-  %77 = load i64, i64* %76, align 8, !tbaa !511
+  %77 = load atomic i64, i64* %76 unordered, align 8, !tbaa !515
   %78 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 3, i32 2), i64 %77 monotonic, align 8
   br label %79
 
 79:                                               ; preds = %68, %64
   %80 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 4, i32 0
-  %81 = load i64, i64* %80, align 8, !tbaa !512
+  %81 = load atomic i64, i64* %80 unordered, align 8, !tbaa !516
   %82 = icmp eq i64 %81, 0
   br i1 %82, label %83, label %87
 
 83:                                               ; preds = %79
   %84 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 4, i32 1
-  %85 = load i64, i64* %84, align 8, !tbaa !513
+  %85 = load atomic i64, i64* %84 unordered, align 8, !tbaa !517
   %86 = icmp eq i64 %85, 0
   br i1 %86, label %98, label %87
 
 87:                                               ; preds = %83, %79
   %88 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 4, i32 0), i64 %81 monotonic, align 8
   %89 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 4, i32 3
-  %90 = load i64, i64* %89, align 8, !tbaa !510
+  %90 = load atomic i64, i64* %89 unordered, align 8, !tbaa !514
   %91 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 4, i32 3), i64 %90 monotonic, align 8
   %92 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 4, i32 1
-  %93 = load i64, i64* %92, align 8, !tbaa !513
+  %93 = load atomic i64, i64* %92 unordered, align 8, !tbaa !517
   %94 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 4, i32 1), i64 %93 monotonic, align 8
   %95 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 4, i32 2
-  %96 = load i64, i64* %95, align 8, !tbaa !511
+  %96 = load atomic i64, i64* %95 unordered, align 8, !tbaa !515
   %97 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 4, i32 2), i64 %96 monotonic, align 8
   br label %98
 
 98:                                               ; preds = %87, %83
   %99 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 5, i32 0
-  %100 = load i64, i64* %99, align 8, !tbaa !512
+  %100 = load atomic i64, i64* %99 unordered, align 8, !tbaa !516
   %101 = icmp eq i64 %100, 0
   br i1 %101, label %102, label %106
 
 102:                                              ; preds = %98
   %103 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 5, i32 1
-  %104 = load i64, i64* %103, align 8, !tbaa !513
+  %104 = load atomic i64, i64* %103 unordered, align 8, !tbaa !517
   %105 = icmp eq i64 %104, 0
   br i1 %105, label %117, label %106
 
 106:                                              ; preds = %102, %98
   %107 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 5, i32 0), i64 %100 monotonic, align 8
   %108 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 5, i32 3
-  %109 = load i64, i64* %108, align 8, !tbaa !510
+  %109 = load atomic i64, i64* %108 unordered, align 8, !tbaa !514
   %110 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 5, i32 3), i64 %109 monotonic, align 8
   %111 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 5, i32 1
-  %112 = load i64, i64* %111, align 8, !tbaa !513
+  %112 = load atomic i64, i64* %111 unordered, align 8, !tbaa !517
   %113 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 5, i32 1), i64 %112 monotonic, align 8
   %114 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 5, i32 2
-  %115 = load i64, i64* %114, align 8, !tbaa !511
+  %115 = load atomic i64, i64* %114 unordered, align 8, !tbaa !515
   %116 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 5, i32 2), i64 %115 monotonic, align 8
   br label %117
 
 117:                                              ; preds = %106, %102
   %118 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 7, i32 0
-  %119 = load i64, i64* %118, align 8, !tbaa !512
+  %119 = load atomic i64, i64* %118 unordered, align 8, !tbaa !516
   %120 = icmp eq i64 %119, 0
   br i1 %120, label %121, label %125
 
 121:                                              ; preds = %117
   %122 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 7, i32 1
-  %123 = load i64, i64* %122, align 8, !tbaa !513
+  %123 = load atomic i64, i64* %122 unordered, align 8, !tbaa !517
   %124 = icmp eq i64 %123, 0
   br i1 %124, label %136, label %125
 
 125:                                              ; preds = %121, %117
   %126 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 7, i32 0), i64 %119 monotonic, align 8
   %127 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 7, i32 3
-  %128 = load i64, i64* %127, align 8, !tbaa !510
+  %128 = load atomic i64, i64* %127 unordered, align 8, !tbaa !514
   %129 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 7, i32 3), i64 %128 monotonic, align 8
   %130 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 7, i32 1
-  %131 = load i64, i64* %130, align 8, !tbaa !513
+  %131 = load atomic i64, i64* %130 unordered, align 8, !tbaa !517
   %132 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 7, i32 1), i64 %131 monotonic, align 8
   %133 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 7, i32 2
-  %134 = load i64, i64* %133, align 8, !tbaa !511
+  %134 = load atomic i64, i64* %133 unordered, align 8, !tbaa !515
   %135 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 7, i32 2), i64 %134 monotonic, align 8
   br label %136
 
 136:                                              ; preds = %125, %121
   %137 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 6, i32 0
-  %138 = load i64, i64* %137, align 8, !tbaa !512
+  %138 = load atomic i64, i64* %137 unordered, align 8, !tbaa !516
   %139 = icmp eq i64 %138, 0
   br i1 %139, label %140, label %144
 
 140:                                              ; preds = %136
   %141 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 6, i32 1
-  %142 = load i64, i64* %141, align 8, !tbaa !513
+  %142 = load atomic i64, i64* %141 unordered, align 8, !tbaa !517
   %143 = icmp eq i64 %142, 0
   br i1 %143, label %155, label %144
 
 144:                                              ; preds = %140, %136
   %145 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 6, i32 0), i64 %138 monotonic, align 8
   %146 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 6, i32 3
-  %147 = load i64, i64* %146, align 8, !tbaa !510
+  %147 = load atomic i64, i64* %146 unordered, align 8, !tbaa !514
   %148 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 6, i32 3), i64 %147 monotonic, align 8
   %149 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 6, i32 1
-  %150 = load i64, i64* %149, align 8, !tbaa !513
+  %150 = load atomic i64, i64* %149 unordered, align 8, !tbaa !517
   %151 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 6, i32 1), i64 %150 monotonic, align 8
   %152 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 6, i32 2
-  %153 = load i64, i64* %152, align 8, !tbaa !511
+  %153 = load atomic i64, i64* %152 unordered, align 8, !tbaa !515
   %154 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 6, i32 2), i64 %153 monotonic, align 8
   br label %155
 
 155:                                              ; preds = %144, %140
   %156 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 8, i32 0
-  %157 = load i64, i64* %156, align 8, !tbaa !512
+  %157 = load atomic i64, i64* %156 unordered, align 8, !tbaa !516
   %158 = icmp eq i64 %157, 0
   br i1 %158, label %159, label %163
 
 159:                                              ; preds = %155
   %160 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 8, i32 1
-  %161 = load i64, i64* %160, align 8, !tbaa !513
+  %161 = load atomic i64, i64* %160 unordered, align 8, !tbaa !517
   %162 = icmp eq i64 %161, 0
   br i1 %162, label %174, label %163
 
 163:                                              ; preds = %159, %155
   %164 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 8, i32 0), i64 %157 monotonic, align 8
   %165 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 8, i32 3
-  %166 = load i64, i64* %165, align 8, !tbaa !510
+  %166 = load atomic i64, i64* %165 unordered, align 8, !tbaa !514
   %167 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 8, i32 3), i64 %166 monotonic, align 8
   %168 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 8, i32 1
-  %169 = load i64, i64* %168, align 8, !tbaa !513
+  %169 = load atomic i64, i64* %168 unordered, align 8, !tbaa !517
   %170 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 8, i32 1), i64 %169 monotonic, align 8
   %171 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 8, i32 2
-  %172 = load i64, i64* %171, align 8, !tbaa !511
+  %172 = load atomic i64, i64* %171 unordered, align 8, !tbaa !515
   %173 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 8, i32 2), i64 %172 monotonic, align 8
   br label %174
 
 174:                                              ; preds = %163, %159
   %175 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 12, i32 0
-  %176 = load i64, i64* %175, align 8, !tbaa !512
+  %176 = load atomic i64, i64* %175 unordered, align 8, !tbaa !516
   %177 = icmp eq i64 %176, 0
   br i1 %177, label %178, label %182
 
 178:                                              ; preds = %174
   %179 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 12, i32 1
-  %180 = load i64, i64* %179, align 8, !tbaa !513
+  %180 = load atomic i64, i64* %179 unordered, align 8, !tbaa !517
   %181 = icmp eq i64 %180, 0
   br i1 %181, label %193, label %182
 
 182:                                              ; preds = %178, %174
   %183 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 12, i32 0), i64 %176 monotonic, align 8
   %184 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 12, i32 3
-  %185 = load i64, i64* %184, align 8, !tbaa !510
+  %185 = load atomic i64, i64* %184 unordered, align 8, !tbaa !514
   %186 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 12, i32 3), i64 %185 monotonic, align 8
   %187 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 12, i32 1
-  %188 = load i64, i64* %187, align 8, !tbaa !513
+  %188 = load atomic i64, i64* %187 unordered, align 8, !tbaa !517
   %189 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 12, i32 1), i64 %188 monotonic, align 8
   %190 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 12, i32 2
-  %191 = load i64, i64* %190, align 8, !tbaa !511
+  %191 = load atomic i64, i64* %190 unordered, align 8, !tbaa !515
   %192 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 12, i32 2), i64 %191 monotonic, align 8
   br label %193
 
 193:                                              ; preds = %182, %178
   %194 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 13, i32 0
-  %195 = load i64, i64* %194, align 8, !tbaa !512
+  %195 = load atomic i64, i64* %194 unordered, align 8, !tbaa !516
   %196 = icmp eq i64 %195, 0
   br i1 %196, label %197, label %201
 
 197:                                              ; preds = %193
   %198 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 13, i32 1
-  %199 = load i64, i64* %198, align 8, !tbaa !513
+  %199 = load atomic i64, i64* %198 unordered, align 8, !tbaa !517
   %200 = icmp eq i64 %199, 0
   br i1 %200, label %212, label %201
 
 201:                                              ; preds = %197, %193
   %202 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 13, i32 0), i64 %195 monotonic, align 8
   %203 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 13, i32 3
-  %204 = load i64, i64* %203, align 8, !tbaa !510
+  %204 = load atomic i64, i64* %203 unordered, align 8, !tbaa !514
   %205 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 13, i32 3), i64 %204 monotonic, align 8
   %206 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 13, i32 1
-  %207 = load i64, i64* %206, align 8, !tbaa !513
+  %207 = load atomic i64, i64* %206 unordered, align 8, !tbaa !517
   %208 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 13, i32 1), i64 %207 monotonic, align 8
   %209 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 13, i32 2
-  %210 = load i64, i64* %209, align 8, !tbaa !511
+  %210 = load atomic i64, i64* %209 unordered, align 8, !tbaa !515
   %211 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 13, i32 2), i64 %210 monotonic, align 8
   br label %212
 
 212:                                              ; preds = %201, %197
   %213 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 9, i32 0
-  %214 = load i64, i64* %213, align 8, !tbaa !512
+  %214 = load atomic i64, i64* %213 unordered, align 8, !tbaa !516
   %215 = icmp eq i64 %214, 0
   br i1 %215, label %216, label %220
 
 216:                                              ; preds = %212
   %217 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 9, i32 1
-  %218 = load i64, i64* %217, align 8, !tbaa !513
+  %218 = load atomic i64, i64* %217 unordered, align 8, !tbaa !517
   %219 = icmp eq i64 %218, 0
   br i1 %219, label %231, label %220
 
 220:                                              ; preds = %216, %212
   %221 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 9, i32 0), i64 %214 monotonic, align 8
   %222 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 9, i32 3
-  %223 = load i64, i64* %222, align 8, !tbaa !510
+  %223 = load atomic i64, i64* %222 unordered, align 8, !tbaa !514
   %224 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 9, i32 3), i64 %223 monotonic, align 8
   %225 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 9, i32 1
-  %226 = load i64, i64* %225, align 8, !tbaa !513
+  %226 = load atomic i64, i64* %225 unordered, align 8, !tbaa !517
   %227 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 9, i32 1), i64 %226 monotonic, align 8
   %228 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 9, i32 2
-  %229 = load i64, i64* %228, align 8, !tbaa !511
+  %229 = load atomic i64, i64* %228 unordered, align 8, !tbaa !515
   %230 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 9, i32 2), i64 %229 monotonic, align 8
   br label %231
 
 231:                                              ; preds = %220, %216
   %232 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 10, i32 0
-  %233 = load i64, i64* %232, align 8, !tbaa !512
+  %233 = load atomic i64, i64* %232 unordered, align 8, !tbaa !516
   %234 = icmp eq i64 %233, 0
   br i1 %234, label %235, label %239
 
 235:                                              ; preds = %231
   %236 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 10, i32 1
-  %237 = load i64, i64* %236, align 8, !tbaa !513
+  %237 = load atomic i64, i64* %236 unordered, align 8, !tbaa !517
   %238 = icmp eq i64 %237, 0
   br i1 %238, label %250, label %239
 
 239:                                              ; preds = %235, %231
   %240 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 10, i32 0), i64 %233 monotonic, align 8
   %241 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 10, i32 3
-  %242 = load i64, i64* %241, align 8, !tbaa !510
+  %242 = load atomic i64, i64* %241 unordered, align 8, !tbaa !514
   %243 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 10, i32 3), i64 %242 monotonic, align 8
   %244 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 10, i32 1
-  %245 = load i64, i64* %244, align 8, !tbaa !513
+  %245 = load atomic i64, i64* %244 unordered, align 8, !tbaa !517
   %246 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 10, i32 1), i64 %245 monotonic, align 8
   %247 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 10, i32 2
-  %248 = load i64, i64* %247, align 8, !tbaa !511
+  %248 = load atomic i64, i64* %247 unordered, align 8, !tbaa !515
   %249 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 10, i32 2), i64 %248 monotonic, align 8
   br label %250
 
 250:                                              ; preds = %239, %235
   %251 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 11, i32 0
-  %252 = load i64, i64* %251, align 8, !tbaa !512
+  %252 = load atomic i64, i64* %251 unordered, align 8, !tbaa !516
   %253 = icmp eq i64 %252, 0
   br i1 %253, label %254, label %258
 
 254:                                              ; preds = %250
   %255 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 11, i32 1
-  %256 = load i64, i64* %255, align 8, !tbaa !513
+  %256 = load atomic i64, i64* %255 unordered, align 8, !tbaa !517
   %257 = icmp eq i64 %256, 0
   br i1 %257, label %269, label %258
 
 258:                                              ; preds = %254, %250
   %259 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 11, i32 0), i64 %252 monotonic, align 8
   %260 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 11, i32 3
-  %261 = load i64, i64* %260, align 8, !tbaa !510
+  %261 = load atomic i64, i64* %260 unordered, align 8, !tbaa !514
   %262 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 11, i32 3), i64 %261 monotonic, align 8
   %263 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 11, i32 1
-  %264 = load i64, i64* %263, align 8, !tbaa !513
+  %264 = load atomic i64, i64* %263 unordered, align 8, !tbaa !517
   %265 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 11, i32 1), i64 %264 monotonic, align 8
   %266 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 11, i32 2
-  %267 = load i64, i64* %266, align 8, !tbaa !511
+  %267 = load atomic i64, i64* %266 unordered, align 8, !tbaa !515
   %268 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 11, i32 2), i64 %267 monotonic, align 8
   br label %269
 
 269:                                              ; preds = %258, %254
   %270 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 14, i32 0
-  %271 = load i64, i64* %270, align 8, !tbaa !466
+  %271 = load atomic i64, i64* %270 unordered, align 8, !tbaa !471
   %272 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 14, i32 0), i64 %271 monotonic, align 8
   %273 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 14, i32 1
-  %274 = load i64, i64* %273, align 8, !tbaa !464
+  %274 = load atomic i64, i64* %273 unordered, align 8, !tbaa !469
   %275 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 14, i32 1), i64 %274 monotonic, align 8
   %276 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 15, i32 0
-  %277 = load i64, i64* %276, align 8, !tbaa !466
+  %277 = load atomic i64, i64* %276 unordered, align 8, !tbaa !471
   %278 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 15, i32 0), i64 %277 monotonic, align 8
   %279 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 15, i32 1
-  %280 = load i64, i64* %279, align 8, !tbaa !464
+  %280 = load atomic i64, i64* %279 unordered, align 8, !tbaa !469
   %281 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 15, i32 1), i64 %280 monotonic, align 8
   %282 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 16, i32 0
-  %283 = load i64, i64* %282, align 8, !tbaa !466
+  %283 = load atomic i64, i64* %282 unordered, align 8, !tbaa !471
   %284 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 16, i32 0), i64 %283 monotonic, align 8
   %285 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 16, i32 1
-  %286 = load i64, i64* %285, align 8, !tbaa !464
+  %286 = load atomic i64, i64* %285 unordered, align 8, !tbaa !469
   %287 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 16, i32 1), i64 %286 monotonic, align 8
   %288 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 17, i32 0
-  %289 = load i64, i64* %288, align 8, !tbaa !466
+  %289 = load atomic i64, i64* %288 unordered, align 8, !tbaa !471
   %290 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 17, i32 0), i64 %289 monotonic, align 8
   %291 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 17, i32 1
-  %292 = load i64, i64* %291, align 8, !tbaa !464
+  %292 = load atomic i64, i64* %291 unordered, align 8, !tbaa !469
   %293 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 17, i32 1), i64 %292 monotonic, align 8
   %294 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 18, i32 0
-  %295 = load i64, i64* %294, align 8, !tbaa !466
+  %295 = load atomic i64, i64* %294 unordered, align 8, !tbaa !471
   %296 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 18, i32 0), i64 %295 monotonic, align 8
   %297 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 18, i32 1
-  %298 = load i64, i64* %297, align 8, !tbaa !464
+  %298 = load atomic i64, i64* %297 unordered, align 8, !tbaa !469
   %299 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 18, i32 1), i64 %298 monotonic, align 8
   %300 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 19, i32 0
-  %301 = load i64, i64* %300, align 8, !tbaa !466
+  %301 = load atomic i64, i64* %300 unordered, align 8, !tbaa !471
   %302 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 19, i32 0), i64 %301 monotonic, align 8
   %303 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 19, i32 1
-  %304 = load i64, i64* %303, align 8, !tbaa !464
+  %304 = load atomic i64, i64* %303 unordered, align 8, !tbaa !469
   %305 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 19, i32 1), i64 %304 monotonic, align 8
   %306 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 20, i32 0
-  %307 = load i64, i64* %306, align 8, !tbaa !466
+  %307 = load atomic i64, i64* %306 unordered, align 8, !tbaa !471
   %308 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 20, i32 0), i64 %307 monotonic, align 8
   %309 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 20, i32 1
-  %310 = load i64, i64* %309, align 8, !tbaa !464
+  %310 = load atomic i64, i64* %309 unordered, align 8, !tbaa !469
   %311 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 20, i32 1), i64 %310 monotonic, align 8
   %312 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 21, i32 0
-  %313 = load i64, i64* %312, align 8, !tbaa !466
+  %313 = load atomic i64, i64* %312 unordered, align 8, !tbaa !471
   %314 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 21, i32 0), i64 %313 monotonic, align 8
   %315 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %0, i64 0, i32 21, i32 1
-  %316 = load i64, i64* %315, align 8, !tbaa !464
+  %316 = load atomic i64, i64* %315 unordered, align 8, !tbaa !469
   %317 = atomicrmw add i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 21, i32 1), i64 %316 monotonic, align 8
   %318 = bitcast %struct.mi_stats_s* %0 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(576) %318, i8 0, i64 576, i1 false)
@@ -34620,30 +35184,30 @@
 
 6:                                                ; preds = %2
   %7 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 0
-  %8 = load %struct.mi_tld_s*, %struct.mi_tld_s** %7, align 8, !tbaa !461
+  %8 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %7 unordered, align 8, !tbaa !466
   %9 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %8, i64 0, i32 0
-  %10 = load i64, i64* %9, align 8, !tbaa !514
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa !518
   %11 = add i64 %10, 1
-  store i64 %11, i64* %9, align 8, !tbaa !514
-  %12 = load volatile void (i1, i64, i8*)*, void (i1, i64, i8*)** @deferred_free, align 8, !tbaa !434
+  store i64 %11, i64* %9, align 8, !tbaa !518
+  %12 = load atomic volatile void (i1, i64, i8*)*, void (i1, i64, i8*)** @deferred_free unordered, align 8, !tbaa !438
   %13 = icmp eq void (i1, i64, i8*)* %12, null
   br i1 %13, label %_mi_deferred_free.exit, label %14
 
 14:                                               ; preds = %6
   %15 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %8, i64 0, i32 1
-  %16 = load i8, i8* %15, align 8, !tbaa !515, !range !72
+  %16 = load atomic i8, i8* %15 unordered, align 8, !tbaa !519, !range !70
   %17 = icmp eq i8 %16, 0
   br i1 %17, label %18, label %_mi_deferred_free.exit
 
 18:                                               ; preds = %14
-  store i8 1, i8* %15, align 8, !tbaa !515
-  %19 = load volatile void (i1, i64, i8*)*, void (i1, i64, i8*)** @deferred_free, align 8, !tbaa !434
+  store i8 1, i8* %15, align 8, !tbaa !519
+  %19 = load atomic volatile void (i1, i64, i8*)*, void (i1, i64, i8*)** @deferred_free unordered, align 8, !tbaa !438
   %20 = load atomic i64, i64* bitcast (i8** @deferred_arg to i64*) monotonic, align 8
   %21 = inttoptr i64 %20 to i8*
   tail call void %19(i1 zeroext true, i64 %11, i8* %21) #37
-  %22 = load %struct.mi_tld_s*, %struct.mi_tld_s** %7, align 8, !tbaa !461
+  %22 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %7 unordered, align 8, !tbaa !466
   %23 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %22, i64 0, i32 1
-  store i8 0, i8* %23, align 8, !tbaa !515
+  store i8 0, i8* %23, align 8, !tbaa !519
   br label %_mi_deferred_free.exit
 
 _mi_deferred_free.exit:                           ; preds = %18, %14, %6
@@ -34654,25 +35218,25 @@
   ]
 
 25:                                               ; preds = %_mi_deferred_free.exit
-  %26 = load i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4), align 8, !tbaa !452
+  %26 = load atomic i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4) unordered, align 8, !tbaa !456
   %27 = icmp eq i64 %26, 0
   br i1 %27, label %_mi_is_main_thread.exit.thread, label %_mi_is_main_thread.exit
 
 _mi_is_main_thread.exit:                          ; preds = %25
-  %28 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !451
+  %28 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !455
   %29 = ptrtoint i8* %28 to i64
   %30 = icmp eq i64 %26, %29
   br i1 %30, label %_mi_is_main_thread.exit.thread, label %_mi_abandoned_reclaim_all.exit
 
 _mi_is_main_thread.exit.thread:                   ; preds = %_mi_is_main_thread.exit, %25
   %31 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %24, i64 0, i32 2
-  %32 = load %struct.mi_heap_s*, %struct.mi_heap_s** %31, align 8, !tbaa !483
+  %32 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** %31 unordered, align 8, !tbaa !487
   %33 = icmp eq %struct.mi_heap_s* %32, %0
   br i1 %33, label %34, label %_mi_abandoned_reclaim_all.exit
 
 34:                                               ; preds = %_mi_is_main_thread.exit.thread
   %35 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 12
-  %36 = load i8, i8* %35, align 8, !tbaa !516, !range !72
+  %36 = load atomic i8, i8* %35 unordered, align 8, !tbaa !520, !range !70
   %37 = icmp eq i8 %36, 0
   br i1 %37, label %38, label %_mi_abandoned_reclaim_all.exit
 
@@ -34683,7 +35247,7 @@
 40:                                               ; preds = %102, %38
   %41 = load atomic i64, i64* @abandoned monotonic, align 64
   %42 = icmp ult i64 %41, 4194304
-  br i1 %42, label %43, label %82, !prof !436, !misexpect !437
+  br i1 %42, label %43, label %82, !prof !440, !misexpect !441
 
 43:                                               ; preds = %40
   %44 = load atomic i64, i64* bitcast (%struct.mi_segment_s** @abandoned_visited to i64*) monotonic, align 64
@@ -34707,7 +35271,7 @@
   %56 = or i64 %55, %47
   %57 = cmpxchg i64* @abandoned, i64 %50, i64 %56 acq_rel acquire, align 8
   %58 = extractvalue { i64, i1 } %57, 1
-  br i1 %58, label %.loopexit28, label %59, !prof !517
+  br i1 %58, label %.loopexit28, label %59, !prof !521
 
 59:                                               ; preds = %52, %49
   br label %60
@@ -34736,7 +35300,7 @@
   %76 = cmpxchg weak i64* @abandoned, i64 %70, i64 %75 release monotonic, align 8
   %77 = extractvalue { i64, i1 } %76, 1
   %78 = extractvalue { i64, i1 } %76, 0
-  br i1 %77, label %.loopexit28, label %69, !prof !517
+  br i1 %77, label %.loopexit28, label %69, !prof !521
 
 .loopexit28:                                      ; preds = %69, %52
   %79 = phi i64 [ %53, %52 ], [ %71, %69 ]
@@ -34781,21 +35345,21 @@
 
 106:                                              ; preds = %_mi_deferred_free.exit
   %107 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 8
-  %108 = load i64, i64* %107, align 8, !tbaa !494
+  %108 = load atomic i64, i64* %107 unordered, align 8, !tbaa !498
   %109 = icmp eq i64 %108, 0
   br i1 %109, label %_mi_abandoned_reclaim_all.exit, label %.preheader31
 
 .preheader31:                                     ; preds = %.loopexit30, %106
   %110 = phi i64 [ %129, %.loopexit30 ], [ 0, %106 ]
   %111 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 2, i64 %110, i32 0
-  %112 = load %struct.mi_page_s*, %struct.mi_page_s** %111, align 8, !tbaa !496
+  %112 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %111 unordered, align 8, !tbaa !500
   %113 = icmp eq %struct.mi_page_s* %112, null
   br i1 %113, label %.loopexit30, label %.preheader29
 
 .preheader29:                                     ; preds = %_mi_page_use_delayed_free.exit, %.preheader31
   %114 = phi %struct.mi_page_s* [ %116, %_mi_page_use_delayed_free.exit ], [ %112, %.preheader31 ]
   %115 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %114, i64 0, i32 12
-  %116 = load %struct.mi_page_s*, %struct.mi_page_s** %115, align 8, !tbaa !499
+  %116 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %115 unordered, align 8, !tbaa !503
   %117 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %114, i64 0, i32 10
   br label %118
 
@@ -34806,7 +35370,7 @@
   switch i32 %121, label %122 [
     i32 1, label %126
     i32 3, label %_mi_page_use_delayed_free.exit
-  ], !prof !518
+  ], !prof !522
 
 122:                                              ; preds = %118
   %123 = or i64 %119, 3
@@ -34852,16 +35416,16 @@
   %142 = phi i64 [ %145, %.preheader26 ], [ %136, %138 ]
   %143 = inttoptr i64 %142 to %"class.kotlin::gc::GCHandle"*
   %144 = inttoptr i64 %142 to i64*
-  %145 = load i64, i64* %144, align 8, !tbaa !443
+  %145 = load atomic i64, i64* %144 unordered, align 8, !tbaa !447
   tail call fastcc void @_mi_free_delayed_block(%"class.kotlin::gc::GCHandle"* nonnull %143) #37
   %146 = icmp eq i64 %145, 0
   br i1 %146, label %_mi_heap_delayed_free.exit, label %.preheader26
 
 _mi_heap_delayed_free.exit:                       ; preds = %.preheader26, %135
   %147 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 9
-  %148 = load i64, i64* %147, align 8, !tbaa !519
+  %148 = load atomic i64, i64* %147 unordered, align 8, !tbaa !523
   %149 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 10
-  %150 = load i64, i64* %149, align 8, !tbaa !520
+  %150 = load atomic i64, i64* %149 unordered, align 8, !tbaa !524
   %151 = icmp ugt i64 %148, %150
   br i1 %151, label %_mi_heap_collect_retired.exit, label %152
 
@@ -34869,19 +35433,19 @@
   %153 = phi i64 [ %172, %171 ], [ %148, %_mi_heap_delayed_free.exit ]
   %154 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 2, i64 %153
   %155 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %154, i64 0, i32 0
-  %156 = load %struct.mi_page_s*, %struct.mi_page_s** %155, align 8, !tbaa !496
+  %156 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %155 unordered, align 8, !tbaa !500
   %157 = icmp eq %struct.mi_page_s* %156, null
   br i1 %157, label %171, label %158
 
 158:                                              ; preds = %152
   %159 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %156, i64 0, i32 5
-  %160 = load i8, i8* %159, align 1
+  %160 = load atomic i8, i8* %159 unordered, align 1
   %161 = icmp ult i8 %160, 2
   br i1 %161, label %171, label %162
 
 162:                                              ; preds = %158
   %163 = getelementptr %struct.mi_page_s, %struct.mi_page_s* %156, i64 0, i32 7
-  %164 = load i32, i32* %163, align 8, !tbaa !442
+  %164 = load atomic i32, i32* %163 unordered, align 8, !tbaa !446
   %165 = icmp eq i32 %164, 0
   br i1 %165, label %168, label %166
 
@@ -34893,21 +35457,21 @@
 168:                                              ; preds = %162
   %169 = add i8 %160, -2
   store i8 %169, i8* %159, align 1
-  %170 = load %struct.mi_page_s*, %struct.mi_page_s** %155, align 8, !tbaa !496
+  %170 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %155 unordered, align 8, !tbaa !500
   tail call fastcc void @_mi_page_free(%struct.mi_page_s* %170, %struct.mi_page_queue_s* nonnull %154, i1 zeroext true) #37
   br label %171
 
 171:                                              ; preds = %168, %166, %158, %152
   %172 = add i64 %153, 1
-  %173 = load i64, i64* %149, align 8, !tbaa !520
+  %173 = load atomic i64, i64* %149 unordered, align 8, !tbaa !524
   %174 = icmp ugt i64 %172, %173
   br i1 %174, label %_mi_heap_collect_retired.exit, label %152
 
 _mi_heap_collect_retired.exit:                    ; preds = %171, %_mi_heap_delayed_free.exit
-  store i64 74, i64* %147, align 8, !tbaa !519
-  store i64 0, i64* %149, align 8, !tbaa !520
+  store i64 74, i64* %147, align 8, !tbaa !523
+  store i64 0, i64* %149, align 8, !tbaa !524
   %175 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 8
-  %176 = load i64, i64* %175, align 8, !tbaa !494
+  %176 = load atomic i64, i64* %175 unordered, align 8, !tbaa !498
   %177 = icmp eq i64 %176, 0
   br i1 %177, label %.loopexit21, label %178
 
@@ -34918,7 +35482,7 @@
   %179 = phi i64 [ %188, %.loopexit19 ], [ 0, %178 ]
   %180 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 2, i64 %179
   %181 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %180, i64 0, i32 0
-  %182 = load %struct.mi_page_s*, %struct.mi_page_s** %181, align 8, !tbaa !496
+  %182 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %181 unordered, align 8, !tbaa !500
   %183 = icmp eq %struct.mi_page_s* %182, null
   br i1 %183, label %.loopexit19, label %.preheader18
 
@@ -34937,10 +35501,10 @@
 190:                                              ; preds = %_mi_page_abandon.exit, %.preheader18
   %191 = phi %struct.mi_page_s* [ %193, %_mi_page_abandon.exit ], [ %182, %.preheader18 ]
   %192 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %191, i64 0, i32 12
-  %193 = load %struct.mi_page_s*, %struct.mi_page_s** %192, align 8, !tbaa !499
+  %193 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %192 unordered, align 8, !tbaa !503
   tail call fastcc void @_mi_page_free_collect(%struct.mi_page_s* nonnull %191, i1 zeroext true) #37
   %194 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %191, i64 0, i32 7
-  %195 = load i32, i32* %194, align 8, !tbaa !442
+  %195 = load atomic i32, i32* %194 unordered, align 8, !tbaa !446
   %196 = icmp eq i32 %195, 0
   br i1 %196, label %421, label %197
 
@@ -34949,25 +35513,25 @@
   %199 = load atomic i64, i64* %198 monotonic, align 8
   %200 = inttoptr i64 %199 to %struct.mi_heap_s*
   %201 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %200, i64 0, i32 0
-  %202 = load %struct.mi_tld_s*, %struct.mi_tld_s** %201, align 8, !tbaa !461
+  %202 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %201 unordered, align 8, !tbaa !466
   %203 = load atomic i64, i64* %198 monotonic, align 8
   %204 = inttoptr i64 %203 to %struct.mi_heap_s*
   %205 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %191, i64 0, i32 13
-  %206 = load %struct.mi_page_s*, %struct.mi_page_s** %205, align 8, !tbaa !504
+  %206 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %205 unordered, align 8, !tbaa !508
   %207 = icmp eq %struct.mi_page_s* %206, null
   %208 = ptrtoint %struct.mi_page_s* %206 to i64
   br i1 %207, label %214, label %209
 
 209:                                              ; preds = %197
   %210 = bitcast %struct.mi_page_s** %192 to i64*
-  %211 = load i64, i64* %210, align 8, !tbaa !499
+  %211 = load atomic i64, i64* %210 unordered, align 8, !tbaa !503
   %212 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %206, i64 0, i32 12
   %213 = bitcast %struct.mi_page_s** %212 to i64*
-  store i64 %211, i64* %213, align 8, !tbaa !499
+  store i64 %211, i64* %213, align 8, !tbaa !503
   br label %214
 
 214:                                              ; preds = %209, %197
-  %215 = load %struct.mi_page_s*, %struct.mi_page_s** %192, align 8, !tbaa !499
+  %215 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %192 unordered, align 8, !tbaa !503
   %216 = icmp eq %struct.mi_page_s* %215, null
   %217 = ptrtoint %struct.mi_page_s* %215 to i64
   br i1 %216, label %221, label %218
@@ -34975,28 +35539,28 @@
 218:                                              ; preds = %214
   %219 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %215, i64 0, i32 13
   %220 = bitcast %struct.mi_page_s** %219 to i64*
-  store i64 %208, i64* %220, align 8, !tbaa !504
+  store i64 %208, i64* %220, align 8, !tbaa !508
   br label %221
 
 221:                                              ; preds = %218, %214
-  %222 = load %struct.mi_page_s*, %struct.mi_page_s** %184, align 8, !tbaa !497
+  %222 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %184 unordered, align 8, !tbaa !501
   %223 = icmp eq %struct.mi_page_s* %222, %191
   br i1 %223, label %224, label %227
 
 224:                                              ; preds = %221
   %225 = bitcast %struct.mi_page_s** %205 to i64*
-  %226 = load i64, i64* %225, align 8, !tbaa !504
-  store i64 %226, i64* %185, align 8, !tbaa !497
+  %226 = load atomic i64, i64* %225 unordered, align 8, !tbaa !508
+  store i64 %226, i64* %185, align 8, !tbaa !501
   br label %227
 
 227:                                              ; preds = %224, %221
-  %228 = load %struct.mi_page_s*, %struct.mi_page_s** %181, align 8, !tbaa !496
+  %228 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %181 unordered, align 8, !tbaa !500
   %229 = icmp eq %struct.mi_page_s* %228, %191
   br i1 %229, label %230, label %.loopexit14
 
 230:                                              ; preds = %227
-  store i64 %217, i64* %186, align 8, !tbaa !496
-  %231 = load i64, i64* %187, align 8, !tbaa !500
+  store i64 %217, i64* %186, align 8, !tbaa !500
+  %231 = load atomic i64, i64* %187 unordered, align 8, !tbaa !504
   %232 = icmp ugt i64 %231, 1024
   br i1 %232, label %.loopexit14, label %233
 
@@ -35005,7 +35569,7 @@
   %235 = add nuw nsw i64 %231, 7
   %236 = lshr i64 %235, 3
   %237 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %204, i64 0, i32 1, i64 %236
-  %238 = load %struct.mi_page_s*, %struct.mi_page_s** %237, align 8, !tbaa !434
+  %238 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %237 unordered, align 8, !tbaa !438
   %239 = icmp eq %struct.mi_page_s* %238, %234
   br i1 %239, label %.loopexit14, label %240
 
@@ -35025,7 +35589,7 @@
 
 248:                                              ; preds = %242
   %249 = add nsw i64 %236, -1
-  %250 = tail call i64 @llvm.ctlz.i64(i64 %249, i1 true) #37, !range !481
+  %250 = tail call i64 @llvm.ctlz.i64(i64 %249, i1 true) #37, !range !486
   %251 = trunc i64 %250 to i32
   %252 = xor i32 %251, 63
   %253 = shl nuw nsw i32 %252, 2
@@ -35048,7 +35612,7 @@
   %266 = phi %struct.mi_page_queue_s* [ %180, %262 ], [ %267, %295 ]
   %267 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %266, i64 -1
   %268 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %266, i64 -1, i32 2
-  %269 = load i64, i64* %268, align 8, !tbaa !500
+  %269 = load atomic i64, i64* %268 unordered, align 8, !tbaa !504
   %270 = add i64 %269, 7
   %271 = lshr i64 %270, 3
   %272 = icmp ult i64 %270, 16
@@ -35070,7 +35634,7 @@
 
 281:                                              ; preds = %279
   %282 = add nsw i64 %271, -1
-  %283 = tail call i64 @llvm.ctlz.i64(i64 %282, i1 true) #37, !range !481
+  %283 = tail call i64 @llvm.ctlz.i64(i64 %282, i1 true) #37, !range !486
   %284 = trunc i64 %283 to i32
   %285 = xor i32 %284, 63
   %286 = shl nuw nsw i32 %285, 2
@@ -35127,38 +35691,38 @@
   %325 = add i64 %306, %323
   %326 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %204, i64 0, i32 1, i64 %325
   %327 = bitcast %struct.mi_page_s** %326 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %327, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %327, align 8, !tbaa !438
   %328 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %326, i64 2
   %329 = bitcast %struct.mi_page_s** %328 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %329, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %329, align 8, !tbaa !438
   %330 = or i64 %323, 4
   %331 = add i64 %306, %330
   %332 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %204, i64 0, i32 1, i64 %331
   %333 = bitcast %struct.mi_page_s** %332 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %333, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %333, align 8, !tbaa !438
   %334 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %332, i64 2
   %335 = bitcast %struct.mi_page_s** %334 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %335, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %335, align 8, !tbaa !438
   %336 = or i64 %323, 8
   %337 = add i64 %306, %336
   %338 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %204, i64 0, i32 1, i64 %337
   %339 = bitcast %struct.mi_page_s** %338 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %339, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %339, align 8, !tbaa !438
   %340 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %338, i64 2
   %341 = bitcast %struct.mi_page_s** %340 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %341, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %341, align 8, !tbaa !438
   %342 = or i64 %323, 12
   %343 = add i64 %306, %342
   %344 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %204, i64 0, i32 1, i64 %343
   %345 = bitcast %struct.mi_page_s** %344 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %345, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %345, align 8, !tbaa !438
   %346 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %344, i64 2
   %347 = bitcast %struct.mi_page_s** %346 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %347, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %347, align 8, !tbaa !438
   %348 = add i64 %323, 16
   %349 = add i64 %324, -4
   %350 = icmp eq i64 %349, 0
-  br i1 %350, label %.loopexit17, label %322, !llvm.loop !521
+  br i1 %350, label %.loopexit17, label %322, !llvm.loop !525
 
 .loopexit17:                                      ; preds = %322, %310
   %351 = phi i64 [ 0, %310 ], [ %348, %322 ]
@@ -35171,14 +35735,14 @@
   %355 = add i64 %306, %353
   %356 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %204, i64 0, i32 1, i64 %355
   %357 = bitcast %struct.mi_page_s** %356 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %357, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %357, align 8, !tbaa !438
   %358 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %356, i64 2
   %359 = bitcast %struct.mi_page_s** %358 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %359, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %359, align 8, !tbaa !438
   %360 = add nuw i64 %353, 4
   %361 = add nsw i64 %354, -1
   %362 = icmp eq i64 %361, 0
-  br i1 %362, label %.loopexit16, label %.preheader15, !llvm.loop !522
+  br i1 %362, label %.loopexit16, label %.preheader15, !llvm.loop !526
 
 .loopexit16:                                      ; preds = %.preheader15, %.loopexit17
   %363 = icmp eq i64 %308, %311
@@ -35191,21 +35755,21 @@
 366:                                              ; preds = %366, %364
   %367 = phi i64 [ %369, %366 ], [ %365, %364 ]
   %368 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %204, i64 0, i32 1, i64 %367
-  store %struct.mi_page_s* %234, %struct.mi_page_s** %368, align 8, !tbaa !434
+  store %struct.mi_page_s* %234, %struct.mi_page_s** %368, align 8, !tbaa !438
   %369 = add nuw nsw i64 %367, 1
   %370 = icmp eq i64 %367, %236
-  br i1 %370, label %.loopexit14, label %366, !llvm.loop !523
+  br i1 %370, label %.loopexit14, label %366, !llvm.loop !527
 
 .loopexit14:                                      ; preds = %366, %.loopexit16, %300, %233, %230, %227
   %371 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %202, i64 0, i32 4
   %372 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %204, i64 0, i32 8
-  %373 = load i64, i64* %372, align 8, !tbaa !494
+  %373 = load atomic i64, i64* %372 unordered, align 8, !tbaa !498
   %374 = add i64 %373, -1
-  store i64 %374, i64* %372, align 8, !tbaa !494
+  store i64 %374, i64* %372, align 8, !tbaa !498
   %375 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %191, i64 0, i32 4, i32 0
   %376 = bitcast %struct.mi_page_s** %192 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %376, i8 0, i64 16, i1 false) #37
-  %377 = load i8, i8* %375, align 2
+  %377 = load atomic i8, i8* %375 unordered, align 2
   %378 = and i8 %377, -2
   store i8 %378, i8* %375, align 2
   store atomic i64 0, i64* %198 release, align 8
@@ -35213,11 +35777,11 @@
   %380 = and i64 %379, -4194304
   %381 = inttoptr i64 %380 to %struct.mi_segment_s*
   %382 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %381, i64 0, i32 6
-  %383 = load i64, i64* %382, align 8, !tbaa !524
+  %383 = load atomic i64, i64* %382 unordered, align 8, !tbaa !528
   %384 = add i64 %383, 1
-  store i64 %384, i64* %382, align 8, !tbaa !524
+  store i64 %384, i64* %382, align 8, !tbaa !528
   %385 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %202, i64 0, i32 4, i32 10
-  %386 = load %struct.mi_stats_s*, %struct.mi_stats_s** %385, align 8, !tbaa !525
+  %386 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %385 unordered, align 8, !tbaa !529
   %387 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %386, i64 0, i32 7
   %388 = icmp uge %"struct.(anonymous namespace)::RootSetStatistics"* %387, getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0)
   %389 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %387, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -35246,34 +35810,33 @@
 403:                                              ; preds = %399, %397
   %404 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %387, i64 0, i32 0
   %405 = atomicrmw add i64* %404, i64 1 monotonic, align 8
-  %.pre = load i64, i64* %382, align 8, !tbaa !524
   br label %_mi_stat_increase.exit.i.i
 
 406:                                              ; preds = %.loopexit14
-  %407 = load i64, i64* %391, align 8, !tbaa !510
+  %407 = load atomic i64, i64* %391 unordered, align 8, !tbaa !514
   %408 = add nsw i64 %407, 1
-  store i64 %408, i64* %391, align 8, !tbaa !510
+  store i64 %408, i64* %391, align 8, !tbaa !514
   %409 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %386, i64 0, i32 7, i32 2
-  %410 = load i64, i64* %409, align 8, !tbaa !511
+  %410 = load atomic i64, i64* %409 unordered, align 8, !tbaa !515
   %.not12 = icmp slt i64 %407, %410
   br i1 %.not12, label %412, label %411
 
 411:                                              ; preds = %406
-  store i64 %408, i64* %409, align 8, !tbaa !511
+  store i64 %408, i64* %409, align 8, !tbaa !515
   br label %412
 
 412:                                              ; preds = %411, %406
   %413 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %387, i64 0, i32 0
-  %414 = load i64, i64* %413, align 8, !tbaa !512
+  %414 = load atomic i64, i64* %413 unordered, align 8, !tbaa !516
   %415 = add nsw i64 %414, 1
-  store i64 %415, i64* %413, align 8, !tbaa !512
+  store i64 %415, i64* %413, align 8, !tbaa !516
   br label %_mi_stat_increase.exit.i.i
 
 _mi_stat_increase.exit.i.i:                       ; preds = %412, %403
-  %416 = phi i64 [ %384, %412 ], [ %.pre, %403 ]
-  %417 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %381, i64 0, i32 8
-  %418 = load i64, i64* %417, align 8, !tbaa !526
-  %419 = icmp eq i64 %418, %416
+  %416 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %381, i64 0, i32 8
+  %417 = load atomic i64, i64* %416 unordered, align 8, !tbaa !530
+  %418 = load atomic i64, i64* %382 unordered, align 8, !tbaa !528
+  %419 = icmp eq i64 %417, %418
   br i1 %419, label %420, label %_mi_page_abandon.exit
 
 420:                                              ; preds = %_mi_stat_increase.exit.i.i
@@ -35292,17 +35855,17 @@
   %423 = phi i64 [ %437, %.loopexit23 ], [ 0, %178 ]
   %424 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 2, i64 %423
   %425 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %424, i64 0, i32 0
-  %426 = load %struct.mi_page_s*, %struct.mi_page_s** %425, align 8, !tbaa !496
+  %426 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %425 unordered, align 8, !tbaa !500
   %427 = icmp eq %struct.mi_page_s* %426, null
   br i1 %427, label %.loopexit23, label %.preheader22
 
 .preheader22:                                     ; preds = %435, %.preheader24
   %428 = phi %struct.mi_page_s* [ %430, %435 ], [ %426, %.preheader24 ]
   %429 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %428, i64 0, i32 12
-  %430 = load %struct.mi_page_s*, %struct.mi_page_s** %429, align 8, !tbaa !499
+  %430 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %429 unordered, align 8, !tbaa !503
   tail call fastcc void @_mi_page_free_collect(%struct.mi_page_s* nonnull %428, i1 zeroext true) #37
   %431 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %428, i64 0, i32 7
-  %432 = load i32, i32* %431, align 8, !tbaa !442
+  %432 = load atomic i32, i32* %431 unordered, align 8, !tbaa !446
   %433 = icmp eq i32 %432, 0
   br i1 %433, label %434, label %435
 
@@ -35320,9 +35883,9 @@
   br i1 %438, label %.loopexit21, label %.preheader24
 
 .loopexit21:                                      ; preds = %.loopexit23, %.loopexit19, %_mi_heap_collect_retired.exit
-  %439 = load %struct.mi_tld_s*, %struct.mi_tld_s** %7, align 8, !tbaa !461
+  %439 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %7 unordered, align 8, !tbaa !466
   %440 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %439, i64 0, i32 4, i32 9
-  %441 = load %struct.mi_segment_s*, %struct.mi_segment_s** %440, align 8, !tbaa !527
+  %441 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %440 unordered, align 8, !tbaa !531
   %442 = icmp eq %struct.mi_segment_s* %441, null
   br i1 %442, label %_mi_segment_thread_collect.exit, label %443
 
@@ -35338,15 +35901,15 @@
 
 451:                                              ; preds = %615, %443
   %452 = phi %struct.mi_segment_s* [ %441, %443 ], [ %623, %615 ]
-  %453 = load i64, i64* %444, align 8, !tbaa !528
+  %453 = load atomic i64, i64* %444 unordered, align 8, !tbaa !532
   %454 = add i64 %453, -1
-  store i64 %454, i64* %444, align 8, !tbaa !528
+  store i64 %454, i64* %444, align 8, !tbaa !532
   %455 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %452, i64 0, i32 4
   %456 = bitcast %struct.mi_segment_s** %455 to i64*
-  %457 = load i64, i64* %456, align 8, !tbaa !529
-  store i64 %457, i64* %445, align 8, !tbaa !527
-  store %struct.mi_segment_s* null, %struct.mi_segment_s** %455, align 8, !tbaa !529
-  %458 = load %struct.mi_stats_s*, %struct.mi_stats_s** %446, align 8, !tbaa !525
+  %457 = load atomic i64, i64* %456 unordered, align 8, !tbaa !533
+  store i64 %457, i64* %445, align 8, !tbaa !531
+  store %struct.mi_segment_s* null, %struct.mi_segment_s** %455, align 8, !tbaa !533
+  %458 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %446 unordered, align 8, !tbaa !529
   %459 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %458, i64 0, i32 13
   %460 = icmp uge %"struct.(anonymous namespace)::RootSetStatistics"* %459, getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0)
   %461 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %459, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -35378,32 +35941,32 @@
   br label %_mi_stat_decrease.exit.i
 
 479:                                              ; preds = %451
-  %480 = load i64, i64* %463, align 8, !tbaa !510
+  %480 = load atomic i64, i64* %463 unordered, align 8, !tbaa !514
   %481 = add i64 %480, -1
-  store i64 %481, i64* %463, align 8, !tbaa !510
+  store i64 %481, i64* %463, align 8, !tbaa !514
   %482 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %458, i64 0, i32 13, i32 2
-  %483 = load i64, i64* %482, align 8, !tbaa !511
+  %483 = load atomic i64, i64* %482 unordered, align 8, !tbaa !515
   %484 = icmp sgt i64 %481, %483
   br i1 %484, label %485, label %486
 
 485:                                              ; preds = %479
-  store i64 %481, i64* %482, align 8, !tbaa !511
+  store i64 %481, i64* %482, align 8, !tbaa !515
   br label %486
 
 486:                                              ; preds = %485, %479
   %487 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %458, i64 0, i32 13, i32 1
-  %488 = load i64, i64* %487, align 8, !tbaa !513
+  %488 = load atomic i64, i64* %487 unordered, align 8, !tbaa !517
   %489 = add i64 %488, 1
-  store i64 %489, i64* %487, align 8, !tbaa !513
+  store i64 %489, i64* %487, align 8, !tbaa !517
   br label %_mi_stat_decrease.exit.i
 
 _mi_stat_decrease.exit.i:                         ; preds = %486, %476
   %490 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %452, i64 0, i32 10
-  %491 = load i64, i64* %490, align 8, !tbaa !530
+  %491 = load atomic i64, i64* %490 unordered, align 8, !tbaa !534
   %492 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %452, i64 0, i32 14
-  store atomic i64 0, i64* %492 seq_cst, align 8, !tbaa !531
+  store atomic i64 0, i64* %492 seq_cst, align 8, !tbaa !535
   %493 = icmp slt i64 %491, 1
-  %494 = load %struct.mi_stats_s*, %struct.mi_stats_s** %446, align 8, !tbaa !525
+  %494 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %446 unordered, align 8, !tbaa !529
   %495 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %494, i64 0, i32 0
   %496 = icmp uge %struct.mi_stats_s* %494, @_mi_stats_main
   %497 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %495, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -35438,23 +36001,23 @@
   br label %_mi_stat_increase.exit.i
 
 515:                                              ; preds = %500
-  %516 = load i64, i64* %499, align 8, !tbaa !510
+  %516 = load atomic i64, i64* %499 unordered, align 8, !tbaa !514
   %517 = add nsw i64 %516, 1
-  store i64 %517, i64* %499, align 8, !tbaa !510
+  store i64 %517, i64* %499, align 8, !tbaa !514
   %518 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %494, i64 0, i32 0, i32 2
-  %519 = load i64, i64* %518, align 8, !tbaa !511
+  %519 = load atomic i64, i64* %518 unordered, align 8, !tbaa !515
   %.not10 = icmp slt i64 %516, %519
   br i1 %.not10, label %521, label %520
 
 520:                                              ; preds = %515
-  store i64 %517, i64* %518, align 8, !tbaa !511
+  store i64 %517, i64* %518, align 8, !tbaa !515
   br label %521
 
 521:                                              ; preds = %520, %515
   %522 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %494, i64 0, i32 0, i32 0
-  %523 = load i64, i64* %522, align 8, !tbaa !512
+  %523 = load atomic i64, i64* %522 unordered, align 8, !tbaa !516
   %524 = add nsw i64 %523, 1
-  store i64 %524, i64* %522, align 8, !tbaa !512
+  store i64 %524, i64* %522, align 8, !tbaa !516
   br label %_mi_stat_increase.exit.i
 
 525:                                              ; preds = %_mi_stat_decrease.exit.i
@@ -35484,53 +36047,53 @@
   br label %_mi_stat_increase.exit.i
 
 541:                                              ; preds = %525
-  %542 = load i64, i64* %499, align 8, !tbaa !510
+  %542 = load atomic i64, i64* %499 unordered, align 8, !tbaa !514
   %543 = add i64 %542, -1
-  store i64 %543, i64* %499, align 8, !tbaa !510
+  store i64 %543, i64* %499, align 8, !tbaa !514
   %544 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %494, i64 0, i32 0, i32 2
-  %545 = load i64, i64* %544, align 8, !tbaa !511
+  %545 = load atomic i64, i64* %544 unordered, align 8, !tbaa !515
   %546 = icmp sgt i64 %543, %545
   br i1 %546, label %547, label %548
 
 547:                                              ; preds = %541
-  store i64 %543, i64* %544, align 8, !tbaa !511
+  store i64 %543, i64* %544, align 8, !tbaa !515
   br label %548
 
 548:                                              ; preds = %547, %541
   %549 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %494, i64 0, i32 0, i32 1
-  %550 = load i64, i64* %549, align 8, !tbaa !513
+  %550 = load atomic i64, i64* %549 unordered, align 8, !tbaa !517
   %551 = add i64 %550, 1
-  store i64 %551, i64* %549, align 8, !tbaa !513
+  store i64 %551, i64* %549, align 8, !tbaa !517
   br label %_mi_stat_increase.exit.i
 
 _mi_stat_increase.exit.i:                         ; preds = %548, %538, %521, %512
   %552 = phi i64 [ 1, %521 ], [ 1, %512 ], [ -1, %548 ], [ -1, %538 ]
-  %553 = load i64, i64* %447, align 8, !tbaa !532
+  %553 = load atomic i64, i64* %447 unordered, align 8, !tbaa !536
   %554 = add i64 %553, %552
-  store i64 %554, i64* %447, align 8, !tbaa !532
-  %555 = load i64, i64* %448, align 8, !tbaa !533
+  store i64 %554, i64* %447, align 8, !tbaa !536
+  %555 = load atomic i64, i64* %448 unordered, align 8, !tbaa !537
   %556 = icmp ugt i64 %554, %555
   br i1 %556, label %557, label %558
 
 557:                                              ; preds = %_mi_stat_increase.exit.i
-  store i64 %554, i64* %448, align 8, !tbaa !533
+  store i64 %554, i64* %448, align 8, !tbaa !537
   br label %558
 
 558:                                              ; preds = %557, %_mi_stat_increase.exit.i
-  %559 = load i64, i64* %449, align 8, !tbaa !534
+  %559 = load atomic i64, i64* %449 unordered, align 8, !tbaa !538
   %560 = sub i64 %559, %491
-  store i64 %560, i64* %449, align 8, !tbaa !534
-  %561 = load i64, i64* %450, align 8, !tbaa !535
+  store i64 %560, i64* %449, align 8, !tbaa !538
+  %561 = load atomic i64, i64* %450 unordered, align 8, !tbaa !539
   %562 = icmp ugt i64 %560, %561
   br i1 %562, label %563, label %564
 
 563:                                              ; preds = %558
-  store i64 %560, i64* %450, align 8, !tbaa !535
+  store i64 %560, i64* %450, align 8, !tbaa !539
   br label %564
 
 564:                                              ; preds = %563, %558
   %565 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %452, i64 0, i32 9
-  %566 = load i64, i64* %565, align 8, !tbaa !536
+  %566 = load atomic i64, i64* %565 unordered, align 8, !tbaa !540
   %567 = icmp eq i64 %566, 0
   br i1 %567, label %615, label %568
 
@@ -35552,7 +36115,7 @@
   %576 = phi i64 [ %572, %573 ], [ 0, %568 ]
   %577 = phi i8 [ %608, %573 ], [ 0, %568 ]
   %578 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %452, i64 0, i32 16, i64 %576, i32 1
-  %579 = load i8, i8* %578, align 1
+  %579 = load atomic i8, i8* %578 unordered, align 1
   %580 = and i8 %579, 2
   %581 = icmp eq i8 %580, 0
   %582 = select i1 %581, i8 %577, i8 1
@@ -35574,10 +36137,10 @@
   %594 = phi i8 [ 1, %571 ], [ %604, %591 ]
   %595 = phi i64 [ %572, %571 ], [ %610, %591 ]
   %596 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %452, i64 0, i32 16, i64 %593, i32 1
-  %597 = load i8, i8* %596, align 1
+  %597 = load atomic i8, i8* %596 unordered, align 1
   %598 = or i64 %593, 1
   %599 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %452, i64 0, i32 16, i64 %598, i32 1
-  %600 = load i8, i8* %599, align 1
+  %600 = load atomic i8, i8* %599 unordered, align 1
   %601 = and i8 %600, %597
   %602 = and i8 %601, 4
   %603 = icmp eq i8 %602, 0
@@ -35602,29 +36165,29 @@
   %617 = phi i8 [ %587, %586 ], [ %614, %612 ], [ 1, %564 ]
   %618 = bitcast %struct.mi_segment_s* %452 to i8*
   %619 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %452, i64 0, i32 0
-  %620 = load i64, i64* %619, align 8, !tbaa !537
+  %620 = load atomic i64, i64* %619 unordered, align 8, !tbaa !541
   %621 = and i8 %617, 1
   %622 = icmp ne i8 %621, 0
   tail call fastcc void @_mi_mem_free(i8* nonnull %618, i64 %491, i64 %620, i1 zeroext %622, i1 zeroext %616) #37
-  %623 = load %struct.mi_segment_s*, %struct.mi_segment_s** %440, align 8, !tbaa !527
+  %623 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %440 unordered, align 8, !tbaa !531
   %624 = icmp eq %struct.mi_segment_s* %623, null
   br i1 %624, label %_mi_segment_thread_collect.exit, label %451
 
 _mi_segment_thread_collect.exit:                  ; preds = %615, %.loopexit21
-  %625 = load i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4), align 8, !tbaa !452
+  %625 = load atomic i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 4) unordered, align 8, !tbaa !456
   %626 = icmp eq i64 %625, 0
   br i1 %626, label %_mi_is_main_thread.exit9.thread, label %_mi_is_main_thread.exit9
 
 _mi_is_main_thread.exit9:                         ; preds = %_mi_segment_thread_collect.exit
-  %627 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !451
+  %627 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !455
   %628 = ptrtoint i8* %627 to i64
   %629 = icmp eq i64 %625, %628
   br i1 %629, label %_mi_is_main_thread.exit9.thread, label %_mi_mem_collect.exit
 
 _mi_is_main_thread.exit9.thread:                  ; preds = %_mi_is_main_thread.exit9, %_mi_segment_thread_collect.exit
-  %630 = load %struct.mi_tld_s*, %struct.mi_tld_s** %7, align 8, !tbaa !461
+  %630 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %7 unordered, align 8, !tbaa !466
   %631 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %630, i64 0, i32 2
-  %632 = load %struct.mi_heap_s*, %struct.mi_heap_s** %631, align 8, !tbaa !483
+  %632 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** %631 unordered, align 8, !tbaa !487
   %633 = icmp eq %struct.mi_heap_s* %632, %0
   br i1 %633, label %634, label %_mi_mem_collect.exit
 
@@ -35728,7 +36291,7 @@
 
 20:                                               ; preds = %16
   %21 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 2
-  %22 = load i16, i16* %21, align 2, !tbaa !538
+  %22 = load atomic i16, i16* %21 unordered, align 2, !tbaa !542
   %23 = zext i16 %22 to i32
   br label %24
 
@@ -35736,7 +36299,7 @@
   %25 = phi i32 [ 1, %20 ], [ %32, %24 ]
   %26 = phi %"class.kotlin::gc::GCHandle"* [ %18, %20 ], [ %28, %24 ]
   %27 = bitcast %"class.kotlin::gc::GCHandle"* %26 to %"class.kotlin::gc::GCHandle"**
-  %28 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %27, align 8, !tbaa !443
+  %28 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %27 unordered, align 8, !tbaa !447
   %29 = icmp ne %"class.kotlin::gc::GCHandle"* %28, null
   %30 = icmp ule i32 %25, %23
   %31 = and i1 %30, %29
@@ -35754,34 +36317,34 @@
 36:                                               ; preds = %33
   %37 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 9
   %38 = bitcast %"class.kotlin::gc::GCHandle"** %37 to i64*
-  %39 = load i64, i64* %38, align 8, !tbaa !539
+  %39 = load atomic i64, i64* %38 unordered, align 8, !tbaa !543
   %40 = getelementptr inbounds %"class.kotlin::gc::GCHandle", %"class.kotlin::gc::GCHandle"* %26, i64 0, i32 0
-  store i64 %39, i64* %40, align 8, !tbaa !443
-  store %"class.kotlin::gc::GCHandle"* %18, %"class.kotlin::gc::GCHandle"** %37, align 8, !tbaa !539
+  store i64 %39, i64* %40, align 8, !tbaa !447
+  store %"class.kotlin::gc::GCHandle"* %18, %"class.kotlin::gc::GCHandle"** %37, align 8, !tbaa !543
   %41 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 7
-  %42 = load i32, i32* %41, align 8, !tbaa !442
+  %42 = load atomic i32, i32* %41 unordered, align 8, !tbaa !446
   %43 = sub i32 %42, %25
-  store i32 %43, i32* %41, align 8, !tbaa !442
+  store i32 %43, i32* %41, align 8, !tbaa !446
   br label %44
 
 44:                                               ; preds = %36, %35, %16, %3
   %45 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 9
-  %46 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %45, align 8, !tbaa !539
+  %46 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %45 unordered, align 8, !tbaa !543
   %47 = icmp eq %"class.kotlin::gc::GCHandle"* %46, null
   %48 = ptrtoint %"class.kotlin::gc::GCHandle"* %46 to i64
   br i1 %47, label %69, label %49
 
 49:                                               ; preds = %44
   %50 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 6
-  %51 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %50, align 8, !tbaa !438
+  %51 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %50 unordered, align 8, !tbaa !442
   %52 = icmp eq %"class.kotlin::gc::GCHandle"* %51, null
-  br i1 %52, label %53, label %57, !prof !436, !misexpect !437
+  br i1 %52, label %53, label %57, !prof !440, !misexpect !441
 
 53:                                               ; preds = %49
-  store %"class.kotlin::gc::GCHandle"* %46, %"class.kotlin::gc::GCHandle"** %50, align 8, !tbaa !438
-  store %"class.kotlin::gc::GCHandle"* null, %"class.kotlin::gc::GCHandle"** %45, align 8, !tbaa !539
+  store %"class.kotlin::gc::GCHandle"* %46, %"class.kotlin::gc::GCHandle"** %50, align 8, !tbaa !442
+  store %"class.kotlin::gc::GCHandle"* null, %"class.kotlin::gc::GCHandle"** %45, align 8, !tbaa !543
   %54 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 5
-  %55 = load i8, i8* %54, align 1
+  %55 = load atomic i8, i8* %54 unordered, align 1
   %56 = and i8 %55, -2
   store i8 %56, i8* %54, align 1
   br label %69
@@ -35792,19 +36355,19 @@
 .preheader:                                       ; preds = %.preheader, %57
   %58 = phi %"class.kotlin::gc::GCHandle"* [ %60, %.preheader ], [ %46, %57 ]
   %59 = bitcast %"class.kotlin::gc::GCHandle"* %58 to %"class.kotlin::gc::GCHandle"**
-  %60 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %59, align 8, !tbaa !443
+  %60 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %59 unordered, align 8, !tbaa !447
   %61 = icmp eq %"class.kotlin::gc::GCHandle"* %60, null
   br i1 %61, label %62, label %.preheader
 
 62:                                               ; preds = %.preheader
   %63 = ptrtoint %"class.kotlin::gc::GCHandle"* %51 to i64
   %64 = getelementptr inbounds %"class.kotlin::gc::GCHandle", %"class.kotlin::gc::GCHandle"* %58, i64 0, i32 0
-  store i64 %63, i64* %64, align 8, !tbaa !443
+  store i64 %63, i64* %64, align 8, !tbaa !447
   %65 = bitcast %"class.kotlin::gc::GCHandle"** %50 to i64*
-  store i64 %48, i64* %65, align 8, !tbaa !438
-  store %"class.kotlin::gc::GCHandle"* null, %"class.kotlin::gc::GCHandle"** %45, align 8, !tbaa !539
+  store i64 %48, i64* %65, align 8, !tbaa !442
+  store %"class.kotlin::gc::GCHandle"* null, %"class.kotlin::gc::GCHandle"** %45, align 8, !tbaa !543
   %66 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 5
-  %67 = load i8, i8* %66, align 1
+  %67 = load atomic i8, i8* %66 unordered, align 1
   %68 = and i8 %67, -2
   store i8 %68, i8* %66, align 1
   br label %69
@@ -35816,18 +36379,18 @@
 ; Function Attrs: nounwind uwtable
 define internal fastcc void @_mi_page_free(%struct.mi_page_s* %0, %struct.mi_page_queue_s* %1, i1 zeroext %2) unnamed_addr #17 {
   %4 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 4, i32 0
-  %5 = load i8, i8* %4, align 2
+  %5 = load atomic i8, i8* %4 unordered, align 2
   %6 = and i8 %5, -3
   store i8 %6, i8* %4, align 2
   %7 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 11
   %8 = load atomic i64, i64* %7 monotonic, align 8
   %9 = inttoptr i64 %8 to %struct.mi_heap_s*
   %10 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %9, i64 0, i32 0
-  %11 = load %struct.mi_tld_s*, %struct.mi_tld_s** %10, align 8, !tbaa !461
+  %11 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %10 unordered, align 8, !tbaa !466
   %12 = load atomic i64, i64* %7 monotonic, align 8
   %13 = inttoptr i64 %12 to %struct.mi_heap_s*
   %14 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 13
-  %15 = load %struct.mi_page_s*, %struct.mi_page_s** %14, align 8, !tbaa !504
+  %15 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %14 unordered, align 8, !tbaa !508
   %16 = icmp eq %struct.mi_page_s* %15, null
   %17 = ptrtoint %struct.mi_page_s* %15 to i64
   br i1 %16, label %24, label %18
@@ -35835,15 +36398,15 @@
 18:                                               ; preds = %3
   %19 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 12
   %20 = bitcast %struct.mi_page_s** %19 to i64*
-  %21 = load i64, i64* %20, align 8, !tbaa !499
+  %21 = load atomic i64, i64* %20 unordered, align 8, !tbaa !503
   %22 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %15, i64 0, i32 12
   %23 = bitcast %struct.mi_page_s** %22 to i64*
-  store i64 %21, i64* %23, align 8, !tbaa !499
+  store i64 %21, i64* %23, align 8, !tbaa !503
   br label %24
 
 24:                                               ; preds = %18, %3
   %25 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 12
-  %26 = load %struct.mi_page_s*, %struct.mi_page_s** %25, align 8, !tbaa !499
+  %26 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %25 unordered, align 8, !tbaa !503
   %27 = icmp eq %struct.mi_page_s* %26, null
   %28 = ptrtoint %struct.mi_page_s* %26 to i64
   br i1 %27, label %32, label %29
@@ -35851,33 +36414,33 @@
 29:                                               ; preds = %24
   %30 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %26, i64 0, i32 13
   %31 = bitcast %struct.mi_page_s** %30 to i64*
-  store i64 %17, i64* %31, align 8, !tbaa !504
+  store i64 %17, i64* %31, align 8, !tbaa !508
   br label %32
 
 32:                                               ; preds = %29, %24
   %33 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %1, i64 0, i32 1
-  %34 = load %struct.mi_page_s*, %struct.mi_page_s** %33, align 8, !tbaa !497
+  %34 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %33 unordered, align 8, !tbaa !501
   %35 = icmp eq %struct.mi_page_s* %34, %0
   br i1 %35, label %36, label %40
 
 36:                                               ; preds = %32
   %37 = bitcast %struct.mi_page_s** %14 to i64*
-  %38 = load i64, i64* %37, align 8, !tbaa !504
+  %38 = load atomic i64, i64* %37 unordered, align 8, !tbaa !508
   %39 = bitcast %struct.mi_page_s** %33 to i64*
-  store i64 %38, i64* %39, align 8, !tbaa !497
+  store i64 %38, i64* %39, align 8, !tbaa !501
   br label %40
 
 40:                                               ; preds = %36, %32
   %41 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %1, i64 0, i32 0
-  %42 = load %struct.mi_page_s*, %struct.mi_page_s** %41, align 8, !tbaa !496
+  %42 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %41 unordered, align 8, !tbaa !500
   %43 = icmp eq %struct.mi_page_s* %42, %0
   br i1 %43, label %44, label %.loopexit
 
 44:                                               ; preds = %40
   %45 = bitcast %struct.mi_page_queue_s* %1 to i64*
-  store i64 %28, i64* %45, align 8, !tbaa !496
+  store i64 %28, i64* %45, align 8, !tbaa !500
   %46 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %1, i64 0, i32 2
-  %47 = load i64, i64* %46, align 8, !tbaa !500
+  %47 = load atomic i64, i64* %46 unordered, align 8, !tbaa !504
   %48 = icmp ugt i64 %47, 1024
   br i1 %48, label %.loopexit, label %49
 
@@ -35886,7 +36449,7 @@
   %51 = add nuw nsw i64 %47, 7
   %52 = lshr i64 %51, 3
   %53 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %13, i64 0, i32 1, i64 %52
-  %54 = load %struct.mi_page_s*, %struct.mi_page_s** %53, align 8, !tbaa !434
+  %54 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %53 unordered, align 8, !tbaa !438
   %55 = icmp eq %struct.mi_page_s* %54, %50
   br i1 %55, label %.loopexit, label %56
 
@@ -35906,7 +36469,7 @@
 
 64:                                               ; preds = %58
   %65 = add nsw i64 %52, -1
-  %66 = tail call i64 @llvm.ctlz.i64(i64 %65, i1 true) #37, !range !481
+  %66 = tail call i64 @llvm.ctlz.i64(i64 %65, i1 true) #37, !range !486
   %67 = trunc i64 %66 to i32
   %68 = xor i32 %67, 63
   %69 = shl nuw nsw i32 %68, 2
@@ -35929,7 +36492,7 @@
   %82 = phi %struct.mi_page_queue_s* [ %1, %78 ], [ %83, %111 ]
   %83 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %82, i64 -1
   %84 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %82, i64 -1, i32 2
-  %85 = load i64, i64* %84, align 8, !tbaa !500
+  %85 = load atomic i64, i64* %84 unordered, align 8, !tbaa !504
   %86 = add i64 %85, 7
   %87 = lshr i64 %86, 3
   %88 = icmp ult i64 %86, 16
@@ -35951,7 +36514,7 @@
 
 97:                                               ; preds = %95
   %98 = add nsw i64 %87, -1
-  %99 = tail call i64 @llvm.ctlz.i64(i64 %98, i1 true) #37, !range !481
+  %99 = tail call i64 @llvm.ctlz.i64(i64 %98, i1 true) #37, !range !486
   %100 = trunc i64 %99 to i32
   %101 = xor i32 %100, 63
   %102 = shl nuw nsw i32 %101, 2
@@ -36008,38 +36571,38 @@
   %141 = add i64 %122, %139
   %142 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %13, i64 0, i32 1, i64 %141
   %143 = bitcast %struct.mi_page_s** %142 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %143, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %143, align 8, !tbaa !438
   %144 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %142, i64 2
   %145 = bitcast %struct.mi_page_s** %144 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %145, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %145, align 8, !tbaa !438
   %146 = or i64 %139, 4
   %147 = add i64 %122, %146
   %148 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %13, i64 0, i32 1, i64 %147
   %149 = bitcast %struct.mi_page_s** %148 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %149, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %149, align 8, !tbaa !438
   %150 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %148, i64 2
   %151 = bitcast %struct.mi_page_s** %150 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %151, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %151, align 8, !tbaa !438
   %152 = or i64 %139, 8
   %153 = add i64 %122, %152
   %154 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %13, i64 0, i32 1, i64 %153
   %155 = bitcast %struct.mi_page_s** %154 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %155, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %155, align 8, !tbaa !438
   %156 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %154, i64 2
   %157 = bitcast %struct.mi_page_s** %156 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %157, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %157, align 8, !tbaa !438
   %158 = or i64 %139, 12
   %159 = add i64 %122, %158
   %160 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %13, i64 0, i32 1, i64 %159
   %161 = bitcast %struct.mi_page_s** %160 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %161, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %161, align 8, !tbaa !438
   %162 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %160, i64 2
   %163 = bitcast %struct.mi_page_s** %162 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %163, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %163, align 8, !tbaa !438
   %164 = add i64 %139, 16
   %165 = add i64 %140, -4
   %166 = icmp eq i64 %165, 0
-  br i1 %166, label %.loopexit10, label %138, !llvm.loop !540
+  br i1 %166, label %.loopexit10, label %138, !llvm.loop !544
 
 .loopexit10:                                      ; preds = %138, %126
   %167 = phi i64 [ 0, %126 ], [ %164, %138 ]
@@ -36052,14 +36615,14 @@
   %171 = add i64 %122, %169
   %172 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %13, i64 0, i32 1, i64 %171
   %173 = bitcast %struct.mi_page_s** %172 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %173, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %173, align 8, !tbaa !438
   %174 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %172, i64 2
   %175 = bitcast %struct.mi_page_s** %174 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %175, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %130, <2 x %struct.mi_page_s*>* %175, align 8, !tbaa !438
   %176 = add nuw i64 %169, 4
   %177 = add nsw i64 %170, -1
   %178 = icmp eq i64 %177, 0
-  br i1 %178, label %.loopexit9, label %.preheader, !llvm.loop !541
+  br i1 %178, label %.loopexit9, label %.preheader, !llvm.loop !545
 
 .loopexit9:                                       ; preds = %.preheader, %.loopexit10
   %179 = icmp eq i64 %124, %127
@@ -36072,20 +36635,20 @@
 182:                                              ; preds = %182, %180
   %183 = phi i64 [ %185, %182 ], [ %181, %180 ]
   %184 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %13, i64 0, i32 1, i64 %183
-  store %struct.mi_page_s* %50, %struct.mi_page_s** %184, align 8, !tbaa !434
+  store %struct.mi_page_s* %50, %struct.mi_page_s** %184, align 8, !tbaa !438
   %185 = add nuw nsw i64 %183, 1
   %186 = icmp eq i64 %183, %52
-  br i1 %186, label %.loopexit, label %182, !llvm.loop !542
+  br i1 %186, label %.loopexit, label %182, !llvm.loop !546
 
 .loopexit:                                        ; preds = %182, %.loopexit9, %116, %49, %44, %40
   %187 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %11, i64 0, i32 4
   %188 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %13, i64 0, i32 8
-  %189 = load i64, i64* %188, align 8, !tbaa !494
+  %189 = load atomic i64, i64* %188 unordered, align 8, !tbaa !498
   %190 = add i64 %189, -1
-  store i64 %190, i64* %188, align 8, !tbaa !494
+  store i64 %190, i64* %188, align 8, !tbaa !498
   %191 = bitcast %struct.mi_page_s** %25 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %191, i8 0, i64 16, i1 false) #37
-  %192 = load i8, i8* %4, align 2
+  %192 = load atomic i8, i8* %4 unordered, align 2
   %193 = and i8 %192, -2
   store i8 %193, i8* %4, align 2
   store atomic i64 0, i64* %7 release, align 8
@@ -36128,7 +36691,7 @@
 
 24:                                               ; preds = %12
   %25 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %19, i64 0, i32 2
-  %26 = load i64, i64* %25, align 8, !tbaa !472
+  %26 = load atomic i64, i64* %25 unordered, align 8, !tbaa !477
   %27 = lshr i64 %2, 14
   %28 = icmp ugt i64 %26, %27
   br i1 %28, label %30, label %29
@@ -36139,7 +36702,7 @@
 
 30:                                               ; preds = %24
   %31 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %19, i64 0, i32 5
-  %32 = load i8, i8* %31, align 1, !tbaa !477, !range !72
+  %32 = load atomic i8, i8* %31 unordered, align 1, !tbaa !482, !range !70
   %33 = icmp eq i8 %32, 0
   br i1 %33, label %34, label %40
 
@@ -36149,7 +36712,7 @@
   %36 = call fastcc zeroext i1 @mi_os_commitx(i8* %0, i64 %35, i1 zeroext false, i1 zeroext true, i8* nonnull %5) #37
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %5) #37
   %37 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %19, i64 0, i32 9
-  %38 = load i64*, i64** %37, align 8, !tbaa !480
+  %38 = load atomic i64*, i64** %37 unordered, align 8, !tbaa !485
   %39 = tail call fastcc zeroext i1 @_mi_bitmap_unclaim_across(i64* %38, i64 %21, i64 %15) #37
   br label %40
 
@@ -36172,7 +36735,7 @@
   %5 = and i64 %2, 63
   %6 = add i64 %5, %1
   %7 = icmp ult i64 %6, 65
-  br i1 %7, label %8, label %16, !prof !436, !misexpect !437
+  br i1 %7, label %8, label %16, !prof !440, !misexpect !441
 
 8:                                                ; preds = %3
   %9 = icmp ugt i64 %1, 63
@@ -36239,7 +36802,7 @@
   %55 = getelementptr inbounds i64, i64* %48, i64 1
   %56 = add nsw i64 %50, -1
   %57 = icmp eq i64 %56, 0
-  br i1 %57, label %.loopexit2, label %.preheader1, !llvm.loop !543
+  br i1 %57, label %.loopexit2, label %.preheader1, !llvm.loop !547
 
 .loopexit2:                                       ; preds = %.preheader1
   %58 = and i64 %34, 288230376151711740
@@ -36348,7 +36911,7 @@
   br i1 %6, label %8, label %7
 
 7:                                                ; preds = %5
-  store i8 0, i8* %4, align 1, !tbaa !482
+  store i8 0, i8* %4, align 1, !tbaa !465
   br label %8
 
 8:                                                ; preds = %7, %5
@@ -36358,9 +36921,9 @@
   br i1 %11, label %112, label %12
 
 12:                                               ; preds = %8
-  %13 = load i64, i64* @os_page_size, align 8, !tbaa !453
+  %13 = load atomic i64, i64* @os_page_size unordered, align 8, !tbaa !457
   %14 = ptrtoint i8* %0 to i64
-  %15 = tail call i64 @llvm.ctpop.i64(i64 %13) #37, !range !481
+  %15 = tail call i64 @llvm.ctpop.i64(i64 %13) #37, !range !486
   %16 = icmp ult i64 %15, 2
   br i1 %3, label %17, label %20
 
@@ -36495,12 +37058,12 @@
   br label %_mi_stat_counter_increase.exit
 
 99:                                               ; preds = %_mi_stat_increase.exit
-  %100 = load i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 16, i32 1), align 8, !tbaa !464
+  %100 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 16, i32 1) unordered, align 8, !tbaa !469
   %101 = add nsw i64 %100, 1
-  store i64 %101, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 16, i32 1), align 8, !tbaa !464
-  %102 = load i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 16, i32 0), align 32, !tbaa !466
+  store i64 %101, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 16, i32 1), align 8, !tbaa !469
+  %102 = load atomic i64, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 16, i32 0) unordered, align 32, !tbaa !471
   %103 = add i64 %102, 1
-  store i64 %103, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 16, i32 0), align 32, !tbaa !466
+  store i64 %103, i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 16, i32 0), align 32, !tbaa !471
   br label %_mi_stat_counter_increase.exit
 
 _mi_stat_counter_increase.exit:                   ; preds = %99, %96
@@ -36510,7 +37073,7 @@
 
 106:                                              ; preds = %_mi_stat_counter_increase.exit, %_mi_stat_decrease.exit
   %107 = tail call i32* @__errno_location() #1
-  %108 = load i32, i32* %107, align 4, !tbaa !459
+  %108 = load atomic i32, i32* %107 unordered, align 4, !tbaa !463
   %109 = icmp eq i32 %108, 0
   br i1 %109, label %112, label %110
 
@@ -36535,11 +37098,11 @@
   %6 = icmp eq i8* %0, null
   %7 = icmp eq i64 %1, 0
   %8 = or i1 %6, %7
-  br i1 %8, label %101, label %9
+  br i1 %8, label %102, label %9
 
 9:                                                ; preds = %5
-  %10 = load i64, i64* @os_page_size, align 8, !tbaa !453
-  %11 = tail call i64 @llvm.ctpop.i64(i64 %10) #37, !range !481
+  %10 = load atomic i64, i64* @os_page_size unordered, align 8, !tbaa !457
+  %11 = tail call i64 @llvm.ctpop.i64(i64 %10) #37, !range !486
   %12 = icmp ult i64 %11, 2
   %13 = add i64 %1, -1
   %14 = add i64 %13, %10
@@ -36564,13 +37127,13 @@
 
 26:                                               ; preds = %21
   tail call fastcc void @_mi_arena_free(i8* nonnull %0, i64 %22, i64 %25, i1 zeroext %3) #37
-  br label %101
+  br label %102
 
 27:                                               ; preds = %21
   %28 = lshr i64 %2, 7
   %29 = and i64 %25, 63
   %30 = icmp ugt i64 %22, 67108864
-  br i1 %30, label %101, label %31
+  br i1 %30, label %102, label %31
 
 31:                                               ; preds = %27
   %32 = add nuw nsw i64 %22, 4194303
@@ -36587,7 +37150,7 @@
   %43 = add nuw nsw i64 %33, %29
   %44 = icmp ugt i64 %43, 64
   %45 = or i1 %44, %42
-  br i1 %45, label %101, label %46
+  br i1 %45, label %102, label %46
 
 46:                                               ; preds = %31
   %47 = and i64 %22, 4194303
@@ -36647,50 +37210,54 @@
   %79 = select i1 %75, i64 0, i64 %78
   %80 = atomicrmw or i64* %74, i64 %79 acq_rel, align 8
   %81 = and i64 %80, %79
-  %.not3 = icmp eq i64 %81, %79
-  br i1 %.not3, label %.thread, label %82
+  %.not4 = icmp eq i64 %81, %79
+  br i1 %.not4, label %.thread3, label %83
 
-82:                                               ; preds = %_mi_bitmap_claim.exit3
-  %83 = load atomic i64, i64* @abandoned_readers acquire, align 64
-  %84 = icmp eq i64 %83, 0
-  br i1 %84, label %.loopexit, label %.preheader
+.thread3:                                         ; preds = %_mi_bitmap_claim.exit3
+  %82 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %28, i32 2
+  br label %92
 
-.preheader:                                       ; preds = %.preheader, %82
+83:                                               ; preds = %_mi_bitmap_claim.exit3
+  %84 = load atomic i64, i64* @abandoned_readers acquire, align 64
+  %85 = icmp eq i64 %84, 0
+  br i1 %85, label %.loopexit, label %.preheader
+
+.preheader:                                       ; preds = %.preheader, %83
   tail call void @llvm.x86.sse2.pause() #37
-  %85 = load atomic i64, i64* @abandoned_readers acquire, align 64
-  %86 = icmp eq i64 %85, 0
-  br i1 %86, label %.loopexit, label %.preheader
+  %86 = load atomic i64, i64* @abandoned_readers acquire, align 64
+  %87 = icmp eq i64 %86, 0
+  br i1 %87, label %.loopexit, label %.preheader
 
-.thread:                                          ; preds = %_mi_bitmap_claim.exit3, %72, %68, %65
-  %87 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %28, i32 2
-  br label %91
+.thread:                                          ; preds = %72, %68, %65
+  %88 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %28, i32 2
+  br label %92
 
-.loopexit:                                        ; preds = %.preheader, %82
-  %88 = and i64 %32, -4194304
-  tail call fastcc void @_mi_os_reset(i8* nonnull %0, i64 %88) #37
-  %89 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %28, i32 2
-  %90 = icmp ugt i64 %22, 264241152
-  br i1 %90, label %mi_bitmap_unclaim.exit, label %91
+.loopexit:                                        ; preds = %.preheader, %83
+  %89 = and i64 %32, -4194304
+  tail call fastcc void @_mi_os_reset(i8* nonnull %0, i64 %89) #37
+  %90 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %28, i32 2
+  %91 = icmp ugt i64 %22, 264241152
+  br i1 %91, label %mi_bitmap_unclaim.exit, label %92
 
-91:                                               ; preds = %.loopexit, %.thread
-  %92 = phi i64* [ %87, %.thread ], [ %89, %.loopexit ]
-  %93 = icmp eq i64 %33, 0
-  br i1 %93, label %mi_bitmap_unclaim.exit, label %94
+92:                                               ; preds = %.loopexit, %.thread, %.thread3
+  %93 = phi i64* [ %88, %.thread ], [ %90, %.loopexit ], [ %82, %.thread3 ]
+  %94 = icmp eq i64 %33, 0
+  br i1 %94, label %mi_bitmap_unclaim.exit, label %95
 
-94:                                               ; preds = %91
-  %95 = shl nsw i64 -1, %33
-  %96 = xor i64 %95, -1
-  %97 = shl i64 %96, %29
-  %phi.bo.i = xor i64 %97, -1
+95:                                               ; preds = %92
+  %96 = shl nsw i64 -1, %33
+  %97 = xor i64 %96, -1
+  %98 = shl i64 %97, %29
+  %phi.bo.i = xor i64 %98, -1
   br label %mi_bitmap_unclaim.exit
 
-mi_bitmap_unclaim.exit:                           ; preds = %94, %91, %.loopexit
-  %98 = phi i64* [ %92, %94 ], [ %89, %.loopexit ], [ %92, %91 ]
-  %99 = phi i64 [ %phi.bo.i, %94 ], [ 0, %.loopexit ], [ -1, %91 ]
-  %100 = atomicrmw and i64* %98, i64 %99 acq_rel, align 8
-  br label %101
+mi_bitmap_unclaim.exit:                           ; preds = %95, %92, %.loopexit
+  %99 = phi i64* [ %93, %95 ], [ %90, %.loopexit ], [ %93, %92 ]
+  %100 = phi i64 [ %phi.bo.i, %95 ], [ 0, %.loopexit ], [ -1, %92 ]
+  %101 = atomicrmw and i64* %99, i64 %100 acq_rel, align 8
+  br label %102
 
-101:                                              ; preds = %mi_bitmap_unclaim.exit, %31, %27, %26, %5
+102:                                              ; preds = %mi_bitmap_unclaim.exit, %31, %27, %26, %5
   ret void
 }
 
@@ -36714,9 +37281,9 @@
   br i1 %10, label %mi_os_resetx.exit, label %11
 
 11:                                               ; preds = %7
-  %12 = load i64, i64* @os_page_size, align 8, !tbaa !453
+  %12 = load atomic i64, i64* @os_page_size unordered, align 8, !tbaa !457
   %13 = ptrtoint i8* %0 to i64
-  %14 = tail call i64 @llvm.ctpop.i64(i64 %12) #37, !range !481
+  %14 = tail call i64 @llvm.ctpop.i64(i64 %12) #37, !range !486
   %15 = icmp ult i64 %14, 2
   %16 = add i64 %13, -1
   %17 = add i64 %16, %12
@@ -36789,12 +37356,12 @@
   br label %61
 
 61:                                               ; preds = %64, %59
-  %62 = load i32, i32* %60, align 4, !tbaa !459
+  %62 = load atomic i32, i32* %60 unordered, align 4, !tbaa !463
   %63 = icmp eq i32 %62, 11
   br i1 %63, label %64, label %67
 
 64:                                               ; preds = %61
-  store i32 0, i32* %60, align 4, !tbaa !459
+  store i32 0, i32* %60, align 4, !tbaa !463
   %65 = tail call i32 @madvise(i8* %34, i64 %35, i32 %56) #37
   %66 = icmp eq i32 %65, 0
   br i1 %66, label %mi_os_resetx.exit, label %61
@@ -36812,7 +37379,7 @@
   br i1 %73, label %mi_os_resetx.exit, label %74
 
 74:                                               ; preds = %71
-  %75 = load i32, i32* %60, align 4, !tbaa !459
+  %75 = load atomic i32, i32* %60 unordered, align 4, !tbaa !463
   br label %76
 
 76:                                               ; preds = %74, %67
@@ -36842,12 +37409,12 @@
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %10) #37
   %11 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %4) #37
   %12 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %4, i64 0, i32 0
-  %13 = load i64, i64* %12, align 8, !tbaa !456
+  %13 = load atomic i64, i64* %12 unordered, align 8, !tbaa !460
   %14 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %4, i64 0, i32 1
-  %15 = load i64, i64* %14, align 8, !tbaa !458
+  %15 = load atomic i64, i64* %14 unordered, align 8, !tbaa !462
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %10) #37
   %16 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %2, i64 0, i32 2, i32 1
-  %17 = load %struct.mi_page_s*, %struct.mi_page_s** %16, align 8, !tbaa !497
+  %17 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %16 unordered, align 8, !tbaa !501
   %18 = icmp eq %struct.mi_page_s* %17, null
   br i1 %18, label %.loopexit, label %19
 
@@ -36861,13 +37428,13 @@
 24:                                               ; preds = %76, %19
   %25 = phi %struct.mi_page_s* [ %17, %19 ], [ %31, %76 ]
   %26 = getelementptr %struct.mi_page_s, %struct.mi_page_s* %25, i64 0, i32 7
-  %27 = load i32, i32* %26, align 8, !tbaa !442
+  %27 = load atomic i32, i32* %26 unordered, align 8, !tbaa !446
   %28 = icmp sgt i32 %27, %23
   br i1 %28, label %80, label %29
 
 29:                                               ; preds = %24
   %30 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %25, i64 0, i32 13
-  %31 = load %struct.mi_page_s*, %struct.mi_page_s** %30, align 8, !tbaa !504
+  %31 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %30 unordered, align 8, !tbaa !508
   %32 = ptrtoint %struct.mi_page_s* %25 to i64
   %33 = and i64 %32, -4194304
   %34 = inttoptr i64 %33 to %struct.mi_segment_s*
@@ -36877,31 +37444,31 @@
 
 36:                                               ; preds = %29
   %37 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %34, i64 0, i32 1
-  %38 = load i8, i8* %37, align 8, !tbaa !544, !range !72
+  %38 = load atomic i8, i8* %37 unordered, align 8, !tbaa !548, !range !70
   %39 = icmp eq i8 %38, 0
   br i1 %39, label %40, label %76
 
 40:                                               ; preds = %36
   %41 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %25, i64 0, i32 1
-  %42 = load i8, i8* %41, align 1
+  %42 = load atomic i8, i8* %41 unordered, align 1
   %43 = and i8 %42, 7
   %44 = icmp eq i8 %43, 4
   br i1 %44, label %45, label %76
 
 45:                                               ; preds = %40
   %46 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %34, i64 0, i32 15
-  %47 = load i32, i32* %46, align 16, !tbaa !545
+  %47 = load atomic i32, i32* %46 unordered, align 16, !tbaa !549
   %48 = icmp eq i32 %47, 3
   br i1 %48, label %49, label %52
 
 49:                                               ; preds = %45
   %50 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %34, i64 0, i32 10
-  %51 = load i64, i64* %50, align 8, !tbaa !530
+  %51 = load atomic i64, i64* %50 unordered, align 8, !tbaa !534
   br label %56
 
 52:                                               ; preds = %45
   %53 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %34, i64 0, i32 13
-  %54 = load i64, i64* %53, align 32, !tbaa !445
+  %54 = load atomic i64, i64* %53 unordered, align 32, !tbaa !449
   %55 = shl nuw i64 1, %54
   br label %56
 
@@ -36909,7 +37476,7 @@
   %57 = phi i64 [ %51, %49 ], [ %55, %52 ]
   %58 = inttoptr i64 %33 to i8*
   %59 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %25, i64 0, i32 0
-  %60 = load i8, i8* %59, align 8, !tbaa !546
+  %60 = load atomic i8, i8* %59 unordered, align 8, !tbaa !550
   %61 = zext i8 %60 to i64
   %62 = mul i64 %57, %61
   %63 = getelementptr inbounds i8, i8* %58, i64 %62
@@ -36918,7 +37485,7 @@
 
 65:                                               ; preds = %56
   %66 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %34, i64 0, i32 11
-  %67 = load i64, i64* %66, align 16, !tbaa !547
+  %67 = load atomic i64, i64* %66 unordered, align 16, !tbaa !551
   %68 = getelementptr inbounds i8, i8* %63, i64 %67
   %69 = sub i64 %57, %67
   br label %70
@@ -36936,7 +37503,7 @@
   br label %76
 
 76:                                               ; preds = %75, %70, %40, %36, %29
-  store i32 0, i32* %26, align 8, !tbaa !442
+  store i32 0, i32* %26, align 8, !tbaa !446
   %77 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %25, i64 0, i32 12
   %78 = icmp eq %struct.mi_page_s* %31, null
   %79 = bitcast %struct.mi_page_s** %77 to i8*
@@ -36944,9 +37511,9 @@
   br i1 %78, label %.loopexit, label %24
 
 80:                                               ; preds = %24
-  store %struct.mi_page_s* %25, %struct.mi_page_s** %16, align 8, !tbaa !497
+  store %struct.mi_page_s* %25, %struct.mi_page_s** %16, align 8, !tbaa !501
   %81 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %25, i64 0, i32 12
-  store %struct.mi_page_s* null, %struct.mi_page_s** %81, align 8, !tbaa !499
+  store %struct.mi_page_s* null, %struct.mi_page_s** %81, align 8, !tbaa !503
   br label %84
 
 .loopexit:                                        ; preds = %76, %9
@@ -36958,7 +37525,7 @@
 84:                                               ; preds = %.loopexit, %80, %3
   tail call fastcc void @mi_segment_page_clear(%struct.mi_segment_s* %7, %struct.mi_page_s* %0, %struct.mi_segments_tld_s* %2)
   %85 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %7, i64 0, i32 8
-  %86 = load i64, i64* %85, align 8, !tbaa !526
+  %86 = load atomic i64, i64* %85 unordered, align 8, !tbaa !530
   %87 = icmp eq i64 %86, 0
   br i1 %87, label %88, label %89
 
@@ -36968,7 +37535,7 @@
 
 89:                                               ; preds = %84
   %90 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %7, i64 0, i32 6
-  %91 = load i64, i64* %90, align 8, !tbaa !524
+  %91 = load atomic i64, i64* %90 unordered, align 8, !tbaa !528
   %92 = icmp eq i64 %86, %91
   br i1 %92, label %93, label %94
 
@@ -36979,13 +37546,13 @@
 94:                                               ; preds = %89
   %95 = add i64 %86, 1
   %96 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %7, i64 0, i32 9
-  %97 = load i64, i64* %96, align 64, !tbaa !536
+  %97 = load atomic i64, i64* %96 unordered, align 64, !tbaa !540
   %98 = icmp eq i64 %95, %97
   br i1 %98, label %99, label %119
 
 99:                                               ; preds = %94
   %100 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %7, i64 0, i32 15
-  %101 = load i32, i32* %100, align 16, !tbaa !545
+  %101 = load atomic i32, i32* %100 unordered, align 16, !tbaa !549
   switch i32 %101, label %106 [
     i32 0, label %102
     i32 1, label %104
@@ -37002,20 +37569,20 @@
 106:                                              ; preds = %104, %102, %99
   %107 = phi %struct.mi_segment_queue_s* [ %103, %102 ], [ %105, %104 ], [ null, %99 ]
   %108 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %7, i64 0, i32 4
-  store %struct.mi_segment_s* null, %struct.mi_segment_s** %108, align 8, !tbaa !529
+  store %struct.mi_segment_s* null, %struct.mi_segment_s** %108, align 8, !tbaa !533
   %109 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %107, i64 0, i32 1
   %110 = bitcast %struct.mi_segment_s** %109 to i64*
-  %111 = load i64, i64* %110, align 8, !tbaa !548
+  %111 = load atomic i64, i64* %110 unordered, align 8, !tbaa !552
   %112 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %7, i64 0, i32 5
   %113 = bitcast %struct.mi_segment_s** %112 to i64*
-  store i64 %111, i64* %113, align 32, !tbaa !549
+  store i64 %111, i64* %113, align 32, !tbaa !553
   %114 = icmp eq i64 %111, 0
   %115 = inttoptr i64 %111 to %struct.mi_segment_s*
   %116 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %115, i64 0, i32 4
   %117 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %107, i64 0, i32 0
   %118 = select i1 %114, %struct.mi_segment_s** %117, %struct.mi_segment_s** %116
-  store %struct.mi_segment_s* %7, %struct.mi_segment_s** %118, align 8, !tbaa !434
-  store %struct.mi_segment_s* %7, %struct.mi_segment_s** %109, align 8, !tbaa !548
+  store %struct.mi_segment_s* %7, %struct.mi_segment_s** %118, align 8, !tbaa !438
+  store %struct.mi_segment_s* %7, %struct.mi_segment_s** %109, align 8, !tbaa !552
   br label %119
 
 119:                                              ; preds = %106, %94, %93, %88
@@ -37026,44 +37593,44 @@
 define internal fastcc void @mi_segment_page_clear(%struct.mi_segment_s* %0, %struct.mi_page_s* %1, %struct.mi_segments_tld_s* nocapture %2) unnamed_addr #17 {
   %4 = alloca { i64, i64 }, align 8
   %5 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %1, i64 0, i32 2
-  %6 = load i16, i16* %5, align 2, !tbaa !538
+  %6 = load atomic i16, i16* %5 unordered, align 2, !tbaa !542
   %7 = zext i16 %6 to i64
   %8 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %1, i64 0, i32 8
-  %9 = load i32, i32* %8, align 4, !tbaa !550
+  %9 = load atomic i32, i32* %8 unordered, align 4, !tbaa !554
   %10 = zext i32 %9 to i64
   %11 = icmp ult i32 %9, 67108864
-  br i1 %11, label %45, label %12, !prof !436, !misexpect !437
+  br i1 %11, label %45, label %12, !prof !440, !misexpect !441
 
 12:                                               ; preds = %3
   %13 = ptrtoint %struct.mi_page_s* %1 to i64
   %14 = and i64 %13, -4194304
   %15 = inttoptr i64 %14 to %struct.mi_segment_s*
   %16 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %15, i64 0, i32 15
-  %17 = load i32, i32* %16, align 16, !tbaa !545
+  %17 = load atomic i32, i32* %16 unordered, align 16, !tbaa !549
   %18 = icmp eq i32 %17, 3
   br i1 %18, label %19, label %22
 
 19:                                               ; preds = %12
   %20 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %15, i64 0, i32 10
-  %21 = load i64, i64* %20, align 8, !tbaa !530
+  %21 = load atomic i64, i64* %20 unordered, align 8, !tbaa !534
   br label %26
 
 22:                                               ; preds = %12
   %23 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %15, i64 0, i32 13
-  %24 = load i64, i64* %23, align 32, !tbaa !445
+  %24 = load atomic i64, i64* %23 unordered, align 32, !tbaa !449
   %25 = shl nuw i64 1, %24
   br label %26
 
 26:                                               ; preds = %22, %19
   %27 = phi i64 [ %21, %19 ], [ %25, %22 ]
   %28 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %1, i64 0, i32 0
-  %29 = load i8, i8* %28, align 8, !tbaa !546
+  %29 = load atomic i8, i8* %28 unordered, align 8, !tbaa !550
   %30 = icmp eq i8 %29, 0
   br i1 %30, label %31, label %45
 
 31:                                               ; preds = %26
   %32 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %15, i64 0, i32 11
-  %33 = load i64, i64* %32, align 16, !tbaa !547
+  %33 = load atomic i64, i64* %32 unordered, align 16, !tbaa !551
   %34 = sub i64 %27, %33
   %35 = icmp ult i32 %17, 2
   br i1 %35, label %36, label %45
@@ -37083,10 +37650,10 @@
   %46 = phi i64 [ %44, %36 ], [ %10, %3 ], [ %34, %31 ], [ %27, %26 ]
   %47 = mul i64 %46, %7
   %48 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %2, i64 0, i32 10
-  %49 = load %struct.mi_stats_s*, %struct.mi_stats_s** %48, align 8, !tbaa !525
+  %49 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %48 unordered, align 8, !tbaa !529
   %50 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %49, i64 0, i32 5
   tail call fastcc void @_mi_stat_decrease(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull %50, i64 %47) #37
-  %51 = load %struct.mi_stats_s*, %struct.mi_stats_s** %48, align 8, !tbaa !525
+  %51 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %48 unordered, align 8, !tbaa !529
   %52 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %51, i64 0, i32 1
   %53 = icmp uge %"struct.(anonymous namespace)::RootSetStatistics"* %52, getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0)
   %54 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %52, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -37118,51 +37685,51 @@
   br label %_mi_stat_decrease.exit
 
 72:                                               ; preds = %45
-  %73 = load i64, i64* %56, align 8, !tbaa !510
+  %73 = load atomic i64, i64* %56 unordered, align 8, !tbaa !514
   %74 = add i64 %73, -1
-  store i64 %74, i64* %56, align 8, !tbaa !510
+  store i64 %74, i64* %56, align 8, !tbaa !514
   %75 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %51, i64 0, i32 1, i32 2
-  %76 = load i64, i64* %75, align 8, !tbaa !511
+  %76 = load atomic i64, i64* %75 unordered, align 8, !tbaa !515
   %77 = icmp sgt i64 %74, %76
   br i1 %77, label %78, label %79
 
 78:                                               ; preds = %72
-  store i64 %74, i64* %75, align 8, !tbaa !511
+  store i64 %74, i64* %75, align 8, !tbaa !515
   br label %79
 
 79:                                               ; preds = %78, %72
   %80 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %51, i64 0, i32 1, i32 1
-  %81 = load i64, i64* %80, align 8, !tbaa !513
+  %81 = load atomic i64, i64* %80 unordered, align 8, !tbaa !517
   %82 = add i64 %81, 1
-  store i64 %82, i64* %80, align 8, !tbaa !513
+  store i64 %82, i64* %80, align 8, !tbaa !517
   br label %_mi_stat_decrease.exit
 
 _mi_stat_decrease.exit:                           ; preds = %79, %69
   %83 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %1, i64 0, i32 1
-  %84 = load i8, i8* %83, align 1
+  %84 = load atomic i8, i8* %83 unordered, align 1
   %85 = and i8 %84, -10
   store i8 %85, i8* %83, align 1
-  %86 = load i32, i32* %8, align 4, !tbaa !550
+  %86 = load atomic i32, i32* %8 unordered, align 4, !tbaa !554
   %87 = getelementptr %struct.mi_page_s, %struct.mi_page_s* %1, i64 0, i32 0
   %88 = getelementptr inbounds i8, i8* %87, i64 6
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 1 dereferenceable(62) %88, i8 0, i64 58, i1 false)
-  store i32 %86, i32* %8, align 4, !tbaa !550
+  store i32 %86, i32* %8, align 4, !tbaa !554
   %89 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 8
-  %90 = load i64, i64* %89, align 8, !tbaa !526
+  %90 = load atomic i64, i64* %89 unordered, align 8, !tbaa !530
   %91 = add i64 %90, -1
-  store i64 %91, i64* %89, align 8, !tbaa !526
+  store i64 %91, i64* %89, align 8, !tbaa !530
   %92 = tail call fastcc i64 @mi_option_get(i32 10) #37
   %.not = icmp eq i64 %92, 0
   br i1 %.not, label %169, label %93
 
 93:                                               ; preds = %_mi_stat_decrease.exit
   %94 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 1
-  %95 = load i8, i8* %94, align 8, !tbaa !544, !range !72
+  %95 = load atomic i8, i8* %94 unordered, align 8, !tbaa !548, !range !70
   %96 = icmp eq i8 %95, 0
   br i1 %96, label %97, label %169
 
 97:                                               ; preds = %93
-  %98 = load i8, i8* %83, align 1
+  %98 = load atomic i8, i8* %83 unordered, align 1
   %99 = and i8 %98, 7
   %100 = icmp eq i8 %99, 4
   br i1 %100, label %101, label %169
@@ -37178,37 +37745,37 @@
   br i1 %.not1, label %169, label %106
 
 106:                                              ; preds = %104
-  %107 = load i8, i8* %94, align 8, !tbaa !544, !range !72
+  %107 = load atomic i8, i8* %94 unordered, align 8, !tbaa !548, !range !70
   %108 = icmp eq i8 %107, 0
   br i1 %108, label %109, label %169
 
 109:                                              ; preds = %106
-  %110 = load i8, i8* %83, align 1
+  %110 = load atomic i8, i8* %83 unordered, align 1
   %111 = and i8 %110, 7
   %112 = icmp eq i8 %111, 4
   br i1 %112, label %113, label %169
 
 113:                                              ; preds = %109
   %114 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 15
-  %115 = load i32, i32* %114, align 8, !tbaa !545
+  %115 = load atomic i32, i32* %114 unordered, align 8, !tbaa !549
   %116 = icmp eq i32 %115, 3
   br i1 %116, label %117, label %120
 
 117:                                              ; preds = %113
   %118 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 10
-  %119 = load i64, i64* %118, align 8, !tbaa !530
+  %119 = load atomic i64, i64* %118 unordered, align 8, !tbaa !534
   br label %124
 
 120:                                              ; preds = %113
   %121 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 13
-  %122 = load i64, i64* %121, align 8, !tbaa !445
+  %122 = load atomic i64, i64* %121 unordered, align 8, !tbaa !449
   %123 = shl nuw i64 1, %122
   br label %124
 
 124:                                              ; preds = %120, %117
   %125 = phi i64 [ %119, %117 ], [ %123, %120 ]
   %126 = bitcast %struct.mi_segment_s* %0 to i8*
-  %127 = load i8, i8* %87, align 8, !tbaa !546
+  %127 = load atomic i8, i8* %87 unordered, align 8, !tbaa !550
   %128 = zext i8 %127 to i64
   %129 = mul i64 %125, %128
   %130 = getelementptr inbounds i8, i8* %126, i64 %129
@@ -37217,7 +37784,7 @@
 
 132:                                              ; preds = %124
   %133 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 11
-  %134 = load i64, i64* %133, align 8, !tbaa !547
+  %134 = load atomic i64, i64* %133 unordered, align 8, !tbaa !551
   %135 = getelementptr inbounds i8, i8* %130, i64 %134
   %136 = sub i64 %125, %134
   br label %137
@@ -37240,10 +37807,10 @@
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %145) #37
   %146 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %4) #37
   %147 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %4, i64 0, i32 0
-  %148 = load i64, i64* %147, align 8, !tbaa !456
+  %148 = load atomic i64, i64* %147 unordered, align 8, !tbaa !460
   %149 = mul nsw i64 %148, 1000
   %150 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %4, i64 0, i32 1
-  %151 = load i64, i64* %150, align 8, !tbaa !458
+  %151 = load atomic i64, i64* %150 unordered, align 8, !tbaa !462
   %152 = sdiv i64 %151, 1000000
   %153 = add nsw i64 %152, %149
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %145) #37
@@ -37251,28 +37818,28 @@
   %155 = add i64 %154, %153
   %156 = trunc i64 %155 to i32
   %157 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %1, i64 0, i32 7
-  store i32 %156, i32* %157, align 8, !tbaa !442
+  store i32 %156, i32* %157, align 8, !tbaa !446
   %158 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %144, i64 0, i32 0
   %159 = bitcast %struct.mi_page_queue_s* %144 to i64*
-  %160 = load i64, i64* %159, align 8, !tbaa !496
+  %160 = load atomic i64, i64* %159 unordered, align 8, !tbaa !500
   %161 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %1, i64 0, i32 12
   %162 = bitcast %struct.mi_page_s** %161 to i64*
-  store i64 %160, i64* %162, align 8, !tbaa !499
+  store i64 %160, i64* %162, align 8, !tbaa !503
   %163 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %1, i64 0, i32 13
-  store %struct.mi_page_s* null, %struct.mi_page_s** %163, align 8, !tbaa !504
+  store %struct.mi_page_s* null, %struct.mi_page_s** %163, align 8, !tbaa !508
   %164 = icmp eq i64 %160, 0
   %165 = inttoptr i64 %160 to %struct.mi_page_s*
   %166 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %165, i64 0, i32 13
   %167 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %2, i64 0, i32 2, i32 1
   %168 = select i1 %164, %struct.mi_page_s** %167, %struct.mi_page_s** %166
-  store %struct.mi_page_s* %1, %struct.mi_page_s** %168, align 8, !tbaa !434
-  store %struct.mi_page_s* %1, %struct.mi_page_s** %158, align 8, !tbaa !496
+  store %struct.mi_page_s* %1, %struct.mi_page_s** %168, align 8, !tbaa !438
+  store %struct.mi_page_s* %1, %struct.mi_page_s** %158, align 8, !tbaa !500
   br label %169
 
 169:                                              ; preds = %143, %142, %137, %109, %106, %104, %97, %93, %_mi_stat_decrease.exit
   %170 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %1, i64 0, i32 3
-  store i16 0, i16* %5, align 2, !tbaa !538
-  store i16 0, i16* %170, align 4, !tbaa !551
+  store i16 0, i16* %5, align 2, !tbaa !542
+  store i16 0, i16* %170, align 4, !tbaa !555
   ret void
 }
 
@@ -37284,13 +37851,13 @@
   %5 = tail call fastcc i64 @mi_option_get(i32 11) #37
   %.not46 = icmp eq i64 %5, 0
   %6 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 1
-  %7 = load i8, i8* %6, align 8, !tbaa !544, !range !72
+  %7 = load atomic i8, i8* %6 unordered, align 8, !tbaa !548, !range !70
   %8 = icmp eq i8 %7, 0
   br i1 %8, label %9, label %.loopexit
 
 9:                                                ; preds = %4
   %10 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 9
-  %11 = load i64, i64* %10, align 8, !tbaa !536
+  %11 = load atomic i64, i64* %10 unordered, align 8, !tbaa !540
   %12 = icmp eq i64 %11, 0
   br i1 %12, label %.loopexit, label %13
 
@@ -37314,18 +37881,18 @@
   %26 = phi i64 [ %118, %116 ], [ 0, %18 ]
   %27 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %26
   %28 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %26, i32 1
-  %29 = load i8, i8* %28, align 1
+  %29 = load atomic i8, i8* %28 unordered, align 1
   %30 = and i8 %29, 7
   %31 = icmp eq i8 %30, 4
   br i1 %31, label %32, label %116
 
 32:                                               ; preds = %24
   %33 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %26, i32 12
-  %34 = load %struct.mi_page_s*, %struct.mi_page_s** %33, align 8, !tbaa !499
+  %34 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %33 unordered, align 8, !tbaa !503
   %35 = icmp eq %struct.mi_page_s* %34, null
   %36 = ptrtoint %struct.mi_page_s* %34 to i64
   %37 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %26, i32 13
-  %38 = load %struct.mi_page_s*, %struct.mi_page_s** %37, align 8, !tbaa !504
+  %38 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %37 unordered, align 8, !tbaa !508
   br i1 %35, label %39, label %49
 
 39:                                               ; preds = %32
@@ -37337,12 +37904,12 @@
   br label %52
 
 43:                                               ; preds = %39
-  %44 = load %struct.mi_page_s*, %struct.mi_page_s** %14, align 8, !tbaa !552
+  %44 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %14 unordered, align 8, !tbaa !556
   %45 = icmp eq %struct.mi_page_s* %44, %27
   br i1 %45, label %65, label %46
 
 46:                                               ; preds = %43
-  %47 = load %struct.mi_page_s*, %struct.mi_page_s** %15, align 8, !tbaa !553
+  %47 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %15 unordered, align 8, !tbaa !557
   %48 = icmp eq %struct.mi_page_s* %47, %27
   br i1 %48, label %65, label %79
 
@@ -37355,8 +37922,8 @@
   %53 = phi i64 [ %42, %41 ], [ %50, %49 ]
   %54 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %38, i64 0, i32 12
   %55 = bitcast %struct.mi_page_s** %54 to i64*
-  store i64 %36, i64* %55, align 8, !tbaa !499
-  %56 = load %struct.mi_page_s*, %struct.mi_page_s** %33, align 8, !tbaa !499
+  store i64 %36, i64* %55, align 8, !tbaa !503
+  %56 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %33 unordered, align 8, !tbaa !503
   %57 = ptrtoint %struct.mi_page_s* %56 to i64
   %58 = icmp eq %struct.mi_page_s* %56, null
   br i1 %58, label %65, label %59
@@ -37367,33 +37934,33 @@
   %62 = phi i64 [ %53, %52 ], [ %50, %49 ]
   %63 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %60, i64 0, i32 13
   %64 = bitcast %struct.mi_page_s** %63 to i64*
-  store i64 %62, i64* %64, align 8, !tbaa !504
+  store i64 %62, i64* %64, align 8, !tbaa !508
   br label %65
 
 65:                                               ; preds = %59, %52, %46, %43
   %66 = phi i64 [ %57, %52 ], [ %61, %59 ], [ %36, %46 ], [ %36, %43 ]
-  %67 = load %struct.mi_page_s*, %struct.mi_page_s** %15, align 8, !tbaa !497
+  %67 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %15 unordered, align 8, !tbaa !501
   %68 = icmp eq %struct.mi_page_s* %67, %27
   br i1 %68, label %69, label %72
 
 69:                                               ; preds = %65
   %70 = bitcast %struct.mi_page_s** %37 to i64*
-  %71 = load i64, i64* %70, align 8, !tbaa !504
-  store i64 %71, i64* %16, align 8, !tbaa !497
+  %71 = load atomic i64, i64* %70 unordered, align 8, !tbaa !508
+  store i64 %71, i64* %16, align 8, !tbaa !501
   br label %72
 
 72:                                               ; preds = %69, %65
-  %73 = load %struct.mi_page_s*, %struct.mi_page_s** %14, align 8, !tbaa !496
+  %73 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %14 unordered, align 8, !tbaa !500
   %74 = icmp eq %struct.mi_page_s* %73, %27
   br i1 %74, label %75, label %76
 
 75:                                               ; preds = %72
-  store i64 %66, i64* %17, align 8, !tbaa !496
+  store i64 %66, i64* %17, align 8, !tbaa !500
   br label %76
 
 76:                                               ; preds = %75, %72
   %77 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %26, i32 7
-  store i32 0, i32* %77, align 8, !tbaa !442
+  store i32 0, i32* %77, align 8, !tbaa !446
   %78 = bitcast %struct.mi_page_s** %33 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %78, i8 0, i64 16, i1 false) #37
   br label %79
@@ -37404,34 +37971,34 @@
   br i1 %.not47, label %114, label %81
 
 81:                                               ; preds = %79
-  %82 = load i8, i8* %6, align 8, !tbaa !544, !range !72
+  %82 = load atomic i8, i8* %6 unordered, align 8, !tbaa !548, !range !70
   %83 = icmp eq i8 %82, 0
   br i1 %83, label %84, label %114
 
 84:                                               ; preds = %81
-  %85 = load i8, i8* %28, align 1
+  %85 = load atomic i8, i8* %28 unordered, align 1
   %86 = and i8 %85, 7
   %87 = icmp eq i8 %86, 4
   br i1 %87, label %88, label %114
 
 88:                                               ; preds = %84
-  %89 = load i32, i32* %19, align 8, !tbaa !545
+  %89 = load atomic i32, i32* %19 unordered, align 8, !tbaa !549
   %90 = icmp eq i32 %89, 3
   br i1 %90, label %91, label %93
 
 91:                                               ; preds = %88
-  %92 = load i64, i64* %21, align 8, !tbaa !530
+  %92 = load atomic i64, i64* %21 unordered, align 8, !tbaa !534
   br label %96
 
 93:                                               ; preds = %88
-  %94 = load i64, i64* %20, align 8, !tbaa !445
+  %94 = load atomic i64, i64* %20 unordered, align 8, !tbaa !449
   %95 = shl nuw i64 1, %94
   br label %96
 
 96:                                               ; preds = %93, %91
   %97 = phi i64 [ %92, %91 ], [ %95, %93 ]
   %98 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %27, i64 0, i32 0
-  %99 = load i8, i8* %98, align 8, !tbaa !546
+  %99 = load atomic i8, i8* %98 unordered, align 8, !tbaa !550
   %100 = zext i8 %99 to i64
   %101 = mul i64 %97, %100
   %102 = getelementptr inbounds i8, i8* %22, i64 %101
@@ -37439,7 +38006,7 @@
   br i1 %103, label %104, label %108
 
 104:                                              ; preds = %96
-  %105 = load i64, i64* %23, align 8, !tbaa !547
+  %105 = load atomic i64, i64* %23 unordered, align 8, !tbaa !551
   %106 = getelementptr inbounds i8, i8* %102, i64 %105
   %107 = sub i64 %97, %105
   br label %108
@@ -37457,7 +38024,7 @@
   br label %114
 
 114:                                              ; preds = %113, %108, %84, %81, %79
-  %115 = load i64, i64* %10, align 8, !tbaa !536
+  %115 = load atomic i64, i64* %10 unordered, align 8, !tbaa !540
   br label %116
 
 116:                                              ; preds = %114, %24
@@ -37469,7 +38036,7 @@
 .preheader:                                       ; preds = %173, %13
   %120 = phi i64 [ %174, %173 ], [ 0, %13 ]
   %121 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %120, i32 1
-  %122 = load i8, i8* %121, align 1
+  %122 = load atomic i8, i8* %121 unordered, align 1
   %123 = and i8 %122, 7
   %124 = icmp eq i8 %123, 4
   br i1 %124, label %125, label %173
@@ -37477,11 +38044,11 @@
 125:                                              ; preds = %.preheader
   %126 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %120
   %127 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %120, i32 12
-  %128 = load %struct.mi_page_s*, %struct.mi_page_s** %127, align 8, !tbaa !499
+  %128 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %127 unordered, align 8, !tbaa !503
   %129 = icmp eq %struct.mi_page_s* %128, null
   %130 = ptrtoint %struct.mi_page_s* %128 to i64
   %131 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %120, i32 13
-  %132 = load %struct.mi_page_s*, %struct.mi_page_s** %131, align 8, !tbaa !504
+  %132 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %131 unordered, align 8, !tbaa !508
   br i1 %129, label %133, label %143
 
 133:                                              ; preds = %125
@@ -37493,12 +38060,12 @@
   br label %146
 
 137:                                              ; preds = %133
-  %138 = load %struct.mi_page_s*, %struct.mi_page_s** %14, align 8, !tbaa !552
+  %138 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %14 unordered, align 8, !tbaa !556
   %139 = icmp eq %struct.mi_page_s* %138, %126
   br i1 %139, label %159, label %140
 
 140:                                              ; preds = %137
-  %141 = load %struct.mi_page_s*, %struct.mi_page_s** %15, align 8, !tbaa !553
+  %141 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %15 unordered, align 8, !tbaa !557
   %142 = icmp eq %struct.mi_page_s* %141, %126
   br i1 %142, label %159, label %173
 
@@ -37511,8 +38078,8 @@
   %147 = phi i64 [ %136, %135 ], [ %144, %143 ]
   %148 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %132, i64 0, i32 12
   %149 = bitcast %struct.mi_page_s** %148 to i64*
-  store i64 %130, i64* %149, align 8, !tbaa !499
-  %150 = load %struct.mi_page_s*, %struct.mi_page_s** %127, align 8, !tbaa !499
+  store i64 %130, i64* %149, align 8, !tbaa !503
+  %150 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %127 unordered, align 8, !tbaa !503
   %151 = ptrtoint %struct.mi_page_s* %150 to i64
   %152 = icmp eq %struct.mi_page_s* %150, null
   br i1 %152, label %159, label %153
@@ -37523,33 +38090,33 @@
   %156 = phi i64 [ %147, %146 ], [ %144, %143 ]
   %157 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %154, i64 0, i32 13
   %158 = bitcast %struct.mi_page_s** %157 to i64*
-  store i64 %156, i64* %158, align 8, !tbaa !504
+  store i64 %156, i64* %158, align 8, !tbaa !508
   br label %159
 
 159:                                              ; preds = %153, %146, %140, %137
   %160 = phi i64 [ %151, %146 ], [ %155, %153 ], [ %130, %140 ], [ %130, %137 ]
-  %161 = load %struct.mi_page_s*, %struct.mi_page_s** %15, align 8, !tbaa !497
+  %161 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %15 unordered, align 8, !tbaa !501
   %162 = icmp eq %struct.mi_page_s* %161, %126
   br i1 %162, label %163, label %166
 
 163:                                              ; preds = %159
   %164 = bitcast %struct.mi_page_s** %131 to i64*
-  %165 = load i64, i64* %164, align 8, !tbaa !504
-  store i64 %165, i64* %16, align 8, !tbaa !497
+  %165 = load atomic i64, i64* %164 unordered, align 8, !tbaa !508
+  store i64 %165, i64* %16, align 8, !tbaa !501
   br label %166
 
 166:                                              ; preds = %163, %159
-  %167 = load %struct.mi_page_s*, %struct.mi_page_s** %14, align 8, !tbaa !496
+  %167 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %14 unordered, align 8, !tbaa !500
   %168 = icmp eq %struct.mi_page_s* %167, %126
   br i1 %168, label %169, label %170
 
 169:                                              ; preds = %166
-  store i64 %160, i64* %17, align 8, !tbaa !496
+  store i64 %160, i64* %17, align 8, !tbaa !500
   br label %170
 
 170:                                              ; preds = %169, %166
   %171 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %120, i32 7
-  store i32 0, i32* %171, align 8, !tbaa !442
+  store i32 0, i32* %171, align 8, !tbaa !446
   %172 = bitcast %struct.mi_page_s** %127 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %172, i8 0, i64 16, i1 false) #37
   br label %173
@@ -37561,7 +38128,7 @@
 
 .loopexit:                                        ; preds = %173, %116, %9, %4
   %176 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 15
-  %177 = load i32, i32* %176, align 8, !tbaa !545
+  %177 = load atomic i32, i32* %176 unordered, align 8, !tbaa !549
   switch i32 %177, label %231 [
     i32 0, label %180
     i32 1, label %178
@@ -37579,11 +38146,11 @@
 183:                                              ; preds = %180, %178
   %184 = phi %struct.mi_segment_queue_s* [ %179, %178 ], [ %181, %180 ]
   %185 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 4
-  %186 = load %struct.mi_segment_s*, %struct.mi_segment_s** %185, align 8, !tbaa !529
+  %186 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %185 unordered, align 8, !tbaa !533
   %187 = icmp eq %struct.mi_segment_s* %186, null
   %188 = ptrtoint %struct.mi_segment_s* %186 to i64
   %189 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 5
-  %190 = load %struct.mi_segment_s*, %struct.mi_segment_s** %189, align 8, !tbaa !549
+  %190 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %189 unordered, align 8, !tbaa !553
   %191 = icmp eq %struct.mi_segment_s* %190, null
   br i1 %187, label %192, label %199
 
@@ -37596,7 +38163,7 @@
 
 195:                                              ; preds = %192
   %196 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %184, i64 0, i32 0
-  %197 = load %struct.mi_segment_s*, %struct.mi_segment_s** %196, align 8, !tbaa !554
+  %197 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %196 unordered, align 8, !tbaa !558
   %198 = icmp eq %struct.mi_segment_s* %197, %0
   br i1 %198, label %214, label %231
 
@@ -37608,8 +38175,8 @@
   %202 = phi i64 [ %194, %193 ], [ %200, %199 ]
   %203 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %190, i64 0, i32 4
   %204 = bitcast %struct.mi_segment_s** %203 to i64*
-  store i64 %188, i64* %204, align 8, !tbaa !529
-  %205 = load %struct.mi_segment_s*, %struct.mi_segment_s** %185, align 8, !tbaa !529
+  store i64 %188, i64* %204, align 8, !tbaa !533
+  %205 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %185 unordered, align 8, !tbaa !533
   %206 = ptrtoint %struct.mi_segment_s* %205 to i64
   %207 = icmp eq %struct.mi_segment_s* %205, null
   br i1 %207, label %214, label %208
@@ -37620,32 +38187,32 @@
   %211 = phi i64 [ %202, %201 ], [ %200, %199 ]
   %212 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %209, i64 0, i32 5
   %213 = bitcast %struct.mi_segment_s** %212 to i64*
-  store i64 %211, i64* %213, align 8, !tbaa !549
+  store i64 %211, i64* %213, align 8, !tbaa !553
   br label %214
 
 214:                                              ; preds = %208, %201, %195
   %215 = phi i64 [ %210, %208 ], [ %206, %201 ], [ %188, %195 ]
   %216 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %184, i64 0, i32 0
-  %217 = load %struct.mi_segment_s*, %struct.mi_segment_s** %216, align 8, !tbaa !554
+  %217 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %216 unordered, align 8, !tbaa !558
   %218 = icmp eq %struct.mi_segment_s* %217, %0
   br i1 %218, label %219, label %221
 
 219:                                              ; preds = %214
   %220 = bitcast %struct.mi_segment_queue_s* %184 to i64*
-  store i64 %215, i64* %220, align 8, !tbaa !554
+  store i64 %215, i64* %220, align 8, !tbaa !558
   br label %221
 
 221:                                              ; preds = %219, %214
   %222 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %184, i64 0, i32 1
-  %223 = load %struct.mi_segment_s*, %struct.mi_segment_s** %222, align 8, !tbaa !548
+  %223 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %222 unordered, align 8, !tbaa !552
   %224 = icmp eq %struct.mi_segment_s* %223, %0
   br i1 %224, label %225, label %229
 
 225:                                              ; preds = %221
   %226 = bitcast %struct.mi_segment_s** %189 to i64*
-  %227 = load i64, i64* %226, align 8, !tbaa !549
+  %227 = load atomic i64, i64* %226 unordered, align 8, !tbaa !553
   %228 = bitcast %struct.mi_segment_s** %222 to i64*
-  store i64 %227, i64* %228, align 8, !tbaa !548
+  store i64 %227, i64* %228, align 8, !tbaa !552
   br label %229
 
 229:                                              ; preds = %225, %221
@@ -37655,22 +38222,22 @@
 
 231:                                              ; preds = %229, %195, %180, %.loopexit
   %232 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %2, i64 0, i32 10
-  %233 = load %struct.mi_stats_s*, %struct.mi_stats_s** %232, align 8, !tbaa !525
+  %233 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %232 unordered, align 8, !tbaa !529
   %234 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %233, i64 0, i32 5
   %235 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 11
-  %236 = load i64, i64* %235, align 8, !tbaa !547
+  %236 = load atomic i64, i64* %235 unordered, align 8, !tbaa !551
   tail call fastcc void @_mi_stat_decrease(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull %234, i64 %236) #37
   br label %.loopexit50
 
 237:                                              ; preds = %3
   %238 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 1
-  %239 = load i8, i8* %238, align 8, !tbaa !544, !range !72
+  %239 = load atomic i8, i8* %238 unordered, align 8, !tbaa !548, !range !70
   %240 = icmp eq i8 %239, 0
   br i1 %240, label %241, label %.loopexit51
 
 241:                                              ; preds = %237
   %242 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 9
-  %243 = load i64, i64* %242, align 8, !tbaa !536
+  %243 = load atomic i64, i64* %242 unordered, align 8, !tbaa !540
   %244 = icmp eq i64 %243, 0
   br i1 %244, label %.loopexit51, label %245
 
@@ -37684,7 +38251,7 @@
 250:                                              ; preds = %304, %245
   %251 = phi i64 [ %305, %304 ], [ 0, %245 ]
   %252 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %251, i32 1
-  %253 = load i8, i8* %252, align 1
+  %253 = load atomic i8, i8* %252 unordered, align 1
   %254 = and i8 %253, 7
   %255 = icmp eq i8 %254, 4
   br i1 %255, label %256, label %304
@@ -37692,11 +38259,11 @@
 256:                                              ; preds = %250
   %257 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %251
   %258 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %251, i32 12
-  %259 = load %struct.mi_page_s*, %struct.mi_page_s** %258, align 8, !tbaa !499
+  %259 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %258 unordered, align 8, !tbaa !503
   %260 = icmp eq %struct.mi_page_s* %259, null
   %261 = ptrtoint %struct.mi_page_s* %259 to i64
   %262 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %251, i32 13
-  %263 = load %struct.mi_page_s*, %struct.mi_page_s** %262, align 8, !tbaa !504
+  %263 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %262 unordered, align 8, !tbaa !508
   br i1 %260, label %264, label %274
 
 264:                                              ; preds = %256
@@ -37708,12 +38275,12 @@
   br label %277
 
 268:                                              ; preds = %264
-  %269 = load %struct.mi_page_s*, %struct.mi_page_s** %246, align 8, !tbaa !552
+  %269 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %246 unordered, align 8, !tbaa !556
   %270 = icmp eq %struct.mi_page_s* %269, %257
   br i1 %270, label %290, label %271
 
 271:                                              ; preds = %268
-  %272 = load %struct.mi_page_s*, %struct.mi_page_s** %247, align 8, !tbaa !553
+  %272 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %247 unordered, align 8, !tbaa !557
   %273 = icmp eq %struct.mi_page_s* %272, %257
   br i1 %273, label %290, label %304
 
@@ -37726,8 +38293,8 @@
   %278 = phi i64 [ %267, %266 ], [ %275, %274 ]
   %279 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %263, i64 0, i32 12
   %280 = bitcast %struct.mi_page_s** %279 to i64*
-  store i64 %261, i64* %280, align 8, !tbaa !499
-  %281 = load %struct.mi_page_s*, %struct.mi_page_s** %258, align 8, !tbaa !499
+  store i64 %261, i64* %280, align 8, !tbaa !503
+  %281 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %258 unordered, align 8, !tbaa !503
   %282 = ptrtoint %struct.mi_page_s* %281 to i64
   %283 = icmp eq %struct.mi_page_s* %281, null
   br i1 %283, label %290, label %284
@@ -37738,33 +38305,33 @@
   %287 = phi i64 [ %278, %277 ], [ %275, %274 ]
   %288 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %285, i64 0, i32 13
   %289 = bitcast %struct.mi_page_s** %288 to i64*
-  store i64 %287, i64* %289, align 8, !tbaa !504
+  store i64 %287, i64* %289, align 8, !tbaa !508
   br label %290
 
 290:                                              ; preds = %284, %277, %271, %268
   %291 = phi i64 [ %282, %277 ], [ %286, %284 ], [ %261, %271 ], [ %261, %268 ]
-  %292 = load %struct.mi_page_s*, %struct.mi_page_s** %247, align 8, !tbaa !497
+  %292 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %247 unordered, align 8, !tbaa !501
   %293 = icmp eq %struct.mi_page_s* %292, %257
   br i1 %293, label %294, label %297
 
 294:                                              ; preds = %290
   %295 = bitcast %struct.mi_page_s** %262 to i64*
-  %296 = load i64, i64* %295, align 8, !tbaa !504
-  store i64 %296, i64* %248, align 8, !tbaa !497
+  %296 = load atomic i64, i64* %295 unordered, align 8, !tbaa !508
+  store i64 %296, i64* %248, align 8, !tbaa !501
   br label %297
 
 297:                                              ; preds = %294, %290
-  %298 = load %struct.mi_page_s*, %struct.mi_page_s** %246, align 8, !tbaa !496
+  %298 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %246 unordered, align 8, !tbaa !500
   %299 = icmp eq %struct.mi_page_s* %298, %257
   br i1 %299, label %300, label %301
 
 300:                                              ; preds = %297
-  store i64 %291, i64* %249, align 8, !tbaa !496
+  store i64 %291, i64* %249, align 8, !tbaa !500
   br label %301
 
 301:                                              ; preds = %300, %297
   %302 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %251, i32 7
-  store i32 0, i32* %302, align 8, !tbaa !442
+  store i32 0, i32* %302, align 8, !tbaa !446
   %303 = bitcast %struct.mi_page_s** %258 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %303, i8 0, i64 16, i1 false) #37
   br label %304
@@ -37776,7 +38343,7 @@
 
 .loopexit51:                                      ; preds = %304, %241, %237
   %307 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 15
-  %308 = load i32, i32* %307, align 8, !tbaa !545
+  %308 = load atomic i32, i32* %307 unordered, align 8, !tbaa !549
   switch i32 %308, label %362 [
     i32 0, label %311
     i32 1, label %309
@@ -37794,11 +38361,11 @@
 314:                                              ; preds = %311, %309
   %315 = phi %struct.mi_segment_queue_s* [ %310, %309 ], [ %312, %311 ]
   %316 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 4
-  %317 = load %struct.mi_segment_s*, %struct.mi_segment_s** %316, align 8, !tbaa !529
+  %317 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %316 unordered, align 8, !tbaa !533
   %318 = icmp eq %struct.mi_segment_s* %317, null
   %319 = ptrtoint %struct.mi_segment_s* %317 to i64
   %320 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 5
-  %321 = load %struct.mi_segment_s*, %struct.mi_segment_s** %320, align 8, !tbaa !549
+  %321 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %320 unordered, align 8, !tbaa !553
   %322 = icmp eq %struct.mi_segment_s* %321, null
   br i1 %318, label %323, label %330
 
@@ -37811,7 +38378,7 @@
 
 326:                                              ; preds = %323
   %327 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %315, i64 0, i32 0
-  %328 = load %struct.mi_segment_s*, %struct.mi_segment_s** %327, align 8, !tbaa !554
+  %328 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %327 unordered, align 8, !tbaa !558
   %329 = icmp eq %struct.mi_segment_s* %328, %0
   br i1 %329, label %345, label %362
 
@@ -37823,8 +38390,8 @@
   %333 = phi i64 [ %325, %324 ], [ %331, %330 ]
   %334 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %321, i64 0, i32 4
   %335 = bitcast %struct.mi_segment_s** %334 to i64*
-  store i64 %319, i64* %335, align 8, !tbaa !529
-  %336 = load %struct.mi_segment_s*, %struct.mi_segment_s** %316, align 8, !tbaa !529
+  store i64 %319, i64* %335, align 8, !tbaa !533
+  %336 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %316 unordered, align 8, !tbaa !533
   %337 = ptrtoint %struct.mi_segment_s* %336 to i64
   %338 = icmp eq %struct.mi_segment_s* %336, null
   br i1 %338, label %345, label %339
@@ -37835,32 +38402,32 @@
   %342 = phi i64 [ %333, %332 ], [ %331, %330 ]
   %343 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %340, i64 0, i32 5
   %344 = bitcast %struct.mi_segment_s** %343 to i64*
-  store i64 %342, i64* %344, align 8, !tbaa !549
+  store i64 %342, i64* %344, align 8, !tbaa !553
   br label %345
 
 345:                                              ; preds = %339, %332, %326
   %346 = phi i64 [ %341, %339 ], [ %337, %332 ], [ %319, %326 ]
   %347 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %315, i64 0, i32 0
-  %348 = load %struct.mi_segment_s*, %struct.mi_segment_s** %347, align 8, !tbaa !554
+  %348 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %347 unordered, align 8, !tbaa !558
   %349 = icmp eq %struct.mi_segment_s* %348, %0
   br i1 %349, label %350, label %352
 
 350:                                              ; preds = %345
   %351 = bitcast %struct.mi_segment_queue_s* %315 to i64*
-  store i64 %346, i64* %351, align 8, !tbaa !554
+  store i64 %346, i64* %351, align 8, !tbaa !558
   br label %352
 
 352:                                              ; preds = %350, %345
   %353 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %315, i64 0, i32 1
-  %354 = load %struct.mi_segment_s*, %struct.mi_segment_s** %353, align 8, !tbaa !548
+  %354 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %353 unordered, align 8, !tbaa !552
   %355 = icmp eq %struct.mi_segment_s* %354, %0
   br i1 %355, label %356, label %360
 
 356:                                              ; preds = %352
   %357 = bitcast %struct.mi_segment_s** %320 to i64*
-  %358 = load i64, i64* %357, align 8, !tbaa !549
+  %358 = load atomic i64, i64* %357 unordered, align 8, !tbaa !553
   %359 = bitcast %struct.mi_segment_s** %353 to i64*
-  store i64 %358, i64* %359, align 8, !tbaa !548
+  store i64 %358, i64* %359, align 8, !tbaa !552
   br label %360
 
 360:                                              ; preds = %356, %352
@@ -37870,26 +38437,26 @@
 
 362:                                              ; preds = %360, %326, %311, %.loopexit51
   %363 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %2, i64 0, i32 10
-  %364 = load %struct.mi_stats_s*, %struct.mi_stats_s** %363, align 8, !tbaa !525
+  %364 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %363 unordered, align 8, !tbaa !529
   %365 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %364, i64 0, i32 5
   %366 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 11
-  %367 = load i64, i64* %366, align 8, !tbaa !547
+  %367 = load atomic i64, i64* %366 unordered, align 8, !tbaa !551
   tail call fastcc void @_mi_stat_decrease(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull %365, i64 %367) #37
   %368 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 10
-  %369 = load i64, i64* %368, align 8, !tbaa !530
+  %369 = load atomic i64, i64* %368 unordered, align 8, !tbaa !534
   %370 = icmp eq i64 %369, 4194304
   br i1 %370, label %371, label %.loopexit50
 
 371:                                              ; preds = %362
   %372 = tail call fastcc i64 @mi_option_get(i32 9) #37
   %373 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %2, i64 0, i32 7
-  %374 = load i64, i64* %373, align 8, !tbaa !528
+  %374 = load atomic i64, i64* %373 unordered, align 8, !tbaa !532
   %375 = icmp ult i64 %374, %372
   br i1 %375, label %376, label %381
 
 376:                                              ; preds = %371
   %377 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %2, i64 0, i32 4
-  %378 = load i64, i64* %377, align 8, !tbaa !533
+  %378 = load atomic i64, i64* %377 unordered, align 8, !tbaa !537
   %379 = lshr i64 %378, 3
   %380 = icmp ugt i64 %374, %379
   br i1 %380, label %381, label %568
@@ -37909,19 +38476,19 @@
 
 390:                                              ; preds = %565, %383
   %391 = phi i64 [ %374, %383 ], [ %566, %565 ]
-  %392 = load %struct.mi_segment_s*, %struct.mi_segment_s** %384, align 8, !tbaa !527
+  %392 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %384 unordered, align 8, !tbaa !531
   %393 = icmp eq %struct.mi_segment_s* %392, null
   br i1 %393, label %565, label %394
 
 394:                                              ; preds = %390
   %395 = add i64 %391, -1
-  store i64 %395, i64* %373, align 8, !tbaa !528
+  store i64 %395, i64* %373, align 8, !tbaa !532
   %396 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %392, i64 0, i32 4
   %397 = bitcast %struct.mi_segment_s** %396 to i64*
-  %398 = load i64, i64* %397, align 8, !tbaa !529
-  store i64 %398, i64* %385, align 8, !tbaa !527
-  store %struct.mi_segment_s* null, %struct.mi_segment_s** %396, align 8, !tbaa !529
-  %399 = load %struct.mi_stats_s*, %struct.mi_stats_s** %363, align 8, !tbaa !525
+  %398 = load atomic i64, i64* %397 unordered, align 8, !tbaa !533
+  store i64 %398, i64* %385, align 8, !tbaa !531
+  store %struct.mi_segment_s* null, %struct.mi_segment_s** %396, align 8, !tbaa !533
+  %399 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %363 unordered, align 8, !tbaa !529
   %400 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %399, i64 0, i32 13
   %401 = icmp uge %"struct.(anonymous namespace)::RootSetStatistics"* %400, getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0)
   %402 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %400, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -37953,32 +38520,32 @@
   br label %_mi_stat_decrease.exit
 
 420:                                              ; preds = %394
-  %421 = load i64, i64* %404, align 8, !tbaa !510
+  %421 = load atomic i64, i64* %404 unordered, align 8, !tbaa !514
   %422 = add i64 %421, -1
-  store i64 %422, i64* %404, align 8, !tbaa !510
+  store i64 %422, i64* %404, align 8, !tbaa !514
   %423 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %399, i64 0, i32 13, i32 2
-  %424 = load i64, i64* %423, align 8, !tbaa !511
+  %424 = load atomic i64, i64* %423 unordered, align 8, !tbaa !515
   %425 = icmp sgt i64 %422, %424
   br i1 %425, label %426, label %427
 
 426:                                              ; preds = %420
-  store i64 %422, i64* %423, align 8, !tbaa !511
+  store i64 %422, i64* %423, align 8, !tbaa !515
   br label %427
 
 427:                                              ; preds = %426, %420
   %428 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %399, i64 0, i32 13, i32 1
-  %429 = load i64, i64* %428, align 8, !tbaa !513
+  %429 = load atomic i64, i64* %428 unordered, align 8, !tbaa !517
   %430 = add i64 %429, 1
-  store i64 %430, i64* %428, align 8, !tbaa !513
+  store i64 %430, i64* %428, align 8, !tbaa !517
   br label %_mi_stat_decrease.exit
 
 _mi_stat_decrease.exit:                           ; preds = %427, %417
   %431 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %392, i64 0, i32 10
-  %432 = load i64, i64* %431, align 8, !tbaa !530
+  %432 = load atomic i64, i64* %431 unordered, align 8, !tbaa !534
   %433 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %392, i64 0, i32 14
-  store atomic i64 0, i64* %433 seq_cst, align 8, !tbaa !531
+  store atomic i64 0, i64* %433 seq_cst, align 8, !tbaa !535
   %434 = icmp slt i64 %432, 1
-  %435 = load %struct.mi_stats_s*, %struct.mi_stats_s** %363, align 8, !tbaa !525
+  %435 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %363 unordered, align 8, !tbaa !529
   %436 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %435, i64 0, i32 0
   %437 = icmp uge %struct.mi_stats_s* %435, @_mi_stats_main
   %438 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %436, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -38013,23 +38580,23 @@
   br label %_mi_stat_increase.exit
 
 456:                                              ; preds = %441
-  %457 = load i64, i64* %440, align 8, !tbaa !510
+  %457 = load atomic i64, i64* %440 unordered, align 8, !tbaa !514
   %458 = add nsw i64 %457, 1
-  store i64 %458, i64* %440, align 8, !tbaa !510
+  store i64 %458, i64* %440, align 8, !tbaa !514
   %459 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %435, i64 0, i32 0, i32 2
-  %460 = load i64, i64* %459, align 8, !tbaa !511
+  %460 = load atomic i64, i64* %459 unordered, align 8, !tbaa !515
   %.not42 = icmp slt i64 %457, %460
   br i1 %.not42, label %462, label %461
 
 461:                                              ; preds = %456
-  store i64 %458, i64* %459, align 8, !tbaa !511
+  store i64 %458, i64* %459, align 8, !tbaa !515
   br label %462
 
 462:                                              ; preds = %461, %456
   %463 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %435, i64 0, i32 0, i32 0
-  %464 = load i64, i64* %463, align 8, !tbaa !512
+  %464 = load atomic i64, i64* %463 unordered, align 8, !tbaa !516
   %465 = add nsw i64 %464, 1
-  store i64 %465, i64* %463, align 8, !tbaa !512
+  store i64 %465, i64* %463, align 8, !tbaa !516
   br label %_mi_stat_increase.exit
 
 466:                                              ; preds = %_mi_stat_decrease.exit
@@ -38059,53 +38626,53 @@
   br label %_mi_stat_increase.exit
 
 482:                                              ; preds = %466
-  %483 = load i64, i64* %440, align 8, !tbaa !510
+  %483 = load atomic i64, i64* %440 unordered, align 8, !tbaa !514
   %484 = add i64 %483, -1
-  store i64 %484, i64* %440, align 8, !tbaa !510
+  store i64 %484, i64* %440, align 8, !tbaa !514
   %485 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %435, i64 0, i32 0, i32 2
-  %486 = load i64, i64* %485, align 8, !tbaa !511
+  %486 = load atomic i64, i64* %485 unordered, align 8, !tbaa !515
   %487 = icmp sgt i64 %484, %486
   br i1 %487, label %488, label %489
 
 488:                                              ; preds = %482
-  store i64 %484, i64* %485, align 8, !tbaa !511
+  store i64 %484, i64* %485, align 8, !tbaa !515
   br label %489
 
 489:                                              ; preds = %488, %482
   %490 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %435, i64 0, i32 0, i32 1
-  %491 = load i64, i64* %490, align 8, !tbaa !513
+  %491 = load atomic i64, i64* %490 unordered, align 8, !tbaa !517
   %492 = add i64 %491, 1
-  store i64 %492, i64* %490, align 8, !tbaa !513
+  store i64 %492, i64* %490, align 8, !tbaa !517
   br label %_mi_stat_increase.exit
 
 _mi_stat_increase.exit:                           ; preds = %489, %479, %462, %453
   %493 = phi i64 [ 1, %453 ], [ 1, %462 ], [ -1, %479 ], [ -1, %489 ]
-  %494 = load i64, i64* %386, align 8, !tbaa !532
+  %494 = load atomic i64, i64* %386 unordered, align 8, !tbaa !536
   %495 = add i64 %494, %493
-  store i64 %495, i64* %386, align 8, !tbaa !532
-  %496 = load i64, i64* %387, align 8, !tbaa !533
+  store i64 %495, i64* %386, align 8, !tbaa !536
+  %496 = load atomic i64, i64* %387 unordered, align 8, !tbaa !537
   %497 = icmp ugt i64 %495, %496
   br i1 %497, label %498, label %499
 
 498:                                              ; preds = %_mi_stat_increase.exit
-  store i64 %495, i64* %387, align 8, !tbaa !533
+  store i64 %495, i64* %387, align 8, !tbaa !537
   br label %499
 
 499:                                              ; preds = %498, %_mi_stat_increase.exit
-  %500 = load i64, i64* %388, align 8, !tbaa !534
+  %500 = load atomic i64, i64* %388 unordered, align 8, !tbaa !538
   %501 = sub i64 %500, %432
-  store i64 %501, i64* %388, align 8, !tbaa !534
-  %502 = load i64, i64* %389, align 8, !tbaa !535
+  store i64 %501, i64* %388, align 8, !tbaa !538
+  %502 = load atomic i64, i64* %389 unordered, align 8, !tbaa !539
   %503 = icmp ugt i64 %501, %502
   br i1 %503, label %504, label %505
 
 504:                                              ; preds = %499
-  store i64 %501, i64* %389, align 8, !tbaa !535
+  store i64 %501, i64* %389, align 8, !tbaa !539
   br label %505
 
 505:                                              ; preds = %504, %499
   %506 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %392, i64 0, i32 9
-  %507 = load i64, i64* %506, align 8, !tbaa !536
+  %507 = load atomic i64, i64* %506 unordered, align 8, !tbaa !540
   %508 = icmp eq i64 %507, 0
   br i1 %508, label %556, label %509
 
@@ -38127,7 +38694,7 @@
   %517 = phi i64 [ %513, %514 ], [ 0, %509 ]
   %518 = phi i8 [ %549, %514 ], [ 0, %509 ]
   %519 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %392, i64 0, i32 16, i64 %517, i32 1
-  %520 = load i8, i8* %519, align 1
+  %520 = load atomic i8, i8* %519 unordered, align 1
   %521 = and i8 %520, 2
   %522 = icmp eq i8 %521, 0
   %523 = select i1 %522, i8 %518, i8 1
@@ -38149,10 +38716,10 @@
   %535 = phi i8 [ 1, %512 ], [ %545, %532 ]
   %536 = phi i64 [ %513, %512 ], [ %551, %532 ]
   %537 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %392, i64 0, i32 16, i64 %534, i32 1
-  %538 = load i8, i8* %537, align 1
+  %538 = load atomic i8, i8* %537 unordered, align 1
   %539 = or i64 %534, 1
   %540 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %392, i64 0, i32 16, i64 %539, i32 1
-  %541 = load i8, i8* %540, align 1
+  %541 = load atomic i8, i8* %540 unordered, align 1
   %542 = and i8 %541, %538
   %543 = and i8 %542, 4
   %544 = icmp eq i8 %543, 0
@@ -38177,11 +38744,11 @@
   %558 = phi i8 [ %528, %527 ], [ %555, %553 ], [ 1, %505 ]
   %559 = bitcast %struct.mi_segment_s* %392 to i8*
   %560 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %392, i64 0, i32 0
-  %561 = load i64, i64* %560, align 8, !tbaa !537
+  %561 = load atomic i64, i64* %560 unordered, align 8, !tbaa !541
   %562 = and i8 %558, 1
   %563 = icmp ne i8 %562, 0
   tail call fastcc void @_mi_mem_free(i8* nonnull %559, i64 %432, i64 %561, i1 zeroext %563, i1 zeroext %557) #37
-  %564 = load i64, i64* %373, align 8, !tbaa !528
+  %564 = load atomic i64, i64* %373 unordered, align 8, !tbaa !532
   br label %565
 
 565:                                              ; preds = %556, %390
@@ -38192,14 +38759,14 @@
 568:                                              ; preds = %376
   %569 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %2, i64 0, i32 9
   %570 = bitcast %struct.mi_segment_s** %569 to i64*
-  %571 = load i64, i64* %570, align 8, !tbaa !527
+  %571 = load atomic i64, i64* %570 unordered, align 8, !tbaa !531
   %572 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 4
   %573 = bitcast %struct.mi_segment_s** %572 to i64*
-  store i64 %571, i64* %573, align 8, !tbaa !529
-  store %struct.mi_segment_s* %0, %struct.mi_segment_s** %569, align 8, !tbaa !527
+  store i64 %571, i64* %573, align 8, !tbaa !533
+  store %struct.mi_segment_s* %0, %struct.mi_segment_s** %569, align 8, !tbaa !531
   %574 = add nuw i64 %374, 1
-  store i64 %574, i64* %373, align 8, !tbaa !528
-  %575 = load %struct.mi_stats_s*, %struct.mi_stats_s** %363, align 8, !tbaa !525
+  store i64 %574, i64* %373, align 8, !tbaa !532
+  %575 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %363 unordered, align 8, !tbaa !529
   %576 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %575, i64 0, i32 13
   %577 = icmp uge %"struct.(anonymous namespace)::RootSetStatistics"* %576, getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0)
   %578 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %576, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -38231,33 +38798,33 @@
   br label %_mi_stat_increase.exit38
 
 595:                                              ; preds = %568
-  %596 = load i64, i64* %580, align 8, !tbaa !510
+  %596 = load atomic i64, i64* %580 unordered, align 8, !tbaa !514
   %597 = add nsw i64 %596, 1
-  store i64 %597, i64* %580, align 8, !tbaa !510
+  store i64 %597, i64* %580, align 8, !tbaa !514
   %598 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %575, i64 0, i32 13, i32 2
-  %599 = load i64, i64* %598, align 8, !tbaa !511
+  %599 = load atomic i64, i64* %598 unordered, align 8, !tbaa !515
   %.not44 = icmp slt i64 %596, %599
   br i1 %.not44, label %601, label %600
 
 600:                                              ; preds = %595
-  store i64 %597, i64* %598, align 8, !tbaa !511
+  store i64 %597, i64* %598, align 8, !tbaa !515
   br label %601
 
 601:                                              ; preds = %600, %595
   %602 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %576, i64 0, i32 0
-  %603 = load i64, i64* %602, align 8, !tbaa !512
+  %603 = load atomic i64, i64* %602 unordered, align 8, !tbaa !516
   %604 = add nsw i64 %603, 1
-  store i64 %604, i64* %602, align 8, !tbaa !512
+  store i64 %604, i64* %602, align 8, !tbaa !516
   br label %_mi_stat_increase.exit38
 
 .loopexit50:                                      ; preds = %565, %381, %362, %231
   %605 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 10
-  %606 = load i64, i64* %605, align 8, !tbaa !530
+  %606 = load atomic i64, i64* %605 unordered, align 8, !tbaa !534
   %607 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 14
-  store atomic i64 0, i64* %607 seq_cst, align 8, !tbaa !531
+  store atomic i64 0, i64* %607 seq_cst, align 8, !tbaa !535
   %608 = icmp slt i64 %606, 1
   %609 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %2, i64 0, i32 10
-  %610 = load %struct.mi_stats_s*, %struct.mi_stats_s** %609, align 8, !tbaa !525
+  %610 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %609 unordered, align 8, !tbaa !529
   %611 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %610, i64 0, i32 0
   %612 = icmp uge %struct.mi_stats_s* %610, @_mi_stats_main
   %613 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %611, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -38292,23 +38859,23 @@
   br label %_mi_stat_increase.exit37
 
 631:                                              ; preds = %616
-  %632 = load i64, i64* %615, align 8, !tbaa !510
+  %632 = load atomic i64, i64* %615 unordered, align 8, !tbaa !514
   %633 = add nsw i64 %632, 1
-  store i64 %633, i64* %615, align 8, !tbaa !510
+  store i64 %633, i64* %615, align 8, !tbaa !514
   %634 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %610, i64 0, i32 0, i32 2
-  %635 = load i64, i64* %634, align 8, !tbaa !511
+  %635 = load atomic i64, i64* %634 unordered, align 8, !tbaa !515
   %.not39 = icmp slt i64 %632, %635
   br i1 %.not39, label %637, label %636
 
 636:                                              ; preds = %631
-  store i64 %633, i64* %634, align 8, !tbaa !511
+  store i64 %633, i64* %634, align 8, !tbaa !515
   br label %637
 
 637:                                              ; preds = %636, %631
   %638 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %610, i64 0, i32 0, i32 0
-  %639 = load i64, i64* %638, align 8, !tbaa !512
+  %639 = load atomic i64, i64* %638 unordered, align 8, !tbaa !516
   %640 = add nsw i64 %639, 1
-  store i64 %640, i64* %638, align 8, !tbaa !512
+  store i64 %640, i64* %638, align 8, !tbaa !516
   br label %_mi_stat_increase.exit37
 
 641:                                              ; preds = %.loopexit50
@@ -38338,57 +38905,57 @@
   br label %_mi_stat_increase.exit37
 
 657:                                              ; preds = %641
-  %658 = load i64, i64* %615, align 8, !tbaa !510
+  %658 = load atomic i64, i64* %615 unordered, align 8, !tbaa !514
   %659 = add i64 %658, -1
-  store i64 %659, i64* %615, align 8, !tbaa !510
+  store i64 %659, i64* %615, align 8, !tbaa !514
   %660 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %610, i64 0, i32 0, i32 2
-  %661 = load i64, i64* %660, align 8, !tbaa !511
+  %661 = load atomic i64, i64* %660 unordered, align 8, !tbaa !515
   %662 = icmp sgt i64 %659, %661
   br i1 %662, label %663, label %664
 
 663:                                              ; preds = %657
-  store i64 %659, i64* %660, align 8, !tbaa !511
+  store i64 %659, i64* %660, align 8, !tbaa !515
   br label %664
 
 664:                                              ; preds = %663, %657
   %665 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %610, i64 0, i32 0, i32 1
-  %666 = load i64, i64* %665, align 8, !tbaa !513
+  %666 = load atomic i64, i64* %665 unordered, align 8, !tbaa !517
   %667 = add i64 %666, 1
-  store i64 %667, i64* %665, align 8, !tbaa !513
+  store i64 %667, i64* %665, align 8, !tbaa !517
   br label %_mi_stat_increase.exit37
 
 _mi_stat_increase.exit37:                         ; preds = %664, %654, %637, %628
   %668 = phi i64 [ 1, %628 ], [ 1, %637 ], [ -1, %654 ], [ -1, %664 ]
   %669 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %2, i64 0, i32 3
-  %670 = load i64, i64* %669, align 8, !tbaa !532
+  %670 = load atomic i64, i64* %669 unordered, align 8, !tbaa !536
   %671 = add i64 %670, %668
-  store i64 %671, i64* %669, align 8, !tbaa !532
+  store i64 %671, i64* %669, align 8, !tbaa !536
   %672 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %2, i64 0, i32 4
-  %673 = load i64, i64* %672, align 8, !tbaa !533
+  %673 = load atomic i64, i64* %672 unordered, align 8, !tbaa !537
   %674 = icmp ugt i64 %671, %673
   br i1 %674, label %675, label %676
 
 675:                                              ; preds = %_mi_stat_increase.exit37
-  store i64 %671, i64* %672, align 8, !tbaa !533
+  store i64 %671, i64* %672, align 8, !tbaa !537
   br label %676
 
 676:                                              ; preds = %675, %_mi_stat_increase.exit37
   %677 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %2, i64 0, i32 5
-  %678 = load i64, i64* %677, align 8, !tbaa !534
+  %678 = load atomic i64, i64* %677 unordered, align 8, !tbaa !538
   %679 = sub i64 %678, %606
-  store i64 %679, i64* %677, align 8, !tbaa !534
+  store i64 %679, i64* %677, align 8, !tbaa !538
   %680 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %2, i64 0, i32 6
-  %681 = load i64, i64* %680, align 8, !tbaa !535
+  %681 = load atomic i64, i64* %680 unordered, align 8, !tbaa !539
   %682 = icmp ugt i64 %679, %681
   br i1 %682, label %683, label %684
 
 683:                                              ; preds = %676
-  store i64 %679, i64* %680, align 8, !tbaa !535
+  store i64 %679, i64* %680, align 8, !tbaa !539
   br label %684
 
 684:                                              ; preds = %683, %676
   %685 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 9
-  %686 = load i64, i64* %685, align 8, !tbaa !536
+  %686 = load atomic i64, i64* %685 unordered, align 8, !tbaa !540
   %687 = icmp eq i64 %686, 0
   br i1 %687, label %735, label %688
 
@@ -38410,7 +38977,7 @@
   %696 = phi i64 [ %692, %693 ], [ 0, %688 ]
   %697 = phi i8 [ %728, %693 ], [ 0, %688 ]
   %698 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %696, i32 1
-  %699 = load i8, i8* %698, align 1
+  %699 = load atomic i8, i8* %698 unordered, align 1
   %700 = and i8 %699, 2
   %701 = icmp eq i8 %700, 0
   %702 = select i1 %701, i8 %697, i8 1
@@ -38432,10 +38999,10 @@
   %714 = phi i8 [ 1, %691 ], [ %724, %711 ]
   %715 = phi i64 [ %692, %691 ], [ %730, %711 ]
   %716 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %713, i32 1
-  %717 = load i8, i8* %716, align 1
+  %717 = load atomic i8, i8* %716 unordered, align 1
   %718 = or i64 %713, 1
   %719 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %718, i32 1
-  %720 = load i8, i8* %719, align 1
+  %720 = load atomic i8, i8* %719 unordered, align 1
   %721 = and i8 %720, %717
   %722 = and i8 %721, 4
   %723 = icmp eq i8 %722, 0
@@ -38460,7 +39027,7 @@
   %737 = phi i8 [ %707, %706 ], [ %734, %732 ], [ 1, %684 ]
   %738 = bitcast %struct.mi_segment_s* %0 to i8*
   %739 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 0
-  %740 = load i64, i64* %739, align 8, !tbaa !537
+  %740 = load atomic i64, i64* %739 unordered, align 8, !tbaa !541
   %741 = and i8 %737, 1
   %742 = icmp ne i8 %741, 0
   tail call fastcc void @_mi_mem_free(i8* %738, i64 %606, i64 %740, i1 zeroext %742, i1 zeroext %736) #37
@@ -38482,12 +39049,12 @@
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %6) #37
   %7 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %3) #37
   %8 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %3, i64 0, i32 0
-  %9 = load i64, i64* %8, align 8, !tbaa !456
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !460
   %10 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %3, i64 0, i32 1
-  %11 = load i64, i64* %10, align 8, !tbaa !458
+  %11 = load atomic i64, i64* %10 unordered, align 8, !tbaa !462
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %6) #37
   %12 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %1, i64 0, i32 2, i32 1
-  %13 = load %struct.mi_page_s*, %struct.mi_page_s** %12, align 8, !tbaa !497
+  %13 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %12 unordered, align 8, !tbaa !501
   %14 = icmp eq %struct.mi_page_s* %13, null
   br i1 %14, label %.loopexit30, label %15
 
@@ -38501,13 +39068,13 @@
 20:                                               ; preds = %72, %15
   %21 = phi %struct.mi_page_s* [ %13, %15 ], [ %27, %72 ]
   %22 = getelementptr %struct.mi_page_s, %struct.mi_page_s* %21, i64 0, i32 7
-  %23 = load i32, i32* %22, align 8, !tbaa !442
+  %23 = load atomic i32, i32* %22 unordered, align 8, !tbaa !446
   %24 = icmp sgt i32 %23, %19
   br i1 %24, label %76, label %25
 
 25:                                               ; preds = %20
   %26 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %21, i64 0, i32 13
-  %27 = load %struct.mi_page_s*, %struct.mi_page_s** %26, align 8, !tbaa !504
+  %27 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %26 unordered, align 8, !tbaa !508
   %28 = ptrtoint %struct.mi_page_s* %21 to i64
   %29 = and i64 %28, -4194304
   %30 = inttoptr i64 %29 to %struct.mi_segment_s*
@@ -38517,31 +39084,31 @@
 
 32:                                               ; preds = %25
   %33 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %30, i64 0, i32 1
-  %34 = load i8, i8* %33, align 8, !tbaa !544, !range !72
+  %34 = load atomic i8, i8* %33 unordered, align 8, !tbaa !548, !range !70
   %35 = icmp eq i8 %34, 0
   br i1 %35, label %36, label %72
 
 36:                                               ; preds = %32
   %37 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %21, i64 0, i32 1
-  %38 = load i8, i8* %37, align 1
+  %38 = load atomic i8, i8* %37 unordered, align 1
   %39 = and i8 %38, 7
   %40 = icmp eq i8 %39, 4
   br i1 %40, label %41, label %72
 
 41:                                               ; preds = %36
   %42 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %30, i64 0, i32 15
-  %43 = load i32, i32* %42, align 16, !tbaa !545
+  %43 = load atomic i32, i32* %42 unordered, align 16, !tbaa !549
   %44 = icmp eq i32 %43, 3
   br i1 %44, label %45, label %48
 
 45:                                               ; preds = %41
   %46 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %30, i64 0, i32 10
-  %47 = load i64, i64* %46, align 8, !tbaa !530
+  %47 = load atomic i64, i64* %46 unordered, align 8, !tbaa !534
   br label %52
 
 48:                                               ; preds = %41
   %49 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %30, i64 0, i32 13
-  %50 = load i64, i64* %49, align 32, !tbaa !445
+  %50 = load atomic i64, i64* %49 unordered, align 32, !tbaa !449
   %51 = shl nuw i64 1, %50
   br label %52
 
@@ -38549,7 +39116,7 @@
   %53 = phi i64 [ %47, %45 ], [ %51, %48 ]
   %54 = inttoptr i64 %29 to i8*
   %55 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %21, i64 0, i32 0
-  %56 = load i8, i8* %55, align 8, !tbaa !546
+  %56 = load atomic i8, i8* %55 unordered, align 8, !tbaa !550
   %57 = zext i8 %56 to i64
   %58 = mul i64 %53, %57
   %59 = getelementptr inbounds i8, i8* %54, i64 %58
@@ -38558,7 +39125,7 @@
 
 61:                                               ; preds = %52
   %62 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %30, i64 0, i32 11
-  %63 = load i64, i64* %62, align 16, !tbaa !547
+  %63 = load atomic i64, i64* %62 unordered, align 16, !tbaa !551
   %64 = getelementptr inbounds i8, i8* %59, i64 %63
   %65 = sub i64 %53, %63
   br label %66
@@ -38576,7 +39143,7 @@
   br label %72
 
 72:                                               ; preds = %71, %66, %36, %32, %25
-  store i32 0, i32* %22, align 8, !tbaa !442
+  store i32 0, i32* %22, align 8, !tbaa !446
   %73 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %21, i64 0, i32 12
   %74 = icmp eq %struct.mi_page_s* %27, null
   %75 = bitcast %struct.mi_page_s** %73 to i8*
@@ -38584,9 +39151,9 @@
   br i1 %74, label %.loopexit30, label %20
 
 76:                                               ; preds = %20
-  store %struct.mi_page_s* %21, %struct.mi_page_s** %12, align 8, !tbaa !497
+  store %struct.mi_page_s* %21, %struct.mi_page_s** %12, align 8, !tbaa !501
   %77 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %21, i64 0, i32 12
-  store %struct.mi_page_s* null, %struct.mi_page_s** %77, align 8, !tbaa !499
+  store %struct.mi_page_s* null, %struct.mi_page_s** %77, align 8, !tbaa !503
   br label %80
 
 .loopexit30:                                      ; preds = %72, %5
@@ -38599,13 +39166,13 @@
   %81 = tail call fastcc i64 @mi_option_get(i32 11) #37
   %.not22 = icmp eq i64 %81, 0
   %82 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 1
-  %83 = load i8, i8* %82, align 8, !tbaa !544, !range !72
+  %83 = load atomic i8, i8* %82 unordered, align 8, !tbaa !548, !range !70
   %84 = icmp eq i8 %83, 0
   br i1 %84, label %85, label %.loopexit
 
 85:                                               ; preds = %80
   %86 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 9
-  %87 = load i64, i64* %86, align 8, !tbaa !536
+  %87 = load atomic i64, i64* %86 unordered, align 8, !tbaa !540
   %88 = icmp eq i64 %87, 0
   br i1 %88, label %.loopexit, label %89
 
@@ -38629,18 +39196,18 @@
   %102 = phi i64 [ %194, %192 ], [ 0, %94 ]
   %103 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %102
   %104 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %102, i32 1
-  %105 = load i8, i8* %104, align 1
+  %105 = load atomic i8, i8* %104 unordered, align 1
   %106 = and i8 %105, 7
   %107 = icmp eq i8 %106, 4
   br i1 %107, label %108, label %192
 
 108:                                              ; preds = %100
   %109 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %102, i32 12
-  %110 = load %struct.mi_page_s*, %struct.mi_page_s** %109, align 8, !tbaa !499
+  %110 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %109 unordered, align 8, !tbaa !503
   %111 = icmp eq %struct.mi_page_s* %110, null
   %112 = ptrtoint %struct.mi_page_s* %110 to i64
   %113 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %102, i32 13
-  %114 = load %struct.mi_page_s*, %struct.mi_page_s** %113, align 8, !tbaa !504
+  %114 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %113 unordered, align 8, !tbaa !508
   br i1 %111, label %115, label %125
 
 115:                                              ; preds = %108
@@ -38652,12 +39219,12 @@
   br label %128
 
 119:                                              ; preds = %115
-  %120 = load %struct.mi_page_s*, %struct.mi_page_s** %90, align 8, !tbaa !552
+  %120 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %90 unordered, align 8, !tbaa !556
   %121 = icmp eq %struct.mi_page_s* %120, %103
   br i1 %121, label %141, label %122
 
 122:                                              ; preds = %119
-  %123 = load %struct.mi_page_s*, %struct.mi_page_s** %91, align 8, !tbaa !553
+  %123 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %91 unordered, align 8, !tbaa !557
   %124 = icmp eq %struct.mi_page_s* %123, %103
   br i1 %124, label %141, label %155
 
@@ -38670,8 +39237,8 @@
   %129 = phi i64 [ %118, %117 ], [ %126, %125 ]
   %130 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %114, i64 0, i32 12
   %131 = bitcast %struct.mi_page_s** %130 to i64*
-  store i64 %112, i64* %131, align 8, !tbaa !499
-  %132 = load %struct.mi_page_s*, %struct.mi_page_s** %109, align 8, !tbaa !499
+  store i64 %112, i64* %131, align 8, !tbaa !503
+  %132 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %109 unordered, align 8, !tbaa !503
   %133 = ptrtoint %struct.mi_page_s* %132 to i64
   %134 = icmp eq %struct.mi_page_s* %132, null
   br i1 %134, label %141, label %135
@@ -38682,33 +39249,33 @@
   %138 = phi i64 [ %129, %128 ], [ %126, %125 ]
   %139 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %136, i64 0, i32 13
   %140 = bitcast %struct.mi_page_s** %139 to i64*
-  store i64 %138, i64* %140, align 8, !tbaa !504
+  store i64 %138, i64* %140, align 8, !tbaa !508
   br label %141
 
 141:                                              ; preds = %135, %128, %122, %119
   %142 = phi i64 [ %133, %128 ], [ %137, %135 ], [ %112, %122 ], [ %112, %119 ]
-  %143 = load %struct.mi_page_s*, %struct.mi_page_s** %91, align 8, !tbaa !497
+  %143 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %91 unordered, align 8, !tbaa !501
   %144 = icmp eq %struct.mi_page_s* %143, %103
   br i1 %144, label %145, label %148
 
 145:                                              ; preds = %141
   %146 = bitcast %struct.mi_page_s** %113 to i64*
-  %147 = load i64, i64* %146, align 8, !tbaa !504
-  store i64 %147, i64* %92, align 8, !tbaa !497
+  %147 = load atomic i64, i64* %146 unordered, align 8, !tbaa !508
+  store i64 %147, i64* %92, align 8, !tbaa !501
   br label %148
 
 148:                                              ; preds = %145, %141
-  %149 = load %struct.mi_page_s*, %struct.mi_page_s** %90, align 8, !tbaa !496
+  %149 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %90 unordered, align 8, !tbaa !500
   %150 = icmp eq %struct.mi_page_s* %149, %103
   br i1 %150, label %151, label %152
 
 151:                                              ; preds = %148
-  store i64 %142, i64* %93, align 8, !tbaa !496
+  store i64 %142, i64* %93, align 8, !tbaa !500
   br label %152
 
 152:                                              ; preds = %151, %148
   %153 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %102, i32 7
-  store i32 0, i32* %153, align 8, !tbaa !442
+  store i32 0, i32* %153, align 8, !tbaa !446
   %154 = bitcast %struct.mi_page_s** %109 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %154, i8 0, i64 16, i1 false) #37
   br label %155
@@ -38719,34 +39286,34 @@
   br i1 %.not27, label %190, label %157
 
 157:                                              ; preds = %155
-  %158 = load i8, i8* %82, align 8, !tbaa !544, !range !72
+  %158 = load atomic i8, i8* %82 unordered, align 8, !tbaa !548, !range !70
   %159 = icmp eq i8 %158, 0
   br i1 %159, label %160, label %190
 
 160:                                              ; preds = %157
-  %161 = load i8, i8* %104, align 1
+  %161 = load atomic i8, i8* %104 unordered, align 1
   %162 = and i8 %161, 7
   %163 = icmp eq i8 %162, 4
   br i1 %163, label %164, label %190
 
 164:                                              ; preds = %160
-  %165 = load i32, i32* %95, align 8, !tbaa !545
+  %165 = load atomic i32, i32* %95 unordered, align 8, !tbaa !549
   %166 = icmp eq i32 %165, 3
   br i1 %166, label %167, label %169
 
 167:                                              ; preds = %164
-  %168 = load i64, i64* %97, align 8, !tbaa !530
+  %168 = load atomic i64, i64* %97 unordered, align 8, !tbaa !534
   br label %172
 
 169:                                              ; preds = %164
-  %170 = load i64, i64* %96, align 8, !tbaa !445
+  %170 = load atomic i64, i64* %96 unordered, align 8, !tbaa !449
   %171 = shl nuw i64 1, %170
   br label %172
 
 172:                                              ; preds = %169, %167
   %173 = phi i64 [ %168, %167 ], [ %171, %169 ]
   %174 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %103, i64 0, i32 0
-  %175 = load i8, i8* %174, align 8, !tbaa !546
+  %175 = load atomic i8, i8* %174 unordered, align 8, !tbaa !550
   %176 = zext i8 %175 to i64
   %177 = mul i64 %173, %176
   %178 = getelementptr inbounds i8, i8* %98, i64 %177
@@ -38754,7 +39321,7 @@
   br i1 %179, label %180, label %184
 
 180:                                              ; preds = %172
-  %181 = load i64, i64* %99, align 8, !tbaa !547
+  %181 = load atomic i64, i64* %99 unordered, align 8, !tbaa !551
   %182 = getelementptr inbounds i8, i8* %178, i64 %181
   %183 = sub i64 %173, %181
   br label %184
@@ -38772,7 +39339,7 @@
   br label %190
 
 190:                                              ; preds = %189, %184, %160, %157, %155
-  %191 = load i64, i64* %86, align 8, !tbaa !536
+  %191 = load atomic i64, i64* %86 unordered, align 8, !tbaa !540
   br label %192
 
 192:                                              ; preds = %190, %100
@@ -38784,7 +39351,7 @@
 .preheader:                                       ; preds = %249, %89
   %196 = phi i64 [ %250, %249 ], [ 0, %89 ]
   %197 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %196, i32 1
-  %198 = load i8, i8* %197, align 1
+  %198 = load atomic i8, i8* %197 unordered, align 1
   %199 = and i8 %198, 7
   %200 = icmp eq i8 %199, 4
   br i1 %200, label %201, label %249
@@ -38792,11 +39359,11 @@
 201:                                              ; preds = %.preheader
   %202 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %196
   %203 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %196, i32 12
-  %204 = load %struct.mi_page_s*, %struct.mi_page_s** %203, align 8, !tbaa !499
+  %204 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %203 unordered, align 8, !tbaa !503
   %205 = icmp eq %struct.mi_page_s* %204, null
   %206 = ptrtoint %struct.mi_page_s* %204 to i64
   %207 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %196, i32 13
-  %208 = load %struct.mi_page_s*, %struct.mi_page_s** %207, align 8, !tbaa !504
+  %208 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %207 unordered, align 8, !tbaa !508
   br i1 %205, label %209, label %219
 
 209:                                              ; preds = %201
@@ -38808,12 +39375,12 @@
   br label %222
 
 213:                                              ; preds = %209
-  %214 = load %struct.mi_page_s*, %struct.mi_page_s** %90, align 8, !tbaa !552
+  %214 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %90 unordered, align 8, !tbaa !556
   %215 = icmp eq %struct.mi_page_s* %214, %202
   br i1 %215, label %235, label %216
 
 216:                                              ; preds = %213
-  %217 = load %struct.mi_page_s*, %struct.mi_page_s** %91, align 8, !tbaa !553
+  %217 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %91 unordered, align 8, !tbaa !557
   %218 = icmp eq %struct.mi_page_s* %217, %202
   br i1 %218, label %235, label %249
 
@@ -38826,8 +39393,8 @@
   %223 = phi i64 [ %212, %211 ], [ %220, %219 ]
   %224 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %208, i64 0, i32 12
   %225 = bitcast %struct.mi_page_s** %224 to i64*
-  store i64 %206, i64* %225, align 8, !tbaa !499
-  %226 = load %struct.mi_page_s*, %struct.mi_page_s** %203, align 8, !tbaa !499
+  store i64 %206, i64* %225, align 8, !tbaa !503
+  %226 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %203 unordered, align 8, !tbaa !503
   %227 = ptrtoint %struct.mi_page_s* %226 to i64
   %228 = icmp eq %struct.mi_page_s* %226, null
   br i1 %228, label %235, label %229
@@ -38838,33 +39405,33 @@
   %232 = phi i64 [ %223, %222 ], [ %220, %219 ]
   %233 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %230, i64 0, i32 13
   %234 = bitcast %struct.mi_page_s** %233 to i64*
-  store i64 %232, i64* %234, align 8, !tbaa !504
+  store i64 %232, i64* %234, align 8, !tbaa !508
   br label %235
 
 235:                                              ; preds = %229, %222, %216, %213
   %236 = phi i64 [ %227, %222 ], [ %231, %229 ], [ %206, %216 ], [ %206, %213 ]
-  %237 = load %struct.mi_page_s*, %struct.mi_page_s** %91, align 8, !tbaa !497
+  %237 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %91 unordered, align 8, !tbaa !501
   %238 = icmp eq %struct.mi_page_s* %237, %202
   br i1 %238, label %239, label %242
 
 239:                                              ; preds = %235
   %240 = bitcast %struct.mi_page_s** %207 to i64*
-  %241 = load i64, i64* %240, align 8, !tbaa !504
-  store i64 %241, i64* %92, align 8, !tbaa !497
+  %241 = load atomic i64, i64* %240 unordered, align 8, !tbaa !508
+  store i64 %241, i64* %92, align 8, !tbaa !501
   br label %242
 
 242:                                              ; preds = %239, %235
-  %243 = load %struct.mi_page_s*, %struct.mi_page_s** %90, align 8, !tbaa !496
+  %243 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %90 unordered, align 8, !tbaa !500
   %244 = icmp eq %struct.mi_page_s* %243, %202
   br i1 %244, label %245, label %246
 
 245:                                              ; preds = %242
-  store i64 %236, i64* %93, align 8, !tbaa !496
+  store i64 %236, i64* %93, align 8, !tbaa !500
   br label %246
 
 246:                                              ; preds = %245, %242
   %247 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %196, i32 7
-  store i32 0, i32* %247, align 8, !tbaa !442
+  store i32 0, i32* %247, align 8, !tbaa !446
   %248 = bitcast %struct.mi_page_s** %203 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %248, i8 0, i64 16, i1 false) #37
   br label %249
@@ -38876,7 +39443,7 @@
 
 .loopexit:                                        ; preds = %249, %192, %85, %80
   %252 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 15
-  %253 = load i32, i32* %252, align 8, !tbaa !545
+  %253 = load atomic i32, i32* %252 unordered, align 8, !tbaa !549
   switch i32 %253, label %307 [
     i32 0, label %256
     i32 1, label %254
@@ -38894,11 +39461,11 @@
 259:                                              ; preds = %256, %254
   %260 = phi %struct.mi_segment_queue_s* [ %255, %254 ], [ %257, %256 ]
   %261 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 4
-  %262 = load %struct.mi_segment_s*, %struct.mi_segment_s** %261, align 8, !tbaa !529
+  %262 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %261 unordered, align 8, !tbaa !533
   %263 = icmp eq %struct.mi_segment_s* %262, null
   %264 = ptrtoint %struct.mi_segment_s* %262 to i64
   %265 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 5
-  %266 = load %struct.mi_segment_s*, %struct.mi_segment_s** %265, align 8, !tbaa !549
+  %266 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %265 unordered, align 8, !tbaa !553
   %267 = icmp eq %struct.mi_segment_s* %266, null
   br i1 %263, label %268, label %275
 
@@ -38911,7 +39478,7 @@
 
 271:                                              ; preds = %268
   %272 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %260, i64 0, i32 0
-  %273 = load %struct.mi_segment_s*, %struct.mi_segment_s** %272, align 8, !tbaa !554
+  %273 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %272 unordered, align 8, !tbaa !558
   %274 = icmp eq %struct.mi_segment_s* %273, %0
   br i1 %274, label %290, label %307
 
@@ -38923,8 +39490,8 @@
   %278 = phi i64 [ %270, %269 ], [ %276, %275 ]
   %279 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %266, i64 0, i32 4
   %280 = bitcast %struct.mi_segment_s** %279 to i64*
-  store i64 %264, i64* %280, align 8, !tbaa !529
-  %281 = load %struct.mi_segment_s*, %struct.mi_segment_s** %261, align 8, !tbaa !529
+  store i64 %264, i64* %280, align 8, !tbaa !533
+  %281 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %261 unordered, align 8, !tbaa !533
   %282 = ptrtoint %struct.mi_segment_s* %281 to i64
   %283 = icmp eq %struct.mi_segment_s* %281, null
   br i1 %283, label %290, label %284
@@ -38935,32 +39502,32 @@
   %287 = phi i64 [ %278, %277 ], [ %276, %275 ]
   %288 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %285, i64 0, i32 5
   %289 = bitcast %struct.mi_segment_s** %288 to i64*
-  store i64 %287, i64* %289, align 8, !tbaa !549
+  store i64 %287, i64* %289, align 8, !tbaa !553
   br label %290
 
 290:                                              ; preds = %284, %277, %271
   %291 = phi i64 [ %286, %284 ], [ %282, %277 ], [ %264, %271 ]
   %292 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %260, i64 0, i32 0
-  %293 = load %struct.mi_segment_s*, %struct.mi_segment_s** %292, align 8, !tbaa !554
+  %293 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %292 unordered, align 8, !tbaa !558
   %294 = icmp eq %struct.mi_segment_s* %293, %0
   br i1 %294, label %295, label %297
 
 295:                                              ; preds = %290
   %296 = bitcast %struct.mi_segment_queue_s* %260 to i64*
-  store i64 %291, i64* %296, align 8, !tbaa !554
+  store i64 %291, i64* %296, align 8, !tbaa !558
   br label %297
 
 297:                                              ; preds = %295, %290
   %298 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %260, i64 0, i32 1
-  %299 = load %struct.mi_segment_s*, %struct.mi_segment_s** %298, align 8, !tbaa !548
+  %299 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %298 unordered, align 8, !tbaa !552
   %300 = icmp eq %struct.mi_segment_s* %299, %0
   br i1 %300, label %301, label %305
 
 301:                                              ; preds = %297
   %302 = bitcast %struct.mi_segment_s** %265 to i64*
-  %303 = load i64, i64* %302, align 8, !tbaa !549
+  %303 = load atomic i64, i64* %302 unordered, align 8, !tbaa !553
   %304 = bitcast %struct.mi_segment_s** %298 to i64*
-  store i64 %303, i64* %304, align 8, !tbaa !548
+  store i64 %303, i64* %304, align 8, !tbaa !552
   br label %305
 
 305:                                              ; preds = %301, %297
@@ -38970,7 +39537,7 @@
 
 307:                                              ; preds = %305, %271, %256, %.loopexit
   %308 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %1, i64 0, i32 10
-  %309 = load %struct.mi_stats_s*, %struct.mi_stats_s** %308, align 8, !tbaa !525
+  %309 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %308 unordered, align 8, !tbaa !529
   %310 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %309, i64 0, i32 6
   %311 = icmp uge %"struct.(anonymous namespace)::RootSetStatistics"* %310, getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0)
   %312 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %310, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -38999,33 +39566,33 @@
 326:                                              ; preds = %322, %320
   %327 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %310, i64 0, i32 0
   %328 = atomicrmw add i64* %327, i64 1 monotonic, align 8
-  %.pre = load %struct.mi_stats_s*, %struct.mi_stats_s** %308, align 8, !tbaa !525
+  %.pre = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %308 unordered, align 8, !tbaa !529
   br label %_mi_stat_increase.exit
 
 329:                                              ; preds = %307
-  %330 = load i64, i64* %314, align 8, !tbaa !510
+  %330 = load atomic i64, i64* %314 unordered, align 8, !tbaa !514
   %331 = add nsw i64 %330, 1
-  store i64 %331, i64* %314, align 8, !tbaa !510
+  store i64 %331, i64* %314, align 8, !tbaa !514
   %332 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %309, i64 0, i32 6, i32 2
-  %333 = load i64, i64* %332, align 8, !tbaa !511
+  %333 = load atomic i64, i64* %332 unordered, align 8, !tbaa !515
   %.not23 = icmp slt i64 %330, %333
   br i1 %.not23, label %335, label %334
 
 334:                                              ; preds = %329
-  store i64 %331, i64* %332, align 8, !tbaa !511
+  store i64 %331, i64* %332, align 8, !tbaa !515
   br label %335
 
 335:                                              ; preds = %334, %329
   %336 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %310, i64 0, i32 0
-  %337 = load i64, i64* %336, align 8, !tbaa !512
+  %337 = load atomic i64, i64* %336 unordered, align 8, !tbaa !516
   %338 = add nsw i64 %337, 1
-  store i64 %338, i64* %336, align 8, !tbaa !512
+  store i64 %338, i64* %336, align 8, !tbaa !516
   br label %_mi_stat_increase.exit
 
 _mi_stat_increase.exit:                           ; preds = %335, %326
   %339 = phi %struct.mi_stats_s* [ %.pre, %326 ], [ %309, %335 ]
   %340 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 10
-  %341 = load i64, i64* %340, align 8, !tbaa !530
+  %341 = load atomic i64, i64* %340 unordered, align 8, !tbaa !534
   %342 = icmp slt i64 %341, 1
   %343 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %339, i64 0, i32 0
   %344 = icmp uge %struct.mi_stats_s* %339, @_mi_stats_main
@@ -39061,23 +39628,23 @@
   br label %_mi_stat_increase.exit21
 
 363:                                              ; preds = %348
-  %364 = load i64, i64* %347, align 8, !tbaa !510
+  %364 = load atomic i64, i64* %347 unordered, align 8, !tbaa !514
   %365 = add nsw i64 %364, 1
-  store i64 %365, i64* %347, align 8, !tbaa !510
+  store i64 %365, i64* %347, align 8, !tbaa !514
   %366 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %339, i64 0, i32 0, i32 2
-  %367 = load i64, i64* %366, align 8, !tbaa !511
+  %367 = load atomic i64, i64* %366 unordered, align 8, !tbaa !515
   %.not24 = icmp slt i64 %364, %367
   br i1 %.not24, label %369, label %368
 
 368:                                              ; preds = %363
-  store i64 %365, i64* %366, align 8, !tbaa !511
+  store i64 %365, i64* %366, align 8, !tbaa !515
   br label %369
 
 369:                                              ; preds = %368, %363
   %370 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %339, i64 0, i32 0, i32 0
-  %371 = load i64, i64* %370, align 8, !tbaa !512
+  %371 = load atomic i64, i64* %370 unordered, align 8, !tbaa !516
   %372 = add nsw i64 %371, 1
-  store i64 %372, i64* %370, align 8, !tbaa !512
+  store i64 %372, i64* %370, align 8, !tbaa !516
   br label %_mi_stat_increase.exit21
 
 373:                                              ; preds = %_mi_stat_increase.exit
@@ -39107,59 +39674,59 @@
   br label %_mi_stat_increase.exit21
 
 389:                                              ; preds = %373
-  %390 = load i64, i64* %347, align 8, !tbaa !510
+  %390 = load atomic i64, i64* %347 unordered, align 8, !tbaa !514
   %391 = add i64 %390, -1
-  store i64 %391, i64* %347, align 8, !tbaa !510
+  store i64 %391, i64* %347, align 8, !tbaa !514
   %392 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %339, i64 0, i32 0, i32 2
-  %393 = load i64, i64* %392, align 8, !tbaa !511
+  %393 = load atomic i64, i64* %392 unordered, align 8, !tbaa !515
   %394 = icmp sgt i64 %391, %393
   br i1 %394, label %395, label %396
 
 395:                                              ; preds = %389
-  store i64 %391, i64* %392, align 8, !tbaa !511
+  store i64 %391, i64* %392, align 8, !tbaa !515
   br label %396
 
 396:                                              ; preds = %395, %389
   %397 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %339, i64 0, i32 0, i32 1
-  %398 = load i64, i64* %397, align 8, !tbaa !513
+  %398 = load atomic i64, i64* %397 unordered, align 8, !tbaa !517
   %399 = add i64 %398, 1
-  store i64 %399, i64* %397, align 8, !tbaa !513
+  store i64 %399, i64* %397, align 8, !tbaa !517
   br label %_mi_stat_increase.exit21
 
 _mi_stat_increase.exit21:                         ; preds = %396, %386, %369, %360
   %400 = phi i64 [ 1, %360 ], [ 1, %369 ], [ -1, %386 ], [ -1, %396 ]
   %401 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %1, i64 0, i32 3
-  %402 = load i64, i64* %401, align 8, !tbaa !532
+  %402 = load atomic i64, i64* %401 unordered, align 8, !tbaa !536
   %403 = add i64 %402, %400
-  store i64 %403, i64* %401, align 8, !tbaa !532
+  store i64 %403, i64* %401, align 8, !tbaa !536
   %404 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %1, i64 0, i32 4
-  %405 = load i64, i64* %404, align 8, !tbaa !533
+  %405 = load atomic i64, i64* %404 unordered, align 8, !tbaa !537
   %406 = icmp ugt i64 %403, %405
   br i1 %406, label %407, label %408
 
 407:                                              ; preds = %_mi_stat_increase.exit21
-  store i64 %403, i64* %404, align 8, !tbaa !533
+  store i64 %403, i64* %404, align 8, !tbaa !537
   br label %408
 
 408:                                              ; preds = %407, %_mi_stat_increase.exit21
   %409 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %1, i64 0, i32 5
-  %410 = load i64, i64* %409, align 8, !tbaa !534
+  %410 = load atomic i64, i64* %409 unordered, align 8, !tbaa !538
   %411 = sub i64 %410, %341
-  store i64 %411, i64* %409, align 8, !tbaa !534
+  store i64 %411, i64* %409, align 8, !tbaa !538
   %412 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %1, i64 0, i32 6
-  %413 = load i64, i64* %412, align 8, !tbaa !535
+  %413 = load atomic i64, i64* %412 unordered, align 8, !tbaa !539
   %414 = icmp ugt i64 %411, %413
   br i1 %414, label %415, label %416
 
 415:                                              ; preds = %408
-  store i64 %411, i64* %412, align 8, !tbaa !535
+  store i64 %411, i64* %412, align 8, !tbaa !539
   br label %416
 
 416:                                              ; preds = %415, %408
   %417 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 14
-  store atomic i64 0, i64* %417 seq_cst, align 8, !tbaa !531
+  store atomic i64 0, i64* %417 seq_cst, align 8, !tbaa !535
   %418 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 7
-  store i64 0, i64* %418, align 8, !tbaa !555
+  store i64 0, i64* %418, align 8, !tbaa !559
   %419 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 3
   %420 = bitcast %struct.mi_segment_s** %419 to i64*
   store atomic i64 0, i64* %420 release, align 8
@@ -39191,7 +39758,7 @@
   %4 = inttoptr i64 %3 to %struct.mi_segment_s*
   %5 = and i64 %2, 4194303
   %6 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 13
-  %7 = load i64, i64* %6, align 32, !tbaa !445
+  %7 = load atomic i64, i64* %6 unordered, align 32, !tbaa !449
   %8 = lshr i64 %5, %7
   %9 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 16, i64 %8
   %10 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 16, i64 %8, i32 10
@@ -39205,7 +39772,7 @@
     i32 1, label %19
     i32 3, label %_mi_page_use_delayed_free.exit
     i32 0, label %_mi_page_use_delayed_free.exit
-  ], !prof !498
+  ], !prof !502
 
 15:                                               ; preds = %11
   %16 = and i64 %12, -4
@@ -39224,16 +39791,16 @@
   tail call fastcc void @_mi_page_free_collect(%struct.mi_page_s* nonnull %9, i1 zeroext false) #37
   %21 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 16, i64 %8, i32 9
   %22 = bitcast %"class.kotlin::gc::GCHandle"** %21 to i64*
-  %23 = load i64, i64* %22, align 8, !tbaa !539
+  %23 = load atomic i64, i64* %22 unordered, align 8, !tbaa !543
   %24 = getelementptr inbounds %"class.kotlin::gc::GCHandle", %"class.kotlin::gc::GCHandle"* %0, i64 0, i32 0
-  store i64 %23, i64* %24, align 8, !tbaa !443
-  store %"class.kotlin::gc::GCHandle"* %0, %"class.kotlin::gc::GCHandle"** %21, align 8, !tbaa !539
+  store i64 %23, i64* %24, align 8, !tbaa !447
+  store %"class.kotlin::gc::GCHandle"* %0, %"class.kotlin::gc::GCHandle"** %21, align 8, !tbaa !543
   %25 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 16, i64 %8, i32 7
-  %26 = load i32, i32* %25, align 8, !tbaa !442
+  %26 = load atomic i32, i32* %25 unordered, align 8, !tbaa !446
   %27 = add i32 %26, -1
-  store i32 %27, i32* %25, align 8, !tbaa !442
+  store i32 %27, i32* %25, align 8, !tbaa !446
   %28 = icmp eq i32 %27, 0
-  br i1 %28, label %29, label %30, !prof !284, !misexpect !285
+  br i1 %28, label %29, label %30, !prof !282, !misexpect !283
 
 29:                                               ; preds = %_mi_page_use_delayed_free.exit
   tail call fastcc void @_mi_page_retire(%struct.mi_page_s* nonnull %9) #37
@@ -39241,10 +39808,10 @@
 
 30:                                               ; preds = %_mi_page_use_delayed_free.exit
   %31 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 16, i64 %8, i32 4, i32 0
-  %32 = load i8, i8* %31, align 2
+  %32 = load atomic i8, i8* %31 unordered, align 2
   %33 = and i8 %32, 1
   %34 = icmp eq i8 %33, 0
-  br i1 %34, label %36, label %35, !prof !436, !misexpect !285
+  br i1 %34, label %36, label %35, !prof !440, !misexpect !283
 
 35:                                               ; preds = %30
   tail call fastcc void @_mi_page_unfull(%struct.mi_page_s* nonnull %9) #37
@@ -39257,13 +39824,13 @@
 ; Function Attrs: nounwind uwtable
 define internal fastcc void @_mi_page_retire(%struct.mi_page_s* %0) unnamed_addr #17 {
   %2 = getelementptr %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 4, i32 0
-  %3 = load i8, i8* %2, align 2
+  %3 = load atomic i8, i8* %2 unordered, align 2
   %4 = and i8 %3, -3
   store i8 %4, i8* %2, align 2
   %5 = and i8 %3, 1
   %6 = icmp eq i8 %5, 0
   %7 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 8
-  %8 = load i32, i32* %7, align 4, !tbaa !550
+  %8 = load atomic i32, i32* %7 unordered, align 4, !tbaa !554
   br i1 %6, label %9, label %38
 
 9:                                                ; preds = %1
@@ -39288,7 +39855,7 @@
 
 21:                                               ; preds = %19
   %22 = add nsw i64 %12, -1
-  %23 = tail call i64 @llvm.ctlz.i64(i64 %22, i1 true) #37, !range !481
+  %23 = tail call i64 @llvm.ctlz.i64(i64 %22, i1 true) #37, !range !486
   %24 = trunc i64 %23 to i32
   %25 = xor i32 %24, 63
   %26 = shl nuw nsw i32 %25, 2
@@ -39316,17 +39883,17 @@
   %44 = icmp ugt i32 %8, 2097152
   %45 = icmp ne i8 %5, 0
   %46 = or i1 %45, %44
-  br i1 %46, label %78, label %47, !prof !556
+  br i1 %46, label %78, label %47, !prof !560
 
 47:                                               ; preds = %38
   %48 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %42, i64 0, i32 2, i64 %39, i32 1
-  %49 = load %struct.mi_page_s*, %struct.mi_page_s** %48, align 8, !tbaa !497
+  %49 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %48 unordered, align 8, !tbaa !501
   %50 = icmp eq %struct.mi_page_s* %49, %0
   br i1 %50, label %51, label %78
 
 51:                                               ; preds = %47
   %52 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %43, i64 0, i32 0
-  %53 = load %struct.mi_page_s*, %struct.mi_page_s** %52, align 8, !tbaa !496
+  %53 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %52 unordered, align 8, !tbaa !500
   %54 = icmp eq %struct.mi_page_s* %53, %0
   br i1 %54, label %55, label %78
 
@@ -39334,7 +39901,7 @@
   %56 = icmp ult i32 %8, 16385
   %57 = select i1 %56, i8 16, i8 4
   %58 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 5
-  %59 = load i8, i8* %58, align 1
+  %59 = load atomic i8, i8* %58 unordered, align 1
   %60 = and i8 %59, 1
   %61 = or i8 %60, %57
   store i8 %61, i8* %58, align 1
@@ -39346,22 +39913,22 @@
   %67 = sub i64 %65, %66
   %68 = sdiv exact i64 %67, 24
   %69 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %63, i64 0, i32 9
-  %70 = load i64, i64* %69, align 8, !tbaa !519
+  %70 = load atomic i64, i64* %69 unordered, align 8, !tbaa !523
   %71 = icmp ult i64 %68, %70
   br i1 %71, label %72, label %73
 
 72:                                               ; preds = %55
-  store i64 %68, i64* %69, align 8, !tbaa !519
+  store i64 %68, i64* %69, align 8, !tbaa !523
   br label %73
 
 73:                                               ; preds = %72, %55
   %74 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %63, i64 0, i32 10
-  %75 = load i64, i64* %74, align 8, !tbaa !520
+  %75 = load atomic i64, i64* %74 unordered, align 8, !tbaa !524
   %76 = icmp ugt i64 %68, %75
   br i1 %76, label %77, label %79
 
 77:                                               ; preds = %73
-  store i64 %68, i64* %74, align 8, !tbaa !520
+  store i64 %68, i64* %74, align 8, !tbaa !524
   br label %79
 
 78:                                               ; preds = %51, %47, %38
@@ -39375,7 +39942,7 @@
 ; Function Attrs: nofree nounwind uwtable
 define internal fastcc void @_mi_page_unfull(%struct.mi_page_s* %0) unnamed_addr #21 {
   %2 = getelementptr %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 4, i32 0
-  %3 = load i8, i8* %2, align 2
+  %3 = load atomic i8, i8* %2 unordered, align 2
   %4 = and i8 %3, 1
   %5 = icmp eq i8 %4, 0
   br i1 %5, label %377, label %6
@@ -39388,7 +39955,7 @@
   %11 = and i8 %3, -2
   store i8 %11, i8* %2, align 2
   %12 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 8
-  %13 = load i32, i32* %12, align 4, !tbaa !550
+  %13 = load atomic i32, i32* %12 unordered, align 4, !tbaa !554
   %14 = zext i32 %13 to i64
   %15 = add nuw nsw i64 %14, 7
   %16 = lshr i64 %15, 3
@@ -39410,7 +39977,7 @@
 
 25:                                               ; preds = %23
   %26 = add nsw i64 %16, -1
-  %27 = tail call i64 @llvm.ctlz.i64(i64 %26, i1 true) #37, !range !481
+  %27 = tail call i64 @llvm.ctlz.i64(i64 %26, i1 true) #37, !range !486
   %28 = trunc i64 %27 to i32
   %29 = xor i32 %28, 63
   %30 = shl nuw nsw i32 %29, 2
@@ -39433,7 +40000,7 @@
   %44 = load atomic i64, i64* %7 monotonic, align 8
   %45 = inttoptr i64 %44 to %struct.mi_heap_s*
   %46 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 13
-  %47 = load %struct.mi_page_s*, %struct.mi_page_s** %46, align 8, !tbaa !504
+  %47 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %46 unordered, align 8, !tbaa !508
   %48 = icmp eq %struct.mi_page_s* %47, null
   %49 = ptrtoint %struct.mi_page_s* %47 to i64
   br i1 %48, label %56, label %50
@@ -39441,15 +40008,15 @@
 50:                                               ; preds = %39
   %51 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 12
   %52 = bitcast %struct.mi_page_s** %51 to i64*
-  %53 = load i64, i64* %52, align 8, !tbaa !499
+  %53 = load atomic i64, i64* %52 unordered, align 8, !tbaa !503
   %54 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %47, i64 0, i32 12
   %55 = bitcast %struct.mi_page_s** %54 to i64*
-  store i64 %53, i64* %55, align 8, !tbaa !499
+  store i64 %53, i64* %55, align 8, !tbaa !503
   br label %56
 
 56:                                               ; preds = %50, %39
   %57 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 12
-  %58 = load %struct.mi_page_s*, %struct.mi_page_s** %57, align 8, !tbaa !499
+  %58 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %57 unordered, align 8, !tbaa !503
   %59 = icmp eq %struct.mi_page_s* %58, null
   %60 = ptrtoint %struct.mi_page_s* %58 to i64
   br i1 %59, label %64, label %61
@@ -39457,33 +40024,33 @@
 61:                                               ; preds = %56
   %62 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %58, i64 0, i32 13
   %63 = bitcast %struct.mi_page_s** %62 to i64*
-  store i64 %49, i64* %63, align 8, !tbaa !504
+  store i64 %49, i64* %63, align 8, !tbaa !508
   br label %64
 
 64:                                               ; preds = %61, %56
   %65 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %9, i64 0, i32 2, i64 74, i32 1
-  %66 = load %struct.mi_page_s*, %struct.mi_page_s** %65, align 8, !tbaa !497
+  %66 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %65 unordered, align 8, !tbaa !501
   %67 = icmp eq %struct.mi_page_s* %66, %0
   br i1 %67, label %68, label %72
 
 68:                                               ; preds = %64
   %69 = bitcast %struct.mi_page_s** %46 to i64*
-  %70 = load i64, i64* %69, align 8, !tbaa !504
+  %70 = load atomic i64, i64* %69 unordered, align 8, !tbaa !508
   %71 = bitcast %struct.mi_page_s** %65 to i64*
-  store i64 %70, i64* %71, align 8, !tbaa !497
+  store i64 %70, i64* %71, align 8, !tbaa !501
   br label %72
 
 72:                                               ; preds = %68, %64
   %73 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %10, i64 0, i32 0
-  %74 = load %struct.mi_page_s*, %struct.mi_page_s** %73, align 8, !tbaa !496
+  %74 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %73 unordered, align 8, !tbaa !500
   %75 = icmp eq %struct.mi_page_s* %74, %0
   br i1 %75, label %76, label %.loopexit20
 
 76:                                               ; preds = %72
   %77 = bitcast %struct.mi_page_queue_s* %10 to i64*
-  store i64 %60, i64* %77, align 8, !tbaa !496
+  store i64 %60, i64* %77, align 8, !tbaa !500
   %78 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %9, i64 0, i32 2, i64 74, i32 2
-  %79 = load i64, i64* %78, align 8, !tbaa !500
+  %79 = load atomic i64, i64* %78 unordered, align 8, !tbaa !504
   %80 = icmp ugt i64 %79, 1024
   br i1 %80, label %.loopexit20, label %81
 
@@ -39492,7 +40059,7 @@
   %83 = add nuw nsw i64 %79, 7
   %84 = lshr i64 %83, 3
   %85 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 1, i64 %84
-  %86 = load %struct.mi_page_s*, %struct.mi_page_s** %85, align 8, !tbaa !434
+  %86 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %85 unordered, align 8, !tbaa !438
   %87 = icmp eq %struct.mi_page_s* %86, %82
   br i1 %87, label %.loopexit20, label %88
 
@@ -39512,7 +40079,7 @@
 
 96:                                               ; preds = %90
   %97 = add nsw i64 %84, -1
-  %98 = tail call i64 @llvm.ctlz.i64(i64 %97, i1 true) #37, !range !481
+  %98 = tail call i64 @llvm.ctlz.i64(i64 %97, i1 true) #37, !range !486
   %99 = trunc i64 %98 to i32
   %100 = xor i32 %99, 63
   %101 = shl nuw nsw i32 %100, 2
@@ -39535,7 +40102,7 @@
   %114 = phi %struct.mi_page_queue_s* [ %10, %110 ], [ %115, %143 ]
   %115 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %114, i64 -1
   %116 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %114, i64 -1, i32 2
-  %117 = load i64, i64* %116, align 8, !tbaa !500
+  %117 = load atomic i64, i64* %116 unordered, align 8, !tbaa !504
   %118 = add i64 %117, 7
   %119 = lshr i64 %118, 3
   %120 = icmp ult i64 %118, 16
@@ -39557,7 +40124,7 @@
 
 129:                                              ; preds = %127
   %130 = add nsw i64 %119, -1
-  %131 = tail call i64 @llvm.ctlz.i64(i64 %130, i1 true) #37, !range !481
+  %131 = tail call i64 @llvm.ctlz.i64(i64 %130, i1 true) #37, !range !486
   %132 = trunc i64 %131 to i32
   %133 = xor i32 %132, 63
   %134 = shl nuw nsw i32 %133, 2
@@ -39614,38 +40181,38 @@
   %173 = add i64 %154, %171
   %174 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 1, i64 %173
   %175 = bitcast %struct.mi_page_s** %174 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %175, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %175, align 8, !tbaa !438
   %176 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %174, i64 2
   %177 = bitcast %struct.mi_page_s** %176 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %177, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %177, align 8, !tbaa !438
   %178 = or i64 %171, 4
   %179 = add i64 %154, %178
   %180 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 1, i64 %179
   %181 = bitcast %struct.mi_page_s** %180 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %181, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %181, align 8, !tbaa !438
   %182 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %180, i64 2
   %183 = bitcast %struct.mi_page_s** %182 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %183, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %183, align 8, !tbaa !438
   %184 = or i64 %171, 8
   %185 = add i64 %154, %184
   %186 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 1, i64 %185
   %187 = bitcast %struct.mi_page_s** %186 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %187, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %187, align 8, !tbaa !438
   %188 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %186, i64 2
   %189 = bitcast %struct.mi_page_s** %188 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %189, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %189, align 8, !tbaa !438
   %190 = or i64 %171, 12
   %191 = add i64 %154, %190
   %192 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 1, i64 %191
   %193 = bitcast %struct.mi_page_s** %192 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %193, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %193, align 8, !tbaa !438
   %194 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %192, i64 2
   %195 = bitcast %struct.mi_page_s** %194 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %195, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %195, align 8, !tbaa !438
   %196 = add i64 %171, 16
   %197 = add i64 %172, -4
   %198 = icmp eq i64 %197, 0
-  br i1 %198, label %.loopexit23, label %170, !llvm.loop !557
+  br i1 %198, label %.loopexit23, label %170, !llvm.loop !561
 
 .loopexit23:                                      ; preds = %170, %158
   %199 = phi i64 [ 0, %158 ], [ %196, %170 ]
@@ -39658,14 +40225,14 @@
   %203 = add i64 %154, %201
   %204 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 1, i64 %203
   %205 = bitcast %struct.mi_page_s** %204 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %205, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %205, align 8, !tbaa !438
   %206 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %204, i64 2
   %207 = bitcast %struct.mi_page_s** %206 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %207, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %162, <2 x %struct.mi_page_s*>* %207, align 8, !tbaa !438
   %208 = add nuw i64 %201, 4
   %209 = add nsw i64 %202, -1
   %210 = icmp eq i64 %209, 0
-  br i1 %210, label %.loopexit22, label %.preheader21, !llvm.loop !558
+  br i1 %210, label %.loopexit22, label %.preheader21, !llvm.loop !562
 
 .loopexit22:                                      ; preds = %.preheader21, %.loopexit23
   %211 = icmp eq i64 %156, %159
@@ -39678,36 +40245,36 @@
 214:                                              ; preds = %214, %212
   %215 = phi i64 [ %217, %214 ], [ %213, %212 ]
   %216 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 1, i64 %215
-  store %struct.mi_page_s* %82, %struct.mi_page_s** %216, align 8, !tbaa !434
+  store %struct.mi_page_s* %82, %struct.mi_page_s** %216, align 8, !tbaa !438
   %217 = add nuw nsw i64 %215, 1
   %218 = icmp eq i64 %215, %84
-  br i1 %218, label %.loopexit20, label %214, !llvm.loop !559
+  br i1 %218, label %.loopexit20, label %214, !llvm.loop !563
 
 .loopexit20:                                      ; preds = %214, %.loopexit22, %148, %81, %76, %72
   %219 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %9, i64 0, i32 2, i64 %41, i32 1
   %220 = bitcast %struct.mi_page_s** %219 to i64*
-  %221 = load i64, i64* %220, align 8, !tbaa !497
+  %221 = load atomic i64, i64* %220 unordered, align 8, !tbaa !501
   %222 = bitcast %struct.mi_page_s** %46 to i64*
-  store i64 %221, i64* %222, align 8, !tbaa !504
-  store %struct.mi_page_s* null, %struct.mi_page_s** %57, align 8, !tbaa !499
+  store i64 %221, i64* %222, align 8, !tbaa !508
+  store %struct.mi_page_s* null, %struct.mi_page_s** %57, align 8, !tbaa !503
   %223 = icmp eq i64 %221, 0
   br i1 %223, label %229, label %224
 
 224:                                              ; preds = %.loopexit20
   %225 = inttoptr i64 %221 to %struct.mi_page_s*
   %226 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %225, i64 0, i32 12
-  store %struct.mi_page_s* %0, %struct.mi_page_s** %226, align 8, !tbaa !499
-  store %struct.mi_page_s* %0, %struct.mi_page_s** %219, align 8, !tbaa !497
+  store %struct.mi_page_s* %0, %struct.mi_page_s** %226, align 8, !tbaa !503
+  store %struct.mi_page_s* %0, %struct.mi_page_s** %219, align 8, !tbaa !501
   %227 = getelementptr %struct.mi_heap_s, %struct.mi_heap_s* %9, i64 0, i32 2, i64 %41, i32 2
-  %228 = load i64, i64* %227, align 8, !tbaa !500
+  %228 = load atomic i64, i64* %227 unordered, align 8, !tbaa !504
   br label %.loopexit
 
 229:                                              ; preds = %.loopexit20
   %230 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %42, i64 0, i32 0
-  store %struct.mi_page_s* %0, %struct.mi_page_s** %230, align 8, !tbaa !496
-  store %struct.mi_page_s* %0, %struct.mi_page_s** %219, align 8, !tbaa !497
+  store %struct.mi_page_s* %0, %struct.mi_page_s** %230, align 8, !tbaa !500
+  store %struct.mi_page_s* %0, %struct.mi_page_s** %219, align 8, !tbaa !501
   %231 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %9, i64 0, i32 2, i64 %41, i32 2
-  %232 = load i64, i64* %231, align 8, !tbaa !500
+  %232 = load atomic i64, i64* %231 unordered, align 8, !tbaa !504
   %233 = icmp ugt i64 %232, 1024
   br i1 %233, label %.loopexit, label %234
 
@@ -39715,7 +40282,7 @@
   %235 = add nuw nsw i64 %232, 7
   %236 = lshr i64 %235, 3
   %237 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 1, i64 %236
-  %238 = load %struct.mi_page_s*, %struct.mi_page_s** %237, align 8, !tbaa !434
+  %238 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %237 unordered, align 8, !tbaa !438
   %239 = icmp eq %struct.mi_page_s* %238, %0
   br i1 %239, label %.loopexit, label %240
 
@@ -39735,7 +40302,7 @@
 
 248:                                              ; preds = %242
   %249 = add nsw i64 %236, -1
-  %250 = tail call i64 @llvm.ctlz.i64(i64 %249, i1 true) #37, !range !481
+  %250 = tail call i64 @llvm.ctlz.i64(i64 %249, i1 true) #37, !range !486
   %251 = trunc i64 %250 to i32
   %252 = xor i32 %251, 63
   %253 = shl nuw nsw i32 %252, 2
@@ -39758,7 +40325,7 @@
   %266 = phi %struct.mi_page_queue_s* [ %42, %262 ], [ %267, %295 ]
   %267 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %266, i64 -1
   %268 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %266, i64 -1, i32 2
-  %269 = load i64, i64* %268, align 8, !tbaa !500
+  %269 = load atomic i64, i64* %268 unordered, align 8, !tbaa !504
   %270 = add i64 %269, 7
   %271 = lshr i64 %270, 3
   %272 = icmp ult i64 %270, 16
@@ -39780,7 +40347,7 @@
 
 281:                                              ; preds = %279
   %282 = add nsw i64 %271, -1
-  %283 = tail call i64 @llvm.ctlz.i64(i64 %282, i1 true) #37, !range !481
+  %283 = tail call i64 @llvm.ctlz.i64(i64 %282, i1 true) #37, !range !486
   %284 = trunc i64 %283 to i32
   %285 = xor i32 %284, 63
   %286 = shl nuw nsw i32 %285, 2
@@ -39837,38 +40404,38 @@
   %325 = add i64 %306, %323
   %326 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 1, i64 %325
   %327 = bitcast %struct.mi_page_s** %326 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %327, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %327, align 8, !tbaa !438
   %328 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %326, i64 2
   %329 = bitcast %struct.mi_page_s** %328 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %329, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %329, align 8, !tbaa !438
   %330 = or i64 %323, 4
   %331 = add i64 %306, %330
   %332 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 1, i64 %331
   %333 = bitcast %struct.mi_page_s** %332 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %333, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %333, align 8, !tbaa !438
   %334 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %332, i64 2
   %335 = bitcast %struct.mi_page_s** %334 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %335, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %335, align 8, !tbaa !438
   %336 = or i64 %323, 8
   %337 = add i64 %306, %336
   %338 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 1, i64 %337
   %339 = bitcast %struct.mi_page_s** %338 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %339, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %339, align 8, !tbaa !438
   %340 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %338, i64 2
   %341 = bitcast %struct.mi_page_s** %340 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %341, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %341, align 8, !tbaa !438
   %342 = or i64 %323, 12
   %343 = add i64 %306, %342
   %344 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 1, i64 %343
   %345 = bitcast %struct.mi_page_s** %344 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %345, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %345, align 8, !tbaa !438
   %346 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %344, i64 2
   %347 = bitcast %struct.mi_page_s** %346 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %347, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %347, align 8, !tbaa !438
   %348 = add i64 %323, 16
   %349 = add i64 %324, -4
   %350 = icmp eq i64 %349, 0
-  br i1 %350, label %.loopexit19, label %322, !llvm.loop !560
+  br i1 %350, label %.loopexit19, label %322, !llvm.loop !564
 
 .loopexit19:                                      ; preds = %322, %310
   %351 = phi i64 [ 0, %310 ], [ %348, %322 ]
@@ -39881,14 +40448,14 @@
   %355 = add i64 %306, %353
   %356 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 1, i64 %355
   %357 = bitcast %struct.mi_page_s** %356 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %357, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %357, align 8, !tbaa !438
   %358 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %356, i64 2
   %359 = bitcast %struct.mi_page_s** %358 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %359, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %314, <2 x %struct.mi_page_s*>* %359, align 8, !tbaa !438
   %360 = add nuw i64 %353, 4
   %361 = add nsw i64 %354, -1
   %362 = icmp eq i64 %361, 0
-  br i1 %362, label %.loopexit18, label %.preheader, !llvm.loop !561
+  br i1 %362, label %.loopexit18, label %.preheader, !llvm.loop !565
 
 .loopexit18:                                      ; preds = %.preheader, %.loopexit19
   %363 = icmp eq i64 %308, %311
@@ -39901,16 +40468,16 @@
 366:                                              ; preds = %366, %364
   %367 = phi i64 [ %369, %366 ], [ %365, %364 ]
   %368 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %45, i64 0, i32 1, i64 %367
-  store %struct.mi_page_s* %0, %struct.mi_page_s** %368, align 8, !tbaa !434
+  store %struct.mi_page_s* %0, %struct.mi_page_s** %368, align 8, !tbaa !438
   %369 = add nuw nsw i64 %367, 1
   %370 = icmp eq i64 %367, %236
-  br i1 %370, label %.loopexit, label %366, !llvm.loop !562
+  br i1 %370, label %.loopexit, label %366, !llvm.loop !566
 
 .loopexit:                                        ; preds = %366, %.loopexit18, %300, %234, %229, %224
   %371 = phi i64 [ %232, %300 ], [ %232, %234 ], [ %232, %229 ], [ %228, %224 ], [ %232, %.loopexit18 ], [ %232, %366 ]
   %372 = icmp eq i64 %371, 2097168
   %373 = zext i1 %372 to i8
-  %374 = load i8, i8* %2, align 2
+  %374 = load atomic i8, i8* %2 unordered, align 2
   %375 = and i8 %374, -2
   %376 = or i8 %375, %373
   store i8 %376, i8* %2, align 2
@@ -39926,21 +40493,21 @@
   br i1 %6, label %8, label %7
 
 7:                                                ; preds = %5
-  store i8 0, i8* %3, align 1, !tbaa !482
+  store i8 0, i8* %3, align 1, !tbaa !465
   br label %8
 
 8:                                                ; preds = %7, %5
-  %9 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !563
+  %9 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !567
   %10 = ptrtoint i8* %9 to i64
   %11 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 14
-  store atomic i64 %10, i64* %11 seq_cst, align 8, !tbaa !531
+  store atomic i64 %10, i64* %11 seq_cst, align 8, !tbaa !535
   %12 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 7
-  store i64 0, i64* %12, align 8, !tbaa !555
+  store i64 0, i64* %12, align 8, !tbaa !559
   %13 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 10
-  %14 = load i64, i64* %13, align 8, !tbaa !530
+  %14 = load atomic i64, i64* %13 unordered, align 8, !tbaa !534
   %15 = icmp sgt i64 %14, -1
   %16 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 10
-  %17 = load %struct.mi_stats_s*, %struct.mi_stats_s** %16, align 8, !tbaa !525
+  %17 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %16 unordered, align 8, !tbaa !529
   %18 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %17, i64 0, i32 0
   %19 = icmp uge %struct.mi_stats_s* %17, @_mi_stats_main
   %20 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %18, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -39975,23 +40542,23 @@
   br label %_mi_stat_increase.exit
 
 38:                                               ; preds = %23
-  %39 = load i64, i64* %22, align 8, !tbaa !510
+  %39 = load atomic i64, i64* %22 unordered, align 8, !tbaa !514
   %40 = add nsw i64 %39, 1
-  store i64 %40, i64* %22, align 8, !tbaa !510
+  store i64 %40, i64* %22, align 8, !tbaa !514
   %41 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %17, i64 0, i32 0, i32 2
-  %42 = load i64, i64* %41, align 8, !tbaa !511
+  %42 = load atomic i64, i64* %41 unordered, align 8, !tbaa !515
   %.not = icmp slt i64 %39, %42
   br i1 %.not, label %44, label %43
 
 43:                                               ; preds = %38
-  store i64 %40, i64* %41, align 8, !tbaa !511
+  store i64 %40, i64* %41, align 8, !tbaa !515
   br label %44
 
 44:                                               ; preds = %43, %38
   %45 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %17, i64 0, i32 0, i32 0
-  %46 = load i64, i64* %45, align 8, !tbaa !512
+  %46 = load atomic i64, i64* %45 unordered, align 8, !tbaa !516
   %47 = add nsw i64 %46, 1
-  store i64 %47, i64* %45, align 8, !tbaa !512
+  store i64 %47, i64* %45, align 8, !tbaa !516
   br label %_mi_stat_increase.exit
 
 48:                                               ; preds = %8
@@ -40021,56 +40588,56 @@
   br label %_mi_stat_increase.exit
 
 64:                                               ; preds = %48
-  %65 = load i64, i64* %22, align 8, !tbaa !510
+  %65 = load atomic i64, i64* %22 unordered, align 8, !tbaa !514
   %66 = add i64 %65, -1
-  store i64 %66, i64* %22, align 8, !tbaa !510
+  store i64 %66, i64* %22, align 8, !tbaa !514
   %67 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %17, i64 0, i32 0, i32 2
-  %68 = load i64, i64* %67, align 8, !tbaa !511
+  %68 = load atomic i64, i64* %67 unordered, align 8, !tbaa !515
   %69 = icmp sgt i64 %66, %68
   br i1 %69, label %70, label %71
 
 70:                                               ; preds = %64
-  store i64 %66, i64* %67, align 8, !tbaa !511
+  store i64 %66, i64* %67, align 8, !tbaa !515
   br label %71
 
 71:                                               ; preds = %70, %64
   %72 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %17, i64 0, i32 0, i32 1
-  %73 = load i64, i64* %72, align 8, !tbaa !513
+  %73 = load atomic i64, i64* %72 unordered, align 8, !tbaa !517
   %74 = add i64 %73, 1
-  store i64 %74, i64* %72, align 8, !tbaa !513
+  store i64 %74, i64* %72, align 8, !tbaa !517
   br label %_mi_stat_increase.exit
 
 _mi_stat_increase.exit:                           ; preds = %71, %61, %44, %35
   %75 = phi i64 [ 1, %35 ], [ 1, %44 ], [ -1, %61 ], [ -1, %71 ]
   %76 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 3
-  %77 = load i64, i64* %76, align 8, !tbaa !532
+  %77 = load atomic i64, i64* %76 unordered, align 8, !tbaa !536
   %78 = add i64 %77, %75
-  store i64 %78, i64* %76, align 8, !tbaa !532
+  store i64 %78, i64* %76, align 8, !tbaa !536
   %79 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 4
-  %80 = load i64, i64* %79, align 8, !tbaa !533
+  %80 = load atomic i64, i64* %79 unordered, align 8, !tbaa !537
   %81 = icmp ugt i64 %78, %80
   br i1 %81, label %82, label %83
 
 82:                                               ; preds = %_mi_stat_increase.exit
-  store i64 %78, i64* %79, align 8, !tbaa !533
+  store i64 %78, i64* %79, align 8, !tbaa !537
   br label %83
 
 83:                                               ; preds = %82, %_mi_stat_increase.exit
   %84 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 5
-  %85 = load i64, i64* %84, align 8, !tbaa !534
+  %85 = load atomic i64, i64* %84 unordered, align 8, !tbaa !538
   %86 = add i64 %85, %14
-  store i64 %86, i64* %84, align 8, !tbaa !534
+  store i64 %86, i64* %84, align 8, !tbaa !538
   %87 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 6
-  %88 = load i64, i64* %87, align 8, !tbaa !535
+  %88 = load atomic i64, i64* %87 unordered, align 8, !tbaa !539
   %89 = icmp ugt i64 %86, %88
   br i1 %89, label %90, label %91
 
 90:                                               ; preds = %83
-  store i64 %86, i64* %87, align 8, !tbaa !535
+  store i64 %86, i64* %87, align 8, !tbaa !539
   br label %91
 
 91:                                               ; preds = %90, %83
-  %92 = load %struct.mi_stats_s*, %struct.mi_stats_s** %16, align 8, !tbaa !525
+  %92 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %16 unordered, align 8, !tbaa !529
   %93 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %92, i64 0, i32 6
   %94 = icmp uge %"struct.(anonymous namespace)::RootSetStatistics"* %93, getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0)
   %95 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %93, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -40102,28 +40669,28 @@
   br label %_mi_stat_decrease.exit9
 
 113:                                              ; preds = %91
-  %114 = load i64, i64* %97, align 8, !tbaa !510
+  %114 = load atomic i64, i64* %97 unordered, align 8, !tbaa !514
   %115 = add i64 %114, -1
-  store i64 %115, i64* %97, align 8, !tbaa !510
+  store i64 %115, i64* %97, align 8, !tbaa !514
   %116 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %92, i64 0, i32 6, i32 2
-  %117 = load i64, i64* %116, align 8, !tbaa !511
+  %117 = load atomic i64, i64* %116 unordered, align 8, !tbaa !515
   %118 = icmp sgt i64 %115, %117
   br i1 %118, label %119, label %120
 
 119:                                              ; preds = %113
-  store i64 %115, i64* %116, align 8, !tbaa !511
+  store i64 %115, i64* %116, align 8, !tbaa !515
   br label %120
 
 120:                                              ; preds = %119, %113
   %121 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %92, i64 0, i32 6, i32 1
-  %122 = load i64, i64* %121, align 8, !tbaa !513
+  %122 = load atomic i64, i64* %121 unordered, align 8, !tbaa !517
   %123 = add i64 %122, 1
-  store i64 %123, i64* %121, align 8, !tbaa !513
+  store i64 %123, i64* %121, align 8, !tbaa !517
   br label %_mi_stat_decrease.exit9
 
 _mi_stat_decrease.exit9:                          ; preds = %120, %110
   %124 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 9
-  %125 = load i64, i64* %124, align 8, !tbaa !536
+  %125 = load atomic i64, i64* %124 unordered, align 8, !tbaa !540
   %126 = icmp eq i64 %125, 0
   br i1 %126, label %.loopexit, label %127
 
@@ -40136,16 +40703,16 @@
   %130 = phi i64 [ %203, %202 ], [ 0, %127 ]
   %131 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %130
   %132 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %130, i32 1
-  %133 = load i8, i8* %132, align 1
+  %133 = load atomic i8, i8* %132 unordered, align 1
   %134 = and i8 %133, 1
   %135 = icmp eq i8 %134, 0
   br i1 %135, label %202, label %136
 
 136:                                              ; preds = %.preheader14
-  %137 = load i64, i64* %128, align 8, !tbaa !524
+  %137 = load atomic i64, i64* %128 unordered, align 8, !tbaa !528
   %138 = add i64 %137, -1
-  store i64 %138, i64* %128, align 8, !tbaa !524
-  %139 = load %struct.mi_stats_s*, %struct.mi_stats_s** %16, align 8, !tbaa !525
+  store i64 %138, i64* %128, align 8, !tbaa !528
+  %139 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %16 unordered, align 8, !tbaa !529
   %140 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %139, i64 0, i32 7
   %141 = icmp uge %"struct.(anonymous namespace)::RootSetStatistics"* %140, getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0)
   %142 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %140, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -40177,23 +40744,23 @@
   br label %_mi_stat_decrease.exit10
 
 160:                                              ; preds = %136
-  %161 = load i64, i64* %144, align 8, !tbaa !510
+  %161 = load atomic i64, i64* %144 unordered, align 8, !tbaa !514
   %162 = add i64 %161, -1
-  store i64 %162, i64* %144, align 8, !tbaa !510
+  store i64 %162, i64* %144, align 8, !tbaa !514
   %163 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %139, i64 0, i32 7, i32 2
-  %164 = load i64, i64* %163, align 8, !tbaa !511
+  %164 = load atomic i64, i64* %163 unordered, align 8, !tbaa !515
   %165 = icmp sgt i64 %162, %164
   br i1 %165, label %166, label %167
 
 166:                                              ; preds = %160
-  store i64 %162, i64* %163, align 8, !tbaa !511
+  store i64 %162, i64* %163, align 8, !tbaa !515
   br label %167
 
 167:                                              ; preds = %166, %160
   %168 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %139, i64 0, i32 7, i32 1
-  %169 = load i64, i64* %168, align 8, !tbaa !513
+  %169 = load atomic i64, i64* %168 unordered, align 8, !tbaa !517
   %170 = add i64 %169, 1
-  store i64 %170, i64* %168, align 8, !tbaa !513
+  store i64 %170, i64* %168, align 8, !tbaa !517
   br label %_mi_stat_decrease.exit10
 
 _mi_stat_decrease.exit10:                         ; preds = %167, %157
@@ -40209,7 +40776,7 @@
   switch i32 %176, label %178 [
     i32 1, label %177
     i32 0, label %_mi_page_use_delayed_free.exit
-  ], !prof !518
+  ], !prof !522
 
 177:                                              ; preds = %173
   tail call void @llvm.x86.sse2.pause() #37
@@ -40227,22 +40794,22 @@
 _mi_page_use_delayed_free.exit:                   ; preds = %178, %173
   tail call fastcc void @_mi_page_free_collect(%struct.mi_page_s* nonnull %131, i1 zeroext false) #37
   %183 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %130, i32 7
-  %184 = load i32, i32* %183, align 8, !tbaa !442
+  %184 = load atomic i32, i32* %183 unordered, align 8, !tbaa !446
   %185 = icmp eq i32 %184, 0
   br i1 %185, label %201, label %186
 
 186:                                              ; preds = %_mi_page_use_delayed_free.exit
   tail call fastcc void @_mi_page_reclaim(%struct.mi_heap_s* %1, %struct.mi_page_s* nonnull %131) #37
   %187 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %130, i32 8
-  %188 = load i32, i32* %187, align 4, !tbaa !550
+  %188 = load atomic i32, i32* %187 unordered, align 4, !tbaa !554
   %189 = zext i32 %188 to i64
   %190 = icmp eq i64 %189, %2
   br i1 %190, label %191, label %202
 
 191:                                              ; preds = %186
-  %192 = load i32, i32* %183, align 8, !tbaa !442
+  %192 = load atomic i32, i32* %183 unordered, align 8, !tbaa !446
   %193 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %130, i32 3
-  %194 = load i16, i16* %193, align 4, !tbaa !551
+  %194 = load atomic i16, i16* %193 unordered, align 4, !tbaa !555
   %195 = zext i16 %194 to i32
   %196 = icmp ult i32 %192, %195
   br i1 %196, label %200, label %197
@@ -40253,7 +40820,7 @@
   br i1 %199, label %200, label %202
 
 200:                                              ; preds = %197, %191
-  store i8 1, i8* %3, align 1, !tbaa !482
+  store i8 1, i8* %3, align 1, !tbaa !465
   br label %202
 
 201:                                              ; preds = %_mi_page_use_delayed_free.exit
@@ -40262,14 +40829,14 @@
 
 202:                                              ; preds = %201, %200, %197, %186, %.preheader14
   %203 = add nuw i64 %130, 1
-  %204 = load i64, i64* %124, align 8, !tbaa !536
+  %204 = load atomic i64, i64* %124 unordered, align 8, !tbaa !540
   %205 = icmp ult i64 %203, %204
   br i1 %205, label %.preheader14, label %.loopexit
 
 .loopexit:                                        ; preds = %280, %202, %_mi_stat_decrease.exit9
   %206 = phi i64 [ 0, %_mi_stat_decrease.exit9 ], [ %282, %280 ], [ %204, %202 ]
   %207 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 8
-  %208 = load i64, i64* %207, align 8, !tbaa !526
+  %208 = load atomic i64, i64* %207 unordered, align 8, !tbaa !530
   %209 = icmp eq i64 %208, 0
   br i1 %209, label %284, label %285
 
@@ -40277,16 +40844,16 @@
   %210 = phi i64 [ %281, %280 ], [ 0, %127 ]
   %211 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %210
   %212 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %210, i32 1
-  %213 = load i8, i8* %212, align 1
+  %213 = load atomic i8, i8* %212 unordered, align 1
   %214 = and i8 %213, 1
   %215 = icmp eq i8 %214, 0
   br i1 %215, label %280, label %216
 
 216:                                              ; preds = %.preheader
-  %217 = load i64, i64* %128, align 8, !tbaa !524
+  %217 = load atomic i64, i64* %128 unordered, align 8, !tbaa !528
   %218 = add i64 %217, -1
-  store i64 %218, i64* %128, align 8, !tbaa !524
-  %219 = load %struct.mi_stats_s*, %struct.mi_stats_s** %16, align 8, !tbaa !525
+  store i64 %218, i64* %128, align 8, !tbaa !528
+  %219 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %16 unordered, align 8, !tbaa !529
   %220 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %219, i64 0, i32 7
   %221 = icmp uge %"struct.(anonymous namespace)::RootSetStatistics"* %220, getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0)
   %222 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %220, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -40318,23 +40885,23 @@
   br label %_mi_stat_decrease.exit12
 
 240:                                              ; preds = %216
-  %241 = load i64, i64* %224, align 8, !tbaa !510
+  %241 = load atomic i64, i64* %224 unordered, align 8, !tbaa !514
   %242 = add i64 %241, -1
-  store i64 %242, i64* %224, align 8, !tbaa !510
+  store i64 %242, i64* %224, align 8, !tbaa !514
   %243 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %219, i64 0, i32 7, i32 2
-  %244 = load i64, i64* %243, align 8, !tbaa !511
+  %244 = load atomic i64, i64* %243 unordered, align 8, !tbaa !515
   %245 = icmp sgt i64 %242, %244
   br i1 %245, label %246, label %247
 
 246:                                              ; preds = %240
-  store i64 %242, i64* %243, align 8, !tbaa !511
+  store i64 %242, i64* %243, align 8, !tbaa !515
   br label %247
 
 247:                                              ; preds = %246, %240
   %248 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %219, i64 0, i32 7, i32 1
-  %249 = load i64, i64* %248, align 8, !tbaa !513
+  %249 = load atomic i64, i64* %248 unordered, align 8, !tbaa !517
   %250 = add i64 %249, 1
-  store i64 %250, i64* %248, align 8, !tbaa !513
+  store i64 %250, i64* %248, align 8, !tbaa !517
   br label %_mi_stat_decrease.exit12
 
 _mi_stat_decrease.exit12:                         ; preds = %247, %237
@@ -40350,7 +40917,7 @@
   switch i32 %256, label %258 [
     i32 1, label %257
     i32 0, label %_mi_page_use_delayed_free.exit11
-  ], !prof !518
+  ], !prof !522
 
 257:                                              ; preds = %253
   tail call void @llvm.x86.sse2.pause() #37
@@ -40368,7 +40935,7 @@
 _mi_page_use_delayed_free.exit11:                 ; preds = %258, %253
   tail call fastcc void @_mi_page_free_collect(%struct.mi_page_s* nonnull %211, i1 zeroext false) #37
   %263 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %210, i32 7
-  %264 = load i32, i32* %263, align 8, !tbaa !442
+  %264 = load atomic i32, i32* %263 unordered, align 8, !tbaa !446
   %265 = icmp eq i32 %264, 0
   br i1 %265, label %266, label %267
 
@@ -40379,15 +40946,15 @@
 267:                                              ; preds = %_mi_page_use_delayed_free.exit11
   tail call fastcc void @_mi_page_reclaim(%struct.mi_heap_s* %1, %struct.mi_page_s* nonnull %211) #37
   %268 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %210, i32 8
-  %269 = load i32, i32* %268, align 4, !tbaa !550
+  %269 = load atomic i32, i32* %268 unordered, align 4, !tbaa !554
   %270 = zext i32 %269 to i64
   %271 = icmp eq i64 %270, %2
   br i1 %271, label %272, label %280
 
 272:                                              ; preds = %267
-  %273 = load i32, i32* %263, align 8, !tbaa !442
+  %273 = load atomic i32, i32* %263 unordered, align 8, !tbaa !446
   %274 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %210, i32 3
-  %275 = load i16, i16* %274, align 4, !tbaa !551
+  %275 = load atomic i16, i16* %274 unordered, align 4, !tbaa !555
   %276 = zext i16 %275 to i32
   %277 = icmp ult i32 %273, %276
   br i1 %277, label %280, label %278
@@ -40398,7 +40965,7 @@
 
 280:                                              ; preds = %278, %272, %267, %266, %.preheader
   %281 = add nuw i64 %210, 1
-  %282 = load i64, i64* %124, align 8, !tbaa !536
+  %282 = load atomic i64, i64* %124 unordered, align 8, !tbaa !540
   %283 = icmp ult i64 %281, %282
   br i1 %283, label %.preheader, label %.loopexit
 
@@ -40408,7 +40975,7 @@
 
 285:                                              ; preds = %.loopexit
   %286 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 15
-  %287 = load i32, i32* %286, align 8, !tbaa !545
+  %287 = load atomic i32, i32* %286 unordered, align 8, !tbaa !549
   %288 = icmp ult i32 %287, 2
   %289 = icmp ult i64 %208, %206
   %290 = and i1 %289, %288
@@ -40431,20 +40998,20 @@
 296:                                              ; preds = %294, %292, %291
   %297 = phi %struct.mi_segment_queue_s* [ %293, %292 ], [ %295, %294 ], [ null, %291 ]
   %298 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 4
-  store %struct.mi_segment_s* null, %struct.mi_segment_s** %298, align 8, !tbaa !529
+  store %struct.mi_segment_s* null, %struct.mi_segment_s** %298, align 8, !tbaa !533
   %299 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %297, i64 0, i32 1
   %300 = bitcast %struct.mi_segment_s** %299 to i64*
-  %301 = load i64, i64* %300, align 8, !tbaa !548
+  %301 = load atomic i64, i64* %300 unordered, align 8, !tbaa !552
   %302 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 5
   %303 = bitcast %struct.mi_segment_s** %302 to i64*
-  store i64 %301, i64* %303, align 8, !tbaa !549
+  store i64 %301, i64* %303, align 8, !tbaa !553
   %304 = icmp eq i64 %301, 0
   %305 = inttoptr i64 %301 to %struct.mi_segment_s*
   %306 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %305, i64 0, i32 4
   %307 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %297, i64 0, i32 0
   %308 = select i1 %304, %struct.mi_segment_s** %307, %struct.mi_segment_s** %306
-  store %struct.mi_segment_s* %0, %struct.mi_segment_s** %308, align 8, !tbaa !434
-  store %struct.mi_segment_s* %0, %struct.mi_segment_s** %299, align 8, !tbaa !548
+  store %struct.mi_segment_s* %0, %struct.mi_segment_s** %308, align 8, !tbaa !438
+  store %struct.mi_segment_s* %0, %struct.mi_segment_s** %299, align 8, !tbaa !552
   br label %309
 
 309:                                              ; preds = %296, %285, %284
@@ -40455,41 +41022,41 @@
 ; Function Attrs: nofree nounwind uwtable
 define internal fastcc void @_mi_page_reclaim(%struct.mi_heap_s* %0, %struct.mi_page_s* %1) unnamed_addr #21 {
   %3 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %1, i64 0, i32 8
-  %4 = load i32, i32* %3, align 4, !tbaa !550
+  %4 = load atomic i32, i32* %3 unordered, align 4, !tbaa !554
   %5 = zext i32 %4 to i64
   %6 = icmp ult i32 %4, 67108864
-  br i1 %6, label %_mi_segment_page_start.exit, label %7, !prof !436, !misexpect !437
+  br i1 %6, label %_mi_segment_page_start.exit, label %7, !prof !440, !misexpect !441
 
 7:                                                ; preds = %2
   %8 = ptrtoint %struct.mi_page_s* %1 to i64
   %9 = and i64 %8, -4194304
   %10 = inttoptr i64 %9 to %struct.mi_segment_s*
   %11 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %10, i64 0, i32 15
-  %12 = load i32, i32* %11, align 16, !tbaa !545
+  %12 = load atomic i32, i32* %11 unordered, align 16, !tbaa !549
   %13 = icmp eq i32 %12, 3
   br i1 %13, label %14, label %17
 
 14:                                               ; preds = %7
   %15 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %10, i64 0, i32 10
-  %16 = load i64, i64* %15, align 8, !tbaa !530
+  %16 = load atomic i64, i64* %15 unordered, align 8, !tbaa !534
   br label %21
 
 17:                                               ; preds = %7
   %18 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %10, i64 0, i32 13
-  %19 = load i64, i64* %18, align 32, !tbaa !445
+  %19 = load atomic i64, i64* %18 unordered, align 32, !tbaa !449
   %20 = shl nuw i64 1, %19
   br label %21
 
 21:                                               ; preds = %17, %14
   %22 = phi i64 [ %16, %14 ], [ %20, %17 ]
   %23 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %1, i64 0, i32 0
-  %24 = load i8, i8* %23, align 8, !tbaa !546
+  %24 = load atomic i8, i8* %23 unordered, align 8, !tbaa !550
   %25 = icmp eq i8 %24, 0
   br i1 %25, label %26, label %_mi_segment_page_start.exit
 
 26:                                               ; preds = %21
   %27 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %10, i64 0, i32 11
-  %28 = load i64, i64* %27, align 16, !tbaa !547
+  %28 = load atomic i64, i64* %27 unordered, align 16, !tbaa !551
   %29 = sub i64 %22, %28
   %30 = icmp ne i32 %4, 0
   %31 = icmp ult i32 %12, 2
@@ -40532,7 +41099,7 @@
 
 55:                                               ; preds = %53
   %56 = add nsw i64 %46, -1
-  %57 = tail call i64 @llvm.ctlz.i64(i64 %56, i1 true) #37, !range !481
+  %57 = tail call i64 @llvm.ctlz.i64(i64 %56, i1 true) #37, !range !486
   %58 = trunc i64 %57 to i32
   %59 = xor i32 %58, 63
   %60 = shl nuw nsw i32 %59, 2
@@ -40551,30 +41118,30 @@
   %71 = and i64 %70, 255
   %72 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 2, i64 %71
   %73 = getelementptr %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 2, i64 %71, i32 2
-  %74 = load i64, i64* %73, align 8, !tbaa !500
+  %74 = load atomic i64, i64* %73 unordered, align 8, !tbaa !504
   %75 = icmp eq i64 %74, 2097168
   %76 = zext i1 %75 to i8
   %77 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %1, i64 0, i32 4, i32 0
-  %78 = load i8, i8* %77, align 2
+  %78 = load atomic i8, i8* %77 unordered, align 2
   %79 = and i8 %78, -2
   %80 = or i8 %79, %76
   store i8 %80, i8* %77, align 2
   %81 = bitcast %struct.mi_page_queue_s* %72 to i64*
-  %82 = load i64, i64* %81, align 8, !tbaa !496
+  %82 = load atomic i64, i64* %81 unordered, align 8, !tbaa !500
   %83 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %1, i64 0, i32 12
   %84 = bitcast %struct.mi_page_s** %83 to i64*
-  store i64 %82, i64* %84, align 8, !tbaa !499
+  store i64 %82, i64* %84, align 8, !tbaa !503
   %85 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %1, i64 0, i32 13
-  store %struct.mi_page_s* null, %struct.mi_page_s** %85, align 8, !tbaa !504
+  store %struct.mi_page_s* null, %struct.mi_page_s** %85, align 8, !tbaa !508
   %86 = icmp eq i64 %82, 0
   %87 = inttoptr i64 %82 to %struct.mi_page_s*
   %88 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %87, i64 0, i32 13
   %89 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 2, i64 %71, i32 1
   %90 = select i1 %86, %struct.mi_page_s** %89, %struct.mi_page_s** %88
-  store %struct.mi_page_s* %1, %struct.mi_page_s** %90, align 8, !tbaa !434
+  store %struct.mi_page_s* %1, %struct.mi_page_s** %90, align 8, !tbaa !438
   %91 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %72, i64 0, i32 0
-  store %struct.mi_page_s* %1, %struct.mi_page_s** %91, align 8, !tbaa !496
-  %92 = load i64, i64* %73, align 8, !tbaa !500
+  store %struct.mi_page_s* %1, %struct.mi_page_s** %91, align 8, !tbaa !500
+  %92 = load atomic i64, i64* %73 unordered, align 8, !tbaa !504
   %93 = icmp ugt i64 %92, 1024
   br i1 %93, label %.loopexit, label %94
 
@@ -40582,7 +41149,7 @@
   %95 = add nuw nsw i64 %92, 7
   %96 = lshr i64 %95, 3
   %97 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %96
-  %98 = load %struct.mi_page_s*, %struct.mi_page_s** %97, align 8, !tbaa !434
+  %98 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %97 unordered, align 8, !tbaa !438
   %99 = icmp eq %struct.mi_page_s* %98, %1
   br i1 %99, label %.loopexit, label %100
 
@@ -40602,7 +41169,7 @@
 
 108:                                              ; preds = %102
   %109 = add nsw i64 %96, -1
-  %110 = tail call i64 @llvm.ctlz.i64(i64 %109, i1 true) #37, !range !481
+  %110 = tail call i64 @llvm.ctlz.i64(i64 %109, i1 true) #37, !range !486
   %111 = trunc i64 %110 to i32
   %112 = xor i32 %111, 63
   %113 = shl nuw nsw i32 %112, 2
@@ -40625,7 +41192,7 @@
   %126 = phi %struct.mi_page_queue_s* [ %72, %122 ], [ %127, %155 ]
   %127 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %126, i64 -1
   %128 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %126, i64 -1, i32 2
-  %129 = load i64, i64* %128, align 8, !tbaa !500
+  %129 = load atomic i64, i64* %128 unordered, align 8, !tbaa !504
   %130 = add i64 %129, 7
   %131 = lshr i64 %130, 3
   %132 = icmp ult i64 %130, 16
@@ -40647,7 +41214,7 @@
 
 141:                                              ; preds = %139
   %142 = add nsw i64 %131, -1
-  %143 = tail call i64 @llvm.ctlz.i64(i64 %142, i1 true) #37, !range !481
+  %143 = tail call i64 @llvm.ctlz.i64(i64 %142, i1 true) #37, !range !486
   %144 = trunc i64 %143 to i32
   %145 = xor i32 %144, 63
   %146 = shl nuw nsw i32 %145, 2
@@ -40692,7 +41259,7 @@
   %177 = add nuw nsw i64 %176, 1
   %178 = and i64 %177, 3
   %179 = icmp ult i64 %175, 12
-  br i1 %179, label %.loopexit9, label %180
+  br i1 %179, label %.loopexit10, label %180
 
 180:                                              ; preds = %170
   %181 = and i64 %177, 9223372036854775804
@@ -40704,80 +41271,80 @@
   %185 = add i64 %166, %183
   %186 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %185
   %187 = bitcast %struct.mi_page_s** %186 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %187, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %187, align 8, !tbaa !438
   %188 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %186, i64 2
   %189 = bitcast %struct.mi_page_s** %188 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %189, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %189, align 8, !tbaa !438
   %190 = or i64 %183, 4
   %191 = add i64 %166, %190
   %192 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %191
   %193 = bitcast %struct.mi_page_s** %192 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %193, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %193, align 8, !tbaa !438
   %194 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %192, i64 2
   %195 = bitcast %struct.mi_page_s** %194 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %195, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %195, align 8, !tbaa !438
   %196 = or i64 %183, 8
   %197 = add i64 %166, %196
   %198 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %197
   %199 = bitcast %struct.mi_page_s** %198 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %199, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %199, align 8, !tbaa !438
   %200 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %198, i64 2
   %201 = bitcast %struct.mi_page_s** %200 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %201, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %201, align 8, !tbaa !438
   %202 = or i64 %183, 12
   %203 = add i64 %166, %202
   %204 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %203
   %205 = bitcast %struct.mi_page_s** %204 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %205, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %205, align 8, !tbaa !438
   %206 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %204, i64 2
   %207 = bitcast %struct.mi_page_s** %206 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %207, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %207, align 8, !tbaa !438
   %208 = add i64 %183, 16
   %209 = add i64 %184, -4
   %210 = icmp eq i64 %209, 0
-  br i1 %210, label %.loopexit9, label %182, !llvm.loop !564
+  br i1 %210, label %.loopexit10, label %182, !llvm.loop !568
 
-.loopexit9:                                       ; preds = %182, %170
+.loopexit10:                                      ; preds = %182, %170
   %211 = phi i64 [ 0, %170 ], [ %208, %182 ]
   %212 = icmp eq i64 %178, 0
-  br i1 %212, label %.loopexit8, label %.preheader
+  br i1 %212, label %.loopexit9, label %.preheader
 
-.preheader:                                       ; preds = %.preheader, %.loopexit9
-  %213 = phi i64 [ %220, %.preheader ], [ %211, %.loopexit9 ]
-  %214 = phi i64 [ %221, %.preheader ], [ %178, %.loopexit9 ]
+.preheader:                                       ; preds = %.preheader, %.loopexit10
+  %213 = phi i64 [ %220, %.preheader ], [ %211, %.loopexit10 ]
+  %214 = phi i64 [ %221, %.preheader ], [ %178, %.loopexit10 ]
   %215 = add i64 %166, %213
   %216 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %215
   %217 = bitcast %struct.mi_page_s** %216 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %217, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %217, align 8, !tbaa !438
   %218 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %216, i64 2
   %219 = bitcast %struct.mi_page_s** %218 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %219, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %174, <2 x %struct.mi_page_s*>* %219, align 8, !tbaa !438
   %220 = add nuw i64 %213, 4
   %221 = add nsw i64 %214, -1
   %222 = icmp eq i64 %221, 0
-  br i1 %222, label %.loopexit8, label %.preheader, !llvm.loop !565
+  br i1 %222, label %.loopexit9, label %.preheader, !llvm.loop !569
 
-.loopexit8:                                       ; preds = %.preheader, %.loopexit9
+.loopexit9:                                       ; preds = %.preheader, %.loopexit10
   %223 = icmp eq i64 %168, %171
   br i1 %223, label %.loopexit, label %224
 
-224:                                              ; preds = %.loopexit8, %165
-  %225 = phi i64 [ %166, %165 ], [ %172, %.loopexit8 ]
+224:                                              ; preds = %.loopexit9, %165
+  %225 = phi i64 [ %166, %165 ], [ %172, %.loopexit9 ]
   br label %226
 
 226:                                              ; preds = %226, %224
   %227 = phi i64 [ %229, %226 ], [ %225, %224 ]
   %228 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %227
-  store %struct.mi_page_s* %1, %struct.mi_page_s** %228, align 8, !tbaa !434
+  store %struct.mi_page_s* %1, %struct.mi_page_s** %228, align 8, !tbaa !438
   %229 = add nuw nsw i64 %227, 1
   %230 = icmp eq i64 %227, %96
-  br i1 %230, label %.loopexit, label %226, !llvm.loop !566
+  br i1 %230, label %.loopexit, label %226, !llvm.loop !570
 
-.loopexit:                                        ; preds = %226, %.loopexit8, %160, %94, %69
+.loopexit:                                        ; preds = %226, %.loopexit9, %160, %94, %69
   %231 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 8
-  %232 = load i64, i64* %231, align 8, !tbaa !494
+  %232 = load atomic i64, i64* %231 unordered, align 8, !tbaa !498
   %233 = add i64 %232, 1
-  store i64 %233, i64* %231, align 8, !tbaa !494
+  store i64 %233, i64* %231, align 8, !tbaa !498
   ret void
 }
 
@@ -40787,48 +41354,48 @@
   %3 = and i64 %2, -4194304
   %4 = inttoptr i64 %3 to %struct.mi_segment_s*
   %5 = icmp eq i64 %3, 0
-  br i1 %5, label %35, label %6, !prof !284, !misexpect !285
+  br i1 %5, label %35, label %6, !prof !282, !misexpect !283
 
 6:                                                ; preds = %1
-  %7 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !567
+  %7 = tail call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !571
   %8 = ptrtoint i8* %7 to i64
   %9 = and i64 %2, 4194303
   %10 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 13
-  %11 = load i64, i64* %10, align 32, !tbaa !445
+  %11 = load atomic i64, i64* %10 unordered, align 32, !tbaa !449
   %12 = lshr i64 %9, %11
   %13 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 16, i64 %12
   %14 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 14
-  %15 = load atomic i64, i64* %14 seq_cst, align 8, !tbaa !531
+  %15 = load atomic i64, i64* %14 seq_cst, align 8, !tbaa !535
   %16 = icmp eq i64 %15, %8
-  br i1 %16, label %17, label %32, !prof !436
+  br i1 %16, label %17, label %32, !prof !440
 
 17:                                               ; preds = %6
   %18 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 16, i64 %12, i32 4, i32 0
-  %19 = load i8, i8* %18, align 2, !tbaa !454
+  %19 = load atomic i8, i8* %18 unordered, align 2, !tbaa !458
   %20 = icmp eq i8 %19, 0
-  br i1 %20, label %21, label %32, !prof !436, !misexpect !437
+  br i1 %20, label %21, label %32, !prof !440, !misexpect !441
 
 21:                                               ; preds = %17
   %22 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 16, i64 %12, i32 9
   %23 = bitcast %"class.kotlin::gc::GCHandle"** %22 to i64*
-  %24 = load i64, i64* %23, align 8, !tbaa !539
+  %24 = load atomic i64, i64* %23 unordered, align 8, !tbaa !543
   %25 = bitcast i8* %0 to i64*
-  store i64 %24, i64* %25, align 8, !tbaa !443
+  store i64 %24, i64* %25, align 8, !tbaa !447
   %26 = bitcast %"class.kotlin::gc::GCHandle"** %22 to i8**
-  store i8* %0, i8** %26, align 8, !tbaa !539
+  store i8* %0, i8** %26, align 8, !tbaa !543
   %27 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 16, i64 %12, i32 7
-  %28 = load i32, i32* %27, align 8, !tbaa !442
+  %28 = load atomic i32, i32* %27 unordered, align 8, !tbaa !446
   %29 = add i32 %28, -1
-  store i32 %29, i32* %27, align 8, !tbaa !442
+  store i32 %29, i32* %27, align 8, !tbaa !446
   %30 = icmp eq i32 %29, 0
-  br i1 %30, label %31, label %35, !prof !284, !misexpect !285
+  br i1 %30, label %31, label %35, !prof !282, !misexpect !283
 
 31:                                               ; preds = %21
   tail call fastcc void @_mi_page_retire(%struct.mi_page_s* nonnull %13) #37
   br label %35
 
 32:                                               ; preds = %17, %6
-  %33 = load atomic i64, i64* %14 seq_cst, align 8, !tbaa !531
+  %33 = load atomic i64, i64* %14 seq_cst, align 8, !tbaa !535
   %34 = icmp eq i64 %33, %8
   tail call fastcc void @mi_free_generic(%struct.mi_segment_s* nonnull %4, i1 zeroext %34, i8* %0)
   br label %35
@@ -40843,27 +41410,27 @@
   %5 = ptrtoint %struct.mi_segment_s* %0 to i64
   %6 = sub i64 %4, %5
   %7 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 13
-  %8 = load i64, i64* %7, align 8, !tbaa !445
+  %8 = load atomic i64, i64* %7 unordered, align 8, !tbaa !449
   %9 = lshr i64 %6, %8
   %10 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %9
   %11 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %9, i32 4, i32 0
-  %12 = load i8, i8* %11, align 2
+  %12 = load atomic i8, i8* %11 unordered, align 2
   %13 = and i8 %12, 2
   %14 = icmp eq i8 %13, 0
   br i1 %14, label %90, label %15
 
 15:                                               ; preds = %3
   %16 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %9, i32 8
-  %17 = load i32, i32* %16, align 4, !tbaa !550
+  %17 = load atomic i32, i32* %16 unordered, align 4, !tbaa !554
   %18 = zext i32 %17 to i64
   %19 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 15
-  %20 = load i32, i32* %19, align 8, !tbaa !545
+  %20 = load atomic i32, i32* %19 unordered, align 8, !tbaa !549
   %21 = icmp eq i32 %20, 3
   br i1 %21, label %22, label %25
 
 22:                                               ; preds = %15
   %23 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 10
-  %24 = load i64, i64* %23, align 8, !tbaa !530
+  %24 = load atomic i64, i64* %23 unordered, align 8, !tbaa !534
   br label %27
 
 25:                                               ; preds = %15
@@ -40874,7 +41441,7 @@
   %28 = phi i64 [ %24, %22 ], [ %26, %25 ]
   %29 = bitcast %struct.mi_segment_s* %0 to i8*
   %30 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %10, i64 0, i32 0
-  %31 = load i8, i8* %30, align 8, !tbaa !546
+  %31 = load atomic i8, i8* %30 unordered, align 8, !tbaa !550
   %32 = zext i8 %31 to i64
   %33 = mul i64 %28, %32
   %34 = getelementptr inbounds i8, i8* %29, i64 %33
@@ -40883,7 +41450,7 @@
 
 36:                                               ; preds = %27
   %37 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 11
-  %38 = load i64, i64* %37, align 8, !tbaa !547
+  %38 = load atomic i64, i64* %37 unordered, align 8, !tbaa !551
   %39 = getelementptr inbounds i8, i8* %34, i64 %38
   %40 = icmp ne i32 %17, 0
   %41 = icmp ult i32 %20, 2
@@ -40902,25 +41469,25 @@
 _mi_segment_page_start.exit:                      ; preds = %43, %36, %27
   %49 = phi i8* [ %39, %36 ], [ %34, %27 ], [ %spec.select, %43 ]
   %50 = icmp ult i32 %17, 67108864
-  br i1 %50, label %_mi_segment_page_start.exit1, label %51, !prof !436, !misexpect !437
+  br i1 %50, label %_mi_segment_page_start.exit1, label %51, !prof !440, !misexpect !441
 
 51:                                               ; preds = %_mi_segment_page_start.exit
   %52 = ptrtoint %struct.mi_page_s* %10 to i64
   %53 = and i64 %52, -4194304
   %54 = inttoptr i64 %53 to %struct.mi_segment_s*
   %55 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %54, i64 0, i32 15
-  %56 = load i32, i32* %55, align 16, !tbaa !545
+  %56 = load atomic i32, i32* %55 unordered, align 16, !tbaa !549
   %57 = icmp eq i32 %56, 3
   br i1 %57, label %58, label %61
 
 58:                                               ; preds = %51
   %59 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %54, i64 0, i32 10
-  %60 = load i64, i64* %59, align 8, !tbaa !530
+  %60 = load atomic i64, i64* %59 unordered, align 8, !tbaa !534
   br label %65
 
 61:                                               ; preds = %51
   %62 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %54, i64 0, i32 13
-  %63 = load i64, i64* %62, align 32, !tbaa !445
+  %63 = load atomic i64, i64* %62 unordered, align 32, !tbaa !449
   %64 = shl nuw i64 1, %63
   br label %65
 
@@ -40930,7 +41497,7 @@
 
 67:                                               ; preds = %65
   %68 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %54, i64 0, i32 11
-  %69 = load i64, i64* %68, align 16, !tbaa !547
+  %69 = load atomic i64, i64* %68 unordered, align 16, !tbaa !551
   %70 = sub i64 %66, %69
   %71 = icmp ne i32 %17, 0
   %72 = icmp ult i32 %56, 2
@@ -40947,11 +41514,11 @@
   %81 = sub nsw i64 %18, %80
   %82 = icmp ult i64 %81, %18
   %83 = select i1 %82, i64 %81, i64 0
-  %spec.select3 = sub i64 %70, %83
+  %spec.select4 = sub i64 %70, %83
   br label %_mi_segment_page_start.exit1
 
 _mi_segment_page_start.exit1:                     ; preds = %74, %67, %65, %_mi_segment_page_start.exit
-  %84 = phi i64 [ %18, %_mi_segment_page_start.exit ], [ %70, %67 ], [ %66, %65 ], [ %spec.select3, %74 ]
+  %84 = phi i64 [ %18, %_mi_segment_page_start.exit ], [ %70, %67 ], [ %66, %65 ], [ %spec.select4, %74 ]
   %85 = ptrtoint i8* %49 to i64
   %86 = sub i64 %4, %85
   %87 = urem i64 %86, %84
@@ -40965,31 +41532,31 @@
 
 92:                                               ; preds = %90, %_mi_segment_page_start.exit1
   %93 = phi %"class.kotlin::gc::GCHandle"* [ %89, %_mi_segment_page_start.exit1 ], [ %91, %90 ]
-  br i1 %1, label %94, label %109, !prof !436, !misexpect !437
+  br i1 %1, label %94, label %109, !prof !440, !misexpect !441
 
 94:                                               ; preds = %92
   %95 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %9, i32 9
   %96 = bitcast %"class.kotlin::gc::GCHandle"** %95 to i64*
-  %97 = load i64, i64* %96, align 8, !tbaa !539
+  %97 = load atomic i64, i64* %96 unordered, align 8, !tbaa !543
   %98 = getelementptr inbounds %"class.kotlin::gc::GCHandle", %"class.kotlin::gc::GCHandle"* %93, i64 0, i32 0
-  store i64 %97, i64* %98, align 8, !tbaa !443
-  store %"class.kotlin::gc::GCHandle"* %93, %"class.kotlin::gc::GCHandle"** %95, align 8, !tbaa !539
+  store i64 %97, i64* %98, align 8, !tbaa !447
+  store %"class.kotlin::gc::GCHandle"* %93, %"class.kotlin::gc::GCHandle"** %95, align 8, !tbaa !543
   %99 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %9, i32 7
-  %100 = load i32, i32* %99, align 8, !tbaa !442
+  %100 = load atomic i32, i32* %99 unordered, align 8, !tbaa !446
   %101 = add i32 %100, -1
-  store i32 %101, i32* %99, align 8, !tbaa !442
+  store i32 %101, i32* %99, align 8, !tbaa !446
   %102 = icmp eq i32 %101, 0
-  br i1 %102, label %103, label %104, !prof !284, !misexpect !285
+  br i1 %102, label %103, label %104, !prof !282, !misexpect !283
 
 103:                                              ; preds = %94
   tail call fastcc void @_mi_page_retire(%struct.mi_page_s* nonnull %10) #37
   br label %110
 
 104:                                              ; preds = %94
-  %105 = load i8, i8* %11, align 2
+  %105 = load atomic i8, i8* %11 unordered, align 2
   %106 = and i8 %105, 1
   %107 = icmp eq i8 %106, 0
-  br i1 %107, label %110, label %108, !prof !436, !misexpect !285
+  br i1 %107, label %110, label %108, !prof !440, !misexpect !283
 
 108:                                              ; preds = %104
   tail call fastcc void @_mi_page_unfull(%struct.mi_page_s* nonnull %10) #37
@@ -41009,16 +41576,16 @@
   %4 = and i64 %3, -4194304
   %5 = inttoptr i64 %4 to %struct.mi_segment_s*
   %6 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %5, i64 0, i32 15
-  %7 = load i32, i32* %6, align 16, !tbaa !545
+  %7 = load atomic i32, i32* %6 unordered, align 16, !tbaa !549
   %8 = icmp eq i32 %7, 3
   br i1 %8, label %9, label %109
 
 9:                                                ; preds = %2
   tail call fastcc void @mi_thread_init() #37
-  %10 = load %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !434
+  %10 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default unordered, align 8, !tbaa !438
   %11 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %5, i64 0, i32 14
   %12 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %10, i64 0, i32 4
-  %13 = load i64, i64* %12, align 8, !tbaa !452
+  %13 = load atomic i64, i64* %12 unordered, align 8, !tbaa !456
   %14 = cmpxchg i64* %11, i64 0, i64 %13 acq_rel acquire, align 8
   %15 = extractvalue { i64, i1 } %14, 1
   br i1 %15, label %16, label %_mi_segment_huge_page_free.exit
@@ -41026,26 +41593,26 @@
 16:                                               ; preds = %9
   %17 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 6
   %18 = bitcast %"class.kotlin::gc::GCHandle"** %17 to i64*
-  %19 = load i64, i64* %18, align 8, !tbaa !438
+  %19 = load atomic i64, i64* %18 unordered, align 8, !tbaa !442
   %20 = getelementptr inbounds %"class.kotlin::gc::GCHandle", %"class.kotlin::gc::GCHandle"* %1, i64 0, i32 0
-  store i64 %19, i64* %20, align 8, !tbaa !443
-  store %"class.kotlin::gc::GCHandle"* %1, %"class.kotlin::gc::GCHandle"** %17, align 8, !tbaa !438
+  store i64 %19, i64* %20, align 8, !tbaa !447
+  store %"class.kotlin::gc::GCHandle"* %1, %"class.kotlin::gc::GCHandle"** %17, align 8, !tbaa !442
   %21 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 7
-  %22 = load i32, i32* %21, align 8, !tbaa !442
+  %22 = load atomic i32, i32* %21 unordered, align 8, !tbaa !446
   %23 = add i32 %22, -1
-  store i32 %23, i32* %21, align 8, !tbaa !442
+  store i32 %23, i32* %21, align 8, !tbaa !446
   %24 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 5
-  %25 = load i8, i8* %24, align 1
+  %25 = load atomic i8, i8* %24 unordered, align 1
   %26 = and i8 %25, -2
   store i8 %26, i8* %24, align 1
   %27 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %10, i64 0, i32 0
-  %28 = load %struct.mi_tld_s*, %struct.mi_tld_s** %27, align 8, !tbaa !461
+  %28 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %27 unordered, align 8, !tbaa !466
   %29 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %5, i64 0, i32 10
-  %30 = load i64, i64* %29, align 8, !tbaa !530
+  %30 = load atomic i64, i64* %29 unordered, align 8, !tbaa !534
   %31 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %28, i64 0, i32 4
   %32 = icmp sgt i64 %30, -1
   %33 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %28, i64 0, i32 4, i32 10
-  %34 = load %struct.mi_stats_s*, %struct.mi_stats_s** %33, align 8, !tbaa !525
+  %34 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %33 unordered, align 8, !tbaa !529
   %35 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %34, i64 0, i32 0
   %36 = icmp uge %struct.mi_stats_s* %34, @_mi_stats_main
   %37 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %35, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -41080,23 +41647,23 @@
   br label %_mi_stat_increase.exit.i
 
 55:                                               ; preds = %40
-  %56 = load i64, i64* %39, align 8, !tbaa !510
+  %56 = load atomic i64, i64* %39 unordered, align 8, !tbaa !514
   %57 = add nsw i64 %56, 1
-  store i64 %57, i64* %39, align 8, !tbaa !510
+  store i64 %57, i64* %39, align 8, !tbaa !514
   %58 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %34, i64 0, i32 0, i32 2
-  %59 = load i64, i64* %58, align 8, !tbaa !511
+  %59 = load atomic i64, i64* %58 unordered, align 8, !tbaa !515
   %.not = icmp slt i64 %56, %59
   br i1 %.not, label %61, label %60
 
 60:                                               ; preds = %55
-  store i64 %57, i64* %58, align 8, !tbaa !511
+  store i64 %57, i64* %58, align 8, !tbaa !515
   br label %61
 
 61:                                               ; preds = %60, %55
   %62 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %34, i64 0, i32 0, i32 0
-  %63 = load i64, i64* %62, align 8, !tbaa !512
+  %63 = load atomic i64, i64* %62 unordered, align 8, !tbaa !516
   %64 = add nsw i64 %63, 1
-  store i64 %64, i64* %62, align 8, !tbaa !512
+  store i64 %64, i64* %62, align 8, !tbaa !516
   br label %_mi_stat_increase.exit.i
 
 65:                                               ; preds = %16
@@ -41126,52 +41693,52 @@
   br label %_mi_stat_increase.exit.i
 
 81:                                               ; preds = %65
-  %82 = load i64, i64* %39, align 8, !tbaa !510
+  %82 = load atomic i64, i64* %39 unordered, align 8, !tbaa !514
   %83 = add i64 %82, -1
-  store i64 %83, i64* %39, align 8, !tbaa !510
+  store i64 %83, i64* %39, align 8, !tbaa !514
   %84 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %34, i64 0, i32 0, i32 2
-  %85 = load i64, i64* %84, align 8, !tbaa !511
+  %85 = load atomic i64, i64* %84 unordered, align 8, !tbaa !515
   %86 = icmp sgt i64 %83, %85
   br i1 %86, label %87, label %88
 
 87:                                               ; preds = %81
-  store i64 %83, i64* %84, align 8, !tbaa !511
+  store i64 %83, i64* %84, align 8, !tbaa !515
   br label %88
 
 88:                                               ; preds = %87, %81
   %89 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %34, i64 0, i32 0, i32 1
-  %90 = load i64, i64* %89, align 8, !tbaa !513
+  %90 = load atomic i64, i64* %89 unordered, align 8, !tbaa !517
   %91 = add i64 %90, 1
-  store i64 %91, i64* %89, align 8, !tbaa !513
+  store i64 %91, i64* %89, align 8, !tbaa !517
   br label %_mi_stat_increase.exit.i
 
 _mi_stat_increase.exit.i:                         ; preds = %88, %78, %61, %52
   %92 = phi i64 [ 1, %61 ], [ 1, %52 ], [ -1, %88 ], [ -1, %78 ]
   %93 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %28, i64 0, i32 4, i32 3
-  %94 = load i64, i64* %93, align 8, !tbaa !532
+  %94 = load atomic i64, i64* %93 unordered, align 8, !tbaa !536
   %95 = add i64 %94, %92
-  store i64 %95, i64* %93, align 8, !tbaa !532
+  store i64 %95, i64* %93, align 8, !tbaa !536
   %96 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %28, i64 0, i32 4, i32 4
-  %97 = load i64, i64* %96, align 8, !tbaa !533
+  %97 = load atomic i64, i64* %96 unordered, align 8, !tbaa !537
   %98 = icmp ugt i64 %95, %97
   br i1 %98, label %99, label %100
 
 99:                                               ; preds = %_mi_stat_increase.exit.i
-  store i64 %95, i64* %96, align 8, !tbaa !533
+  store i64 %95, i64* %96, align 8, !tbaa !537
   br label %100
 
 100:                                              ; preds = %99, %_mi_stat_increase.exit.i
   %101 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %28, i64 0, i32 4, i32 5
-  %102 = load i64, i64* %101, align 8, !tbaa !534
+  %102 = load atomic i64, i64* %101 unordered, align 8, !tbaa !538
   %103 = add i64 %102, %30
-  store i64 %103, i64* %101, align 8, !tbaa !534
+  store i64 %103, i64* %101, align 8, !tbaa !538
   %104 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %28, i64 0, i32 4, i32 6
-  %105 = load i64, i64* %104, align 8, !tbaa !535
+  %105 = load atomic i64, i64* %104 unordered, align 8, !tbaa !539
   %106 = icmp ugt i64 %103, %105
   br i1 %106, label %107, label %108
 
 107:                                              ; preds = %100
-  store i64 %103, i64* %104, align 8, !tbaa !535
+  store i64 %103, i64* %104, align 8, !tbaa !539
   br label %108
 
 108:                                              ; preds = %107, %100
@@ -41190,7 +41757,7 @@
   %116 = and i64 %115, 3
   %117 = icmp eq i64 %116, 0
   %118 = and i64 %115, -4
-  br i1 %117, label %119, label %126, !prof !284, !misexpect !285
+  br i1 %117, label %119, label %126, !prof !282, !misexpect !283
 
 119:                                              ; preds = %114
   %120 = or i64 %118, 1
@@ -41204,7 +41771,7 @@
   br label %114
 
 126:                                              ; preds = %114
-  store i64 %118, i64* %112, align 8, !tbaa !443
+  store i64 %118, i64* %112, align 8, !tbaa !447
   %127 = or i64 %116, %113
   %128 = cmpxchg weak i64* %110, i64 %115, i64 %127 release monotonic, align 8
   %129 = extractvalue { i64, i1 } %128, 1
@@ -41226,7 +41793,7 @@
 
 140:                                              ; preds = %140, %135
   %141 = phi i64 [ %139, %135 ], [ %144, %140 ]
-  store i64 %141, i64* %112, align 8, !tbaa !443
+  store i64 %141, i64* %112, align 8, !tbaa !447
   %142 = cmpxchg weak i64* %138, i64 %141, i64 %113 release monotonic, align 8
   %143 = extractvalue { i64, i1 } %142, 1
   %144 = extractvalue { i64, i1 } %142, 0
@@ -41254,7 +41821,7 @@
 
 ; Function Attrs: nounwind uwtable
 define internal void @mi_out_buf_stderr(i8* readonly %0, i8* nocapture readnone %1) #17 {
-  %3 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8, !tbaa !434
+  %3 = load atomic %struct._IO_FILE*, %struct._IO_FILE** @stderr unordered, align 8, !tbaa !438
   %4 = tail call i32 @fputs(i8* %0, %struct._IO_FILE* %3) #55
   %5 = icmp eq i8* %0, null
   br i1 %5, label %21, label %6
@@ -41295,7 +41862,7 @@
   br i1 %5, label %.loopexit, label %6
 
 6:                                                ; preds = %2
-  %7 = load i8, i8* %0, align 1, !tbaa !454
+  %7 = load atomic i8, i8* %0 unordered, align 1, !tbaa !458
   %8 = icmp eq i8 %7, 0
   br i1 %8, label %.loopexit, label %9
 
@@ -41314,26 +41881,26 @@
 19:                                               ; preds = %78, %9
   %20 = phi i8 [ %7, %9 ], [ %80, %78 ]
   %21 = phi i8* [ %0, %9 ], [ %79, %78 ]
-  %22 = load i64, i64* %11, align 8, !tbaa !568
-  %23 = load i64, i64* %13, align 8, !tbaa !569
+  %22 = load atomic i64, i64* %11 unordered, align 8, !tbaa !572
+  %23 = load atomic i64, i64* %13 unordered, align 8, !tbaa !573
   %24 = icmp ult i64 %22, %23
   br i1 %24, label %48, label %25
 
 25:                                               ; preds = %19
-  %26 = load i8*, i8** %15, align 8, !tbaa !462
+  %26 = load atomic i8*, i8** %15 unordered, align 8, !tbaa !467
   %27 = getelementptr inbounds i8, i8* %26, i64 %22
-  store i8 0, i8* %27, align 1, !tbaa !454
-  %28 = load void (i8*, i8*)*, void (i8*, i8*)** %16, align 8, !tbaa !570
-  %29 = load i8*, i8** %18, align 8, !tbaa !571
-  %30 = load i8*, i8** %15, align 8, !tbaa !462
+  store i8 0, i8* %27, align 1, !tbaa !458
+  %28 = load atomic void (i8*, i8*)*, void (i8*, i8*)** %16 unordered, align 8, !tbaa !574
+  %29 = load atomic i8*, i8** %18 unordered, align 8, !tbaa !575
+  %30 = load atomic i8*, i8** %15 unordered, align 8, !tbaa !467
   %31 = icmp eq void (i8*, i8*)* %28, null
   br i1 %31, label %39, label %32
 
 32:                                               ; preds = %25
   %33 = bitcast void (i8*, i8*)* %28 to %struct._IO_FILE*
-  %34 = load %struct._IO_FILE*, %struct._IO_FILE** @stdout, align 8, !tbaa !434
+  %34 = load atomic %struct._IO_FILE*, %struct._IO_FILE** @stdout unordered, align 8, !tbaa !438
   %35 = icmp eq %struct._IO_FILE* %34, %33
-  %36 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
+  %36 = load atomic %struct._IO_FILE*, %struct._IO_FILE** @stderr unordered, align 8
   %37 = icmp eq %struct._IO_FILE* %36, %33
   %38 = or i1 %35, %37
   br i1 %38, label %39, label %47
@@ -41345,7 +41912,7 @@
 41:                                               ; preds = %39
   store i1 true, i1* @recurse, align 1
   %42 = load atomic i64, i64* bitcast (i8** @mi_out_arg to i64*) acquire, align 8
-  %43 = load volatile void (i8*, i8*)*, void (i8*, i8*)** @mi_out_default, align 8, !tbaa !434
+  %43 = load atomic volatile void (i8*, i8*)*, void (i8*, i8*)** @mi_out_default unordered, align 8, !tbaa !438
   %44 = icmp eq void (i8*, i8*)* %43, null
   %45 = select i1 %44, void (i8*, i8*)* @mi_out_buf, void (i8*, i8*)* %43
   %46 = inttoptr i64 %42 to i8*
@@ -41358,35 +41925,35 @@
   br label %_mi_fputs.exit
 
 _mi_fputs.exit:                                   ; preds = %47, %41, %39
-  store i64 0, i64* %11, align 8, !tbaa !568
+  store i64 0, i64* %11, align 8, !tbaa !572
   br label %48
 
 48:                                               ; preds = %_mi_fputs.exit, %19
   %49 = phi i64 [ %22, %19 ], [ 0, %_mi_fputs.exit ]
-  %50 = load i8*, i8** %15, align 8, !tbaa !462
+  %50 = load atomic i8*, i8** %15 unordered, align 8, !tbaa !467
   %51 = add nuw i64 %49, 1
-  store i64 %51, i64* %11, align 8, !tbaa !568
+  store i64 %51, i64* %11, align 8, !tbaa !572
   %52 = getelementptr inbounds i8, i8* %50, i64 %49
-  store i8 %20, i8* %52, align 1, !tbaa !454
+  store i8 %20, i8* %52, align 1, !tbaa !458
   %53 = icmp eq i8 %20, 10
   br i1 %53, label %54, label %78
 
 54:                                               ; preds = %48
-  %55 = load i8*, i8** %15, align 8, !tbaa !462
-  %56 = load i64, i64* %11, align 8, !tbaa !568
+  %55 = load atomic i8*, i8** %15 unordered, align 8, !tbaa !467
+  %56 = load atomic i64, i64* %11 unordered, align 8, !tbaa !572
   %57 = getelementptr inbounds i8, i8* %55, i64 %56
-  store i8 0, i8* %57, align 1, !tbaa !454
-  %58 = load void (i8*, i8*)*, void (i8*, i8*)** %16, align 8, !tbaa !570
-  %59 = load i8*, i8** %18, align 8, !tbaa !571
-  %60 = load i8*, i8** %15, align 8, !tbaa !462
+  store i8 0, i8* %57, align 1, !tbaa !458
+  %58 = load atomic void (i8*, i8*)*, void (i8*, i8*)** %16 unordered, align 8, !tbaa !574
+  %59 = load atomic i8*, i8** %18 unordered, align 8, !tbaa !575
+  %60 = load atomic i8*, i8** %15 unordered, align 8, !tbaa !467
   %61 = icmp eq void (i8*, i8*)* %58, null
   br i1 %61, label %69, label %62
 
 62:                                               ; preds = %54
   %63 = bitcast void (i8*, i8*)* %58 to %struct._IO_FILE*
-  %64 = load %struct._IO_FILE*, %struct._IO_FILE** @stdout, align 8, !tbaa !434
+  %64 = load atomic %struct._IO_FILE*, %struct._IO_FILE** @stdout unordered, align 8, !tbaa !438
   %65 = icmp eq %struct._IO_FILE* %64, %63
-  %66 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
+  %66 = load atomic %struct._IO_FILE*, %struct._IO_FILE** @stderr unordered, align 8
   %67 = icmp eq %struct._IO_FILE* %66, %63
   %68 = or i1 %65, %67
   br i1 %68, label %69, label %77
@@ -41398,7 +41965,7 @@
 71:                                               ; preds = %69
   store i1 true, i1* @recurse, align 1
   %72 = load atomic i64, i64* bitcast (i8** @mi_out_arg to i64*) acquire, align 8
-  %73 = load volatile void (i8*, i8*)*, void (i8*, i8*)** @mi_out_default, align 8, !tbaa !434
+  %73 = load atomic volatile void (i8*, i8*)*, void (i8*, i8*)** @mi_out_default unordered, align 8, !tbaa !438
   %74 = icmp eq void (i8*, i8*)* %73, null
   %75 = select i1 %74, void (i8*, i8*)* @mi_out_buf, void (i8*, i8*)* %73
   %76 = inttoptr i64 %72 to i8*
@@ -41411,12 +41978,12 @@
   br label %_mi_fputs.exit5
 
 _mi_fputs.exit5:                                  ; preds = %77, %71, %69
-  store i64 0, i64* %11, align 8, !tbaa !568
+  store i64 0, i64* %11, align 8, !tbaa !572
   br label %78
 
 78:                                               ; preds = %_mi_fputs.exit5, %48
   %79 = getelementptr inbounds i8, i8* %21, i64 1
-  %80 = load i8, i8* %79, align 1, !tbaa !454
+  %80 = load atomic i8, i8* %79 unordered, align 1, !tbaa !458
   %81 = icmp eq i8 %80, 0
   br i1 %81, label %.loopexit, label %19
 
@@ -41445,9 +42012,9 @@
   store i1 true, i1* @recurse, align 1
   %13 = call i32 @vsnprintf(i8* nonnull %8, i64 511, i8* nonnull %2, %struct.__va_list_tag* nonnull %7) #37
   store i1 false, i1* @recurse, align 1
-  %14 = load %struct._IO_FILE*, %struct._IO_FILE** @stdout, align 8, !tbaa !434
+  %14 = load atomic %struct._IO_FILE*, %struct._IO_FILE** @stdout unordered, align 8, !tbaa !438
   %15 = icmp eq %struct._IO_FILE* %14, bitcast (void (i8*, i8*)* @mi_buffered_out to %struct._IO_FILE*)
-  %16 = load %struct._IO_FILE*, %struct._IO_FILE** @stderr, align 8
+  %16 = load atomic %struct._IO_FILE*, %struct._IO_FILE** @stderr unordered, align 8
   %17 = icmp eq %struct._IO_FILE* %16, bitcast (void (i8*, i8*)* @mi_buffered_out to %struct._IO_FILE*)
   %18 = or i1 %15, %17
   br i1 %18, label %19, label %25
@@ -41456,7 +42023,7 @@
   store i1 true, i1* @recurse, align 1
   %20 = load atomic i64, i64* bitcast (i8** @mi_out_arg to i64*) acquire, align 8
   %21 = inttoptr i64 %20 to i8*
-  %22 = load volatile void (i8*, i8*)*, void (i8*, i8*)** @mi_out_default, align 8, !tbaa !434
+  %22 = load atomic volatile void (i8*, i8*)*, void (i8*, i8*)** @mi_out_default unordered, align 8, !tbaa !438
   %23 = icmp eq void (i8*, i8*)* %22, null
   %24 = select i1 %23, void (i8*, i8*)* @mi_out_buf, void (i8*, i8*)* %22
   call void %24(i8* nonnull %8, i8* %21) #37
@@ -41483,7 +42050,7 @@
 
 7:                                                ; preds = %4
   %8 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 2
-  %9 = load i64, i64* %8, align 8, !tbaa !511
+  %9 = load atomic i64, i64* %8 unordered, align 8, !tbaa !515
   %10 = getelementptr inbounds [32 x i8], [32 x i8]* %5, i64 0, i64 0
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %10) #37
   %11 = icmp slt i64 %9, 0
@@ -41521,7 +42088,7 @@
   call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* %3, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.36.513, i64 0, i64 0), i8* nonnull %10) #37
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %10) #37
   %37 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 0
-  %38 = load i64, i64* %37, align 8, !tbaa !512
+  %38 = load atomic i64, i64* %37 unordered, align 8, !tbaa !516
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %10) #37
   %39 = icmp slt i64 %38, 0
   %40 = sub nsw i64 0, %38
@@ -41558,7 +42125,7 @@
   call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* %3, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.36.513, i64 0, i64 0), i8* nonnull %10) #37
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %10) #37
   %65 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 1
-  %66 = load i64, i64* %65, align 8, !tbaa !513
+  %66 = load atomic i64, i64* %65 unordered, align 8, !tbaa !517
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %10) #37
   %67 = icmp slt i64 %66, 0
   %68 = sub nsw i64 0, %66
@@ -41595,7 +42162,7 @@
   call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* %3, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.36.513, i64 0, i64 0), i8* nonnull %10) #37
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %10) #37
   %93 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 3
-  %94 = load i64, i64* %93, align 8, !tbaa !510
+  %94 = load atomic i64, i64* %93 unordered, align 8, !tbaa !514
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %10) #37
   %95 = icmp slt i64 %94, 0
   %96 = sub nsw i64 0, %94
@@ -41636,8 +42203,8 @@
   call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* %3, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.36.513, i64 0, i64 0), i8* nonnull %10) #37
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %10) #37
   call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* %3, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.36.513, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.37.512, i64 0, i64 0)) #37
-  %122 = load i64, i64* %37, align 8, !tbaa !512
-  %123 = load i64, i64* %65, align 8, !tbaa !513
+  %122 = load atomic i64, i64* %37 unordered, align 8, !tbaa !516
+  %123 = load atomic i64, i64* %65 unordered, align 8, !tbaa !517
   %124 = icmp sgt i64 %122, %123
   %125 = select i1 %124, i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.32.514, i64 0, i64 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.33.515, i64 0, i64 0)
   br label %325
@@ -41645,7 +42212,7 @@
 126:                                              ; preds = %4
   %127 = icmp slt i64 %2, 0
   %128 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 2
-  %129 = load i64, i64* %128, align 8, !tbaa !511
+  %129 = load atomic i64, i64* %128 unordered, align 8, !tbaa !515
   %130 = getelementptr inbounds [32 x i8], [32 x i8]* %5, i64 0, i64 0
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %130) #37
   %131 = icmp slt i64 %129, 0
@@ -41686,7 +42253,7 @@
   call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* %3, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.36.513, i64 0, i64 0), i8* nonnull %130) #37
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %130) #37
   %158 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 0
-  %159 = load i64, i64* %158, align 8, !tbaa !512
+  %159 = load atomic i64, i64* %158 unordered, align 8, !tbaa !516
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %130) #37
   %160 = icmp slt i64 %159, 0
   %161 = sub nsw i64 0, %159
@@ -41723,7 +42290,7 @@
   call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* %3, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.36.513, i64 0, i64 0), i8* nonnull %130) #37
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %130) #37
   %186 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 1
-  %187 = load i64, i64* %186, align 8, !tbaa !513
+  %187 = load atomic i64, i64* %186 unordered, align 8, !tbaa !517
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %130) #37
   %188 = icmp slt i64 %187, 0
   %189 = sub nsw i64 0, %187
@@ -41760,7 +42327,7 @@
   call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* %3, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.36.513, i64 0, i64 0), i8* nonnull %130) #37
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %130) #37
   %214 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 3
-  %215 = load i64, i64* %214, align 8, !tbaa !510
+  %215 = load atomic i64, i64* %214 unordered, align 8, !tbaa !514
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %130) #37
   %216 = icmp slt i64 %215, 0
   %217 = sub nsw i64 0, %215
@@ -41797,8 +42364,8 @@
   call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* %3, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.36.513, i64 0, i64 0), i8* nonnull %130) #37
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %130) #37
   call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* %3, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.34.516, i64 0, i64 0), i8* getelementptr inbounds ([1 x i8], [1 x i8]* @.str.7.558, i64 0, i64 0)) #37
-  %242 = load i64, i64* %158, align 8, !tbaa !512
-  %243 = load i64, i64* %186, align 8, !tbaa !513
+  %242 = load atomic i64, i64* %158 unordered, align 8, !tbaa !516
+  %243 = load atomic i64, i64* %186 unordered, align 8, !tbaa !517
   %244 = icmp sgt i64 %242, %243
   %245 = select i1 %244, i8* getelementptr inbounds ([18 x i8], [18 x i8]* @.str.32.514, i64 0, i64 0), i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.33.515, i64 0, i64 0)
   br label %325
@@ -41835,7 +42402,7 @@
   call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* %3, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.36.513, i64 0, i64 0), i8* nonnull %130) #37
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %130) #37
   %269 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 0
-  %270 = load i64, i64* %269, align 8, !tbaa !512
+  %270 = load atomic i64, i64* %269 unordered, align 8, !tbaa !516
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %130) #37
   %271 = icmp slt i64 %270, 0
   %272 = sub nsw i64 0, %270
@@ -41873,7 +42440,7 @@
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %130) #37
   call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* %3, i8* getelementptr inbounds ([5 x i8], [5 x i8]* @.str.36.513, i64 0, i64 0), i8* getelementptr inbounds ([2 x i8], [2 x i8]* @.str.37.512, i64 0, i64 0)) #37
   %297 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %0, i64 0, i32 3
-  %298 = load i64, i64* %297, align 8, !tbaa !510
+  %298 = load atomic i64, i64* %297 unordered, align 8, !tbaa !514
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %130) #37
   %299 = icmp slt i64 %298, 0
   %300 = sub nsw i64 0, %298
@@ -41922,7 +42489,7 @@
   %4 = alloca [32 x i8], align 16
   tail call void (void (i8*, i8*)*, i8*, i8*, ...) @_mi_fprintf(void (i8*, i8*)* nonnull undef, i8* %2, i8* getelementptr inbounds ([6 x i8], [6 x i8]* @.str.31.511, i64 0, i64 0), i8* %1) #37
   %5 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %0, i64 0, i32 0
-  %6 = load i64, i64* %5, align 8, !tbaa !466
+  %6 = load atomic i64, i64* %5 unordered, align 8, !tbaa !471
   %7 = getelementptr inbounds [32 x i8], [32 x i8]* %4, i64 0, i64 0
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %7) #37
   %8 = icmp slt i64 %6, 0
@@ -42003,62 +42570,62 @@
   br label %48
 
 2:                                                ; preds = %48
-  %3 = load i32, i32* %.sroa.0.0..sroa_idx, align 4, !tbaa !459
+  %3 = load atomic i32, i32* %.sroa.0.0..sroa_idx unordered, align 4, !tbaa !463
   %4 = add i32 %3, %156
   %5 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 1, i64 0
-  store i32 %4, i32* %5, align 4, !tbaa !459
+  store i32 %4, i32* %5, align 4, !tbaa !463
   %6 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 1, i64 1
   %7 = bitcast i32* %.sroa.5.0..sroa_idx3 to <4 x i32>*
-  %8 = load <4 x i32>, <4 x i32>* %7, align 4, !tbaa !459
+  %8 = load <4 x i32>, <4 x i32>* %7, align 4, !tbaa !463
   %9 = insertelement <4 x i32> undef, i32 %176, i32 0
   %10 = insertelement <4 x i32> %9, i32 %196, i32 1
   %11 = insertelement <4 x i32> %10, i32 %216, i32 2
   %12 = insertelement <4 x i32> %11, i32 %225, i32 3
   %13 = add <4 x i32> %8, %12
   %14 = bitcast i32* %6 to <4 x i32>*
-  store <4 x i32> %13, <4 x i32>* %14, align 4, !tbaa !459
+  store <4 x i32> %13, <4 x i32>* %14, align 4, !tbaa !463
   %15 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 1, i64 5
   %16 = bitcast i32* %.sroa.13.0..sroa_idx11 to <4 x i32>*
-  %17 = load <4 x i32>, <4 x i32>* %16, align 4, !tbaa !459
+  %17 = load <4 x i32>, <4 x i32>* %16, align 4, !tbaa !463
   %18 = insertelement <4 x i32> undef, i32 %165, i32 0
   %19 = insertelement <4 x i32> %18, i32 %185, i32 1
   %20 = insertelement <4 x i32> %19, i32 %205, i32 2
   %21 = insertelement <4 x i32> %20, i32 %201, i32 3
   %22 = add <4 x i32> %17, %21
   %23 = bitcast i32* %15 to <4 x i32>*
-  store <4 x i32> %22, <4 x i32>* %23, align 4, !tbaa !459
-  %24 = load i32, i32* %.sroa.21.0..sroa_idx19, align 4, !tbaa !459
+  store <4 x i32> %22, <4 x i32>* %23, align 4, !tbaa !463
+  %24 = load atomic i32, i32* %.sroa.21.0..sroa_idx19 unordered, align 4, !tbaa !463
   %25 = add i32 %24, %221
   %26 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 1, i64 9
-  store i32 %25, i32* %26, align 4, !tbaa !459
-  %27 = load i32, i32* %.sroa.23.0..sroa_idx21, align 4, !tbaa !459
+  store i32 %25, i32* %26, align 4, !tbaa !463
+  %27 = load atomic i32, i32* %.sroa.23.0..sroa_idx21 unordered, align 4, !tbaa !463
   %28 = add i32 %27, %161
   %29 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 1, i64 10
-  store i32 %28, i32* %29, align 4, !tbaa !459
-  %30 = load i32, i32* %.sroa.25.0..sroa_idx23, align 4, !tbaa !459
+  store i32 %28, i32* %29, align 4, !tbaa !463
+  %30 = load atomic i32, i32* %.sroa.25.0..sroa_idx23 unordered, align 4, !tbaa !463
   %31 = add i32 %30, %181
   %32 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 1, i64 11
-  store i32 %31, i32* %32, align 4, !tbaa !459
-  %33 = load i32, i32* %.sroa.27.0..sroa_idx25, align 4, !tbaa !459
+  store i32 %31, i32* %32, align 4, !tbaa !463
+  %33 = load atomic i32, i32* %.sroa.27.0..sroa_idx25 unordered, align 4, !tbaa !463
   %34 = add i32 %33, %180
   %35 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 1, i64 12
-  store i32 %34, i32* %35, align 4, !tbaa !459
-  %36 = load i32, i32* %.sroa.29.0..sroa_idx27, align 4, !tbaa !459
+  store i32 %34, i32* %35, align 4, !tbaa !463
+  %36 = load atomic i32, i32* %.sroa.29.0..sroa_idx27 unordered, align 4, !tbaa !463
   %37 = add i32 %36, %200
   %38 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 1, i64 13
-  store i32 %37, i32* %38, align 4, !tbaa !459
-  %39 = load i32, i32* %.sroa.31.0..sroa_idx29, align 4, !tbaa !459
+  store i32 %37, i32* %38, align 4, !tbaa !463
+  %39 = load atomic i32, i32* %.sroa.31.0..sroa_idx29 unordered, align 4, !tbaa !463
   %40 = add i32 %39, %220
   %41 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 1, i64 14
-  store i32 %40, i32* %41, align 4, !tbaa !459
-  %42 = load i32, i32* %.sroa.33.0..sroa_idx31, align 4, !tbaa !459
+  store i32 %40, i32* %41, align 4, !tbaa !463
+  %42 = load atomic i32, i32* %.sroa.33.0..sroa_idx31 unordered, align 4, !tbaa !463
   %43 = add i32 %42, %160
   %44 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 1, i64 15
-  store i32 %43, i32* %44, align 4, !tbaa !459
+  store i32 %43, i32* %44, align 4, !tbaa !463
   %45 = getelementptr inbounds %struct.mi_random_cxt_s, %struct.mi_random_cxt_s* %0, i64 0, i32 2
-  store i32 16, i32* %45, align 4, !tbaa !460
+  store i32 16, i32* %45, align 4, !tbaa !464
   %46 = add i32 %33, 1
-  store i32 %46, i32* %.sroa.27.0..sroa_idx25, align 4, !tbaa !459
+  store i32 %46, i32* %.sroa.27.0..sroa_idx25, align 4, !tbaa !463
   %47 = icmp eq i32 %46, 0
   br i1 %47, label %228, label %233
 
@@ -42246,13 +42813,13 @@
 
 228:                                              ; preds = %2
   %229 = add i32 %36, 1
-  store i32 %229, i32* %.sroa.29.0..sroa_idx27, align 4, !tbaa !459
+  store i32 %229, i32* %.sroa.29.0..sroa_idx27, align 4, !tbaa !463
   %230 = icmp eq i32 %229, 0
   br i1 %230, label %231, label %233
 
 231:                                              ; preds = %228
   %232 = add i32 %39, 1
-  store i32 %232, i32* %.sroa.31.0..sroa_idx29, align 4, !tbaa !459
+  store i32 %232, i32* %.sroa.31.0..sroa_idx29, align 4, !tbaa !463
   br label %233
 
 233:                                              ; preds = %231, %228, %2
@@ -42266,41 +42833,41 @@
 tailrecurse:                                      ; preds = %48, %2
   %.tr = phi %struct.mi_heap_s* [ %0, %2 ], [ %8, %48 ]
   %3 = icmp eq %struct.mi_heap_s* %.tr, @_mi_heap_empty
-  br i1 %3, label %4, label %7, !prof !284, !misexpect !285
+  br i1 %3, label %4, label %7, !prof !282, !misexpect !283
 
 4:                                                ; preds = %tailrecurse
   tail call fastcc void @mi_thread_init() #37
-  %5 = load %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default, align 8, !tbaa !434
+  %5 = load atomic %struct.mi_heap_s*, %struct.mi_heap_s** @_mi_heap_default unordered, align 8, !tbaa !438
   %6 = icmp eq %struct.mi_heap_s* %5, @_mi_heap_empty
-  br i1 %6, label %_mi_page_malloc.exit, label %7, !prof !284, !misexpect !285
+  br i1 %6, label %_mi_page_malloc.exit, label %7, !prof !282, !misexpect !283
 
 7:                                                ; preds = %4, %tailrecurse
   %8 = phi %struct.mi_heap_s* [ %5, %4 ], [ %.tr, %tailrecurse ]
   %9 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %8, i64 0, i32 0
-  %10 = load %struct.mi_tld_s*, %struct.mi_tld_s** %9, align 8, !tbaa !461
+  %10 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %9 unordered, align 8, !tbaa !466
   %11 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %10, i64 0, i32 0
-  %12 = load i64, i64* %11, align 8, !tbaa !514
+  %12 = load atomic i64, i64* %11 unordered, align 8, !tbaa !518
   %13 = add i64 %12, 1
-  store i64 %13, i64* %11, align 8, !tbaa !514
-  %14 = load volatile void (i1, i64, i8*)*, void (i1, i64, i8*)** @deferred_free, align 8, !tbaa !434
+  store i64 %13, i64* %11, align 8, !tbaa !518
+  %14 = load atomic volatile void (i1, i64, i8*)*, void (i1, i64, i8*)** @deferred_free unordered, align 8, !tbaa !438
   %15 = icmp eq void (i1, i64, i8*)* %14, null
   br i1 %15, label %26, label %16
 
 16:                                               ; preds = %7
   %17 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %10, i64 0, i32 1
-  %18 = load i8, i8* %17, align 8, !tbaa !515, !range !72
+  %18 = load atomic i8, i8* %17 unordered, align 8, !tbaa !519, !range !70
   %19 = icmp eq i8 %18, 0
   br i1 %19, label %20, label %26
 
 20:                                               ; preds = %16
-  store i8 1, i8* %17, align 8, !tbaa !515
-  %21 = load volatile void (i1, i64, i8*)*, void (i1, i64, i8*)** @deferred_free, align 8, !tbaa !434
+  store i8 1, i8* %17, align 8, !tbaa !519
+  %21 = load atomic volatile void (i1, i64, i8*)*, void (i1, i64, i8*)** @deferred_free unordered, align 8, !tbaa !438
   %22 = load atomic i64, i64* bitcast (i8** @deferred_arg to i64*) monotonic, align 8
   %23 = inttoptr i64 %22 to i8*
   tail call void %21(i1 zeroext false, i64 %13, i8* %23) #37
-  %24 = load %struct.mi_tld_s*, %struct.mi_tld_s** %9, align 8, !tbaa !461
+  %24 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %9 unordered, align 8, !tbaa !466
   %25 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %24, i64 0, i32 1
-  store i8 0, i8* %25, align 8, !tbaa !515
+  store i8 0, i8* %25, align 8, !tbaa !519
   br label %26
 
 26:                                               ; preds = %20, %16, %7
@@ -42324,7 +42891,7 @@
   %37 = phi i64 [ %40, %.preheader ], [ %31, %33 ]
   %38 = inttoptr i64 %37 to %"class.kotlin::gc::GCHandle"*
   %39 = inttoptr i64 %37 to i64*
-  %40 = load i64, i64* %39, align 8, !tbaa !443
+  %40 = load atomic i64, i64* %39 unordered, align 8, !tbaa !447
   tail call fastcc void @_mi_free_delayed_block(%"class.kotlin::gc::GCHandle"* nonnull %38) #37
   %41 = icmp eq i64 %40, 0
   br i1 %41, label %.loopexit, label %.preheader
@@ -42332,13 +42899,13 @@
 .loopexit:                                        ; preds = %.preheader, %30
   %42 = tail call fastcc %struct.mi_page_s* @mi_find_page(%struct.mi_heap_s* %8, i64 %1)
   %43 = icmp eq %struct.mi_page_s* %42, null
-  br i1 %43, label %44, label %48, !prof !284, !misexpect !285
+  br i1 %43, label %44, label %48, !prof !282, !misexpect !283
 
 44:                                               ; preds = %.loopexit
   tail call fastcc void @mi_heap_collect_ex(%struct.mi_heap_s* %8, i32 1) #37
   %45 = tail call fastcc %struct.mi_page_s* @mi_find_page(%struct.mi_heap_s* %8, i64 %1)
   %46 = icmp eq %struct.mi_page_s* %45, null
-  br i1 %46, label %47, label %48, !prof !284, !misexpect !285
+  br i1 %46, label %47, label %48, !prof !282, !misexpect !283
 
 47:                                               ; preds = %44
   tail call void (i32, i8*, ...) @_mi_error_message(i32 12, i8* getelementptr inbounds ([39 x i8], [39 x i8]* @.str.520, i64 0, i64 0), i64 %1) #37
@@ -42347,19 +42914,19 @@
 48:                                               ; preds = %44, %.loopexit
   %49 = phi %struct.mi_page_s* [ %45, %44 ], [ %42, %.loopexit ]
   %50 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %49, i64 0, i32 6
-  %51 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %50, align 8, !tbaa !438
+  %51 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %50 unordered, align 8, !tbaa !442
   %52 = icmp eq %"class.kotlin::gc::GCHandle"* %51, null
-  br i1 %52, label %tailrecurse, label %53, !prof !284, !misexpect !285
+  br i1 %52, label %tailrecurse, label %53, !prof !282, !misexpect !283
 
 53:                                               ; preds = %48
   %54 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %49, i64 0, i32 7
-  %55 = load i32, i32* %54, align 8, !tbaa !442
+  %55 = load atomic i32, i32* %54 unordered, align 8, !tbaa !446
   %56 = add i32 %55, 1
-  store i32 %56, i32* %54, align 8, !tbaa !442
+  store i32 %56, i32* %54, align 8, !tbaa !446
   %57 = getelementptr %"class.kotlin::gc::GCHandle", %"class.kotlin::gc::GCHandle"* %51, i64 0, i32 0
-  %58 = load i64, i64* %57, align 8, !tbaa !443
+  %58 = load atomic i64, i64* %57 unordered, align 8, !tbaa !447
   %59 = bitcast %"class.kotlin::gc::GCHandle"** %50 to i64*
-  store i64 %58, i64* %59, align 8, !tbaa !438
+  store i64 %58, i64* %59, align 8, !tbaa !442
   %60 = bitcast %"class.kotlin::gc::GCHandle"* %51 to i8*
   br label %_mi_page_malloc.exit
 
@@ -42371,11 +42938,11 @@
 ; Function Attrs: nounwind uwtable
 define internal fastcc %struct.mi_page_s* @mi_find_page(%struct.mi_heap_s* %0, i64 %1) unnamed_addr #17 {
   %3 = icmp ugt i64 %1, 2097152
-  br i1 %3, label %4, label %103, !prof !284, !misexpect !285
+  br i1 %3, label %4, label %103, !prof !282, !misexpect !283
 
 4:                                                ; preds = %2
   %5 = icmp sgt i64 %1, -1
-  br i1 %5, label %_mi_os_good_alloc_size.exit, label %6, !prof !436, !misexpect !285
+  br i1 %5, label %_mi_os_good_alloc_size.exit, label %6, !prof !440, !misexpect !283
 
 6:                                                ; preds = %4
   tail call void (i32, i8*, ...) @_mi_error_message(i32 75, i8* getelementptr inbounds ([45 x i8], [45 x i8]* @.str.2.521, i64 0, i64 0), i64 %1) #37
@@ -42392,48 +42959,48 @@
   %14 = add i64 %13, %10
   %15 = sub nsw i64 0, %10
   %16 = and i64 %14, %15
-  %17 = select i1 %12, i64 %16, i64 %1, !prof !436
+  %17 = select i1 %12, i64 %16, i64 %1, !prof !440
   %18 = tail call fastcc %struct.mi_page_s* @mi_page_fresh_alloc(%struct.mi_heap_s* %0, %struct.mi_page_queue_s* null, i64 %17) #37
   %19 = icmp eq %struct.mi_page_s* %18, null
   br i1 %19, label %_mi_stat_counter_increase.exit, label %20
 
 20:                                               ; preds = %_mi_os_good_alloc_size.exit
   %21 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %18, i64 0, i32 8
-  %22 = load i32, i32* %21, align 4, !tbaa !550
+  %22 = load atomic i32, i32* %21 unordered, align 4, !tbaa !554
   %23 = zext i32 %22 to i64
   %24 = icmp ult i32 %22, 67108864
-  br i1 %24, label %_mi_segment_page_start.exit, label %25, !prof !436, !misexpect !437
+  br i1 %24, label %_mi_segment_page_start.exit, label %25, !prof !440, !misexpect !441
 
 25:                                               ; preds = %20
   %26 = ptrtoint %struct.mi_page_s* %18 to i64
   %27 = and i64 %26, -4194304
   %28 = inttoptr i64 %27 to %struct.mi_segment_s*
   %29 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %28, i64 0, i32 15
-  %30 = load i32, i32* %29, align 16, !tbaa !545
+  %30 = load atomic i32, i32* %29 unordered, align 16, !tbaa !549
   %31 = icmp eq i32 %30, 3
   br i1 %31, label %32, label %35
 
 32:                                               ; preds = %25
   %33 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %28, i64 0, i32 10
-  %34 = load i64, i64* %33, align 8, !tbaa !530
+  %34 = load atomic i64, i64* %33 unordered, align 8, !tbaa !534
   br label %39
 
 35:                                               ; preds = %25
   %36 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %28, i64 0, i32 13
-  %37 = load i64, i64* %36, align 32, !tbaa !445
+  %37 = load atomic i64, i64* %36 unordered, align 32, !tbaa !449
   %38 = shl nuw i64 1, %37
   br label %39
 
 39:                                               ; preds = %35, %32
   %40 = phi i64 [ %34, %32 ], [ %38, %35 ]
   %41 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %18, i64 0, i32 0
-  %42 = load i8, i8* %41, align 8, !tbaa !546
+  %42 = load atomic i8, i8* %41 unordered, align 8, !tbaa !550
   %43 = icmp eq i8 %42, 0
   br i1 %43, label %44, label %_mi_segment_page_start.exit
 
 44:                                               ; preds = %39
   %45 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %28, i64 0, i32 11
-  %46 = load i64, i64* %45, align 16, !tbaa !547
+  %46 = load atomic i64, i64* %45 unordered, align 16, !tbaa !551
   %47 = sub i64 %40, %46
   %48 = icmp ne i32 %22, 0
   %49 = icmp ult i32 %30, 2
@@ -42460,13 +43027,13 @@
   store atomic i64 0, i64* %63 release, align 8
   %64 = icmp ugt i64 %62, 67108864
   %65 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 0
-  %66 = load %struct.mi_tld_s*, %struct.mi_tld_s** %65, align 8, !tbaa !461
+  %66 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %65 unordered, align 8, !tbaa !466
   br i1 %64, label %67, label %85
 
 67:                                               ; preds = %_mi_segment_page_start.exit
   %68 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %66, i64 0, i32 6, i32 11
   tail call fastcc void @_mi_stat_increase(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull %68, i64 %62) #37
-  %69 = load %struct.mi_tld_s*, %struct.mi_tld_s** %65, align 8, !tbaa !461
+  %69 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %65 unordered, align 8, !tbaa !466
   %70 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %69, i64 0, i32 6, i32 21
   %71 = icmp uge { i64, i64 }* %70, bitcast (%struct.mi_stats_s* @_mi_stats_main to { i64, i64 }*)
   %72 = icmp ult { i64, i64 }* %70, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to { i64, i64 }*)
@@ -42481,19 +43048,19 @@
   br label %_mi_stat_counter_increase.exit
 
 79:                                               ; preds = %67
-  %80 = load i64, i64* %74, align 8, !tbaa !464
+  %80 = load atomic i64, i64* %74 unordered, align 8, !tbaa !469
   %81 = add nsw i64 %80, 1
-  store i64 %81, i64* %74, align 8, !tbaa !464
+  store i64 %81, i64* %74, align 8, !tbaa !469
   %82 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %70, i64 0, i32 0
-  %83 = load i64, i64* %82, align 8, !tbaa !466
+  %83 = load atomic i64, i64* %82 unordered, align 8, !tbaa !471
   %84 = add i64 %83, 1
-  store i64 %84, i64* %82, align 8, !tbaa !466
+  store i64 %84, i64* %82, align 8, !tbaa !471
   br label %_mi_stat_counter_increase.exit
 
 85:                                               ; preds = %_mi_segment_page_start.exit
   %86 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %66, i64 0, i32 6, i32 10
   tail call fastcc void @_mi_stat_increase(%"struct.(anonymous namespace)::RootSetStatistics"* nonnull %86, i64 %62) #37
-  %87 = load %struct.mi_tld_s*, %struct.mi_tld_s** %65, align 8, !tbaa !461
+  %87 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %65 unordered, align 8, !tbaa !466
   %88 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %87, i64 0, i32 6, i32 20
   %89 = icmp uge { i64, i64 }* %88, bitcast (%struct.mi_stats_s* @_mi_stats_main to { i64, i64 }*)
   %90 = icmp ult { i64, i64 }* %88, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to { i64, i64 }*)
@@ -42508,13 +43075,13 @@
   br label %_mi_stat_counter_increase.exit
 
 97:                                               ; preds = %85
-  %98 = load i64, i64* %92, align 8, !tbaa !464
+  %98 = load atomic i64, i64* %92 unordered, align 8, !tbaa !469
   %99 = add nsw i64 %98, 1
-  store i64 %99, i64* %92, align 8, !tbaa !464
+  store i64 %99, i64* %92, align 8, !tbaa !469
   %100 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %88, i64 0, i32 0
-  %101 = load i64, i64* %100, align 8, !tbaa !466
+  %101 = load atomic i64, i64* %100 unordered, align 8, !tbaa !471
   %102 = add i64 %101, 1
-  store i64 %102, i64* %100, align 8, !tbaa !466
+  store i64 %102, i64* %100, align 8, !tbaa !471
   br label %_mi_stat_counter_increase.exit
 
 103:                                              ; preds = %2
@@ -42534,7 +43101,7 @@
 
 112:                                              ; preds = %107
   %113 = add nsw i64 %105, -1
-  %114 = tail call i64 @llvm.ctlz.i64(i64 %113, i1 true) #37, !range !481
+  %114 = tail call i64 @llvm.ctlz.i64(i64 %113, i1 true) #37, !range !486
   %115 = trunc i64 %114 to i32
   %116 = xor i32 %115, 63
   %117 = shl nuw nsw i32 %116, 2
@@ -42553,7 +43120,7 @@
   %128 = and i64 %127, 255
   %129 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 2, i64 %128
   %130 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %129, i64 0, i32 0
-  %131 = load %struct.mi_page_s*, %struct.mi_page_s** %130, align 8, !tbaa !496
+  %131 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %130 unordered, align 8, !tbaa !500
   %132 = icmp eq %struct.mi_page_s* %131, null
   br i1 %132, label %190, label %133
 
@@ -42583,7 +43150,7 @@
 
 149:                                              ; preds = %145
   %150 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %131, i64 0, i32 2
-  %151 = load i16, i16* %150, align 2, !tbaa !538
+  %151 = load atomic i16, i16* %150 unordered, align 2, !tbaa !542
   %152 = zext i16 %151 to i32
   br label %153
 
@@ -42591,7 +43158,7 @@
   %154 = phi i32 [ 1, %149 ], [ %161, %153 ]
   %155 = phi %"class.kotlin::gc::GCHandle"* [ %147, %149 ], [ %157, %153 ]
   %156 = bitcast %"class.kotlin::gc::GCHandle"* %155 to %"class.kotlin::gc::GCHandle"**
-  %157 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %156, align 8, !tbaa !443
+  %157 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %156 unordered, align 8, !tbaa !447
   %158 = icmp ne %"class.kotlin::gc::GCHandle"* %157, null
   %159 = icmp ule i32 %154, %152
   %160 = and i1 %159, %158
@@ -42609,33 +43176,33 @@
 165:                                              ; preds = %162
   %166 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %131, i64 0, i32 9
   %167 = bitcast %"class.kotlin::gc::GCHandle"** %166 to i64*
-  %168 = load i64, i64* %167, align 8, !tbaa !539
+  %168 = load atomic i64, i64* %167 unordered, align 8, !tbaa !543
   %169 = getelementptr inbounds %"class.kotlin::gc::GCHandle", %"class.kotlin::gc::GCHandle"* %155, i64 0, i32 0
-  store i64 %168, i64* %169, align 8, !tbaa !443
-  store %"class.kotlin::gc::GCHandle"* %147, %"class.kotlin::gc::GCHandle"** %166, align 8, !tbaa !539
+  store i64 %168, i64* %169, align 8, !tbaa !447
+  store %"class.kotlin::gc::GCHandle"* %147, %"class.kotlin::gc::GCHandle"** %166, align 8, !tbaa !543
   %170 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %131, i64 0, i32 7
-  %171 = load i32, i32* %170, align 8, !tbaa !442
+  %171 = load atomic i32, i32* %170 unordered, align 8, !tbaa !446
   %172 = sub i32 %171, %154
-  store i32 %172, i32* %170, align 8, !tbaa !442
+  store i32 %172, i32* %170, align 8, !tbaa !446
   br label %173
 
 173:                                              ; preds = %165, %164, %145, %133
   %174 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %131, i64 0, i32 9
-  %175 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %174, align 8, !tbaa !539
+  %175 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %174 unordered, align 8, !tbaa !543
   %176 = icmp eq %"class.kotlin::gc::GCHandle"* %175, null
   %177 = getelementptr %struct.mi_page_s, %struct.mi_page_s* %131, i64 0, i32 6
-  %178 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %177, align 8, !tbaa !438
+  %178 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %177 unordered, align 8, !tbaa !442
   %179 = icmp eq %"class.kotlin::gc::GCHandle"* %178, null
   br i1 %176, label %185, label %180
 
 180:                                              ; preds = %173
-  br i1 %179, label %181, label %186, !prof !436, !misexpect !437
+  br i1 %179, label %181, label %186, !prof !440, !misexpect !441
 
 181:                                              ; preds = %180
-  store %"class.kotlin::gc::GCHandle"* %175, %"class.kotlin::gc::GCHandle"** %177, align 8, !tbaa !438
-  store %"class.kotlin::gc::GCHandle"* null, %"class.kotlin::gc::GCHandle"** %174, align 8, !tbaa !539
+  store %"class.kotlin::gc::GCHandle"* %175, %"class.kotlin::gc::GCHandle"** %177, align 8, !tbaa !442
+  store %"class.kotlin::gc::GCHandle"* null, %"class.kotlin::gc::GCHandle"** %174, align 8, !tbaa !543
   %182 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %131, i64 0, i32 5
-  %183 = load i8, i8* %182, align 1
+  %183 = load atomic i8, i8* %182 unordered, align 1
   %184 = and i8 %183, -2
   store i8 %184, i8* %182, align 1
   br label %186
@@ -42645,7 +43212,7 @@
 
 186:                                              ; preds = %185, %181, %180
   %187 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %131, i64 0, i32 5
-  %188 = load i8, i8* %187, align 1
+  %188 = load atomic i8, i8* %187 unordered, align 1
   %189 = and i8 %188, 1
   store i8 %189, i8* %187, align 1
   br label %_mi_stat_counter_increase.exit
@@ -42663,7 +43230,7 @@
 define internal fastcc %struct.mi_page_s* @mi_page_fresh_alloc(%struct.mi_heap_s* %0, %struct.mi_page_queue_s* %1, i64 %2) unnamed_addr #17 {
   %4 = alloca { i64, i64 }, align 8
   %5 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 0
-  %6 = load %struct.mi_tld_s*, %struct.mi_tld_s** %5, align 8, !tbaa !461
+  %6 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %5 unordered, align 8, !tbaa !466
   %7 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %6, i64 0, i32 4
   %8 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %6, i64 0, i32 5
   %9 = icmp ult i64 %2, 16385
@@ -42671,7 +43238,7 @@
 
 10:                                               ; preds = %3
   %11 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %7, i64 0, i32 0, i32 0
-  %12 = load %struct.mi_segment_s*, %struct.mi_segment_s** %11, align 8, !tbaa !554
+  %12 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %11 unordered, align 8, !tbaa !558
   %13 = icmp eq %struct.mi_segment_s* %12, null
   br i1 %13, label %14, label %19
 
@@ -42681,7 +43248,7 @@
   br i1 %16, label %128, label %17
 
 17:                                               ; preds = %14
-  %18 = load %struct.mi_segment_s*, %struct.mi_segment_s** %11, align 8, !tbaa !554
+  %18 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %11 unordered, align 8, !tbaa !558
   br label %19
 
 19:                                               ; preds = %17, %10
@@ -42695,7 +43262,7 @@
 
 24:                                               ; preds = %22
   %25 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %6, i64 0, i32 4, i32 1, i32 0
-  %26 = load %struct.mi_segment_s*, %struct.mi_segment_s** %25, align 8, !tbaa !554
+  %26 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %25 unordered, align 8, !tbaa !558
   %27 = icmp eq %struct.mi_segment_s* %26, null
   br i1 %27, label %28, label %33
 
@@ -42705,7 +43272,7 @@
   br i1 %30, label %128, label %31
 
 31:                                               ; preds = %28
-  %32 = load %struct.mi_segment_s*, %struct.mi_segment_s** %25, align 8, !tbaa !554
+  %32 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %25 unordered, align 8, !tbaa !558
   br label %33
 
 33:                                               ; preds = %31, %24
@@ -42733,12 +43300,12 @@
 
 46:                                               ; preds = %43
   %47 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %44, i64 0, i32 14
-  store atomic i64 0, i64* %47 seq_cst, align 8, !tbaa !531
+  store atomic i64 0, i64* %47 seq_cst, align 8, !tbaa !535
   %48 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %44, i64 0, i32 10
-  %49 = load i64, i64* %48, align 8, !tbaa !530
+  %49 = load atomic i64, i64* %48 unordered, align 8, !tbaa !534
   %50 = icmp slt i64 %49, 1
   %51 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %6, i64 0, i32 4, i32 10
-  %52 = load %struct.mi_stats_s*, %struct.mi_stats_s** %51, align 8, !tbaa !525
+  %52 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %51 unordered, align 8, !tbaa !529
   %53 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %52, i64 0, i32 0
   %54 = icmp uge %struct.mi_stats_s* %52, @_mi_stats_main
   %55 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %53, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -42773,23 +43340,23 @@
   br label %_mi_stat_increase.exit.i
 
 73:                                               ; preds = %58
-  %74 = load i64, i64* %57, align 8, !tbaa !510
+  %74 = load atomic i64, i64* %57 unordered, align 8, !tbaa !514
   %75 = add nsw i64 %74, 1
-  store i64 %75, i64* %57, align 8, !tbaa !510
+  store i64 %75, i64* %57, align 8, !tbaa !514
   %76 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %52, i64 0, i32 0, i32 2
-  %77 = load i64, i64* %76, align 8, !tbaa !511
+  %77 = load atomic i64, i64* %76 unordered, align 8, !tbaa !515
   %.not13 = icmp slt i64 %74, %77
   br i1 %.not13, label %79, label %78
 
 78:                                               ; preds = %73
-  store i64 %75, i64* %76, align 8, !tbaa !511
+  store i64 %75, i64* %76, align 8, !tbaa !515
   br label %79
 
 79:                                               ; preds = %78, %73
   %80 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %52, i64 0, i32 0, i32 0
-  %81 = load i64, i64* %80, align 8, !tbaa !512
+  %81 = load atomic i64, i64* %80 unordered, align 8, !tbaa !516
   %82 = add nsw i64 %81, 1
-  store i64 %82, i64* %80, align 8, !tbaa !512
+  store i64 %82, i64* %80, align 8, !tbaa !516
   br label %_mi_stat_increase.exit.i
 
 83:                                               ; preds = %46
@@ -42819,52 +43386,52 @@
   br label %_mi_stat_increase.exit.i
 
 99:                                               ; preds = %83
-  %100 = load i64, i64* %57, align 8, !tbaa !510
+  %100 = load atomic i64, i64* %57 unordered, align 8, !tbaa !514
   %101 = add i64 %100, -1
-  store i64 %101, i64* %57, align 8, !tbaa !510
+  store i64 %101, i64* %57, align 8, !tbaa !514
   %102 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %52, i64 0, i32 0, i32 2
-  %103 = load i64, i64* %102, align 8, !tbaa !511
+  %103 = load atomic i64, i64* %102 unordered, align 8, !tbaa !515
   %104 = icmp sgt i64 %101, %103
   br i1 %104, label %105, label %106
 
 105:                                              ; preds = %99
-  store i64 %101, i64* %102, align 8, !tbaa !511
+  store i64 %101, i64* %102, align 8, !tbaa !515
   br label %106
 
 106:                                              ; preds = %105, %99
   %107 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %52, i64 0, i32 0, i32 1
-  %108 = load i64, i64* %107, align 8, !tbaa !513
+  %108 = load atomic i64, i64* %107 unordered, align 8, !tbaa !517
   %109 = add i64 %108, 1
-  store i64 %109, i64* %107, align 8, !tbaa !513
+  store i64 %109, i64* %107, align 8, !tbaa !517
   br label %_mi_stat_increase.exit.i
 
 _mi_stat_increase.exit.i:                         ; preds = %106, %96, %79, %70
   %110 = phi i64 [ 1, %79 ], [ 1, %70 ], [ -1, %106 ], [ -1, %96 ]
   %111 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %6, i64 0, i32 4, i32 3
-  %112 = load i64, i64* %111, align 8, !tbaa !532
+  %112 = load atomic i64, i64* %111 unordered, align 8, !tbaa !536
   %113 = add i64 %112, %110
-  store i64 %113, i64* %111, align 8, !tbaa !532
+  store i64 %113, i64* %111, align 8, !tbaa !536
   %114 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %6, i64 0, i32 4, i32 4
-  %115 = load i64, i64* %114, align 8, !tbaa !533
+  %115 = load atomic i64, i64* %114 unordered, align 8, !tbaa !537
   %116 = icmp ugt i64 %113, %115
   br i1 %116, label %117, label %118
 
 117:                                              ; preds = %_mi_stat_increase.exit.i
-  store i64 %113, i64* %114, align 8, !tbaa !533
+  store i64 %113, i64* %114, align 8, !tbaa !537
   br label %118
 
 118:                                              ; preds = %117, %_mi_stat_increase.exit.i
   %119 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %6, i64 0, i32 4, i32 5
-  %120 = load i64, i64* %119, align 8, !tbaa !534
+  %120 = load atomic i64, i64* %119 unordered, align 8, !tbaa !538
   %121 = sub i64 %120, %49
-  store i64 %121, i64* %119, align 8, !tbaa !534
+  store i64 %121, i64* %119, align 8, !tbaa !538
   %122 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %6, i64 0, i32 4, i32 6
-  %123 = load i64, i64* %122, align 8, !tbaa !535
+  %123 = load atomic i64, i64* %122 unordered, align 8, !tbaa !539
   %124 = icmp ugt i64 %121, %123
   br i1 %124, label %125, label %126
 
 125:                                              ; preds = %118
-  store i64 %121, i64* %122, align 8, !tbaa !535
+  store i64 %121, i64* %122, align 8, !tbaa !539
   br label %126
 
 126:                                              ; preds = %125, %118
@@ -42882,14 +43449,14 @@
   call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %132) #37
   %133 = call i32 @clock_gettime(i32 0, { i64, i64 }* nonnull %4) #37
   %134 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %4, i64 0, i32 0
-  %135 = load i64, i64* %134, align 8, !tbaa !456
+  %135 = load atomic i64, i64* %134 unordered, align 8, !tbaa !460
   %136 = getelementptr inbounds { i64, i64 }, { i64, i64 }* %4, i64 0, i32 1
-  %137 = load i64, i64* %136, align 8, !tbaa !458
+  %137 = load atomic i64, i64* %136 unordered, align 8, !tbaa !462
   call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %132) #37
   %138 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %6, i64 0, i32 4, i32 2, i32 1
-  %139 = load %struct.mi_page_s*, %struct.mi_page_s** %138, align 8, !tbaa !497
+  %139 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %138 unordered, align 8, !tbaa !501
   %140 = icmp eq %struct.mi_page_s* %139, null
-  br i1 %140, label %.loopexit18, label %141
+  br i1 %140, label %.loopexit22, label %141
 
 141:                                              ; preds = %131
   %142 = sdiv i64 %137, 1000000
@@ -42901,13 +43468,13 @@
 146:                                              ; preds = %198, %141
   %147 = phi %struct.mi_page_s* [ %139, %141 ], [ %153, %198 ]
   %148 = getelementptr %struct.mi_page_s, %struct.mi_page_s* %147, i64 0, i32 7
-  %149 = load i32, i32* %148, align 8, !tbaa !442
+  %149 = load atomic i32, i32* %148 unordered, align 8, !tbaa !446
   %150 = icmp sgt i32 %149, %145
   br i1 %150, label %202, label %151
 
 151:                                              ; preds = %146
   %152 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %147, i64 0, i32 13
-  %153 = load %struct.mi_page_s*, %struct.mi_page_s** %152, align 8, !tbaa !504
+  %153 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %152 unordered, align 8, !tbaa !508
   %154 = ptrtoint %struct.mi_page_s* %147 to i64
   %155 = and i64 %154, -4194304
   %156 = inttoptr i64 %155 to %struct.mi_segment_s*
@@ -42917,31 +43484,31 @@
 
 158:                                              ; preds = %151
   %159 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %156, i64 0, i32 1
-  %160 = load i8, i8* %159, align 8, !tbaa !544, !range !72
+  %160 = load atomic i8, i8* %159 unordered, align 8, !tbaa !548, !range !70
   %161 = icmp eq i8 %160, 0
   br i1 %161, label %162, label %198
 
 162:                                              ; preds = %158
   %163 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %147, i64 0, i32 1
-  %164 = load i8, i8* %163, align 1
+  %164 = load atomic i8, i8* %163 unordered, align 1
   %165 = and i8 %164, 7
   %166 = icmp eq i8 %165, 4
   br i1 %166, label %167, label %198
 
 167:                                              ; preds = %162
   %168 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %156, i64 0, i32 15
-  %169 = load i32, i32* %168, align 16, !tbaa !545
+  %169 = load atomic i32, i32* %168 unordered, align 16, !tbaa !549
   %170 = icmp eq i32 %169, 3
   br i1 %170, label %171, label %174
 
 171:                                              ; preds = %167
   %172 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %156, i64 0, i32 10
-  %173 = load i64, i64* %172, align 8, !tbaa !530
+  %173 = load atomic i64, i64* %172 unordered, align 8, !tbaa !534
   br label %178
 
 174:                                              ; preds = %167
   %175 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %156, i64 0, i32 13
-  %176 = load i64, i64* %175, align 32, !tbaa !445
+  %176 = load atomic i64, i64* %175 unordered, align 32, !tbaa !449
   %177 = shl nuw i64 1, %176
   br label %178
 
@@ -42949,7 +43516,7 @@
   %179 = phi i64 [ %173, %171 ], [ %177, %174 ]
   %180 = inttoptr i64 %155 to i8*
   %181 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %147, i64 0, i32 0
-  %182 = load i8, i8* %181, align 8, !tbaa !546
+  %182 = load atomic i8, i8* %181 unordered, align 8, !tbaa !550
   %183 = zext i8 %182 to i64
   %184 = mul i64 %179, %183
   %185 = getelementptr inbounds i8, i8* %180, i64 %184
@@ -42958,7 +43525,7 @@
 
 187:                                              ; preds = %178
   %188 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %156, i64 0, i32 11
-  %189 = load i64, i64* %188, align 16, !tbaa !547
+  %189 = load atomic i64, i64* %188 unordered, align 16, !tbaa !551
   %190 = getelementptr inbounds i8, i8* %185, i64 %189
   %191 = sub i64 %179, %189
   br label %192
@@ -42976,28 +43543,28 @@
   br label %198
 
 198:                                              ; preds = %197, %192, %162, %158, %151
-  store i32 0, i32* %148, align 8, !tbaa !442
+  store i32 0, i32* %148, align 8, !tbaa !446
   %199 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %147, i64 0, i32 12
   %200 = icmp eq %struct.mi_page_s* %153, null
   %201 = bitcast %struct.mi_page_s** %199 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %201, i8 0, i64 16, i1 false) #37
-  br i1 %200, label %.loopexit18, label %146
+  br i1 %200, label %.loopexit22, label %146
 
 202:                                              ; preds = %146
-  store %struct.mi_page_s* %147, %struct.mi_page_s** %138, align 8, !tbaa !497
+  store %struct.mi_page_s* %147, %struct.mi_page_s** %138, align 8, !tbaa !501
   %203 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %147, i64 0, i32 12
-  store %struct.mi_page_s* null, %struct.mi_page_s** %203, align 8, !tbaa !499
+  store %struct.mi_page_s* null, %struct.mi_page_s** %203, align 8, !tbaa !503
   br label %_mi_segment_page_alloc.exit
 
-.loopexit18:                                      ; preds = %198, %131
+.loopexit22:                                      ; preds = %198, %131
   %204 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %6, i64 0, i32 4, i32 2, i32 0
   %205 = bitcast %struct.mi_page_s** %204 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %205, i8 0, i64 16, i1 false) #37
   br label %_mi_segment_page_alloc.exit
 
-_mi_segment_page_alloc.exit:                      ; preds = %.loopexit18, %202, %128
+_mi_segment_page_alloc.exit:                      ; preds = %.loopexit22, %202, %128
   %206 = icmp eq %struct.mi_page_s* %129, null
-  br i1 %206, label %515, label %207
+  br i1 %206, label %518, label %207
 
 207:                                              ; preds = %_mi_segment_page_alloc.exit
   %208 = ptrtoint %struct.mi_page_s* %129 to i64
@@ -43007,18 +43574,18 @@
   %212 = ptrtoint %struct.mi_heap_s* %0 to i64
   store atomic i64 %212, i64* %211 release, align 8
   %213 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %210, i64 0, i32 15
-  %214 = load i32, i32* %213, align 16, !tbaa !545
+  %214 = load atomic i32, i32* %213 unordered, align 16, !tbaa !549
   %215 = icmp eq i32 %214, 3
   br i1 %215, label %216, label %219
 
 216:                                              ; preds = %207
   %217 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %210, i64 0, i32 10
-  %218 = load i64, i64* %217, align 8, !tbaa !530
+  %218 = load atomic i64, i64* %217 unordered, align 8, !tbaa !534
   br label %223
 
 219:                                              ; preds = %207
   %220 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %210, i64 0, i32 13
-  %221 = load i64, i64* %220, align 32, !tbaa !445
+  %221 = load atomic i64, i64* %220 unordered, align 32, !tbaa !449
   %222 = shl nuw i64 1, %221
   br label %223
 
@@ -43026,14 +43593,14 @@
   %224 = phi i64 [ %218, %216 ], [ %222, %219 ]
   %225 = inttoptr i64 %209 to i8*
   %226 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %129, i64 0, i32 0
-  %227 = load i8, i8* %226, align 8, !tbaa !546
+  %227 = load atomic i8, i8* %226 unordered, align 8, !tbaa !550
   %228 = zext i8 %227 to i64
   %229 = icmp eq i8 %227, 0
   br i1 %229, label %230, label %_mi_segment_page_start.exit
 
 230:                                              ; preds = %223
   %231 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %210, i64 0, i32 11
-  %232 = load i64, i64* %231, align 16, !tbaa !547
+  %232 = load atomic i64, i64* %231 unordered, align 16, !tbaa !551
   %233 = sub i64 %224, %232
   %234 = icmp ne i64 %2, 0
   %235 = icmp ult i32 %214, 2
@@ -43058,44 +43625,44 @@
   %248 = select i1 %247, i64 %2, i64 67108864
   %249 = trunc i64 %248 to i32
   %250 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %129, i64 0, i32 8
-  store i32 %249, i32* %250, align 4, !tbaa !550
+  store i32 %249, i32* %250, align 4, !tbaa !554
   %251 = udiv i64 %246, %2
   %252 = trunc i64 %251 to i16
   %253 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %129, i64 0, i32 3
-  store i16 %252, i16* %253, align 4, !tbaa !551
+  store i16 %252, i16* %253, align 4, !tbaa !555
   %254 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %129, i64 0, i32 1
-  %255 = load i8, i8* %254, align 1
+  %255 = load atomic i8, i8* %254 unordered, align 1
   %256 = lshr i8 %255, 3
   %257 = and i8 %256, 1
   %258 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %129, i64 0, i32 5
-  %259 = load i8, i8* %258, align 1
+  %259 = load atomic i8, i8* %258 unordered, align 1
   %260 = and i8 %259, -2
   %261 = or i8 %260, %257
   store i8 %261, i8* %258, align 1
   %262 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %129, i64 0, i32 6
-  %263 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %262, align 8, !tbaa !438
+  %263 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %262 unordered, align 8, !tbaa !442
   %264 = icmp eq %"class.kotlin::gc::GCHandle"* %263, null
-  br i1 %264, label %265, label %321
+  br i1 %264, label %265, label %324
 
 265:                                              ; preds = %_mi_segment_page_start.exit
   %266 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %129, i64 0, i32 2
-  %267 = load i16, i16* %266, align 2, !tbaa !538
+  %267 = load atomic i16, i16* %266 unordered, align 2, !tbaa !542
   %268 = icmp ult i16 %267, %252
-  br i1 %268, label %269, label %321
+  br i1 %268, label %269, label %324
 
 269:                                              ; preds = %265
-  %270 = load i32, i32* %213, align 16, !tbaa !545
+  %270 = load atomic i32, i32* %213 unordered, align 16, !tbaa !549
   %271 = icmp eq i32 %270, 3
   br i1 %271, label %272, label %275
 
 272:                                              ; preds = %269
   %273 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %210, i64 0, i32 10
-  %274 = load i64, i64* %273, align 8, !tbaa !530
+  %274 = load atomic i64, i64* %273 unordered, align 8, !tbaa !534
   br label %279
 
 275:                                              ; preds = %269
   %276 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %210, i64 0, i32 13
-  %277 = load i64, i64* %276, align 32, !tbaa !445
+  %277 = load atomic i64, i64* %276 unordered, align 32, !tbaa !449
   %278 = shl nuw i64 1, %277
   br label %279
 
@@ -43105,7 +43672,7 @@
 
 281:                                              ; preds = %279
   %282 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %210, i64 0, i32 11
-  %283 = load i64, i64* %282, align 16, !tbaa !547
+  %283 = load atomic i64, i64* %282 unordered, align 16, !tbaa !551
   %284 = sub i64 %280, %283
   %285 = icmp ne i64 %248, 0
   %286 = icmp ult i32 %270, 2
@@ -43121,333 +43688,336 @@
   %294 = sub nsw i64 %248, %293
   %295 = icmp ult i64 %294, %248
   %296 = select i1 %295, i64 %294, i64 0
-  %spec.select25 = sub i64 %284, %296
+  %spec.select29 = sub i64 %284, %296
   br label %_mi_segment_page_start.exit9
 
 _mi_segment_page_start.exit9:                     ; preds = %288, %281, %279
-  %297 = phi i64 [ %284, %281 ], [ %280, %279 ], [ %spec.select25, %288 ]
-  %298 = icmp ult i32 %249, 67108864
-  %299 = select i1 %298, i64 %248, i64 %297
-  %300 = and i64 %251, 65535
-  %301 = zext i16 %267 to i64
-  %302 = sub nsw i64 %300, %301
-  %303 = icmp ugt i64 %299, 4095
-  br i1 %303, label %308, label %304
+  %297 = phi i64 [ %284, %281 ], [ %280, %279 ], [ %spec.select29, %288 ]
+  %298 = load atomic i32, i32* %250 unordered, align 4, !tbaa !554
+  %299 = icmp ult i32 %298, 67108864
+  %300 = zext i32 %298 to i64
+  %301 = select i1 %299, i64 %300, i64 %297
+  %302 = load atomic i16, i16* %253 unordered, align 4, !tbaa !555
+  %303 = zext i16 %302 to i64
+  %304 = zext i16 %267 to i64
+  %305 = sub nsw i64 %303, %304
+  %306 = icmp ugt i64 %301, 4095
+  br i1 %306, label %311, label %307
 
-304:                                              ; preds = %_mi_segment_page_start.exit9
-  %305 = trunc i64 %299 to i16
-  %306 = udiv i16 4096, %305
-  %307 = zext i16 %306 to i64
-  br label %308
+307:                                              ; preds = %_mi_segment_page_start.exit9
+  %308 = trunc i64 %301 to i16
+  %309 = udiv i16 4096, %308
+  %310 = zext i16 %309 to i64
+  br label %311
 
-308:                                              ; preds = %304, %_mi_segment_page_start.exit9
-  %309 = phi i64 [ %307, %304 ], [ 1, %_mi_segment_page_start.exit9 ]
-  %310 = icmp ugt i64 %302, %309
-  %311 = select i1 %310, i64 %309, i64 %302
-  call fastcc void @mi_page_free_list_extend(%struct.mi_page_s* nonnull %129, i64 %299, i64 %311) #37
-  %312 = trunc i64 %311 to i16
-  %313 = load i16, i16* %266, align 2, !tbaa !538
-  %314 = add i16 %313, %312
-  store i16 %314, i16* %266, align 2, !tbaa !538
-  %315 = load i8, i8* %254, align 1
-  %316 = and i8 %315, 8
-  %317 = icmp eq i8 %316, 0
-  br i1 %317, label %318, label %321
+311:                                              ; preds = %307, %_mi_segment_page_start.exit9
+  %312 = phi i64 [ %310, %307 ], [ 1, %_mi_segment_page_start.exit9 ]
+  %313 = icmp ugt i64 %305, %312
+  %314 = select i1 %313, i64 %312, i64 %305
+  call fastcc void @mi_page_free_list_extend(%struct.mi_page_s* nonnull %129, i64 %301, i64 %314) #37
+  %315 = trunc i64 %314 to i16
+  %316 = load atomic i16, i16* %266 unordered, align 2, !tbaa !542
+  %317 = add i16 %316, %315
+  store i16 %317, i16* %266, align 2, !tbaa !542
+  %318 = load atomic i8, i8* %254 unordered, align 1
+  %319 = and i8 %318, 8
+  %320 = icmp eq i8 %319, 0
+  br i1 %320, label %321, label %324
 
-318:                                              ; preds = %308
-  %319 = load i8, i8* %258, align 1
-  %320 = and i8 %319, -2
-  store i8 %320, i8* %258, align 1
-  br label %321
+321:                                              ; preds = %311
+  %322 = load atomic i8, i8* %258 unordered, align 1
+  %323 = and i8 %322, -2
+  store i8 %323, i8* %258, align 1
+  br label %324
 
-321:                                              ; preds = %318, %308, %265, %_mi_segment_page_start.exit
-  %322 = load %struct.mi_tld_s*, %struct.mi_tld_s** %5, align 8, !tbaa !461
-  %323 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %322, i64 0, i32 6, i32 1
-  %324 = icmp uge %"struct.(anonymous namespace)::RootSetStatistics"* %323, getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0)
-  %325 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %323, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
-  %326 = and i1 %324, %325
-  %327 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %322, i64 0, i32 6, i32 1, i32 3
-  br i1 %326, label %328, label %342
+324:                                              ; preds = %321, %311, %265, %_mi_segment_page_start.exit
+  %325 = load atomic %struct.mi_tld_s*, %struct.mi_tld_s** %5 unordered, align 8, !tbaa !466
+  %326 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %325, i64 0, i32 6, i32 1
+  %327 = icmp uge %"struct.(anonymous namespace)::RootSetStatistics"* %326, getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0)
+  %328 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %326, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
+  %329 = and i1 %327, %328
+  %330 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %325, i64 0, i32 6, i32 1, i32 3
+  br i1 %329, label %331, label %345
 
-328:                                              ; preds = %321
-  %329 = atomicrmw add i64* %327, i64 1 monotonic, align 8
-  %330 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %322, i64 0, i32 6, i32 1, i32 2
-  %331 = add nsw i64 %329, 1
-  %332 = load atomic i64, i64* %330 monotonic, align 8
-  br label %333
+331:                                              ; preds = %324
+  %332 = atomicrmw add i64* %330, i64 1 monotonic, align 8
+  %333 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %325, i64 0, i32 6, i32 1, i32 2
+  %334 = add nsw i64 %332, 1
+  %335 = load atomic i64, i64* %333 monotonic, align 8
+  br label %336
 
-333:                                              ; preds = %335, %328
-  %334 = phi i64 [ %332, %328 ], [ %338, %335 ]
-  %.not11 = icmp sgt i64 %334, %329
-  br i1 %.not11, label %339, label %335
+336:                                              ; preds = %338, %331
+  %337 = phi i64 [ %335, %331 ], [ %341, %338 ]
+  %.not11 = icmp sgt i64 %337, %332
+  br i1 %.not11, label %342, label %338
 
-335:                                              ; preds = %333
-  %336 = cmpxchg weak i64* %330, i64 %334, i64 %331 release monotonic, align 8
-  %337 = extractvalue { i64, i1 } %336, 1
-  %338 = extractvalue { i64, i1 } %336, 0
-  br i1 %337, label %339, label %333
+338:                                              ; preds = %336
+  %339 = cmpxchg weak i64* %333, i64 %337, i64 %334 release monotonic, align 8
+  %340 = extractvalue { i64, i1 } %339, 1
+  %341 = extractvalue { i64, i1 } %339, 0
+  br i1 %340, label %342, label %336
 
-339:                                              ; preds = %335, %333
-  %340 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %323, i64 0, i32 0
-  %341 = atomicrmw add i64* %340, i64 1 monotonic, align 8
+342:                                              ; preds = %338, %336
+  %343 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %326, i64 0, i32 0
+  %344 = atomicrmw add i64* %343, i64 1 monotonic, align 8
   br label %_mi_stat_increase.exit
 
-342:                                              ; preds = %321
-  %343 = load i64, i64* %327, align 8, !tbaa !510
-  %344 = add nsw i64 %343, 1
-  store i64 %344, i64* %327, align 8, !tbaa !510
-  %345 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %322, i64 0, i32 6, i32 1, i32 2
-  %346 = load i64, i64* %345, align 8, !tbaa !511
-  %.not10 = icmp slt i64 %343, %346
-  br i1 %.not10, label %348, label %347
+345:                                              ; preds = %324
+  %346 = load atomic i64, i64* %330 unordered, align 8, !tbaa !514
+  %347 = add nsw i64 %346, 1
+  store i64 %347, i64* %330, align 8, !tbaa !514
+  %348 = getelementptr inbounds %struct.mi_tld_s, %struct.mi_tld_s* %325, i64 0, i32 6, i32 1, i32 2
+  %349 = load atomic i64, i64* %348 unordered, align 8, !tbaa !515
+  %.not10 = icmp slt i64 %346, %349
+  br i1 %.not10, label %351, label %350
 
-347:                                              ; preds = %342
-  store i64 %344, i64* %345, align 8, !tbaa !511
-  br label %348
+350:                                              ; preds = %345
+  store i64 %347, i64* %348, align 8, !tbaa !515
+  br label %351
 
-348:                                              ; preds = %347, %342
-  %349 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %323, i64 0, i32 0
-  %350 = load i64, i64* %349, align 8, !tbaa !512
-  %351 = add nsw i64 %350, 1
-  store i64 %351, i64* %349, align 8, !tbaa !512
+351:                                              ; preds = %350, %345
+  %352 = getelementptr inbounds %"struct.(anonymous namespace)::RootSetStatistics", %"struct.(anonymous namespace)::RootSetStatistics"* %326, i64 0, i32 0
+  %353 = load atomic i64, i64* %352 unordered, align 8, !tbaa !516
+  %354 = add nsw i64 %353, 1
+  store i64 %354, i64* %352, align 8, !tbaa !516
   br label %_mi_stat_increase.exit
 
-_mi_stat_increase.exit:                           ; preds = %348, %339
-  %352 = icmp eq %struct.mi_page_queue_s* %1, null
-  br i1 %352, label %515, label %353
-
-353:                                              ; preds = %_mi_stat_increase.exit
-  %354 = getelementptr %struct.mi_page_queue_s, %struct.mi_page_queue_s* %1, i64 0, i32 2
-  %355 = load i64, i64* %354, align 8, !tbaa !500
-  %356 = icmp eq i64 %355, 2097168
-  %357 = zext i1 %356 to i8
-  %358 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %129, i64 0, i32 4, i32 0
-  %359 = load i8, i8* %358, align 2
-  %360 = and i8 %359, -2
-  %361 = or i8 %360, %357
-  store i8 %361, i8* %358, align 2
-  %362 = bitcast %struct.mi_page_queue_s* %1 to i64*
-  %363 = load i64, i64* %362, align 8, !tbaa !496
-  %364 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %129, i64 0, i32 12
-  %365 = bitcast %struct.mi_page_s** %364 to i64*
-  store i64 %363, i64* %365, align 8, !tbaa !499
-  %366 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %129, i64 0, i32 13
-  store %struct.mi_page_s* null, %struct.mi_page_s** %366, align 8, !tbaa !504
-  %367 = icmp eq i64 %363, 0
-  %368 = inttoptr i64 %363 to %struct.mi_page_s*
-  %369 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %368, i64 0, i32 13
-  %370 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %1, i64 0, i32 1
-  %371 = select i1 %367, %struct.mi_page_s** %370, %struct.mi_page_s** %369
-  store %struct.mi_page_s* %129, %struct.mi_page_s** %371, align 8, !tbaa !434
-  %372 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %1, i64 0, i32 0
-  store %struct.mi_page_s* %129, %struct.mi_page_s** %372, align 8, !tbaa !496
-  %373 = load i64, i64* %354, align 8, !tbaa !500
-  %374 = icmp ugt i64 %373, 1024
-  br i1 %374, label %.loopexit, label %375
+_mi_stat_increase.exit:                           ; preds = %351, %342
+  %355 = icmp eq %struct.mi_page_queue_s* %1, null
+  br i1 %355, label %518, label %356
 
-375:                                              ; preds = %353
-  %376 = add nuw nsw i64 %373, 7
-  %377 = lshr i64 %376, 3
-  %378 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %377
-  %379 = load %struct.mi_page_s*, %struct.mi_page_s** %378, align 8, !tbaa !434
-  %380 = icmp eq %struct.mi_page_s* %379, %129
-  br i1 %380, label %.loopexit, label %381
+356:                                              ; preds = %_mi_stat_increase.exit
+  %357 = getelementptr %struct.mi_page_queue_s, %struct.mi_page_queue_s* %1, i64 0, i32 2
+  %358 = load atomic i64, i64* %357 unordered, align 8, !tbaa !504
+  %359 = icmp eq i64 %358, 2097168
+  %360 = zext i1 %359 to i8
+  %361 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %129, i64 0, i32 4, i32 0
+  %362 = load atomic i8, i8* %361 unordered, align 2
+  %363 = and i8 %362, -2
+  %364 = or i8 %363, %360
+  store i8 %364, i8* %361, align 2
+  %365 = bitcast %struct.mi_page_queue_s* %1 to i64*
+  %366 = load atomic i64, i64* %365 unordered, align 8, !tbaa !500
+  %367 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %129, i64 0, i32 12
+  %368 = bitcast %struct.mi_page_s** %367 to i64*
+  store i64 %366, i64* %368, align 8, !tbaa !503
+  %369 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %129, i64 0, i32 13
+  store %struct.mi_page_s* null, %struct.mi_page_s** %369, align 8, !tbaa !508
+  %370 = icmp eq i64 %366, 0
+  %371 = inttoptr i64 %366 to %struct.mi_page_s*
+  %372 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %371, i64 0, i32 13
+  %373 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %1, i64 0, i32 1
+  %374 = select i1 %370, %struct.mi_page_s** %373, %struct.mi_page_s** %372
+  store %struct.mi_page_s* %129, %struct.mi_page_s** %374, align 8, !tbaa !438
+  %375 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %1, i64 0, i32 0
+  store %struct.mi_page_s* %129, %struct.mi_page_s** %375, align 8, !tbaa !500
+  %376 = load atomic i64, i64* %357 unordered, align 8, !tbaa !504
+  %377 = icmp ugt i64 %376, 1024
+  br i1 %377, label %.loopexit, label %378
 
-381:                                              ; preds = %375
-  %382 = icmp ult i64 %373, 9
-  br i1 %382, label %446, label %383
+378:                                              ; preds = %356
+  %379 = add nuw nsw i64 %376, 7
+  %380 = lshr i64 %379, 3
+  %381 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %380
+  %382 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %381 unordered, align 8, !tbaa !438
+  %383 = icmp eq %struct.mi_page_s* %382, %129
+  br i1 %383, label %.loopexit, label %384
 
-383:                                              ; preds = %381
-  %384 = icmp ult i64 %373, 65
-  br i1 %384, label %385, label %389
+384:                                              ; preds = %378
+  %385 = icmp ult i64 %376, 9
+  br i1 %385, label %449, label %386
 
-385:                                              ; preds = %383
-  %386 = trunc i64 %377 to i8
-  %387 = add nuw nsw i8 %386, 1
-  %388 = and i8 %387, -2
-  br label %403
+386:                                              ; preds = %384
+  %387 = icmp ult i64 %376, 65
+  br i1 %387, label %388, label %392
 
-389:                                              ; preds = %383
-  %390 = add nsw i64 %377, -1
-  %391 = call i64 @llvm.ctlz.i64(i64 %390, i1 true) #37, !range !481
-  %392 = trunc i64 %391 to i32
-  %393 = xor i32 %392, 63
-  %394 = shl nuw nsw i32 %393, 2
-  %395 = add nsw i32 %393, -2
-  %396 = zext i32 %395 to i64
-  %397 = lshr i64 %390, %396
-  %398 = trunc i64 %397 to i32
-  %399 = and i32 %398, 3
-  %400 = or i32 %399, %394
-  %401 = trunc i32 %400 to i8
-  %402 = add i8 %401, -3
-  br label %403
+388:                                              ; preds = %386
+  %389 = trunc i64 %380 to i8
+  %390 = add nuw nsw i8 %389, 1
+  %391 = and i8 %390, -2
+  br label %406
 
-403:                                              ; preds = %389, %385
-  %404 = phi i8 [ %388, %385 ], [ %402, %389 ]
-  %405 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 2, i64 0
+392:                                              ; preds = %386
+  %393 = add nsw i64 %380, -1
+  %394 = call i64 @llvm.ctlz.i64(i64 %393, i1 true) #37, !range !486
+  %395 = trunc i64 %394 to i32
+  %396 = xor i32 %395, 63
+  %397 = shl nuw nsw i32 %396, 2
+  %398 = add nsw i32 %396, -2
+  %399 = zext i32 %398 to i64
+  %400 = lshr i64 %393, %399
+  %401 = trunc i64 %400 to i32
+  %402 = and i32 %401, 3
+  %403 = or i32 %402, %397
+  %404 = trunc i32 %403 to i8
+  %405 = add i8 %404, -3
   br label %406
 
-406:                                              ; preds = %436, %403
-  %407 = phi %struct.mi_page_queue_s* [ %1, %403 ], [ %408, %436 ]
-  %408 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %407, i64 -1
-  %409 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %407, i64 -1, i32 2
-  %410 = load i64, i64* %409, align 8, !tbaa !500
-  %411 = add i64 %410, 7
-  %412 = lshr i64 %411, 3
-  %413 = icmp ult i64 %411, 16
-  br i1 %413, label %436, label %414
+406:                                              ; preds = %392, %388
+  %407 = phi i8 [ %391, %388 ], [ %405, %392 ]
+  %408 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 2, i64 0
+  br label %409
 
-414:                                              ; preds = %406
-  %415 = icmp ult i64 %411, 72
-  br i1 %415, label %416, label %420
+409:                                              ; preds = %439, %406
+  %410 = phi %struct.mi_page_queue_s* [ %1, %406 ], [ %411, %439 ]
+  %411 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %410, i64 -1
+  %412 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %410, i64 -1, i32 2
+  %413 = load atomic i64, i64* %412 unordered, align 8, !tbaa !504
+  %414 = add i64 %413, 7
+  %415 = lshr i64 %414, 3
+  %416 = icmp ult i64 %414, 16
+  br i1 %416, label %439, label %417
 
-416:                                              ; preds = %414
-  %417 = trunc i64 %412 to i8
-  %418 = add nuw nsw i8 %417, 1
-  %419 = and i8 %418, -2
-  br label %436
+417:                                              ; preds = %409
+  %418 = icmp ult i64 %414, 72
+  br i1 %418, label %419, label %423
 
-420:                                              ; preds = %414
-  %421 = icmp ugt i64 %411, 2097159
-  br i1 %421, label %436, label %422
+419:                                              ; preds = %417
+  %420 = trunc i64 %415 to i8
+  %421 = add nuw nsw i8 %420, 1
+  %422 = and i8 %421, -2
+  br label %439
 
-422:                                              ; preds = %420
-  %423 = add nsw i64 %412, -1
-  %424 = call i64 @llvm.ctlz.i64(i64 %423, i1 true) #37, !range !481
-  %425 = trunc i64 %424 to i32
-  %426 = xor i32 %425, 63
-  %427 = shl nuw nsw i32 %426, 2
-  %428 = add nsw i32 %426, -2
-  %429 = zext i32 %428 to i64
-  %430 = lshr i64 %423, %429
-  %431 = trunc i64 %430 to i32
-  %432 = and i32 %431, 3
-  %433 = or i32 %432, %427
-  %434 = trunc i32 %433 to i8
-  %435 = add i8 %434, -3
-  br label %436
+423:                                              ; preds = %417
+  %424 = icmp ugt i64 %414, 2097159
+  br i1 %424, label %439, label %425
 
-436:                                              ; preds = %422, %420, %416, %406
-  %437 = phi i8 [ %419, %416 ], [ %435, %422 ], [ 1, %406 ], [ 73, %420 ]
-  %438 = icmp eq i8 %404, %437
-  %439 = icmp ugt %struct.mi_page_queue_s* %408, %405
-  %440 = and i1 %439, %438
-  br i1 %440, label %406, label %441
+425:                                              ; preds = %423
+  %426 = add nsw i64 %415, -1
+  %427 = call i64 @llvm.ctlz.i64(i64 %426, i1 true) #37, !range !486
+  %428 = trunc i64 %427 to i32
+  %429 = xor i32 %428, 63
+  %430 = shl nuw nsw i32 %429, 2
+  %431 = add nsw i32 %429, -2
+  %432 = zext i32 %431 to i64
+  %433 = lshr i64 %426, %432
+  %434 = trunc i64 %433 to i32
+  %435 = and i32 %434, 3
+  %436 = or i32 %435, %430
+  %437 = trunc i32 %436 to i8
+  %438 = add i8 %437, -3
+  br label %439
 
-441:                                              ; preds = %436
-  %442 = add nuw nsw i64 %412, 1
-  %443 = icmp ult i64 %412, %377
-  %444 = select i1 %443, i64 %442, i64 %377
-  %445 = icmp ugt i64 %444, %377
-  br i1 %445, label %.loopexit, label %446
+439:                                              ; preds = %425, %423, %419, %409
+  %440 = phi i8 [ %422, %419 ], [ %438, %425 ], [ 1, %409 ], [ 73, %423 ]
+  %441 = icmp eq i8 %407, %440
+  %442 = icmp ugt %struct.mi_page_queue_s* %411, %408
+  %443 = and i1 %442, %441
+  br i1 %443, label %409, label %444
 
-446:                                              ; preds = %441, %381
-  %447 = phi i64 [ %444, %441 ], [ 0, %381 ]
-  %448 = add nuw nsw i64 %377, 1
-  %449 = sub nsw i64 %448, %447
-  %450 = icmp ult i64 %449, 4
-  br i1 %450, label %505, label %451
+444:                                              ; preds = %439
+  %445 = add nuw nsw i64 %415, 1
+  %446 = icmp ult i64 %415, %380
+  %447 = select i1 %446, i64 %445, i64 %380
+  %448 = icmp ugt i64 %447, %380
+  br i1 %448, label %.loopexit, label %449
 
-451:                                              ; preds = %446
-  %452 = and i64 %449, -4
-  %453 = add i64 %447, %452
-  %454 = insertelement <2 x %struct.mi_page_s*> undef, %struct.mi_page_s* %129, i32 0
-  %455 = shufflevector <2 x %struct.mi_page_s*> %454, <2 x %struct.mi_page_s*> undef, <2 x i32> zeroinitializer
-  %456 = add i64 %452, -4
-  %457 = lshr exact i64 %456, 2
-  %458 = add nuw nsw i64 %457, 1
-  %459 = and i64 %458, 3
-  %460 = icmp ult i64 %456, 12
-  br i1 %460, label %.loopexit17, label %461
+449:                                              ; preds = %444, %384
+  %450 = phi i64 [ %447, %444 ], [ 0, %384 ]
+  %451 = add nuw nsw i64 %380, 1
+  %452 = sub nsw i64 %451, %450
+  %453 = icmp ult i64 %452, 4
+  br i1 %453, label %508, label %454
 
-461:                                              ; preds = %451
-  %462 = and i64 %458, 9223372036854775804
-  br label %463
+454:                                              ; preds = %449
+  %455 = and i64 %452, -4
+  %456 = add i64 %450, %455
+  %457 = insertelement <2 x %struct.mi_page_s*> undef, %struct.mi_page_s* %129, i32 0
+  %458 = shufflevector <2 x %struct.mi_page_s*> %457, <2 x %struct.mi_page_s*> undef, <2 x i32> zeroinitializer
+  %459 = add i64 %455, -4
+  %460 = lshr exact i64 %459, 2
+  %461 = add nuw nsw i64 %460, 1
+  %462 = and i64 %461, 3
+  %463 = icmp ult i64 %459, 12
+  br i1 %463, label %.loopexit21, label %464
 
-463:                                              ; preds = %463, %461
-  %464 = phi i64 [ 0, %461 ], [ %489, %463 ]
-  %465 = phi i64 [ %462, %461 ], [ %490, %463 ]
-  %466 = add i64 %447, %464
-  %467 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %466
-  %468 = bitcast %struct.mi_page_s** %467 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %455, <2 x %struct.mi_page_s*>* %468, align 8, !tbaa !434
-  %469 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %467, i64 2
-  %470 = bitcast %struct.mi_page_s** %469 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %455, <2 x %struct.mi_page_s*>* %470, align 8, !tbaa !434
-  %471 = or i64 %464, 4
-  %472 = add i64 %447, %471
-  %473 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %472
-  %474 = bitcast %struct.mi_page_s** %473 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %455, <2 x %struct.mi_page_s*>* %474, align 8, !tbaa !434
-  %475 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %473, i64 2
-  %476 = bitcast %struct.mi_page_s** %475 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %455, <2 x %struct.mi_page_s*>* %476, align 8, !tbaa !434
-  %477 = or i64 %464, 8
-  %478 = add i64 %447, %477
-  %479 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %478
-  %480 = bitcast %struct.mi_page_s** %479 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %455, <2 x %struct.mi_page_s*>* %480, align 8, !tbaa !434
-  %481 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %479, i64 2
-  %482 = bitcast %struct.mi_page_s** %481 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %455, <2 x %struct.mi_page_s*>* %482, align 8, !tbaa !434
-  %483 = or i64 %464, 12
-  %484 = add i64 %447, %483
-  %485 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %484
-  %486 = bitcast %struct.mi_page_s** %485 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %455, <2 x %struct.mi_page_s*>* %486, align 8, !tbaa !434
-  %487 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %485, i64 2
-  %488 = bitcast %struct.mi_page_s** %487 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %455, <2 x %struct.mi_page_s*>* %488, align 8, !tbaa !434
-  %489 = add i64 %464, 16
-  %490 = add i64 %465, -4
-  %491 = icmp eq i64 %490, 0
-  br i1 %491, label %.loopexit17, label %463, !llvm.loop !572
+464:                                              ; preds = %454
+  %465 = and i64 %461, 9223372036854775804
+  br label %466
 
-.loopexit17:                                      ; preds = %463, %451
-  %492 = phi i64 [ 0, %451 ], [ %489, %463 ]
-  %493 = icmp eq i64 %459, 0
-  br i1 %493, label %.loopexit16, label %.preheader
+466:                                              ; preds = %466, %464
+  %467 = phi i64 [ 0, %464 ], [ %492, %466 ]
+  %468 = phi i64 [ %465, %464 ], [ %493, %466 ]
+  %469 = add i64 %450, %467
+  %470 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %469
+  %471 = bitcast %struct.mi_page_s** %470 to <2 x %struct.mi_page_s*>*
+  store <2 x %struct.mi_page_s*> %458, <2 x %struct.mi_page_s*>* %471, align 8, !tbaa !438
+  %472 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %470, i64 2
+  %473 = bitcast %struct.mi_page_s** %472 to <2 x %struct.mi_page_s*>*
+  store <2 x %struct.mi_page_s*> %458, <2 x %struct.mi_page_s*>* %473, align 8, !tbaa !438
+  %474 = or i64 %467, 4
+  %475 = add i64 %450, %474
+  %476 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %475
+  %477 = bitcast %struct.mi_page_s** %476 to <2 x %struct.mi_page_s*>*
+  store <2 x %struct.mi_page_s*> %458, <2 x %struct.mi_page_s*>* %477, align 8, !tbaa !438
+  %478 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %476, i64 2
+  %479 = bitcast %struct.mi_page_s** %478 to <2 x %struct.mi_page_s*>*
+  store <2 x %struct.mi_page_s*> %458, <2 x %struct.mi_page_s*>* %479, align 8, !tbaa !438
+  %480 = or i64 %467, 8
+  %481 = add i64 %450, %480
+  %482 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %481
+  %483 = bitcast %struct.mi_page_s** %482 to <2 x %struct.mi_page_s*>*
+  store <2 x %struct.mi_page_s*> %458, <2 x %struct.mi_page_s*>* %483, align 8, !tbaa !438
+  %484 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %482, i64 2
+  %485 = bitcast %struct.mi_page_s** %484 to <2 x %struct.mi_page_s*>*
+  store <2 x %struct.mi_page_s*> %458, <2 x %struct.mi_page_s*>* %485, align 8, !tbaa !438
+  %486 = or i64 %467, 12
+  %487 = add i64 %450, %486
+  %488 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %487
+  %489 = bitcast %struct.mi_page_s** %488 to <2 x %struct.mi_page_s*>*
+  store <2 x %struct.mi_page_s*> %458, <2 x %struct.mi_page_s*>* %489, align 8, !tbaa !438
+  %490 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %488, i64 2
+  %491 = bitcast %struct.mi_page_s** %490 to <2 x %struct.mi_page_s*>*
+  store <2 x %struct.mi_page_s*> %458, <2 x %struct.mi_page_s*>* %491, align 8, !tbaa !438
+  %492 = add i64 %467, 16
+  %493 = add i64 %468, -4
+  %494 = icmp eq i64 %493, 0
+  br i1 %494, label %.loopexit21, label %466, !llvm.loop !576
 
-.preheader:                                       ; preds = %.preheader, %.loopexit17
-  %494 = phi i64 [ %501, %.preheader ], [ %492, %.loopexit17 ]
-  %495 = phi i64 [ %502, %.preheader ], [ %459, %.loopexit17 ]
-  %496 = add i64 %447, %494
-  %497 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %496
-  %498 = bitcast %struct.mi_page_s** %497 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %455, <2 x %struct.mi_page_s*>* %498, align 8, !tbaa !434
-  %499 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %497, i64 2
-  %500 = bitcast %struct.mi_page_s** %499 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %455, <2 x %struct.mi_page_s*>* %500, align 8, !tbaa !434
-  %501 = add nuw i64 %494, 4
-  %502 = add nsw i64 %495, -1
-  %503 = icmp eq i64 %502, 0
-  br i1 %503, label %.loopexit16, label %.preheader, !llvm.loop !573
+.loopexit21:                                      ; preds = %466, %454
+  %495 = phi i64 [ 0, %454 ], [ %492, %466 ]
+  %496 = icmp eq i64 %462, 0
+  br i1 %496, label %.loopexit20, label %.preheader
 
-.loopexit16:                                      ; preds = %.preheader, %.loopexit17
-  %504 = icmp eq i64 %449, %452
-  br i1 %504, label %.loopexit, label %505
+.preheader:                                       ; preds = %.preheader, %.loopexit21
+  %497 = phi i64 [ %504, %.preheader ], [ %495, %.loopexit21 ]
+  %498 = phi i64 [ %505, %.preheader ], [ %462, %.loopexit21 ]
+  %499 = add i64 %450, %497
+  %500 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %499
+  %501 = bitcast %struct.mi_page_s** %500 to <2 x %struct.mi_page_s*>*
+  store <2 x %struct.mi_page_s*> %458, <2 x %struct.mi_page_s*>* %501, align 8, !tbaa !438
+  %502 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %500, i64 2
+  %503 = bitcast %struct.mi_page_s** %502 to <2 x %struct.mi_page_s*>*
+  store <2 x %struct.mi_page_s*> %458, <2 x %struct.mi_page_s*>* %503, align 8, !tbaa !438
+  %504 = add nuw i64 %497, 4
+  %505 = add nsw i64 %498, -1
+  %506 = icmp eq i64 %505, 0
+  br i1 %506, label %.loopexit20, label %.preheader, !llvm.loop !577
 
-505:                                              ; preds = %.loopexit16, %446
-  %506 = phi i64 [ %447, %446 ], [ %453, %.loopexit16 ]
-  br label %507
+.loopexit20:                                      ; preds = %.preheader, %.loopexit21
+  %507 = icmp eq i64 %452, %455
+  br i1 %507, label %.loopexit, label %508
 
-507:                                              ; preds = %507, %505
-  %508 = phi i64 [ %510, %507 ], [ %506, %505 ]
-  %509 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %508
-  store %struct.mi_page_s* %129, %struct.mi_page_s** %509, align 8, !tbaa !434
-  %510 = add nuw nsw i64 %508, 1
-  %511 = icmp eq i64 %508, %377
-  br i1 %511, label %.loopexit, label %507, !llvm.loop !574
+508:                                              ; preds = %.loopexit20, %449
+  %509 = phi i64 [ %450, %449 ], [ %456, %.loopexit20 ]
+  br label %510
 
-.loopexit:                                        ; preds = %507, %.loopexit16, %441, %375, %353
-  %512 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 8
-  %513 = load i64, i64* %512, align 8, !tbaa !494
-  %514 = add i64 %513, 1
-  store i64 %514, i64* %512, align 8, !tbaa !494
-  br label %515
+510:                                              ; preds = %510, %508
+  %511 = phi i64 [ %513, %510 ], [ %509, %508 ]
+  %512 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %511
+  store %struct.mi_page_s* %129, %struct.mi_page_s** %512, align 8, !tbaa !438
+  %513 = add nuw nsw i64 %511, 1
+  %514 = icmp eq i64 %511, %380
+  br i1 %514, label %.loopexit, label %510, !llvm.loop !578
 
-515:                                              ; preds = %.loopexit, %_mi_stat_increase.exit, %_mi_segment_page_alloc.exit
+.loopexit:                                        ; preds = %510, %.loopexit20, %444, %378, %356
+  %515 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 8
+  %516 = load atomic i64, i64* %515 unordered, align 8, !tbaa !498
+  %517 = add i64 %516, 1
+  store i64 %517, i64* %515, align 8, !tbaa !498
+  br label %518
+
+518:                                              ; preds = %.loopexit, %_mi_stat_increase.exit, %_mi_segment_page_alloc.exit
   ret %struct.mi_page_s* %129
 }
 
@@ -43463,16 +44033,16 @@
   %phi.bo = xor i1 %2, true
   br label %tailrecurse
 
-tailrecurse:                                      ; preds = %.loopexit37, %3
-  %.tr29 = phi i1 [ %phi.bo, %3 ], [ true, %.loopexit37 ]
-  %11 = load %struct.mi_page_s*, %struct.mi_page_s** %4, align 8, !tbaa !496
+tailrecurse:                                      ; preds = %.loopexit38, %3
+  %.tr30 = phi i1 [ %phi.bo, %3 ], [ true, %.loopexit38 ]
+  %11 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %4 unordered, align 8, !tbaa !500
   %12 = icmp eq %struct.mi_page_s* %11, null
-  br i1 %12, label %.loopexit39, label %13
+  br i1 %12, label %.loopexit40, label %13
 
 13:                                               ; preds = %528, %tailrecurse
   %14 = phi %struct.mi_page_s* [ %16, %528 ], [ %11, %tailrecurse ]
   %15 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 12
-  %16 = load %struct.mi_page_s*, %struct.mi_page_s** %15, align 8, !tbaa !499
+  %16 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %15 unordered, align 8, !tbaa !503
   %17 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 10
   %18 = load atomic i64, i64* %17 monotonic, align 8
   %19 = icmp ult i64 %18, 4
@@ -43498,7 +44068,7 @@
 
 32:                                               ; preds = %28
   %33 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 2
-  %34 = load i16, i16* %33, align 2, !tbaa !538
+  %34 = load atomic i16, i16* %33 unordered, align 2, !tbaa !542
   %35 = zext i16 %34 to i32
   br label %36
 
@@ -43506,7 +44076,7 @@
   %37 = phi i32 [ 1, %32 ], [ %44, %36 ]
   %38 = phi %"class.kotlin::gc::GCHandle"* [ %30, %32 ], [ %40, %36 ]
   %39 = bitcast %"class.kotlin::gc::GCHandle"* %38 to %"class.kotlin::gc::GCHandle"**
-  %40 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %39, align 8, !tbaa !443
+  %40 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %39 unordered, align 8, !tbaa !447
   %41 = icmp ne %"class.kotlin::gc::GCHandle"* %40, null
   %42 = icmp ule i32 %37, %35
   %43 = and i1 %42, %41
@@ -43524,48 +44094,48 @@
 48:                                               ; preds = %45
   %49 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 9
   %50 = bitcast %"class.kotlin::gc::GCHandle"** %49 to i64*
-  %51 = load i64, i64* %50, align 8, !tbaa !539
+  %51 = load atomic i64, i64* %50 unordered, align 8, !tbaa !543
   %52 = getelementptr inbounds %"class.kotlin::gc::GCHandle", %"class.kotlin::gc::GCHandle"* %38, i64 0, i32 0
-  store i64 %51, i64* %52, align 8, !tbaa !443
-  store %"class.kotlin::gc::GCHandle"* %30, %"class.kotlin::gc::GCHandle"** %49, align 8, !tbaa !539
+  store i64 %51, i64* %52, align 8, !tbaa !447
+  store %"class.kotlin::gc::GCHandle"* %30, %"class.kotlin::gc::GCHandle"** %49, align 8, !tbaa !543
   %53 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 7
-  %54 = load i32, i32* %53, align 8, !tbaa !442
+  %54 = load atomic i32, i32* %53 unordered, align 8, !tbaa !446
   %55 = sub i32 %54, %37
-  store i32 %55, i32* %53, align 8, !tbaa !442
+  store i32 %55, i32* %53, align 8, !tbaa !446
   br label %56
 
 56:                                               ; preds = %48, %47, %28, %13
   %57 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 9
-  %58 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %57, align 8, !tbaa !539
+  %58 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %57 unordered, align 8, !tbaa !543
   %59 = icmp eq %"class.kotlin::gc::GCHandle"* %58, null
   br i1 %59, label %68, label %60
 
 60:                                               ; preds = %56
   %61 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 6
-  %62 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %61, align 8, !tbaa !438
+  %62 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %61 unordered, align 8, !tbaa !442
   %63 = icmp eq %"class.kotlin::gc::GCHandle"* %62, null
-  br i1 %63, label %64, label %68, !prof !436, !misexpect !437
+  br i1 %63, label %64, label %68, !prof !440, !misexpect !441
 
 64:                                               ; preds = %60
-  store %"class.kotlin::gc::GCHandle"* %58, %"class.kotlin::gc::GCHandle"** %61, align 8, !tbaa !438
-  store %"class.kotlin::gc::GCHandle"* null, %"class.kotlin::gc::GCHandle"** %57, align 8, !tbaa !539
+  store %"class.kotlin::gc::GCHandle"* %58, %"class.kotlin::gc::GCHandle"** %61, align 8, !tbaa !442
+  store %"class.kotlin::gc::GCHandle"* null, %"class.kotlin::gc::GCHandle"** %57, align 8, !tbaa !543
   %65 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 5
-  %66 = load i8, i8* %65, align 1
+  %66 = load atomic i8, i8* %65 unordered, align 1
   %67 = and i8 %66, -2
   store i8 %67, i8* %65, align 1
   br label %68
 
 68:                                               ; preds = %64, %60, %56
   %69 = getelementptr %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 6
-  %70 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %69, align 8, !tbaa !438
+  %70 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %69 unordered, align 8, !tbaa !442
   %71 = icmp eq %"class.kotlin::gc::GCHandle"* %70, null
-  br i1 %71, label %72, label %.loopexit38
+  br i1 %71, label %72, label %.loopexit39
 
 72:                                               ; preds = %68
   %73 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 2
-  %74 = load i16, i16* %73, align 2, !tbaa !538
+  %74 = load atomic i16, i16* %73 unordered, align 2, !tbaa !542
   %75 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 3
-  %76 = load i16, i16* %75, align 4, !tbaa !551
+  %76 = load atomic i16, i16* %75 unordered, align 4, !tbaa !555
   %77 = icmp ult i16 %74, %76
   br i1 %77, label %78, label %144
 
@@ -43574,34 +44144,34 @@
   %80 = and i64 %79, -4194304
   %81 = inttoptr i64 %80 to %struct.mi_segment_s*
   %82 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 8
-  %83 = load i32, i32* %82, align 4, !tbaa !550
+  %83 = load atomic i32, i32* %82 unordered, align 4, !tbaa !554
   %84 = zext i32 %83 to i64
   %85 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %81, i64 0, i32 15
-  %86 = load i32, i32* %85, align 16, !tbaa !545
+  %86 = load atomic i32, i32* %85 unordered, align 16, !tbaa !549
   %87 = icmp eq i32 %86, 3
   br i1 %87, label %88, label %91
 
 88:                                               ; preds = %78
   %89 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %81, i64 0, i32 10
-  %90 = load i64, i64* %89, align 8, !tbaa !530
+  %90 = load atomic i64, i64* %89 unordered, align 8, !tbaa !534
   br label %95
 
 91:                                               ; preds = %78
   %92 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %81, i64 0, i32 13
-  %93 = load i64, i64* %92, align 32, !tbaa !445
+  %93 = load atomic i64, i64* %92 unordered, align 32, !tbaa !449
   %94 = shl nuw i64 1, %93
   br label %95
 
 95:                                               ; preds = %91, %88
   %96 = phi i64 [ %90, %88 ], [ %94, %91 ]
   %97 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 0
-  %98 = load i8, i8* %97, align 8, !tbaa !546
+  %98 = load atomic i8, i8* %97 unordered, align 8, !tbaa !550
   %99 = icmp eq i8 %98, 0
   br i1 %99, label %100, label %_mi_segment_page_start.exit
 
 100:                                              ; preds = %95
   %101 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %81, i64 0, i32 11
-  %102 = load i64, i64* %101, align 16, !tbaa !547
+  %102 = load atomic i64, i64* %101 unordered, align 16, !tbaa !551
   %103 = sub i64 %96, %102
   %104 = icmp ne i32 %83, 0
   %105 = icmp ult i32 %86, 2
@@ -43644,25 +44214,25 @@
   %132 = select i1 %131, i64 %130, i64 %123
   tail call fastcc void @mi_page_free_list_extend(%struct.mi_page_s* nonnull %14, i64 %120, i64 %132) #37
   %133 = trunc i64 %132 to i16
-  %134 = load i16, i16* %73, align 2, !tbaa !538
+  %134 = load atomic i16, i16* %73 unordered, align 2, !tbaa !542
   %135 = add i16 %134, %133
-  store i16 %135, i16* %73, align 2, !tbaa !538
+  store i16 %135, i16* %73, align 2, !tbaa !542
   %136 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 1
-  %137 = load i8, i8* %136, align 1
+  %137 = load atomic i8, i8* %136 unordered, align 1
   %138 = and i8 %137, 8
   %139 = icmp eq i8 %138, 0
-  br i1 %139, label %140, label %.loopexit38
+  br i1 %139, label %140, label %.loopexit39
 
 140:                                              ; preds = %129
   %141 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 5
-  %142 = load i8, i8* %141, align 1
+  %142 = load atomic i8, i8* %141 unordered, align 1
   %143 = and i8 %142, -2
   store i8 %143, i8* %141, align 1
-  br label %.loopexit38
+  br label %.loopexit39
 
 144:                                              ; preds = %72
   %145 = getelementptr %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 4, i32 0
-  %146 = load i8, i8* %145, align 2
+  %146 = load atomic i8, i8* %145 unordered, align 2
   %147 = and i8 %146, 1
   %148 = icmp eq i8 %147, 0
   br i1 %148, label %149, label %528
@@ -43675,21 +44245,21 @@
   %154 = load atomic i64, i64* %150 monotonic, align 8
   %155 = inttoptr i64 %154 to %struct.mi_heap_s*
   %156 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 13
-  %157 = load %struct.mi_page_s*, %struct.mi_page_s** %156, align 8, !tbaa !504
+  %157 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %156 unordered, align 8, !tbaa !508
   %158 = icmp eq %struct.mi_page_s* %157, null
   %159 = ptrtoint %struct.mi_page_s* %157 to i64
   br i1 %158, label %165, label %160
 
 160:                                              ; preds = %149
   %161 = bitcast %struct.mi_page_s** %15 to i64*
-  %162 = load i64, i64* %161, align 8, !tbaa !499
+  %162 = load atomic i64, i64* %161 unordered, align 8, !tbaa !503
   %163 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %157, i64 0, i32 12
   %164 = bitcast %struct.mi_page_s** %163 to i64*
-  store i64 %162, i64* %164, align 8, !tbaa !499
+  store i64 %162, i64* %164, align 8, !tbaa !503
   br label %165
 
 165:                                              ; preds = %160, %149
-  %166 = load %struct.mi_page_s*, %struct.mi_page_s** %15, align 8, !tbaa !499
+  %166 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %15 unordered, align 8, !tbaa !503
   %167 = icmp eq %struct.mi_page_s* %166, null
   %168 = ptrtoint %struct.mi_page_s* %166 to i64
   br i1 %167, label %172, label %169
@@ -43697,39 +44267,39 @@
 169:                                              ; preds = %165
   %170 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %166, i64 0, i32 13
   %171 = bitcast %struct.mi_page_s** %170 to i64*
-  store i64 %159, i64* %171, align 8, !tbaa !504
+  store i64 %159, i64* %171, align 8, !tbaa !508
   br label %172
 
 172:                                              ; preds = %169, %165
-  %173 = load %struct.mi_page_s*, %struct.mi_page_s** %5, align 8, !tbaa !497
+  %173 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %5 unordered, align 8, !tbaa !501
   %174 = icmp eq %struct.mi_page_s* %173, %14
   br i1 %174, label %175, label %178
 
 175:                                              ; preds = %172
   %176 = bitcast %struct.mi_page_s** %156 to i64*
-  %177 = load i64, i64* %176, align 8, !tbaa !504
-  store i64 %177, i64* %6, align 8, !tbaa !497
+  %177 = load atomic i64, i64* %176 unordered, align 8, !tbaa !508
+  store i64 %177, i64* %6, align 8, !tbaa !501
   br label %178
 
 178:                                              ; preds = %175, %172
-  %179 = load %struct.mi_page_s*, %struct.mi_page_s** %4, align 8, !tbaa !496
+  %179 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %4 unordered, align 8, !tbaa !500
   %180 = icmp eq %struct.mi_page_s* %179, %14
-  br i1 %180, label %181, label %.loopexit32
+  br i1 %180, label %181, label %.loopexit33
 
 181:                                              ; preds = %178
-  store i64 %168, i64* %7, align 8, !tbaa !496
-  %182 = load i64, i64* %8, align 8, !tbaa !500
+  store i64 %168, i64* %7, align 8, !tbaa !500
+  %182 = load atomic i64, i64* %8 unordered, align 8, !tbaa !504
   %183 = icmp ugt i64 %182, 1024
-  br i1 %183, label %.loopexit32, label %184
+  br i1 %183, label %.loopexit33, label %184
 
 184:                                              ; preds = %181
   %185 = select i1 %167, %struct.mi_page_s* @_mi_page_empty, %struct.mi_page_s* %166
   %186 = add nuw nsw i64 %182, 7
   %187 = lshr i64 %186, 3
   %188 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %155, i64 0, i32 1, i64 %187
-  %189 = load %struct.mi_page_s*, %struct.mi_page_s** %188, align 8, !tbaa !434
+  %189 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %188 unordered, align 8, !tbaa !438
   %190 = icmp eq %struct.mi_page_s* %189, %185
-  br i1 %190, label %.loopexit32, label %191
+  br i1 %190, label %.loopexit33, label %191
 
 191:                                              ; preds = %184
   %192 = icmp ult i64 %182, 9
@@ -43747,7 +44317,7 @@
 
 199:                                              ; preds = %193
   %200 = add nsw i64 %187, -1
-  %201 = tail call i64 @llvm.ctlz.i64(i64 %200, i1 true) #37, !range !481
+  %201 = tail call i64 @llvm.ctlz.i64(i64 %200, i1 true) #37, !range !486
   %202 = trunc i64 %201 to i32
   %203 = xor i32 %202, 63
   %204 = shl nuw nsw i32 %203, 2
@@ -43770,7 +44340,7 @@
   %217 = phi %struct.mi_page_queue_s* [ %1, %213 ], [ %218, %246 ]
   %218 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %217, i64 -1
   %219 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %217, i64 -1, i32 2
-  %220 = load i64, i64* %219, align 8, !tbaa !500
+  %220 = load atomic i64, i64* %219 unordered, align 8, !tbaa !504
   %221 = add i64 %220, 7
   %222 = lshr i64 %221, 3
   %223 = icmp ult i64 %221, 16
@@ -43792,7 +44362,7 @@
 
 232:                                              ; preds = %230
   %233 = add nsw i64 %222, -1
-  %234 = tail call i64 @llvm.ctlz.i64(i64 %233, i1 true) #37, !range !481
+  %234 = tail call i64 @llvm.ctlz.i64(i64 %233, i1 true) #37, !range !486
   %235 = trunc i64 %234 to i32
   %236 = xor i32 %235, 63
   %237 = shl nuw nsw i32 %236, 2
@@ -43818,7 +44388,7 @@
   %253 = icmp ult i64 %222, %187
   %254 = select i1 %253, i64 %252, i64 %187
   %255 = icmp ugt i64 %254, %187
-  br i1 %255, label %.loopexit32, label %256
+  br i1 %255, label %.loopexit33, label %256
 
 256:                                              ; preds = %251, %191
   %257 = phi i64 [ %254, %251 ], [ 0, %191 ]
@@ -43837,7 +44407,7 @@
   %268 = add nuw nsw i64 %267, 1
   %269 = and i64 %268, 3
   %270 = icmp ult i64 %266, 12
-  br i1 %270, label %.loopexit35, label %271
+  br i1 %270, label %.loopexit36, label %271
 
 271:                                              ; preds = %261
   %272 = and i64 %268, 9223372036854775804
@@ -43849,100 +44419,100 @@
   %276 = add i64 %257, %274
   %277 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %155, i64 0, i32 1, i64 %276
   %278 = bitcast %struct.mi_page_s** %277 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %278, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %278, align 8, !tbaa !438
   %279 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %277, i64 2
   %280 = bitcast %struct.mi_page_s** %279 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %280, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %280, align 8, !tbaa !438
   %281 = or i64 %274, 4
   %282 = add i64 %257, %281
   %283 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %155, i64 0, i32 1, i64 %282
   %284 = bitcast %struct.mi_page_s** %283 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %284, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %284, align 8, !tbaa !438
   %285 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %283, i64 2
   %286 = bitcast %struct.mi_page_s** %285 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %286, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %286, align 8, !tbaa !438
   %287 = or i64 %274, 8
   %288 = add i64 %257, %287
   %289 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %155, i64 0, i32 1, i64 %288
   %290 = bitcast %struct.mi_page_s** %289 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %290, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %290, align 8, !tbaa !438
   %291 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %289, i64 2
   %292 = bitcast %struct.mi_page_s** %291 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %292, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %292, align 8, !tbaa !438
   %293 = or i64 %274, 12
   %294 = add i64 %257, %293
   %295 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %155, i64 0, i32 1, i64 %294
   %296 = bitcast %struct.mi_page_s** %295 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %296, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %296, align 8, !tbaa !438
   %297 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %295, i64 2
   %298 = bitcast %struct.mi_page_s** %297 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %298, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %298, align 8, !tbaa !438
   %299 = add i64 %274, 16
   %300 = add i64 %275, -4
   %301 = icmp eq i64 %300, 0
-  br i1 %301, label %.loopexit35, label %273, !llvm.loop !575
+  br i1 %301, label %.loopexit36, label %273, !llvm.loop !579
 
-.loopexit35:                                      ; preds = %273, %261
+.loopexit36:                                      ; preds = %273, %261
   %302 = phi i64 [ 0, %261 ], [ %299, %273 ]
   %303 = icmp eq i64 %269, 0
-  br i1 %303, label %.loopexit34, label %.preheader33
+  br i1 %303, label %.loopexit35, label %.preheader34
 
-.preheader33:                                     ; preds = %.preheader33, %.loopexit35
-  %304 = phi i64 [ %311, %.preheader33 ], [ %302, %.loopexit35 ]
-  %305 = phi i64 [ %312, %.preheader33 ], [ %269, %.loopexit35 ]
+.preheader34:                                     ; preds = %.preheader34, %.loopexit36
+  %304 = phi i64 [ %311, %.preheader34 ], [ %302, %.loopexit36 ]
+  %305 = phi i64 [ %312, %.preheader34 ], [ %269, %.loopexit36 ]
   %306 = add i64 %257, %304
   %307 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %155, i64 0, i32 1, i64 %306
   %308 = bitcast %struct.mi_page_s** %307 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %308, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %308, align 8, !tbaa !438
   %309 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %307, i64 2
   %310 = bitcast %struct.mi_page_s** %309 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %310, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %265, <2 x %struct.mi_page_s*>* %310, align 8, !tbaa !438
   %311 = add nuw i64 %304, 4
   %312 = add nsw i64 %305, -1
   %313 = icmp eq i64 %312, 0
-  br i1 %313, label %.loopexit34, label %.preheader33, !llvm.loop !576
+  br i1 %313, label %.loopexit35, label %.preheader34, !llvm.loop !580
 
-.loopexit34:                                      ; preds = %.preheader33, %.loopexit35
+.loopexit35:                                      ; preds = %.preheader34, %.loopexit36
   %314 = icmp eq i64 %259, %262
-  br i1 %314, label %.loopexit32, label %315
+  br i1 %314, label %.loopexit33, label %315
 
-315:                                              ; preds = %.loopexit34, %256
-  %316 = phi i64 [ %257, %256 ], [ %263, %.loopexit34 ]
+315:                                              ; preds = %.loopexit35, %256
+  %316 = phi i64 [ %257, %256 ], [ %263, %.loopexit35 ]
   br label %317
 
 317:                                              ; preds = %317, %315
   %318 = phi i64 [ %320, %317 ], [ %316, %315 ]
   %319 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %155, i64 0, i32 1, i64 %318
-  store %struct.mi_page_s* %185, %struct.mi_page_s** %319, align 8, !tbaa !434
+  store %struct.mi_page_s* %185, %struct.mi_page_s** %319, align 8, !tbaa !438
   %320 = add nuw nsw i64 %318, 1
   %321 = icmp eq i64 %318, %187
-  br i1 %321, label %.loopexit32, label %317, !llvm.loop !577
+  br i1 %321, label %.loopexit33, label %317, !llvm.loop !581
 
-.loopexit32:                                      ; preds = %317, %.loopexit34, %251, %184, %181, %178
+.loopexit33:                                      ; preds = %317, %.loopexit35, %251, %184, %181, %178
   %322 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %152, i64 0, i32 2, i64 74, i32 1
   %323 = bitcast %struct.mi_page_s** %322 to i64*
-  %324 = load i64, i64* %323, align 8, !tbaa !497
+  %324 = load atomic i64, i64* %323 unordered, align 8, !tbaa !501
   %325 = bitcast %struct.mi_page_s** %156 to i64*
-  store i64 %324, i64* %325, align 8, !tbaa !504
-  store %struct.mi_page_s* null, %struct.mi_page_s** %15, align 8, !tbaa !499
+  store i64 %324, i64* %325, align 8, !tbaa !508
+  store %struct.mi_page_s* null, %struct.mi_page_s** %15, align 8, !tbaa !503
   %326 = icmp eq i64 %324, 0
   br i1 %326, label %332, label %327
 
-327:                                              ; preds = %.loopexit32
+327:                                              ; preds = %.loopexit33
   %328 = inttoptr i64 %324 to %struct.mi_page_s*
   %329 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %328, i64 0, i32 12
-  store %struct.mi_page_s* %14, %struct.mi_page_s** %329, align 8, !tbaa !499
-  store %struct.mi_page_s* %14, %struct.mi_page_s** %322, align 8, !tbaa !497
+  store %struct.mi_page_s* %14, %struct.mi_page_s** %329, align 8, !tbaa !503
+  store %struct.mi_page_s* %14, %struct.mi_page_s** %322, align 8, !tbaa !501
   %330 = getelementptr %struct.mi_heap_s, %struct.mi_heap_s* %152, i64 0, i32 2, i64 74, i32 2
-  %331 = load i64, i64* %330, align 8, !tbaa !500
+  %331 = load atomic i64, i64* %330 unordered, align 8, !tbaa !504
   br label %.loopexit
 
-332:                                              ; preds = %.loopexit32
+332:                                              ; preds = %.loopexit33
   %333 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %153, i64 0, i32 0
-  store %struct.mi_page_s* %14, %struct.mi_page_s** %333, align 8, !tbaa !496
-  store %struct.mi_page_s* %14, %struct.mi_page_s** %322, align 8, !tbaa !497
+  store %struct.mi_page_s* %14, %struct.mi_page_s** %333, align 8, !tbaa !500
+  store %struct.mi_page_s* %14, %struct.mi_page_s** %322, align 8, !tbaa !501
   %334 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %152, i64 0, i32 2, i64 74, i32 2
-  %335 = load i64, i64* %334, align 8, !tbaa !500
+  %335 = load atomic i64, i64* %334 unordered, align 8, !tbaa !504
   %336 = icmp ugt i64 %335, 1024
   br i1 %336, label %.loopexit, label %337
 
@@ -43950,7 +44520,7 @@
   %338 = add nuw nsw i64 %335, 7
   %339 = lshr i64 %338, 3
   %340 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %155, i64 0, i32 1, i64 %339
-  %341 = load %struct.mi_page_s*, %struct.mi_page_s** %340, align 8, !tbaa !434
+  %341 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %340 unordered, align 8, !tbaa !438
   %342 = icmp eq %struct.mi_page_s* %341, %14
   br i1 %342, label %.loopexit, label %343
 
@@ -43970,7 +44540,7 @@
 
 351:                                              ; preds = %345
   %352 = add nsw i64 %339, -1
-  %353 = tail call i64 @llvm.ctlz.i64(i64 %352, i1 true) #37, !range !481
+  %353 = tail call i64 @llvm.ctlz.i64(i64 %352, i1 true) #37, !range !486
   %354 = trunc i64 %353 to i32
   %355 = xor i32 %354, 63
   %356 = shl nuw nsw i32 %355, 2
@@ -43993,7 +44563,7 @@
   %369 = phi %struct.mi_page_queue_s* [ %153, %365 ], [ %370, %398 ]
   %370 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %369, i64 -1
   %371 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %369, i64 -1, i32 2
-  %372 = load i64, i64* %371, align 8, !tbaa !500
+  %372 = load atomic i64, i64* %371 unordered, align 8, !tbaa !504
   %373 = add i64 %372, 7
   %374 = lshr i64 %373, 3
   %375 = icmp ult i64 %373, 16
@@ -44015,7 +44585,7 @@
 
 384:                                              ; preds = %382
   %385 = add nsw i64 %374, -1
-  %386 = tail call i64 @llvm.ctlz.i64(i64 %385, i1 true) #37, !range !481
+  %386 = tail call i64 @llvm.ctlz.i64(i64 %385, i1 true) #37, !range !486
   %387 = trunc i64 %386 to i32
   %388 = xor i32 %387, 63
   %389 = shl nuw nsw i32 %388, 2
@@ -44060,7 +44630,7 @@
   %420 = add nuw nsw i64 %419, 1
   %421 = and i64 %420, 3
   %422 = icmp ult i64 %418, 12
-  br i1 %422, label %.loopexit31, label %423
+  br i1 %422, label %.loopexit32, label %423
 
 423:                                              ; preds = %413
   %424 = and i64 %420, 9223372036854775804
@@ -44072,80 +44642,80 @@
   %428 = add i64 %409, %426
   %429 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %155, i64 0, i32 1, i64 %428
   %430 = bitcast %struct.mi_page_s** %429 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %430, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %430, align 8, !tbaa !438
   %431 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %429, i64 2
   %432 = bitcast %struct.mi_page_s** %431 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %432, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %432, align 8, !tbaa !438
   %433 = or i64 %426, 4
   %434 = add i64 %409, %433
   %435 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %155, i64 0, i32 1, i64 %434
   %436 = bitcast %struct.mi_page_s** %435 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %436, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %436, align 8, !tbaa !438
   %437 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %435, i64 2
   %438 = bitcast %struct.mi_page_s** %437 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %438, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %438, align 8, !tbaa !438
   %439 = or i64 %426, 8
   %440 = add i64 %409, %439
   %441 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %155, i64 0, i32 1, i64 %440
   %442 = bitcast %struct.mi_page_s** %441 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %442, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %442, align 8, !tbaa !438
   %443 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %441, i64 2
   %444 = bitcast %struct.mi_page_s** %443 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %444, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %444, align 8, !tbaa !438
   %445 = or i64 %426, 12
   %446 = add i64 %409, %445
   %447 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %155, i64 0, i32 1, i64 %446
   %448 = bitcast %struct.mi_page_s** %447 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %448, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %448, align 8, !tbaa !438
   %449 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %447, i64 2
   %450 = bitcast %struct.mi_page_s** %449 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %450, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %450, align 8, !tbaa !438
   %451 = add i64 %426, 16
   %452 = add i64 %427, -4
   %453 = icmp eq i64 %452, 0
-  br i1 %453, label %.loopexit31, label %425, !llvm.loop !578
+  br i1 %453, label %.loopexit32, label %425, !llvm.loop !582
 
-.loopexit31:                                      ; preds = %425, %413
+.loopexit32:                                      ; preds = %425, %413
   %454 = phi i64 [ 0, %413 ], [ %451, %425 ]
   %455 = icmp eq i64 %421, 0
-  br i1 %455, label %.loopexit30, label %.preheader
+  br i1 %455, label %.loopexit31, label %.preheader
 
-.preheader:                                       ; preds = %.preheader, %.loopexit31
-  %456 = phi i64 [ %463, %.preheader ], [ %454, %.loopexit31 ]
-  %457 = phi i64 [ %464, %.preheader ], [ %421, %.loopexit31 ]
+.preheader:                                       ; preds = %.preheader, %.loopexit32
+  %456 = phi i64 [ %463, %.preheader ], [ %454, %.loopexit32 ]
+  %457 = phi i64 [ %464, %.preheader ], [ %421, %.loopexit32 ]
   %458 = add i64 %409, %456
   %459 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %155, i64 0, i32 1, i64 %458
   %460 = bitcast %struct.mi_page_s** %459 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %460, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %460, align 8, !tbaa !438
   %461 = getelementptr inbounds %struct.mi_page_s*, %struct.mi_page_s** %459, i64 2
   %462 = bitcast %struct.mi_page_s** %461 to <2 x %struct.mi_page_s*>*
-  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %462, align 8, !tbaa !434
+  store <2 x %struct.mi_page_s*> %417, <2 x %struct.mi_page_s*>* %462, align 8, !tbaa !438
   %463 = add nuw i64 %456, 4
   %464 = add nsw i64 %457, -1
   %465 = icmp eq i64 %464, 0
-  br i1 %465, label %.loopexit30, label %.preheader, !llvm.loop !579
+  br i1 %465, label %.loopexit31, label %.preheader, !llvm.loop !583
 
-.loopexit30:                                      ; preds = %.preheader, %.loopexit31
+.loopexit31:                                      ; preds = %.preheader, %.loopexit32
   %466 = icmp eq i64 %411, %414
   br i1 %466, label %.loopexit, label %467
 
-467:                                              ; preds = %.loopexit30, %408
-  %468 = phi i64 [ %409, %408 ], [ %415, %.loopexit30 ]
+467:                                              ; preds = %.loopexit31, %408
+  %468 = phi i64 [ %409, %408 ], [ %415, %.loopexit31 ]
   br label %469
 
 469:                                              ; preds = %469, %467
   %470 = phi i64 [ %472, %469 ], [ %468, %467 ]
   %471 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %155, i64 0, i32 1, i64 %470
-  store %struct.mi_page_s* %14, %struct.mi_page_s** %471, align 8, !tbaa !434
+  store %struct.mi_page_s* %14, %struct.mi_page_s** %471, align 8, !tbaa !438
   %472 = add nuw nsw i64 %470, 1
   %473 = icmp eq i64 %470, %339
-  br i1 %473, label %.loopexit, label %469, !llvm.loop !580
+  br i1 %473, label %.loopexit, label %469, !llvm.loop !584
 
-.loopexit:                                        ; preds = %469, %.loopexit30, %403, %337, %332, %327
-  %474 = phi i64 [ %335, %403 ], [ %335, %337 ], [ %335, %332 ], [ %331, %327 ], [ %335, %.loopexit30 ], [ %335, %469 ]
+.loopexit:                                        ; preds = %469, %.loopexit31, %403, %337, %332, %327
+  %474 = phi i64 [ %335, %403 ], [ %335, %337 ], [ %335, %332 ], [ %331, %327 ], [ %335, %.loopexit31 ], [ %335, %469 ]
   %475 = icmp eq i64 %474, 2097168
   %476 = zext i1 %475 to i8
-  %477 = load i8, i8* %145, align 2
+  %477 = load atomic i8, i8* %145 unordered, align 2
   %478 = and i8 %477, -2
   %479 = or i8 %478, %476
   store i8 %479, i8* %145, align 2
@@ -44172,7 +44742,7 @@
   br i1 %493, label %516, label %494
 
 494:                                              ; preds = %490
-  %495 = load i16, i16* %73, align 2, !tbaa !538
+  %495 = load atomic i16, i16* %73 unordered, align 2, !tbaa !542
   %496 = zext i16 %495 to i32
   br label %497
 
@@ -44180,7 +44750,7 @@
   %498 = phi i32 [ 1, %494 ], [ %505, %497 ]
   %499 = phi %"class.kotlin::gc::GCHandle"* [ %492, %494 ], [ %501, %497 ]
   %500 = bitcast %"class.kotlin::gc::GCHandle"* %499 to %"class.kotlin::gc::GCHandle"**
-  %501 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %500, align 8, !tbaa !443
+  %501 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %500 unordered, align 8, !tbaa !447
   %502 = icmp ne %"class.kotlin::gc::GCHandle"* %501, null
   %503 = icmp ule i32 %498, %496
   %504 = and i1 %503, %502
@@ -44197,18 +44767,18 @@
 
 509:                                              ; preds = %506
   %510 = bitcast %"class.kotlin::gc::GCHandle"** %57 to i64*
-  %511 = load i64, i64* %510, align 8, !tbaa !539
+  %511 = load atomic i64, i64* %510 unordered, align 8, !tbaa !543
   %512 = getelementptr inbounds %"class.kotlin::gc::GCHandle", %"class.kotlin::gc::GCHandle"* %499, i64 0, i32 0
-  store i64 %511, i64* %512, align 8, !tbaa !443
-  store %"class.kotlin::gc::GCHandle"* %492, %"class.kotlin::gc::GCHandle"** %57, align 8, !tbaa !539
+  store i64 %511, i64* %512, align 8, !tbaa !447
+  store %"class.kotlin::gc::GCHandle"* %492, %"class.kotlin::gc::GCHandle"** %57, align 8, !tbaa !543
   %513 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 7
-  %514 = load i32, i32* %513, align 8, !tbaa !442
+  %514 = load atomic i32, i32* %513 unordered, align 8, !tbaa !446
   %515 = sub i32 %514, %498
-  store i32 %515, i32* %513, align 8, !tbaa !442
+  store i32 %515, i32* %513, align 8, !tbaa !446
   br label %518
 
 516:                                              ; preds = %508, %490, %.loopexit
-  %517 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %57, align 8, !tbaa !539
+  %517 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %57 unordered, align 8, !tbaa !543
   br label %518
 
 518:                                              ; preds = %516, %509
@@ -44217,48 +44787,48 @@
   br i1 %520, label %528, label %521
 
 521:                                              ; preds = %518
-  %522 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %69, align 8, !tbaa !438
+  %522 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %69 unordered, align 8, !tbaa !442
   %523 = icmp eq %"class.kotlin::gc::GCHandle"* %522, null
-  br i1 %523, label %524, label %528, !prof !436, !misexpect !437
+  br i1 %523, label %524, label %528, !prof !440, !misexpect !441
 
 524:                                              ; preds = %521
-  store %"class.kotlin::gc::GCHandle"* %519, %"class.kotlin::gc::GCHandle"** %69, align 8, !tbaa !438
-  store %"class.kotlin::gc::GCHandle"* null, %"class.kotlin::gc::GCHandle"** %57, align 8, !tbaa !539
+  store %"class.kotlin::gc::GCHandle"* %519, %"class.kotlin::gc::GCHandle"** %69, align 8, !tbaa !442
+  store %"class.kotlin::gc::GCHandle"* null, %"class.kotlin::gc::GCHandle"** %57, align 8, !tbaa !543
   %525 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 5
-  %526 = load i8, i8* %525, align 1
+  %526 = load atomic i8, i8* %525 unordered, align 1
   %527 = and i8 %526, -2
   store i8 %527, i8* %525, align 1
   br label %528
 
 528:                                              ; preds = %524, %521, %518, %144
   %529 = icmp eq %struct.mi_page_s* %16, null
-  br i1 %529, label %.loopexit39, label %13
+  br i1 %529, label %.loopexit40, label %13
 
-.loopexit39:                                      ; preds = %528, %tailrecurse
-  %530 = load i64, i64* %9, align 8, !tbaa !519
-  %531 = load i64, i64* %10, align 8, !tbaa !520
+.loopexit40:                                      ; preds = %528, %tailrecurse
+  %530 = load atomic i64, i64* %9 unordered, align 8, !tbaa !523
+  %531 = load atomic i64, i64* %10 unordered, align 8, !tbaa !524
   %532 = icmp ugt i64 %530, %531
-  br i1 %532, label %.loopexit37, label %.preheader36
+  br i1 %532, label %.loopexit38, label %.preheader37
 
-.preheader36:                                     ; preds = %560, %.loopexit39
-  %533 = phi i64 [ %562, %560 ], [ 74, %.loopexit39 ]
-  %534 = phi i64 [ %561, %560 ], [ 0, %.loopexit39 ]
-  %535 = phi i64 [ %563, %560 ], [ %530, %.loopexit39 ]
+.preheader37:                                     ; preds = %560, %.loopexit40
+  %533 = phi i64 [ %562, %560 ], [ 74, %.loopexit40 ]
+  %534 = phi i64 [ %561, %560 ], [ 0, %.loopexit40 ]
+  %535 = phi i64 [ %563, %560 ], [ %530, %.loopexit40 ]
   %536 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 2, i64 %535
   %537 = getelementptr inbounds %struct.mi_page_queue_s, %struct.mi_page_queue_s* %536, i64 0, i32 0
-  %538 = load %struct.mi_page_s*, %struct.mi_page_s** %537, align 8, !tbaa !496
+  %538 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %537 unordered, align 8, !tbaa !500
   %539 = icmp eq %struct.mi_page_s* %538, null
   br i1 %539, label %560, label %540
 
-540:                                              ; preds = %.preheader36
+540:                                              ; preds = %.preheader37
   %541 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %538, i64 0, i32 5
-  %542 = load i8, i8* %541, align 1
+  %542 = load atomic i8, i8* %541 unordered, align 1
   %543 = icmp ult i8 %542, 2
   br i1 %543, label %560, label %544
 
 544:                                              ; preds = %540
   %545 = getelementptr %struct.mi_page_s, %struct.mi_page_s* %538, i64 0, i32 7
-  %546 = load i32, i32* %545, align 8, !tbaa !442
+  %546 = load atomic i32, i32* %545 unordered, align 8, !tbaa !446
   %547 = icmp eq i32 %546, 0
   br i1 %547, label %548, label %558
 
@@ -44269,7 +44839,7 @@
   br i1 %550, label %551, label %553
 
 551:                                              ; preds = %548
-  %552 = load %struct.mi_page_s*, %struct.mi_page_s** %537, align 8, !tbaa !496
+  %552 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %537 unordered, align 8, !tbaa !500
   tail call fastcc void @_mi_page_free(%struct.mi_page_s* %552, %struct.mi_page_queue_s* nonnull %536, i1 zeroext false) #37
   br label %560
 
@@ -44285,34 +44855,34 @@
   store i8 %559, i8* %541, align 1
   br label %560
 
-560:                                              ; preds = %558, %553, %551, %540, %.preheader36
-  %561 = phi i64 [ %534, %551 ], [ %534, %558 ], [ %534, %540 ], [ %534, %.preheader36 ], [ %557, %553 ]
-  %562 = phi i64 [ %533, %551 ], [ %533, %558 ], [ %533, %540 ], [ %533, %.preheader36 ], [ %555, %553 ]
+560:                                              ; preds = %558, %553, %551, %540, %.preheader37
+  %561 = phi i64 [ %534, %551 ], [ %534, %558 ], [ %534, %540 ], [ %534, %.preheader37 ], [ %557, %553 ]
+  %562 = phi i64 [ %533, %551 ], [ %533, %558 ], [ %533, %540 ], [ %533, %.preheader37 ], [ %555, %553 ]
   %563 = add i64 %535, 1
-  %564 = load i64, i64* %10, align 8, !tbaa !520
+  %564 = load atomic i64, i64* %10 unordered, align 8, !tbaa !524
   %565 = icmp ugt i64 %563, %564
-  br i1 %565, label %.loopexit37, label %.preheader36
+  br i1 %565, label %.loopexit38, label %.preheader37
 
-.loopexit37:                                      ; preds = %560, %.loopexit39
-  %566 = phi i64 [ 0, %.loopexit39 ], [ %561, %560 ]
-  %567 = phi i64 [ 74, %.loopexit39 ], [ %562, %560 ]
-  store i64 %567, i64* %9, align 8, !tbaa !519
-  store i64 %566, i64* %10, align 8, !tbaa !520
-  %568 = load i64, i64* %8, align 8, !tbaa !500
+.loopexit38:                                      ; preds = %560, %.loopexit40
+  %566 = phi i64 [ 0, %.loopexit40 ], [ %561, %560 ]
+  %567 = phi i64 [ 74, %.loopexit40 ], [ %562, %560 ]
+  store i64 %567, i64* %9, align 8, !tbaa !523
+  store i64 %566, i64* %10, align 8, !tbaa !524
+  %568 = load atomic i64, i64* %8 unordered, align 8, !tbaa !504
   %569 = tail call fastcc %struct.mi_page_s* @mi_page_fresh_alloc(%struct.mi_heap_s* nonnull %0, %struct.mi_page_queue_s* %1, i64 %568) #37
   %570 = icmp ne %struct.mi_page_s* %569, null
-  %571 = or i1 %570, %.tr29
-  br i1 %571, label %.loopexit40, label %tailrecurse
+  %571 = or i1 %570, %.tr30
+  br i1 %571, label %.loopexit41, label %tailrecurse
 
-.loopexit38:                                      ; preds = %140, %129, %68
+.loopexit39:                                      ; preds = %140, %129, %68
   %572 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %14, i64 0, i32 5
-  %573 = load i8, i8* %572, align 1
+  %573 = load atomic i8, i8* %572 unordered, align 1
   %574 = and i8 %573, 1
   store i8 %574, i8* %572, align 1
-  br label %.loopexit40
+  br label %.loopexit41
 
-.loopexit40:                                      ; preds = %.loopexit38, %.loopexit37
-  %575 = phi %struct.mi_page_s* [ %14, %.loopexit38 ], [ %569, %.loopexit37 ]
+.loopexit41:                                      ; preds = %.loopexit39, %.loopexit38
+  %575 = phi %struct.mi_page_s* [ %14, %.loopexit39 ], [ %569, %.loopexit38 ]
   ret %struct.mi_page_s* %575
 }
 
@@ -44322,21 +44892,21 @@
   %5 = and i64 %4, -4194304
   %6 = inttoptr i64 %5 to %struct.mi_segment_s*
   %7 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 8
-  %8 = load i32, i32* %7, align 4, !tbaa !550
+  %8 = load atomic i32, i32* %7 unordered, align 4, !tbaa !554
   %9 = zext i32 %8 to i64
   %10 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %6, i64 0, i32 15
-  %11 = load i32, i32* %10, align 16, !tbaa !545
+  %11 = load atomic i32, i32* %10 unordered, align 16, !tbaa !549
   %12 = icmp eq i32 %11, 3
   br i1 %12, label %13, label %16
 
 13:                                               ; preds = %3
   %14 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %6, i64 0, i32 10
-  %15 = load i64, i64* %14, align 8, !tbaa !530
+  %15 = load atomic i64, i64* %14 unordered, align 8, !tbaa !534
   br label %20
 
 16:                                               ; preds = %3
   %17 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %6, i64 0, i32 13
-  %18 = load i64, i64* %17, align 32, !tbaa !445
+  %18 = load atomic i64, i64* %17 unordered, align 32, !tbaa !449
   %19 = shl nuw i64 1, %18
   br label %20
 
@@ -44344,7 +44914,7 @@
   %21 = phi i64 [ %15, %13 ], [ %19, %16 ]
   %22 = inttoptr i64 %5 to i8*
   %23 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 0
-  %24 = load i8, i8* %23, align 8, !tbaa !546
+  %24 = load atomic i8, i8* %23 unordered, align 8, !tbaa !550
   %25 = zext i8 %24 to i64
   %26 = mul i64 %21, %25
   %27 = getelementptr inbounds i8, i8* %22, i64 %26
@@ -44353,7 +44923,7 @@
 
 29:                                               ; preds = %20
   %30 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %6, i64 0, i32 11
-  %31 = load i64, i64* %30, align 16, !tbaa !547
+  %31 = load atomic i64, i64* %30 unordered, align 16, !tbaa !551
   %32 = getelementptr inbounds i8, i8* %27, i64 %31
   %33 = icmp ne i32 %8, 0
   %34 = icmp ult i32 %11, 2
@@ -44372,7 +44942,7 @@
 _mi_segment_page_start.exit:                      ; preds = %36, %29, %20
   %42 = phi i8* [ %32, %29 ], [ %27, %20 ], [ %spec.select, %36 ]
   %43 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 2
-  %44 = load i16, i16* %43, align 2, !tbaa !538
+  %44 = load atomic i16, i16* %43 unordered, align 2, !tbaa !542
   %45 = zext i16 %44 to i64
   %46 = mul i64 %45, %1
   %47 = getelementptr inbounds i8, i8* %42, i64 %46
@@ -44388,18 +44958,18 @@
   %54 = getelementptr inbounds i8, i8* %53, i64 %1
   %55 = ptrtoint i8* %54 to i64
   %56 = bitcast i8* %53 to i64*
-  store i64 %55, i64* %56, align 8, !tbaa !443
+  store i64 %55, i64* %56, align 8, !tbaa !447
   %57 = icmp ugt i8* %54, %51
   br i1 %57, label %.loopexit, label %.preheader
 
 .loopexit:                                        ; preds = %.preheader, %_mi_segment_page_start.exit
   %58 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %0, i64 0, i32 6
   %59 = bitcast %"class.kotlin::gc::GCHandle"** %58 to i64*
-  %60 = load i64, i64* %59, align 8, !tbaa !438
+  %60 = load atomic i64, i64* %59 unordered, align 8, !tbaa !442
   %61 = bitcast i8* %51 to i64*
-  store i64 %60, i64* %61, align 8, !tbaa !443
+  store i64 %60, i64* %61, align 8, !tbaa !447
   %62 = bitcast %"class.kotlin::gc::GCHandle"** %58 to i8**
-  store i8* %47, i8** %62, align 8, !tbaa !438
+  store i8* %47, i8** %62, align 8, !tbaa !442
   ret void
 }
 
@@ -44407,23 +44977,23 @@
 define internal fastcc %struct.mi_segment_s* @mi_segment_reclaim_or_alloc(%struct.mi_heap_s* %0, i64 %1, i32 %2, i64 %3, %struct.mi_segments_tld_s* %4, %struct.mi_os_tld_s* nocapture %5) unnamed_addr #17 {
   %7 = alloca i8, align 1
   %8 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 9
-  %9 = load %struct.mi_segment_s*, %struct.mi_segment_s** %8, align 8, !tbaa !527
+  %9 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %8 unordered, align 8, !tbaa !531
   %10 = icmp eq %struct.mi_segment_s* %9, null
   br i1 %10, label %53, label %11
 
 11:                                               ; preds = %6
   %12 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 7
-  %13 = load i64, i64* %12, align 8, !tbaa !528
+  %13 = load atomic i64, i64* %12 unordered, align 8, !tbaa !532
   %14 = add i64 %13, -1
-  store i64 %14, i64* %12, align 8, !tbaa !528
+  store i64 %14, i64* %12, align 8, !tbaa !532
   %15 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %9, i64 0, i32 4
   %16 = bitcast %struct.mi_segment_s** %15 to i64*
-  %17 = load i64, i64* %16, align 8, !tbaa !529
+  %17 = load atomic i64, i64* %16 unordered, align 8, !tbaa !533
   %18 = bitcast %struct.mi_segment_s** %8 to i64*
-  store i64 %17, i64* %18, align 8, !tbaa !527
-  store %struct.mi_segment_s* null, %struct.mi_segment_s** %15, align 8, !tbaa !529
+  store i64 %17, i64* %18, align 8, !tbaa !531
+  store %struct.mi_segment_s* null, %struct.mi_segment_s** %15, align 8, !tbaa !533
   %19 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 10
-  %20 = load %struct.mi_stats_s*, %struct.mi_stats_s** %19, align 8, !tbaa !525
+  %20 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %19 unordered, align 8, !tbaa !529
   %21 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %20, i64 0, i32 13
   %22 = icmp uge %"struct.(anonymous namespace)::RootSetStatistics"* %21, getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 0, i32 0)
   %23 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %21, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
@@ -44455,23 +45025,23 @@
   br label %_mi_stat_decrease.exit
 
 41:                                               ; preds = %11
-  %42 = load i64, i64* %25, align 8, !tbaa !510
+  %42 = load atomic i64, i64* %25 unordered, align 8, !tbaa !514
   %43 = add i64 %42, -1
-  store i64 %43, i64* %25, align 8, !tbaa !510
+  store i64 %43, i64* %25, align 8, !tbaa !514
   %44 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %20, i64 0, i32 13, i32 2
-  %45 = load i64, i64* %44, align 8, !tbaa !511
+  %45 = load atomic i64, i64* %44 unordered, align 8, !tbaa !515
   %46 = icmp sgt i64 %43, %45
   br i1 %46, label %47, label %48
 
 47:                                               ; preds = %41
-  store i64 %43, i64* %44, align 8, !tbaa !511
+  store i64 %43, i64* %44, align 8, !tbaa !515
   br label %48
 
 48:                                               ; preds = %47, %41
   %49 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %20, i64 0, i32 13, i32 1
-  %50 = load i64, i64* %49, align 8, !tbaa !513
+  %50 = load atomic i64, i64* %49 unordered, align 8, !tbaa !517
   %51 = add i64 %50, 1
-  store i64 %51, i64* %49, align 8, !tbaa !513
+  store i64 %51, i64* %49, align 8, !tbaa !517
   br label %_mi_stat_decrease.exit
 
 _mi_stat_decrease.exit:                           ; preds = %48, %38
@@ -44480,14 +45050,14 @@
 
 53:                                               ; preds = %6
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %7) #37
-  store i8 0, i8* %7, align 1, !tbaa !482
+  store i8 0, i8* %7, align 1, !tbaa !465
   br label %54
 
 54:                                               ; preds = %191, %53
   %55 = phi i32 [ 7, %53 ], [ %192, %191 ]
   %56 = load atomic i64, i64* @abandoned monotonic, align 64
   %57 = icmp ult i64 %56, 4194304
-  br i1 %57, label %58, label %97, !prof !436, !misexpect !437
+  br i1 %57, label %58, label %97, !prof !440, !misexpect !441
 
 58:                                               ; preds = %54
   %59 = load atomic i64, i64* bitcast (%struct.mi_segment_s** @abandoned_visited to i64*) monotonic, align 64
@@ -44511,7 +45081,7 @@
   %71 = or i64 %70, %62
   %72 = cmpxchg i64* @abandoned, i64 %65, i64 %71 acq_rel acquire, align 8
   %73 = extractvalue { i64, i1 } %72, 1
-  br i1 %73, label %.loopexit, label %74, !prof !517
+  br i1 %73, label %.loopexit, label %74, !prof !521
 
 74:                                               ; preds = %67, %64
   br label %75
@@ -44540,7 +45110,7 @@
   %91 = cmpxchg weak i64* @abandoned, i64 %85, i64 %90 release monotonic, align 8
   %92 = extractvalue { i64, i1 } %91, 1
   %93 = extractvalue { i64, i1 } %91, 0
-  br i1 %92, label %.loopexit, label %84, !prof !517
+  br i1 %92, label %.loopexit, label %84, !prof !521
 
 .loopexit:                                        ; preds = %84, %67
   %94 = phi i64 [ %68, %67 ], [ %86, %84 ]
@@ -44581,11 +45151,11 @@
   store atomic i64 0, i64* %107 release, align 16
   %119 = atomicrmw sub i64* @abandoned_count, i64 1 monotonic, align 8
   %120 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %105, i64 0, i32 7
-  %121 = load i64, i64* %120, align 16, !tbaa !555
+  %121 = load atomic i64, i64* %120 unordered, align 16, !tbaa !559
   %122 = add i64 %121, 1
-  store i64 %122, i64* %120, align 16, !tbaa !555
+  store i64 %122, i64* %120, align 16, !tbaa !559
   %123 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %105, i64 0, i32 9
-  %124 = load i64, i64* %123, align 64, !tbaa !536
+  %124 = load atomic i64, i64* %123 unordered, align 64, !tbaa !540
   %125 = icmp eq i64 %124, 0
   br i1 %125, label %166, label %.preheader
 
@@ -44595,7 +45165,7 @@
   %128 = phi i64 [ %159, %157 ], [ 0, %117 ]
   %129 = phi i64 [ %158, %157 ], [ 0, %117 ]
   %130 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %105, i64 0, i32 16, i64 %127, i32 1
-  %131 = load i8, i8* %130, align 1
+  %131 = load atomic i8, i8* %130 unordered, align 1
   %132 = and i8 %131, 1
   %133 = icmp eq i8 %132, 0
   br i1 %133, label %157, label %134
@@ -44605,7 +45175,7 @@
   %136 = add i64 %129, 1
   tail call fastcc void @_mi_page_free_collect(%struct.mi_page_s* nonnull %135, i1 zeroext false) #37
   %137 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %105, i64 0, i32 16, i64 %127, i32 7
-  %138 = load i32, i32* %137, align 8, !tbaa !442
+  %138 = load atomic i32, i32* %137 unordered, align 8, !tbaa !446
   %139 = icmp eq i32 %138, 0
   br i1 %139, label %140, label %142
 
@@ -44615,14 +45185,14 @@
 
 142:                                              ; preds = %134
   %143 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %105, i64 0, i32 16, i64 %127, i32 8
-  %144 = load i32, i32* %143, align 4, !tbaa !550
+  %144 = load atomic i32, i32* %143 unordered, align 4, !tbaa !554
   %145 = zext i32 %144 to i64
   %146 = icmp eq i64 %145, %1
   br i1 %146, label %147, label %157
 
 147:                                              ; preds = %142
   %148 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %105, i64 0, i32 16, i64 %127, i32 3
-  %149 = load i16, i16* %148, align 4, !tbaa !551
+  %149 = load atomic i16, i16* %148 unordered, align 4, !tbaa !555
   %150 = zext i16 %149 to i32
   %151 = icmp ult i32 %138, %150
   br i1 %151, label %156, label %152
@@ -44641,7 +45211,7 @@
   %159 = phi i64 [ %141, %140 ], [ %128, %142 ], [ %128, %.preheader ], [ %128, %152 ], [ %128, %156 ]
   %160 = phi i8 [ 1, %140 ], [ %126, %142 ], [ 1, %.preheader ], [ %126, %152 ], [ 1, %156 ]
   %161 = add nuw i64 %127, 1
-  %162 = load i64, i64* %123, align 64, !tbaa !536
+  %162 = load atomic i64, i64* %123 unordered, align 64, !tbaa !540
   %163 = icmp ult i64 %161, %162
   br i1 %163, label %.preheader, label %164
 
@@ -44660,7 +45230,7 @@
 
 171:                                              ; preds = %168
   %172 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %105, i64 0, i32 15
-  %173 = load i32, i32* %172, align 16, !tbaa !545
+  %173 = load atomic i32, i32* %172 unordered, align 16, !tbaa !549
   %174 = icmp eq i32 %173, %2
   br i1 %174, label %175, label %177
 
@@ -44669,7 +45239,7 @@
   br label %.loopexit7
 
 177:                                              ; preds = %171, %168
-  %178 = load i64, i64* %120, align 16, !tbaa !555
+  %178 = load atomic i64, i64* %120 unordered, align 16, !tbaa !559
   %179 = icmp ugt i64 %178, 2
   br i1 %179, label %180, label %182
 
@@ -44700,7 +45270,7 @@
 
 .loopexit7:                                       ; preds = %191, %175, %115, %61, %58
   %194 = phi %struct.mi_segment_s* [ %176, %175 ], [ null, %115 ], [ null, %191 ], [ null, %61 ], [ null, %58 ]
-  %195 = load i8, i8* %7, align 1, !tbaa !482, !range !72
+  %195 = load atomic i8, i8* %7 unordered, align 1, !tbaa !465, !range !70
   %196 = icmp eq i8 %195, 0
   br i1 %196, label %197, label %201
 
@@ -44727,7 +45297,7 @@
   %3 = alloca i8, align 1
   %4 = alloca i8, align 1
   %5 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 9
-  %6 = load i64, i64* %5, align 8, !tbaa !536
+  %6 = load atomic i64, i64* %5 unordered, align 8, !tbaa !540
   %7 = icmp eq i64 %6, 0
   br i1 %7, label %.loopexit10, label %8
 
@@ -44749,18 +45319,18 @@
   %21 = phi i64 [ 0, %8 ], [ %228, %227 ]
   %22 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %21
   %23 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %21, i32 1
-  %24 = load i8, i8* %23, align 1
+  %24 = load atomic i8, i8* %23 unordered, align 1
   %25 = and i8 %24, 1
   %26 = icmp eq i8 %25, 0
   br i1 %26, label %27, label %227
 
 27:                                               ; preds = %20
   %28 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %21, i32 12
-  %29 = load %struct.mi_page_s*, %struct.mi_page_s** %28, align 8, !tbaa !499
+  %29 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %28 unordered, align 8, !tbaa !503
   %30 = icmp eq %struct.mi_page_s* %29, null
   %31 = ptrtoint %struct.mi_page_s* %29 to i64
   %32 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %21, i32 13
-  %33 = load %struct.mi_page_s*, %struct.mi_page_s** %32, align 8, !tbaa !504
+  %33 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %32 unordered, align 8, !tbaa !508
   br i1 %30, label %34, label %44
 
 34:                                               ; preds = %27
@@ -44772,12 +45342,12 @@
   br label %47
 
 38:                                               ; preds = %34
-  %39 = load %struct.mi_page_s*, %struct.mi_page_s** %9, align 8, !tbaa !552
+  %39 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %9 unordered, align 8, !tbaa !556
   %40 = icmp eq %struct.mi_page_s* %39, %22
   br i1 %40, label %60, label %41
 
 41:                                               ; preds = %38
-  %42 = load %struct.mi_page_s*, %struct.mi_page_s** %10, align 8, !tbaa !553
+  %42 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %10 unordered, align 8, !tbaa !557
   %43 = icmp eq %struct.mi_page_s* %42, %22
   br i1 %43, label %60, label %75
 
@@ -44790,8 +45360,8 @@
   %48 = phi i64 [ %37, %36 ], [ %45, %44 ]
   %49 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %33, i64 0, i32 12
   %50 = bitcast %struct.mi_page_s** %49 to i64*
-  store i64 %31, i64* %50, align 8, !tbaa !499
-  %51 = load %struct.mi_page_s*, %struct.mi_page_s** %28, align 8, !tbaa !499
+  store i64 %31, i64* %50, align 8, !tbaa !503
+  %51 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %28 unordered, align 8, !tbaa !503
   %52 = ptrtoint %struct.mi_page_s* %51 to i64
   %53 = icmp eq %struct.mi_page_s* %51, null
   br i1 %53, label %60, label %54
@@ -44802,36 +45372,36 @@
   %57 = phi i64 [ %48, %47 ], [ %45, %44 ]
   %58 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %55, i64 0, i32 13
   %59 = bitcast %struct.mi_page_s** %58 to i64*
-  store i64 %57, i64* %59, align 8, !tbaa !504
+  store i64 %57, i64* %59, align 8, !tbaa !508
   br label %60
 
 60:                                               ; preds = %54, %47, %41, %38
   %61 = phi i64 [ %52, %47 ], [ %56, %54 ], [ %31, %41 ], [ %31, %38 ]
-  %62 = load %struct.mi_page_s*, %struct.mi_page_s** %10, align 8, !tbaa !497
+  %62 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %10 unordered, align 8, !tbaa !501
   %63 = icmp eq %struct.mi_page_s* %62, %22
   br i1 %63, label %64, label %67
 
 64:                                               ; preds = %60
   %65 = bitcast %struct.mi_page_s** %32 to i64*
-  %66 = load i64, i64* %65, align 8, !tbaa !504
-  store i64 %66, i64* %11, align 8, !tbaa !497
+  %66 = load atomic i64, i64* %65 unordered, align 8, !tbaa !508
+  store i64 %66, i64* %11, align 8, !tbaa !501
   br label %67
 
 67:                                               ; preds = %64, %60
-  %68 = load %struct.mi_page_s*, %struct.mi_page_s** %9, align 8, !tbaa !496
+  %68 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %9 unordered, align 8, !tbaa !500
   %69 = icmp eq %struct.mi_page_s* %68, %22
   br i1 %69, label %70, label %71
 
 70:                                               ; preds = %67
-  store i64 %61, i64* %12, align 8, !tbaa !496
+  store i64 %61, i64* %12, align 8, !tbaa !500
   br label %71
 
 71:                                               ; preds = %70, %67
   %72 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %21, i32 7
-  store i32 0, i32* %72, align 8, !tbaa !442
+  store i32 0, i32* %72, align 8, !tbaa !446
   %73 = bitcast %struct.mi_page_s** %28 to i8*
   call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %73, i8 0, i64 16, i1 false) #37
-  %74 = load i8, i8* %23, align 1
+  %74 = load atomic i8, i8* %23 unordered, align 1
   br label %75
 
 75:                                               ; preds = %71, %41
@@ -44841,23 +45411,23 @@
   br i1 %78, label %79, label %113
 
 79:                                               ; preds = %75
-  %80 = load i32, i32* %13, align 8, !tbaa !545
+  %80 = load atomic i32, i32* %13 unordered, align 8, !tbaa !549
   %81 = icmp eq i32 %80, 3
   br i1 %81, label %82, label %84
 
 82:                                               ; preds = %79
-  %83 = load i64, i64* %15, align 8, !tbaa !530
+  %83 = load atomic i64, i64* %15 unordered, align 8, !tbaa !534
   br label %87
 
 84:                                               ; preds = %79
-  %85 = load i64, i64* %14, align 8, !tbaa !445
+  %85 = load atomic i64, i64* %14 unordered, align 8, !tbaa !449
   %86 = shl nuw i64 1, %85
   br label %87
 
 87:                                               ; preds = %84, %82
   %88 = phi i64 [ %83, %82 ], [ %86, %84 ]
   %89 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %22, i64 0, i32 0
-  %90 = load i8, i8* %89, align 8, !tbaa !546
+  %90 = load atomic i8, i8* %89 unordered, align 8, !tbaa !550
   %91 = zext i8 %90 to i64
   %92 = mul i64 %88, %91
   %93 = getelementptr inbounds i8, i8* %16, i64 %92
@@ -44865,7 +45435,7 @@
   br i1 %94, label %95, label %99
 
 95:                                               ; preds = %87
-  %96 = load i64, i64* %17, align 8, !tbaa !547
+  %96 = load atomic i64, i64* %17 unordered, align 8, !tbaa !551
   %97 = getelementptr inbounds i8, i8* %93, i64 %96
   %98 = sub i64 %88, %96
   br label %99
@@ -44874,14 +45444,14 @@
   %100 = phi i64 [ %98, %95 ], [ %88, %87 ]
   %101 = phi i8* [ %97, %95 ], [ %93, %87 ]
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %4) #37
-  store i8 0, i8* %4, align 1, !tbaa !482
+  store i8 0, i8* %4, align 1, !tbaa !465
   %102 = call fastcc zeroext i1 @mi_os_commitx(i8* %101, i64 %100, i1 zeroext true, i1 zeroext false, i8* nonnull %4) #37
   br i1 %102, label %103, label %112
 
 103:                                              ; preds = %99
-  %104 = load i8, i8* %4, align 1, !tbaa !482, !range !72
+  %104 = load atomic i8, i8* %4 unordered, align 1, !tbaa !465, !range !70
   %105 = icmp eq i8 %104, 0
-  %106 = load i8, i8* %23, align 1
+  %106 = load atomic i8, i8* %23 unordered, align 1
   br i1 %105, label %109, label %107
 
 107:                                              ; preds = %103
@@ -44904,16 +45474,16 @@
   %114 = phi i8 [ %111, %109 ], [ %76, %75 ]
   %115 = or i8 %114, 1
   store i8 %115, i8* %23, align 1
-  %116 = load i64, i64* %18, align 8, !tbaa !526
+  %116 = load atomic i64, i64* %18 unordered, align 8, !tbaa !530
   %117 = add i64 %116, 1
-  store i64 %117, i64* %18, align 8, !tbaa !526
-  %118 = load i8, i8* %23, align 1
+  store i64 %117, i64* %18, align 8, !tbaa !530
+  %118 = load atomic i8, i8* %23 unordered, align 1
   %119 = and i8 %118, 2
   %120 = icmp eq i8 %119, 0
   br i1 %120, label %.loopexit, label %121
 
 121:                                              ; preds = %113
-  %122 = load i8, i8* %19, align 8, !tbaa !544, !range !72
+  %122 = load atomic i8, i8* %19 unordered, align 8, !tbaa !548, !range !70
   %123 = icmp eq i8 %122, 0
   %124 = and i8 %118, 6
   %125 = icmp eq i8 %124, 6
@@ -44923,23 +45493,23 @@
 127:                                              ; preds = %121
   %128 = and i8 %118, -3
   store i8 %128, i8* %23, align 1
-  %129 = load i32, i32* %13, align 8, !tbaa !545
+  %129 = load atomic i32, i32* %13 unordered, align 8, !tbaa !549
   %130 = icmp eq i32 %129, 3
   br i1 %130, label %131, label %133
 
 131:                                              ; preds = %127
-  %132 = load i64, i64* %15, align 8, !tbaa !530
+  %132 = load atomic i64, i64* %15 unordered, align 8, !tbaa !534
   br label %136
 
 133:                                              ; preds = %127
-  %134 = load i64, i64* %14, align 8, !tbaa !445
+  %134 = load atomic i64, i64* %14 unordered, align 8, !tbaa !449
   %135 = shl nuw i64 1, %134
   br label %136
 
 136:                                              ; preds = %133, %131
   %137 = phi i64 [ %132, %131 ], [ %135, %133 ]
   %138 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %22, i64 0, i32 0
-  %139 = load i8, i8* %138, align 8, !tbaa !546
+  %139 = load atomic i8, i8* %138 unordered, align 8, !tbaa !550
   %140 = zext i8 %139 to i64
   %141 = mul i64 %137, %140
   %142 = getelementptr inbounds i8, i8* %16, i64 %141
@@ -44947,7 +45517,7 @@
   br i1 %143, label %144, label %148
 
 144:                                              ; preds = %136
-  %145 = load i64, i64* %17, align 8, !tbaa !547
+  %145 = load atomic i64, i64* %17 unordered, align 8, !tbaa !551
   %146 = getelementptr inbounds i8, i8* %142, i64 %145
   %147 = sub i64 %137, %145
   br label %148
@@ -44956,7 +45526,7 @@
   %149 = phi i64 [ %147, %144 ], [ %137, %136 ]
   %150 = phi i8* [ %146, %144 ], [ %142, %136 ]
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %3) #37
-  store i8 0, i8* %3, align 1, !tbaa !482
+  store i8 0, i8* %3, align 1, !tbaa !465
   %151 = icmp eq i64 %149, 0
   br i1 %151, label %152, label %153
 
@@ -44966,12 +45536,12 @@
 
 153:                                              ; preds = %148
   %154 = call fastcc zeroext i1 @_mi_os_unreset(i8* %150, i64 %149, i8* nonnull %3) #37
-  %155 = load i8, i8* %3, align 1, !tbaa !482
+  %155 = load atomic i8, i8* %3 unordered, align 1, !tbaa !465
   %156 = icmp eq i8 %155, 0
   br i1 %156, label %160, label %157
 
 157:                                              ; preds = %153
-  %158 = load i8, i8* %23, align 1
+  %158 = load atomic i8, i8* %23 unordered, align 1
   %159 = or i8 %158, 8
   store i8 %159, i8* %23, align 1
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %3) #37
@@ -44982,26 +45552,26 @@
   br i1 %154, label %.loopexit, label %161
 
 161:                                              ; preds = %160
-  %162 = load i8, i8* %23, align 1
+  %162 = load atomic i8, i8* %23 unordered, align 1
   br label %163
 
 163:                                              ; preds = %161, %157
   %164 = phi i8 [ %162, %161 ], [ %159, %157 ]
   %165 = and i8 %164, -2
   store i8 %165, i8* %23, align 1
-  %166 = load i64, i64* %18, align 8, !tbaa !526
+  %166 = load atomic i64, i64* %18 unordered, align 8, !tbaa !530
   %167 = add i64 %166, -1
-  store i64 %167, i64* %18, align 8, !tbaa !526
+  store i64 %167, i64* %18, align 8, !tbaa !530
   br label %227
 
 .loopexit:                                        ; preds = %160, %157, %152, %121, %113
-  %168 = load i64, i64* %18, align 8, !tbaa !526
-  %169 = load i64, i64* %5, align 8, !tbaa !536
+  %168 = load atomic i64, i64* %18 unordered, align 8, !tbaa !530
+  %169 = load atomic i64, i64* %5 unordered, align 8, !tbaa !540
   %170 = icmp eq i64 %168, %169
   br i1 %170, label %171, label %.loopexit10
 
 171:                                              ; preds = %.loopexit
-  %172 = load i32, i32* %13, align 8, !tbaa !545
+  %172 = load atomic i32, i32* %13 unordered, align 8, !tbaa !549
   %173 = icmp ult i32 %172, 2
   br i1 %173, label %174, label %.loopexit10
 
@@ -45022,11 +45592,11 @@
 179:                                              ; preds = %177, %175
   %180 = phi %struct.mi_segment_queue_s* [ %176, %175 ], [ %178, %177 ]
   %181 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 4
-  %182 = load %struct.mi_segment_s*, %struct.mi_segment_s** %181, align 8, !tbaa !529
+  %182 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %181 unordered, align 8, !tbaa !533
   %183 = icmp eq %struct.mi_segment_s* %182, null
   %184 = ptrtoint %struct.mi_segment_s* %182 to i64
   %185 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 5
-  %186 = load %struct.mi_segment_s*, %struct.mi_segment_s** %185, align 8, !tbaa !549
+  %186 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %185 unordered, align 8, !tbaa !553
   %187 = icmp eq %struct.mi_segment_s* %186, null
   br i1 %183, label %188, label %195
 
@@ -45039,7 +45609,7 @@
 
 191:                                              ; preds = %188
   %192 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %180, i64 0, i32 0
-  %193 = load %struct.mi_segment_s*, %struct.mi_segment_s** %192, align 8, !tbaa !554
+  %193 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %192 unordered, align 8, !tbaa !558
   %194 = icmp eq %struct.mi_segment_s* %193, %0
   br i1 %194, label %210, label %.loopexit10
 
@@ -45051,8 +45621,8 @@
   %198 = phi i64 [ %190, %189 ], [ %196, %195 ]
   %199 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %186, i64 0, i32 4
   %200 = bitcast %struct.mi_segment_s** %199 to i64*
-  store i64 %184, i64* %200, align 8, !tbaa !529
-  %201 = load %struct.mi_segment_s*, %struct.mi_segment_s** %181, align 8, !tbaa !529
+  store i64 %184, i64* %200, align 8, !tbaa !533
+  %201 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %181 unordered, align 8, !tbaa !533
   %202 = ptrtoint %struct.mi_segment_s* %201 to i64
   %203 = icmp eq %struct.mi_segment_s* %201, null
   br i1 %203, label %210, label %204
@@ -45063,32 +45633,32 @@
   %207 = phi i64 [ %198, %197 ], [ %196, %195 ]
   %208 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %205, i64 0, i32 5
   %209 = bitcast %struct.mi_segment_s** %208 to i64*
-  store i64 %207, i64* %209, align 8, !tbaa !549
+  store i64 %207, i64* %209, align 8, !tbaa !553
   br label %210
 
 210:                                              ; preds = %204, %197, %191
   %211 = phi i64 [ %206, %204 ], [ %202, %197 ], [ %184, %191 ]
   %212 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %180, i64 0, i32 0
-  %213 = load %struct.mi_segment_s*, %struct.mi_segment_s** %212, align 8, !tbaa !554
+  %213 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %212 unordered, align 8, !tbaa !558
   %214 = icmp eq %struct.mi_segment_s* %213, %0
   br i1 %214, label %215, label %217
 
 215:                                              ; preds = %210
   %216 = bitcast %struct.mi_segment_queue_s* %180 to i64*
-  store i64 %211, i64* %216, align 8, !tbaa !554
+  store i64 %211, i64* %216, align 8, !tbaa !558
   br label %217
 
 217:                                              ; preds = %215, %210
   %218 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %180, i64 0, i32 1
-  %219 = load %struct.mi_segment_s*, %struct.mi_segment_s** %218, align 8, !tbaa !548
+  %219 = load atomic %struct.mi_segment_s*, %struct.mi_segment_s** %218 unordered, align 8, !tbaa !552
   %220 = icmp eq %struct.mi_segment_s* %219, %0
   br i1 %220, label %221, label %225
 
 221:                                              ; preds = %217
   %222 = bitcast %struct.mi_segment_s** %185 to i64*
-  %223 = load i64, i64* %222, align 8, !tbaa !549
+  %223 = load atomic i64, i64* %222 unordered, align 8, !tbaa !553
   %224 = bitcast %struct.mi_segment_s** %218 to i64*
-  store i64 %223, i64* %224, align 8, !tbaa !548
+  store i64 %223, i64* %224, align 8, !tbaa !552
   br label %225
 
 225:                                              ; preds = %221, %217
@@ -45098,7 +45668,7 @@
 
 227:                                              ; preds = %163, %112, %20
   %228 = add nuw i64 %21, 1
-  %229 = load i64, i64* %5, align 8, !tbaa !536
+  %229 = load atomic i64, i64* %5 unordered, align 8, !tbaa !540
   %230 = icmp ult i64 %228, %229
   br i1 %230, label %20, label %.loopexit10
 
@@ -45141,7 +45711,7 @@
 
 35:                                               ; preds = %6
   %36 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 3
-  %37 = load i64, i64* %36, align 8, !tbaa !532
+  %37 = load atomic i64, i64* %36 unordered, align 8, !tbaa !536
   %38 = tail call fastcc i64 @mi_option_get(i32 13) #37
   %39 = icmp ult i64 %37, %38
   br i1 %39, label %43, label %40
@@ -45152,999 +45722,990 @@
   br label %43
 
 43:                                               ; preds = %40, %35
-  %44 = phi i1 [ true, %40 ], [ false, %35 ]
-  %45 = phi i8 [ 1, %40 ], [ 0, %35 ]
-  %46 = phi i1 [ %42, %40 ], [ false, %35 ]
-  %47 = zext i1 %46 to i8
+  %44 = phi i8 [ 0, %35 ], [ 1, %40 ]
+  %45 = phi i1 [ false, %35 ], [ %42, %40 ]
+  %46 = zext i1 %45 to i8
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %17) #37
-  store i8 %47, i8* %17, align 1, !tbaa !482
+  store i8 %46, i8* %17, align 1, !tbaa !465
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %18) #37
-  store i8 0, i8* %18, align 1, !tbaa !482
-  %48 = icmp eq %struct.mi_segment_s* %0, null
-  br i1 %48, label %134, label %49
+  store i8 0, i8* %18, align 1, !tbaa !465
+  %47 = icmp eq %struct.mi_segment_s* %0, null
+  br i1 %47, label %135, label %48
 
-49:                                               ; preds = %43
-  br i1 %34, label %50, label %58
+48:                                               ; preds = %43
+  br i1 %34, label %49, label %57
 
-50:                                               ; preds = %49
-  %51 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 15
-  %52 = load i32, i32* %51, align 8, !tbaa !545
-  %53 = icmp eq i32 %52, %2
-  br i1 %53, label %54, label %58
+49:                                               ; preds = %48
+  %50 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 15
+  %51 = load atomic i32, i32* %50 unordered, align 8, !tbaa !549
+  %52 = icmp eq i32 %51, %2
+  br i1 %52, label %53, label %57
 
-54:                                               ; preds = %50
-  %55 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 10
-  %56 = load i64, i64* %55, align 8, !tbaa !530
-  %57 = icmp eq i64 %56, %33
-  br i1 %57, label %582, label %58
+53:                                               ; preds = %49
+  %54 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 10
+  %55 = load atomic i64, i64* %54 unordered, align 8, !tbaa !534
+  %56 = icmp eq i64 %55, %33
+  br i1 %56, label %577, label %57
 
-58:                                               ; preds = %54, %50, %49
-  %59 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 9
-  %60 = load i64, i64* %59, align 8, !tbaa !536
-  %61 = icmp eq i64 %60, 0
-  br i1 %61, label %.loopexit24, label %62
+57:                                               ; preds = %53, %49, %48
+  %58 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 9
+  %59 = load atomic i64, i64* %58 unordered, align 8, !tbaa !540
+  %60 = icmp eq i64 %59, 0
+  br i1 %60, label %.loopexit24, label %61
 
-62:                                               ; preds = %58
-  %63 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 1
-  %64 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 15
-  %65 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 13
-  %66 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 10
-  %67 = bitcast %struct.mi_segment_s* %0 to i8*
-  %68 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 11
-  br label %71
+61:                                               ; preds = %57
+  %62 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 1
+  %63 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 15
+  %64 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 13
+  %65 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 10
+  %66 = bitcast %struct.mi_segment_s* %0 to i8*
+  %67 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 11
+  %68 = load atomic i8, i8* %17 unordered, align 1
+  %69 = icmp eq i8 %68, 0
+  br label %72
 
-.loopexit24:                                      ; preds = %123, %58
-  %69 = phi i64 [ 0, %58 ], [ %125, %123 ]
-  %70 = icmp ult i64 %69, %25
-  br i1 %70, label %127, label %557
+.loopexit24:                                      ; preds = %124, %57
+  %70 = phi i64 [ 0, %57 ], [ %126, %124 ]
+  %71 = icmp ult i64 %70, %25
+  br i1 %71, label %128, label %552
 
-71:                                               ; preds = %123, %62
-  %72 = phi i64 [ 0, %62 ], [ %124, %123 ]
-  %73 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %72, i32 1
-  %74 = load i8, i8* %73, align 1
-  %75 = and i8 %74, 2
-  %76 = icmp eq i8 %75, 0
-  br i1 %76, label %123, label %77
+72:                                               ; preds = %124, %61
+  %73 = phi i64 [ 0, %61 ], [ %125, %124 ]
+  %74 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %73, i32 1
+  %75 = load atomic i8, i8* %74 unordered, align 1
+  %76 = and i8 %75, 2
+  %77 = icmp eq i8 %76, 0
+  br i1 %77, label %124, label %78
 
-77:                                               ; preds = %71
-  br i1 %46, label %83, label %78
+78:                                               ; preds = %72
+  br i1 %69, label %79, label %84
 
-78:                                               ; preds = %77
-  %79 = call fastcc i64 @mi_option_get(i32 5) #37
-  %.not = icmp eq i64 %79, 0
-  br i1 %.not, label %83, label %80
+79:                                               ; preds = %78
+  %80 = call fastcc i64 @mi_option_get(i32 5) #37
+  %.not = icmp eq i64 %80, 0
+  br i1 %.not, label %84, label %81
 
-80:                                               ; preds = %78
-  %81 = load i8, i8* %73, align 1
-  %82 = and i8 %81, -3
-  store i8 %82, i8* %73, align 1
-  br label %123
+81:                                               ; preds = %79
+  %82 = load atomic i8, i8* %74 unordered, align 1
+  %83 = and i8 %82, -3
+  store i8 %83, i8* %74, align 1
+  br label %124
 
-83:                                               ; preds = %78, %77
-  %84 = load i8, i8* %63, align 8, !tbaa !544, !range !72
-  %85 = icmp eq i8 %84, 0
-  br i1 %85, label %86, label %123
+84:                                               ; preds = %79, %78
+  %85 = load atomic i8, i8* %62 unordered, align 8, !tbaa !548, !range !70
+  %86 = icmp eq i8 %85, 0
+  br i1 %86, label %87, label %124
 
-86:                                               ; preds = %83
-  %87 = load i8, i8* %73, align 1
-  %88 = and i8 %87, 6
-  %89 = icmp eq i8 %88, 6
-  br i1 %89, label %90, label %123
+87:                                               ; preds = %84
+  %88 = load atomic i8, i8* %74 unordered, align 1
+  %89 = and i8 %88, 6
+  %90 = icmp eq i8 %89, 6
+  br i1 %90, label %91, label %124
 
-90:                                               ; preds = %86
-  %91 = and i8 %87, -3
-  store i8 %91, i8* %73, align 1
-  %92 = load i32, i32* %64, align 8, !tbaa !545
-  %93 = icmp eq i32 %92, 3
-  br i1 %93, label %94, label %96
+91:                                               ; preds = %87
+  %92 = and i8 %88, -3
+  store i8 %92, i8* %74, align 1
+  %93 = load atomic i32, i32* %63 unordered, align 8, !tbaa !549
+  %94 = icmp eq i32 %93, 3
+  br i1 %94, label %95, label %97
 
-94:                                               ; preds = %90
-  %95 = load i64, i64* %66, align 8, !tbaa !530
-  br label %99
+95:                                               ; preds = %91
+  %96 = load atomic i64, i64* %65 unordered, align 8, !tbaa !534
+  br label %100
 
-96:                                               ; preds = %90
-  %97 = load i64, i64* %65, align 8, !tbaa !445
-  %98 = shl nuw i64 1, %97
-  br label %99
+97:                                               ; preds = %91
+  %98 = load atomic i64, i64* %64 unordered, align 8, !tbaa !449
+  %99 = shl nuw i64 1, %98
+  br label %100
 
-99:                                               ; preds = %96, %94
-  %100 = phi i64 [ %95, %94 ], [ %98, %96 ]
-  %101 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %72, i32 0
-  %102 = load i8, i8* %101, align 8, !tbaa !546
-  %103 = zext i8 %102 to i64
-  %104 = mul i64 %100, %103
-  %105 = getelementptr inbounds i8, i8* %67, i64 %104
-  %106 = icmp eq i8 %102, 0
-  br i1 %106, label %107, label %111
+100:                                              ; preds = %97, %95
+  %101 = phi i64 [ %96, %95 ], [ %99, %97 ]
+  %102 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 16, i64 %73, i32 0
+  %103 = load atomic i8, i8* %102 unordered, align 8, !tbaa !550
+  %104 = zext i8 %103 to i64
+  %105 = mul i64 %101, %104
+  %106 = getelementptr inbounds i8, i8* %66, i64 %105
+  %107 = icmp eq i8 %103, 0
+  br i1 %107, label %108, label %112
 
-107:                                              ; preds = %99
-  %108 = load i64, i64* %68, align 8, !tbaa !547
-  %109 = getelementptr inbounds i8, i8* %105, i64 %108
-  %110 = sub i64 %100, %108
-  br label %111
+108:                                              ; preds = %100
+  %109 = load atomic i64, i64* %67 unordered, align 8, !tbaa !551
+  %110 = getelementptr inbounds i8, i8* %106, i64 %109
+  %111 = sub i64 %101, %109
+  br label %112
 
-111:                                              ; preds = %107, %99
-  %112 = phi i64 [ %110, %107 ], [ %100, %99 ]
-  %113 = phi i8* [ %109, %107 ], [ %105, %99 ]
+112:                                              ; preds = %108, %100
+  %113 = phi i64 [ %111, %108 ], [ %101, %100 ]
+  %114 = phi i8* [ %110, %108 ], [ %106, %100 ]
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %16) #37
-  store i8 0, i8* %16, align 1, !tbaa !482
-  %114 = icmp eq i64 %112, 0
-  br i1 %114, label %122, label %115
+  store i8 0, i8* %16, align 1, !tbaa !465
+  %115 = icmp eq i64 %113, 0
+  br i1 %115, label %123, label %116
 
-115:                                              ; preds = %111
-  %116 = call fastcc zeroext i1 @_mi_os_unreset(i8* %113, i64 %112, i8* nonnull %16) #37
-  %117 = load i8, i8* %16, align 1, !tbaa !482
-  %118 = icmp eq i8 %117, 0
-  br i1 %118, label %122, label %119
+116:                                              ; preds = %112
+  %117 = call fastcc zeroext i1 @_mi_os_unreset(i8* %114, i64 %113, i8* nonnull %16) #37
+  %118 = load atomic i8, i8* %16 unordered, align 1, !tbaa !465
+  %119 = icmp eq i8 %118, 0
+  br i1 %119, label %123, label %120
 
-119:                                              ; preds = %115
-  %120 = load i8, i8* %73, align 1
-  %121 = or i8 %120, 8
-  store i8 %121, i8* %73, align 1
-  br label %122
+120:                                              ; preds = %116
+  %121 = load atomic i8, i8* %74 unordered, align 1
+  %122 = or i8 %121, 8
+  store i8 %122, i8* %74, align 1
+  br label %123
 
-122:                                              ; preds = %119, %115, %111
+123:                                              ; preds = %120, %116, %112
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %16) #37
-  br label %123
+  br label %124
 
-123:                                              ; preds = %122, %86, %83, %80, %71
-  %124 = add nuw i64 %72, 1
-  %125 = load i64, i64* %59, align 8, !tbaa !536
-  %126 = icmp ult i64 %124, %125
-  br i1 %126, label %71, label %.loopexit24
+124:                                              ; preds = %123, %87, %84, %81, %72
+  %125 = add nuw i64 %73, 1
+  %126 = load atomic i64, i64* %58 unordered, align 8, !tbaa !540
+  %127 = icmp ult i64 %125, %126
+  br i1 %127, label %72, label %.loopexit24
 
-127:                                              ; preds = %.loopexit24
+128:                                              ; preds = %.loopexit24
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %19) #37
-  store i8 0, i8* %19, align 1, !tbaa !482
-  %128 = bitcast %struct.mi_segment_s* %0 to i8*
-  %129 = call fastcc zeroext i1 @mi_os_commitx(i8* nonnull %128, i64 %28, i1 zeroext true, i1 zeroext false, i8* nonnull %19) #37
-  %130 = load i8, i8* %19, align 1, !tbaa !482, !range !72
-  %131 = icmp eq i8 %130, 0
-  br i1 %131, label %133, label %132
+  store i8 0, i8* %19, align 1, !tbaa !465
+  %129 = bitcast %struct.mi_segment_s* %0 to i8*
+  %130 = call fastcc zeroext i1 @mi_os_commitx(i8* nonnull %129, i64 %28, i1 zeroext true, i1 zeroext false, i8* nonnull %19) #37
+  %131 = load atomic i8, i8* %19 unordered, align 1, !tbaa !465, !range !70
+  %132 = icmp eq i8 %131, 0
+  br i1 %132, label %134, label %133
 
-132:                                              ; preds = %127
-  store i8 1, i8* %18, align 1, !tbaa !482
-  br label %133
+133:                                              ; preds = %128
+  store i8 1, i8* %18, align 1, !tbaa !465
+  br label %134
 
-133:                                              ; preds = %132, %127
+134:                                              ; preds = %133, %128
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %19) #37
-  br i1 %129, label %557, label %619
+  br i1 %130, label %552, label %614
 
-134:                                              ; preds = %43
+135:                                              ; preds = %43
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %20) #37
-  store i8 %45, i8* %20, align 1, !tbaa !482
+  store i8 %44, i8* %20, align 1, !tbaa !465
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %21) #37
-  store i8 0, i8* %18, align 1, !tbaa !482
-  store i8 0, i8* %21, align 1, !tbaa !482
-  %135 = icmp eq i64 %33, 0
-  br i1 %135, label %_mi_mem_alloc_aligned.exit.thread, label %136
-
-136:                                              ; preds = %134
-  %137 = load i64, i64* @os_page_size, align 8, !tbaa !453
-  %138 = tail call i64 @llvm.ctpop.i64(i64 %137) #37, !range !481
-  %139 = icmp ult i64 %138, 2
-  %140 = add i64 %33, -1
-  %141 = add i64 %140, %137
-  br i1 %139, label %142, label %145
+  store i8 0, i8* %18, align 1, !tbaa !465
+  store i8 0, i8* %21, align 1, !tbaa !465
+  %136 = icmp eq i64 %33, 0
+  br i1 %136, label %_mi_mem_alloc_aligned.exit.thread, label %137
 
-142:                                              ; preds = %136
-  %143 = sub i64 0, %137
-  %144 = and i64 %141, %143
-  br label %148
+137:                                              ; preds = %135
+  %138 = load atomic i64, i64* @os_page_size unordered, align 8, !tbaa !457
+  %139 = tail call i64 @llvm.ctpop.i64(i64 %138) #37, !range !486
+  %140 = icmp ult i64 %139, 2
+  %141 = add i64 %33, -1
+  %142 = add i64 %141, %138
+  br i1 %140, label %143, label %146
 
-145:                                              ; preds = %136
-  %146 = urem i64 %141, %137
-  %147 = sub i64 %141, %146
-  br label %148
+143:                                              ; preds = %137
+  %144 = sub i64 0, %138
+  %145 = and i64 %142, %144
+  br label %149
 
-148:                                              ; preds = %145, %142
-  %149 = phi i64 [ %144, %142 ], [ %147, %145 ]
-  %150 = bitcast i64* %15 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %150) #37
-  %151 = add i64 %149, 4194303
-  %152 = lshr i64 %151, 22
-  %153 = icmp ult i64 %151, 71303168
-  br i1 %153, label %154, label %452
+146:                                              ; preds = %137
+  %147 = urem i64 %142, %138
+  %148 = sub i64 %142, %147
+  br label %149
 
-154:                                              ; preds = %148
-  %155 = bitcast i64* %12 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %155) #37
-  %156 = load atomic i64, i64* @_mi_numa_node_count monotonic, align 8
-  %157 = icmp eq i64 %156, 0
-  br i1 %157, label %158, label %160, !prof !284, !misexpect !437
+149:                                              ; preds = %146, %143
+  %150 = phi i64 [ %145, %143 ], [ %148, %146 ]
+  %151 = bitcast i64* %15 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %151) #37
+  %152 = add i64 %150, 4194303
+  %153 = lshr i64 %152, 22
+  %154 = icmp ult i64 %152, 71303168
+  br i1 %154, label %155, label %447
 
-158:                                              ; preds = %154
-  %159 = tail call i64 @_mi_os_numa_node_count_get() #37
-  br label %160
+155:                                              ; preds = %149
+  %156 = bitcast i64* %12 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %156) #37
+  %157 = load atomic i64, i64* @_mi_numa_node_count monotonic, align 8
+  %158 = icmp eq i64 %157, 0
+  br i1 %158, label %159, label %161, !prof !282, !misexpect !441
 
-160:                                              ; preds = %158, %154
-  %161 = phi i64 [ %159, %158 ], [ %156, %154 ]
-  %162 = icmp ult i64 %161, 2
-  br i1 %162, label %.thread, label %163
+159:                                              ; preds = %155
+  %160 = tail call i64 @_mi_os_numa_node_count_get() #37
+  br label %161
 
-163:                                              ; preds = %160
-  %164 = load atomic i64, i64* @_mi_numa_node_count monotonic, align 8
-  %165 = icmp eq i64 %164, 1
-  br i1 %165, label %168, label %166, !prof !436, !misexpect !437
+161:                                              ; preds = %159, %155
+  %162 = phi i64 [ %160, %159 ], [ %157, %155 ]
+  %163 = icmp ult i64 %162, 2
+  br i1 %163, label %169, label %164
 
-166:                                              ; preds = %163
-  %167 = tail call fastcc i32 @_mi_os_numa_node_get() #37
-  br label %168
+164:                                              ; preds = %161
+  %165 = load atomic i64, i64* @_mi_numa_node_count monotonic, align 8
+  %166 = icmp eq i64 %165, 1
+  br i1 %166, label %169, label %167, !prof !440, !misexpect !441
 
-168:                                              ; preds = %166, %163
-  %169 = phi i32 [ %167, %166 ], [ 0, %163 ]
-  %170 = load atomic i64, i64* @regions_count monotonic, align 8
-  %171 = getelementptr inbounds %struct.mi_os_tld_s, %struct.mi_os_tld_s* %5, i64 0, i32 0
-  %172 = load i64, i64* %171, align 8, !tbaa !581
-  %173 = icmp eq i64 %170, 0
-  br i1 %173, label %.loopexit17, label %178
+167:                                              ; preds = %164
+  %168 = tail call fastcc i32 @_mi_os_numa_node_get() #37
+  br label %169
 
-.thread:                                          ; preds = %160
-  %174 = load atomic i64, i64* @regions_count monotonic, align 8
-  %175 = getelementptr inbounds %struct.mi_os_tld_s, %struct.mi_os_tld_s* %5, i64 0, i32 0
-  %176 = load i64, i64* %175, align 8, !tbaa !581
-  %177 = icmp eq i64 %174, 0
-  br i1 %177, label %.loopexit17, label %.thread49
+169:                                              ; preds = %167, %164, %161
+  %170 = phi i32 [ -1, %161 ], [ %168, %167 ], [ 0, %164 ]
+  %171 = load atomic i8, i8* %20 unordered, align 1, !tbaa !465, !range !70
+  %172 = icmp ne i8 %171, 0
+  %173 = load atomic i64, i64* @regions_count monotonic, align 8
+  %174 = getelementptr inbounds %struct.mi_os_tld_s, %struct.mi_os_tld_s* %5, i64 0, i32 0
+  %175 = load atomic i64, i64* %174 unordered, align 8, !tbaa !585
+  %176 = icmp eq i64 %173, 0
+  br i1 %176, label %.loopexit17, label %177
 
-178:                                              ; preds = %168
-  %179 = phi i64 [ %172, %168 ]
-  %180 = phi i64* [ %171, %168 ]
-  %181 = phi i64 [ %170, %168 ]
-  %182 = phi i32 [ %169, %168 ]
-  %183 = icmp sgt i32 %182, -1
-  br i1 %183, label %.preheader, label %.thread49
+177:                                              ; preds = %169
+  %178 = icmp sgt i32 %170, -1
+  br i1 %178, label %.preheader, label %204
 
-.preheader:                                       ; preds = %205, %178
-  %184 = phi i64 [ %206, %205 ], [ 0, %178 ]
-  %185 = phi i64 [ %207, %205 ], [ %179, %178 ]
-  %186 = icmp ult i64 %185, %181
-  %187 = select i1 %186, i64 %185, i64 0
-  %188 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %187
-  %189 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %188, i64 0, i32 0
-  %190 = load atomic i64, i64* %189 monotonic, align 16
-  %191 = icmp eq i64 %190, 0
-  br i1 %191, label %205, label %192
+.preheader:                                       ; preds = %200, %177
+  %179 = phi i64 [ %201, %200 ], [ 0, %177 ]
+  %180 = phi i64 [ %202, %200 ], [ %175, %177 ]
+  %181 = icmp ult i64 %180, %173
+  %182 = select i1 %181, i64 %180, i64 0
+  %183 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %182
+  %184 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %183, i64 0, i32 0
+  %185 = load atomic i64, i64* %184 monotonic, align 16
+  %186 = icmp eq i64 %185, 0
+  br i1 %186, label %200, label %187
 
-192:                                              ; preds = %.preheader
-  %193 = and i64 %190, 256
-  %194 = icmp eq i64 %193, 0
-  %195 = trunc i64 %190 to i32
-  %196 = icmp slt i32 %195, 0
-  %197 = ashr i32 %195, 16
-  %198 = icmp eq i32 %197, %182
-  %199 = or i1 %196, %198
-  %200 = or i1 %44, %194
-  %201 = and i1 %200, %199
-  br i1 %201, label %202, label %205
+187:                                              ; preds = %.preheader
+  %188 = and i64 %185, 256
+  %189 = icmp eq i64 %188, 0
+  %190 = trunc i64 %185 to i32
+  %191 = icmp slt i32 %190, 0
+  %192 = ashr i32 %190, 16
+  %193 = icmp eq i32 %192, %170
+  %194 = or i1 %191, %193
+  %195 = or i1 %172, %189
+  %196 = and i1 %195, %194
+  br i1 %196, label %197, label %200
 
-202:                                              ; preds = %192
-  %203 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %187, i32 2
-  %204 = call fastcc zeroext i1 @_mi_bitmap_try_find_claim_field(i64* nonnull %203, i64 %152, i64* nonnull %12) #37
-  br i1 %204, label %.loopexit16, label %205
+197:                                              ; preds = %187
+  %198 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %182, i32 2
+  %199 = call fastcc zeroext i1 @_mi_bitmap_try_find_claim_field(i64* nonnull %198, i64 %153, i64* nonnull %12) #37
+  br i1 %199, label %.loopexit16, label %200
 
-205:                                              ; preds = %202, %192, %.preheader
-  %206 = add nuw i64 %184, 1
-  %207 = add i64 %187, 1
-  %208 = icmp eq i64 %206, %181
-  br i1 %208, label %.loopexit17, label %.preheader
+200:                                              ; preds = %197, %187, %.preheader
+  %201 = add nuw i64 %179, 1
+  %202 = add i64 %182, 1
+  %203 = icmp eq i64 %201, %173
+  br i1 %203, label %.loopexit17, label %.preheader
 
-.thread49:                                        ; preds = %178, %.thread
-  %209 = phi i64 [ %181, %178 ], [ %174, %.thread ]
-  %210 = phi i64* [ %180, %178 ], [ %175, %.thread ]
-  %211 = phi i64 [ %179, %178 ], [ %176, %.thread ]
-  br i1 %44, label %.preheader18, label %.preheader21
+204:                                              ; preds = %177
+  br i1 %172, label %.preheader18, label %.preheader21
 
-.preheader18:                                     ; preds = %223, %.thread49
-  %212 = phi i64 [ %224, %223 ], [ 0, %.thread49 ]
-  %213 = phi i64 [ %225, %223 ], [ %211, %.thread49 ]
-  %214 = icmp ult i64 %213, %209
-  %215 = select i1 %214, i64 %213, i64 0
-  %216 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %215
-  %217 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %216, i64 0, i32 0
-  %218 = load atomic i64, i64* %217 monotonic, align 16
-  %219 = icmp eq i64 %218, 0
-  br i1 %219, label %223, label %220
+.preheader18:                                     ; preds = %216, %204
+  %205 = phi i64 [ %217, %216 ], [ 0, %204 ]
+  %206 = phi i64 [ %218, %216 ], [ %175, %204 ]
+  %207 = icmp ult i64 %206, %173
+  %208 = select i1 %207, i64 %206, i64 0
+  %209 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %208
+  %210 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %209, i64 0, i32 0
+  %211 = load atomic i64, i64* %210 monotonic, align 16
+  %212 = icmp eq i64 %211, 0
+  br i1 %212, label %216, label %213
 
-220:                                              ; preds = %.preheader18
-  %221 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %215, i32 2
-  %222 = call fastcc zeroext i1 @_mi_bitmap_try_find_claim_field(i64* nonnull %221, i64 %152, i64* nonnull %12) #37
-  br i1 %222, label %.loopexit16, label %223
+213:                                              ; preds = %.preheader18
+  %214 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %208, i32 2
+  %215 = call fastcc zeroext i1 @_mi_bitmap_try_find_claim_field(i64* nonnull %214, i64 %153, i64* nonnull %12) #37
+  br i1 %215, label %.loopexit16, label %216
 
-223:                                              ; preds = %220, %.preheader18
-  %224 = add nuw i64 %212, 1
-  %225 = add i64 %215, 1
-  %226 = icmp eq i64 %224, %209
-  br i1 %226, label %.loopexit17, label %.preheader18
+216:                                              ; preds = %213, %.preheader18
+  %217 = add nuw i64 %205, 1
+  %218 = add i64 %208, 1
+  %219 = icmp eq i64 %217, %173
+  br i1 %219, label %.loopexit17, label %.preheader18
 
-.preheader21:                                     ; preds = %241, %.thread49
-  %227 = phi i64 [ %242, %241 ], [ 0, %.thread49 ]
-  %228 = phi i64 [ %243, %241 ], [ %211, %.thread49 ]
-  %229 = icmp ult i64 %228, %209
-  %230 = select i1 %229, i64 %228, i64 0
-  %231 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %230
-  %232 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %231, i64 0, i32 0
-  %233 = load atomic i64, i64* %232 monotonic, align 16
-  %234 = and i64 %233, 256
-  %235 = icmp ne i64 %234, 0
-  %236 = icmp eq i64 %233, 0
-  %237 = or i1 %236, %235
-  br i1 %237, label %241, label %238
+.preheader21:                                     ; preds = %234, %204
+  %220 = phi i64 [ %235, %234 ], [ 0, %204 ]
+  %221 = phi i64 [ %236, %234 ], [ %175, %204 ]
+  %222 = icmp ult i64 %221, %173
+  %223 = select i1 %222, i64 %221, i64 0
+  %224 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %223
+  %225 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %224, i64 0, i32 0
+  %226 = load atomic i64, i64* %225 monotonic, align 16
+  %227 = and i64 %226, 256
+  %228 = icmp ne i64 %227, 0
+  %229 = icmp eq i64 %226, 0
+  %230 = or i1 %229, %228
+  br i1 %230, label %234, label %231
 
-238:                                              ; preds = %.preheader21
-  %239 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %230, i32 2
-  %240 = call fastcc zeroext i1 @_mi_bitmap_try_find_claim_field(i64* nonnull %239, i64 %152, i64* nonnull %12) #37
-  br i1 %240, label %.loopexit16, label %241
+231:                                              ; preds = %.preheader21
+  %232 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %223, i32 2
+  %233 = call fastcc zeroext i1 @_mi_bitmap_try_find_claim_field(i64* nonnull %232, i64 %153, i64* nonnull %12) #37
+  br i1 %233, label %.loopexit16, label %234
 
-241:                                              ; preds = %238, %.preheader21
-  %242 = add nuw i64 %227, 1
-  %243 = add i64 %230, 1
-  %244 = icmp eq i64 %242, %209
-  br i1 %244, label %.loopexit17, label %.preheader21
+234:                                              ; preds = %231, %.preheader21
+  %235 = add nuw i64 %220, 1
+  %236 = add i64 %223, 1
+  %237 = icmp eq i64 %235, %173
+  br i1 %237, label %.loopexit17, label %.preheader21
 
-.loopexit16:                                      ; preds = %238, %220, %202
-  %245 = phi i64* [ %180, %202 ], [ %210, %220 ], [ %210, %238 ]
-  %246 = phi i64 [ %187, %202 ], [ %215, %220 ], [ %230, %238 ]
-  %247 = phi %struct.mem_region_s* [ %188, %202 ], [ %216, %220 ], [ %231, %238 ]
-  store i64 %246, i64* %245, align 8, !tbaa !581
-  br label %318
+.loopexit16:                                      ; preds = %231, %213, %197
+  %238 = phi i64 [ %182, %197 ], [ %208, %213 ], [ %223, %231 ]
+  %239 = phi %struct.mem_region_s* [ %183, %197 ], [ %209, %213 ], [ %224, %231 ]
+  store i64 %238, i64* %174, align 8, !tbaa !585
+  br label %312
 
-.loopexit17:                                      ; preds = %241, %223, %205, %.thread, %168
-  %248 = load i8, i8* %20, align 1, !tbaa !482, !range !72
-  %249 = icmp ne i8 %248, 0
-  %250 = load atomic i64, i64* @regions_count monotonic, align 8
-  %251 = icmp ugt i64 %250, 1022
-  br i1 %251, label %448, label %252
+.loopexit17:                                      ; preds = %234, %216, %200, %169
+  %240 = load atomic i8, i8* %17 unordered, align 1, !tbaa !465, !range !70
+  %241 = icmp ne i8 %240, 0
+  %242 = load atomic i8, i8* %20 unordered, align 1, !tbaa !465, !range !70
+  %243 = icmp ne i8 %242, 0
+  %244 = load atomic i64, i64* @regions_count monotonic, align 8
+  %245 = icmp ugt i64 %244, 1022
+  br i1 %245, label %443, label %246
 
-252:                                              ; preds = %.loopexit17
+246:                                              ; preds = %.loopexit17
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %7) #37
-  br i1 %46, label %253, label %257
+  br i1 %241, label %247, label %251
 
-253:                                              ; preds = %252
-  %254 = tail call fastcc i64 @mi_option_get(i32 4) #37
-  %255 = icmp ne i64 %254, 0
-  %256 = zext i1 %255 to i8
-  br label %257
+247:                                              ; preds = %246
+  %248 = tail call fastcc i64 @mi_option_get(i32 4) #37
+  %249 = icmp ne i64 %248, 0
+  %250 = zext i1 %249 to i8
+  br label %251
 
-257:                                              ; preds = %253, %252
-  %258 = phi i8 [ 0, %252 ], [ %256, %253 ]
-  store i8 %258, i8* %7, align 1, !tbaa !482
+251:                                              ; preds = %247, %246
+  %252 = phi i8 [ 0, %246 ], [ %250, %247 ]
+  store i8 %252, i8* %7, align 1, !tbaa !465
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %8) #37
-  %259 = and i1 %46, %249
-  %260 = zext i1 %259 to i8
-  store i8 %260, i8* %8, align 1, !tbaa !482
+  %253 = and i1 %241, %243
+  %254 = zext i1 %253 to i8
+  store i8 %254, i8* %8, align 1, !tbaa !465
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %9) #37
-  store i8 0, i8* %9, align 1, !tbaa !482
+  store i8 0, i8* %9, align 1, !tbaa !465
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %10) #37
-  store i8 0, i8* %10, align 1, !tbaa !482
-  %261 = bitcast i64* %11 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %261) #37
-  store i64 0, i64* %11, align 8, !tbaa !453
-  %262 = call fastcc i8* @_mi_arena_alloc_aligned(i64 268435456, i8* nonnull %7, i8* nonnull %8, i8* nonnull %10, i8* nonnull %9, i64* nonnull %11) #37
-  %263 = icmp eq i8* %262, null
-  br i1 %263, label %315, label %264
+  store i8 0, i8* %10, align 1, !tbaa !465
+  %255 = bitcast i64* %11 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %255) #37
+  store i64 0, i64* %11, align 8, !tbaa !457
+  %256 = call fastcc i8* @_mi_arena_alloc_aligned(i64 268435456, i8* nonnull %7, i8* nonnull %8, i8* nonnull %10, i8* nonnull %9, i64* nonnull %11) #37
+  %257 = icmp eq i8* %256, null
+  br i1 %257, label %309, label %258
 
-264:                                              ; preds = %257
-  %265 = atomicrmw add i64* @regions_count, i64 1 acq_rel, align 8
-  %266 = icmp ugt i64 %265, 1023
-  br i1 %266, label %267, label %272
+258:                                              ; preds = %251
+  %259 = atomicrmw add i64* @regions_count, i64 1 acq_rel, align 8
+  %260 = icmp ugt i64 %259, 1023
+  br i1 %260, label %261, label %266
 
-267:                                              ; preds = %264
-  %268 = atomicrmw sub i64* @regions_count, i64 1 acq_rel, align 8
-  %269 = load i64, i64* %11, align 8, !tbaa !453
-  %270 = load i8, i8* %7, align 1, !tbaa !482, !range !72
-  %271 = icmp ne i8 %270, 0
-  call fastcc void @_mi_arena_free(i8* nonnull %262, i64 268435456, i64 %269, i1 zeroext %271) #37
+261:                                              ; preds = %258
+  %262 = atomicrmw sub i64* @regions_count, i64 1 acq_rel, align 8
+  %263 = load atomic i64, i64* %11 unordered, align 8, !tbaa !457
+  %264 = load atomic i8, i8* %7 unordered, align 1, !tbaa !465, !range !70
+  %265 = icmp ne i8 %264, 0
+  call fastcc void @_mi_arena_free(i8* nonnull %256, i64 268435456, i64 %263, i1 zeroext %265) #37
   call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([100 x i8], [100 x i8]* @.str.1.86, i64 0, i64 0), i64 256) #37
-  br label %315
+  br label %309
 
-272:                                              ; preds = %264
-  %273 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %265
-  %274 = load i64, i64* %11, align 8, !tbaa !453
-  %275 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %265, i32 6
-  store atomic i64 %274, i64* %275 seq_cst, align 16, !tbaa !582
-  %276 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %265, i32 2
-  store atomic i64 0, i64* %276 release, align 16
-  %277 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %265, i32 3
-  %278 = load i8, i8* %9, align 1, !tbaa !482, !range !72
-  %279 = add nsw i8 %278, -1
-  %280 = sext i8 %279 to i64
-  store atomic i64 %280, i64* %277 release, align 8
-  %281 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %265, i32 4
-  %282 = load i8, i8* %7, align 1, !tbaa !482, !range !72
-  %283 = shl nuw i8 %282, 7
-  %284 = ashr exact i8 %283, 7
-  %285 = sext i8 %284 to i64
-  store atomic i64 %285, i64* %281 release, align 16
-  %286 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %265, i32 5
-  store atomic i64 0, i64* %286 release, align 8
-  store i64 0, i64* %12, align 8, !tbaa !453
-  %287 = icmp ugt i64 %151, 268435455
-  br i1 %287, label %_mi_bitmap_claim.exit.i, label %288
+266:                                              ; preds = %258
+  %267 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %259
+  %268 = load atomic i64, i64* %11 unordered, align 8, !tbaa !457
+  %269 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %259, i32 6
+  store atomic i64 %268, i64* %269 seq_cst, align 16, !tbaa !586
+  %270 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %259, i32 2
+  store atomic i64 0, i64* %270 release, align 16
+  %271 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %259, i32 3
+  %272 = load atomic i8, i8* %9 unordered, align 1, !tbaa !465, !range !70
+  %273 = add nsw i8 %272, -1
+  %274 = sext i8 %273 to i64
+  store atomic i64 %274, i64* %271 release, align 8
+  %275 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %259, i32 4
+  %276 = load atomic i8, i8* %7 unordered, align 1, !tbaa !465, !range !70
+  %277 = shl nuw i8 %276, 7
+  %278 = ashr exact i8 %277, 7
+  %279 = sext i8 %278 to i64
+  store atomic i64 %279, i64* %275 release, align 16
+  %280 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %259, i32 5
+  store atomic i64 0, i64* %280 release, align 8
+  store i64 0, i64* %12, align 8, !tbaa !457
+  %281 = icmp ugt i64 %152, 268435455
+  br i1 %281, label %_mi_bitmap_claim.exit.i, label %282
 
-288:                                              ; preds = %272
-  %289 = icmp eq i64 %152, 0
-  br i1 %289, label %_mi_bitmap_claim.exit.i, label %290
+282:                                              ; preds = %266
+  %283 = icmp eq i64 %153, 0
+  br i1 %283, label %_mi_bitmap_claim.exit.i, label %284
 
-290:                                              ; preds = %288
-  %291 = shl nsw i64 -1, %152
-  %292 = xor i64 %291, -1
+284:                                              ; preds = %282
+  %285 = shl nsw i64 -1, %153
+  %286 = xor i64 %285, -1
   br label %_mi_bitmap_claim.exit.i
 
-_mi_bitmap_claim.exit.i:                          ; preds = %290, %288, %272
-  %293 = phi i64 [ %292, %290 ], [ -1, %272 ], [ 0, %288 ]
-  %294 = atomicrmw or i64* %276, i64 %293 acq_rel, align 8
-  %295 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %265, i32 1
-  %296 = ptrtoint i8* %262 to i64
-  %297 = bitcast i8** %295 to i64*
-  store atomic i64 %296, i64* %297 release, align 8
-  %298 = load i8, i8* %8, align 1, !tbaa !482, !range !72
-  %299 = load i8, i8* %10, align 1, !tbaa !482, !range !72
-  %300 = shl nuw nsw i8 %299, 1
-  %301 = or i8 %300, %298
-  %302 = load atomic i64, i64* @_mi_numa_node_count monotonic, align 8
-  %303 = icmp eq i64 %302, 1
-  br i1 %303, label %308, label %304, !prof !436, !misexpect !437
+_mi_bitmap_claim.exit.i:                          ; preds = %284, %282, %266
+  %287 = phi i64 [ %286, %284 ], [ -1, %266 ], [ 0, %282 ]
+  %288 = atomicrmw or i64* %270, i64 %287 acq_rel, align 8
+  %289 = getelementptr inbounds [1024 x %struct.mem_region_s], [1024 x %struct.mem_region_s]* @regions, i64 0, i64 %259, i32 1
+  %290 = ptrtoint i8* %256 to i64
+  %291 = bitcast i8** %289 to i64*
+  store atomic i64 %290, i64* %291 release, align 8
+  %292 = load atomic i8, i8* %8 unordered, align 1, !tbaa !465, !range !70
+  %293 = load atomic i8, i8* %10 unordered, align 1, !tbaa !465, !range !70
+  %294 = shl nuw nsw i8 %293, 1
+  %295 = or i8 %294, %292
+  %296 = load atomic i64, i64* @_mi_numa_node_count monotonic, align 8
+  %297 = icmp eq i64 %296, 1
+  br i1 %297, label %302, label %298, !prof !440, !misexpect !441
 
-304:                                              ; preds = %_mi_bitmap_claim.exit.i
-  %305 = call fastcc i32 @_mi_os_numa_node_get() #37
-  %306 = shl i32 %305, 16
-  %307 = zext i32 %306 to i64
-  br label %308
+298:                                              ; preds = %_mi_bitmap_claim.exit.i
+  %299 = call fastcc i32 @_mi_os_numa_node_get() #37
+  %300 = shl i32 %299, 16
+  %301 = zext i32 %300 to i64
+  br label %302
 
-308:                                              ; preds = %304, %_mi_bitmap_claim.exit.i
-  %309 = phi i64 [ %307, %304 ], [ 0, %_mi_bitmap_claim.exit.i ]
-  %310 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %273, i64 0, i32 0
-  %311 = zext i8 %301 to i64
-  %312 = shl nuw nsw i64 %311, 8
-  %313 = or i64 %312, %309
-  %314 = or i64 %313, 1
-  store atomic i64 %314, i64* %310 release, align 16
-  br label %315
+302:                                              ; preds = %298, %_mi_bitmap_claim.exit.i
+  %303 = phi i64 [ %301, %298 ], [ 0, %_mi_bitmap_claim.exit.i ]
+  %304 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %267, i64 0, i32 0
+  %305 = zext i8 %295 to i64
+  %306 = shl nuw nsw i64 %305, 8
+  %307 = or i64 %306, %303
+  %308 = or i64 %307, 1
+  store atomic i64 %308, i64* %304 release, align 16
+  br label %309
 
-315:                                              ; preds = %308, %267, %257
-  %316 = phi %struct.mem_region_s* [ undef, %257 ], [ undef, %267 ], [ %273, %308 ]
-  %317 = phi i1 [ false, %257 ], [ false, %267 ], [ true, %308 ]
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %261) #37
+309:                                              ; preds = %302, %261, %251
+  %310 = phi %struct.mem_region_s* [ undef, %251 ], [ undef, %261 ], [ %267, %302 ]
+  %311 = phi i1 [ false, %251 ], [ false, %261 ], [ true, %302 ]
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %255) #37
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %10) #37
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %9) #37
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %8) #37
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %7) #37
-  br i1 %317, label %318, label %448
+  br i1 %311, label %312, label %443
 
-318:                                              ; preds = %315, %.loopexit16
-  %319 = phi %struct.mem_region_s* [ %247, %.loopexit16 ], [ %316, %315 ]
-  %320 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %319, i64 0, i32 0
-  %321 = load atomic i64, i64* %320 acquire, align 8
-  %322 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %319, i64 0, i32 1
-  %323 = bitcast i8** %322 to i64*
-  %324 = load atomic i64, i64* %323 acquire, align 8
-  %325 = inttoptr i64 %324 to i8*
-  %326 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %319, i64 0, i32 3
-  %327 = load i64, i64* %12, align 8, !tbaa !453
-  %328 = lshr i64 %327, 6
-  %329 = and i64 %327, 63
-  %330 = icmp ugt i64 %151, 268435455
-  br i1 %330, label %_mi_bitmap_claim.exit1.i, label %331
+312:                                              ; preds = %309, %.loopexit16
+  %313 = phi %struct.mem_region_s* [ %239, %.loopexit16 ], [ %310, %309 ]
+  %314 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %313, i64 0, i32 0
+  %315 = load atomic i64, i64* %314 acquire, align 8
+  %316 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %313, i64 0, i32 1
+  %317 = bitcast i8** %316 to i64*
+  %318 = load atomic i64, i64* %317 acquire, align 8
+  %319 = inttoptr i64 %318 to i8*
+  %320 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %313, i64 0, i32 3
+  %321 = load atomic i64, i64* %12 unordered, align 8, !tbaa !457
+  %322 = lshr i64 %321, 6
+  %323 = and i64 %321, 63
+  %324 = icmp ugt i64 %152, 268435455
+  br i1 %324, label %_mi_bitmap_claim.exit1.i, label %325
 
-331:                                              ; preds = %318
-  %332 = icmp eq i64 %152, 0
-  br i1 %332, label %_mi_bitmap_claim.exit1.i, label %333
+325:                                              ; preds = %312
+  %326 = icmp eq i64 %153, 0
+  br i1 %326, label %_mi_bitmap_claim.exit1.i, label %327
 
-333:                                              ; preds = %331
-  %334 = shl nsw i64 -1, %152
-  %335 = xor i64 %334, -1
-  %336 = shl i64 %335, %329
+327:                                              ; preds = %325
+  %328 = shl nsw i64 -1, %153
+  %329 = xor i64 %328, -1
+  %330 = shl i64 %329, %323
   br label %_mi_bitmap_claim.exit1.i
 
-_mi_bitmap_claim.exit1.i:                         ; preds = %333, %331, %318
-  %337 = phi i64 [ %336, %333 ], [ -1, %318 ], [ 0, %331 ]
-  %338 = getelementptr inbounds i64, i64* %326, i64 %328
-  %339 = atomicrmw or i64* %338, i64 %337 acq_rel, align 8
-  %340 = and i64 %339, %337
-  %341 = icmp eq i64 %340, 0
-  %342 = zext i1 %341 to i8
-  store i8 %342, i8* %18, align 1, !tbaa !482
-  %343 = lshr i64 %321, 8
-  %344 = trunc i64 %343 to i8
-  %345 = and i8 %344, 1
-  store i8 %345, i8* %20, align 1, !tbaa !482
-  %346 = lshr i64 %321, 9
-  %347 = trunc i64 %346 to i8
-  %348 = and i8 %347, 1
-  store i8 %348, i8* %21, align 1, !tbaa !482
-  %349 = load i64, i64* %12, align 8, !tbaa !453
-  %350 = ptrtoint %struct.mem_region_s* %319 to i64
-  %351 = sub i64 %350, ptrtoint ([1024 x %struct.mem_region_s]* @regions to i64)
-  %352 = add i64 %351, %349
-  %353 = shl i64 %352, 1
-  %354 = shl i64 %349, 22
-  %355 = and i64 %354, 264241152
-  %356 = getelementptr inbounds i8, i8* %325, i64 %355
-  %357 = load i8, i8* %17, align 1, !tbaa !482, !range !72
-  %358 = icmp eq i8 %357, 0
-  %359 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %319, i64 0, i32 4
-  br i1 %358, label %395, label %360
+_mi_bitmap_claim.exit1.i:                         ; preds = %327, %325, %312
+  %331 = phi i64 [ %330, %327 ], [ -1, %312 ], [ 0, %325 ]
+  %332 = getelementptr inbounds i64, i64* %320, i64 %322
+  %333 = atomicrmw or i64* %332, i64 %331 acq_rel, align 8
+  %334 = and i64 %333, %331
+  %335 = icmp eq i64 %334, 0
+  %336 = zext i1 %335 to i8
+  store i8 %336, i8* %18, align 1, !tbaa !465
+  %337 = lshr i64 %315, 8
+  %338 = trunc i64 %337 to i8
+  %339 = and i8 %338, 1
+  store i8 %339, i8* %20, align 1, !tbaa !465
+  %340 = lshr i64 %315, 9
+  %341 = trunc i64 %340 to i8
+  %342 = and i8 %341, 1
+  store i8 %342, i8* %21, align 1, !tbaa !465
+  %343 = load atomic i64, i64* %12 unordered, align 8, !tbaa !457
+  %344 = ptrtoint %struct.mem_region_s* %313 to i64
+  %345 = sub i64 %344, ptrtoint ([1024 x %struct.mem_region_s]* @regions to i64)
+  %346 = add i64 %345, %343
+  %347 = shl i64 %346, 1
+  %348 = shl i64 %343, 22
+  %349 = and i64 %348, 264241152
+  %350 = getelementptr inbounds i8, i8* %319, i64 %349
+  %351 = load atomic i8, i8* %17 unordered, align 1, !tbaa !465, !range !70
+  %352 = icmp eq i8 %351, 0
+  %353 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %313, i64 0, i32 4
+  br i1 %352, label %389, label %354
 
-360:                                              ; preds = %_mi_bitmap_claim.exit1.i
-  %361 = lshr i64 %349, 6
-  %362 = and i64 %349, 63
-  br i1 %330, label %_mi_bitmap_claim.exit2.i, label %363
+354:                                              ; preds = %_mi_bitmap_claim.exit1.i
+  %355 = lshr i64 %343, 6
+  %356 = and i64 %343, 63
+  br i1 %324, label %_mi_bitmap_claim.exit2.i, label %357
 
-363:                                              ; preds = %360
-  %364 = icmp eq i64 %152, 0
-  br i1 %364, label %_mi_bitmap_claim.exit2.i, label %365
+357:                                              ; preds = %354
+  %358 = icmp eq i64 %153, 0
+  br i1 %358, label %_mi_bitmap_claim.exit2.i, label %359
 
-365:                                              ; preds = %363
-  %366 = shl nsw i64 -1, %152
-  %367 = xor i64 %366, -1
-  %368 = shl i64 %367, %362
+359:                                              ; preds = %357
+  %360 = shl nsw i64 -1, %153
+  %361 = xor i64 %360, -1
+  %362 = shl i64 %361, %356
   br label %_mi_bitmap_claim.exit2.i
 
-_mi_bitmap_claim.exit2.i:                         ; preds = %365, %363, %360
-  %369 = phi i64 [ %368, %365 ], [ -1, %360 ], [ 0, %363 ]
-  %370 = getelementptr inbounds i64, i64* %359, i64 %361
-  %371 = atomicrmw or i64* %370, i64 %369 acq_rel, align 8
-  %372 = and i64 %371, %369
-  %.not10 = icmp eq i64 %372, %369
-  br i1 %.not10, label %410, label %373
+_mi_bitmap_claim.exit2.i:                         ; preds = %359, %357, %354
+  %363 = phi i64 [ %362, %359 ], [ -1, %354 ], [ 0, %357 ]
+  %364 = getelementptr inbounds i64, i64* %353, i64 %355
+  %365 = atomicrmw or i64* %364, i64 %363 acq_rel, align 8
+  %366 = and i64 %365, %363
+  %.not49 = icmp eq i64 %366, %363
+  br i1 %.not49, label %404, label %367
 
-373:                                              ; preds = %_mi_bitmap_claim.exit2.i
+367:                                              ; preds = %_mi_bitmap_claim.exit2.i
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %13) #37
-  store i8 0, i8* %13, align 1, !tbaa !482
-  %374 = and i64 %151, -4194304
-  %375 = call fastcc zeroext i1 @mi_os_commitx(i8* %356, i64 %374, i1 zeroext true, i1 zeroext false, i8* nonnull %13) #37
-  br i1 %375, label %390, label %376
+  store i8 0, i8* %13, align 1, !tbaa !465
+  %368 = and i64 %152, -4194304
+  %369 = call fastcc zeroext i1 @mi_os_commitx(i8* %350, i64 %368, i1 zeroext true, i1 zeroext false, i8* nonnull %13) #37
+  br i1 %369, label %384, label %370
 
-376:                                              ; preds = %373
-  %377 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %319, i64 0, i32 2
-  %378 = load i64, i64* %12, align 8, !tbaa !453
-  %379 = and i64 %378, 63
-  br i1 %330, label %mi_bitmap_unclaim.exit.i, label %380
+370:                                              ; preds = %367
+  %371 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %313, i64 0, i32 2
+  %372 = load atomic i64, i64* %12 unordered, align 8, !tbaa !457
+  %373 = and i64 %372, 63
+  br i1 %324, label %mi_bitmap_unclaim.exit.i, label %374
 
-380:                                              ; preds = %376
-  %381 = icmp eq i64 %152, 0
-  br i1 %381, label %mi_bitmap_unclaim.exit.i, label %382
+374:                                              ; preds = %370
+  %375 = icmp eq i64 %153, 0
+  br i1 %375, label %mi_bitmap_unclaim.exit.i, label %376
 
-382:                                              ; preds = %380
-  %383 = shl nsw i64 -1, %152
-  %384 = xor i64 %383, -1
-  %385 = shl i64 %384, %379
-  %phi.bo.i.i = xor i64 %385, -1
+376:                                              ; preds = %374
+  %377 = shl nsw i64 -1, %153
+  %378 = xor i64 %377, -1
+  %379 = shl i64 %378, %373
+  %phi.bo.i.i = xor i64 %379, -1
   br label %mi_bitmap_unclaim.exit.i
 
-mi_bitmap_unclaim.exit.i:                         ; preds = %382, %380, %376
-  %386 = phi i64 [ %phi.bo.i.i, %382 ], [ 0, %376 ], [ -1, %380 ]
-  %387 = lshr i64 %378, 6
-  %388 = getelementptr inbounds i64, i64* %377, i64 %387
-  %389 = atomicrmw and i64* %388, i64 %386 acq_rel, align 8
+mi_bitmap_unclaim.exit.i:                         ; preds = %376, %374, %370
+  %380 = phi i64 [ %phi.bo.i.i, %376 ], [ 0, %370 ], [ -1, %374 ]
+  %381 = lshr i64 %372, 6
+  %382 = getelementptr inbounds i64, i64* %371, i64 %381
+  %383 = atomicrmw and i64* %382, i64 %380 acq_rel, align 8
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %13) #37
-  br label %448
+  br label %443
 
-390:                                              ; preds = %373
-  %391 = load i8, i8* %13, align 1, !tbaa !482, !range !72
-  %392 = icmp eq i8 %391, 0
-  br i1 %392, label %394, label %393
+384:                                              ; preds = %367
+  %385 = load atomic i8, i8* %13 unordered, align 1, !tbaa !465, !range !70
+  %386 = icmp eq i8 %385, 0
+  br i1 %386, label %388, label %387
 
-393:                                              ; preds = %390
-  store i8 1, i8* %18, align 1, !tbaa !482
-  br label %394
+387:                                              ; preds = %384
+  store i8 1, i8* %18, align 1, !tbaa !465
+  br label %388
 
-394:                                              ; preds = %393, %390
+388:                                              ; preds = %387, %384
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %13) #37
-  br label %410
+  br label %404
 
-395:                                              ; preds = %_mi_bitmap_claim.exit1.i
-  %396 = and i64 %349, 63
-  br i1 %330, label %_mi_bitmap_is_claimed.exit.i, label %397
+389:                                              ; preds = %_mi_bitmap_claim.exit1.i
+  %390 = and i64 %343, 63
+  br i1 %324, label %_mi_bitmap_is_claimed.exit.i, label %391
 
-397:                                              ; preds = %395
-  %398 = icmp eq i64 %152, 0
-  br i1 %398, label %_mi_bitmap_is_claimed.exit.i, label %399
+391:                                              ; preds = %389
+  %392 = icmp eq i64 %153, 0
+  br i1 %392, label %_mi_bitmap_is_claimed.exit.i, label %393
 
-399:                                              ; preds = %397
-  %400 = shl nsw i64 -1, %152
-  %401 = xor i64 %400, -1
-  %402 = shl i64 %401, %396
+393:                                              ; preds = %391
+  %394 = shl nsw i64 -1, %153
+  %395 = xor i64 %394, -1
+  %396 = shl i64 %395, %390
   br label %_mi_bitmap_is_claimed.exit.i
 
-_mi_bitmap_is_claimed.exit.i:                     ; preds = %399, %397, %395
-  %403 = phi i64 [ %402, %399 ], [ -1, %395 ], [ 0, %397 ]
-  %404 = lshr i64 %349, 6
-  %405 = getelementptr inbounds i64, i64* %359, i64 %404
-  %406 = load atomic i64, i64* %405 monotonic, align 8
-  %407 = and i64 %406, %403
-  %408 = icmp eq i64 %407, %403
-  %409 = zext i1 %408 to i8
-  store i8 %409, i8* %17, align 1, !tbaa !482
-  br label %410
+_mi_bitmap_is_claimed.exit.i:                     ; preds = %393, %391, %389
+  %397 = phi i64 [ %396, %393 ], [ -1, %389 ], [ 0, %391 ]
+  %398 = lshr i64 %343, 6
+  %399 = getelementptr inbounds i64, i64* %353, i64 %398
+  %400 = load atomic i64, i64* %399 monotonic, align 8
+  %401 = and i64 %400, %397
+  %402 = icmp eq i64 %401, %397
+  %403 = zext i1 %402 to i8
+  store i8 %403, i8* %17, align 1, !tbaa !465
+  br label %404
 
-410:                                              ; preds = %_mi_bitmap_is_claimed.exit.i, %394, %_mi_bitmap_claim.exit2.i
-  %411 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %319, i64 0, i32 5
-  %412 = load i64, i64* %12, align 8, !tbaa !453
-  %413 = and i64 %412, 63
-  br i1 %330, label %_mi_bitmap_is_any_claimed.exit.i.thread, label %_mi_bitmap_is_any_claimed.exit.i
+404:                                              ; preds = %_mi_bitmap_is_claimed.exit.i, %388, %_mi_bitmap_claim.exit2.i
+  %405 = getelementptr inbounds %struct.mem_region_s, %struct.mem_region_s* %313, i64 0, i32 5
+  %406 = load atomic i64, i64* %12 unordered, align 8, !tbaa !457
+  %407 = and i64 %406, 63
+  br i1 %324, label %_mi_bitmap_is_any_claimed.exit.i, label %408
 
-_mi_bitmap_is_any_claimed.exit.i:                 ; preds = %410
-  %414 = icmp eq i64 %152, 0
-  %415 = shl nsw i64 -1, %152
-  %416 = xor i64 %415, -1
-  %417 = shl i64 %416, %413
-  %418 = select i1 %414, i64 0, i64 %417
-  %419 = lshr i64 %412, 6
-  %420 = getelementptr inbounds i64, i64* %411, i64 %419
-  %421 = load atomic i64, i64* %420 monotonic, align 8
-  %422 = and i64 %421, %418
-  %.not11 = icmp eq i64 %422, 0
-  br i1 %.not11, label %449, label %426
+408:                                              ; preds = %404
+  %409 = icmp eq i64 %153, 0
+  br i1 %409, label %_mi_bitmap_is_any_claimed.exit.i, label %410
 
-_mi_bitmap_is_any_claimed.exit.i.thread:          ; preds = %410
-  %423 = lshr i64 %412, 6
-  %424 = getelementptr inbounds i64, i64* %411, i64 %423
-  %425 = load atomic i64, i64* %424 monotonic, align 8
-  %.not1150 = icmp eq i64 %425, 0
-  br i1 %.not1150, label %449, label %mi_bitmap_unclaim.exit4.i
+410:                                              ; preds = %408
+  %411 = shl nsw i64 -1, %153
+  %412 = xor i64 %411, -1
+  %413 = shl i64 %412, %407
+  br label %_mi_bitmap_is_any_claimed.exit.i
 
-426:                                              ; preds = %_mi_bitmap_is_any_claimed.exit.i
-  %427 = phi i64* [ %420, %_mi_bitmap_is_any_claimed.exit.i ]
-  br i1 %330, label %mi_bitmap_unclaim.exit4.i, label %428
+_mi_bitmap_is_any_claimed.exit.i:                 ; preds = %410, %408, %404
+  %414 = phi i64 [ %413, %410 ], [ -1, %404 ], [ 0, %408 ]
+  %415 = lshr i64 %406, 6
+  %416 = getelementptr inbounds i64, i64* %405, i64 %415
+  %417 = load atomic i64, i64* %416 monotonic, align 8
+  %418 = and i64 %417, %414
+  %.not10 = icmp eq i64 %418, 0
+  br i1 %.not10, label %444, label %419
 
-428:                                              ; preds = %426
-  %429 = icmp eq i64 %152, 0
-  br i1 %429, label %mi_bitmap_unclaim.exit4.i, label %430
+419:                                              ; preds = %_mi_bitmap_is_any_claimed.exit.i
+  %420 = load atomic i64, i64* %12 unordered, align 8, !tbaa !457
+  %421 = and i64 %420, 63
+  br i1 %324, label %mi_bitmap_unclaim.exit4.i, label %422
 
-430:                                              ; preds = %428
-  %431 = shl nsw i64 -1, %152
-  %432 = xor i64 %431, -1
-  %433 = shl i64 %432, %413
-  %phi.bo.i3.i = xor i64 %433, -1
+422:                                              ; preds = %419
+  %423 = icmp eq i64 %153, 0
+  br i1 %423, label %mi_bitmap_unclaim.exit4.i, label %424
+
+424:                                              ; preds = %422
+  %425 = shl nsw i64 -1, %153
+  %426 = xor i64 %425, -1
+  %427 = shl i64 %426, %421
+  %phi.bo.i3.i = xor i64 %427, -1
   br label %mi_bitmap_unclaim.exit4.i
 
-mi_bitmap_unclaim.exit4.i:                        ; preds = %430, %428, %426, %_mi_bitmap_is_any_claimed.exit.i.thread
-  %434 = phi i64* [ %427, %430 ], [ %427, %426 ], [ %427, %428 ], [ %424, %_mi_bitmap_is_any_claimed.exit.i.thread ]
-  %435 = phi i64 [ %phi.bo.i3.i, %430 ], [ 0, %426 ], [ -1, %428 ], [ 0, %_mi_bitmap_is_any_claimed.exit.i.thread ]
-  %436 = atomicrmw and i64* %434, i64 %435 acq_rel, align 8
-  %437 = load i8, i8* %17, align 1, !tbaa !482, !range !72
-  %438 = icmp eq i8 %437, 0
-  br i1 %438, label %439, label %441
+mi_bitmap_unclaim.exit4.i:                        ; preds = %424, %422, %419
+  %428 = phi i64 [ %phi.bo.i3.i, %424 ], [ 0, %419 ], [ -1, %422 ]
+  %429 = lshr i64 %420, 6
+  %430 = getelementptr inbounds i64, i64* %405, i64 %429
+  %431 = atomicrmw and i64* %430, i64 %428 acq_rel, align 8
+  %432 = load atomic i8, i8* %17 unordered, align 1, !tbaa !465, !range !70
+  %433 = icmp eq i8 %432, 0
+  br i1 %433, label %434, label %436
 
-439:                                              ; preds = %mi_bitmap_unclaim.exit4.i
-  %440 = call fastcc i64 @mi_option_get(i32 5) #37
-  %.not12 = icmp eq i64 %440, 0
-  br i1 %.not12, label %441, label %449
+434:                                              ; preds = %mi_bitmap_unclaim.exit4.i
+  %435 = call fastcc i64 @mi_option_get(i32 5) #37
+  %.not11 = icmp eq i64 %435, 0
+  br i1 %.not11, label %436, label %444
 
-441:                                              ; preds = %439, %mi_bitmap_unclaim.exit4.i
+436:                                              ; preds = %434, %mi_bitmap_unclaim.exit4.i
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %14) #37
-  store i8 0, i8* %14, align 1, !tbaa !482
-  %442 = and i64 %151, -4194304
-  %443 = call fastcc zeroext i1 @_mi_os_unreset(i8* %356, i64 %442, i8* nonnull %14) #37
-  %444 = load i8, i8* %14, align 1, !tbaa !482, !range !72
-  %445 = icmp eq i8 %444, 0
-  br i1 %445, label %447, label %446
+  store i8 0, i8* %14, align 1, !tbaa !465
+  %437 = and i64 %152, -4194304
+  %438 = call fastcc zeroext i1 @_mi_os_unreset(i8* %350, i64 %437, i8* nonnull %14) #37
+  %439 = load atomic i8, i8* %14 unordered, align 1, !tbaa !465, !range !70
+  %440 = icmp eq i8 %439, 0
+  br i1 %440, label %442, label %441
 
-446:                                              ; preds = %441
-  store i8 1, i8* %18, align 1, !tbaa !482
-  br label %447
+441:                                              ; preds = %436
+  store i8 1, i8* %18, align 1, !tbaa !465
+  br label %442
 
-447:                                              ; preds = %446, %441
+442:                                              ; preds = %441, %436
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %14) #37
-  br label %449
+  br label %444
 
-448:                                              ; preds = %mi_bitmap_unclaim.exit.i, %315, %.loopexit17
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %155) #37
-  br label %451
+443:                                              ; preds = %mi_bitmap_unclaim.exit.i, %309, %.loopexit17
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %156) #37
+  br label %446
 
-449:                                              ; preds = %447, %439, %_mi_bitmap_is_any_claimed.exit.i.thread, %_mi_bitmap_is_any_claimed.exit.i
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %155) #37
-  %450 = icmp eq i64 %324, 0
-  br i1 %450, label %451, label %_mi_mem_alloc_aligned.exit
+444:                                              ; preds = %442, %434, %_mi_bitmap_is_any_claimed.exit.i
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %156) #37
+  %445 = icmp eq i64 %318, 0
+  br i1 %445, label %446, label %_mi_mem_alloc_aligned.exit
 
-451:                                              ; preds = %449, %448
-  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.87.522, i64 0, i64 0), i64 %149) #37
-  br label %452
+446:                                              ; preds = %444, %443
+  call void (i8*, ...) @_mi_warning_message(i8* getelementptr inbounds ([42 x i8], [42 x i8]* @.str.87.522, i64 0, i64 0), i64 %150) #37
+  br label %447
 
-452:                                              ; preds = %451, %148
-  %453 = call fastcc i8* @_mi_arena_alloc_aligned(i64 %149, i8* nonnull %17, i8* nonnull %20, i8* nonnull %21, i8* nonnull %18, i64* nonnull %15) #37
-  %454 = load i64, i64* %15, align 8, !tbaa !453
-  %455 = shl i64 %454, 1
-  %456 = or i64 %455, 1
+447:                                              ; preds = %446, %149
+  %448 = call fastcc i8* @_mi_arena_alloc_aligned(i64 %150, i8* nonnull %17, i8* nonnull %20, i8* nonnull %21, i8* nonnull %18, i64* nonnull %15) #37
+  %449 = load atomic i64, i64* %15 unordered, align 8, !tbaa !457
+  %450 = shl i64 %449, 1
+  %451 = or i64 %450, 1
   br label %_mi_mem_alloc_aligned.exit
 
-_mi_mem_alloc_aligned.exit:                       ; preds = %452, %449
-  %.0 = phi i64 [ %456, %452 ], [ %353, %449 ]
-  %457 = phi i8* [ %453, %452 ], [ %356, %449 ]
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %150) #37
-  %458 = bitcast i8* %457 to %struct.mi_segment_s*
-  %459 = icmp eq i8* %457, null
-  br i1 %459, label %_mi_mem_alloc_aligned.exit.thread, label %460
+_mi_mem_alloc_aligned.exit:                       ; preds = %447, %444
+  %.0 = phi i64 [ %451, %447 ], [ %347, %444 ]
+  %452 = phi i8* [ %448, %447 ], [ %350, %444 ]
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %151) #37
+  %453 = bitcast i8* %452 to %struct.mi_segment_s*
+  %454 = icmp eq i8* %452, null
+  br i1 %454, label %_mi_mem_alloc_aligned.exit.thread, label %455
 
-460:                                              ; preds = %_mi_mem_alloc_aligned.exit
-  %461 = load i8, i8* %17, align 1, !tbaa !482, !range !72
-  %462 = icmp eq i8 %461, 0
-  br i1 %462, label %463, label %471
+455:                                              ; preds = %_mi_mem_alloc_aligned.exit
+  %456 = load atomic i8, i8* %17 unordered, align 1, !tbaa !465, !range !70
+  %457 = icmp eq i8 %456, 0
+  br i1 %457, label %458, label %466
 
-463:                                              ; preds = %460
+458:                                              ; preds = %455
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %22) #37
-  store i8 0, i8* %22, align 1, !tbaa !482
-  %464 = call fastcc zeroext i1 @mi_os_commitx(i8* nonnull %457, i64 %28, i1 zeroext true, i1 zeroext false, i8* nonnull %22) #37
-  %465 = load i8, i8* %22, align 1, !tbaa !482, !range !72
-  %466 = icmp eq i8 %465, 0
-  br i1 %466, label %468, label %467
+  store i8 0, i8* %22, align 1, !tbaa !465
+  %459 = call fastcc zeroext i1 @mi_os_commitx(i8* nonnull %452, i64 %28, i1 zeroext true, i1 zeroext false, i8* nonnull %22) #37
+  %460 = load atomic i8, i8* %22 unordered, align 1, !tbaa !465, !range !70
+  %461 = icmp eq i8 %460, 0
+  br i1 %461, label %463, label %462
 
-467:                                              ; preds = %463
-  store i8 1, i8* %18, align 1, !tbaa !482
-  br label %468
+462:                                              ; preds = %458
+  store i8 1, i8* %18, align 1, !tbaa !465
+  br label %463
 
-468:                                              ; preds = %467, %463
-  br i1 %464, label %470, label %469
+463:                                              ; preds = %462, %458
+  br i1 %459, label %465, label %464
 
-469:                                              ; preds = %468
-  call fastcc void @_mi_mem_free(i8* nonnull %457, i64 4194304, i64 %.0, i1 zeroext false, i1 zeroext false) #37
+464:                                              ; preds = %463
+  call fastcc void @_mi_mem_free(i8* nonnull %452, i64 4194304, i64 %.0, i1 zeroext false, i1 zeroext false) #37
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %22) #37
   br label %_mi_mem_alloc_aligned.exit.thread
 
-470:                                              ; preds = %468
+465:                                              ; preds = %463
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %22) #37
-  br label %471
+  br label %466
 
-471:                                              ; preds = %470, %460
-  %472 = phi i8 [ 0, %470 ], [ 1, %460 ]
-  %473 = bitcast i8* %457 to i64*
-  store i64 %.0, i64* %473, align 8, !tbaa !537
-  %474 = load i8, i8* %20, align 1, !tbaa !482, !range !72
-  %475 = load i8, i8* %21, align 1
-  %476 = and i8 %475, 1
-  %477 = or i8 %476, %474
-  %478 = getelementptr inbounds i8, i8* %457, i64 8
-  store i8 %477, i8* %478, align 8, !tbaa !544
-  %479 = getelementptr inbounds i8, i8* %457, i64 9
-  store i8 %472, i8* %479, align 1, !tbaa !584
-  %480 = icmp sgt i64 %33, -1
-  %481 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 10
-  %482 = load %struct.mi_stats_s*, %struct.mi_stats_s** %481, align 8, !tbaa !525
-  %483 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %482, i64 0, i32 0
-  %484 = icmp uge %struct.mi_stats_s* %482, @_mi_stats_main
-  %485 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %483, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
-  %486 = and i1 %484, %485
-  %487 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %482, i64 0, i32 0, i32 3
-  br i1 %480, label %488, label %513
+466:                                              ; preds = %465, %455
+  %467 = phi i8 [ 0, %465 ], [ 1, %455 ]
+  %468 = bitcast i8* %452 to i64*
+  store i64 %.0, i64* %468, align 8, !tbaa !541
+  %469 = load atomic i8, i8* %20 unordered, align 1, !tbaa !465, !range !70
+  %470 = load atomic i8, i8* %21 unordered, align 1
+  %471 = and i8 %470, 1
+  %472 = or i8 %471, %469
+  %473 = getelementptr inbounds i8, i8* %452, i64 8
+  store i8 %472, i8* %473, align 8, !tbaa !548
+  %474 = getelementptr inbounds i8, i8* %452, i64 9
+  store i8 %467, i8* %474, align 1, !tbaa !588
+  %475 = icmp sgt i64 %33, -1
+  %476 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 10
+  %477 = load atomic %struct.mi_stats_s*, %struct.mi_stats_s** %476 unordered, align 8, !tbaa !529
+  %478 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %477, i64 0, i32 0
+  %479 = icmp uge %struct.mi_stats_s* %477, @_mi_stats_main
+  %480 = icmp ult %"struct.(anonymous namespace)::RootSetStatistics"* %478, bitcast (i64* getelementptr inbounds (%struct.mi_stats_s, %struct.mi_stats_s* @_mi_stats_main, i64 1, i32 0, i32 0) to %"struct.(anonymous namespace)::RootSetStatistics"*)
+  %481 = and i1 %479, %480
+  %482 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %477, i64 0, i32 0, i32 3
+  br i1 %475, label %483, label %508
 
-488:                                              ; preds = %471
-  br i1 %486, label %489, label %503
+483:                                              ; preds = %466
+  br i1 %481, label %484, label %498
 
-489:                                              ; preds = %488
-  %490 = atomicrmw add i64* %487, i64 1 monotonic, align 8
-  %491 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %482, i64 0, i32 0, i32 2
-  %492 = add nsw i64 %490, 1
-  %493 = load atomic i64, i64* %491 monotonic, align 8
-  br label %494
+484:                                              ; preds = %483
+  %485 = atomicrmw add i64* %482, i64 1 monotonic, align 8
+  %486 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %477, i64 0, i32 0, i32 2
+  %487 = add nsw i64 %485, 1
+  %488 = load atomic i64, i64* %486 monotonic, align 8
+  br label %489
 
-494:                                              ; preds = %496, %489
-  %495 = phi i64 [ %493, %489 ], [ %499, %496 ]
-  %.not9 = icmp sgt i64 %495, %490
-  br i1 %.not9, label %500, label %496
+489:                                              ; preds = %491, %484
+  %490 = phi i64 [ %488, %484 ], [ %494, %491 ]
+  %.not9 = icmp sgt i64 %490, %485
+  br i1 %.not9, label %495, label %491
 
-496:                                              ; preds = %494
-  %497 = cmpxchg weak i64* %491, i64 %495, i64 %492 release monotonic, align 8
-  %498 = extractvalue { i64, i1 } %497, 1
-  %499 = extractvalue { i64, i1 } %497, 0
-  br i1 %498, label %500, label %494
+491:                                              ; preds = %489
+  %492 = cmpxchg weak i64* %486, i64 %490, i64 %487 release monotonic, align 8
+  %493 = extractvalue { i64, i1 } %492, 1
+  %494 = extractvalue { i64, i1 } %492, 0
+  br i1 %493, label %495, label %489
 
-500:                                              ; preds = %496, %494
-  %501 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %482, i64 0, i32 0, i32 0
-  %502 = atomicrmw add i64* %501, i64 1 monotonic, align 8
+495:                                              ; preds = %491, %489
+  %496 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %477, i64 0, i32 0, i32 0
+  %497 = atomicrmw add i64* %496, i64 1 monotonic, align 8
   br label %_mi_stat_increase.exit
 
-503:                                              ; preds = %488
-  %504 = load i64, i64* %487, align 8, !tbaa !510
-  %505 = add nsw i64 %504, 1
-  store i64 %505, i64* %487, align 8, !tbaa !510
-  %506 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %482, i64 0, i32 0, i32 2
-  %507 = load i64, i64* %506, align 8, !tbaa !511
-  %.not8 = icmp slt i64 %504, %507
-  br i1 %.not8, label %509, label %508
+498:                                              ; preds = %483
+  %499 = load atomic i64, i64* %482 unordered, align 8, !tbaa !514
+  %500 = add nsw i64 %499, 1
+  store i64 %500, i64* %482, align 8, !tbaa !514
+  %501 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %477, i64 0, i32 0, i32 2
+  %502 = load atomic i64, i64* %501 unordered, align 8, !tbaa !515
+  %.not8 = icmp slt i64 %499, %502
+  br i1 %.not8, label %504, label %503
 
-508:                                              ; preds = %503
-  store i64 %505, i64* %506, align 8, !tbaa !511
-  br label %509
+503:                                              ; preds = %498
+  store i64 %500, i64* %501, align 8, !tbaa !515
+  br label %504
 
-509:                                              ; preds = %508, %503
-  %510 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %482, i64 0, i32 0, i32 0
-  %511 = load i64, i64* %510, align 8, !tbaa !512
-  %512 = add nsw i64 %511, 1
-  store i64 %512, i64* %510, align 8, !tbaa !512
+504:                                              ; preds = %503, %498
+  %505 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %477, i64 0, i32 0, i32 0
+  %506 = load atomic i64, i64* %505 unordered, align 8, !tbaa !516
+  %507 = add nsw i64 %506, 1
+  store i64 %507, i64* %505, align 8, !tbaa !516
   br label %_mi_stat_increase.exit
 
-513:                                              ; preds = %471
-  br i1 %486, label %514, label %529
+508:                                              ; preds = %466
+  br i1 %481, label %509, label %524
 
-514:                                              ; preds = %513
-  %515 = atomicrmw add i64* %487, i64 -1 monotonic, align 8
-  %516 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %482, i64 0, i32 0, i32 2
-  %517 = add i64 %515, -1
-  %518 = load atomic i64, i64* %516 monotonic, align 8
-  br label %519
+509:                                              ; preds = %508
+  %510 = atomicrmw add i64* %482, i64 -1 monotonic, align 8
+  %511 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %477, i64 0, i32 0, i32 2
+  %512 = add i64 %510, -1
+  %513 = load atomic i64, i64* %511 monotonic, align 8
+  br label %514
 
-519:                                              ; preds = %522, %514
-  %520 = phi i64 [ %518, %514 ], [ %525, %522 ]
-  %521 = icmp slt i64 %520, %517
-  br i1 %521, label %522, label %526
+514:                                              ; preds = %517, %509
+  %515 = phi i64 [ %513, %509 ], [ %520, %517 ]
+  %516 = icmp slt i64 %515, %512
+  br i1 %516, label %517, label %521
 
-522:                                              ; preds = %519
-  %523 = cmpxchg weak i64* %516, i64 %520, i64 %517 release monotonic, align 8
-  %524 = extractvalue { i64, i1 } %523, 1
-  %525 = extractvalue { i64, i1 } %523, 0
-  br i1 %524, label %526, label %519
+517:                                              ; preds = %514
+  %518 = cmpxchg weak i64* %511, i64 %515, i64 %512 release monotonic, align 8
+  %519 = extractvalue { i64, i1 } %518, 1
+  %520 = extractvalue { i64, i1 } %518, 0
+  br i1 %519, label %521, label %514
 
-526:                                              ; preds = %522, %519
-  %527 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %482, i64 0, i32 0, i32 1
-  %528 = atomicrmw add i64* %527, i64 1 monotonic, align 8
+521:                                              ; preds = %517, %514
+  %522 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %477, i64 0, i32 0, i32 1
+  %523 = atomicrmw add i64* %522, i64 1 monotonic, align 8
   br label %_mi_stat_increase.exit
 
-529:                                              ; preds = %513
-  %530 = load i64, i64* %487, align 8, !tbaa !510
-  %531 = add i64 %530, -1
-  store i64 %531, i64* %487, align 8, !tbaa !510
-  %532 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %482, i64 0, i32 0, i32 2
-  %533 = load i64, i64* %532, align 8, !tbaa !511
-  %534 = icmp sgt i64 %531, %533
-  br i1 %534, label %535, label %536
+524:                                              ; preds = %508
+  %525 = load atomic i64, i64* %482 unordered, align 8, !tbaa !514
+  %526 = add i64 %525, -1
+  store i64 %526, i64* %482, align 8, !tbaa !514
+  %527 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %477, i64 0, i32 0, i32 2
+  %528 = load atomic i64, i64* %527 unordered, align 8, !tbaa !515
+  %529 = icmp sgt i64 %526, %528
+  br i1 %529, label %530, label %531
 
-535:                                              ; preds = %529
-  store i64 %531, i64* %532, align 8, !tbaa !511
-  br label %536
+530:                                              ; preds = %524
+  store i64 %526, i64* %527, align 8, !tbaa !515
+  br label %531
 
-536:                                              ; preds = %535, %529
-  %537 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %482, i64 0, i32 0, i32 1
-  %538 = load i64, i64* %537, align 8, !tbaa !513
-  %539 = add i64 %538, 1
-  store i64 %539, i64* %537, align 8, !tbaa !513
+531:                                              ; preds = %530, %524
+  %532 = getelementptr inbounds %struct.mi_stats_s, %struct.mi_stats_s* %477, i64 0, i32 0, i32 1
+  %533 = load atomic i64, i64* %532 unordered, align 8, !tbaa !517
+  %534 = add i64 %533, 1
+  store i64 %534, i64* %532, align 8, !tbaa !517
   br label %_mi_stat_increase.exit
 
-_mi_stat_increase.exit:                           ; preds = %536, %526, %509, %500
-  %540 = phi i64 [ 1, %500 ], [ 1, %509 ], [ -1, %526 ], [ -1, %536 ]
-  %541 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 3
-  %542 = load i64, i64* %541, align 8, !tbaa !532
-  %543 = add i64 %542, %540
-  store i64 %543, i64* %541, align 8, !tbaa !532
-  %544 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 4
-  %545 = load i64, i64* %544, align 8, !tbaa !533
-  %546 = icmp ugt i64 %543, %545
-  br i1 %546, label %547, label %548
+_mi_stat_increase.exit:                           ; preds = %531, %521, %504, %495
+  %535 = phi i64 [ 1, %495 ], [ 1, %504 ], [ -1, %521 ], [ -1, %531 ]
+  %536 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 3
+  %537 = load atomic i64, i64* %536 unordered, align 8, !tbaa !536
+  %538 = add i64 %537, %535
+  store i64 %538, i64* %536, align 8, !tbaa !536
+  %539 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 4
+  %540 = load atomic i64, i64* %539 unordered, align 8, !tbaa !537
+  %541 = icmp ugt i64 %538, %540
+  br i1 %541, label %542, label %543
 
-547:                                              ; preds = %_mi_stat_increase.exit
-  store i64 %543, i64* %544, align 8, !tbaa !533
-  br label %548
+542:                                              ; preds = %_mi_stat_increase.exit
+  store i64 %538, i64* %539, align 8, !tbaa !537
+  br label %543
 
-548:                                              ; preds = %547, %_mi_stat_increase.exit
-  %549 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 5
-  %550 = load i64, i64* %549, align 8, !tbaa !534
-  %551 = add i64 %550, %33
-  store i64 %551, i64* %549, align 8, !tbaa !534
-  %552 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 6
-  %553 = load i64, i64* %552, align 8, !tbaa !535
-  %554 = icmp ugt i64 %551, %553
-  br i1 %554, label %555, label %556
+543:                                              ; preds = %542, %_mi_stat_increase.exit
+  %544 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 5
+  %545 = load atomic i64, i64* %544 unordered, align 8, !tbaa !538
+  %546 = add i64 %545, %33
+  store i64 %546, i64* %544, align 8, !tbaa !538
+  %547 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 6
+  %548 = load atomic i64, i64* %547 unordered, align 8, !tbaa !539
+  %549 = icmp ugt i64 %546, %548
+  br i1 %549, label %550, label %551
 
-555:                                              ; preds = %548
-  store i64 %551, i64* %552, align 8, !tbaa !535
-  br label %556
+550:                                              ; preds = %543
+  store i64 %546, i64* %547, align 8, !tbaa !539
+  br label %551
 
-556:                                              ; preds = %555, %548
+551:                                              ; preds = %550, %543
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %21) #37
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %20) #37
-  br label %557
+  br label %552
 
-_mi_mem_alloc_aligned.exit.thread:                ; preds = %469, %_mi_mem_alloc_aligned.exit, %134
+_mi_mem_alloc_aligned.exit.thread:                ; preds = %464, %_mi_mem_alloc_aligned.exit, %135
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %21) #37
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %20) #37
-  br label %619
+  br label %614
 
-557:                                              ; preds = %556, %133, %.loopexit24
-  %558 = phi %struct.mi_segment_s* [ %458, %556 ], [ %0, %.loopexit24 ], [ %0, %133 ]
-  %559 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %558, i64 0, i32 3
-  %560 = bitcast %struct.mi_segment_s** %559 to i64*
-  store atomic i64 0, i64* %560 release, align 8
-  %561 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %558, i64 0, i32 4
-  %562 = bitcast %struct.mi_segment_s** %561 to i8*
-  %563 = add i64 %28, -24
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 1 %562, i8 0, i64 %563, i1 false)
-  br label %564
+552:                                              ; preds = %551, %134, %.loopexit24
+  %553 = phi %struct.mi_segment_s* [ %453, %551 ], [ %0, %.loopexit24 ], [ %0, %134 ]
+  %554 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %553, i64 0, i32 3
+  %555 = bitcast %struct.mi_segment_s** %554 to i64*
+  store atomic i64 0, i64* %555 release, align 8
+  %556 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %553, i64 0, i32 4
+  %557 = bitcast %struct.mi_segment_s** %556 to i8*
+  %558 = add i64 %28, -24
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 1 %557, i8 0, i64 %558, i1 false)
+  br label %559
 
-564:                                              ; preds = %564, %557
-  %565 = phi i64 [ %580, %564 ], [ 0, %557 ]
-  %566 = phi i8 [ %579, %564 ], [ 0, %557 ]
-  %567 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %558, i64 0, i32 16, i64 %565, i32 0
-  store i8 %566, i8* %567, align 8, !tbaa !546
-  %568 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %558, i64 0, i32 16, i64 %565, i32 1
-  %569 = load i8, i8* %568, align 1
-  %570 = and i8 %569, -3
-  store i8 %570, i8* %568, align 1
-  %571 = load i8, i8* %17, align 1, !tbaa !482, !range !72
-  %572 = shl nuw nsw i8 %571, 2
-  %573 = and i8 %569, -7
-  %574 = or i8 %572, %573
-  store i8 %574, i8* %568, align 1
-  %575 = load i8, i8* %18, align 1, !tbaa !482, !range !72
-  %576 = shl nuw nsw i8 %575, 3
-  %577 = and i8 %574, -11
-  %578 = or i8 %577, %576
-  store i8 %578, i8* %568, align 1
-  %579 = add i8 %566, 1
-  %580 = zext i8 %579 to i64
-  %581 = icmp ugt i64 %25, %580
-  br i1 %581, label %564, label %.loopexit
+559:                                              ; preds = %559, %552
+  %560 = phi i64 [ %575, %559 ], [ 0, %552 ]
+  %561 = phi i8 [ %574, %559 ], [ 0, %552 ]
+  %562 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %553, i64 0, i32 16, i64 %560, i32 0
+  store i8 %561, i8* %562, align 8, !tbaa !550
+  %563 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %553, i64 0, i32 16, i64 %560, i32 1
+  %564 = load atomic i8, i8* %563 unordered, align 1
+  %565 = and i8 %564, -3
+  store i8 %565, i8* %563, align 1
+  %566 = load atomic i8, i8* %17 unordered, align 1, !tbaa !465, !range !70
+  %567 = shl nuw nsw i8 %566, 2
+  %568 = and i8 %564, -7
+  %569 = or i8 %567, %568
+  store i8 %569, i8* %563, align 1
+  %570 = load atomic i8, i8* %18 unordered, align 1, !tbaa !465, !range !70
+  %571 = shl nuw nsw i8 %570, 3
+  %572 = and i8 %569, -11
+  %573 = or i8 %572, %571
+  store i8 %573, i8* %563, align 1
+  %574 = add i8 %561, 1
+  %575 = zext i8 %574 to i64
+  %576 = icmp ugt i64 %25, %575
+  br i1 %576, label %559, label %.loopexit
 
-582:                                              ; preds = %54
-  %583 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 3
-  %584 = bitcast %struct.mi_segment_s** %583 to i64*
-  store atomic i64 0, i64* %584 release, align 8
-  %585 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 4
-  %586 = bitcast %struct.mi_segment_s** %585 to i8*
-  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 1 dereferenceable(96) %586, i8 0, i64 96, i1 false)
+577:                                              ; preds = %53
+  %578 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 3
+  %579 = bitcast %struct.mi_segment_s** %578 to i64*
+  store atomic i64 0, i64* %579 release, align 8
+  %580 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %0, i64 0, i32 4
+  %581 = bitcast %struct.mi_segment_s** %580 to i8*
+  tail call void @llvm.memset.p0i8.i64(i8* nonnull align 1 dereferenceable(96) %581, i8 0, i64 96, i1 false)
   br label %.loopexit
 
-.loopexit:                                        ; preds = %582, %564
-  %587 = phi %struct.mi_segment_s** [ %585, %582 ], [ %561, %564 ]
-  %588 = phi %struct.mi_segment_s* [ %0, %582 ], [ %558, %564 ]
-  %589 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %588, i64 0, i32 15
-  store i32 %2, i32* %589, align 8, !tbaa !545
-  %590 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %588, i64 0, i32 9
-  store i64 %25, i64* %590, align 8, !tbaa !536
-  %591 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %588, i64 0, i32 13
-  store i64 %3, i64* %591, align 8, !tbaa !445
-  %592 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %588, i64 0, i32 10
-  store i64 %33, i64* %592, align 8, !tbaa !530
-  %593 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %588, i64 0, i32 11
-  store i64 %28, i64* %593, align 8, !tbaa !547
-  %594 = call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !563
-  %595 = ptrtoint i8* %594 to i64
-  %596 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %588, i64 0, i32 14
-  store atomic i64 %595, i64* %596 seq_cst, align 8, !tbaa !531
-  %597 = ptrtoint %struct.mi_segment_s* %588 to i64
-  %598 = load i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5), align 8, !tbaa !448
-  %599 = xor i64 %598, %597
-  %600 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %588, i64 0, i32 12
-  store i64 %599, i64* %600, align 8, !tbaa !585
-  br i1 %34, label %601, label %619
+.loopexit:                                        ; preds = %577, %559
+  %582 = phi %struct.mi_segment_s** [ %580, %577 ], [ %556, %559 ]
+  %583 = phi %struct.mi_segment_s* [ %0, %577 ], [ %553, %559 ]
+  %584 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %583, i64 0, i32 15
+  store i32 %2, i32* %584, align 8, !tbaa !549
+  %585 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %583, i64 0, i32 9
+  store i64 %25, i64* %585, align 8, !tbaa !540
+  %586 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %583, i64 0, i32 13
+  store i64 %3, i64* %586, align 8, !tbaa !449
+  %587 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %583, i64 0, i32 10
+  store i64 %33, i64* %587, align 8, !tbaa !534
+  %588 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %583, i64 0, i32 11
+  store i64 %28, i64* %588, align 8, !tbaa !551
+  %589 = call i8* asm "movq %fs:$1, $0", "=r,*m,~{dirflag},~{fpsr},~{flags}"(i8** elementtype(i8*) null) #54, !srcloc !567
+  %590 = ptrtoint i8* %589 to i64
+  %591 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %583, i64 0, i32 14
+  store atomic i64 %590, i64* %591 seq_cst, align 8, !tbaa !535
+  %592 = ptrtoint %struct.mi_segment_s* %583 to i64
+  %593 = load atomic i64, i64* getelementptr inbounds ({ %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }, { %struct.mi_tld_s*, [129 x %struct.mi_page_s*], [75 x %struct.mi_page_queue_s], %"class.kotlin::gc::GCHandle"*, i64, i64, [2 x i64], { <{ i32, [15 x i32] }>, [16 x i32], i32 }, i64, i64, i64, %struct.mi_heap_s*, i8 }* @_mi_heap_main, i64 0, i32 5) unordered, align 8, !tbaa !452
+  %594 = xor i64 %593, %592
+  %595 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %583, i64 0, i32 12
+  store i64 %594, i64* %595, align 8, !tbaa !589
+  br i1 %34, label %596, label %614
 
-601:                                              ; preds = %.loopexit
-  %602 = load i32, i32* %589, align 8, !tbaa !545
-  switch i32 %602, label %607 [
-    i32 0, label %603
-    i32 1, label %605
+596:                                              ; preds = %.loopexit
+  %597 = load atomic i32, i32* %584 unordered, align 8, !tbaa !549
+  switch i32 %597, label %602 [
+    i32 0, label %598
+    i32 1, label %600
   ]
 
-603:                                              ; preds = %601
-  %604 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 0
-  br label %607
+598:                                              ; preds = %596
+  %599 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 0
+  br label %602
 
-605:                                              ; preds = %601
-  %606 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 1
-  br label %607
+600:                                              ; preds = %596
+  %601 = getelementptr inbounds %struct.mi_segments_tld_s, %struct.mi_segments_tld_s* %4, i64 0, i32 1
+  br label %602
 
-607:                                              ; preds = %605, %603, %601
-  %608 = phi %struct.mi_segment_queue_s* [ %604, %603 ], [ %606, %605 ], [ null, %601 ]
-  store %struct.mi_segment_s* null, %struct.mi_segment_s** %587, align 8, !tbaa !529
-  %609 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %608, i64 0, i32 1
-  %610 = bitcast %struct.mi_segment_s** %609 to i64*
-  %611 = load i64, i64* %610, align 8, !tbaa !548
-  %612 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %588, i64 0, i32 5
-  %613 = bitcast %struct.mi_segment_s** %612 to i64*
-  store i64 %611, i64* %613, align 8, !tbaa !549
-  %614 = icmp eq i64 %611, 0
-  %615 = inttoptr i64 %611 to %struct.mi_segment_s*
-  %616 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %615, i64 0, i32 4
-  %617 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %608, i64 0, i32 0
-  %618 = select i1 %614, %struct.mi_segment_s** %617, %struct.mi_segment_s** %616
-  store %struct.mi_segment_s* %588, %struct.mi_segment_s** %618, align 8, !tbaa !434
-  store %struct.mi_segment_s* %588, %struct.mi_segment_s** %609, align 8, !tbaa !548
-  br label %619
+602:                                              ; preds = %600, %598, %596
+  %603 = phi %struct.mi_segment_queue_s* [ %599, %598 ], [ %601, %600 ], [ null, %596 ]
+  store %struct.mi_segment_s* null, %struct.mi_segment_s** %582, align 8, !tbaa !533
+  %604 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %603, i64 0, i32 1
+  %605 = bitcast %struct.mi_segment_s** %604 to i64*
+  %606 = load atomic i64, i64* %605 unordered, align 8, !tbaa !552
+  %607 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %583, i64 0, i32 5
+  %608 = bitcast %struct.mi_segment_s** %607 to i64*
+  store i64 %606, i64* %608, align 8, !tbaa !553
+  %609 = icmp eq i64 %606, 0
+  %610 = inttoptr i64 %606 to %struct.mi_segment_s*
+  %611 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %610, i64 0, i32 4
+  %612 = getelementptr inbounds %struct.mi_segment_queue_s, %struct.mi_segment_queue_s* %603, i64 0, i32 0
+  %613 = select i1 %609, %struct.mi_segment_s** %612, %struct.mi_segment_s** %611
+  store %struct.mi_segment_s* %583, %struct.mi_segment_s** %613, align 8, !tbaa !438
+  store %struct.mi_segment_s* %583, %struct.mi_segment_s** %604, align 8, !tbaa !552
+  br label %614
 
-619:                                              ; preds = %607, %.loopexit, %_mi_mem_alloc_aligned.exit.thread, %133
-  %620 = phi %struct.mi_segment_s* [ null, %133 ], [ null, %_mi_mem_alloc_aligned.exit.thread ], [ %588, %607 ], [ %588, %.loopexit ]
+614:                                              ; preds = %602, %.loopexit, %_mi_mem_alloc_aligned.exit.thread, %134
+  %615 = phi %struct.mi_segment_s* [ null, %134 ], [ null, %_mi_mem_alloc_aligned.exit.thread ], [ %583, %602 ], [ %583, %.loopexit ]
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %18) #37
   call void @llvm.lifetime.end.p0i8(i64 1, i8* nonnull %17) #37
-  ret %struct.mi_segment_s* %620
+  ret %struct.mi_segment_s* %615
 }
 
 ; Function Attrs: nounwind uwtable
@@ -46154,7 +46715,7 @@
   %3 = alloca [128 x i8], align 16
   %4 = load atomic i64, i64* @_mi_numa_node_count monotonic, align 8
   %5 = icmp eq i64 %4, 0
-  br i1 %5, label %6, label %26, !prof !284, !misexpect !437
+  br i1 %5, label %6, label %26, !prof !282, !misexpect !441
 
 6:                                                ; preds = %0
   %7 = load atomic i64, i64* @_mi_numa_node_count acquire, align 8
@@ -46204,13 +46765,13 @@
 29:                                               ; preds = %26
   %30 = bitcast i64* %1 to i8*
   call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %30) #37
-  store i64 0, i64* %1, align 8, !tbaa !453
+  store i64 0, i64* %1, align 8, !tbaa !457
   %31 = bitcast i64* %2 to i8*
   call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %31) #37
-  store i64 0, i64* %2, align 8, !tbaa !453
+  store i64 0, i64* %2, align 8, !tbaa !457
   %32 = call i64 (i64, ...) @syscall(i64 309, i64* nonnull %2, i64* nonnull %1, i8* null) #37
   %33 = icmp eq i64 %32, 0
-  %34 = load i64, i64* %1, align 8
+  %34 = load atomic i64, i64* %1 unordered, align 8
   %35 = select i1 %33, i64 %34, i64 0
   call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %31) #37
   call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %30) #37
@@ -46254,7 +46815,7 @@
   %14 = phi i64 [ %12, %10 ], [ -1, %6 ], [ 0, %8 ]
   %15 = sub i64 64, %1
   %16 = xor i64 %4, -1
-  %17 = tail call i64 @llvm.cttz.i64(i64 %16, i1 false) #37, !range !481
+  %17 = tail call i64 @llvm.cttz.i64(i64 %16, i1 false) #37, !range !486
   %18 = shl i64 %14, %17
   %19 = icmp ugt i64 %17, %15
   br i1 %19, label %.loopexit1, label %20
@@ -46307,11 +46868,11 @@
 
 .loopexit:                                        ; preds = %45, %30
   %50 = phi i64 [ %23, %30 ], [ %41, %45 ]
-  store i64 %50, i64* %2, align 8, !tbaa !453
+  store i64 %50, i64* %2, align 8, !tbaa !457
   br label %.loopexit1
 
 51:                                               ; preds = %.preheader2
-  %52 = tail call i64 @llvm.ctlz.i64(i64 %43, i1 true) #37, !range !481
+  %52 = tail call i64 @llvm.ctlz.i64(i64 %43, i1 true) #37, !range !486
   %53 = xor i64 %52, 63
   %54 = sub i64 1, %41
   %55 = add i64 %54, %53
@@ -46333,9 +46894,9 @@
 
 ; Function Attrs: nounwind uwtable
 define internal fastcc i8* @_mi_arena_alloc_aligned(i64 %0, i8* nocapture %1, i8* %2, i8* nocapture %3, i8* nocapture %4, i64* nocapture %5) unnamed_addr #17 {
-  store i64 0, i64* %5, align 8, !tbaa !453
-  store i8 0, i8* %4, align 1, !tbaa !482
-  store i8 0, i8* %3, align 1, !tbaa !482
+  store i64 0, i64* %5, align 8, !tbaa !457
+  store i8 0, i8* %4, align 1, !tbaa !465
+  store i8 0, i8* %3, align 1, !tbaa !465
   %7 = icmp ugt i64 %0, 8388607
   br i1 %7, label %8, label %.loopexit
 
@@ -46349,7 +46910,7 @@
   %13 = lshr i64 %12, 24
   %14 = load atomic i64, i64* @_mi_numa_node_count monotonic, align 8
   %15 = icmp eq i64 %14, 1
-  br i1 %15, label %18, label %16, !prof !436, !misexpect !437
+  br i1 %15, label %18, label %16, !prof !440, !misexpect !441
 
 16:                                               ; preds = %11
   %17 = tail call fastcc i32 @_mi_os_numa_node_get() #37
@@ -46370,20 +46931,20 @@
 
 27:                                               ; preds = %20
   %28 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %25, i64 0, i32 3
-  %29 = load i32, i32* %28, align 8, !tbaa !474
+  %29 = load atomic i32, i32* %28 unordered, align 8, !tbaa !479
   %30 = icmp slt i32 %29, 0
   %31 = icmp eq i32 %29, %19
   %32 = or i1 %30, %31
   br i1 %32, label %33, label %43
 
 33:                                               ; preds = %27
-  %34 = load i8, i8* %2, align 1, !tbaa !482, !range !72
+  %34 = load atomic i8, i8* %2 unordered, align 1, !tbaa !465, !range !70
   %35 = icmp eq i8 %34, 0
   br i1 %35, label %36, label %40
 
 36:                                               ; preds = %33
   %37 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %25, i64 0, i32 6
-  %38 = load i8, i8* %37, align 2, !tbaa !475, !range !72
+  %38 = load atomic i8, i8* %37 unordered, align 2, !tbaa !480, !range !70
   %39 = icmp eq i8 %38, 0
   br i1 %39, label %40, label %43
 
@@ -46411,20 +46972,20 @@
 
 54:                                               ; preds = %47
   %55 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %52, i64 0, i32 3
-  %56 = load i32, i32* %55, align 8, !tbaa !474
+  %56 = load atomic i32, i32* %55 unordered, align 8, !tbaa !479
   %57 = icmp slt i32 %56, 0
   %58 = icmp eq i32 %56, %19
   %59 = or i1 %57, %58
   br i1 %59, label %70, label %60
 
 60:                                               ; preds = %54
-  %61 = load i8, i8* %2, align 1, !tbaa !482, !range !72
+  %61 = load atomic i8, i8* %2 unordered, align 1, !tbaa !465, !range !70
   %62 = icmp eq i8 %61, 0
   br i1 %62, label %63, label %67
 
 63:                                               ; preds = %60
   %64 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %52, i64 0, i32 6
-  %65 = load i8, i8* %64, align 2, !tbaa !475, !range !72
+  %65 = load atomic i8, i8* %64 unordered, align 2, !tbaa !480, !range !70
   %66 = icmp eq i8 %65, 0
   br i1 %66, label %67, label %70
 
@@ -46445,21 +47006,21 @@
 
 74:                                               ; preds = %.loopexit
   %75 = tail call i32* @__errno_location() #1
-  store i32 12, i32* %75, align 4, !tbaa !459
+  store i32 12, i32* %75, align 4, !tbaa !463
   br label %.loopexit1
 
 76:                                               ; preds = %.loopexit
-  store i8 1, i8* %4, align 1, !tbaa !482
-  store i64 0, i64* %5, align 8, !tbaa !453
-  %77 = load i8, i8* %1, align 1, !tbaa !482, !range !72
+  store i8 1, i8* %4, align 1, !tbaa !465
+  store i64 0, i64* %5, align 8, !tbaa !457
+  %77 = load atomic i8, i8* %1 unordered, align 1, !tbaa !465, !range !70
   %78 = icmp ne i8 %77, 0
   %79 = tail call fastcc i8* @_mi_os_alloc_aligned(i64 %0, i1 zeroext %78, i8* %2) #37
   %80 = icmp eq i8* %79, null
   br i1 %80, label %.loopexit1, label %81
 
 81:                                               ; preds = %76
-  %82 = load i8, i8* %2, align 1, !tbaa !482, !range !72
-  store i8 %82, i8* %3, align 1, !tbaa !482
+  %82 = load atomic i8, i8* %2 unordered, align 1, !tbaa !465, !range !70
+  store i8 %82, i8* %3, align 1, !tbaa !465
   br label %.loopexit1
 
 .loopexit1:                                       ; preds = %81, %76, %74, %67, %40
@@ -46478,16 +47039,16 @@
   br label %_mi_stat_decrease.exit
 
 7:                                                ; preds = %3
-  store i8 0, i8* %2, align 1, !tbaa !482
+  store i8 0, i8* %2, align 1, !tbaa !465
   %8 = icmp eq i64 %1, 0
   %9 = icmp eq i8* %0, null
   %10 = or i1 %9, %8
   br i1 %10, label %_mi_stat_decrease.exit, label %11
 
 11:                                               ; preds = %7
-  %12 = load i64, i64* @os_page_size, align 8, !tbaa !453
+  %12 = load atomic i64, i64* @os_page_size unordered, align 8, !tbaa !457
   %13 = ptrtoint i8* %0 to i64
-  %14 = tail call i64 @llvm.ctpop.i64(i64 %12) #37, !range !481
+  %14 = tail call i64 @llvm.ctpop.i64(i64 %12) #37, !range !486
   %15 = icmp ult i64 %14, 2
   %16 = add i64 %13, -1
   %17 = add i64 %16, %12
@@ -46559,7 +47120,7 @@
   %11 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %0, i64 0, i32 7
   %12 = load atomic i64, i64* %11 acquire, align 8
   %13 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %0, i64 0, i32 2
-  %14 = load i64, i64* %13, align 8, !tbaa !472
+  %14 = load atomic i64, i64* %13 unordered, align 8, !tbaa !477
   %15 = icmp eq i64 %2, 1
   %16 = icmp eq i64 %14, 0
   br i1 %15, label %28, label %17
@@ -46594,7 +47155,7 @@
 
 36:                                               ; preds = %.preheader7
   %37 = xor i64 %34, -1
-  %38 = tail call i64 @llvm.cttz.i64(i64 %37, i1 false) #37, !range !481
+  %38 = tail call i64 @llvm.cttz.i64(i64 %37, i1 false) #37, !range !486
   %39 = icmp ugt i64 %38, 63
   br i1 %39, label %.loopexit6, label %40
 
@@ -46655,7 +47216,7 @@
 
 76:                                               ; preds = %72
   %77 = xor i64 %74, -1
-  %78 = tail call i64 @llvm.cttz.i64(i64 %77, i1 false) #37, !range !481
+  %78 = tail call i64 @llvm.cttz.i64(i64 %77, i1 false) #37, !range !486
   %79 = icmp ugt i64 %78, %24
   br i1 %79, label %.loopexit19, label %80
 
@@ -46679,7 +47240,7 @@
   br i1 %91, label %105, label %100
 
 93:                                               ; preds = %82
-  %94 = tail call i64 @llvm.ctlz.i64(i64 %86, i1 true) #37, !range !481
+  %94 = tail call i64 @llvm.ctlz.i64(i64 %86, i1 true) #37, !range !486
   %95 = xor i64 %94, 63
   %96 = sub i64 1, %84
   %97 = add i64 %96, %95
@@ -46702,7 +47263,7 @@
 .loopexit19:                                      ; preds = %100, %76, %72, %67
   %108 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %0, i64 0, i32 10, i64 %71
   %109 = load atomic i64, i64* %108 monotonic, align 8
-  %110 = tail call i64 @llvm.ctlz.i64(i64 %109, i1 false) #37, !range !481
+  %110 = tail call i64 @llvm.ctlz.i64(i64 %109, i1 false) #37, !range !486
   %111 = icmp eq i64 %110, 0
   br i1 %111, label %.loopexit16, label %112
 
@@ -46713,7 +47274,7 @@
 114:                                              ; preds = %.loopexit8
   %115 = add nuw nsw i64 %122, 1
   %116 = load atomic i64, i64* %108 monotonic, align 8
-  %117 = tail call i64 @llvm.ctlz.i64(i64 %116, i1 false) #37, !range !481
+  %117 = tail call i64 @llvm.ctlz.i64(i64 %116, i1 false) #37, !range !486
   %118 = icmp eq i64 %117, 0
   br i1 %118, label %.loopexit16, label %119
 
@@ -46731,7 +47292,7 @@
 
 127:                                              ; preds = %124
   %128 = xor i64 %125, -1
-  %129 = tail call i64 @llvm.cttz.i64(i64 %128, i1 false) #37, !range !481
+  %129 = tail call i64 @llvm.cttz.i64(i64 %128, i1 false) #37, !range !486
   %130 = icmp ugt i64 %129, %24
   br i1 %130, label %.loopexit16, label %131
 
@@ -46760,7 +47321,7 @@
   br label %242
 
 147:                                              ; preds = %133
-  %148 = tail call i64 @llvm.ctlz.i64(i64 %137, i1 true) #37, !range !481
+  %148 = tail call i64 @llvm.ctlz.i64(i64 %137, i1 true) #37, !range !486
   %149 = xor i64 %148, 63
   %150 = sub i64 1, %135
   %151 = add i64 %150, %149
@@ -46914,7 +47475,7 @@
   %.0 = phi i64 [ %66, %64 ], [ %220, %218 ], [ %146, %144 ], [ %107, %105 ]
   store atomic i64 %12, i64* %11 release, align 8
   %243 = bitcast %struct.mi_arena_s* %0 to i64*
-  %244 = load atomic i64, i64* %243 seq_cst, align 8, !tbaa !473
+  %244 = load atomic i64, i64* %243 seq_cst, align 8, !tbaa !478
   %245 = inttoptr i64 %244 to i8*
   %246 = shl i64 %.0, 24
   %247 = getelementptr inbounds i8, i8* %245, i64 %246
@@ -46922,47 +47483,47 @@
   %249 = add i64 %1, 1
   %250 = and i64 %249, 255
   %251 = or i64 %248, %250
-  store i64 %251, i64* %7, align 8, !tbaa !453
+  store i64 %251, i64* %7, align 8, !tbaa !457
   %252 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %0, i64 0, i32 8
-  %253 = load i64*, i64** %252, align 8, !tbaa !479
+  %253 = load atomic i64*, i64** %252 unordered, align 8, !tbaa !484
   %254 = tail call fastcc zeroext i1 @_mi_bitmap_claim_across(i64* %253, i64 %2, i64 %.0, i8* null) #37
   %255 = zext i1 %254 to i8
-  store i8 %255, i8* %6, align 1, !tbaa !482
+  store i8 %255, i8* %6, align 1, !tbaa !465
   %256 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %0, i64 0, i32 6
-  %257 = load i8, i8* %256, align 2, !tbaa !475, !range !72
-  store i8 %257, i8* %4, align 1, !tbaa !482
-  %258 = load i8, i8* %256, align 2, !tbaa !475, !range !72
+  %257 = load atomic i8, i8* %256 unordered, align 2, !tbaa !480, !range !70
+  store i8 %257, i8* %4, align 1, !tbaa !465
+  %258 = load atomic i8, i8* %256 unordered, align 2, !tbaa !480, !range !70
   %259 = icmp eq i8 %258, 0
   br i1 %259, label %260, label %263
 
 260:                                              ; preds = %242
   %261 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %0, i64 0, i32 5
-  %262 = load i8, i8* %261, align 1, !tbaa !477, !range !72
+  %262 = load atomic i8, i8* %261 unordered, align 1, !tbaa !482, !range !70
   br label %263
 
 263:                                              ; preds = %260, %242
   %264 = phi i8 [ 1, %242 ], [ %262, %260 ]
-  store i8 %264, i8* %5, align 1, !tbaa !482
+  store i8 %264, i8* %5, align 1, !tbaa !465
   %265 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %0, i64 0, i32 5
-  %266 = load i8, i8* %265, align 1, !tbaa !477, !range !72
+  %266 = load atomic i8, i8* %265 unordered, align 1, !tbaa !482, !range !70
   %267 = icmp eq i8 %266, 0
   br i1 %267, label %269, label %268
 
 268:                                              ; preds = %263
-  store i8 1, i8* %3, align 1, !tbaa !482
+  store i8 1, i8* %3, align 1, !tbaa !465
   br label %_mi_bitmap_try_find_from_claim_across.exit
 
 269:                                              ; preds = %263
-  %270 = load i8, i8* %3, align 1, !tbaa !482, !range !72
+  %270 = load atomic i8, i8* %3 unordered, align 1, !tbaa !465, !range !70
   %271 = icmp eq i8 %270, 0
   br i1 %271, label %286, label %272
 
 272:                                              ; preds = %269
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %9) #37
   %273 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %0, i64 0, i32 9
-  %274 = load i64*, i64** %273, align 8, !tbaa !480
+  %274 = load atomic i64*, i64** %273 unordered, align 8, !tbaa !485
   %275 = call fastcc zeroext i1 @_mi_bitmap_claim_across(i64* %274, i64 %2, i64 %.0, i8* nonnull %9) #37
-  %276 = load i8, i8* %9, align 1, !tbaa !482, !range !72
+  %276 = load atomic i8, i8* %9 unordered, align 1, !tbaa !465, !range !70
   %277 = icmp eq i8 %276, 0
   br i1 %277, label %285, label %278
 
@@ -46970,12 +47531,12 @@
   call void @llvm.lifetime.start.p0i8(i64 1, i8* nonnull %10) #37
   %279 = shl i64 %2, 24
   %280 = call fastcc zeroext i1 @mi_os_commitx(i8* %247, i64 %279, i1 zeroext true, i1 zeroext false, i8* nonnull %10) #37
-  %281 = load i8, i8* %10, align 1, !tbaa !482, !range !72
+  %281 = load atomic i8, i8* %10 unordered, align 1, !tbaa !465, !range !70
   %282 = icmp eq i8 %281, 0
   br i1 %282, label %284, label %283
 
 283:                                              ; preds = %278
-  store i8 1, i8* %6, align 1, !tbaa !482
+  store i8 1, i8* %6, align 1, !tbaa !465
   br label %284
 
 284:                                              ; preds = %283, %278
@@ -46988,12 +47549,12 @@
 
 286:                                              ; preds = %269
   %287 = getelementptr inbounds %struct.mi_arena_s, %struct.mi_arena_s* %0, i64 0, i32 9
-  %288 = load i64*, i64** %287, align 8, !tbaa !480
+  %288 = load atomic i64*, i64** %287 unordered, align 8, !tbaa !485
   %289 = lshr i64 %.0, 6
   %290 = and i64 %.0, 63
   %291 = add i64 %290, %2
   %292 = icmp ult i64 %291, 65
-  br i1 %292, label %293, label %301, !prof !436, !misexpect !437
+  br i1 %292, label %293, label %301, !prof !440, !misexpect !441
 
 293:                                              ; preds = %286
   %294 = icmp ugt i64 %2, 63
@@ -47058,7 +47619,7 @@
   %338 = getelementptr inbounds i64, i64* %331, i64 1
   %339 = add nsw i64 %333, -1
   %340 = icmp eq i64 %339, 0
-  br i1 %340, label %.loopexit5, label %.preheader4, !llvm.loop !586
+  br i1 %340, label %.loopexit5, label %.preheader4, !llvm.loop !590
 
 .loopexit5:                                       ; preds = %.preheader4
   %341 = and i64 %319, 288230376151711740
@@ -47156,7 +47717,7 @@
 _mi_bitmap_is_claimed_across.exit:                ; preds = %401, %.loopexit
   %406 = phi i8 [ %398, %.loopexit ], [ %405, %401 ]
   %407 = and i8 %406, 1
-  store i8 %407, i8* %3, align 1, !tbaa !482
+  store i8 %407, i8* %3, align 1, !tbaa !465
   br label %_mi_bitmap_try_find_from_claim_across.exit
 
 _mi_bitmap_try_find_from_claim_across.exit:       ; preds = %_mi_bitmap_is_claimed_across.exit, %285, %268, %.loopexit16, %.loopexit6, %28, %17
@@ -47170,7 +47731,7 @@
   %6 = and i64 %2, 63
   %7 = add i64 %6, %1
   %8 = icmp ult i64 %7, 65
-  br i1 %8, label %9, label %17, !prof !436, !misexpect !437
+  br i1 %8, label %9, label %17, !prof !440, !misexpect !441
 
 9:                                                ; preds = %4
   %10 = icmp ugt i64 %1, 63
@@ -47333,7 +47894,7 @@
 
 123:                                              ; preds = %119
   %124 = and i8 %120, 1
-  store i8 %124, i8* %3, align 1, !tbaa !482
+  store i8 %124, i8* %3, align 1, !tbaa !465
   br label %125
 
 125:                                              ; preds = %123, %119
@@ -47356,27 +47917,27 @@
 6:                                                ; preds = %1
   %7 = and i64 %2, 4194303
   %8 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 13
-  %9 = load i64, i64* %8, align 32, !tbaa !445
+  %9 = load atomic i64, i64* %8 unordered, align 32, !tbaa !449
   %10 = lshr i64 %7, %9
   %11 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 16, i64 %10
   %12 = getelementptr %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 16, i64 %10, i32 4, i32 0
-  %13 = load i8, i8* %12, align 2
+  %13 = load atomic i8, i8* %12 unordered, align 2
   %14 = and i8 %13, 2
   %15 = icmp eq i8 %14, 0
   %16 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 16, i64 %10, i32 8
-  %17 = load i32, i32* %16, align 4, !tbaa !550
+  %17 = load atomic i32, i32* %16 unordered, align 4, !tbaa !554
   %18 = zext i32 %17 to i64
-  br i1 %15, label %128, label %19, !prof !436, !misexpect !285
+  br i1 %15, label %128, label %19, !prof !440, !misexpect !283
 
 19:                                               ; preds = %6
   %20 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 15
-  %21 = load i32, i32* %20, align 16, !tbaa !545
+  %21 = load atomic i32, i32* %20 unordered, align 16, !tbaa !549
   %22 = icmp eq i32 %21, 3
   br i1 %22, label %23, label %26
 
 23:                                               ; preds = %19
   %24 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 10
-  %25 = load i64, i64* %24, align 8, !tbaa !530
+  %25 = load atomic i64, i64* %24 unordered, align 8, !tbaa !534
   br label %28
 
 26:                                               ; preds = %19
@@ -47387,7 +47948,7 @@
   %29 = phi i64 [ %25, %23 ], [ %27, %26 ]
   %30 = inttoptr i64 %3 to i8*
   %31 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %11, i64 0, i32 0
-  %32 = load i8, i8* %31, align 8, !tbaa !546
+  %32 = load atomic i8, i8* %31 unordered, align 8, !tbaa !550
   %33 = zext i8 %32 to i64
   %34 = mul i64 %29, %33
   %35 = getelementptr inbounds i8, i8* %30, i64 %34
@@ -47396,7 +47957,7 @@
 
 37:                                               ; preds = %28
   %38 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %4, i64 0, i32 11
-  %39 = load i64, i64* %38, align 16, !tbaa !547
+  %39 = load atomic i64, i64* %38 unordered, align 16, !tbaa !551
   %40 = getelementptr inbounds i8, i8* %35, i64 %39
   %41 = icmp ne i32 %17, 0
   %42 = icmp ult i32 %21, 2
@@ -47415,25 +47976,25 @@
 _mi_segment_page_start.exit.i:                    ; preds = %44, %37, %28
   %50 = phi i8* [ %40, %37 ], [ %35, %28 ], [ %spec.select, %44 ]
   %51 = icmp ult i32 %17, 67108864
-  br i1 %51, label %_mi_page_ptr_unalign.exit, label %52, !prof !436, !misexpect !437
+  br i1 %51, label %_mi_page_ptr_unalign.exit, label %52, !prof !440, !misexpect !441
 
 52:                                               ; preds = %_mi_segment_page_start.exit.i
   %53 = ptrtoint %struct.mi_page_s* %11 to i64
   %54 = and i64 %53, -4194304
   %55 = inttoptr i64 %54 to %struct.mi_segment_s*
   %56 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %55, i64 0, i32 15
-  %57 = load i32, i32* %56, align 16, !tbaa !545
+  %57 = load atomic i32, i32* %56 unordered, align 16, !tbaa !549
   %58 = icmp eq i32 %57, 3
   br i1 %58, label %59, label %62
 
 59:                                               ; preds = %52
   %60 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %55, i64 0, i32 10
-  %61 = load i64, i64* %60, align 8, !tbaa !530
+  %61 = load atomic i64, i64* %60 unordered, align 8, !tbaa !534
   br label %66
 
 62:                                               ; preds = %52
   %63 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %55, i64 0, i32 13
-  %64 = load i64, i64* %63, align 32, !tbaa !445
+  %64 = load atomic i64, i64* %63 unordered, align 32, !tbaa !449
   %65 = shl nuw i64 1, %64
   br label %66
 
@@ -47443,7 +48004,7 @@
 
 68:                                               ; preds = %66
   %69 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %55, i64 0, i32 11
-  %70 = load i64, i64* %69, align 16, !tbaa !547
+  %70 = load atomic i64, i64* %69 unordered, align 16, !tbaa !551
   %71 = sub i64 %67, %70
   %72 = icmp ne i32 %17, 0
   %73 = icmp ult i32 %57, 2
@@ -47460,7 +48021,7 @@
   %82 = sub nsw i64 %18, %81
   %83 = icmp ult i64 %82, %18
   %84 = select i1 %83, i64 %82, i64 0
-  %spec.select5 = sub i64 %71, %84
+  %spec.select12 = sub i64 %71, %84
   br label %89
 
 _mi_page_ptr_unalign.exit:                        ; preds = %_mi_segment_page_start.exit.i
@@ -47471,7 +48032,7 @@
   br label %_mi_segment_page_start.exit1
 
 89:                                               ; preds = %75, %68, %66
-  %.ph = phi i64 [ %spec.select5, %75 ], [ %67, %66 ], [ %71, %68 ]
+  %.ph = phi i64 [ %spec.select12, %75 ], [ %67, %66 ], [ %71, %68 ]
   %90 = ptrtoint i8* %50 to i64
   %91 = sub i64 %2, %90
   %92 = urem i64 %91, %.ph
@@ -47479,18 +48040,18 @@
   %94 = and i64 %93, -4194304
   %95 = inttoptr i64 %94 to %struct.mi_segment_s*
   %96 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %95, i64 0, i32 15
-  %97 = load i32, i32* %96, align 16, !tbaa !545
+  %97 = load atomic i32, i32* %96 unordered, align 16, !tbaa !549
   %98 = icmp eq i32 %97, 3
   br i1 %98, label %99, label %102
 
 99:                                               ; preds = %89
   %100 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %95, i64 0, i32 10
-  %101 = load i64, i64* %100, align 8, !tbaa !530
+  %101 = load atomic i64, i64* %100 unordered, align 8, !tbaa !534
   br label %106
 
 102:                                              ; preds = %89
   %103 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %95, i64 0, i32 13
-  %104 = load i64, i64* %103, align 32, !tbaa !445
+  %104 = load atomic i64, i64* %103 unordered, align 32, !tbaa !449
   %105 = shl nuw i64 1, %104
   br label %106
 
@@ -47500,7 +48061,7 @@
 
 108:                                              ; preds = %106
   %109 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %95, i64 0, i32 11
-  %110 = load i64, i64* %109, align 16, !tbaa !547
+  %110 = load atomic i64, i64* %109 unordered, align 16, !tbaa !551
   %111 = sub i64 %107, %110
   %112 = icmp ne i32 %17, 0
   %113 = icmp ult i32 %97, 2
@@ -47517,49 +48078,49 @@
   %122 = sub nsw i64 %18, %121
   %123 = icmp ult i64 %122, %18
   %124 = select i1 %123, i64 %122, i64 0
-  %spec.select6 = sub i64 %111, %124
+  %spec.select13 = sub i64 %111, %124
   br label %_mi_segment_page_start.exit1
 
 _mi_segment_page_start.exit1:                     ; preds = %115, %108, %106, %_mi_page_ptr_unalign.exit
   %125 = phi i64 [ %88, %_mi_page_ptr_unalign.exit ], [ %92, %108 ], [ %92, %106 ], [ %92, %115 ]
-  %126 = phi i64 [ %18, %_mi_page_ptr_unalign.exit ], [ %111, %108 ], [ %107, %106 ], [ %spec.select6, %115 ]
+  %126 = phi i64 [ %18, %_mi_page_ptr_unalign.exit ], [ %111, %108 ], [ %107, %106 ], [ %spec.select13, %115 ]
   %127 = sub i64 %126, %125
   br label %_mi_segment_page_start.exit
 
 128:                                              ; preds = %6
   %129 = icmp ult i32 %17, 67108864
-  br i1 %129, label %_mi_segment_page_start.exit, label %130, !prof !436, !misexpect !437
+  br i1 %129, label %_mi_segment_page_start.exit, label %130, !prof !440, !misexpect !441
 
 130:                                              ; preds = %128
   %131 = ptrtoint %struct.mi_page_s* %11 to i64
   %132 = and i64 %131, -4194304
   %133 = inttoptr i64 %132 to %struct.mi_segment_s*
   %134 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %133, i64 0, i32 15
-  %135 = load i32, i32* %134, align 16, !tbaa !545
+  %135 = load atomic i32, i32* %134 unordered, align 16, !tbaa !549
   %136 = icmp eq i32 %135, 3
   br i1 %136, label %137, label %140
 
 137:                                              ; preds = %130
   %138 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %133, i64 0, i32 10
-  %139 = load i64, i64* %138, align 8, !tbaa !530
+  %139 = load atomic i64, i64* %138 unordered, align 8, !tbaa !534
   br label %144
 
 140:                                              ; preds = %130
   %141 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %133, i64 0, i32 13
-  %142 = load i64, i64* %141, align 32, !tbaa !445
+  %142 = load atomic i64, i64* %141 unordered, align 32, !tbaa !449
   %143 = shl nuw i64 1, %142
   br label %144
 
 144:                                              ; preds = %140, %137
   %145 = phi i64 [ %139, %137 ], [ %143, %140 ]
   %146 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %11, i64 0, i32 0
-  %147 = load i8, i8* %146, align 8, !tbaa !546
+  %147 = load atomic i8, i8* %146 unordered, align 8, !tbaa !550
   %148 = icmp eq i8 %147, 0
   br i1 %148, label %149, label %_mi_segment_page_start.exit
 
 149:                                              ; preds = %144
   %150 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %133, i64 0, i32 11
-  %151 = load i64, i64* %150, align 16, !tbaa !547
+  %151 = load atomic i64, i64* %150 unordered, align 16, !tbaa !551
   %152 = sub i64 %145, %151
   %153 = icmp ne i32 %17, 0
   %154 = icmp ult i32 %135, 2
@@ -47577,8 +48138,8 @@
   %164 = sub nsw i64 %18, %163
   %165 = icmp ult i64 %164, %18
   %166 = select i1 %165, i64 %164, i64 0
-  %spec.select7 = sub i64 %152, %166
-  ret i64 %spec.select7
+  %spec.select14 = sub i64 %152, %166
+  ret i64 %spec.select14
 
 _mi_segment_page_start.exit:                      ; preds = %149, %144, %128, %_mi_segment_page_start.exit1, %1
   %167 = phi i64 [ 0, %1 ], [ %127, %_mi_segment_page_start.exit1 ], [ %18, %128 ], [ %152, %149 ], [ %145, %144 ]
@@ -47588,17 +48149,17 @@
 ; Function Attrs: nounwind uwtable
 define internal fastcc i8* @_mi_heap_malloc_zero(%struct.mi_heap_s* %0, i64 %1) unnamed_addr #17 {
   %3 = icmp ult i64 %1, 1025
-  br i1 %3, label %4, label %22, !prof !436, !misexpect !437
+  br i1 %3, label %4, label %22, !prof !440, !misexpect !441
 
 4:                                                ; preds = %2
   %5 = add nuw nsw i64 %1, 7
   %6 = lshr i64 %5, 3
   %7 = getelementptr inbounds %struct.mi_heap_s, %struct.mi_heap_s* %0, i64 0, i32 1, i64 %6
-  %8 = load %struct.mi_page_s*, %struct.mi_page_s** %7, align 8, !tbaa !434
+  %8 = load atomic %struct.mi_page_s*, %struct.mi_page_s** %7 unordered, align 8, !tbaa !438
   %9 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %8, i64 0, i32 6
-  %10 = load %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %9, align 8, !tbaa !438
+  %10 = load atomic %"class.kotlin::gc::GCHandle"*, %"class.kotlin::gc::GCHandle"** %9 unordered, align 8, !tbaa !442
   %11 = icmp eq %"class.kotlin::gc::GCHandle"* %10, null
-  br i1 %11, label %12, label %14, !prof !284, !misexpect !285
+  br i1 %11, label %12, label %14, !prof !282, !misexpect !283
 
 12:                                               ; preds = %4
   %13 = tail call fastcc noalias i8* @_mi_malloc_generic(%struct.mi_heap_s* nonnull %0, i64 %1) #37
@@ -47606,13 +48167,13 @@
 
 14:                                               ; preds = %4
   %15 = getelementptr inbounds %struct.mi_page_s, %struct.mi_page_s* %8, i64 0, i32 7
-  %16 = load i32, i32* %15, align 8, !tbaa !442
+  %16 = load atomic i32, i32* %15 unordered, align 8, !tbaa !446
   %17 = add i32 %16, 1
-  store i32 %17, i32* %15, align 8, !tbaa !442
+  store i32 %17, i32* %15, align 8, !tbaa !446
   %18 = getelementptr %"class.kotlin::gc::GCHandle", %"class.kotlin::gc::GCHandle"* %10, i64 0, i32 0
-  %19 = load i64, i64* %18, align 8, !tbaa !443
+  %19 = load atomic i64, i64* %18 unordered, align 8, !tbaa !447
   %20 = bitcast %"class.kotlin::gc::GCHandle"** %9 to i64*
-  store i64 %19, i64* %20, align 8, !tbaa !438
+  store i64 %19, i64* %20, align 8, !tbaa !442
   %21 = bitcast %"class.kotlin::gc::GCHandle"* %10 to i8*
   br label %24
 
@@ -47631,10 +48192,10 @@
   %29 = inttoptr i64 %28 to %struct.mi_segment_s*
   %30 = and i64 %27, 4194303
   %31 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %29, i64 0, i32 13
-  %32 = load i64, i64* %31, align 32, !tbaa !445
+  %32 = load atomic i64, i64* %31 unordered, align 32, !tbaa !449
   %33 = lshr i64 %30, %32
   %34 = getelementptr inbounds %struct.mi_segment_s, %struct.mi_segment_s* %29, i64 0, i32 16, i64 %33, i32 5
-  %35 = load i8, i8* %34, align 1
+  %35 = load atomic i8, i8* %34 unordered, align 1
   %36 = and i8 %35, 1
   %37 = icmp ne i8 %36, 0
   %38 = icmp ugt i64 %1, 8
@@ -47643,7 +48204,7 @@
 
 40:                                               ; preds = %26
   %41 = bitcast i8* %25 to i64*
-  store i64 0, i64* %41, align 8, !tbaa !443
+  store i64 0, i64* %41, align 8, !tbaa !447
   br label %44
 
 42:                                               ; preds = %26
@@ -47657,7 +48218,7 @@
 
 ; Function Attrs: uwtable
 define weak i8* @Konan_cxa_demangle(i8* %0, i8* %1, i64* %2, i32* %3) #20 {
-  store i32 -2, i32* %3, align 4, !tbaa !73
+  store i32 -2, i32* %3, align 4, !tbaa !71
   ret i8* null
 }
 
@@ -47743,7 +48304,7 @@
 
 ; Function Attrs: nounwind uwtable
 define internal zeroext i1 @_ZN5konan36isOnThreadExitNotSetOrAlreadyStartedEv() #17 {
-  %1 = load i32, i32* @_ZN5konan14terminationKeyE, align 4, !tbaa !73
+  %1 = load atomic i32, i32* @_ZN5konan14terminationKeyE unordered, align 4, !tbaa !71
   %2 = icmp eq i32 %1, 0
   br i1 %2, label %6, label %3
 
@@ -47788,7 +48349,7 @@
   ]
 
 6:                                                ; preds = %3
-  store i8 0, i8* %0, align 1, !tbaa !51
+  store i8 0, i8* %0, align 1, !tbaa !50
   br label %_ZN6kotlin13VFormatToSpanENS_11std_support4spanIcLm18446744073709551615EEEPKcP13__va_list_tag.exit
 
 7:                                                ; preds = %3
@@ -47843,7 +48404,7 @@
   ]
 
 8:                                                ; preds = %2
-  store i8 0, i8* %6, align 1, !tbaa !51
+  store i8 0, i8* %6, align 1, !tbaa !50
   br label %_ZN6kotlin13VFormatToSpanENS_11std_support4spanIcLm18446744073709551615EEEPKcP13__va_list_tag.exit
 
 9:                                                ; preds = %2
@@ -47897,9 +48458,9 @@
   call fastcc void @_ZN6kotlin8internal20GetCurrentStackTraceEm(%"class.std::vector.195"* noalias nonnull align 8 %2) #37
   %4 = getelementptr inbounds %"class.std::vector.195", %"class.std::vector.195"* %2, i64 0, i32 0, i32 0, i32 1
   %5 = bitcast i8*** %4 to i64*
-  %6 = load i64, i64* %5, align 8, !tbaa !587
+  %6 = load atomic i64, i64* %5 unordered, align 8, !tbaa !591
   %7 = bitcast %"class.std::vector.195"* %2 to i64*
-  %8 = load i64, i64* %7, align 8, !tbaa !590
+  %8 = load atomic i64, i64* %7 unordered, align 8, !tbaa !594
   %9 = sub i64 %6, %8
   %10 = ashr exact i64 %9, 3
   %11 = bitcast %"class.kotlin::StackTrace.198"* %0 to i8*
@@ -47918,12 +48479,12 @@
 19:                                               ; preds = %16, %1
   %20 = phi i8** [ %18, %16 ], [ null, %1 ]
   %21 = getelementptr inbounds %"class.kotlin::StackTrace.198", %"class.kotlin::StackTrace.198"* %0, i64 0, i32 0, i32 0, i32 0, i32 0
-  store i8** %20, i8*** %21, align 8, !tbaa !590
+  store i8** %20, i8*** %21, align 8, !tbaa !594
   %22 = getelementptr inbounds %"class.kotlin::StackTrace.198", %"class.kotlin::StackTrace.198"* %0, i64 0, i32 0, i32 0, i32 0, i32 1
-  store i8** %20, i8*** %22, align 8, !tbaa !587
+  store i8** %20, i8*** %22, align 8, !tbaa !591
   %23 = getelementptr inbounds i8*, i8** %20, i64 %10
   %24 = getelementptr inbounds %"class.kotlin::StackTrace.198", %"class.kotlin::StackTrace.198"* %0, i64 0, i32 0, i32 0, i32 0, i32 2
-  store i8** %23, i8*** %24, align 8, !tbaa !591
+  store i8** %23, i8*** %24, align 8, !tbaa !595
   %25 = getelementptr inbounds %"class.std::vector.195", %"class.std::vector.195"* %2, i64 0, i32 0, i32 0, i32 0
   %26 = icmp eq i8** %13, %15
   br i1 %26, label %133, label %27
@@ -47969,58 +48530,58 @@
   %57 = getelementptr i8*, i8** %20, i64 %55
   %58 = getelementptr i8*, i8** %13, i64 %55
   %59 = bitcast i8** %58 to <2 x i64>*
-  %60 = load <2 x i64>, <2 x i64>* %59, align 8, !tbaa !3, !alias.scope !592
+  %60 = load <2 x i64>, <2 x i64>* %59, align 8, !tbaa !3, !alias.scope !596
   %61 = getelementptr i8*, i8** %58, i64 2
   %62 = bitcast i8** %61 to <2 x i64>*
-  %63 = load <2 x i64>, <2 x i64>* %62, align 8, !tbaa !3, !alias.scope !592
+  %63 = load <2 x i64>, <2 x i64>* %62, align 8, !tbaa !3, !alias.scope !596
   %64 = bitcast i8** %57 to <2 x i64>*
-  store <2 x i64> %60, <2 x i64>* %64, align 8, !tbaa !3, !alias.scope !595, !noalias !592
+  store <2 x i64> %60, <2 x i64>* %64, align 8, !tbaa !3, !alias.scope !599, !noalias !596
   %65 = getelementptr i8*, i8** %57, i64 2
   %66 = bitcast i8** %65 to <2 x i64>*
-  store <2 x i64> %63, <2 x i64>* %66, align 8, !tbaa !3, !alias.scope !595, !noalias !592
+  store <2 x i64> %63, <2 x i64>* %66, align 8, !tbaa !3, !alias.scope !599, !noalias !596
   %67 = or i64 %55, 4
   %68 = getelementptr i8*, i8** %20, i64 %67
   %69 = getelementptr i8*, i8** %13, i64 %67
   %70 = bitcast i8** %69 to <2 x i64>*
-  %71 = load <2 x i64>, <2 x i64>* %70, align 8, !tbaa !3, !alias.scope !592
+  %71 = load <2 x i64>, <2 x i64>* %70, align 8, !tbaa !3, !alias.scope !596
   %72 = getelementptr i8*, i8** %69, i64 2
   %73 = bitcast i8** %72 to <2 x i64>*
-  %74 = load <2 x i64>, <2 x i64>* %73, align 8, !tbaa !3, !alias.scope !592
+  %74 = load <2 x i64>, <2 x i64>* %73, align 8, !tbaa !3, !alias.scope !596
   %75 = bitcast i8** %68 to <2 x i64>*
-  store <2 x i64> %71, <2 x i64>* %75, align 8, !tbaa !3, !alias.scope !595, !noalias !592
+  store <2 x i64> %71, <2 x i64>* %75, align 8, !tbaa !3, !alias.scope !599, !noalias !596
   %76 = getelementptr i8*, i8** %68, i64 2
   %77 = bitcast i8** %76 to <2 x i64>*
-  store <2 x i64> %74, <2 x i64>* %77, align 8, !tbaa !3, !alias.scope !595, !noalias !592
+  store <2 x i64> %74, <2 x i64>* %77, align 8, !tbaa !3, !alias.scope !599, !noalias !596
   %78 = or i64 %55, 8
   %79 = getelementptr i8*, i8** %20, i64 %78
   %80 = getelementptr i8*, i8** %13, i64 %78
   %81 = bitcast i8** %80 to <2 x i64>*
-  %82 = load <2 x i64>, <2 x i64>* %81, align 8, !tbaa !3, !alias.scope !592
+  %82 = load <2 x i64>, <2 x i64>* %81, align 8, !tbaa !3, !alias.scope !596
   %83 = getelementptr i8*, i8** %80, i64 2
   %84 = bitcast i8** %83 to <2 x i64>*
-  %85 = load <2 x i64>, <2 x i64>* %84, align 8, !tbaa !3, !alias.scope !592
+  %85 = load <2 x i64>, <2 x i64>* %84, align 8, !tbaa !3, !alias.scope !596
   %86 = bitcast i8** %79 to <2 x i64>*
-  store <2 x i64> %82, <2 x i64>* %86, align 8, !tbaa !3, !alias.scope !595, !noalias !592
+  store <2 x i64> %82, <2 x i64>* %86, align 8, !tbaa !3, !alias.scope !599, !noalias !596
   %87 = getelementptr i8*, i8** %79, i64 2
   %88 = bitcast i8** %87 to <2 x i64>*
-  store <2 x i64> %85, <2 x i64>* %88, align 8, !tbaa !3, !alias.scope !595, !noalias !592
+  store <2 x i64> %85, <2 x i64>* %88, align 8, !tbaa !3, !alias.scope !599, !noalias !596
   %89 = or i64 %55, 12
   %90 = getelementptr i8*, i8** %20, i64 %89
   %91 = getelementptr i8*, i8** %13, i64 %89
   %92 = bitcast i8** %91 to <2 x i64>*
-  %93 = load <2 x i64>, <2 x i64>* %92, align 8, !tbaa !3, !alias.scope !592
+  %93 = load <2 x i64>, <2 x i64>* %92, align 8, !tbaa !3, !alias.scope !596
   %94 = getelementptr i8*, i8** %91, i64 2
   %95 = bitcast i8** %94 to <2 x i64>*
-  %96 = load <2 x i64>, <2 x i64>* %95, align 8, !tbaa !3, !alias.scope !592
+  %96 = load <2 x i64>, <2 x i64>* %95, align 8, !tbaa !3, !alias.scope !596
   %97 = bitcast i8** %90 to <2 x i64>*
-  store <2 x i64> %93, <2 x i64>* %97, align 8, !tbaa !3, !alias.scope !595, !noalias !592
+  store <2 x i64> %93, <2 x i64>* %97, align 8, !tbaa !3, !alias.scope !599, !noalias !596
   %98 = getelementptr i8*, i8** %90, i64 2
   %99 = bitcast i8** %98 to <2 x i64>*
-  store <2 x i64> %96, <2 x i64>* %99, align 8, !tbaa !3, !alias.scope !595, !noalias !592
+  store <2 x i64> %96, <2 x i64>* %99, align 8, !tbaa !3, !alias.scope !599, !noalias !596
   %100 = add i64 %55, 16
   %101 = add i64 %56, -4
   %102 = icmp eq i64 %101, 0
-  br i1 %102, label %.loopexit2, label %54, !llvm.loop !597
+  br i1 %102, label %.loopexit2, label %54, !llvm.loop !601
 
 .loopexit2:                                       ; preds = %54, %43
   %103 = phi i64 [ 0, %43 ], [ %100, %54 ]
@@ -48033,19 +48594,19 @@
   %107 = getelementptr i8*, i8** %20, i64 %105
   %108 = getelementptr i8*, i8** %13, i64 %105
   %109 = bitcast i8** %108 to <2 x i64>*
-  %110 = load <2 x i64>, <2 x i64>* %109, align 8, !tbaa !3, !alias.scope !592
+  %110 = load <2 x i64>, <2 x i64>* %109, align 8, !tbaa !3, !alias.scope !596
   %111 = getelementptr i8*, i8** %108, i64 2
   %112 = bitcast i8** %111 to <2 x i64>*
-  %113 = load <2 x i64>, <2 x i64>* %112, align 8, !tbaa !3, !alias.scope !592
+  %113 = load <2 x i64>, <2 x i64>* %112, align 8, !tbaa !3, !alias.scope !596
   %114 = bitcast i8** %107 to <2 x i64>*
-  store <2 x i64> %110, <2 x i64>* %114, align 8, !tbaa !3, !alias.scope !595, !noalias !592
+  store <2 x i64> %110, <2 x i64>* %114, align 8, !tbaa !3, !alias.scope !599, !noalias !596
   %115 = getelementptr i8*, i8** %107, i64 2
   %116 = bitcast i8** %115 to <2 x i64>*
-  store <2 x i64> %113, <2 x i64>* %116, align 8, !tbaa !3, !alias.scope !595, !noalias !592
+  store <2 x i64> %113, <2 x i64>* %116, align 8, !tbaa !3, !alias.scope !599, !noalias !596
   %117 = add i64 %105, 4
   %118 = add nsw i64 %106, -1
   %119 = icmp eq i64 %118, 0
-  br i1 %119, label %.loopexit1, label %.preheader, !llvm.loop !598
+  br i1 %119, label %.loopexit1, label %.preheader, !llvm.loop !602
 
 .loopexit1:                                       ; preds = %.preheader, %.loopexit2
   %120 = icmp eq i64 %34, %44
@@ -48060,22 +48621,22 @@
   %125 = phi i8** [ %131, %124 ], [ %122, %121 ]
   %126 = phi i8** [ %130, %124 ], [ %123, %121 ]
   %127 = bitcast i8** %126 to i64*
-  %128 = load i64, i64* %127, align 8, !tbaa !3
+  %128 = load atomic i64, i64* %127 unordered, align 8, !tbaa !3
   %129 = bitcast i8** %125 to i64*
   store i64 %128, i64* %129, align 8, !tbaa !3
   %130 = getelementptr inbounds i8*, i8** %126, i64 1
   %131 = getelementptr inbounds i8*, i8** %125, i64 1
   %132 = icmp eq i8** %130, %15
-  br i1 %132, label %.loopexit, label %124, !llvm.loop !599
+  br i1 %132, label %.loopexit, label %124, !llvm.loop !603
 
 .loopexit:                                        ; preds = %124
-  %.pre = load i8**, i8*** %25, align 8, !tbaa !590
+  %.pre = load atomic i8**, i8*** %25 unordered, align 8, !tbaa !594
   br label %133
 
 133:                                              ; preds = %.loopexit, %.loopexit1, %19
   %134 = phi i8** [ %13, %19 ], [ %13, %.loopexit1 ], [ %.pre, %.loopexit ]
   %135 = phi i8** [ %20, %19 ], [ %45, %.loopexit1 ], [ %131, %.loopexit ]
-  store i8** %135, i8*** %22, align 8, !tbaa !587
+  store i8** %135, i8*** %22, align 8, !tbaa !591
   %136 = icmp eq i8** %134, null
   br i1 %136, label %139, label %137
 
@@ -48109,7 +48670,7 @@
   call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(32) %15, i8 0, i64 32, i1 false)
   %16 = call i32 @dladdr(i8* %3, %struct.Dl_info* nonnull %10) #37
   %17 = getelementptr inbounds %struct.Dl_info, %struct.Dl_info* %10, i64 0, i32 0
-  %18 = load i8*, i8** %17, align 8, !tbaa !600
+  %18 = load atomic i8*, i8** %17 unordered, align 8, !tbaa !604
   %19 = icmp eq i8* %18, null
   br i1 %19, label %25, label %20
 
@@ -48134,20 +48695,20 @@
 
 32:                                               ; preds = %28
   %33 = getelementptr inbounds %struct.Dl_info, %struct.Dl_info* %8, i64 0, i32 2
-  %34 = load i8*, i8** %33, align 8, !tbaa !602
+  %34 = load atomic i8*, i8** %33 unordered, align 8, !tbaa !606
   %35 = icmp eq i8* %34, null
   br i1 %35, label %41, label %36
 
 36:                                               ; preds = %32
   %37 = getelementptr inbounds %struct.Dl_info, %struct.Dl_info* %8, i64 0, i32 3
   %38 = bitcast i8** %37 to i64*
-  %39 = load i64, i64* %38, align 8, !tbaa !603
+  %39 = load atomic i64, i64* %38 unordered, align 8, !tbaa !607
   %40 = sub nsw i64 %14, %39
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %29) #37
   br label %265
 
 41:                                               ; preds = %32, %28
-  %42 = load %"class.std::vector.169"*, %"class.std::vector.169"** @_ZN12_GLOBAL__N_17symbolsE, align 8, !tbaa !3
+  %42 = load atomic %"class.std::vector.169"*, %"class.std::vector.169"** @_ZN12_GLOBAL__N_17symbolsE unordered, align 8, !tbaa !3
   %43 = icmp eq %"class.std::vector.169"* %42, null
   br i1 %43, label %44, label %.loopexit9
 
@@ -48178,7 +48739,7 @@
 
 58:                                               ; preds = %53
   %59 = getelementptr inbounds %struct.stat.204, %struct.stat.204* %7, i64 0, i32 8
-  %60 = load i64, i64* %59, align 8, !tbaa !604
+  %60 = load atomic i64, i64* %59 unordered, align 8, !tbaa !608
   %61 = call i8* @mmap(i8* null, i64 %60, i32 1, i32 2, i32 %51, i64 0) #37
   %62 = icmp eq i8* %61, inttoptr (i64 -1 to i8*)
   %63 = bitcast i8* %61 to %struct.Elf64_Ehdr*
@@ -48196,59 +48757,59 @@
 67:                                               ; preds = %65
   %68 = getelementptr inbounds i8, i8* %61, i64 40
   %69 = bitcast i8* %68 to i64*
-  %70 = load i64, i64* %69, align 8, !tbaa !606
+  %70 = load atomic i64, i64* %69 unordered, align 8, !tbaa !610
   %71 = getelementptr inbounds %struct.Elf64_Ehdr, %struct.Elf64_Ehdr* %63, i64 0, i32 0, i64 %70
   %72 = bitcast i8* %71 to %struct.b_elf_shdr*
   %73 = getelementptr inbounds i8, i8* %61, i64 60
   %74 = bitcast i8* %73 to i16*
-  %75 = load i16, i16* %74, align 4, !tbaa !608
+  %75 = load atomic i16, i16* %74 unordered, align 4, !tbaa !612
   %76 = icmp eq i16 %75, 0
   br i1 %76, label %.loopexit9, label %.preheader8
 
 .preheader8:                                      ; preds = %225, %67
   %77 = phi i64 [ %226, %225 ], [ 0, %67 ]
   %78 = getelementptr inbounds %struct.b_elf_shdr, %struct.b_elf_shdr* %72, i64 %77, i32 1
-  %79 = load i32, i32* %78, align 4, !tbaa !609
+  %79 = load atomic i32, i32* %78 unordered, align 4, !tbaa !613
   %80 = icmp eq i32 %79, 2
   br i1 %80, label %81, label %152
 
 81:                                               ; preds = %.preheader8
   %82 = getelementptr inbounds %struct.b_elf_shdr, %struct.b_elf_shdr* %72, i64 %77, i32 4
-  %83 = load i64, i64* %82, align 8, !tbaa !611
+  %83 = load atomic i64, i64* %82 unordered, align 8, !tbaa !615
   %84 = getelementptr inbounds %struct.Elf64_Ehdr, %struct.Elf64_Ehdr* %63, i64 0, i32 0, i64 %83
   %85 = getelementptr inbounds %struct.b_elf_shdr, %struct.b_elf_shdr* %72, i64 %77, i32 5
-  %86 = load i64, i64* %85, align 8, !tbaa !612
+  %86 = load atomic i64, i64* %85 unordered, align 8, !tbaa !616
   %87 = getelementptr inbounds i8, i8* %84, i64 %86
   %88 = getelementptr inbounds %struct.b_elf_shdr, %struct.b_elf_shdr* %72, i64 %77, i32 6
-  %89 = load i32, i32* %88, align 8, !tbaa !613
+  %89 = load atomic i32, i32* %88 unordered, align 8, !tbaa !617
   %90 = zext i32 %89 to i64
   %91 = getelementptr inbounds %struct.b_elf_shdr, %struct.b_elf_shdr* %72, i64 %90, i32 4
-  %92 = load i64, i64* %91, align 8, !tbaa !611
+  %92 = load atomic i64, i64* %91 unordered, align 8, !tbaa !615
   %93 = getelementptr inbounds %struct.Elf64_Ehdr, %struct.Elf64_Ehdr* %63, i64 0, i32 0, i64 %92
-  %94 = load %"class.std::vector.169"*, %"class.std::vector.169"** @_ZN12_GLOBAL__N_17symbolsE, align 8, !tbaa !3
+  %94 = load atomic %"class.std::vector.169"*, %"class.std::vector.169"** @_ZN12_GLOBAL__N_17symbolsE unordered, align 8, !tbaa !3
   %95 = getelementptr inbounds %"class.std::vector.169", %"class.std::vector.169"* %94, i64 0, i32 0, i32 0, i32 1
-  %96 = load %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %95, align 8, !tbaa !614
+  %96 = load atomic %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %95 unordered, align 8, !tbaa !618
   %97 = getelementptr inbounds %"class.std::vector.169", %"class.std::vector.169"* %94, i64 0, i32 0, i32 0, i32 2
-  %98 = load %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %97, align 8, !tbaa !617
+  %98 = load atomic %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %97 unordered, align 8, !tbaa !621
   %99 = icmp eq %"struct.(anonymous namespace)::SymRecord"* %96, %98
   br i1 %99, label %107, label %100
 
 100:                                              ; preds = %81
   %101 = bitcast %"struct.(anonymous namespace)::SymRecord"* %96 to i8**
-  store i8* %84, i8** %101, align 8, !tbaa.struct !618
+  store i8* %84, i8** %101, align 8, !tbaa.struct !622
   %102 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %96, i64 0, i32 1
   %103 = bitcast %struct.b_elf_sym** %102 to i8**
-  store i8* %87, i8** %103, align 8, !tbaa.struct !618
+  store i8* %87, i8** %103, align 8, !tbaa.struct !622
   %104 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %96, i64 0, i32 2
-  store i8* %93, i8** %104, align 8, !tbaa.struct !618
-  %105 = load %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %95, align 8, !tbaa !614
+  store i8* %93, i8** %104, align 8, !tbaa.struct !622
+  %105 = load atomic %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %95 unordered, align 8, !tbaa !618
   %106 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %105, i64 1
   br label %148
 
 107:                                              ; preds = %81
   %108 = ptrtoint %"struct.(anonymous namespace)::SymRecord"* %96 to i64
   %109 = bitcast %"class.std::vector.169"* %94 to i64*
-  %110 = load i64, i64* %109, align 8, !tbaa !619
+  %110 = load atomic i64, i64* %109 unordered, align 8, !tbaa !623
   %111 = sub i64 %108, %110
   %112 = sdiv exact i64 %111, 24
   %113 = icmp eq i64 %111, 0
@@ -48271,12 +48832,12 @@
   %126 = phi %"struct.(anonymous namespace)::SymRecord"* [ %124, %122 ], [ null, %107 ]
   %127 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %126, i64 %112
   %128 = bitcast %"struct.(anonymous namespace)::SymRecord"* %127 to i8**
-  store i8* %84, i8** %128, align 8, !tbaa.struct !618
+  store i8* %84, i8** %128, align 8, !tbaa.struct !622
   %129 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %126, i64 %112, i32 1
   %130 = bitcast %struct.b_elf_sym** %129 to i8**
-  store i8* %87, i8** %130, align 8, !tbaa.struct !618
+  store i8* %87, i8** %130, align 8, !tbaa.struct !622
   %131 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %126, i64 %112, i32 2
-  store i8* %93, i8** %131, align 8, !tbaa.struct !618
+  store i8* %93, i8** %131, align 8, !tbaa.struct !622
   %132 = icmp eq %"struct.(anonymous namespace)::SymRecord"* %96, %120
   br i1 %132, label %.loopexit7, label %.preheader6
 
@@ -48285,7 +48846,7 @@
   %134 = phi %"struct.(anonymous namespace)::SymRecord"* [ %137, %.preheader6 ], [ %120, %125 ]
   %135 = bitcast %"struct.(anonymous namespace)::SymRecord"* %133 to i8*
   %136 = bitcast %"struct.(anonymous namespace)::SymRecord"* %134 to i8*
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %135, i8* nonnull align 8 dereferenceable(24) %136, i64 24, i1 false) #37, !tbaa.struct !618
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %135, i8* nonnull align 8 dereferenceable(24) %136, i64 24, i1 false) #37, !tbaa.struct !622
   %137 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %134, i64 1
   %138 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %133, i64 1
   %139 = icmp eq %"struct.(anonymous namespace)::SymRecord"* %137, %96
@@ -48304,8 +48865,8 @@
 
 145:                                              ; preds = %143, %.loopexit7
   %146 = getelementptr %"class.std::vector.169", %"class.std::vector.169"* %94, i64 0, i32 0, i32 0, i32 0
-  store %"struct.(anonymous namespace)::SymRecord"* %126, %"struct.(anonymous namespace)::SymRecord"** %146, align 8, !tbaa !619
-  store %"struct.(anonymous namespace)::SymRecord"* %141, %"struct.(anonymous namespace)::SymRecord"** %95, align 8, !tbaa !614
+  store %"struct.(anonymous namespace)::SymRecord"* %126, %"struct.(anonymous namespace)::SymRecord"** %146, align 8, !tbaa !623
+  store %"struct.(anonymous namespace)::SymRecord"* %141, %"struct.(anonymous namespace)::SymRecord"** %95, align 8, !tbaa !618
   %147 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %126, i64 %119
   br label %148
 
@@ -48313,7 +48874,7 @@
   %149 = phi %"struct.(anonymous namespace)::SymRecord"** [ %97, %145 ], [ %95, %100 ]
   %150 = phi %"struct.(anonymous namespace)::SymRecord"* [ %147, %145 ], [ %106, %100 ]
   store %"struct.(anonymous namespace)::SymRecord"* %150, %"struct.(anonymous namespace)::SymRecord"** %149, align 8, !tbaa !3
-  %151 = load i32, i32* %78, align 4, !tbaa !609
+  %151 = load atomic i32, i32* %78 unordered, align 4, !tbaa !613
   br label %152
 
 152:                                              ; preds = %148, %.preheader8
@@ -48323,41 +48884,41 @@
 
 155:                                              ; preds = %152
   %156 = getelementptr inbounds %struct.b_elf_shdr, %struct.b_elf_shdr* %72, i64 %77, i32 4
-  %157 = load i64, i64* %156, align 8, !tbaa !611
+  %157 = load atomic i64, i64* %156 unordered, align 8, !tbaa !615
   %158 = getelementptr inbounds %struct.Elf64_Ehdr, %struct.Elf64_Ehdr* %63, i64 0, i32 0, i64 %157
   %159 = getelementptr inbounds %struct.b_elf_shdr, %struct.b_elf_shdr* %72, i64 %77, i32 5
-  %160 = load i64, i64* %159, align 8, !tbaa !612
+  %160 = load atomic i64, i64* %159 unordered, align 8, !tbaa !616
   %161 = getelementptr inbounds i8, i8* %158, i64 %160
   %162 = getelementptr inbounds %struct.b_elf_shdr, %struct.b_elf_shdr* %72, i64 %77, i32 6
-  %163 = load i32, i32* %162, align 8, !tbaa !613
+  %163 = load atomic i32, i32* %162 unordered, align 8, !tbaa !617
   %164 = zext i32 %163 to i64
   %165 = getelementptr inbounds %struct.b_elf_shdr, %struct.b_elf_shdr* %72, i64 %164, i32 4
-  %166 = load i64, i64* %165, align 8, !tbaa !611
+  %166 = load atomic i64, i64* %165 unordered, align 8, !tbaa !615
   %167 = getelementptr inbounds %struct.Elf64_Ehdr, %struct.Elf64_Ehdr* %63, i64 0, i32 0, i64 %166
-  %168 = load %"class.std::vector.169"*, %"class.std::vector.169"** @_ZN12_GLOBAL__N_17symbolsE, align 8, !tbaa !3
+  %168 = load atomic %"class.std::vector.169"*, %"class.std::vector.169"** @_ZN12_GLOBAL__N_17symbolsE unordered, align 8, !tbaa !3
   %169 = getelementptr inbounds %"class.std::vector.169", %"class.std::vector.169"* %168, i64 0, i32 0, i32 0, i32 1
-  %170 = load %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %169, align 8, !tbaa !614
+  %170 = load atomic %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %169 unordered, align 8, !tbaa !618
   %171 = getelementptr inbounds %"class.std::vector.169", %"class.std::vector.169"* %168, i64 0, i32 0, i32 0, i32 2
-  %172 = load %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %171, align 8, !tbaa !617
+  %172 = load atomic %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %171 unordered, align 8, !tbaa !621
   %173 = icmp eq %"struct.(anonymous namespace)::SymRecord"* %170, %172
   br i1 %173, label %181, label %174
 
 174:                                              ; preds = %155
   %175 = bitcast %"struct.(anonymous namespace)::SymRecord"* %170 to i8**
-  store i8* %158, i8** %175, align 8, !tbaa.struct !618
+  store i8* %158, i8** %175, align 8, !tbaa.struct !622
   %176 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %170, i64 0, i32 1
   %177 = bitcast %struct.b_elf_sym** %176 to i8**
-  store i8* %161, i8** %177, align 8, !tbaa.struct !618
+  store i8* %161, i8** %177, align 8, !tbaa.struct !622
   %178 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %170, i64 0, i32 2
-  store i8* %167, i8** %178, align 8, !tbaa.struct !618
-  %179 = load %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %169, align 8, !tbaa !614
+  store i8* %167, i8** %178, align 8, !tbaa.struct !622
+  %179 = load atomic %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %169 unordered, align 8, !tbaa !618
   %180 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %179, i64 1
   br label %222
 
 181:                                              ; preds = %155
   %182 = ptrtoint %"struct.(anonymous namespace)::SymRecord"* %170 to i64
   %183 = bitcast %"class.std::vector.169"* %168 to i64*
-  %184 = load i64, i64* %183, align 8, !tbaa !619
+  %184 = load atomic i64, i64* %183 unordered, align 8, !tbaa !623
   %185 = sub i64 %182, %184
   %186 = sdiv exact i64 %185, 24
   %187 = icmp eq i64 %185, 0
@@ -48380,12 +48941,12 @@
   %200 = phi %"struct.(anonymous namespace)::SymRecord"* [ %198, %196 ], [ null, %181 ]
   %201 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %200, i64 %186
   %202 = bitcast %"struct.(anonymous namespace)::SymRecord"* %201 to i8**
-  store i8* %158, i8** %202, align 8, !tbaa.struct !618
+  store i8* %158, i8** %202, align 8, !tbaa.struct !622
   %203 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %200, i64 %186, i32 1
   %204 = bitcast %struct.b_elf_sym** %203 to i8**
-  store i8* %161, i8** %204, align 8, !tbaa.struct !618
+  store i8* %161, i8** %204, align 8, !tbaa.struct !622
   %205 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %200, i64 %186, i32 2
-  store i8* %167, i8** %205, align 8, !tbaa.struct !618
+  store i8* %167, i8** %205, align 8, !tbaa.struct !622
   %206 = icmp eq %"struct.(anonymous namespace)::SymRecord"* %170, %194
   br i1 %206, label %.loopexit5, label %.preheader4
 
@@ -48394,7 +48955,7 @@
   %208 = phi %"struct.(anonymous namespace)::SymRecord"* [ %211, %.preheader4 ], [ %194, %199 ]
   %209 = bitcast %"struct.(anonymous namespace)::SymRecord"* %207 to i8*
   %210 = bitcast %"struct.(anonymous namespace)::SymRecord"* %208 to i8*
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %209, i8* nonnull align 8 dereferenceable(24) %210, i64 24, i1 false) #37, !tbaa.struct !618
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %209, i8* nonnull align 8 dereferenceable(24) %210, i64 24, i1 false) #37, !tbaa.struct !622
   %211 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %208, i64 1
   %212 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %207, i64 1
   %213 = icmp eq %"struct.(anonymous namespace)::SymRecord"* %211, %170
@@ -48413,8 +48974,8 @@
 
 219:                                              ; preds = %217, %.loopexit5
   %220 = getelementptr %"class.std::vector.169", %"class.std::vector.169"* %168, i64 0, i32 0, i32 0, i32 0
-  store %"struct.(anonymous namespace)::SymRecord"* %200, %"struct.(anonymous namespace)::SymRecord"** %220, align 8, !tbaa !619
-  store %"struct.(anonymous namespace)::SymRecord"* %215, %"struct.(anonymous namespace)::SymRecord"** %169, align 8, !tbaa !614
+  store %"struct.(anonymous namespace)::SymRecord"* %200, %"struct.(anonymous namespace)::SymRecord"** %220, align 8, !tbaa !623
+  store %"struct.(anonymous namespace)::SymRecord"* %215, %"struct.(anonymous namespace)::SymRecord"** %169, align 8, !tbaa !618
   %221 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %200, i64 %193
   br label %222
 
@@ -48426,39 +48987,39 @@
 
 225:                                              ; preds = %222, %152
   %226 = add nuw nsw i64 %77, 1
-  %227 = load i16, i16* %74, align 4, !tbaa !608
+  %227 = load atomic i16, i16* %74 unordered, align 4, !tbaa !612
   %228 = zext i16 %227 to i64
   %229 = icmp ult i64 %226, %228
   br i1 %229, label %.preheader8, label %.loopexit9
 
 .loopexit9:                                       ; preds = %225, %67, %65, %64, %49, %41
-  %230 = load %"class.std::vector.169"*, %"class.std::vector.169"** @_ZN12_GLOBAL__N_17symbolsE, align 8, !tbaa !3
+  %230 = load atomic %"class.std::vector.169"*, %"class.std::vector.169"** @_ZN12_GLOBAL__N_17symbolsE unordered, align 8, !tbaa !3
   %231 = getelementptr %"class.std::vector.169", %"class.std::vector.169"* %230, i64 0, i32 0, i32 0, i32 0
-  %232 = load %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %231, align 8, !tbaa !3
+  %232 = load atomic %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %231 unordered, align 8, !tbaa !3
   %233 = getelementptr inbounds %"class.std::vector.169", %"class.std::vector.169"* %230, i64 0, i32 0, i32 0, i32 1
-  %234 = load %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %233, align 8, !tbaa !3
+  %234 = load atomic %"struct.(anonymous namespace)::SymRecord"*, %"struct.(anonymous namespace)::SymRecord"** %233 unordered, align 8, !tbaa !3
   %235 = icmp eq %"struct.(anonymous namespace)::SymRecord"* %232, %234
   br i1 %235, label %.loopexit3, label %.preheader2
 
 .preheader2:                                      ; preds = %.loopexit, %.loopexit9
   %236 = phi %"struct.(anonymous namespace)::SymRecord"* [ %254, %.loopexit ], [ %232, %.loopexit9 ]
   %237 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %236, i64 0, i32 0
-  %238 = load %struct.b_elf_sym*, %struct.b_elf_sym** %237, align 8, !tbaa.struct !618
+  %238 = load atomic %struct.b_elf_sym*, %struct.b_elf_sym** %237 unordered, align 8, !tbaa.struct !622
   %239 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %236, i64 0, i32 1
-  %240 = load %struct.b_elf_sym*, %struct.b_elf_sym** %239, align 8, !tbaa.struct !618
+  %240 = load atomic %struct.b_elf_sym*, %struct.b_elf_sym** %239 unordered, align 8, !tbaa.struct !622
   %241 = icmp ult %struct.b_elf_sym* %238, %240
   br i1 %241, label %.preheader, label %.loopexit
 
 .preheader:                                       ; preds = %251, %.preheader2
   %242 = phi %struct.b_elf_sym* [ %252, %251 ], [ %238, %.preheader2 ]
   %243 = getelementptr inbounds %struct.b_elf_sym, %struct.b_elf_sym* %242, i64 0, i32 4
-  %244 = load i64, i64* %243, align 8, !tbaa !620
+  %244 = load atomic i64, i64* %243 unordered, align 8, !tbaa !624
   %245 = icmp ugt i64 %244, %14
   br i1 %245, label %251, label %246
 
 246:                                              ; preds = %.preheader
   %247 = getelementptr inbounds %struct.b_elf_sym, %struct.b_elf_sym* %242, i64 0, i32 5
-  %248 = load i64, i64* %247, align 8, !tbaa !622
+  %248 = load atomic i64, i64* %247 unordered, align 8, !tbaa !626
   %249 = add i64 %248, %244
   %250 = icmp ugt i64 %249, %14
   br i1 %250, label %256, label %251
@@ -48479,10 +49040,10 @@
 
 256:                                              ; preds = %246
   %257 = getelementptr inbounds %"struct.(anonymous namespace)::SymRecord", %"struct.(anonymous namespace)::SymRecord"* %236, i64 0, i32 2
-  %258 = load i8*, i8** %257, align 8, !tbaa.struct !618
+  %258 = load atomic i8*, i8** %257 unordered, align 8, !tbaa.struct !622
   %259 = sub i64 %14, %244
   %260 = getelementptr inbounds %struct.b_elf_sym, %struct.b_elf_sym* %242, i64 0, i32 0
-  %261 = load i32, i32* %260, align 8, !tbaa !623
+  %261 = load atomic i32, i32* %260 unordered, align 8, !tbaa !627
   %262 = zext i32 %261 to i64
   %263 = getelementptr inbounds i8, i8* %258, i64 %262
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %29) #37
@@ -48494,7 +49055,7 @@
   %266 = phi i8* [ %263, %256 ], [ %34, %36 ]
   %267 = call i8* @strncpy(i8* nonnull dereferenceable(1) %12, i8* nonnull %266, i64 512) #37
   %268 = getelementptr inbounds [512 x i8], [512 x i8]* %9, i64 0, i64 511
-  store i8 0, i8* %268, align 1, !tbaa !51
+  store i8 0, i8* %268, align 1, !tbaa !50
   br label %AddressToSymbol.exit
 
 AddressToSymbol.exit:                             ; preds = %265, %256, %.loopexit3, %25
@@ -48522,7 +49083,7 @@
   ]
 
 280:                                              ; preds = %276
-  store i8 0, i8* %278, align 1, !tbaa !51
+  store i8 0, i8* %278, align 1, !tbaa !50
   br label %_ZN6kotlin13VFormatToSpanENS_11std_support4spanIcLm18446744073709551615EEEPKcP13__va_list_tag.exit
 
 281:                                              ; preds = %276
@@ -48547,16 +49108,16 @@
 ; Function Attrs: nounwind uwtable
 define internal fastcc void @_ZNSt6vectorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEED2Ev(%"class.std::vector.1"* nocapture readonly %0) unnamed_addr #17 align 2 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
   %2 = getelementptr inbounds %"class.std::vector.1", %"class.std::vector.1"* %0, i64 0, i32 0, i32 0, i32 0
-  %3 = load %"class.std::__cxx11::basic_string"*, %"class.std::__cxx11::basic_string"** %2, align 8, !tbaa !41
+  %3 = load atomic %"class.std::__cxx11::basic_string"*, %"class.std::__cxx11::basic_string"** %2 unordered, align 8, !tbaa !43
   %4 = getelementptr inbounds %"class.std::vector.1", %"class.std::vector.1"* %0, i64 0, i32 0, i32 0, i32 1
-  %5 = load %"class.std::__cxx11::basic_string"*, %"class.std::__cxx11::basic_string"** %4, align 8, !tbaa !44
+  %5 = load atomic %"class.std::__cxx11::basic_string"*, %"class.std::__cxx11::basic_string"** %4 unordered, align 8, !tbaa !44
   %6 = icmp eq %"class.std::__cxx11::basic_string"* %3, %5
   br i1 %6, label %19, label %.preheader
 
 .preheader:                                       ; preds = %14, %1
   %7 = phi %"class.std::__cxx11::basic_string"* [ %15, %14 ], [ %3, %1 ]
   %8 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %7, i64 0, i32 0, i32 0
-  %9 = load i8*, i8** %8, align 8, !tbaa !58
+  %9 = load atomic i8*, i8** %8 unordered, align 8, !tbaa !47
   %10 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %7, i64 0, i32 2
   %11 = bitcast %union.anon.108* %10 to i8*
   %12 = icmp eq i8* %9, %11
@@ -48572,7 +49133,7 @@
   br i1 %16, label %17, label %.preheader
 
 17:                                               ; preds = %14
-  %18 = load %"class.std::__cxx11::basic_string"*, %"class.std::__cxx11::basic_string"** %2, align 8, !tbaa !41
+  %18 = load atomic %"class.std::__cxx11::basic_string"*, %"class.std::__cxx11::basic_string"** %2 unordered, align 8, !tbaa !43
   br label %19
 
 19:                                               ; preds = %17, %1
@@ -48590,31 +49151,35 @@
 }
 
 ; Function Attrs: inlinehint nounwind uwtable
-define internal fastcc void @_ZN6kotlin31NativeOrUnregisteredThreadGuardD2Ev(%"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %.0.1.0.val, i32 %.0.1.1.val) unnamed_addr #19 align 2 personality i32 (...)* @__gxx_personality_v0 {
-  %1 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %.0.1.0.val, null
-  br i1 %1, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %2
+define internal fastcc void @_ZN6kotlin31NativeOrUnregisteredThreadGuardD2Ev(%"class.kotlin::NativeOrUnregisteredThreadGuard"* nocapture readonly %0) unnamed_addr #19 align 2 personality i32 (...)* @__gxx_personality_v0 {
+  %2 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %0, i64 0, i32 1, i32 0
+  %3 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %2 unordered, align 8, !tbaa !34
+  %4 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %3, null
+  br i1 %4, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %5
 
-2:                                                ; preds = %0
-  %3 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %.0.1.0.val, i64 328
-  %4 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %3 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %5 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %3 to i32*
-  %6 = atomicrmw xchg i32* %5, i32 %.0.1.1.val seq_cst, align 4
-  %7 = icmp eq i32 %6, 1
-  %8 = icmp eq i32 %.0.1.1.val, 0
-  %9 = and i1 %8, %7
-  br i1 %9, label %10, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
+5:                                                ; preds = %1
+  %6 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %0, i64 0, i32 1, i32 1
+  %7 = load atomic i32, i32* %6 unordered, align 8, !tbaa !38
+  %8 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %3, i64 328
+  %9 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %8 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %10 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %8 to i32*
+  %11 = atomicrmw xchg i32* %10, i32 %7 seq_cst, align 4
+  %12 = icmp eq i32 %11, 1
+  %13 = icmp eq i32 %7, 0
+  %14 = and i1 %13, %12
+  br i1 %14, label %15, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-10:                                               ; preds = %2
-  %11 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %12 = and i8 %11, 1
-  %13 = icmp eq i8 %12, 0
-  br i1 %13, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %14
+15:                                               ; preds = %5
+  %16 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %17 = and i8 %16, 1
+  %18 = icmp eq i8 %17, 0
+  br i1 %18, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %19
 
-14:                                               ; preds = %10
-  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %4) #37
+19:                                               ; preds = %15
+  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %9) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %14, %10, %2, %0
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %19, %15, %5, %1
   ret void
 }
 
@@ -48626,160 +49191,414 @@
 
 ; Function Attrs: noinline nounwind uwtable
 define internal fastcc void @_ZN6kotlin8internal20GetCurrentStackTraceEm(%"class.std::vector.195"* noalias nocapture align 8 %0) unnamed_addr #7 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
-  %.sroa.0 = alloca <2 x i64>, align 16
-  %2 = alloca i64, align 8
-  %3 = alloca %"struct.(anonymous namespace)::Backtrace", align 8
-  %4 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %.not = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, null
-  br i1 %.not, label %8, label %5
+  %2 = alloca %"class.kotlin::NativeOrUnregisteredThreadGuard", align 8
+  %3 = alloca %"class.std::vector.195", align 16
+  %4 = alloca i64, align 8
+  %5 = alloca %"struct.(anonymous namespace)::Backtrace", align 8
+  %6 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %2, i64 0, i32 0, i64 0
+  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %6) #37
+  %7 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %2, i64 0, i32 1
+  %8 = getelementptr inbounds %"class.kotlin::CalledFromNativeGuard", %"class.kotlin::CalledFromNativeGuard"* %7, i64 0, i32 0
+  store %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* null, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %8, align 8, !tbaa !34
+  %9 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %2, i64 0, i32 1, i32 1
+  store i32 1, i32* %9, align 8, !tbaa !38
+  %10 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %2, i64 0, i32 1, i32 2
+  store i8 0, i8* %10, align 4, !tbaa !39
+  %11 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %.not = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, null
+  br i1 %.not, label %17, label %12
 
-5:                                                ; preds = %1
-  %6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4, i64 0, i32 1, i32 8, i32 0, i32 0
-  %7 = atomicrmw xchg i32* %6, i32 1 seq_cst, align 4
-  %phi.cast = bitcast %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %4 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*
-  br label %8
+12:                                               ; preds = %1
+  %13 = ptrtoint %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11 to i64
+  %14 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 8, i32 0, i32 0
+  %15 = atomicrmw xchg i32* %14, i32 1 seq_cst, align 4
+  %16 = bitcast %"class.kotlin::CalledFromNativeGuard"* %7 to i64*
+  store i64 %13, i64* %16, align 8, !tbaa !34
+  store i32 %15, i32* %9, align 8, !tbaa !38
+  store i8 1, i8* %10, align 4, !tbaa !39
+  br label %17
 
-8:                                                ; preds = %5, %1
-  %.sroa.7.0 = phi i32 [ 1, %1 ], [ %7, %5 ]
-  %.sroa.3.0 = phi %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* [ null, %1 ], [ %phi.cast, %5 ]
-  %.sroa.0.0.sroa_cast47 = bitcast <2 x i64>* %.sroa.0 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 16, i8* nonnull %.sroa.0.0.sroa_cast47)
-  store <2 x i64> zeroinitializer, <2 x i64>* %.sroa.0, align 16
-  %9 = bitcast i64* %2 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %9) #37
-  store i64 0, i64* %2, align 8, !tbaa !89
-  %10 = invoke i32 @_Unwind_Backtrace(i32 (%struct._Unwind_Context*, i8*)* nonnull @_ZN12_GLOBAL__N_118depthCountCallbackEP15_Unwind_ContextPv, i8* nonnull %9)
-          to label %11 unwind label %14
+17:                                               ; preds = %12, %1
+  %18 = bitcast %"class.std::vector.195"* %3 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %18) #37
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 16 dereferenceable(24) %18, i8 0, i64 24, i1 false) #37
+  %19 = bitcast i64* %4 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %19) #37
+  store i64 0, i64* %4, align 8, !tbaa !87
+  %20 = invoke i32 @_Unwind_Backtrace(i32 (%struct._Unwind_Context*, i8*)* nonnull @_ZN12_GLOBAL__N_118depthCountCallbackEP15_Unwind_ContextPv, i8* nonnull %19)
+          to label %21 unwind label %24
 
-11:                                               ; preds = %8
-  %12 = load i64, i64* %2, align 8, !tbaa !89
-  %13 = icmp ugt i64 %12, 4
-  br i1 %13, label %17, label %46
+21:                                               ; preds = %17
+  %22 = load atomic i64, i64* %4 unordered, align 8, !tbaa !87
+  %23 = icmp ugt i64 %22, 4
+  br i1 %23, label %27, label %222
 
-14:                                               ; preds = %8
-  %15 = landingpad { i8*, i32 }
+24:                                               ; preds = %17
+  %25 = landingpad { i8*, i32 }
           catch i8* null
-  %16 = extractvalue { i8*, i32 } %15, 0
-  br label %66
+  %26 = extractvalue { i8*, i32 } %25, 0
+  br label %247
 
-17:                                               ; preds = %11
-  %18 = add i64 %12, -4
-  %19 = icmp ugt i64 %18, 2305843009213693951
-  br i1 %19, label %20, label %21
+27:                                               ; preds = %21
+  %28 = add i64 %22, -4
+  %29 = getelementptr inbounds %"class.std::vector.195", %"class.std::vector.195"* %3, i64 0, i32 0, i32 0, i32 1
+  %30 = bitcast i8*** %29 to i64*
+  %31 = load atomic i64, i64* %30 unordered, align 8, !tbaa !591
+  %32 = bitcast %"class.std::vector.195"* %3 to i64*
+  %33 = load atomic i64, i64* %32 unordered, align 16, !tbaa !594
+  %34 = sub i64 %31, %33
+  %35 = ashr exact i64 %34, 3
+  %36 = icmp ugt i64 %28, %35
+  %37 = inttoptr i64 %33 to i8**
+  %38 = inttoptr i64 %31 to i8**
+  br i1 %36, label %39, label %192
 
-20:                                               ; preds = %17
+39:                                               ; preds = %27
+  %40 = sub i64 %28, %35
+  %41 = icmp eq i64 %40, 0
+  br i1 %41, label %_ZNSt6vectorIPvN6kotlin11std_support9allocatorIS0_EEE17_M_default_appendEm.exit, label %42
+
+42:                                               ; preds = %39
+  %43 = getelementptr inbounds %"class.std::vector.195", %"class.std::vector.195"* %3, i64 0, i32 0, i32 0, i32 2
+  %44 = bitcast i8*** %43 to i64*
+  %45 = load atomic i64, i64* %44 unordered, align 16, !tbaa !595
+  %46 = sub i64 %45, %31
+  %47 = ashr exact i64 %46, 3
+  %48 = icmp ult i64 %35, 2305843009213693952
+  call void @llvm.assume(i1 %48) #37
+  %49 = xor i64 %35, 2305843009213693951
+  %50 = icmp ule i64 %47, %49
+  call void @llvm.assume(i1 %50) #37
+  %51 = icmp ult i64 %47, %40
+  br i1 %51, label %56, label %52
+
+52:                                               ; preds = %42
+  %53 = inttoptr i64 %31 to i8*
+  %54 = shl nuw i64 %40, 3
+  call void @llvm.memset.p0i8.i64(i8* align 8 %53, i8 0, i64 %54, i1 false) #37
+  %55 = getelementptr i8*, i8** %38, i64 %40
+  br label %189
+
+56:                                               ; preds = %42
+  %57 = icmp ult i64 %49, %40
+  br i1 %57, label %58, label %59
+
+58:                                               ; preds = %56
   call fastcc void @_ZSt20__throw_length_errorPKc(i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17.572, i64 0, i64 0)) #51
   unreachable
 
-21:                                               ; preds = %17
-  %.sroa.0.8.sroa_idx58 = getelementptr inbounds <2 x i64>, <2 x i64>* %.sroa.0, i64 0, i64 1
-  %.sroa.0.8.sroa_cast57 = bitcast i64* %.sroa.0.8.sroa_idx58 to i8***
-  %22 = call noalias i8* @calloc(i64 %18, i64 8) #37
-  %23 = bitcast i8* %22 to i8**
-  %24 = shl nuw i64 %18, 3
-  call void @llvm.memset.p0i8.i64(i8* align 8 %22, i8 0, i64 %24, i1 false) #37
-  %25 = bitcast <2 x i64>* %.sroa.0 to i8**
-  store i8* %22, i8** %25, align 16, !tbaa !590
-  %26 = getelementptr inbounds i8*, i8** %23, i64 %18
-  store i8** %26, i8*** %.sroa.0.8.sroa_cast57, align 8, !tbaa !587
-  %27 = ptrtoint i8* %22 to i64
-  %28 = ptrtoint i8** %26 to i64
-  %phi.cast84 = ptrtoint i8** %26 to i64
-  %29 = bitcast i8* %22 to i8**
-  %30 = bitcast %"struct.(anonymous namespace)::Backtrace"* %3 to i8*
-  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %30) #37
-  %31 = sub i64 %28, %27
-  %32 = ashr exact i64 %31, 3
-  %33 = getelementptr inbounds %"struct.(anonymous namespace)::Backtrace", %"struct.(anonymous namespace)::Backtrace"* %3, i64 0, i32 0
-  store i64 0, i64* %33, align 8, !tbaa !624
-  %34 = getelementptr inbounds %"struct.(anonymous namespace)::Backtrace", %"struct.(anonymous namespace)::Backtrace"* %3, i64 0, i32 1
-  store i64 4, i64* %34, align 8, !tbaa !627
-  %35 = getelementptr inbounds %"struct.(anonymous namespace)::Backtrace", %"struct.(anonymous namespace)::Backtrace"* %3, i64 0, i32 2, i32 0
-  %36 = bitcast i8*** %35 to i64*
-  store i64 %27, i64* %36, align 8, !tbaa.struct !628
-  %37 = getelementptr inbounds %"struct.(anonymous namespace)::Backtrace", %"struct.(anonymous namespace)::Backtrace"* %3, i64 0, i32 2, i32 1
-  store i64 %32, i64* %37, align 8, !tbaa.struct !628
-  %38 = invoke i32 @_Unwind_Backtrace(i32 (%struct._Unwind_Context*, i8*)* nonnull @_ZN12_GLOBAL__N_114unwindCallbackEP15_Unwind_ContextPv, i8* nonnull %30)
-          to label %42 unwind label %39
+59:                                               ; preds = %56
+  %60 = icmp ult i64 %35, %40
+  %61 = select i1 %60, i64 %40, i64 %35
+  %62 = add i64 %61, %35
+  %63 = icmp ult i64 %62, %35
+  %64 = icmp ugt i64 %62, 2305843009213693951
+  %65 = or i1 %63, %64
+  %66 = select i1 %65, i64 2305843009213693951, i64 %62
+  %67 = icmp eq i64 %66, 0
+  br i1 %67, label %71, label %68
 
-39:                                               ; preds = %21
-  %40 = landingpad { i8*, i32 }
+68:                                               ; preds = %59
+  %69 = call noalias i8* @calloc(i64 %66, i64 8) #37
+  %70 = bitcast i8* %69 to i8**
+  br label %71
+
+71:                                               ; preds = %68, %59
+  %72 = phi i8** [ %70, %68 ], [ null, %59 ]
+  %73 = getelementptr inbounds i8*, i8** %72, i64 %35
+  %74 = bitcast i8** %73 to i8*
+  %75 = shl nuw i64 %40, 3
+  call void @llvm.memset.p0i8.i64(i8* align 8 %74, i8 0, i64 %75, i1 false) #37
+  %76 = getelementptr inbounds %"class.std::vector.195", %"class.std::vector.195"* %3, i64 0, i32 0, i32 0, i32 0
+  %77 = icmp eq i8** %37, %38
+  br i1 %77, label %181, label %78
+
+78:                                               ; preds = %71
+  %79 = getelementptr i8*, i8** %38, i64 -1
+  %80 = ptrtoint i8** %79 to i64
+  %81 = sub i64 %80, %33
+  %82 = lshr i64 %81, 3
+  %83 = add nuw nsw i64 %82, 1
+  %84 = icmp ult i64 %81, 24
+  br i1 %84, label %169, label %85
+
+85:                                               ; preds = %78
+  %86 = getelementptr i8*, i8** %72, i64 %83
+  %87 = getelementptr i8*, i8** %37, i64 %83
+  %88 = icmp ult i8** %72, %87
+  %89 = icmp ugt i8** %86, %37
+  %90 = and i1 %88, %89
+  br i1 %90, label %169, label %91
+
+91:                                               ; preds = %85
+  %92 = and i64 %83, 4611686018427387900
+  %93 = getelementptr i8*, i8** %72, i64 %92
+  %94 = getelementptr i8*, i8** %37, i64 %92
+  %95 = add nsw i64 %92, -4
+  %96 = lshr exact i64 %95, 2
+  %97 = add nuw nsw i64 %96, 1
+  %98 = and i64 %97, 3
+  %99 = icmp ult i64 %95, 12
+  br i1 %99, label %.loopexit2, label %100
+
+100:                                              ; preds = %91
+  %101 = and i64 %97, 9223372036854775804
+  br label %102
+
+102:                                              ; preds = %102, %100
+  %103 = phi i64 [ 0, %100 ], [ %148, %102 ]
+  %104 = phi i64 [ %101, %100 ], [ %149, %102 ]
+  %105 = getelementptr i8*, i8** %72, i64 %103
+  %106 = getelementptr i8*, i8** %37, i64 %103
+  %107 = bitcast i8** %106 to <2 x i64>*
+  %108 = load <2 x i64>, <2 x i64>* %107, align 8, !tbaa !3, !alias.scope !628
+  %109 = getelementptr i8*, i8** %106, i64 2
+  %110 = bitcast i8** %109 to <2 x i64>*
+  %111 = load <2 x i64>, <2 x i64>* %110, align 8, !tbaa !3, !alias.scope !628
+  %112 = bitcast i8** %105 to <2 x i64>*
+  store <2 x i64> %108, <2 x i64>* %112, align 8, !tbaa !3, !alias.scope !631, !noalias !628
+  %113 = getelementptr i8*, i8** %105, i64 2
+  %114 = bitcast i8** %113 to <2 x i64>*
+  store <2 x i64> %111, <2 x i64>* %114, align 8, !tbaa !3, !alias.scope !631, !noalias !628
+  %115 = or i64 %103, 4
+  %116 = getelementptr i8*, i8** %72, i64 %115
+  %117 = getelementptr i8*, i8** %37, i64 %115
+  %118 = bitcast i8** %117 to <2 x i64>*
+  %119 = load <2 x i64>, <2 x i64>* %118, align 8, !tbaa !3, !alias.scope !628
+  %120 = getelementptr i8*, i8** %117, i64 2
+  %121 = bitcast i8** %120 to <2 x i64>*
+  %122 = load <2 x i64>, <2 x i64>* %121, align 8, !tbaa !3, !alias.scope !628
+  %123 = bitcast i8** %116 to <2 x i64>*
+  store <2 x i64> %119, <2 x i64>* %123, align 8, !tbaa !3, !alias.scope !631, !noalias !628
+  %124 = getelementptr i8*, i8** %116, i64 2
+  %125 = bitcast i8** %124 to <2 x i64>*
+  store <2 x i64> %122, <2 x i64>* %125, align 8, !tbaa !3, !alias.scope !631, !noalias !628
+  %126 = or i64 %103, 8
+  %127 = getelementptr i8*, i8** %72, i64 %126
+  %128 = getelementptr i8*, i8** %37, i64 %126
+  %129 = bitcast i8** %128 to <2 x i64>*
+  %130 = load <2 x i64>, <2 x i64>* %129, align 8, !tbaa !3, !alias.scope !628
+  %131 = getelementptr i8*, i8** %128, i64 2
+  %132 = bitcast i8** %131 to <2 x i64>*
+  %133 = load <2 x i64>, <2 x i64>* %132, align 8, !tbaa !3, !alias.scope !628
+  %134 = bitcast i8** %127 to <2 x i64>*
+  store <2 x i64> %130, <2 x i64>* %134, align 8, !tbaa !3, !alias.scope !631, !noalias !628
+  %135 = getelementptr i8*, i8** %127, i64 2
+  %136 = bitcast i8** %135 to <2 x i64>*
+  store <2 x i64> %133, <2 x i64>* %136, align 8, !tbaa !3, !alias.scope !631, !noalias !628
+  %137 = or i64 %103, 12
+  %138 = getelementptr i8*, i8** %72, i64 %137
+  %139 = getelementptr i8*, i8** %37, i64 %137
+  %140 = bitcast i8** %139 to <2 x i64>*
+  %141 = load <2 x i64>, <2 x i64>* %140, align 8, !tbaa !3, !alias.scope !628
+  %142 = getelementptr i8*, i8** %139, i64 2
+  %143 = bitcast i8** %142 to <2 x i64>*
+  %144 = load <2 x i64>, <2 x i64>* %143, align 8, !tbaa !3, !alias.scope !628
+  %145 = bitcast i8** %138 to <2 x i64>*
+  store <2 x i64> %141, <2 x i64>* %145, align 8, !tbaa !3, !alias.scope !631, !noalias !628
+  %146 = getelementptr i8*, i8** %138, i64 2
+  %147 = bitcast i8** %146 to <2 x i64>*
+  store <2 x i64> %144, <2 x i64>* %147, align 8, !tbaa !3, !alias.scope !631, !noalias !628
+  %148 = add i64 %103, 16
+  %149 = add i64 %104, -4
+  %150 = icmp eq i64 %149, 0
+  br i1 %150, label %.loopexit2, label %102, !llvm.loop !633
+
+.loopexit2:                                       ; preds = %102, %91
+  %151 = phi i64 [ 0, %91 ], [ %148, %102 ]
+  %152 = icmp eq i64 %98, 0
+  br i1 %152, label %.loopexit1, label %.preheader
+
+.preheader:                                       ; preds = %.preheader, %.loopexit2
+  %153 = phi i64 [ %165, %.preheader ], [ %151, %.loopexit2 ]
+  %154 = phi i64 [ %166, %.preheader ], [ %98, %.loopexit2 ]
+  %155 = getelementptr i8*, i8** %72, i64 %153
+  %156 = getelementptr i8*, i8** %37, i64 %153
+  %157 = bitcast i8** %156 to <2 x i64>*
+  %158 = load <2 x i64>, <2 x i64>* %157, align 8, !tbaa !3, !alias.scope !628
+  %159 = getelementptr i8*, i8** %156, i64 2
+  %160 = bitcast i8** %159 to <2 x i64>*
+  %161 = load <2 x i64>, <2 x i64>* %160, align 8, !tbaa !3, !alias.scope !628
+  %162 = bitcast i8** %155 to <2 x i64>*
+  store <2 x i64> %158, <2 x i64>* %162, align 8, !tbaa !3, !alias.scope !631, !noalias !628
+  %163 = getelementptr i8*, i8** %155, i64 2
+  %164 = bitcast i8** %163 to <2 x i64>*
+  store <2 x i64> %161, <2 x i64>* %164, align 8, !tbaa !3, !alias.scope !631, !noalias !628
+  %165 = add i64 %153, 4
+  %166 = add nsw i64 %154, -1
+  %167 = icmp eq i64 %166, 0
+  br i1 %167, label %.loopexit1, label %.preheader, !llvm.loop !634
+
+.loopexit1:                                       ; preds = %.preheader, %.loopexit2
+  %168 = icmp eq i64 %83, %92
+  br i1 %168, label %181, label %169
+
+169:                                              ; preds = %.loopexit1, %85, %78
+  %170 = phi i8** [ %72, %85 ], [ %72, %78 ], [ %93, %.loopexit1 ]
+  %171 = phi i8** [ %37, %85 ], [ %37, %78 ], [ %94, %.loopexit1 ]
+  br label %172
+
+172:                                              ; preds = %172, %169
+  %173 = phi i8** [ %179, %172 ], [ %170, %169 ]
+  %174 = phi i8** [ %178, %172 ], [ %171, %169 ]
+  %175 = bitcast i8** %174 to i64*
+  %176 = load atomic i64, i64* %175 unordered, align 8, !tbaa !3
+  %177 = bitcast i8** %173 to i64*
+  store i64 %176, i64* %177, align 8, !tbaa !3
+  %178 = getelementptr inbounds i8*, i8** %174, i64 1
+  %179 = getelementptr inbounds i8*, i8** %173, i64 1
+  %180 = icmp eq i8** %178, %38
+  br i1 %180, label %.loopexit, label %172, !llvm.loop !635
+
+.loopexit:                                        ; preds = %172
+  %.pre = load atomic i8**, i8*** %76 unordered, align 16, !tbaa !594
+  br label %181
+
+181:                                              ; preds = %.loopexit, %.loopexit1, %71
+  %182 = phi i8** [ %37, %71 ], [ %.pre, %.loopexit ], [ %37, %.loopexit1 ]
+  %183 = icmp eq i8** %182, null
+  br i1 %183, label %186, label %184
+
+184:                                              ; preds = %181
+  %185 = bitcast i8** %182 to i8*
+  call void @free(i8* %185) #37
+  br label %186
+
+186:                                              ; preds = %184, %181
+  store i8** %72, i8*** %76, align 16, !tbaa !594
+  %187 = getelementptr inbounds i8*, i8** %72, i64 %28
+  store i8** %187, i8*** %29, align 8, !tbaa !591
+  %188 = getelementptr inbounds i8*, i8** %72, i64 %66
+  br label %189
+
+189:                                              ; preds = %186, %52
+  %190 = phi i8*** [ %29, %52 ], [ %43, %186 ]
+  %191 = phi i8** [ %55, %52 ], [ %188, %186 ]
+  store i8** %191, i8*** %190, align 8, !tbaa !3
+  %.pre3 = load atomic i64, i64* %32 unordered, align 16, !tbaa !594
+  %.pre4 = load atomic i64, i64* %30 unordered, align 8, !tbaa !591
+  br label %_ZNSt6vectorIPvN6kotlin11std_support9allocatorIS0_EEE17_M_default_appendEm.exit
+
+192:                                              ; preds = %27
+  %193 = icmp ult i64 %28, %35
+  br i1 %193, label %194, label %_ZNSt6vectorIPvN6kotlin11std_support9allocatorIS0_EEE17_M_default_appendEm.exit
+
+194:                                              ; preds = %192
+  %195 = getelementptr inbounds i8*, i8** %37, i64 %28
+  %196 = icmp eq i8** %195, %38
+  br i1 %196, label %_ZNSt6vectorIPvN6kotlin11std_support9allocatorIS0_EEE17_M_default_appendEm.exit, label %197
+
+197:                                              ; preds = %194
+  store i8** %195, i8*** %29, align 8, !tbaa !591
+  %198 = ptrtoint i8** %195 to i64
+  br label %_ZNSt6vectorIPvN6kotlin11std_support9allocatorIS0_EEE17_M_default_appendEm.exit
+
+_ZNSt6vectorIPvN6kotlin11std_support9allocatorIS0_EEE17_M_default_appendEm.exit: ; preds = %197, %194, %192, %189, %39
+  %199 = phi i64 [ %198, %197 ], [ %31, %194 ], [ %31, %192 ], [ %.pre4, %189 ], [ %31, %39 ]
+  %200 = phi i64 [ %33, %197 ], [ %33, %194 ], [ %33, %192 ], [ %.pre3, %189 ], [ %33, %39 ]
+  %201 = bitcast %"struct.(anonymous namespace)::Backtrace"* %5 to i8*
+  call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %201) #37
+  %202 = sub i64 %199, %200
+  %203 = ashr exact i64 %202, 3
+  %204 = getelementptr inbounds %"struct.(anonymous namespace)::Backtrace", %"struct.(anonymous namespace)::Backtrace"* %5, i64 0, i32 0
+  store i64 0, i64* %204, align 8, !tbaa !636
+  %205 = getelementptr inbounds %"struct.(anonymous namespace)::Backtrace", %"struct.(anonymous namespace)::Backtrace"* %5, i64 0, i32 1
+  store i64 4, i64* %205, align 8, !tbaa !639
+  %206 = getelementptr inbounds %"struct.(anonymous namespace)::Backtrace", %"struct.(anonymous namespace)::Backtrace"* %5, i64 0, i32 2, i32 0
+  %207 = bitcast i8*** %206 to i64*
+  store i64 %200, i64* %207, align 8, !tbaa.struct !640
+  %208 = getelementptr inbounds %"struct.(anonymous namespace)::Backtrace", %"struct.(anonymous namespace)::Backtrace"* %5, i64 0, i32 2, i32 1
+  store i64 %203, i64* %208, align 8, !tbaa.struct !640
+  %209 = invoke i32 @_Unwind_Backtrace(i32 (%struct._Unwind_Context*, i8*)* nonnull @_ZN12_GLOBAL__N_114unwindCallbackEP15_Unwind_ContextPv, i8* nonnull %201)
+          to label %213 unwind label %210
+
+210:                                              ; preds = %_ZNSt6vectorIPvN6kotlin11std_support9allocatorIS0_EEE17_M_default_appendEm.exit
+  %211 = landingpad { i8*, i32 }
           catch i8* null
-  %41 = extractvalue { i8*, i32 } %40, 0
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %30) #37
-  br label %66
+  %212 = extractvalue { i8*, i32 } %211, 0
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %201) #37
+  br label %247
 
-42:                                               ; preds = %21
-  %.sroa.0.0..sroa.0.0. = load <2 x i64>, <2 x i64>* %.sroa.0, align 16, !tbaa !3
-  %43 = bitcast %"class.std::vector.195"* %0 to <2 x i64>*
-  store <2 x i64> %.sroa.0.0..sroa.0.0., <2 x i64>* %43, align 8, !tbaa !3
-  store <2 x i64> zeroinitializer, <2 x i64>* %.sroa.0, align 16, !tbaa !3
-  %44 = getelementptr inbounds %"class.std::vector.195", %"class.std::vector.195"* %0, i64 0, i32 0, i32 0, i32 2
-  %45 = bitcast i8*** %44 to i64*
-  store i64 %phi.cast84, i64* %45, align 8, !tbaa !3
-  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %30) #37
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %9) #37
-  br label %51
+213:                                              ; preds = %_ZNSt6vectorIPvN6kotlin11std_support9allocatorIS0_EEE17_M_default_appendEm.exit
+  %214 = bitcast %"class.std::vector.195"* %3 to <2 x i64>*
+  %215 = load <2 x i64>, <2 x i64>* %214, align 16, !tbaa !3
+  %216 = bitcast %"class.std::vector.195"* %0 to <2 x i64>*
+  store <2 x i64> %215, <2 x i64>* %216, align 8, !tbaa !3
+  store <2 x i64> zeroinitializer, <2 x i64>* %214, align 16, !tbaa !3
+  %217 = getelementptr inbounds %"class.std::vector.195", %"class.std::vector.195"* %0, i64 0, i32 0, i32 0, i32 2
+  %218 = getelementptr inbounds %"class.std::vector.195", %"class.std::vector.195"* %3, i64 0, i32 0, i32 0, i32 2
+  %219 = bitcast i8*** %217 to i64*
+  %220 = bitcast i8*** %218 to i64*
+  %221 = load atomic i64, i64* %220 unordered, align 16, !tbaa !3
+  store i64 %221, i64* %219, align 8, !tbaa !3
+  store i64 0, i64* %220, align 16, !tbaa !3
+  call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %201) #37
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %19) #37
+  br label %229
 
-46:                                               ; preds = %11
-  %47 = bitcast %"class.std::vector.195"* %0 to i8*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %47, i8 0, i64 24, i1 false) #37
-  %.sroa.0.0.sroa_cast39 = bitcast <2 x i64>* %.sroa.0 to i8***
-  %.sroa.0.0..sroa.0.0.3 = load i8**, i8*** %.sroa.0.0.sroa_cast39, align 16, !tbaa !590
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %9) #37
-  %48 = icmp eq i8** %.sroa.0.0..sroa.0.0.3, null
-  br i1 %48, label %51, label %49
+222:                                              ; preds = %21
+  %223 = bitcast %"class.std::vector.195"* %0 to i8*
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %223, i8 0, i64 24, i1 false) #37
+  %224 = getelementptr inbounds %"class.std::vector.195", %"class.std::vector.195"* %3, i64 0, i32 0, i32 0, i32 0
+  %225 = load atomic i8**, i8*** %224 unordered, align 16, !tbaa !594
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %19) #37
+  %226 = icmp eq i8** %225, null
+  br i1 %226, label %229, label %227
 
-49:                                               ; preds = %46
-  %50 = bitcast i8** %.sroa.0.0..sroa.0.0.3 to i8*
-  call void @free(i8* %50) #37
-  br label %51
+227:                                              ; preds = %222
+  %228 = bitcast i8** %225 to i8*
+  call void @free(i8* %228) #37
+  br label %229
 
-51:                                               ; preds = %49, %46, %42
-  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %.sroa.0.0.sroa_cast47)
-  %52 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %.sroa.3.0, null
-  br i1 %52, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %53
+229:                                              ; preds = %227, %222, %213
+  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %18) #37
+  %230 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %2, i64 0, i32 1, i32 0
+  %231 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %230 unordered, align 8, !tbaa !34
+  %232 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %231, null
+  br i1 %232, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %233
 
-53:                                               ; preds = %51
-  %54 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %.sroa.3.0, i64 328
-  %55 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %54 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %56 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %54 to i32*
-  %57 = atomicrmw xchg i32* %56, i32 %.sroa.7.0 seq_cst, align 4
-  %58 = icmp eq i32 %57, 1
-  %59 = icmp eq i32 %.sroa.7.0, 0
-  %60 = and i1 %59, %58
-  br i1 %60, label %61, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
+233:                                              ; preds = %229
+  %234 = load atomic i32, i32* %9 unordered, align 8, !tbaa !38
+  %235 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %231, i64 328
+  %236 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %235 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %237 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %235 to i32*
+  %238 = atomicrmw xchg i32* %237, i32 %234 seq_cst, align 4
+  %239 = icmp eq i32 %238, 1
+  %240 = icmp eq i32 %234, 0
+  %241 = and i1 %240, %239
+  br i1 %241, label %242, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-61:                                               ; preds = %53
-  %62 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %63 = and i8 %62, 1
-  %64 = icmp eq i8 %63, 0
-  br i1 %64, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %65
+242:                                              ; preds = %233
+  %243 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %244 = and i8 %243, 1
+  %245 = icmp eq i8 %244, 0
+  br i1 %245, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %246
 
-65:                                               ; preds = %61
-  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %55) #37
+246:                                              ; preds = %242
+  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %236) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %65, %61, %53, %51
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %246, %242, %233, %229
+  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %6) #37
   ret void
 
-66:                                               ; preds = %39, %14
-  %.sroa.0.0..sroa.0.0..idx.val = phi i8** [ %29, %39 ], [ null, %14 ]
-  %67 = phi i8* [ %41, %39 ], [ %16, %14 ]
-  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %9) #37
-  call fastcc void @_ZNSt6vectorIPvN6kotlin11std_support9allocatorIS0_EEED2Ev(i8** %.sroa.0.0..sroa.0.0..idx.val) #37
-  call void @llvm.lifetime.end.p0i8(i64 16, i8* nonnull %.sroa.0.0.sroa_cast47)
-  call fastcc void @_ZN6kotlin31NativeOrUnregisteredThreadGuardD2Ev(%"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %.sroa.3.0, i32 %.sroa.7.0) #37
-  call fastcc void @__clang_call_terminate(i8* %67) #51
+247:                                              ; preds = %210, %24
+  %248 = phi i8* [ %212, %210 ], [ %26, %24 ]
+  call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %19) #37
+  call fastcc void @_ZNSt6vectorIPvN6kotlin11std_support9allocatorIS0_EEED2Ev(%"class.std::vector.195"* nonnull %3) #37
+  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %18) #37
+  call fastcc void @_ZN6kotlin31NativeOrUnregisteredThreadGuardD2Ev(%"class.kotlin::NativeOrUnregisteredThreadGuard"* nonnull %2) #37
+  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %6) #37
+  call fastcc void @__clang_call_terminate(i8* %248) #51
   unreachable
 }
 
 ; Function Attrs: nofree norecurse nounwind uwtable
 define internal i32 @_ZN12_GLOBAL__N_118depthCountCallbackEP15_Unwind_ContextPv(%struct._Unwind_Context* nocapture readnone %0, i8* nocapture %1) #26 {
   %3 = bitcast i8* %1 to i64*
-  %4 = load i64, i64* %3, align 8, !tbaa !89
+  %4 = load atomic i64, i64* %3 unordered, align 8, !tbaa !87
   %5 = add i64 %4, 1
-  store i64 %5, i64* %3, align 8, !tbaa !89
+  store i64 %5, i64* %3, align 8, !tbaa !87
   ret i32 0
 }
 
@@ -48787,33 +49606,33 @@
 define internal i32 @_ZN12_GLOBAL__N_114unwindCallbackEP15_Unwind_ContextPv(%struct._Unwind_Context* %0, i8* nocapture %1) #20 {
   %3 = getelementptr inbounds i8, i8* %1, i64 8
   %4 = bitcast i8* %3 to i64*
-  %5 = load i64, i64* %4, align 8, !tbaa !627
+  %5 = load atomic i64, i64* %4 unordered, align 8, !tbaa !639
   %6 = icmp eq i64 %5, 0
   br i1 %6, label %9, label %7
 
 7:                                                ; preds = %2
   %8 = add i64 %5, -1
-  store i64 %8, i64* %4, align 8, !tbaa !627
+  store i64 %8, i64* %4, align 8, !tbaa !639
   br label %25
 
 9:                                                ; preds = %2
   %10 = bitcast i8* %1 to i64*
-  %11 = load i64, i64* %10, align 8, !tbaa !624
+  %11 = load atomic i64, i64* %10 unordered, align 8, !tbaa !636
   %12 = getelementptr inbounds i8, i8* %1, i64 24
   %13 = bitcast i8* %12 to i64*
-  %14 = load i64, i64* %13, align 8, !tbaa !629
+  %14 = load atomic i64, i64* %13 unordered, align 8, !tbaa !641
   %15 = icmp ult i64 %11, %14
   br i1 %15, label %16, label %25
 
 16:                                               ; preds = %9
   %17 = tail call i64 @_Unwind_GetIP(%struct._Unwind_Context* %0)
-  %18 = load i64, i64* %10, align 8, !tbaa !624
+  %18 = load atomic i64, i64* %10 unordered, align 8, !tbaa !636
   %19 = add i64 %18, 1
-  store i64 %19, i64* %10, align 8, !tbaa !624
+  store i64 %19, i64* %10, align 8, !tbaa !636
   %20 = inttoptr i64 %17 to i8*
   %21 = getelementptr inbounds i8, i8* %1, i64 16
   %22 = bitcast i8* %21 to i8***
-  %23 = load i8**, i8*** %22, align 8, !tbaa !630
+  %23 = load atomic i8**, i8*** %22 unordered, align 8, !tbaa !642
   %24 = getelementptr inbounds i8*, i8** %23, i64 %18
   store i8* %20, i8** %24, align 8, !tbaa !3
   br label %25
@@ -48823,16 +49642,18 @@
 }
 
 ; Function Attrs: nounwind uwtable
-define internal fastcc void @_ZNSt6vectorIPvN6kotlin11std_support9allocatorIS0_EEED2Ev(i8** %.0.0.0.0.val) unnamed_addr #17 align 2 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
-  %1 = icmp eq i8** %.0.0.0.0.val, null
-  br i1 %1, label %4, label %2
+define internal fastcc void @_ZNSt6vectorIPvN6kotlin11std_support9allocatorIS0_EEED2Ev(%"class.std::vector.195"* nocapture readonly %0) unnamed_addr #17 align 2 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
+  %2 = getelementptr inbounds %"class.std::vector.195", %"class.std::vector.195"* %0, i64 0, i32 0, i32 0, i32 0
+  %3 = load atomic i8**, i8*** %2 unordered, align 8, !tbaa !594
+  %4 = icmp eq i8** %3, null
+  br i1 %4, label %7, label %5
 
-2:                                                ; preds = %0
-  %3 = bitcast i8** %.0.0.0.0.val to i8*
-  tail call void @free(i8* %3) #37
-  br label %4
+5:                                                ; preds = %1
+  %6 = bitcast i8** %3 to i8*
+  tail call void @free(i8* %6) #37
+  br label %7
 
-4:                                                ; preds = %2, %0
+7:                                                ; preds = %5, %1
   ret void
 }
 
@@ -48867,7 +49688,7 @@
 14:                                               ; preds = %37, %12
   %15 = phi i32 [ 0, %12 ], [ %40, %37 ]
   call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %13) #37
-  store i32 0, i32* %5, align 4, !tbaa !73
+  store i32 0, i32* %5, align 4, !tbaa !71
   %16 = call fastcc i32 @_ZN4utf88internal13validate_nextIPKcEENS0_9utf_errorERT_S5_Rj(i8** nonnull align 8 dereferenceable(8) %6, i8* nonnull %9, i32* nonnull align 4 dereferenceable(4) %5)
   switch i32 %16, label %30 [
     i32 0, label %32
@@ -48879,13 +49700,13 @@
   ]
 
 17:                                               ; preds = %14, %14, %14
-  %18 = load i8*, i8** %6, align 8, !tbaa !3
+  %18 = load atomic i8*, i8** %6 unordered, align 8, !tbaa !3
   %19 = getelementptr inbounds i8, i8* %18, i64 1
   store i8* %19, i8** %6, align 8, !tbaa !3
   br label %.loopexit2
 
 20:                                               ; preds = %14, %14
-  %21 = load i8*, i8** %6, align 8, !tbaa !3
+  %21 = load atomic i8*, i8** %6 unordered, align 8, !tbaa !3
   br label %22
 
 22:                                               ; preds = %26, %20
@@ -48896,7 +49717,7 @@
   br i1 %25, label %26, label %.loopexit2
 
 26:                                               ; preds = %22
-  %27 = load i8, i8* %24, align 1, !tbaa !51
+  %27 = load atomic i8, i8* %24 unordered, align 1, !tbaa !50
   %28 = and i8 %27, -64
   %29 = icmp eq i8 %28, -128
   br i1 %29, label %22, label %.loopexit2
@@ -48910,8 +49731,8 @@
   br label %37
 
 32:                                               ; preds = %14
-  %33 = load i32, i32* %5, align 4, !tbaa !73
-  %34 = load i8*, i8** %6, align 8, !tbaa !3
+  %33 = load atomic i32, i32* %5 unordered, align 4, !tbaa !71
+  %34 = load atomic i8*, i8** %6 unordered, align 8, !tbaa !3
   call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %13) #37
   %35 = icmp ugt i32 %33, 65535
   %36 = select i1 %35, i32 2, i32 1
@@ -48935,10 +49756,10 @@
 
 AllocArrayInstance.exit.i:                        ; preds = %42, %.thread
   %45 = phi i32 [ 0, %.thread ], [ %40, %42 ]
-  %46 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %46 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %47 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %46, i64 0, i32 1, i32 6
   %48 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %47 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %49 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %48, align 8, !tbaa !3
+  %49 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %48 unordered, align 8, !tbaa !3
   %50 = zext i32 %45 to i64
   %51 = shl nuw nsw i64 %50, 1
   %52 = add nuw nsw i64 %51, 31
@@ -48972,7 +49793,7 @@
 70:                                               ; preds = %103, %66
   %71 = phi i16* [ %68, %66 ], [ %104, %103 ]
   call void @llvm.lifetime.start.p0i8(i64 4, i8* nonnull %69) #37
-  store i32 0, i32* %3, align 4, !tbaa !73
+  store i32 0, i32* %3, align 4, !tbaa !71
   %72 = call fastcc i32 @_ZN4utf88internal13validate_nextIPKcEENS0_9utf_errorERT_S5_Rj(i8** nonnull align 8 dereferenceable(8) %4, i8* nonnull %9, i32* nonnull align 4 dereferenceable(4) %3)
   switch i32 %72, label %86 [
     i32 0, label %87
@@ -48984,13 +49805,13 @@
   ]
 
 73:                                               ; preds = %70, %70, %70
-  %74 = load i8*, i8** %4, align 8, !tbaa !3
+  %74 = load atomic i8*, i8** %4 unordered, align 8, !tbaa !3
   %75 = getelementptr inbounds i8, i8* %74, i64 1
   store i8* %75, i8** %4, align 8, !tbaa !3
   br label %.loopexit
 
 76:                                               ; preds = %70, %70
-  %77 = load i8*, i8** %4, align 8, !tbaa !3
+  %77 = load atomic i8*, i8** %4 unordered, align 8, !tbaa !3
   br label %78
 
 78:                                               ; preds = %82, %76
@@ -49001,7 +49822,7 @@
   br i1 %81, label %82, label %.loopexit
 
 82:                                               ; preds = %78
-  %83 = load i8, i8* %80, align 1, !tbaa !51
+  %83 = load atomic i8, i8* %80 unordered, align 1, !tbaa !50
   %84 = and i8 %83, -64
   %85 = icmp eq i8 %84, -128
   br i1 %85, label %78, label %.loopexit
@@ -49014,7 +49835,7 @@
   br label %99
 
 87:                                               ; preds = %70
-  %88 = load i32, i32* %3, align 4, !tbaa !73
+  %88 = load atomic i32, i32* %3 unordered, align 4, !tbaa !71
   call void @llvm.lifetime.end.p0i8(i64 4, i8* nonnull %69) #37
   %89 = icmp ugt i32 %88, 65535
   br i1 %89, label %90, label %99
@@ -49024,24 +49845,24 @@
   %92 = trunc i32 %91 to i16
   %93 = add i16 %92, -10304
   %94 = getelementptr inbounds i16, i16* %71, i64 1
-  store i16 %93, i16* %71, align 2, !tbaa !34
+  store i16 %93, i16* %71, align 2, !tbaa !27
   %95 = trunc i32 %88 to i16
   %96 = and i16 %95, 1023
   %97 = or i16 %96, -9216
   %98 = getelementptr inbounds i16, i16* %71, i64 2
-  store i16 %97, i16* %94, align 2, !tbaa !34
+  store i16 %97, i16* %94, align 2, !tbaa !27
   br label %103
 
 99:                                               ; preds = %87, %.loopexit
   %100 = phi i32 [ 65533, %.loopexit ], [ %88, %87 ]
   %101 = trunc i32 %100 to i16
   %102 = getelementptr inbounds i16, i16* %71, i64 1
-  store i16 %101, i16* %71, align 2, !tbaa !34
+  store i16 %101, i16* %71, align 2, !tbaa !27
   br label %103
 
 103:                                              ; preds = %99, %90
   %104 = phi i16* [ %98, %90 ], [ %102, %99 ]
-  %105 = load i8*, i8** %4, align 8, !tbaa !3
+  %105 = load atomic i8*, i8** %4 unordered, align 8, !tbaa !3
   %106 = icmp eq i8* %105, %9
   br i1 %106, label %_ZN12_GLOBAL__N_111utf8ToUtf16EPKcmPP9ObjHeader.exit, label %70
 
@@ -49058,9 +49879,9 @@
 ; Function Attrs: nofree norecurse nounwind uwtable
 define internal fastcc i32 @_ZN4utf88internal13validate_nextIPKcEENS0_9utf_errorERT_S5_Rj(i8** nocapture nonnull align 8 dereferenceable(8) %0, i8* readnone %1, i32* nocapture nonnull align 4 dereferenceable(4) %2) unnamed_addr #26 {
   %4 = bitcast i8** %0 to i64*
-  %5 = load i64, i64* %4, align 8, !tbaa !3
+  %5 = load atomic i64, i64* %4 unordered, align 8, !tbaa !3
   %6 = inttoptr i64 %5 to i8*
-  %7 = load i8, i8* %6, align 1, !tbaa !51
+  %7 = load atomic i8, i8* %6 unordered, align 1, !tbaa !50
   %8 = zext i8 %7 to i32
   %9 = icmp sgt i8 %7, -1
   br i1 %9, label %19, label %10
@@ -49095,7 +49916,7 @@
   br i1 %25, label %113, label %26
 
 26:                                               ; preds = %23
-  %27 = load i8, i8* %24, align 1, !tbaa !51
+  %27 = load atomic i8, i8* %24 unordered, align 1, !tbaa !50
   %28 = and i8 %27, -64
   %29 = icmp eq i8 %28, -128
   br i1 %29, label %30, label %113
@@ -49120,7 +49941,7 @@
   br i1 %41, label %113, label %42
 
 42:                                               ; preds = %39
-  %43 = load i8, i8* %40, align 1, !tbaa !51
+  %43 = load atomic i8, i8* %40 unordered, align 1, !tbaa !50
   %44 = and i8 %43, -64
   %45 = icmp eq i8 %44, -128
   br i1 %45, label %46, label %113
@@ -49147,7 +49968,7 @@
   br i1 %59, label %113, label %60
 
 60:                                               ; preds = %57
-  %61 = load i8, i8* %58, align 1, !tbaa !51
+  %61 = load atomic i8, i8* %58 unordered, align 1, !tbaa !50
   %62 = and i8 %61, -64
   %63 = icmp eq i8 %62, -128
   br i1 %63, label %64, label %113
@@ -49169,7 +49990,7 @@
   br i1 %72, label %113, label %73
 
 73:                                               ; preds = %70
-  %74 = load i8, i8* %71, align 1, !tbaa !51
+  %74 = load atomic i8, i8* %71 unordered, align 1, !tbaa !50
   %75 = and i8 %74, -64
   %76 = icmp eq i8 %75, -128
   br i1 %76, label %77, label %113
@@ -49195,7 +50016,7 @@
   br i1 %89, label %113, label %90
 
 90:                                               ; preds = %87
-  %91 = load i8, i8* %88, align 1, !tbaa !51
+  %91 = load atomic i8, i8* %88 unordered, align 1, !tbaa !50
   %92 = and i8 %91, -64
   %93 = icmp eq i8 %92, -128
   br i1 %93, label %94, label %113
@@ -49211,7 +50032,7 @@
   br i1 %100, label %113, label %101
 
 101:                                              ; preds = %94
-  %102 = load i8, i8* %99, align 1, !tbaa !51
+  %102 = load atomic i8, i8* %99 unordered, align 1, !tbaa !50
   %103 = and i8 %102, -64
   %104 = icmp eq i8 %103, -128
   br i1 %104, label %105, label %113
@@ -49225,7 +50046,7 @@
 109:                                              ; preds = %105, %64, %30, %19
   %110 = phi i8* [ %24, %30 ], [ %58, %64 ], [ %99, %105 ], [ %6, %19 ]
   %111 = phi i32 [ %35, %30 ], [ %67, %64 ], [ %108, %105 ], [ %8, %19 ]
-  store i32 %111, i32* %2, align 4, !tbaa !73
+  store i32 %111, i32* %2, align 4, !tbaa !71
   %112 = getelementptr inbounds i8, i8* %110, i64 1
   store i8* %112, i8** %0, align 8, !tbaa !3
   br label %115
@@ -49248,10 +50069,10 @@
 4:                                                ; preds = %2
   %5 = trunc i32 %0 to i8
   %6 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 1
-  %7 = load i64, i64* %6, align 8, !tbaa !60
+  %7 = load atomic i64, i64* %6 unordered, align 8, !tbaa !51
   %8 = add i64 %7, 1
   %9 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 0, i32 0
-  %10 = load i8*, i8** %9, align 8, !tbaa !58
+  %10 = load atomic i8*, i8** %9 unordered, align 8, !tbaa !47
   %11 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 2
   %12 = bitcast %union.anon.108* %11 to i8*
   %13 = icmp eq i8* %10, %12
@@ -49259,7 +50080,7 @@
 
 14:                                               ; preds = %4
   %15 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 2, i32 0
-  %16 = load i64, i64* %15, align 8, !tbaa !51
+  %16 = load atomic i64, i64* %15 unordered, align 8, !tbaa !50
   br label %17
 
 17:                                               ; preds = %14, %4
@@ -49269,14 +50090,14 @@
 
 20:                                               ; preds = %17
   tail call fastcc void @_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE9_M_mutateEmmPKcm(%"class.std::__cxx11::basic_string"* nonnull %1, i64 %7)
-  %21 = load i8*, i8** %9, align 8, !tbaa !58
+  %21 = load atomic i8*, i8** %9 unordered, align 8, !tbaa !47
   br label %22
 
 22:                                               ; preds = %20, %17
   %23 = phi i8* [ %21, %20 ], [ %10, %17 ]
   %24 = getelementptr inbounds i8, i8* %23, i64 %7
-  store i8 %5, i8* %24, align 1, !tbaa !51
-  store i64 %8, i64* %6, align 8, !tbaa !60
+  store i8 %5, i8* %24, align 1, !tbaa !50
+  store i64 %8, i64* %6, align 8, !tbaa !51
   br label %221
 
 25:                                               ; preds = %2
@@ -49288,10 +50109,10 @@
   %29 = trunc i32 %28 to i8
   %30 = or i8 %29, -64
   %31 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 1
-  %32 = load i64, i64* %31, align 8, !tbaa !60
+  %32 = load atomic i64, i64* %31 unordered, align 8, !tbaa !51
   %33 = add i64 %32, 1
   %34 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 0, i32 0
-  %35 = load i8*, i8** %34, align 8, !tbaa !58
+  %35 = load atomic i8*, i8** %34 unordered, align 8, !tbaa !47
   %36 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 2
   %37 = bitcast %union.anon.108* %36 to i8*
   %38 = icmp eq i8* %35, %37
@@ -49299,7 +50120,7 @@
 
 39:                                               ; preds = %27
   %40 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 2, i32 0
-  %41 = load i64, i64* %40, align 8, !tbaa !51
+  %41 = load atomic i64, i64* %40 unordered, align 8, !tbaa !50
   br label %42
 
 42:                                               ; preds = %39, %27
@@ -49309,29 +50130,29 @@
 
 45:                                               ; preds = %42
   tail call fastcc void @_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE9_M_mutateEmmPKcm(%"class.std::__cxx11::basic_string"* nonnull %1, i64 %32)
-  %46 = load i8*, i8** %34, align 8, !tbaa !58
+  %46 = load atomic i8*, i8** %34 unordered, align 8, !tbaa !47
   br label %47
 
 47:                                               ; preds = %45, %42
   %48 = phi i8* [ %46, %45 ], [ %35, %42 ]
   %49 = getelementptr inbounds i8, i8* %48, i64 %32
-  store i8 %30, i8* %49, align 1, !tbaa !51
-  store i64 %33, i64* %31, align 8, !tbaa !60
-  %50 = load i8*, i8** %34, align 8, !tbaa !58
+  store i8 %30, i8* %49, align 1, !tbaa !50
+  store i64 %33, i64* %31, align 8, !tbaa !51
+  %50 = load atomic i8*, i8** %34 unordered, align 8, !tbaa !47
   %51 = getelementptr inbounds i8, i8* %50, i64 %33
-  store i8 0, i8* %51, align 1, !tbaa !51
+  store i8 0, i8* %51, align 1, !tbaa !50
   %52 = trunc i32 %0 to i8
   %53 = and i8 %52, 63
   %54 = or i8 %53, -128
-  %55 = load i64, i64* %31, align 8, !tbaa !60
+  %55 = load atomic i64, i64* %31 unordered, align 8, !tbaa !51
   %56 = add i64 %55, 1
-  %57 = load i8*, i8** %34, align 8, !tbaa !58
+  %57 = load atomic i8*, i8** %34 unordered, align 8, !tbaa !47
   %58 = icmp eq i8* %57, %37
   br i1 %58, label %62, label %59
 
 59:                                               ; preds = %47
   %60 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 2, i32 0
-  %61 = load i64, i64* %60, align 8, !tbaa !51
+  %61 = load atomic i64, i64* %60 unordered, align 8, !tbaa !50
   br label %62
 
 62:                                               ; preds = %59, %47
@@ -49341,14 +50162,14 @@
 
 65:                                               ; preds = %62
   tail call fastcc void @_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE9_M_mutateEmmPKcm(%"class.std::__cxx11::basic_string"* nonnull %1, i64 %55)
-  %66 = load i8*, i8** %34, align 8, !tbaa !58
+  %66 = load atomic i8*, i8** %34 unordered, align 8, !tbaa !47
   br label %67
 
 67:                                               ; preds = %65, %62
   %68 = phi i8* [ %66, %65 ], [ %57, %62 ]
   %69 = getelementptr inbounds i8, i8* %68, i64 %55
-  store i8 %54, i8* %69, align 1, !tbaa !51
-  store i64 %56, i64* %31, align 8, !tbaa !60
+  store i8 %54, i8* %69, align 1, !tbaa !50
+  store i64 %56, i64* %31, align 8, !tbaa !51
   br label %221
 
 70:                                               ; preds = %25
@@ -49360,10 +50181,10 @@
   %74 = trunc i32 %73 to i8
   %75 = or i8 %74, -32
   %76 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 1
-  %77 = load i64, i64* %76, align 8, !tbaa !60
+  %77 = load atomic i64, i64* %76 unordered, align 8, !tbaa !51
   %78 = add i64 %77, 1
   %79 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 0, i32 0
-  %80 = load i8*, i8** %79, align 8, !tbaa !58
+  %80 = load atomic i8*, i8** %79 unordered, align 8, !tbaa !47
   %81 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 2
   %82 = bitcast %union.anon.108* %81 to i8*
   %83 = icmp eq i8* %80, %82
@@ -49371,7 +50192,7 @@
 
 84:                                               ; preds = %72
   %85 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 2, i32 0
-  %86 = load i64, i64* %85, align 8, !tbaa !51
+  %86 = load atomic i64, i64* %85 unordered, align 8, !tbaa !50
   br label %87
 
 87:                                               ; preds = %84, %72
@@ -49381,30 +50202,30 @@
 
 90:                                               ; preds = %87
   tail call fastcc void @_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE9_M_mutateEmmPKcm(%"class.std::__cxx11::basic_string"* nonnull %1, i64 %77)
-  %91 = load i8*, i8** %79, align 8, !tbaa !58
+  %91 = load atomic i8*, i8** %79 unordered, align 8, !tbaa !47
   br label %92
 
 92:                                               ; preds = %90, %87
   %93 = phi i8* [ %91, %90 ], [ %80, %87 ]
   %94 = getelementptr inbounds i8, i8* %93, i64 %77
-  store i8 %75, i8* %94, align 1, !tbaa !51
-  store i64 %78, i64* %76, align 8, !tbaa !60
-  %95 = load i8*, i8** %79, align 8, !tbaa !58
+  store i8 %75, i8* %94, align 1, !tbaa !50
+  store i64 %78, i64* %76, align 8, !tbaa !51
+  %95 = load atomic i8*, i8** %79 unordered, align 8, !tbaa !47
   %96 = getelementptr inbounds i8, i8* %95, i64 %78
-  store i8 0, i8* %96, align 1, !tbaa !51
+  store i8 0, i8* %96, align 1, !tbaa !50
   %97 = lshr i32 %0, 6
   %98 = trunc i32 %97 to i8
   %99 = and i8 %98, 63
   %100 = or i8 %99, -128
-  %101 = load i64, i64* %76, align 8, !tbaa !60
+  %101 = load atomic i64, i64* %76 unordered, align 8, !tbaa !51
   %102 = add i64 %101, 1
-  %103 = load i8*, i8** %79, align 8, !tbaa !58
+  %103 = load atomic i8*, i8** %79 unordered, align 8, !tbaa !47
   %104 = icmp eq i8* %103, %82
   br i1 %104, label %108, label %105
 
 105:                                              ; preds = %92
   %106 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 2, i32 0
-  %107 = load i64, i64* %106, align 8, !tbaa !51
+  %107 = load atomic i64, i64* %106 unordered, align 8, !tbaa !50
   br label %108
 
 108:                                              ; preds = %105, %92
@@ -49414,29 +50235,29 @@
 
 111:                                              ; preds = %108
   tail call fastcc void @_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE9_M_mutateEmmPKcm(%"class.std::__cxx11::basic_string"* nonnull %1, i64 %101)
-  %112 = load i8*, i8** %79, align 8, !tbaa !58
+  %112 = load atomic i8*, i8** %79 unordered, align 8, !tbaa !47
   br label %113
 
 113:                                              ; preds = %111, %108
   %114 = phi i8* [ %112, %111 ], [ %103, %108 ]
   %115 = getelementptr inbounds i8, i8* %114, i64 %101
-  store i8 %100, i8* %115, align 1, !tbaa !51
-  store i64 %102, i64* %76, align 8, !tbaa !60
-  %116 = load i8*, i8** %79, align 8, !tbaa !58
+  store i8 %100, i8* %115, align 1, !tbaa !50
+  store i64 %102, i64* %76, align 8, !tbaa !51
+  %116 = load atomic i8*, i8** %79 unordered, align 8, !tbaa !47
   %117 = getelementptr inbounds i8, i8* %116, i64 %102
-  store i8 0, i8* %117, align 1, !tbaa !51
+  store i8 0, i8* %117, align 1, !tbaa !50
   %118 = trunc i32 %0 to i8
   %119 = and i8 %118, 63
   %120 = or i8 %119, -128
-  %121 = load i64, i64* %76, align 8, !tbaa !60
+  %121 = load atomic i64, i64* %76 unordered, align 8, !tbaa !51
   %122 = add i64 %121, 1
-  %123 = load i8*, i8** %79, align 8, !tbaa !58
+  %123 = load atomic i8*, i8** %79 unordered, align 8, !tbaa !47
   %124 = icmp eq i8* %123, %82
   br i1 %124, label %128, label %125
 
 125:                                              ; preds = %113
   %126 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 2, i32 0
-  %127 = load i64, i64* %126, align 8, !tbaa !51
+  %127 = load atomic i64, i64* %126 unordered, align 8, !tbaa !50
   br label %128
 
 128:                                              ; preds = %125, %113
@@ -49446,14 +50267,14 @@
 
 131:                                              ; preds = %128
   tail call fastcc void @_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE9_M_mutateEmmPKcm(%"class.std::__cxx11::basic_string"* nonnull %1, i64 %121)
-  %132 = load i8*, i8** %79, align 8, !tbaa !58
+  %132 = load atomic i8*, i8** %79 unordered, align 8, !tbaa !47
   br label %133
 
 133:                                              ; preds = %131, %128
   %134 = phi i8* [ %132, %131 ], [ %123, %128 ]
   %135 = getelementptr inbounds i8, i8* %134, i64 %121
-  store i8 %120, i8* %135, align 1, !tbaa !51
-  store i64 %122, i64* %76, align 8, !tbaa !60
+  store i8 %120, i8* %135, align 1, !tbaa !50
+  store i64 %122, i64* %76, align 8, !tbaa !51
   br label %221
 
 136:                                              ; preds = %70
@@ -49461,10 +50282,10 @@
   %138 = trunc i32 %137 to i8
   %139 = or i8 %138, -16
   %140 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 1
-  %141 = load i64, i64* %140, align 8, !tbaa !60
+  %141 = load atomic i64, i64* %140 unordered, align 8, !tbaa !51
   %142 = add i64 %141, 1
   %143 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 0, i32 0
-  %144 = load i8*, i8** %143, align 8, !tbaa !58
+  %144 = load atomic i8*, i8** %143 unordered, align 8, !tbaa !47
   %145 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 2
   %146 = bitcast %union.anon.108* %145 to i8*
   %147 = icmp eq i8* %144, %146
@@ -49472,7 +50293,7 @@
 
 148:                                              ; preds = %136
   %149 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 2, i32 0
-  %150 = load i64, i64* %149, align 8, !tbaa !51
+  %150 = load atomic i64, i64* %149 unordered, align 8, !tbaa !50
   br label %151
 
 151:                                              ; preds = %148, %136
@@ -49482,30 +50303,30 @@
 
 154:                                              ; preds = %151
   tail call fastcc void @_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE9_M_mutateEmmPKcm(%"class.std::__cxx11::basic_string"* nonnull %1, i64 %141)
-  %155 = load i8*, i8** %143, align 8, !tbaa !58
+  %155 = load atomic i8*, i8** %143 unordered, align 8, !tbaa !47
   br label %156
 
 156:                                              ; preds = %154, %151
   %157 = phi i8* [ %155, %154 ], [ %144, %151 ]
   %158 = getelementptr inbounds i8, i8* %157, i64 %141
-  store i8 %139, i8* %158, align 1, !tbaa !51
-  store i64 %142, i64* %140, align 8, !tbaa !60
-  %159 = load i8*, i8** %143, align 8, !tbaa !58
+  store i8 %139, i8* %158, align 1, !tbaa !50
+  store i64 %142, i64* %140, align 8, !tbaa !51
+  %159 = load atomic i8*, i8** %143 unordered, align 8, !tbaa !47
   %160 = getelementptr inbounds i8, i8* %159, i64 %142
-  store i8 0, i8* %160, align 1, !tbaa !51
+  store i8 0, i8* %160, align 1, !tbaa !50
   %161 = lshr i32 %0, 12
   %162 = trunc i32 %161 to i8
   %163 = and i8 %162, 63
   %164 = or i8 %163, -128
-  %165 = load i64, i64* %140, align 8, !tbaa !60
+  %165 = load atomic i64, i64* %140 unordered, align 8, !tbaa !51
   %166 = add i64 %165, 1
-  %167 = load i8*, i8** %143, align 8, !tbaa !58
+  %167 = load atomic i8*, i8** %143 unordered, align 8, !tbaa !47
   %168 = icmp eq i8* %167, %146
   br i1 %168, label %172, label %169
 
 169:                                              ; preds = %156
   %170 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 2, i32 0
-  %171 = load i64, i64* %170, align 8, !tbaa !51
+  %171 = load atomic i64, i64* %170 unordered, align 8, !tbaa !50
   br label %172
 
 172:                                              ; preds = %169, %156
@@ -49515,30 +50336,30 @@
 
 175:                                              ; preds = %172
   tail call fastcc void @_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE9_M_mutateEmmPKcm(%"class.std::__cxx11::basic_string"* nonnull %1, i64 %165)
-  %176 = load i8*, i8** %143, align 8, !tbaa !58
+  %176 = load atomic i8*, i8** %143 unordered, align 8, !tbaa !47
   br label %177
 
 177:                                              ; preds = %175, %172
   %178 = phi i8* [ %176, %175 ], [ %167, %172 ]
   %179 = getelementptr inbounds i8, i8* %178, i64 %165
-  store i8 %164, i8* %179, align 1, !tbaa !51
-  store i64 %166, i64* %140, align 8, !tbaa !60
-  %180 = load i8*, i8** %143, align 8, !tbaa !58
+  store i8 %164, i8* %179, align 1, !tbaa !50
+  store i64 %166, i64* %140, align 8, !tbaa !51
+  %180 = load atomic i8*, i8** %143 unordered, align 8, !tbaa !47
   %181 = getelementptr inbounds i8, i8* %180, i64 %166
-  store i8 0, i8* %181, align 1, !tbaa !51
+  store i8 0, i8* %181, align 1, !tbaa !50
   %182 = lshr i32 %0, 6
   %183 = trunc i32 %182 to i8
   %184 = and i8 %183, 63
   %185 = or i8 %184, -128
-  %186 = load i64, i64* %140, align 8, !tbaa !60
+  %186 = load atomic i64, i64* %140 unordered, align 8, !tbaa !51
   %187 = add i64 %186, 1
-  %188 = load i8*, i8** %143, align 8, !tbaa !58
+  %188 = load atomic i8*, i8** %143 unordered, align 8, !tbaa !47
   %189 = icmp eq i8* %188, %146
   br i1 %189, label %193, label %190
 
 190:                                              ; preds = %177
   %191 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 2, i32 0
-  %192 = load i64, i64* %191, align 8, !tbaa !51
+  %192 = load atomic i64, i64* %191 unordered, align 8, !tbaa !50
   br label %193
 
 193:                                              ; preds = %190, %177
@@ -49548,29 +50369,29 @@
 
 196:                                              ; preds = %193
   tail call fastcc void @_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE9_M_mutateEmmPKcm(%"class.std::__cxx11::basic_string"* nonnull %1, i64 %186)
-  %197 = load i8*, i8** %143, align 8, !tbaa !58
+  %197 = load atomic i8*, i8** %143 unordered, align 8, !tbaa !47
   br label %198
 
 198:                                              ; preds = %196, %193
   %199 = phi i8* [ %197, %196 ], [ %188, %193 ]
   %200 = getelementptr inbounds i8, i8* %199, i64 %186
-  store i8 %185, i8* %200, align 1, !tbaa !51
-  store i64 %187, i64* %140, align 8, !tbaa !60
-  %201 = load i8*, i8** %143, align 8, !tbaa !58
+  store i8 %185, i8* %200, align 1, !tbaa !50
+  store i64 %187, i64* %140, align 8, !tbaa !51
+  %201 = load atomic i8*, i8** %143 unordered, align 8, !tbaa !47
   %202 = getelementptr inbounds i8, i8* %201, i64 %187
-  store i8 0, i8* %202, align 1, !tbaa !51
+  store i8 0, i8* %202, align 1, !tbaa !50
   %203 = trunc i32 %0 to i8
   %204 = and i8 %203, 63
   %205 = or i8 %204, -128
-  %206 = load i64, i64* %140, align 8, !tbaa !60
+  %206 = load atomic i64, i64* %140 unordered, align 8, !tbaa !51
   %207 = add i64 %206, 1
-  %208 = load i8*, i8** %143, align 8, !tbaa !58
+  %208 = load atomic i8*, i8** %143 unordered, align 8, !tbaa !47
   %209 = icmp eq i8* %208, %146
   br i1 %209, label %213, label %210
 
 210:                                              ; preds = %198
   %211 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %1, i64 0, i32 2, i32 0
-  %212 = load i64, i64* %211, align 8, !tbaa !51
+  %212 = load atomic i64, i64* %211 unordered, align 8, !tbaa !50
   br label %213
 
 213:                                              ; preds = %210, %198
@@ -49580,33 +50401,33 @@
 
 216:                                              ; preds = %213
   tail call fastcc void @_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE9_M_mutateEmmPKcm(%"class.std::__cxx11::basic_string"* nonnull %1, i64 %206)
-  %217 = load i8*, i8** %143, align 8, !tbaa !58
+  %217 = load atomic i8*, i8** %143 unordered, align 8, !tbaa !47
   br label %218
 
 218:                                              ; preds = %216, %213
   %219 = phi i8* [ %217, %216 ], [ %208, %213 ]
   %220 = getelementptr inbounds i8, i8* %219, i64 %206
-  store i8 %205, i8* %220, align 1, !tbaa !51
-  store i64 %207, i64* %140, align 8, !tbaa !60
+  store i8 %205, i8* %220, align 1, !tbaa !50
+  store i64 %207, i64* %140, align 8, !tbaa !51
   br label %221
 
 221:                                              ; preds = %218, %133, %67, %22
   %222 = phi i8** [ %34, %67 ], [ %143, %218 ], [ %79, %133 ], [ %9, %22 ]
   %223 = phi i64 [ %56, %67 ], [ %207, %218 ], [ %122, %133 ], [ %8, %22 ]
-  %224 = load i8*, i8** %222, align 8, !tbaa !58
+  %224 = load atomic i8*, i8** %222 unordered, align 8, !tbaa !47
   %225 = getelementptr inbounds i8, i8* %224, i64 %223
-  store i8 0, i8* %225, align 1, !tbaa !51
+  store i8 0, i8* %225, align 1, !tbaa !50
   ret %"class.std::__cxx11::basic_string"* %1
 }
 
 ; Function Attrs: nounwind uwtable
 define internal fastcc void @_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE9_M_mutateEmmPKcm(%"class.std::__cxx11::basic_string"* %0, i64 %1) unnamed_addr #17 align 2 personality i32 (...)* @__gxx_personality_v0 {
   %3 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %0, i64 0, i32 1
-  %4 = load i64, i64* %3, align 8, !tbaa !60
+  %4 = load atomic i64, i64* %3 unordered, align 8, !tbaa !51
   %5 = sub i64 %4, %1
   %6 = add i64 %4, 1
   %7 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %0, i64 0, i32 0, i32 0
-  %8 = load i8*, i8** %7, align 8, !tbaa !58
+  %8 = load atomic i8*, i8** %7 unordered, align 8, !tbaa !47
   %9 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %0, i64 0, i32 2
   %10 = bitcast %union.anon.108* %9 to i8*
   %11 = icmp eq i8* %8, %10
@@ -49614,7 +50435,7 @@
 
 12:                                               ; preds = %2
   %13 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %0, i64 0, i32 2, i32 0
-  %14 = load i64, i64* %13, align 8, !tbaa !51
+  %14 = load atomic i64, i64* %13 unordered, align 8, !tbaa !50
   br label %15
 
 15:                                               ; preds = %12, %2
@@ -49650,8 +50471,8 @@
   ]
 
 31:                                               ; preds = %27
-  %32 = load i8, i8* %8, align 1, !tbaa !51
-  store i8 %32, i8* %30, align 1, !tbaa !51
+  %32 = load atomic i8, i8* %8 unordered, align 1, !tbaa !50
+  store i8 %32, i8* %30, align 1, !tbaa !50
   br label %34
 
 33:                                               ; preds = %27
@@ -49670,8 +50491,8 @@
   br i1 %40, label %41, label %43
 
 41:                                               ; preds = %36
-  %42 = load i8, i8* %39, align 1, !tbaa !51
-  store i8 %42, i8* %38, align 1, !tbaa !51
+  %42 = load atomic i8, i8* %39 unordered, align 1, !tbaa !50
+  store i8 %42, i8* %38, align 1, !tbaa !50
   br label %44
 
 43:                                               ; preds = %36
@@ -49686,18 +50507,18 @@
   br label %46
 
 46:                                               ; preds = %45, %44
-  store i8* %30, i8** %7, align 8, !tbaa !58
+  store i8* %30, i8** %7, align 8, !tbaa !47
   %47 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %0, i64 0, i32 2, i32 0
-  store i64 %28, i64* %47, align 8, !tbaa !51
+  store i64 %28, i64* %47, align 8, !tbaa !50
   ret void
 }
 
 ; Function Attrs: uwtable
 define internal fastcc nonnull %struct.ObjHeader* @Kotlin_String_plusImpl(%struct.ArrayHeader* nocapture readonly %0, %struct.ArrayHeader* nocapture readonly %1, %struct.ObjHeader** nocapture %2) unnamed_addr #20 personality i32 (...)* @__gxx_personality_v0 {
   %4 = getelementptr inbounds %struct.ArrayHeader, %struct.ArrayHeader* %0, i64 0, i32 1
-  %5 = load i32, i32* %4, align 8, !tbaa !18
+  %5 = load atomic i32, i32* %4 unordered, align 8, !tbaa !18
   %6 = getelementptr inbounds %struct.ArrayHeader, %struct.ArrayHeader* %1, i64 0, i32 1
-  %7 = load i32, i32* %6, align 8, !tbaa !18
+  %7 = load atomic i32, i32* %6 unordered, align 8, !tbaa !18
   %8 = add i32 %7, %5
   %9 = icmp slt i32 %8, 0
   br i1 %9, label %10, label %AllocArrayInstance.exit
@@ -49707,10 +50528,10 @@
   unreachable
 
 AllocArrayInstance.exit:                          ; preds = %3
-  %11 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %11 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %12 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 6
   %13 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %12 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %14 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %13, align 8, !tbaa !3
+  %14 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %13 unordered, align 8, !tbaa !3
   %15 = zext i32 %8 to i64
   %16 = shl nuw nsw i64 %15, 1
   %17 = add nuw nsw i64 %16, 31
@@ -49734,17 +50555,17 @@
   %31 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %29 to i8*
   %32 = getelementptr inbounds %struct.ArrayHeader, %struct.ArrayHeader* %0, i64 1
   %33 = bitcast %struct.ArrayHeader* %32 to i8*
-  %34 = load i32, i32* %4, align 8, !tbaa !18
+  %34 = load atomic i32, i32* %4 unordered, align 8, !tbaa !18
   %35 = zext i32 %34 to i64
   %36 = shl nuw nsw i64 %35, 1
   tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %31, i8* nonnull align 2 %33, i64 %36, i1 false)
-  %37 = load i32, i32* %4, align 8, !tbaa !18
+  %37 = load atomic i32, i32* %4 unordered, align 8, !tbaa !18
   %38 = sext i32 %37 to i64
   %39 = getelementptr inbounds i16, i16* %30, i64 %38
   %40 = bitcast i16* %39 to i8*
   %41 = getelementptr inbounds %struct.ArrayHeader, %struct.ArrayHeader* %1, i64 1
   %42 = bitcast %struct.ArrayHeader* %41 to i8*
-  %43 = load i32, i32* %6, align 8, !tbaa !18
+  %43 = load atomic i32, i32* %6 unordered, align 8, !tbaa !18
   %44 = zext i32 %43 to i64
   %45 = shl nuw nsw i64 %44, 1
   tail call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 2 %40, i8* nonnull align 2 %42, i64 %45, i1 false)
@@ -49760,7 +50581,7 @@
 
 7:                                                ; preds = %4
   %8 = getelementptr inbounds %struct.ArrayHeader, %struct.ArrayHeader* %0, i64 0, i32 1
-  %9 = load i32, i32* %8, align 8, !tbaa !18
+  %9 = load atomic i32, i32* %8 unordered, align 8, !tbaa !18
   %10 = icmp ult i32 %9, %2
   %11 = icmp slt i32 %2, %1
   %12 = or i1 %11, %10
@@ -49780,11 +50601,11 @@
   %.sub.i = getelementptr inbounds [3 x %struct.ObjHeader*], [3 x %struct.ObjHeader*]* %5, i64 0, i64 0
   %18 = bitcast [3 x %struct.ObjHeader*]* %5 to i64*
   store i64 0, i64* %18, align 8
-  %19 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %19 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %20 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %19, i64 0, i32 1, i32 5
   %21 = bitcast [3 x %struct.ObjHeader*]* %5 to %struct.FrameOverlay.6*
   %22 = bitcast %"class.kotlin::mm::ShadowStack"* %20 to i64*
-  %23 = load i64, i64* %22, align 8, !tbaa !7
+  %23 = load atomic i64, i64* %22 unordered, align 8, !tbaa !7
   %24 = getelementptr inbounds [3 x %struct.ObjHeader*], [3 x %struct.ObjHeader*]* %5, i64 0, i64 1
   %25 = bitcast %struct.ObjHeader** %24 to i64*
   store i64 %23, i64* %25, align 8, !tbaa !9
@@ -49806,9 +50627,9 @@
 
 Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %33, %16
   store %struct.ObjHeader* bitcast ({ %struct.ArrayHeader, [0 x i8] }* @102 to %struct.ObjHeader*), %struct.ObjHeader** %3, align 8, !tbaa !3
-  %34 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %34 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %35 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %34, i64 0, i32 1, i32 5
-  %36 = load i64, i64* %25, align 8, !tbaa !9
+  %36 = load atomic i64, i64* %25 unordered, align 8, !tbaa !9
   %37 = bitcast %"class.kotlin::mm::ShadowStack"* %35 to i64*
   store i64 %36, i64* %37, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %17)
@@ -49824,10 +50645,10 @@
   unreachable
 
 AllocArrayInstance.exit:                          ; preds = %38
-  %42 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %42 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %43 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %42, i64 0, i32 1, i32 6
   %44 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %43 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %45 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %44, align 8, !tbaa !3
+  %45 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %44 unordered, align 8, !tbaa !3
   %46 = zext i32 %39 to i64
   %47 = shl nuw nsw i64 %46, 1
   %48 = add nuw nsw i64 %47, 31
@@ -49867,7 +50688,7 @@
 ; Function Attrs: uwtable
 define internal zeroext i16 @Kotlin_String_get(%struct.ArrayHeader* nocapture readonly %0, i32 %1) #20 {
   %3 = getelementptr inbounds %struct.ArrayHeader, %struct.ArrayHeader* %0, i64 0, i32 1
-  %4 = load i32, i32* %3, align 8, !tbaa !18
+  %4 = load atomic i32, i32* %3 unordered, align 8, !tbaa !18
   %5 = icmp ugt i32 %4, %1
   br i1 %5, label %7, label %6
 
@@ -49880,7 +50701,7 @@
   %9 = bitcast %struct.ArrayHeader* %8 to i16*
   %10 = sext i32 %1 to i64
   %11 = getelementptr inbounds i16, i16* %9, i64 %10
-  %12 = load i16, i16* %11, align 2, !tbaa !34
+  %12 = load atomic i16, i16* %11 unordered, align 2, !tbaa !27
   ret i16 %12
 }
 
@@ -49919,10 +50740,10 @@
 
 15:                                               ; preds = %12
   %16 = getelementptr inbounds %struct.ArrayHeader, %struct.ArrayHeader* %0, i64 0, i32 1
-  %17 = load i32, i32* %16, align 8, !tbaa !18
+  %17 = load atomic i32, i32* %16 unordered, align 8, !tbaa !18
   %18 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %1, i64 1
   %19 = bitcast %struct.ObjHeader* %18 to i32*
-  %20 = load i32, i32* %19, align 8, !tbaa !18
+  %20 = load atomic i32, i32* %19 unordered, align 8, !tbaa !18
   %21 = icmp eq i32 %17, %20
   br i1 %21, label %22, label %31
 
@@ -49945,7 +50766,7 @@
 ; Function Attrs: nofree nounwind uwtable
 define internal i32 @Kotlin_String_hashCode(%struct.ArrayHeader* nocapture readonly %0) #21 {
   %2 = getelementptr inbounds %struct.ArrayHeader, %struct.ArrayHeader* %0, i64 0, i32 1
-  %3 = load i32, i32* %2, align 8, !tbaa !18
+  %3 = load atomic i32, i32* %2 unordered, align 8, !tbaa !18
   %4 = getelementptr inbounds %struct.ArrayHeader, %struct.ArrayHeader* %0, i64 1
   %5 = bitcast %struct.ArrayHeader* %4 to i16*
   %6 = load i1, i1* @_ZN12_GLOBAL__N_111initializedE, align 1
@@ -49953,14 +50774,14 @@
 
 7:                                                ; preds = %1
   store i1 true, i1* @_ZN12_GLOBAL__N_111initializedE, align 1
-  %8 = load i32, i32* getelementptr inbounds ({ i32, i32, i32, [1 x i32] }, { i32, i32, i32, [1 x i32] }* @__cpu_model, i64 0, i32 3, i64 0), align 4
+  %8 = load atomic i32, i32* getelementptr inbounds ({ i32, i32, i32, [1 x i32] }, { i32, i32, i32, [1 x i32] }* @__cpu_model, i64 0, i32 3, i64 0) unordered, align 4
   %9 = trunc i32 %8 to i8
   %10 = lshr i8 %9, 7
-  store i8 %10, i8* @_ZN12_GLOBAL__N_112sseSupportedE, align 1, !tbaa !70
+  store i8 %10, i8* @_ZN12_GLOBAL__N_112sseSupportedE, align 1, !tbaa !69
   %11 = lshr i32 %8, 10
   %12 = trunc i32 %11 to i8
   %13 = and i8 %12, 1
-  store i8 %13, i8* @_ZN12_GLOBAL__N_113avx2SupportedE, align 1, !tbaa !70
+  store i8 %13, i8* @_ZN12_GLOBAL__N_113avx2SupportedE, align 1, !tbaa !69
   br label %14
 
 14:                                               ; preds = %7, %1
@@ -49968,8 +50789,8 @@
   br i1 %15, label %22, label %16
 
 16:                                               ; preds = %14
-  %17 = load i8, i8* @_ZN12_GLOBAL__N_112sseSupportedE, align 1, !tbaa !70, !range !72
-  %18 = load i8, i8* @_ZN12_GLOBAL__N_113avx2SupportedE, align 1
+  %17 = load atomic i8, i8* @_ZN12_GLOBAL__N_112sseSupportedE unordered, align 1, !tbaa !69, !range !70
+  %18 = load atomic i8, i8* @_ZN12_GLOBAL__N_113avx2SupportedE unordered, align 1
   %19 = icmp eq i8 %18, 0
   %20 = or i8 %18, %17
   %21 = icmp eq i8 %20, 0
@@ -49996,25 +50817,25 @@
   %34 = phi i64 [ %30, %29 ], [ %59, %31 ]
   %35 = mul i32 %33, 31
   %36 = getelementptr inbounds i16, i16* %5, i64 %32
-  %37 = load i16, i16* %36, align 2, !tbaa !34
+  %37 = load atomic i16, i16* %36 unordered, align 2, !tbaa !27
   %38 = zext i16 %37 to i32
   %39 = add i32 %35, %38
   %40 = or i64 %32, 1
   %41 = mul i32 %39, 31
   %42 = getelementptr inbounds i16, i16* %5, i64 %40
-  %43 = load i16, i16* %42, align 2, !tbaa !34
+  %43 = load atomic i16, i16* %42 unordered, align 2, !tbaa !27
   %44 = zext i16 %43 to i32
   %45 = add i32 %41, %44
   %46 = or i64 %32, 2
   %47 = mul i32 %45, 31
   %48 = getelementptr inbounds i16, i16* %5, i64 %46
-  %49 = load i16, i16* %48, align 2, !tbaa !34
+  %49 = load atomic i16, i16* %48 unordered, align 2, !tbaa !27
   %50 = zext i16 %49 to i32
   %51 = add i32 %47, %50
   %52 = or i64 %32, 3
   %53 = mul i32 %51, 31
   %54 = getelementptr inbounds i16, i16* %5, i64 %52
-  %55 = load i16, i16* %54, align 2, !tbaa !34
+  %55 = load atomic i16, i16* %54 unordered, align 2, !tbaa !27
   %56 = zext i16 %55 to i32
   %57 = add i32 %53, %56
   %58 = add nuw nsw i64 %32, 4
@@ -50082,13 +50903,13 @@
   %95 = phi i64 [ %102, %.preheader3 ], [ %91, %86 ]
   %96 = mul i32 %94, 31
   %97 = getelementptr inbounds i16, i16* %5, i64 %93
-  %98 = load i16, i16* %97, align 2, !tbaa !34
+  %98 = load atomic i16, i16* %97 unordered, align 2, !tbaa !27
   %99 = zext i16 %98 to i32
   %100 = add i32 %96, %99
   %101 = add nuw nsw i64 %93, 1
   %102 = add nsw i64 %95, -1
   %103 = icmp eq i64 %102, 0
-  br i1 %103, label %.loopexit4, label %.preheader3, !llvm.loop !631
+  br i1 %103, label %.loopexit4, label %.preheader3, !llvm.loop !643
 
 .loopexit4:                                       ; preds = %.preheader3
   %104 = or i64 %91, %87
@@ -50106,25 +50927,25 @@
   %111 = phi i32 [ %134, %.preheader1 ], [ %108, %105 ]
   %112 = mul i32 %111, 31
   %113 = getelementptr inbounds i16, i16* %5, i64 %110
-  %114 = load i16, i16* %113, align 2, !tbaa !34
+  %114 = load atomic i16, i16* %113 unordered, align 2, !tbaa !27
   %115 = zext i16 %114 to i32
   %116 = add i32 %112, %115
   %117 = add nuw nsw i64 %110, 1
   %118 = mul i32 %116, 31
   %119 = getelementptr inbounds i16, i16* %5, i64 %117
-  %120 = load i16, i16* %119, align 2, !tbaa !34
+  %120 = load atomic i16, i16* %119 unordered, align 2, !tbaa !27
   %121 = zext i16 %120 to i32
   %122 = add i32 %118, %121
   %123 = add nuw nsw i64 %110, 2
   %124 = mul i32 %122, 31
   %125 = getelementptr inbounds i16, i16* %5, i64 %123
-  %126 = load i16, i16* %125, align 2, !tbaa !34
+  %126 = load atomic i16, i16* %125 unordered, align 2, !tbaa !27
   %127 = zext i16 %126 to i32
   %128 = add i32 %124, %127
   %129 = add nuw nsw i64 %110, 3
   %130 = mul i32 %128, 31
   %131 = getelementptr inbounds i16, i16* %5, i64 %129
-  %132 = load i16, i16* %131, align 2, !tbaa !34
+  %132 = load atomic i16, i16* %131 unordered, align 2, !tbaa !27
   %133 = zext i16 %132 to i32
   %134 = add i32 %130, %133
   %135 = add nuw nsw i64 %110, 4
@@ -50144,13 +50965,13 @@
   %143 = phi i64 [ %150, %.preheader ], [ %27, %.loopexit ]
   %144 = mul i32 %142, 31
   %145 = getelementptr inbounds i16, i16* %5, i64 %141
-  %146 = load i16, i16* %145, align 2, !tbaa !34
+  %146 = load atomic i16, i16* %145 unordered, align 2, !tbaa !27
   %147 = zext i16 %146 to i32
   %148 = add i32 %144, %147
   %149 = add nuw nsw i64 %141, 1
   %150 = add nsw i64 %143, -1
   %151 = icmp eq i64 %150, 0
-  br i1 %151, label %_Z8polyHashiPKt.exit, label %.preheader, !llvm.loop !632
+  br i1 %151, label %_Z8polyHashiPKt.exit, label %.preheader, !llvm.loop !644
 
 _Z8polyHashiPKt.exit:                             ; preds = %.preheader, %.loopexit, %.preheader1, %105, %82, %22
   %152 = phi i32 [ 0, %22 ], [ %83, %82 ], [ %137, %.loopexit ], [ %106, %105 ], [ %148, %.preheader ], [ %134, %.preheader1 ]
@@ -50167,12 +50988,12 @@
   %6 = phi <4 x i32> [ %22, %3 ], [ zeroinitializer, %2 ]
   %7 = phi <4 x i32> [ %21, %3 ], [ zeroinitializer, %2 ]
   %8 = bitcast i16* %5 to <8 x i16>*
-  %9 = load <8 x i16>, <8 x i16>* %8, align 16, !tbaa !51
+  %9 = load <8 x i16>, <8 x i16>* %8, align 16, !tbaa !50
   %10 = shufflevector <8 x i16> %9, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
   %11 = zext <4 x i16> %10 to <4 x i32>
   %12 = getelementptr inbounds i16, i16* %5, i64 4
   %13 = bitcast i16* %12 to <8 x i16>*
-  %14 = load <8 x i16>, <8 x i16>* %13, align 16, !tbaa !51
+  %14 = load <8 x i16>, <8 x i16>* %13, align 16, !tbaa !50
   %15 = shufflevector <8 x i16> %14, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
   %16 = zext <4 x i16> %15 to <4 x i32>
   %17 = mul <4 x i32> %7, <i32 -1807454463, i32 -1807454463, i32 -1807454463, i32 -1807454463>
@@ -50195,7 +51016,7 @@
 
 30:                                               ; preds = %26
   %31 = bitcast i16* %23 to <8 x i16>*
-  %32 = load <8 x i16>, <8 x i16>* %31, align 16, !tbaa !51
+  %32 = load <8 x i16>, <8 x i16>* %31, align 16, !tbaa !50
   %33 = shufflevector <8 x i16> %32, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
   %34 = zext <4 x i16> %33 to <4 x i32>
   %35 = mul <4 x i32> %29, <i32 923521, i32 923521, i32 923521, i32 923521>
@@ -50223,22 +51044,22 @@
   %8 = phi <4 x i32> [ %38, %3 ], [ zeroinitializer, %2 ]
   %9 = phi <4 x i32> [ %37, %3 ], [ zeroinitializer, %2 ]
   %10 = bitcast i16* %5 to <8 x i16>*
-  %11 = load <8 x i16>, <8 x i16>* %10, align 16, !tbaa !51
+  %11 = load <8 x i16>, <8 x i16>* %10, align 16, !tbaa !50
   %12 = shufflevector <8 x i16> %11, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
   %13 = zext <4 x i16> %12 to <4 x i32>
   %14 = getelementptr inbounds i16, i16* %5, i64 4
   %15 = bitcast i16* %14 to <8 x i16>*
-  %16 = load <8 x i16>, <8 x i16>* %15, align 16, !tbaa !51
+  %16 = load <8 x i16>, <8 x i16>* %15, align 16, !tbaa !50
   %17 = shufflevector <8 x i16> %16, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
   %18 = zext <4 x i16> %17 to <4 x i32>
   %19 = getelementptr inbounds i16, i16* %5, i64 8
   %20 = bitcast i16* %19 to <8 x i16>*
-  %21 = load <8 x i16>, <8 x i16>* %20, align 16, !tbaa !51
+  %21 = load <8 x i16>, <8 x i16>* %20, align 16, !tbaa !50
   %22 = shufflevector <8 x i16> %21, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
   %23 = zext <4 x i16> %22 to <4 x i32>
   %24 = getelementptr inbounds i16, i16* %5, i64 12
   %25 = bitcast i16* %24 to <8 x i16>*
-  %26 = load <8 x i16>, <8 x i16>* %25, align 16, !tbaa !51
+  %26 = load <8 x i16>, <8 x i16>* %25, align 16, !tbaa !50
   %27 = shufflevector <8 x i16> %26, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
   %28 = zext <4 x i16> %27 to <4 x i32>
   %29 = mul <4 x i32> %9, <i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697>
@@ -50275,12 +51096,12 @@
   %55 = phi <4 x i32> [ %71, %.preheader ], [ zeroinitializer, %44 ]
   %56 = phi <4 x i32> [ %70, %.preheader ], [ zeroinitializer, %44 ]
   %57 = bitcast i16* %54 to <8 x i16>*
-  %58 = load <8 x i16>, <8 x i16>* %57, align 16, !tbaa !51
+  %58 = load <8 x i16>, <8 x i16>* %57, align 16, !tbaa !50
   %59 = shufflevector <8 x i16> %58, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
   %60 = zext <4 x i16> %59 to <4 x i32>
   %61 = getelementptr inbounds i16, i16* %54, i64 4
   %62 = bitcast i16* %61 to <8 x i16>*
-  %63 = load <8 x i16>, <8 x i16>* %62, align 16, !tbaa !51
+  %63 = load <8 x i16>, <8 x i16>* %62, align 16, !tbaa !50
   %64 = shufflevector <8 x i16> %63, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
   %65 = zext <4 x i16> %64 to <4 x i32>
   %66 = mul <4 x i32> %56, <i32 -1807454463, i32 -1807454463, i32 -1807454463, i32 -1807454463>
@@ -50311,7 +51132,7 @@
 
 86:                                               ; preds = %81
   %87 = bitcast i16* %83 to <8 x i16>*
-  %88 = load <8 x i16>, <8 x i16>* %87, align 16, !tbaa !51
+  %88 = load <8 x i16>, <8 x i16>* %87, align 16, !tbaa !50
   %89 = shufflevector <8 x i16> %88, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
   %90 = zext <4 x i16> %89 to <4 x i32>
   %91 = mul <4 x i32> %84, <i32 923521, i32 923521, i32 923521, i32 923521>
@@ -50337,11 +51158,11 @@
   %6 = phi <8 x i32> [ %20, %3 ], [ zeroinitializer, %2 ]
   %7 = phi <8 x i32> [ %19, %3 ], [ zeroinitializer, %2 ]
   %8 = bitcast i16* %5 to <8 x i16>*
-  %9 = load <8 x i16>, <8 x i16>* %8, align 16, !tbaa !51
+  %9 = load <8 x i16>, <8 x i16>* %8, align 16, !tbaa !50
   %10 = zext <8 x i16> %9 to <8 x i32>
   %11 = getelementptr inbounds i16, i16* %5, i64 8
   %12 = bitcast i16* %11 to <8 x i16>*
-  %13 = load <8 x i16>, <8 x i16>* %12, align 16, !tbaa !51
+  %13 = load <8 x i16>, <8 x i16>* %12, align 16, !tbaa !50
   %14 = zext <8 x i16> %13 to <8 x i32>
   %15 = mul <8 x i32> %7, <i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697>
   %16 = mul <8 x i32> %6, <i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697>
@@ -50369,7 +51190,7 @@
 
 35:                                               ; preds = %24
   %36 = bitcast i16* %21 to <8 x i16>*
-  %37 = load <8 x i16>, <8 x i16>* %36, align 16, !tbaa !51
+  %37 = load <8 x i16>, <8 x i16>* %36, align 16, !tbaa !50
   %38 = zext <8 x i16> %37 to <8 x i32>
   %39 = mul <4 x i32> %33, <i32 -1807454463, i32 -1807454463, i32 -1807454463, i32 -1807454463>
   %40 = mul <8 x i32> %38, <i32 1742810335, i32 887503681, i32 28629151, i32 923521, i32 29791, i32 961, i32 31, i32 1>
@@ -50395,7 +51216,7 @@
 
 57:                                               ; preds = %52
   %58 = bitcast i16* %54 to <8 x i16>*
-  %59 = load <8 x i16>, <8 x i16>* %58, align 16, !tbaa !51
+  %59 = load <8 x i16>, <8 x i16>* %58, align 16, !tbaa !50
   %60 = shufflevector <8 x i16> %59, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
   %61 = zext <4 x i16> %60 to <4 x i32>
   %62 = mul <4 x i32> %55, <i32 923521, i32 923521, i32 923521, i32 923521>
@@ -50423,19 +51244,19 @@
   %8 = phi <8 x i32> [ %34, %3 ], [ zeroinitializer, %2 ]
   %9 = phi <8 x i32> [ %33, %3 ], [ zeroinitializer, %2 ]
   %10 = bitcast i16* %5 to <8 x i16>*
-  %11 = load <8 x i16>, <8 x i16>* %10, align 16, !tbaa !51
+  %11 = load <8 x i16>, <8 x i16>* %10, align 16, !tbaa !50
   %12 = zext <8 x i16> %11 to <8 x i32>
   %13 = getelementptr inbounds i16, i16* %5, i64 8
   %14 = bitcast i16* %13 to <8 x i16>*
-  %15 = load <8 x i16>, <8 x i16>* %14, align 16, !tbaa !51
+  %15 = load <8 x i16>, <8 x i16>* %14, align 16, !tbaa !50
   %16 = zext <8 x i16> %15 to <8 x i32>
   %17 = getelementptr inbounds i16, i16* %5, i64 16
   %18 = bitcast i16* %17 to <8 x i16>*
-  %19 = load <8 x i16>, <8 x i16>* %18, align 16, !tbaa !51
+  %19 = load <8 x i16>, <8 x i16>* %18, align 16, !tbaa !50
   %20 = zext <8 x i16> %19 to <8 x i32>
   %21 = getelementptr inbounds i16, i16* %5, i64 24
   %22 = bitcast i16* %21 to <8 x i16>*
-  %23 = load <8 x i16>, <8 x i16>* %22, align 16, !tbaa !51
+  %23 = load <8 x i16>, <8 x i16>* %22, align 16, !tbaa !50
   %24 = zext <8 x i16> %23 to <8 x i32>
   %25 = mul <8 x i32> %9, <i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369>
   %26 = mul <8 x i32> %8, <i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369>
@@ -50483,11 +51304,11 @@
   %63 = phi <8 x i32> [ %77, %.preheader ], [ zeroinitializer, %40 ]
   %64 = phi <8 x i32> [ %76, %.preheader ], [ zeroinitializer, %40 ]
   %65 = bitcast i16* %62 to <8 x i16>*
-  %66 = load <8 x i16>, <8 x i16>* %65, align 16, !tbaa !51
+  %66 = load <8 x i16>, <8 x i16>* %65, align 16, !tbaa !50
   %67 = zext <8 x i16> %66 to <8 x i32>
   %68 = getelementptr inbounds i16, i16* %62, i64 8
   %69 = bitcast i16* %68 to <8 x i16>*
-  %70 = load <8 x i16>, <8 x i16>* %69, align 16, !tbaa !51
+  %70 = load <8 x i16>, <8 x i16>* %69, align 16, !tbaa !50
   %71 = zext <8 x i16> %70 to <8 x i32>
   %72 = mul <8 x i32> %64, <i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697>
   %73 = mul <8 x i32> %63, <i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697>
@@ -50523,7 +51344,7 @@
 
 98:                                               ; preds = %93
   %99 = bitcast i16* %95 to <8 x i16>*
-  %100 = load <8 x i16>, <8 x i16>* %99, align 16, !tbaa !51
+  %100 = load <8 x i16>, <8 x i16>* %99, align 16, !tbaa !50
   %101 = zext <8 x i16> %100 to <8 x i32>
   %102 = mul <4 x i32> %96, <i32 -1807454463, i32 -1807454463, i32 -1807454463, i32 -1807454463>
   %103 = mul <8 x i32> %101, <i32 1742810335, i32 887503681, i32 28629151, i32 923521, i32 29791, i32 961, i32 31, i32 1>
@@ -50549,7 +51370,7 @@
 
 120:                                              ; preds = %115
   %121 = bitcast i16* %117 to <8 x i16>*
-  %122 = load <8 x i16>, <8 x i16>* %121, align 16, !tbaa !51
+  %122 = load <8 x i16>, <8 x i16>* %121, align 16, !tbaa !50
   %123 = shufflevector <8 x i16> %122, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
   %124 = zext <4 x i16> %123 to <4 x i32>
   %125 = mul <4 x i32> %118, <i32 923521, i32 923521, i32 923521, i32 923521>
@@ -50581,35 +51402,35 @@
   %12 = phi <8 x i32> [ %62, %3 ], [ zeroinitializer, %2 ]
   %13 = phi <8 x i32> [ %61, %3 ], [ zeroinitializer, %2 ]
   %14 = bitcast i16* %5 to <8 x i16>*
-  %15 = load <8 x i16>, <8 x i16>* %14, align 16, !tbaa !51
+  %15 = load <8 x i16>, <8 x i16>* %14, align 16, !tbaa !50
   %16 = zext <8 x i16> %15 to <8 x i32>
   %17 = getelementptr inbounds i16, i16* %5, i64 8
   %18 = bitcast i16* %17 to <8 x i16>*
-  %19 = load <8 x i16>, <8 x i16>* %18, align 16, !tbaa !51
+  %19 = load <8 x i16>, <8 x i16>* %18, align 16, !tbaa !50
   %20 = zext <8 x i16> %19 to <8 x i32>
   %21 = getelementptr inbounds i16, i16* %5, i64 16
   %22 = bitcast i16* %21 to <8 x i16>*
-  %23 = load <8 x i16>, <8 x i16>* %22, align 16, !tbaa !51
+  %23 = load <8 x i16>, <8 x i16>* %22, align 16, !tbaa !50
   %24 = zext <8 x i16> %23 to <8 x i32>
   %25 = getelementptr inbounds i16, i16* %5, i64 24
   %26 = bitcast i16* %25 to <8 x i16>*
-  %27 = load <8 x i16>, <8 x i16>* %26, align 16, !tbaa !51
+  %27 = load <8 x i16>, <8 x i16>* %26, align 16, !tbaa !50
   %28 = zext <8 x i16> %27 to <8 x i32>
   %29 = getelementptr inbounds i16, i16* %5, i64 32
   %30 = bitcast i16* %29 to <8 x i16>*
-  %31 = load <8 x i16>, <8 x i16>* %30, align 16, !tbaa !51
+  %31 = load <8 x i16>, <8 x i16>* %30, align 16, !tbaa !50
   %32 = zext <8 x i16> %31 to <8 x i32>
   %33 = getelementptr inbounds i16, i16* %5, i64 40
   %34 = bitcast i16* %33 to <8 x i16>*
-  %35 = load <8 x i16>, <8 x i16>* %34, align 16, !tbaa !51
+  %35 = load <8 x i16>, <8 x i16>* %34, align 16, !tbaa !50
   %36 = zext <8 x i16> %35 to <8 x i32>
   %37 = getelementptr inbounds i16, i16* %5, i64 48
   %38 = bitcast i16* %37 to <8 x i16>*
-  %39 = load <8 x i16>, <8 x i16>* %38, align 16, !tbaa !51
+  %39 = load <8 x i16>, <8 x i16>* %38, align 16, !tbaa !50
   %40 = zext <8 x i16> %39 to <8 x i32>
   %41 = getelementptr inbounds i16, i16* %5, i64 56
   %42 = bitcast i16* %41 to <8 x i16>*
-  %43 = load <8 x i16>, <8 x i16>* %42, align 16, !tbaa !51
+  %43 = load <8 x i16>, <8 x i16>* %42, align 16, !tbaa !50
   %44 = zext <8 x i16> %43 to <8 x i32>
   %45 = mul <8 x i32> %13, <i32 1304393729, i32 1304393729, i32 1304393729, i32 1304393729, i32 1304393729, i32 1304393729, i32 1304393729, i32 1304393729>
   %46 = mul <8 x i32> %12, <i32 1304393729, i32 1304393729, i32 1304393729, i32 1304393729, i32 1304393729, i32 1304393729, i32 1304393729, i32 1304393729>
@@ -50691,19 +51512,19 @@
   %117 = phi <8 x i32> [ %143, %.preheader7 ], [ zeroinitializer, %72 ]
   %118 = phi <8 x i32> [ %142, %.preheader7 ], [ zeroinitializer, %72 ]
   %119 = bitcast i16* %114 to <8 x i16>*
-  %120 = load <8 x i16>, <8 x i16>* %119, align 16, !tbaa !51
+  %120 = load <8 x i16>, <8 x i16>* %119, align 16, !tbaa !50
   %121 = zext <8 x i16> %120 to <8 x i32>
   %122 = getelementptr inbounds i16, i16* %114, i64 8
   %123 = bitcast i16* %122 to <8 x i16>*
-  %124 = load <8 x i16>, <8 x i16>* %123, align 16, !tbaa !51
+  %124 = load <8 x i16>, <8 x i16>* %123, align 16, !tbaa !50
   %125 = zext <8 x i16> %124 to <8 x i32>
   %126 = getelementptr inbounds i16, i16* %114, i64 16
   %127 = bitcast i16* %126 to <8 x i16>*
-  %128 = load <8 x i16>, <8 x i16>* %127, align 16, !tbaa !51
+  %128 = load <8 x i16>, <8 x i16>* %127, align 16, !tbaa !50
   %129 = zext <8 x i16> %128 to <8 x i32>
   %130 = getelementptr inbounds i16, i16* %114, i64 24
   %131 = bitcast i16* %130 to <8 x i16>*
-  %132 = load <8 x i16>, <8 x i16>* %131, align 16, !tbaa !51
+  %132 = load <8 x i16>, <8 x i16>* %131, align 16, !tbaa !50
   %133 = zext <8 x i16> %132 to <8 x i32>
   %134 = mul <8 x i32> %118, <i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369>
   %135 = mul <8 x i32> %117, <i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369, i32 2111290369>
@@ -50759,11 +51580,11 @@
   %178 = phi <8 x i32> [ %192, %.preheader ], [ zeroinitializer, %171 ]
   %179 = phi <8 x i32> [ %191, %.preheader ], [ zeroinitializer, %171 ]
   %180 = bitcast i16* %177 to <8 x i16>*
-  %181 = load <8 x i16>, <8 x i16>* %180, align 16, !tbaa !51
+  %181 = load <8 x i16>, <8 x i16>* %180, align 16, !tbaa !50
   %182 = zext <8 x i16> %181 to <8 x i32>
   %183 = getelementptr inbounds i16, i16* %177, i64 8
   %184 = bitcast i16* %183 to <8 x i16>*
-  %185 = load <8 x i16>, <8 x i16>* %184, align 16, !tbaa !51
+  %185 = load <8 x i16>, <8 x i16>* %184, align 16, !tbaa !50
   %186 = zext <8 x i16> %185 to <8 x i32>
   %187 = mul <8 x i32> %179, <i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697>
   %188 = mul <8 x i32> %178, <i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697, i32 1353309697>
@@ -50799,7 +51620,7 @@
 
 213:                                              ; preds = %208
   %214 = bitcast i16* %210 to <8 x i16>*
-  %215 = load <8 x i16>, <8 x i16>* %214, align 16, !tbaa !51
+  %215 = load <8 x i16>, <8 x i16>* %214, align 16, !tbaa !50
   %216 = zext <8 x i16> %215 to <8 x i32>
   %217 = mul <4 x i32> %211, <i32 -1807454463, i32 -1807454463, i32 -1807454463, i32 -1807454463>
   %218 = mul <8 x i32> %216, <i32 1742810335, i32 887503681, i32 28629151, i32 923521, i32 29791, i32 961, i32 31, i32 1>
@@ -50825,7 +51646,7 @@
 
 235:                                              ; preds = %230
   %236 = bitcast i16* %232 to <8 x i16>*
-  %237 = load <8 x i16>, <8 x i16>* %236, align 16, !tbaa !51
+  %237 = load <8 x i16>, <8 x i16>* %236, align 16, !tbaa !50
   %238 = shufflevector <8 x i16> %237, <8 x i16> undef, <4 x i32> <i32 0, i32 1, i32 2, i32 3>
   %239 = zext <4 x i16> %238 to <4 x i32>
   %240 = mul <4 x i32> %233, <i32 923521, i32 923521, i32 923521, i32 923521>
@@ -50862,12 +51683,12 @@
 7:                                                ; preds = %4
   %8 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %9 = bitcast %struct.ObjHeader* %8 to i64*
-  %10 = load i64, i64* %9, align 8, !tbaa !633
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa !645
   %11 = tail call fastcc %"class.(anonymous namespace)::State"* @_ZN12_GLOBAL__N_18theStateEv() #37
   %.sroa.5.0.sroa_cast = bitcast { i8*, %"class.(anonymous namespace)::Future"*, i32 }* %.sroa.5 to i8*
   call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %.sroa.5.0.sroa_cast)
   %12 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %11, i64 0, i32 0
-  %13 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
+  %13 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
   %14 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %13, i64 328
   %15 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %14 to i32*
   %16 = atomicrmw xchg i32* %15, i32 1 seq_cst, align 4
@@ -50896,21 +51717,21 @@
 _ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit1.i.i: ; preds = %29, %25, %19, %7
   %30 = sext i32 %5 to i64
   %31 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %11, i64 0, i32 3, i32 0, i32 1
-  %32 = load i64, i64* %31, align 8, !tbaa !635
+  %32 = load atomic i64, i64* %31 unordered, align 8, !tbaa !647
   %33 = urem i64 %30, %32
   %34 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %11, i64 0, i32 3, i32 0, i32 0
-  %35 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %34, align 8, !tbaa !637
+  %35 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %34 unordered, align 8, !tbaa !649
   %36 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %35, i64 %33
-  %37 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %36, align 8, !tbaa !3
+  %37 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %36 unordered, align 8, !tbaa !3
   %38 = icmp eq %"struct.std::__detail::_Hash_node_base"* %37, null
   br i1 %38, label %.loopexit, label %39
 
 39:                                               ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit1.i.i
   %40 = bitcast %"struct.std::__detail::_Hash_node_base"* %37 to %"struct.std::__detail::_Hash_node.203"**
-  %41 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %40, align 8, !tbaa !216
+  %41 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %40 unordered, align 8, !tbaa !215
   %42 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %41, i64 0, i32 0, i32 1
   %43 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %42 to i32*
-  %44 = load i32, i32* %43, align 4, !tbaa !73
+  %44 = load atomic i32, i32* %43 unordered, align 4, !tbaa !71
   %45 = icmp eq i32 %44, %5
   br i1 %45, label %62, label %.preheader
 
@@ -50921,7 +51742,7 @@
 .preheader:                                       ; preds = %46, %39
   %48 = phi %"struct.std::__detail::_Hash_node.203"* [ %52, %46 ], [ %41, %39 ]
   %49 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %48, i64 0, i32 0, i32 0, i32 0
-  %50 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %49, align 8, !tbaa !216
+  %50 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %49 unordered, align 8, !tbaa !215
   %51 = icmp eq %"struct.std::__detail::_Hash_node_base"* %50, null
   %52 = bitcast %"struct.std::__detail::_Hash_node_base"* %50 to %"struct.std::__detail::_Hash_node.203"*
   br i1 %51, label %.loopexit, label %53
@@ -50929,7 +51750,7 @@
 53:                                               ; preds = %.preheader
   %54 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %50, i64 1
   %55 = bitcast %"struct.std::__detail::_Hash_node_base"* %54 to i32*
-  %56 = load i32, i32* %55, align 4, !tbaa !73
+  %56 = load atomic i32, i32* %55 unordered, align 4, !tbaa !71
   %57 = sext i32 %56 to i64
   %58 = urem i64 %57, %32
   %59 = icmp eq i64 %58, %33
@@ -50947,16 +51768,16 @@
   %65 = phi %"struct.std::__detail::_Hash_node.203"* [ %52, %60 ], [ %41, %62 ]
   %66 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %65, i64 0, i32 0, i32 1, i32 0, i32 0, i64 8
   %67 = bitcast i8* %66 to %class.Worker**
-  %68 = load %class.Worker*, %class.Worker** %67, align 8, !tbaa !638
+  %68 = load atomic %class.Worker*, %class.Worker** %67 unordered, align 8, !tbaa !650
   %.sroa.7.0.sroa_cast26 = bitcast { i8*, %"class.(anonymous namespace)::Future"*, i32 }* %.sroa.7 to i8*
   call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %.sroa.7.0.sroa_cast26)
   call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %.sroa.7.0.sroa_cast26, i8* nonnull align 8 dereferenceable(24) %.sroa.5.0.sroa_cast, i64 24, i1 false)
-  %69 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
+  %69 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
   %70 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %69, i64 328
   %71 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %70 to i32*
   %72 = atomicrmw xchg i32* %71, i32 1 seq_cst, align 4
   %73 = getelementptr inbounds %class.Worker, %class.Worker* %68, i64 0, i32 5
-  %74 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
+  %74 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
   %75 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %74, i64 328
   %76 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %75 to i32*
   %77 = atomicrmw xchg i32* %76, i32 1 seq_cst, align 4
@@ -50985,35 +51806,35 @@
 _ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i.i: ; preds = %90, %86, %80, %64
   %91 = getelementptr inbounds %class.Worker, %class.Worker* %68, i64 0, i32 2
   %92 = getelementptr inbounds %class.Worker, %class.Worker* %68, i64 0, i32 2, i32 0, i32 0, i32 3, i32 0
-  %93 = load %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %92, align 8, !tbaa !640
+  %93 = load atomic %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %92 unordered, align 8, !tbaa !652
   %94 = getelementptr inbounds %class.Worker, %class.Worker* %68, i64 0, i32 2, i32 0, i32 0, i32 3, i32 2
-  %95 = load %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %94, align 8, !tbaa !644
+  %95 = load atomic %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %94 unordered, align 8, !tbaa !656
   %96 = getelementptr inbounds %"struct.(anonymous namespace)::Job", %"struct.(anonymous namespace)::Job"* %95, i64 -1
   %97 = icmp eq %"struct.(anonymous namespace)::Job"* %93, %96
   br i1 %97, label %101, label %98
 
 98:                                               ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i.i
   %.sroa.011.0..sroa_idx = getelementptr inbounds %"struct.(anonymous namespace)::Job", %"struct.(anonymous namespace)::Job"* %93, i64 0, i32 0
-  store i32 3, i32* %.sroa.011.0..sroa_idx, align 8, !tbaa.struct !645
+  store i32 3, i32* %.sroa.011.0..sroa_idx, align 8, !tbaa.struct !657
   %.sroa.6.0..sroa_idx19 = getelementptr inbounds %"struct.(anonymous namespace)::Job", %"struct.(anonymous namespace)::Job"* %93, i64 0, i32 1
   %.sroa.6.0..sroa_cast = bitcast %union.anon.103* %.sroa.6.0..sroa_idx19 to i64*
-  store i64 %10, i64* %.sroa.6.0..sroa_cast, align 8, !tbaa.struct !645
+  store i64 %10, i64* %.sroa.6.0..sroa_cast, align 8, !tbaa.struct !657
   %.sroa.7.0..sroa_idx = getelementptr inbounds %"struct.(anonymous namespace)::Job", %"struct.(anonymous namespace)::Job"* %93, i64 0, i32 1, i32 0, i32 1
   %.sroa.7.0..sroa_cast = bitcast i8** %.sroa.7.0..sroa_idx to i8*
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %.sroa.7.0..sroa_cast, i8* nonnull align 8 dereferenceable(24) %.sroa.7.0.sroa_cast26, i64 24, i1 false), !tbaa.struct !645
-  %99 = load %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %92, align 8, !tbaa !640
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %.sroa.7.0..sroa_cast, i8* nonnull align 8 dereferenceable(24) %.sroa.7.0.sroa_cast26, i64 24, i1 false), !tbaa.struct !657
+  %99 = load atomic %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %92 unordered, align 8, !tbaa !652
   %100 = getelementptr inbounds %"struct.(anonymous namespace)::Job", %"struct.(anonymous namespace)::Job"* %99, i64 1
-  store %"struct.(anonymous namespace)::Job"* %100, %"struct.(anonymous namespace)::Job"** %92, align 8, !tbaa !640
+  store %"struct.(anonymous namespace)::Job"* %100, %"struct.(anonymous namespace)::Job"** %92, align 8, !tbaa !652
   br label %193
 
 101:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i.i
   %102 = getelementptr inbounds %class.Worker, %class.Worker* %68, i64 0, i32 2, i32 0, i32 0, i32 1
-  %103 = load i64, i64* %102, align 8, !tbaa !646
+  %103 = load atomic i64, i64* %102 unordered, align 8, !tbaa !658
   %104 = getelementptr inbounds %class.Worker, %class.Worker* %68, i64 0, i32 2, i32 0, i32 0, i32 3, i32 3
   %105 = bitcast %"struct.(anonymous namespace)::Job"*** %104 to i64*
-  %106 = load i64, i64* %105, align 8, !tbaa !647
+  %106 = load atomic i64, i64* %105 unordered, align 8, !tbaa !659
   %107 = bitcast %"class.std::deque"* %91 to i64*
-  %108 = load i64, i64* %107, align 8, !tbaa !648
+  %108 = load atomic i64, i64* %107 unordered, align 8, !tbaa !660
   %109 = sub i64 %106, %108
   %110 = ashr exact i64 %109, 3
   %111 = sub i64 %103, %110
@@ -51024,7 +51845,7 @@
 
 115:                                              ; preds = %101
   %116 = getelementptr inbounds %class.Worker, %class.Worker* %68, i64 0, i32 2, i32 0, i32 0, i32 2, i32 3
-  %117 = load %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %116, align 8, !tbaa !649
+  %117 = load atomic %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %116 unordered, align 8, !tbaa !661
   %118 = ptrtoint %"struct.(anonymous namespace)::Job"** %117 to i64
   %119 = sub i64 %106, %118
   %120 = ashr exact i64 %119, 3
@@ -51077,8 +51898,8 @@
   %153 = sub i64 %150, %122
   %154 = lshr i64 %153, 1
   %155 = getelementptr inbounds %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %152, i64 %154
-  %156 = load %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %116, align 8, !tbaa !649
-  %157 = load %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %104, align 8, !tbaa !647
+  %156 = load atomic %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %116 unordered, align 8, !tbaa !661
+  %157 = load atomic %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %104 unordered, align 8, !tbaa !659
   %158 = getelementptr inbounds %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %157, i64 1
   %159 = ptrtoint %"struct.(anonymous namespace)::Job"** %158 to i64
   %160 = ptrtoint %"struct.(anonymous namespace)::Job"** %156 to i64
@@ -51094,63 +51915,63 @@
 
 166:                                              ; preds = %163, %146
   %167 = bitcast %"class.std::deque"* %91 to i8**
-  %168 = load i8*, i8** %167, align 8, !tbaa !648
+  %168 = load atomic i8*, i8** %167 unordered, align 8, !tbaa !660
   tail call void @free(i8* %168) #37
-  store i8* %151, i8** %167, align 8, !tbaa !648
-  store i64 %150, i64* %102, align 8, !tbaa !646
+  store i8* %151, i8** %167, align 8, !tbaa !660
+  store i64 %150, i64* %102, align 8, !tbaa !658
   br label %_ZNSt5dequeIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE17_M_reallocate_mapEmb.exit.i.i.i
 
 _ZNSt5dequeIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE17_M_reallocate_mapEmb.exit.i.i.i: ; preds = %166, %139, %138, %135, %134
   %169 = phi %"struct.(anonymous namespace)::Job"** [ %155, %166 ], [ %128, %134 ], [ %128, %135 ], [ %128, %138 ], [ %128, %139 ]
-  store %"struct.(anonymous namespace)::Job"** %169, %"struct.(anonymous namespace)::Job"*** %116, align 8, !tbaa !650
-  %170 = load %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %169, align 8, !tbaa !3
+  store %"struct.(anonymous namespace)::Job"** %169, %"struct.(anonymous namespace)::Job"*** %116, align 8, !tbaa !662
+  %170 = load atomic %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %169 unordered, align 8, !tbaa !3
   %171 = getelementptr inbounds %class.Worker, %class.Worker* %68, i64 0, i32 2, i32 0, i32 0, i32 2, i32 1
-  store %"struct.(anonymous namespace)::Job"* %170, %"struct.(anonymous namespace)::Job"** %171, align 8, !tbaa !651
+  store %"struct.(anonymous namespace)::Job"* %170, %"struct.(anonymous namespace)::Job"** %171, align 8, !tbaa !663
   %172 = getelementptr inbounds %"struct.(anonymous namespace)::Job", %"struct.(anonymous namespace)::Job"* %170, i64 12
   %173 = getelementptr inbounds %class.Worker, %class.Worker* %68, i64 0, i32 2, i32 0, i32 0, i32 2, i32 2
-  store %"struct.(anonymous namespace)::Job"* %172, %"struct.(anonymous namespace)::Job"** %173, align 8, !tbaa !652
+  store %"struct.(anonymous namespace)::Job"* %172, %"struct.(anonymous namespace)::Job"** %173, align 8, !tbaa !664
   %174 = getelementptr inbounds %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %169, i64 %120
-  store %"struct.(anonymous namespace)::Job"** %174, %"struct.(anonymous namespace)::Job"*** %104, align 8, !tbaa !650
-  %175 = load %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %174, align 8, !tbaa !3
+  store %"struct.(anonymous namespace)::Job"** %174, %"struct.(anonymous namespace)::Job"*** %104, align 8, !tbaa !662
+  %175 = load atomic %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %174 unordered, align 8, !tbaa !3
   %176 = getelementptr inbounds %class.Worker, %class.Worker* %68, i64 0, i32 2, i32 0, i32 0, i32 3, i32 1
-  store %"struct.(anonymous namespace)::Job"* %175, %"struct.(anonymous namespace)::Job"** %176, align 8, !tbaa !651
+  store %"struct.(anonymous namespace)::Job"* %175, %"struct.(anonymous namespace)::Job"** %176, align 8, !tbaa !663
   %177 = getelementptr inbounds %"struct.(anonymous namespace)::Job", %"struct.(anonymous namespace)::Job"* %175, i64 12
-  store %"struct.(anonymous namespace)::Job"* %177, %"struct.(anonymous namespace)::Job"** %94, align 8, !tbaa !652
+  store %"struct.(anonymous namespace)::Job"* %177, %"struct.(anonymous namespace)::Job"** %94, align 8, !tbaa !664
   br label %178
 
 178:                                              ; preds = %_ZNSt5dequeIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE17_M_reallocate_mapEmb.exit.i.i.i, %101
   %179 = tail call noalias dereferenceable_or_null(480) i8* @calloc(i64 12, i64 40) #37
   %180 = getelementptr inbounds %class.Worker, %class.Worker* %68, i64 0, i32 2, i32 0, i32 0, i32 3
-  %181 = load %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %104, align 8, !tbaa !647
+  %181 = load atomic %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %104 unordered, align 8, !tbaa !659
   %182 = getelementptr inbounds %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %181, i64 1
   %183 = bitcast %"struct.(anonymous namespace)::Job"** %182 to i8**
   store i8* %179, i8** %183, align 8, !tbaa !3
   %184 = bitcast %"struct.std::_Deque_iterator"* %180 to i8**
-  %185 = load i8*, i8** %184, align 8, !tbaa !640
+  %185 = load atomic i8*, i8** %184 unordered, align 8, !tbaa !652
   %.sroa.011.0..sroa_cast = bitcast i8* %185 to i32*
-  store i32 3, i32* %.sroa.011.0..sroa_cast, align 8, !tbaa.struct !645
+  store i32 3, i32* %.sroa.011.0..sroa_cast, align 8, !tbaa.struct !657
   %.sroa.6.0..sroa_idx = getelementptr inbounds i8, i8* %185, i64 8
   %.sroa.6.0..sroa_cast21 = bitcast i8* %.sroa.6.0..sroa_idx to i64*
-  store i64 %10, i64* %.sroa.6.0..sroa_cast21, align 8, !tbaa.struct !645
+  store i64 %10, i64* %.sroa.6.0..sroa_cast21, align 8, !tbaa.struct !657
   %.sroa.7.0..sroa_raw_idx = getelementptr inbounds i8, i8* %185, i64 16
-  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %.sroa.7.0..sroa_raw_idx, i8* nonnull align 8 dereferenceable(24) %.sroa.7.0.sroa_cast26, i64 24, i1 false), !tbaa.struct !645
-  %186 = load %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %104, align 8, !tbaa !647
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %.sroa.7.0..sroa_raw_idx, i8* nonnull align 8 dereferenceable(24) %.sroa.7.0.sroa_cast26, i64 24, i1 false), !tbaa.struct !657
+  %186 = load atomic %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %104 unordered, align 8, !tbaa !659
   %187 = getelementptr inbounds %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %186, i64 1
-  store %"struct.(anonymous namespace)::Job"** %187, %"struct.(anonymous namespace)::Job"*** %104, align 8, !tbaa !650
-  %188 = load %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %187, align 8, !tbaa !3
+  store %"struct.(anonymous namespace)::Job"** %187, %"struct.(anonymous namespace)::Job"*** %104, align 8, !tbaa !662
+  %188 = load atomic %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %187 unordered, align 8, !tbaa !3
   %189 = getelementptr inbounds %class.Worker, %class.Worker* %68, i64 0, i32 2, i32 0, i32 0, i32 3, i32 1
-  store %"struct.(anonymous namespace)::Job"* %188, %"struct.(anonymous namespace)::Job"** %189, align 8, !tbaa !651
+  store %"struct.(anonymous namespace)::Job"* %188, %"struct.(anonymous namespace)::Job"** %189, align 8, !tbaa !663
   %190 = getelementptr inbounds %"struct.(anonymous namespace)::Job", %"struct.(anonymous namespace)::Job"* %188, i64 12
-  store %"struct.(anonymous namespace)::Job"* %190, %"struct.(anonymous namespace)::Job"** %94, align 8, !tbaa !652
+  store %"struct.(anonymous namespace)::Job"* %190, %"struct.(anonymous namespace)::Job"** %94, align 8, !tbaa !664
   %191 = ptrtoint %"struct.(anonymous namespace)::Job"* %188 to i64
   %192 = bitcast %"struct.std::_Deque_iterator"* %180 to i64*
-  store i64 %191, i64* %192, align 8, !tbaa !640
+  store i64 %191, i64* %192, align 8, !tbaa !652
   br label %193
 
 193:                                              ; preds = %178, %98
   %194 = getelementptr inbounds %class.Worker, %class.Worker* %68, i64 0, i32 6
   %195 = tail call i32 @pthread_cond_signal(%union.pthread_cond_t* nonnull %194) #37
-  %196 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
+  %196 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
   %197 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %196, i64 328
   %198 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %197 to i32*
   %199 = atomicrmw xchg i32* %198, i32 1 seq_cst, align 4
@@ -51203,7 +52024,7 @@
   br label %.loopexit
 
 .loopexit:                                        ; preds = %_ZN6Worker6putJobEN12_GLOBAL__N_13JobEb.exit.i.i, %62, %60, %53, %.preheader, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit1.i.i
-  %225 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
+  %225 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
   %226 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %225, i64 328
   %227 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %226 to i32*
   %228 = atomicrmw xchg i32* %227, i32 1 seq_cst, align 4
@@ -51240,21 +52061,21 @@
 244:                                              ; preds = %242
   %245 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %0, i64 1
   %246 = bitcast %struct.ObjHeader* %245 to %class.KRefSharedHolder.206**
-  %247 = load %class.KRefSharedHolder.206*, %class.KRefSharedHolder.206** %246, align 8, !tbaa !653
+  %247 = load atomic %class.KRefSharedHolder.206*, %class.KRefSharedHolder.206** %246 unordered, align 8, !tbaa !665
   %248 = icmp eq %class.KRefSharedHolder.206* %247, null
   br i1 %248, label %_Z14DisposeCleanerP9ObjHeader.exit, label %249
 
 249:                                              ; preds = %244
   %250 = getelementptr inbounds %class.KRefSharedHolder.206, %class.KRefSharedHolder.206* %247, i64 0, i32 0
-  %251 = load %struct.ObjHeader*, %struct.ObjHeader** %250, align 8, !tbaa !655
+  %251 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %250 unordered, align 8, !tbaa !667
   %252 = icmp eq %struct.ObjHeader* %251, null
   br i1 %252, label %_ZNK16KRefSharedHolder7disposeEv.exit.i, label %253
 
 253:                                              ; preds = %249
   %254 = getelementptr inbounds %class.KRefSharedHolder.206, %class.KRefSharedHolder.206* %247, i64 0, i32 1
   %255 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %254 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"**
-  %256 = load %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %255, align 8, !tbaa !657
-  %257 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %256 = load atomic %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %255 unordered, align 8, !tbaa !669
+  %257 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %258 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %257, i64 0, i32 1
   tail call fastcc void @_ZN6kotlin2mm17StableRefRegistry19UnregisterStableRefEPNS0_10ThreadDataEPNS_16MultiSourceQueueIP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS6_EEE4NodeE(%"class.kotlin::mm::ThreadData.38"* nonnull %258, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %256) #37
   br label %_ZNK16KRefSharedHolder7disposeEv.exit.i
@@ -51270,7 +52091,7 @@
 
 ; Function Attrs: nounwind uwtable
 define internal fastcc %"class.(anonymous namespace)::State"* @_ZN12_GLOBAL__N_18theStateEv() unnamed_addr #17 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
-  %1 = load %"class.(anonymous namespace)::State"*, %"class.(anonymous namespace)::State"** @_ZZN12_GLOBAL__N_18theStateEvE5state, align 8, !tbaa !3
+  %1 = load atomic %"class.(anonymous namespace)::State"*, %"class.(anonymous namespace)::State"** @_ZZN12_GLOBAL__N_18theStateEvE5state unordered, align 8, !tbaa !3
   %2 = icmp eq %"class.(anonymous namespace)::State"* %1, null
   br i1 %2, label %3, label %161
 
@@ -51284,46 +52105,46 @@
   %8 = getelementptr inbounds i8, i8* %4, i64 88
   %9 = getelementptr inbounds i8, i8* %4, i64 136
   %10 = bitcast i8* %8 to i8**
-  store i8* %9, i8** %10, align 8, !tbaa !658
+  store i8* %9, i8** %10, align 8, !tbaa !670
   %11 = getelementptr inbounds i8, i8* %4, i64 96
   %12 = bitcast i8* %11 to i64*
-  store i64 1, i64* %12, align 8, !tbaa !660
+  store i64 1, i64* %12, align 8, !tbaa !672
   %13 = getelementptr inbounds i8, i8* %4, i64 104
   %14 = getelementptr inbounds i8, i8* %4, i64 120
   %15 = bitcast i8* %14 to float*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %13, i8 0, i64 16, i1 false) #37
-  store float 1.000000e+00, float* %15, align 8, !tbaa !209
+  store float 1.000000e+00, float* %15, align 8, !tbaa !208
   %16 = getelementptr inbounds i8, i8* %4, i64 128
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %16, i8 0, i64 16, i1 false) #37
   %17 = getelementptr inbounds i8, i8* %4, i64 144
   %18 = getelementptr inbounds i8, i8* %4, i64 192
   %19 = bitcast i8* %17 to i8**
-  store i8* %18, i8** %19, align 8, !tbaa !637
+  store i8* %18, i8** %19, align 8, !tbaa !649
   %20 = getelementptr inbounds i8, i8* %4, i64 152
   %21 = bitcast i8* %20 to i64*
-  store i64 1, i64* %21, align 8, !tbaa !635
+  store i64 1, i64* %21, align 8, !tbaa !647
   %22 = getelementptr inbounds i8, i8* %4, i64 160
   %23 = getelementptr inbounds i8, i8* %4, i64 176
   %24 = bitcast i8* %23 to float*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %22, i8 0, i64 16, i1 false) #37
-  store float 1.000000e+00, float* %24, align 8, !tbaa !209
+  store float 1.000000e+00, float* %24, align 8, !tbaa !208
   %25 = getelementptr inbounds i8, i8* %4, i64 184
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %25, i8 0, i64 16, i1 false) #37
   %26 = getelementptr inbounds i8, i8* %4, i64 200
   %27 = getelementptr inbounds i8, i8* %4, i64 248
   %28 = bitcast i8* %26 to i8**
-  store i8* %27, i8** %28, align 8, !tbaa !661
+  store i8* %27, i8** %28, align 8, !tbaa !673
   %29 = getelementptr inbounds i8, i8* %4, i64 208
   %30 = bitcast i8* %29 to i64*
-  store i64 1, i64* %30, align 8, !tbaa !663
+  store i64 1, i64* %30, align 8, !tbaa !675
   %31 = getelementptr inbounds i8, i8* %4, i64 216
   %32 = getelementptr inbounds i8, i8* %4, i64 232
   %33 = bitcast i8* %32 to float*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %31, i8 0, i64 16, i1 false) #37
-  store float 1.000000e+00, float* %33, align 8, !tbaa !209
+  store float 1.000000e+00, float* %33, align 8, !tbaa !208
   %34 = getelementptr inbounds i8, i8* %4, i64 240
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %34, i8 0, i64 16, i1 false) #37
-  %35 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
+  %35 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
   %36 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %35, i64 328
   %37 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %36 to i32*
   %38 = atomicrmw xchg i32* %37, i32 1 seq_cst, align 4
@@ -51334,13 +52155,13 @@
   %43 = tail call i32 @pthread_cond_init(%union.pthread_cond_t* nonnull %42, %"struct.std::atomic"* null) #37
   %44 = getelementptr inbounds i8, i8* %4, i64 256
   %45 = bitcast i8* %44 to i32*
-  store i32 1, i32* %45, align 8, !tbaa !664
+  store i32 1, i32* %45, align 8, !tbaa !676
   %46 = getelementptr inbounds i8, i8* %4, i64 260
   %47 = bitcast i8* %46 to i32*
-  store i32 1, i32* %47, align 4, !tbaa !669
+  store i32 1, i32* %47, align 4, !tbaa !681
   %48 = getelementptr inbounds i8, i8* %4, i64 264
   %49 = bitcast i8* %48 to i32*
-  store i32 0, i32* %49, align 8, !tbaa !670
+  store i32 0, i32* %49, align 8, !tbaa !682
   %50 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %35, null
   br i1 %50, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %51
 
@@ -51372,7 +52193,7 @@
 66:                                               ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
   %67 = extractvalue { i64, i1 } %64, 0
   %68 = inttoptr i64 %67 to %"class.(anonymous namespace)::State"*
-  %69 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
+  %69 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
   %70 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %69, i64 328
   %71 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %70 to i32*
   %72 = atomicrmw xchg i32* %71, i32 1 seq_cst, align 4
@@ -51405,14 +52226,14 @@
   %89 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %62, i64 0, i32 4
   %90 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %62, i64 0, i32 4, i32 0, i32 2, i32 0
   %91 = bitcast %"struct.std::__detail::_Hash_node_base"** %90 to %"struct.std::__detail::_Hash_node.203"**
-  %92 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %91, align 8, !tbaa !671
+  %92 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %91 unordered, align 8, !tbaa !683
   %93 = icmp eq %"struct.std::__detail::_Hash_node.203"* %92, null
   br i1 %93, label %.loopexit14, label %.preheader13
 
 .preheader13:                                     ; preds = %.preheader13, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit10
   %94 = phi %"struct.std::__detail::_Hash_node.203"* [ %96, %.preheader13 ], [ %92, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit10 ]
   %95 = bitcast %"struct.std::__detail::_Hash_node.203"* %94 to %"struct.std::__detail::_Hash_node.203"**
-  %96 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %95, align 8, !tbaa !216
+  %96 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %95 unordered, align 8, !tbaa !215
   %97 = bitcast %"struct.std::__detail::_Hash_node.203"* %94 to i8*
   tail call void @free(i8* %97) #37
   %98 = icmp eq %"struct.std::__detail::_Hash_node.203"* %96, null
@@ -51420,15 +52241,15 @@
 
 .loopexit14:                                      ; preds = %.preheader13, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit10
   %99 = bitcast %"class.std::unordered_map"* %89 to i8**
-  %100 = load i8*, i8** %99, align 8, !tbaa !661
+  %100 = load atomic i8*, i8** %99 unordered, align 8, !tbaa !673
   %101 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %62, i64 0, i32 4, i32 0, i32 1
-  %102 = load i64, i64* %101, align 8, !tbaa !663
+  %102 = load atomic i64, i64* %101 unordered, align 8, !tbaa !675
   %103 = shl i64 %102, 3
   tail call void @llvm.memset.p0i8.i64(i8* align 8 %100, i8 0, i64 %103, i1 false) #37
   %104 = bitcast %"struct.std::__detail::_Hash_node_base"** %90 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %104, i8 0, i64 16, i1 false) #37
   %105 = getelementptr inbounds %"class.std::unordered_map", %"class.std::unordered_map"* %89, i64 0, i32 0, i32 0
-  %106 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %105, align 8, !tbaa !661
+  %106 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %105 unordered, align 8, !tbaa !673
   %107 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %62, i64 0, i32 4, i32 0, i32 5
   %108 = icmp eq %"struct.std::__detail::_Hash_node_base"** %107, %106
   br i1 %108, label %111, label %109
@@ -51442,14 +52263,14 @@
   %112 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %62, i64 0, i32 3
   %113 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %62, i64 0, i32 3, i32 0, i32 2, i32 0
   %114 = bitcast %"struct.std::__detail::_Hash_node_base"** %113 to %"struct.std::__detail::_Hash_node.203"**
-  %115 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %114, align 8, !tbaa !672
+  %115 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %114 unordered, align 8, !tbaa !684
   %116 = icmp eq %"struct.std::__detail::_Hash_node.203"* %115, null
   br i1 %116, label %.loopexit12, label %.preheader11
 
 .preheader11:                                     ; preds = %.preheader11, %111
   %117 = phi %"struct.std::__detail::_Hash_node.203"* [ %119, %.preheader11 ], [ %115, %111 ]
   %118 = bitcast %"struct.std::__detail::_Hash_node.203"* %117 to %"struct.std::__detail::_Hash_node.203"**
-  %119 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %118, align 8, !tbaa !216
+  %119 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %118 unordered, align 8, !tbaa !215
   %120 = bitcast %"struct.std::__detail::_Hash_node.203"* %117 to i8*
   tail call void @free(i8* %120) #37
   %121 = icmp eq %"struct.std::__detail::_Hash_node.203"* %119, null
@@ -51457,15 +52278,15 @@
 
 .loopexit12:                                      ; preds = %.preheader11, %111
   %122 = bitcast %"class.std::unordered_map"* %112 to i8**
-  %123 = load i8*, i8** %122, align 8, !tbaa !637
+  %123 = load atomic i8*, i8** %122 unordered, align 8, !tbaa !649
   %124 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %62, i64 0, i32 3, i32 0, i32 1
-  %125 = load i64, i64* %124, align 8, !tbaa !635
+  %125 = load atomic i64, i64* %124 unordered, align 8, !tbaa !647
   %126 = shl i64 %125, 3
   tail call void @llvm.memset.p0i8.i64(i8* align 8 %123, i8 0, i64 %126, i1 false) #37
   %127 = bitcast %"struct.std::__detail::_Hash_node_base"** %113 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %127, i8 0, i64 16, i1 false) #37
   %128 = getelementptr inbounds %"class.std::unordered_map", %"class.std::unordered_map"* %112, i64 0, i32 0, i32 0
-  %129 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %128, align 8, !tbaa !637
+  %129 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %128 unordered, align 8, !tbaa !649
   %130 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %62, i64 0, i32 3, i32 0, i32 5
   %131 = icmp eq %"struct.std::__detail::_Hash_node_base"** %130, %129
   br i1 %131, label %134, label %132
@@ -51479,14 +52300,14 @@
   %135 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %62, i64 0, i32 2
   %136 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %62, i64 0, i32 2, i32 0, i32 2, i32 0
   %137 = bitcast %"struct.std::__detail::_Hash_node_base"** %136 to %"struct.std::__detail::_Hash_node.203"**
-  %138 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %137, align 8, !tbaa !673
+  %138 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %137 unordered, align 8, !tbaa !685
   %139 = icmp eq %"struct.std::__detail::_Hash_node.203"* %138, null
   br i1 %139, label %.loopexit, label %.preheader
 
 .preheader:                                       ; preds = %.preheader, %134
   %140 = phi %"struct.std::__detail::_Hash_node.203"* [ %142, %.preheader ], [ %138, %134 ]
   %141 = bitcast %"struct.std::__detail::_Hash_node.203"* %140 to %"struct.std::__detail::_Hash_node.203"**
-  %142 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %141, align 8, !tbaa !216
+  %142 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %141 unordered, align 8, !tbaa !215
   %143 = bitcast %"struct.std::__detail::_Hash_node.203"* %140 to i8*
   tail call void @free(i8* %143) #37
   %144 = icmp eq %"struct.std::__detail::_Hash_node.203"* %142, null
@@ -51494,15 +52315,15 @@
 
 .loopexit:                                        ; preds = %.preheader, %134
   %145 = bitcast %"class.std::unordered_map"* %135 to i8**
-  %146 = load i8*, i8** %145, align 8, !tbaa !658
+  %146 = load atomic i8*, i8** %145 unordered, align 8, !tbaa !670
   %147 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %62, i64 0, i32 2, i32 0, i32 1
-  %148 = load i64, i64* %147, align 8, !tbaa !660
+  %148 = load atomic i64, i64* %147 unordered, align 8, !tbaa !672
   %149 = shl i64 %148, 3
   tail call void @llvm.memset.p0i8.i64(i8* align 8 %146, i8 0, i64 %149, i1 false) #37
   %150 = bitcast %"struct.std::__detail::_Hash_node_base"** %136 to i8*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %150, i8 0, i64 16, i1 false) #37
   %151 = getelementptr inbounds %"class.std::unordered_map", %"class.std::unordered_map"* %135, i64 0, i32 0, i32 0
-  %152 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %151, align 8, !tbaa !658
+  %152 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %151 unordered, align 8, !tbaa !670
   %153 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %62, i64 0, i32 2, i32 0, i32 5
   %154 = icmp eq %"struct.std::__detail::_Hash_node_base"** %153, %152
   br i1 %154, label %157, label %155
@@ -51518,7 +52339,7 @@
   br label %161
 
 159:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
-  %160 = load %"class.(anonymous namespace)::State"*, %"class.(anonymous namespace)::State"** @_ZZN12_GLOBAL__N_18theStateEvE5state, align 8, !tbaa !3
+  %160 = load atomic %"class.(anonymous namespace)::State"*, %"class.(anonymous namespace)::State"** @_ZZN12_GLOBAL__N_18theStateEvE5state unordered, align 8, !tbaa !3
   br label %161
 
 161:                                              ; preds = %159, %157, %0
@@ -51551,14 +52372,14 @@
 define internal fastcc void @Kotlin_initRuntimeIfNeeded() unnamed_addr #17 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
   %1 = alloca %class.anon.0, align 8
   %2 = alloca { i8 }, align 1
-  %3 = load %"struct.(anonymous namespace)::RuntimeState"*, %"struct.(anonymous namespace)::RuntimeState"** @_ZN12_GLOBAL__N_112runtimeStateE, align 8, !tbaa !3
+  %3 = load atomic %"struct.(anonymous namespace)::RuntimeState"*, %"struct.(anonymous namespace)::RuntimeState"** @_ZN12_GLOBAL__N_112runtimeStateE unordered, align 8, !tbaa !3
   %4 = icmp eq %"struct.(anonymous namespace)::RuntimeState"* %3, null
-  br i1 %4, label %5, label %713
+  br i1 %4, label %5, label %720
 
 5:                                                ; preds = %0
   %6 = load atomic i8, i8* bitcast (i64* @_ZGVZN12_GLOBAL__N_116TerminateHandler8instanceEvE9singleton to i8*) acquire, align 8
   %7 = icmp eq i8 %6, 0
-  br i1 %7, label %8, label %SetKonanTerminateHandler.exit, !prof !674
+  br i1 %7, label %8, label %SetKonanTerminateHandler.exit, !prof !686
 
 8:                                                ; preds = %5
   %9 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN12_GLOBAL__N_116TerminateHandler8instanceEvE9singleton) #37
@@ -51567,7 +52388,7 @@
 
 11:                                               ; preds = %8
   %12 = tail call void ()* @_ZSt13set_terminatePFvvE(void ()* nonnull @_ZN12_GLOBAL__N_116TerminateHandler13kotlinHandlerEv) #37
-  store void ()* %12, void ()** @_ZZN12_GLOBAL__N_116TerminateHandler8instanceEvE9singleton.0, align 8, !tbaa !675
+  store void ()* %12, void ()** @_ZZN12_GLOBAL__N_116TerminateHandler8instanceEvE9singleton.0, align 8, !tbaa !687
   tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN12_GLOBAL__N_116TerminateHandler8instanceEvE9singleton) #37
   br label %SetKonanTerminateHandler.exit
 
@@ -51618,7 +52439,7 @@
   %29 = getelementptr inbounds i8, i8* %26, i64 16
   %30 = bitcast i8* %29 to i32*
   tail call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %26, i8 0, i64 24, i1 false)
-  %31 = load %"struct.(anonymous namespace)::RuntimeState"*, %"struct.(anonymous namespace)::RuntimeState"** @_ZN12_GLOBAL__N_112runtimeStateE, align 8, !tbaa !3
+  %31 = load atomic %"struct.(anonymous namespace)::RuntimeState"*, %"struct.(anonymous namespace)::RuntimeState"** @_ZN12_GLOBAL__N_112runtimeStateE unordered, align 8, !tbaa !3
   %32 = icmp eq %"struct.(anonymous namespace)::RuntimeState"* %31, null
   br i1 %32, label %40, label %33
 
@@ -51631,12 +52452,12 @@
           catch i8* null
   br label %.body
 
-36:                                               ; preds = %.preheader11
+36:                                               ; preds = %.preheader12
   %37 = landingpad { i8*, i32 }
           catch i8* null
   br label %.body
 
-38:                                               ; preds = %.preheader17
+38:                                               ; preds = %.preheader18
   %39 = landingpad { i8*, i32 }
           catch i8* null
   br label %.body
@@ -51650,86 +52471,86 @@
   %45 = call noalias dereferenceable_or_null(368) i8* @calloc(i64 1, i64 368) #37
   %46 = getelementptr inbounds i8, i8* %45, i64 8
   %47 = bitcast i8* %46 to i32*
-  store i32 %44, i32* %47, align 8, !tbaa !677, !noalias !687
+  store i32 %44, i32* %47, align 8, !tbaa !689, !noalias !699
   %48 = getelementptr inbounds i8, i8* %45, i64 16
   %49 = bitcast i8* %48 to %"class.kotlin::MultiSourceQueue"**
-  store %"class.kotlin::MultiSourceQueue"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0), %"class.kotlin::MultiSourceQueue"** %49, align 8, !tbaa !3, !noalias !687
+  store %"class.kotlin::MultiSourceQueue"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 3, i32 0), %"class.kotlin::MultiSourceQueue"** %49, align 8, !tbaa !3, !noalias !699
   %50 = getelementptr inbounds i8, i8* %45, i64 24
   %51 = getelementptr inbounds i8, i8* %45, i64 32
   %52 = bitcast i8* %51 to i8**
-  store i8* %50, i8** %52, align 8, !tbaa !123, !noalias !687
+  store i8* %50, i8** %52, align 8, !tbaa !121, !noalias !699
   %53 = bitcast i8* %50 to i8**
-  store i8* %50, i8** %53, align 8, !tbaa !125, !noalias !687
+  store i8* %50, i8** %53, align 8, !tbaa !123, !noalias !699
   %54 = getelementptr inbounds i8, i8* %45, i64 48
   %55 = getelementptr inbounds i8, i8* %45, i64 56
   %56 = bitcast i8* %55 to i8**
-  store i8* %54, i8** %56, align 8, !tbaa !123, !noalias !687
+  store i8* %54, i8** %56, align 8, !tbaa !121, !noalias !699
   %57 = bitcast i8* %54 to i8**
-  store i8* %54, i8** %57, align 8, !tbaa !125, !noalias !687
+  store i8* %54, i8** %57, align 8, !tbaa !123, !noalias !699
   %58 = getelementptr inbounds i8, i8* %45, i64 64
   %59 = getelementptr inbounds i8, i8* %45, i64 96
   %60 = getelementptr inbounds i8, i8* %45, i64 144
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(32) %58, i8 0, i64 32, i1 false) #37, !noalias !687
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(32) %58, i8 0, i64 32, i1 false) #37, !noalias !699
   %61 = bitcast i8* %59 to i8**
-  store i8* %60, i8** %61, align 8, !tbaa !217, !noalias !687
+  store i8* %60, i8** %61, align 8, !tbaa !216, !noalias !699
   %62 = getelementptr inbounds i8, i8* %45, i64 104
   %63 = bitcast i8* %62 to i64*
-  store i64 1, i64* %63, align 8, !tbaa !218, !noalias !687
+  store i64 1, i64* %63, align 8, !tbaa !217, !noalias !699
   %64 = getelementptr inbounds i8, i8* %45, i64 112
   %65 = getelementptr inbounds i8, i8* %45, i64 128
   %66 = bitcast i8* %65 to float*
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %64, i8 0, i64 16, i1 false) #37, !noalias !687
-  store float 1.000000e+00, float* %66, align 8, !tbaa !209, !noalias !687
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %64, i8 0, i64 16, i1 false) #37, !noalias !699
+  store float 1.000000e+00, float* %66, align 8, !tbaa !208, !noalias !699
   %67 = getelementptr inbounds i8, i8* %45, i64 136
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %67, i8 0, i64 40, i1 false) #37, !noalias !687
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(40) %67, i8 0, i64 40, i1 false) #37, !noalias !699
   %68 = getelementptr inbounds i8, i8* %45, i64 176
   %69 = bitcast i8* %68 to %"class.kotlin::MultiSourceQueue"**
-  store %"class.kotlin::MultiSourceQueue"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0), %"class.kotlin::MultiSourceQueue"** %69, align 8, !tbaa !3, !noalias !687
+  store %"class.kotlin::MultiSourceQueue"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 4, i32 0), %"class.kotlin::MultiSourceQueue"** %69, align 8, !tbaa !3, !noalias !699
   %70 = getelementptr inbounds i8, i8* %45, i64 184
   %71 = getelementptr inbounds i8, i8* %45, i64 192
   %72 = bitcast i8* %71 to i8**
-  store i8* %70, i8** %72, align 8, !tbaa !123, !noalias !687
+  store i8* %70, i8** %72, align 8, !tbaa !121, !noalias !699
   %73 = bitcast i8* %70 to i8**
-  store i8* %70, i8** %73, align 8, !tbaa !125, !noalias !687
+  store i8* %70, i8** %73, align 8, !tbaa !123, !noalias !699
   %74 = getelementptr inbounds i8, i8* %45, i64 208
   %75 = getelementptr inbounds i8, i8* %45, i64 216
   %76 = bitcast i8* %75 to i8**
-  store i8* %74, i8** %76, align 8, !tbaa !123, !noalias !687
+  store i8* %74, i8** %76, align 8, !tbaa !121, !noalias !699
   %77 = bitcast i8* %74 to i8**
-  store i8* %74, i8** %77, align 8, !tbaa !125, !noalias !687
+  store i8* %74, i8** %77, align 8, !tbaa !123, !noalias !699
   %78 = getelementptr inbounds i8, i8* %45, i64 232
   %79 = bitcast i8* %78 to %"class.kotlin::MultiSourceQueue"**
-  store %"class.kotlin::MultiSourceQueue"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0), %"class.kotlin::MultiSourceQueue"** %79, align 8, !tbaa !3, !noalias !687
+  store %"class.kotlin::MultiSourceQueue"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 5, i32 0), %"class.kotlin::MultiSourceQueue"** %79, align 8, !tbaa !3, !noalias !699
   %80 = getelementptr inbounds i8, i8* %45, i64 240
   %81 = getelementptr inbounds i8, i8* %45, i64 248
   %82 = bitcast i8* %81 to i8**
-  store i8* %80, i8** %82, align 8, !tbaa !123, !noalias !687
+  store i8* %80, i8** %82, align 8, !tbaa !121, !noalias !699
   %83 = bitcast i8* %80 to i8**
-  store i8* %80, i8** %83, align 8, !tbaa !125, !noalias !687
+  store i8* %80, i8** %83, align 8, !tbaa !123, !noalias !699
   %84 = getelementptr inbounds i8, i8* %45, i64 264
   %85 = getelementptr inbounds i8, i8* %45, i64 272
   %86 = bitcast i8* %85 to i8**
-  store i8* %84, i8** %86, align 8, !tbaa !123, !noalias !687
+  store i8* %84, i8** %86, align 8, !tbaa !121, !noalias !699
   %87 = bitcast i8* %84 to i8**
-  store i8* %84, i8** %87, align 8, !tbaa !125, !noalias !687
+  store i8* %84, i8** %87, align 8, !tbaa !123, !noalias !699
   %88 = getelementptr inbounds i8, i8* %45, i64 280
   %89 = getelementptr inbounds i8, i8* %45, i64 296
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %88, i8 0, i64 16, i1 false) #37, !noalias !687
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %88, i8 0, i64 16, i1 false) #37, !noalias !699
   %90 = bitcast i8* %89 to %"class.kotlin::gc::GC::ThreadData.116"*
   %91 = bitcast i8* %46 to %"class.kotlin::mm::ThreadData.119"*
   call fastcc void @_ZN6kotlin2gc2GC10ThreadDataC2ERS1_RNS_2mm10ThreadDataE(%"class.kotlin::gc::GC::ThreadData.116"* nonnull %90, %"class.kotlin::gc::GC"* nonnull align 8 dereferenceable(8) getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 6), %"class.kotlin::mm::ThreadData.119"* nonnull align 8 dereferenceable(344) %91) #37
   %92 = getelementptr inbounds i8, i8* %45, i64 304
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %92, i8 0, i64 24, i1 false) #37, !noalias !687
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(24) %92, i8 0, i64 24, i1 false) #37, !noalias !699
   %93 = getelementptr inbounds i8, i8* %45, i64 328
   %94 = bitcast i8* %93 to i32*
-  store i32 1, i32* %94, align 4, !tbaa !690, !noalias !687
+  store i32 1, i32* %94, align 4, !tbaa !702, !noalias !699
   %95 = getelementptr inbounds i8, i8* %45, i64 336
   %96 = bitcast i8* %95 to i8**
-  store i8* %46, i8** %96, align 8, !tbaa !3, !noalias !687
+  store i8* %46, i8** %96, align 8, !tbaa !3, !noalias !699
   %97 = getelementptr inbounds i8, i8* %45, i64 344
-  store i8 0, i8* %97, align 1, !tbaa !139, !noalias !687
+  store i8 0, i8* %97, align 1, !tbaa !137, !noalias !699
   %98 = getelementptr inbounds i8, i8* %45, i64 352
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %98, i8 0, i64 16, i1 false) #37, !noalias !687
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %98, i8 0, i64 16, i1 false) #37, !noalias !699
   %99 = ptrtoint i8* %45 to i64
   %100 = bitcast i8* %45 to %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*
   br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %101, label %106
@@ -51747,7 +52568,7 @@
   unreachable
 
 106:                                              ; preds = %101, %40
-  %107 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !3
+  %107 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) unordered, align 8, !tbaa !3
   %108 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %107, null
   br i1 %108, label %117, label %109
 
@@ -51755,22 +52576,22 @@
   %110 = ptrtoint %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %107 to i64
   %111 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %107, i64 0, i32 3
   %112 = bitcast %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %111 to i8**
-  store i8* %45, i8** %112, align 8, !tbaa !691
+  store i8* %45, i8** %112, align 8, !tbaa !703
   br label %118
 
 113:                                              ; preds = %104
   %114 = landingpad { i8*, i32 }
           catch i8* null
   %115 = icmp eq i8* %45, null
-  br i1 %115, label %146, label %116
+  br i1 %115, label %148, label %116
 
 116:                                              ; preds = %113
   call fastcc void @_ZNSt16allocator_traitsIN6kotlin11std_support9allocatorINS0_14SingleLockListINS0_2mm10ThreadDataESt15recursive_mutexNS2_IS5_EEE4NodeEEEE10_S_destroyISA_S9_EEvRT_PT0_z(%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* nonnull %100) #37
   call void @free(i8* %45) #37
-  br label %146
+  br label %148
 
 117:                                              ; preds = %106
-  store i8* %45, i8** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 2) to i8**), align 8, !tbaa !696
+  store i8* %45, i8** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 2) to i8**), align 8, !tbaa !708
   br label %118
 
 118:                                              ; preds = %117, %109
@@ -51778,18 +52599,14 @@
   store %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* null, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !3
   %120 = bitcast i8* %98 to i64*
   %121 = bitcast i8* %98 to %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"**
-  %122 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %121, align 8, !tbaa !3
+  %122 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %121 unordered, align 8, !tbaa !3
   store i64 %119, i64* %120, align 8, !tbaa !3
   %123 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %122, null
-  br i1 %123, label %.thread, label %124
-
-.thread:                                          ; preds = %118
-  store i64 %99, i64* bitcast (%"class.std::unique_ptr.59"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1) to i64*), align 8, !tbaa !3
-  br label %143
+  br i1 %123, label %133, label %124
 
 124:                                              ; preds = %118
   %125 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %122, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
-  %126 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %125, align 8, !tbaa !3
+  %126 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %125 unordered, align 8, !tbaa !3
   %127 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %126, null
   br i1 %127, label %130, label %128
 
@@ -51805,939 +52622,947 @@
   call fastcc void @_ZN6kotlin2mm10ThreadDataD2Ev(%"class.kotlin::mm::ThreadData.38"* nonnull %131) #37
   %132 = getelementptr %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %122, i64 0, i32 0, i64 0
   call void @free(i8* %132) #37
-  %.pre = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !3
+  br label %133
+
+133:                                              ; preds = %130, %118
+  %134 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) unordered, align 8, !tbaa !3
   store i64 %99, i64* bitcast (%"class.std::unique_ptr.59"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1) to i64*), align 8, !tbaa !3
-  %133 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %.pre, null
-  br i1 %133, label %143, label %134
+  %135 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %134, null
+  br i1 %135, label %145, label %136
 
-134:                                              ; preds = %130
-  %135 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %.pre, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
-  %136 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %135, align 8, !tbaa !3
-  %137 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %136, null
-  br i1 %137, label %140, label %138
+136:                                              ; preds = %133
+  %137 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %134, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
+  %138 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %137 unordered, align 8, !tbaa !3
+  %139 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %138, null
+  br i1 %139, label %142, label %140
 
-138:                                              ; preds = %134
-  call fastcc void @_ZNSt16allocator_traitsIN6kotlin11std_support9allocatorINS0_14SingleLockListINS0_2mm10ThreadDataESt15recursive_mutexNS2_IS5_EEE4NodeEEEE10_S_destroyISA_S9_EEvRT_PT0_z(%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* nonnull %136) #37
-  %139 = getelementptr %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %136, i64 0, i32 0, i64 0
-  call void @free(i8* %139) #37
-  br label %140
+140:                                              ; preds = %136
+  call fastcc void @_ZNSt16allocator_traitsIN6kotlin11std_support9allocatorINS0_14SingleLockListINS0_2mm10ThreadDataESt15recursive_mutexNS2_IS5_EEE4NodeEEEE10_S_destroyISA_S9_EEvRT_PT0_z(%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* nonnull %138) #37
+  %141 = getelementptr %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %138, i64 0, i32 0, i64 0
+  call void @free(i8* %141) #37
+  br label %142
 
-140:                                              ; preds = %138, %134
-  store %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* null, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %135, align 8, !tbaa !3
-  %141 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %.pre, i64 0, i32 1
-  call fastcc void @_ZN6kotlin2mm10ThreadDataD2Ev(%"class.kotlin::mm::ThreadData.38"* nonnull %141) #37
-  %142 = getelementptr %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %.pre, i64 0, i32 0, i64 0
-  call void @free(i8* %142) #37
-  br label %143
+142:                                              ; preds = %140, %136
+  store %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* null, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %137, align 8, !tbaa !3
+  %143 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %134, i64 0, i32 1
+  call fastcc void @_ZN6kotlin2mm10ThreadDataD2Ev(%"class.kotlin::mm::ThreadData.38"* nonnull %143) #37
+  %144 = getelementptr %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %134, i64 0, i32 0, i64 0
+  call void @free(i8* %144) #37
+  br label %145
 
-143:                                              ; preds = %140, %130, %.thread
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %144, label %148
+145:                                              ; preds = %142, %133
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %146, label %150
 
-144:                                              ; preds = %143
-  %145 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0)) #37
-  br label %148
+146:                                              ; preds = %145
+  %147 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0)) #37
+  br label %150
 
-146:                                              ; preds = %116, %113
-  %147 = extractvalue { i8*, i32 } %114, 0
-  call fastcc void @__clang_call_terminate(i8* %147) #51
+148:                                              ; preds = %116, %113
+  %149 = extractvalue { i8*, i32 } %114, 0
+  call fastcc void @__clang_call_terminate(i8* %149) #51
   unreachable
 
-148:                                              ; preds = %144, %143
+150:                                              ; preds = %146, %145
   store i8* %45, i8** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to i8**), align 8, !tbaa !3
-  %149 = bitcast i8* %26 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**
-  %150 = bitcast i8* %26 to i8**
-  store i8* %45, i8** %150, align 8, !tbaa !699
-  %151 = bitcast i8* %93 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %152 = atomicrmw xchg i32* %94, i32 0 seq_cst, align 4
-  %153 = icmp eq i32 %152, 1
-  br i1 %153, label %154, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
+  %151 = bitcast i8* %26 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**
+  %152 = bitcast i8* %26 to i8**
+  store i8* %45, i8** %152, align 8, !tbaa !711
+  %153 = bitcast i8* %93 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %154 = atomicrmw xchg i32* %94, i32 0 seq_cst, align 4
+  %155 = icmp eq i32 %154, 1
+  br i1 %155, label %156, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-154:                                              ; preds = %148
-  %155 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %156 = and i8 %155, 1
-  %157 = icmp eq i8 %156, 0
-  br i1 %157, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %158
+156:                                              ; preds = %150
+  %157 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %158 = and i8 %157, 1
+  %159 = icmp eq i8 %158, 0
+  br i1 %159, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %160
 
-158:                                              ; preds = %154
-  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %151) #37
+160:                                              ; preds = %156
+  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %153) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %158, %154, %148
-  %159 = bitcast i8* %26 to i64*
-  %160 = load i64, i64* %159, align 8, !tbaa !699
-  %161 = load %class.Worker*, %class.Worker** @_ZN12_GLOBAL__N_18g_workerE, align 8, !tbaa !3
-  %162 = icmp eq %class.Worker* %161, null
-  %163 = inttoptr i64 %160 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*
-  br i1 %162, label %164, label %453
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %160, %156, %150
+  %161 = bitcast i8* %26 to i64*
+  %162 = load atomic i64, i64* %161 unordered, align 8, !tbaa !711
+  %163 = load atomic %class.Worker*, %class.Worker** @_ZN12_GLOBAL__N_18g_workerE unordered, align 8, !tbaa !3
+  %164 = icmp eq %class.Worker* %163, null
+  %165 = inttoptr i64 %162 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*
+  br i1 %164, label %166, label %460
 
-164:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
-  %165 = call fastcc %"class.(anonymous namespace)::State"* @_ZN12_GLOBAL__N_18theStateEv()
-  %166 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %165, i64 0, i32 0
-  %167 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
-  %168 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %167, i64 328
-  %169 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %168 to i32*
-  %170 = atomicrmw xchg i32* %169, i32 1 seq_cst, align 4
-  %171 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %166) #37
-  %172 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %167, null
-  br i1 %172, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i, label %173
+166:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
+  %167 = call fastcc %"class.(anonymous namespace)::State"* @_ZN12_GLOBAL__N_18theStateEv()
+  %168 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %167, i64 0, i32 0
+  %169 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
+  %170 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %169, i64 328
+  %171 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %170 to i32*
+  %172 = atomicrmw xchg i32* %171, i32 1 seq_cst, align 4
+  %173 = call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %168) #37
+  %174 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %169, null
+  br i1 %174, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i, label %175
 
-173:                                              ; preds = %164
-  %174 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %168 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %175 = atomicrmw xchg i32* %169, i32 %170 seq_cst, align 4
-  %176 = icmp eq i32 %175, 1
-  %177 = icmp eq i32 %170, 0
-  %178 = and i1 %177, %176
-  br i1 %178, label %179, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i
+175:                                              ; preds = %166
+  %176 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %170 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %177 = atomicrmw xchg i32* %171, i32 %172 seq_cst, align 4
+  %178 = icmp eq i32 %177, 1
+  %179 = icmp eq i32 %172, 0
+  %180 = and i1 %179, %178
+  br i1 %180, label %181, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i
 
-179:                                              ; preds = %173
-  %180 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %181 = and i8 %180, 1
-  %182 = icmp eq i8 %181, 0
-  br i1 %182, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i, label %183
+181:                                              ; preds = %175
+  %182 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %183 = and i8 %182, 1
+  %184 = icmp eq i8 %183, 0
+  br i1 %184, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i, label %185
 
-183:                                              ; preds = %179
-  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %174) #37
+185:                                              ; preds = %181
+  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %176) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i: ; preds = %183, %179, %173, %164
-  %184 = call noalias dereferenceable_or_null(256) i8* @calloc(i64 1, i64 256) #37
-  %185 = icmp eq i8* %184, null
-  br i1 %185, label %415, label %186
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i: ; preds = %185, %181, %175, %166
+  %186 = call noalias dereferenceable_or_null(256) i8* @calloc(i64 1, i64 256) #37
+  %187 = icmp eq i8* %186, null
+  br i1 %187, label %422, label %188
 
-186:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i
-  %187 = bitcast i8* %184 to %class.Worker*
-  %188 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %165, i64 0, i32 5
-  %189 = load i32, i32* %188, align 8, !tbaa !664
-  %190 = add nsw i32 %189, 1
-  store i32 %190, i32* %188, align 8, !tbaa !664
-  %191 = bitcast i8* %184 to i32*
-  store i32 %189, i32* %191, align 8, !tbaa !701
-  %192 = getelementptr inbounds i8, i8* %184, i64 4
-  %193 = bitcast i8* %192 to i32*
-  store i32 1, i32* %193, align 4, !tbaa !707
-  %194 = getelementptr inbounds i8, i8* %184, i64 8
-  %195 = getelementptr inbounds i8, i8* %184, i64 16
-  %196 = bitcast i8* %195 to i64*
-  store i64 8, i64* %196, align 8, !tbaa !646
-  %197 = call noalias dereferenceable_or_null(64) i8* @calloc(i64 8, i64 8) #37
-  %198 = bitcast i8* %194 to i8**
-  store i8* %197, i8** %198, align 8, !tbaa !648
-  %199 = getelementptr inbounds i8, i8* %197, i64 24
-  %200 = call noalias dereferenceable_or_null(480) i8* @calloc(i64 12, i64 40) #37
-  %201 = bitcast i8* %199 to i8**
-  store i8* %200, i8** %201, align 8, !tbaa !3
-  %202 = getelementptr inbounds i8, i8* %184, i64 24
-  %203 = getelementptr inbounds i8, i8* %184, i64 48
-  %204 = bitcast i8* %203 to i8**
-  store i8* %199, i8** %204, align 8, !tbaa !650
-  %205 = getelementptr inbounds i8, i8* %184, i64 32
-  %206 = bitcast i8* %205 to i8**
-  store i8* %200, i8** %206, align 8, !tbaa !651
-  %207 = getelementptr inbounds i8, i8* %200, i64 480
-  %208 = getelementptr inbounds i8, i8* %184, i64 40
-  %209 = bitcast i8* %208 to i8**
-  store i8* %207, i8** %209, align 8, !tbaa !652
-  %210 = getelementptr inbounds i8, i8* %184, i64 56
-  %211 = getelementptr inbounds i8, i8* %184, i64 80
-  %212 = bitcast i8* %211 to i8**
-  store i8* %199, i8** %212, align 8, !tbaa !650
-  %213 = getelementptr inbounds i8, i8* %184, i64 64
-  %214 = bitcast i8* %213 to i8**
-  store i8* %200, i8** %214, align 8, !tbaa !651
-  %215 = getelementptr inbounds i8, i8* %200, i64 480
-  %216 = getelementptr inbounds i8, i8* %184, i64 72
-  %217 = bitcast i8* %216 to i8**
-  store i8* %215, i8** %217, align 8, !tbaa !652
-  %218 = ptrtoint i8* %200 to i64
-  %219 = bitcast i8* %202 to i64*
-  store i64 %218, i64* %219, align 8, !tbaa !708
-  %220 = ptrtoint i8* %200 to i64
-  %221 = bitcast i8* %210 to i64*
-  store i64 %220, i64* %221, align 8, !tbaa !640
-  %222 = getelementptr inbounds i8, i8* %184, i64 96
-  %223 = getelementptr inbounds i8, i8* %184, i64 112
-  %224 = bitcast i8* %223 to i8**
-  store i8* %222, i8** %224, align 8, !tbaa !709
-  %225 = getelementptr inbounds i8, i8* %184, i64 120
-  %226 = bitcast i8* %225 to i8**
-  store i8* %222, i8** %226, align 8, !tbaa !713
-  %227 = getelementptr inbounds i8, i8* %184, i64 128
-  %228 = getelementptr inbounds i8, i8* %184, i64 240
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %228, i8 0, i64 16, i1 false) #37
-  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %227, i8 0, i64 16, i1 false)
-  %229 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
-  %230 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %229, i64 328
-  %231 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %230 to i32*
-  %232 = atomicrmw xchg i32* %231, i32 1 seq_cst, align 4
-  %233 = getelementptr inbounds i8, i8* %184, i64 144
-  %234 = bitcast i8* %233 to %union.pthread_mutex_t*
-  %235 = call i32 @pthread_mutex_init(%union.pthread_mutex_t* nonnull %234, %"struct.std::atomic"* null) #37
-  %236 = getelementptr inbounds i8, i8* %184, i64 184
-  %237 = bitcast i8* %236 to %union.pthread_cond_t*
-  %238 = call i32 @pthread_cond_init(%union.pthread_cond_t* nonnull %237, %"struct.std::atomic"* null) #37
-  %239 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %229, null
-  br i1 %239, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit4.i.i, label %240
+188:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i
+  %189 = bitcast i8* %186 to %class.Worker*
+  %190 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %167, i64 0, i32 5
+  %191 = load atomic i32, i32* %190 unordered, align 8, !tbaa !676
+  %192 = add nsw i32 %191, 1
+  store i32 %192, i32* %190, align 8, !tbaa !676
+  %193 = bitcast i8* %186 to i32*
+  store i32 %191, i32* %193, align 8, !tbaa !713
+  %194 = getelementptr inbounds i8, i8* %186, i64 4
+  %195 = bitcast i8* %194 to i32*
+  store i32 1, i32* %195, align 4, !tbaa !719
+  %196 = getelementptr inbounds i8, i8* %186, i64 8
+  %197 = getelementptr inbounds i8, i8* %186, i64 16
+  %198 = bitcast i8* %197 to i64*
+  store i64 8, i64* %198, align 8, !tbaa !658
+  %199 = call noalias dereferenceable_or_null(64) i8* @calloc(i64 8, i64 8) #37
+  %200 = bitcast i8* %199 to %"struct.(anonymous namespace)::Job"**
+  %201 = bitcast i8* %196 to i8**
+  store i8* %199, i8** %201, align 8, !tbaa !660
+  %202 = load atomic i64, i64* %198 unordered, align 8, !tbaa !658
+  %203 = add i64 %202, -1
+  %204 = lshr i64 %203, 1
+  %205 = getelementptr inbounds %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %200, i64 %204
+  %206 = call noalias dereferenceable_or_null(480) i8* @calloc(i64 12, i64 40) #37
+  %207 = bitcast %"struct.(anonymous namespace)::Job"** %205 to i8**
+  store i8* %206, i8** %207, align 8, !tbaa !3
+  %208 = getelementptr inbounds %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %205, i64 1
+  %209 = getelementptr inbounds i8, i8* %186, i64 24
+  %210 = getelementptr inbounds i8, i8* %186, i64 48
+  %211 = bitcast i8* %210 to %"struct.(anonymous namespace)::Job"***
+  store %"struct.(anonymous namespace)::Job"** %205, %"struct.(anonymous namespace)::Job"*** %211, align 8, !tbaa !662
+  %212 = load atomic %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %205 unordered, align 8, !tbaa !3
+  %213 = getelementptr inbounds i8, i8* %186, i64 32
+  %214 = bitcast i8* %213 to %"struct.(anonymous namespace)::Job"**
+  store %"struct.(anonymous namespace)::Job"* %212, %"struct.(anonymous namespace)::Job"** %214, align 8, !tbaa !663
+  %215 = getelementptr inbounds %"struct.(anonymous namespace)::Job", %"struct.(anonymous namespace)::Job"* %212, i64 12
+  %216 = getelementptr inbounds i8, i8* %186, i64 40
+  %217 = bitcast i8* %216 to %"struct.(anonymous namespace)::Job"**
+  store %"struct.(anonymous namespace)::Job"* %215, %"struct.(anonymous namespace)::Job"** %217, align 8, !tbaa !664
+  %218 = getelementptr inbounds i8, i8* %186, i64 56
+  %219 = getelementptr inbounds %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %208, i64 -1
+  %220 = getelementptr inbounds i8, i8* %186, i64 80
+  %221 = bitcast i8* %220 to %"struct.(anonymous namespace)::Job"***
+  store %"struct.(anonymous namespace)::Job"** %219, %"struct.(anonymous namespace)::Job"*** %221, align 8, !tbaa !662
+  %222 = getelementptr inbounds i8, i8* %186, i64 64
+  %223 = bitcast i8* %222 to %"struct.(anonymous namespace)::Job"**
+  store %"struct.(anonymous namespace)::Job"* %212, %"struct.(anonymous namespace)::Job"** %223, align 8, !tbaa !663
+  %224 = getelementptr inbounds i8, i8* %186, i64 72
+  %225 = bitcast i8* %224 to %"struct.(anonymous namespace)::Job"**
+  store %"struct.(anonymous namespace)::Job"* %215, %"struct.(anonymous namespace)::Job"** %225, align 8, !tbaa !664
+  %226 = ptrtoint %"struct.(anonymous namespace)::Job"* %212 to i64
+  %227 = bitcast i8* %209 to i64*
+  store i64 %226, i64* %227, align 8, !tbaa !720
+  %228 = bitcast i8* %218 to i64*
+  store i64 %226, i64* %228, align 8, !tbaa !652
+  %229 = getelementptr inbounds i8, i8* %186, i64 96
+  %230 = getelementptr inbounds i8, i8* %186, i64 112
+  %231 = bitcast i8* %230 to i8**
+  store i8* %229, i8** %231, align 8, !tbaa !721
+  %232 = getelementptr inbounds i8, i8* %186, i64 120
+  %233 = bitcast i8* %232 to i8**
+  store i8* %229, i8** %233, align 8, !tbaa !725
+  %234 = getelementptr inbounds i8, i8* %186, i64 128
+  %235 = getelementptr inbounds i8, i8* %186, i64 240
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %235, i8 0, i64 16, i1 false) #37
+  call void @llvm.memset.p0i8.i64(i8* nonnull align 8 dereferenceable(16) %234, i8 0, i64 16, i1 false)
+  %236 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
+  %237 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %236, i64 328
+  %238 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %237 to i32*
+  %239 = atomicrmw xchg i32* %238, i32 1 seq_cst, align 4
+  %240 = getelementptr inbounds i8, i8* %186, i64 144
+  %241 = bitcast i8* %240 to %union.pthread_mutex_t*
+  %242 = call i32 @pthread_mutex_init(%union.pthread_mutex_t* nonnull %241, %"struct.std::atomic"* null) #37
+  %243 = getelementptr inbounds i8, i8* %186, i64 184
+  %244 = bitcast i8* %243 to %union.pthread_cond_t*
+  %245 = call i32 @pthread_cond_init(%union.pthread_cond_t* nonnull %244, %"struct.std::atomic"* null) #37
+  %246 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %236, null
+  br i1 %246, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit4.i.i, label %247
 
-240:                                              ; preds = %186
-  %241 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %230 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %242 = atomicrmw xchg i32* %231, i32 %232 seq_cst, align 4
-  %243 = icmp eq i32 %242, 1
-  %244 = icmp eq i32 %232, 0
-  %245 = and i1 %244, %243
-  br i1 %245, label %246, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit4.i.i
+247:                                              ; preds = %188
+  %248 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %237 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %249 = atomicrmw xchg i32* %238, i32 %239 seq_cst, align 4
+  %250 = icmp eq i32 %249, 1
+  %251 = icmp eq i32 %239, 0
+  %252 = and i1 %251, %250
+  br i1 %252, label %253, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit4.i.i
 
-246:                                              ; preds = %240
-  %247 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %248 = and i8 %247, 1
-  %249 = icmp eq i8 %248, 0
-  br i1 %249, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit4.i.i, label %250
+253:                                              ; preds = %247
+  %254 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %255 = and i8 %254, 1
+  %256 = icmp eq i8 %255, 0
+  br i1 %256, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit4.i.i, label %257
 
-250:                                              ; preds = %246
-  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %241) #37
+257:                                              ; preds = %253
+  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %248) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit4.i.i
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit4.i.i: ; preds = %250, %246, %240, %186
-  %251 = load i32, i32* %191, align 8, !tbaa !701
-  %252 = sext i32 %251 to i64
-  %253 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %165, i64 0, i32 3, i32 0, i32 1
-  %254 = load i64, i64* %253, align 8, !tbaa !635
-  %255 = urem i64 %252, %254
-  %256 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %165, i64 0, i32 3, i32 0, i32 0
-  %257 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %256, align 8, !tbaa !637
-  %258 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %257, i64 %255
-  %259 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %258, align 8, !tbaa !3
-  %260 = icmp eq %"struct.std::__detail::_Hash_node_base"* %259, null
-  br i1 %260, label %.loopexit20, label %261
-
-261:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit4.i.i
-  %262 = bitcast %"struct.std::__detail::_Hash_node_base"* %259 to %"struct.std::__detail::_Hash_node.203"**
-  %263 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %262, align 8, !tbaa !216
-  %264 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %263, i64 0, i32 0, i32 1
-  %265 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %264 to i32*
-  %266 = load i32, i32* %265, align 4, !tbaa !73
-  %267 = icmp eq i32 %251, %266
-  br i1 %267, label %284, label %.preheader19
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit4.i.i: ; preds = %257, %253, %247, %188
+  %258 = load atomic i32, i32* %193 unordered, align 8, !tbaa !713
+  %259 = sext i32 %258 to i64
+  %260 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %167, i64 0, i32 3, i32 0, i32 1
+  %261 = load atomic i64, i64* %260 unordered, align 8, !tbaa !647
+  %262 = urem i64 %259, %261
+  %263 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %167, i64 0, i32 3, i32 0, i32 0
+  %264 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %263 unordered, align 8, !tbaa !649
+  %265 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %264, i64 %262
+  %266 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %265 unordered, align 8, !tbaa !3
+  %267 = icmp eq %"struct.std::__detail::_Hash_node_base"* %266, null
+  br i1 %267, label %.loopexit21, label %268
 
-268:                                              ; preds = %275
-  %269 = icmp eq i32 %251, %278
-  br i1 %269, label %282, label %.preheader19
+268:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit4.i.i
+  %269 = bitcast %"struct.std::__detail::_Hash_node_base"* %266 to %"struct.std::__detail::_Hash_node.203"**
+  %270 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %269 unordered, align 8, !tbaa !215
+  %271 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %270, i64 0, i32 0, i32 1
+  %272 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %271 to i32*
+  %273 = load atomic i32, i32* %272 unordered, align 4, !tbaa !71
+  %274 = icmp eq i32 %258, %273
+  br i1 %274, label %291, label %.preheader20
 
-.preheader19:                                     ; preds = %268, %261
-  %270 = phi %"struct.std::__detail::_Hash_node.203"* [ %274, %268 ], [ %263, %261 ]
-  %271 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %270, i64 0, i32 0, i32 0, i32 0
-  %272 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %271, align 8, !tbaa !216
-  %273 = icmp eq %"struct.std::__detail::_Hash_node_base"* %272, null
-  %274 = bitcast %"struct.std::__detail::_Hash_node_base"* %272 to %"struct.std::__detail::_Hash_node.203"*
-  br i1 %273, label %.loopexit20, label %275
+275:                                              ; preds = %282
+  %276 = icmp eq i32 %258, %285
+  br i1 %276, label %289, label %.preheader20
 
-275:                                              ; preds = %.preheader19
-  %276 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %272, i64 1
-  %277 = bitcast %"struct.std::__detail::_Hash_node_base"* %276 to i32*
-  %278 = load i32, i32* %277, align 4, !tbaa !73
-  %279 = sext i32 %278 to i64
-  %280 = urem i64 %279, %254
-  %281 = icmp eq i64 %280, %255
-  br i1 %281, label %268, label %.loopexit20
+.preheader20:                                     ; preds = %275, %268
+  %277 = phi %"struct.std::__detail::_Hash_node.203"* [ %281, %275 ], [ %270, %268 ]
+  %278 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %277, i64 0, i32 0, i32 0, i32 0
+  %279 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %278 unordered, align 8, !tbaa !215
+  %280 = icmp eq %"struct.std::__detail::_Hash_node_base"* %279, null
+  %281 = bitcast %"struct.std::__detail::_Hash_node_base"* %279 to %"struct.std::__detail::_Hash_node.203"*
+  br i1 %280, label %.loopexit21, label %282
 
-282:                                              ; preds = %268
-  %283 = icmp eq %"struct.std::__detail::_Hash_node.203"* %270, null
-  br i1 %283, label %.loopexit20, label %394
+282:                                              ; preds = %.preheader20
+  %283 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %279, i64 1
+  %284 = bitcast %"struct.std::__detail::_Hash_node_base"* %283 to i32*
+  %285 = load atomic i32, i32* %284 unordered, align 4, !tbaa !71
+  %286 = sext i32 %285 to i64
+  %287 = urem i64 %286, %261
+  %288 = icmp eq i64 %287, %262
+  br i1 %288, label %275, label %.loopexit21
 
-284:                                              ; preds = %261
-  %285 = icmp eq %"struct.std::__detail::_Hash_node.203"* %263, null
-  br i1 %285, label %.loopexit20, label %394
+289:                                              ; preds = %275
+  %290 = icmp eq %"struct.std::__detail::_Hash_node.203"* %277, null
+  br i1 %290, label %.loopexit21, label %401
 
-.loopexit20:                                      ; preds = %284, %282, %275, %.preheader19, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit4.i.i
-  %286 = call noalias dereferenceable_or_null(24) i8* @calloc(i64 1, i64 24) #37
-  %287 = bitcast i8* %286 to %"struct.std::__detail::_Hash_node.203"*
-  %288 = bitcast i8* %286 to %"struct.std::__detail::_Hash_node_base"**
-  %289 = getelementptr inbounds i8, i8* %286, i64 8
-  %290 = bitcast i8* %289 to i32*
-  store i32 %251, i32* %290, align 8, !tbaa !714
-  %291 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %165, i64 0, i32 3, i32 0, i32 4
-  %292 = load i64, i64* %253, align 8, !tbaa !635
-  %293 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %165, i64 0, i32 3, i32 0, i32 3
-  %294 = load i64, i64* %293, align 8, !tbaa !715
-  %295 = invoke { i8, i64 } @_ZNKSt8__detail20_Prime_rehash_policy14_M_need_rehashEmmm(%"struct.std::__detail::_Prime_rehash_policy"* nonnull %291, i64 %292, i64 %294, i64 1)
-          to label %.noexc.i.i unwind label %433
+291:                                              ; preds = %268
+  %292 = icmp eq %"struct.std::__detail::_Hash_node.203"* %270, null
+  br i1 %292, label %.loopexit21, label %401
 
-.noexc.i.i:                                       ; preds = %.loopexit20
-  %296 = extractvalue { i8, i64 } %295, 0
-  %297 = and i8 %296, 1
-  %298 = icmp eq i8 %297, 0
-  br i1 %298, label %299, label %301
+.loopexit21:                                      ; preds = %291, %289, %282, %.preheader20, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit4.i.i
+  %293 = call noalias dereferenceable_or_null(24) i8* @calloc(i64 1, i64 24) #37
+  %294 = bitcast i8* %293 to %"struct.std::__detail::_Hash_node.203"*
+  %295 = bitcast i8* %293 to %"struct.std::__detail::_Hash_node_base"**
+  %296 = getelementptr inbounds i8, i8* %293, i64 8
+  %297 = bitcast i8* %296 to i32*
+  store i32 %258, i32* %297, align 8, !tbaa !726
+  %298 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %167, i64 0, i32 3, i32 0, i32 4
+  %299 = load atomic i64, i64* %260 unordered, align 8, !tbaa !647
+  %300 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %167, i64 0, i32 3, i32 0, i32 3
+  %301 = load atomic i64, i64* %300 unordered, align 8, !tbaa !727
+  %302 = invoke { i8, i64 } @_ZNKSt8__detail20_Prime_rehash_policy14_M_need_rehashEmmm(%"struct.std::__detail::_Prime_rehash_policy"* nonnull %298, i64 %299, i64 %301, i64 1)
+          to label %.noexc.i.i unwind label %440
 
-299:                                              ; preds = %.noexc.i.i
-  %300 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %256, align 8, !tbaa !637
-  br label %359
+.noexc.i.i:                                       ; preds = %.loopexit21
+  %303 = extractvalue { i8, i64 } %302, 0
+  %304 = and i8 %303, 1
+  %305 = icmp eq i8 %304, 0
+  br i1 %305, label %306, label %308
 
-301:                                              ; preds = %.noexc.i.i
-  %302 = extractvalue { i8, i64 } %295, 1
-  %303 = icmp eq i64 %302, 1
-  br i1 %303, label %304, label %306, !prof !284, !misexpect !285
+306:                                              ; preds = %.noexc.i.i
+  %307 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %263 unordered, align 8, !tbaa !649
+  br label %366
 
-304:                                              ; preds = %301
-  %305 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %165, i64 0, i32 3, i32 0, i32 5
-  store %"struct.std::__detail::_Hash_node_base"* null, %"struct.std::__detail::_Hash_node_base"** %305, align 8, !tbaa !716
-  br label %310
+308:                                              ; preds = %.noexc.i.i
+  %309 = extractvalue { i8, i64 } %302, 1
+  %310 = icmp eq i64 %309, 1
+  br i1 %310, label %311, label %313, !prof !282, !misexpect !283
 
-306:                                              ; preds = %301
-  %307 = call noalias i8* @calloc(i64 %302, i64 8) #37
-  %308 = bitcast i8* %307 to %"struct.std::__detail::_Hash_node_base"**
-  %309 = shl i64 %302, 3
-  call void @llvm.memset.p0i8.i64(i8* align 8 %307, i8 0, i64 %309, i1 false)
-  br label %310
+311:                                              ; preds = %308
+  %312 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %167, i64 0, i32 3, i32 0, i32 5
+  store %"struct.std::__detail::_Hash_node_base"* null, %"struct.std::__detail::_Hash_node_base"** %312, align 8, !tbaa !728
+  br label %317
 
-310:                                              ; preds = %306, %304
-  %311 = phi %"struct.std::__detail::_Hash_node_base"** [ %305, %304 ], [ %308, %306 ]
-  %312 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %165, i64 0, i32 3, i32 0, i32 2, i32 0
-  %313 = bitcast %"struct.std::__detail::_Hash_node_base"** %312 to %"struct.std::__detail::_Hash_node.203"**
-  %314 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %313, align 8, !tbaa !672
-  %315 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %165, i64 0, i32 3, i32 0, i32 2
-  %316 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %315, i64 0, i32 0
-  store %"struct.std::__detail::_Hash_node_base"* null, %"struct.std::__detail::_Hash_node_base"** %316, align 8, !tbaa !672
-  %317 = icmp eq %"struct.std::__detail::_Hash_node.203"* %314, null
-  br i1 %317, label %.loopexit18, label %318
+313:                                              ; preds = %308
+  %314 = call noalias i8* @calloc(i64 %309, i64 8) #37
+  %315 = bitcast i8* %314 to %"struct.std::__detail::_Hash_node_base"**
+  %316 = shl i64 %309, 3
+  call void @llvm.memset.p0i8.i64(i8* align 8 %314, i8 0, i64 %316, i1 false)
+  br label %317
 
-318:                                              ; preds = %310
-  %319 = bitcast %"struct.std::__detail::_Hash_node_base"* %315 to i64*
-  br label %320
+317:                                              ; preds = %313, %311
+  %318 = phi %"struct.std::__detail::_Hash_node_base"** [ %312, %311 ], [ %315, %313 ]
+  %319 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %167, i64 0, i32 3, i32 0, i32 2, i32 0
+  %320 = bitcast %"struct.std::__detail::_Hash_node_base"** %319 to %"struct.std::__detail::_Hash_node.203"**
+  %321 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %320 unordered, align 8, !tbaa !684
+  %322 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %167, i64 0, i32 3, i32 0, i32 2
+  %323 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %322, i64 0, i32 0
+  store %"struct.std::__detail::_Hash_node_base"* null, %"struct.std::__detail::_Hash_node_base"** %323, align 8, !tbaa !684
+  %324 = icmp eq %"struct.std::__detail::_Hash_node.203"* %321, null
+  br i1 %324, label %.loopexit19, label %325
 
-320:                                              ; preds = %349, %318
-  %321 = phi %"struct.std::__detail::_Hash_node.203"* [ %314, %318 ], [ %324, %349 ]
-  %322 = phi i64 [ 0, %318 ], [ %350, %349 ]
-  %323 = bitcast %"struct.std::__detail::_Hash_node.203"* %321 to %"struct.std::__detail::_Hash_node.203"**
-  %324 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %323, align 8, !tbaa !216
-  %325 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %321, i64 0, i32 0, i32 1
-  %326 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %325 to i32*
-  %327 = load i32, i32* %326, align 4, !tbaa !73
-  %328 = sext i32 %327 to i64
-  %329 = urem i64 %328, %302
-  %330 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %311, i64 %329
-  %331 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %330, align 8, !tbaa !3
-  %332 = icmp eq %"struct.std::__detail::_Hash_node_base"* %331, null
-  br i1 %332, label %333, label %342
+325:                                              ; preds = %317
+  %326 = bitcast %"struct.std::__detail::_Hash_node_base"* %322 to i64*
+  br label %327
 
-333:                                              ; preds = %320
-  %334 = load i64, i64* %319, align 8, !tbaa !672
-  %335 = getelementptr %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %321, i64 0, i32 0, i32 0
-  %336 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %321, i64 0, i32 0, i32 0, i32 0
-  %337 = bitcast %"struct.std::__detail::_Hash_node.203"* %321 to i64*
-  store i64 %334, i64* %337, align 8, !tbaa !216
-  store %"struct.std::__detail::_Hash_node_base"* %335, %"struct.std::__detail::_Hash_node_base"** %316, align 8, !tbaa !672
-  store %"struct.std::__detail::_Hash_node_base"* %315, %"struct.std::__detail::_Hash_node_base"** %330, align 8, !tbaa !3
-  %338 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %336, align 8, !tbaa !216
+327:                                              ; preds = %356, %325
+  %328 = phi %"struct.std::__detail::_Hash_node.203"* [ %321, %325 ], [ %331, %356 ]
+  %329 = phi i64 [ 0, %325 ], [ %357, %356 ]
+  %330 = bitcast %"struct.std::__detail::_Hash_node.203"* %328 to %"struct.std::__detail::_Hash_node.203"**
+  %331 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %330 unordered, align 8, !tbaa !215
+  %332 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %328, i64 0, i32 0, i32 1
+  %333 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %332 to i32*
+  %334 = load atomic i32, i32* %333 unordered, align 4, !tbaa !71
+  %335 = sext i32 %334 to i64
+  %336 = urem i64 %335, %309
+  %337 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %318, i64 %336
+  %338 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %337 unordered, align 8, !tbaa !3
   %339 = icmp eq %"struct.std::__detail::_Hash_node_base"* %338, null
-  br i1 %339, label %349, label %340
+  br i1 %339, label %340, label %349
 
-340:                                              ; preds = %333
-  %341 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %311, i64 %322
-  store %"struct.std::__detail::_Hash_node_base"* %335, %"struct.std::__detail::_Hash_node_base"** %341, align 8, !tbaa !3
-  br label %349
+340:                                              ; preds = %327
+  %341 = load atomic i64, i64* %326 unordered, align 8, !tbaa !684
+  %342 = getelementptr %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %328, i64 0, i32 0, i32 0
+  %343 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %328, i64 0, i32 0, i32 0, i32 0
+  %344 = bitcast %"struct.std::__detail::_Hash_node.203"* %328 to i64*
+  store i64 %341, i64* %344, align 8, !tbaa !215
+  store %"struct.std::__detail::_Hash_node_base"* %342, %"struct.std::__detail::_Hash_node_base"** %323, align 8, !tbaa !684
+  store %"struct.std::__detail::_Hash_node_base"* %322, %"struct.std::__detail::_Hash_node_base"** %337, align 8, !tbaa !3
+  %345 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %343 unordered, align 8, !tbaa !215
+  %346 = icmp eq %"struct.std::__detail::_Hash_node_base"* %345, null
+  br i1 %346, label %356, label %347
 
-342:                                              ; preds = %320
-  %343 = bitcast %"struct.std::__detail::_Hash_node_base"* %331 to i64*
-  %344 = load i64, i64* %343, align 8, !tbaa !216
-  %345 = getelementptr %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %321, i64 0, i32 0, i32 0
-  %346 = bitcast %"struct.std::__detail::_Hash_node.203"* %321 to i64*
-  store i64 %344, i64* %346, align 8, !tbaa !216
-  %347 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %330, align 8, !tbaa !3
-  %348 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %347, i64 0, i32 0
-  store %"struct.std::__detail::_Hash_node_base"* %345, %"struct.std::__detail::_Hash_node_base"** %348, align 8, !tbaa !216
-  br label %349
+347:                                              ; preds = %340
+  %348 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %318, i64 %329
+  store %"struct.std::__detail::_Hash_node_base"* %342, %"struct.std::__detail::_Hash_node_base"** %348, align 8, !tbaa !3
+  br label %356
 
-349:                                              ; preds = %342, %340, %333
-  %350 = phi i64 [ %322, %342 ], [ %329, %333 ], [ %329, %340 ]
-  %351 = icmp eq %"struct.std::__detail::_Hash_node.203"* %324, null
-  br i1 %351, label %.loopexit18, label %320
+349:                                              ; preds = %327
+  %350 = bitcast %"struct.std::__detail::_Hash_node_base"* %338 to i64*
+  %351 = load atomic i64, i64* %350 unordered, align 8, !tbaa !215
+  %352 = getelementptr %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %328, i64 0, i32 0, i32 0
+  %353 = bitcast %"struct.std::__detail::_Hash_node.203"* %328 to i64*
+  store i64 %351, i64* %353, align 8, !tbaa !215
+  %354 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %337 unordered, align 8, !tbaa !3
+  %355 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %354, i64 0, i32 0
+  store %"struct.std::__detail::_Hash_node_base"* %352, %"struct.std::__detail::_Hash_node_base"** %355, align 8, !tbaa !215
+  br label %356
 
-.loopexit18:                                      ; preds = %349, %310
-  %352 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %256, align 8, !tbaa !637
-  %353 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %165, i64 0, i32 3, i32 0, i32 5
-  %354 = icmp eq %"struct.std::__detail::_Hash_node_base"** %353, %352
-  br i1 %354, label %357, label %355
+356:                                              ; preds = %349, %347, %340
+  %357 = phi i64 [ %329, %349 ], [ %336, %340 ], [ %336, %347 ]
+  %358 = icmp eq %"struct.std::__detail::_Hash_node.203"* %331, null
+  br i1 %358, label %.loopexit19, label %327
 
-355:                                              ; preds = %.loopexit18
-  %356 = bitcast %"struct.std::__detail::_Hash_node_base"** %352 to i8*
-  call void @free(i8* %356) #37
-  br label %357
+.loopexit19:                                      ; preds = %356, %317
+  %359 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %263 unordered, align 8, !tbaa !649
+  %360 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %167, i64 0, i32 3, i32 0, i32 5
+  %361 = icmp eq %"struct.std::__detail::_Hash_node_base"** %360, %359
+  br i1 %361, label %364, label %362
 
-357:                                              ; preds = %355, %.loopexit18
-  store i64 %302, i64* %253, align 8, !tbaa !635
-  store %"struct.std::__detail::_Hash_node_base"** %311, %"struct.std::__detail::_Hash_node_base"*** %256, align 8, !tbaa !637
-  %358 = urem i64 %252, %302
-  br label %359
+362:                                              ; preds = %.loopexit19
+  %363 = bitcast %"struct.std::__detail::_Hash_node_base"** %359 to i8*
+  call void @free(i8* %363) #37
+  br label %364
 
-359:                                              ; preds = %357, %299
-  %360 = phi %"struct.std::__detail::_Hash_node_base"** [ %300, %299 ], [ %311, %357 ]
-  %361 = phi i64 [ %255, %299 ], [ %358, %357 ]
-  %362 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %360, i64 %361
-  %363 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %362, align 8, !tbaa !3
-  %364 = icmp eq %"struct.std::__detail::_Hash_node_base"* %363, null
-  br i1 %364, label %371, label %365
+364:                                              ; preds = %362, %.loopexit19
+  store i64 %309, i64* %260, align 8, !tbaa !647
+  store %"struct.std::__detail::_Hash_node_base"** %318, %"struct.std::__detail::_Hash_node_base"*** %263, align 8, !tbaa !649
+  %365 = urem i64 %259, %309
+  br label %366
 
-365:                                              ; preds = %359
-  %366 = bitcast %"struct.std::__detail::_Hash_node_base"* %363 to i64*
-  %367 = load i64, i64* %366, align 8, !tbaa !216
-  %368 = bitcast i8* %286 to i64*
-  store i64 %367, i64* %368, align 8, !tbaa !216
-  %369 = bitcast %"struct.std::__detail::_Hash_node_base"** %362 to i8***
-  %370 = load i8**, i8*** %369, align 8, !tbaa !3
-  store i8* %286, i8** %370, align 8, !tbaa !216
+366:                                              ; preds = %364, %306
+  %367 = phi %"struct.std::__detail::_Hash_node_base"** [ %307, %306 ], [ %318, %364 ]
+  %368 = phi i64 [ %262, %306 ], [ %365, %364 ]
+  %369 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %367, i64 %368
+  %370 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %369 unordered, align 8, !tbaa !3
+  %371 = icmp eq %"struct.std::__detail::_Hash_node_base"* %370, null
+  br i1 %371, label %378, label %372
+
+372:                                              ; preds = %366
+  %373 = bitcast %"struct.std::__detail::_Hash_node_base"* %370 to i64*
+  %374 = load atomic i64, i64* %373 unordered, align 8, !tbaa !215
+  %375 = bitcast i8* %293 to i64*
+  store i64 %374, i64* %375, align 8, !tbaa !215
+  %376 = bitcast %"struct.std::__detail::_Hash_node_base"** %369 to i8***
+  %377 = load atomic i8**, i8*** %376 unordered, align 8, !tbaa !3
+  store i8* %293, i8** %377, align 8, !tbaa !215
   br label %_ZNSt10_HashtableIiSt4pairIKiP6WorkerEN6kotlin11std_support9allocatorIS4_EENSt8__detail10_Select1stESt8equal_toIiESt4hashIiENS9_18_Mod_range_hashingENS9_20_Default_ranged_hashENS9_20_Prime_rehash_policyENS9_17_Hashtable_traitsILb0ELb0ELb1EEEE21_M_insert_unique_nodeEmmPNS9_10_Hash_nodeIS4_Lb0EEEm.exit.i.i
 
-371:                                              ; preds = %359
-  %372 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %165, i64 0, i32 3, i32 0, i32 2
-  %373 = bitcast %"struct.std::__detail::_Hash_node_base"* %372 to i64*
-  %374 = load i64, i64* %373, align 8, !tbaa !672
-  %375 = bitcast i8* %286 to i64*
-  store i64 %374, i64* %375, align 8, !tbaa !216
-  %376 = bitcast %"struct.std::__detail::_Hash_node_base"* %372 to i8**
-  store i8* %286, i8** %376, align 8, !tbaa !672
-  %377 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %288, align 8, !tbaa !216
-  %378 = icmp eq %"struct.std::__detail::_Hash_node_base"* %377, null
-  br i1 %378, label %389, label %379
+378:                                              ; preds = %366
+  %379 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %167, i64 0, i32 3, i32 0, i32 2
+  %380 = bitcast %"struct.std::__detail::_Hash_node_base"* %379 to i64*
+  %381 = load atomic i64, i64* %380 unordered, align 8, !tbaa !684
+  %382 = bitcast i8* %293 to i64*
+  store i64 %381, i64* %382, align 8, !tbaa !215
+  %383 = bitcast %"struct.std::__detail::_Hash_node_base"* %379 to i8**
+  store i8* %293, i8** %383, align 8, !tbaa !684
+  %384 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %295 unordered, align 8, !tbaa !215
+  %385 = icmp eq %"struct.std::__detail::_Hash_node_base"* %384, null
+  br i1 %385, label %396, label %386
 
-379:                                              ; preds = %371
-  %380 = load i64, i64* %253, align 8, !tbaa !635
-  %381 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %377, i64 1
-  %382 = bitcast %"struct.std::__detail::_Hash_node_base"* %381 to i32*
-  %383 = load i32, i32* %382, align 4, !tbaa !73
-  %384 = sext i32 %383 to i64
-  %385 = urem i64 %384, %380
-  %386 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %360, i64 %385
-  %387 = bitcast %"struct.std::__detail::_Hash_node_base"** %386 to i8**
-  store i8* %286, i8** %387, align 8, !tbaa !3
-  %388 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %256, align 8, !tbaa !637
-  br label %389
+386:                                              ; preds = %378
+  %387 = load atomic i64, i64* %260 unordered, align 8, !tbaa !647
+  %388 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %384, i64 1
+  %389 = bitcast %"struct.std::__detail::_Hash_node_base"* %388 to i32*
+  %390 = load atomic i32, i32* %389 unordered, align 4, !tbaa !71
+  %391 = sext i32 %390 to i64
+  %392 = urem i64 %391, %387
+  %393 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %367, i64 %392
+  %394 = bitcast %"struct.std::__detail::_Hash_node_base"** %393 to i8**
+  store i8* %293, i8** %394, align 8, !tbaa !3
+  %395 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %263 unordered, align 8, !tbaa !649
+  br label %396
 
-389:                                              ; preds = %379, %371
-  %390 = phi %"struct.std::__detail::_Hash_node_base"** [ %360, %371 ], [ %388, %379 ]
-  %391 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %390, i64 %361
-  store %"struct.std::__detail::_Hash_node_base"* %372, %"struct.std::__detail::_Hash_node_base"** %391, align 8, !tbaa !3
+396:                                              ; preds = %386, %378
+  %397 = phi %"struct.std::__detail::_Hash_node_base"** [ %367, %378 ], [ %395, %386 ]
+  %398 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %397, i64 %368
+  store %"struct.std::__detail::_Hash_node_base"* %379, %"struct.std::__detail::_Hash_node_base"** %398, align 8, !tbaa !3
   br label %_ZNSt10_HashtableIiSt4pairIKiP6WorkerEN6kotlin11std_support9allocatorIS4_EENSt8__detail10_Select1stESt8equal_toIiESt4hashIiENS9_18_Mod_range_hashingENS9_20_Default_ranged_hashENS9_20_Prime_rehash_policyENS9_17_Hashtable_traitsILb0ELb0ELb1EEEE21_M_insert_unique_nodeEmmPNS9_10_Hash_nodeIS4_Lb0EEEm.exit.i.i
 
-_ZNSt10_HashtableIiSt4pairIKiP6WorkerEN6kotlin11std_support9allocatorIS4_EENSt8__detail10_Select1stESt8equal_toIiESt4hashIiENS9_18_Mod_range_hashingENS9_20_Default_ranged_hashENS9_20_Prime_rehash_policyENS9_17_Hashtable_traitsILb0ELb0ELb1EEEE21_M_insert_unique_nodeEmmPNS9_10_Hash_nodeIS4_Lb0EEEm.exit.i.i: ; preds = %389, %365
-  %392 = load i64, i64* %293, align 8, !tbaa !715
-  %393 = add i64 %392, 1
-  store i64 %393, i64* %293, align 8, !tbaa !715
-  br label %394
+_ZNSt10_HashtableIiSt4pairIKiP6WorkerEN6kotlin11std_support9allocatorIS4_EENSt8__detail10_Select1stESt8equal_toIiESt4hashIiENS9_18_Mod_range_hashingENS9_20_Default_ranged_hashENS9_20_Prime_rehash_policyENS9_17_Hashtable_traitsILb0ELb0ELb1EEEE21_M_insert_unique_nodeEmmPNS9_10_Hash_nodeIS4_Lb0EEEm.exit.i.i: ; preds = %396, %372
+  %399 = load atomic i64, i64* %300 unordered, align 8, !tbaa !727
+  %400 = add i64 %399, 1
+  store i64 %400, i64* %300, align 8, !tbaa !727
+  br label %401
 
-394:                                              ; preds = %_ZNSt10_HashtableIiSt4pairIKiP6WorkerEN6kotlin11std_support9allocatorIS4_EENSt8__detail10_Select1stESt8equal_toIiESt4hashIiENS9_18_Mod_range_hashingENS9_20_Default_ranged_hashENS9_20_Prime_rehash_policyENS9_17_Hashtable_traitsILb0ELb0ELb1EEEE21_M_insert_unique_nodeEmmPNS9_10_Hash_nodeIS4_Lb0EEEm.exit.i.i, %284, %282
-  %395 = phi %"struct.std::__detail::_Hash_node.203"* [ %263, %284 ], [ %274, %282 ], [ %287, %_ZNSt10_HashtableIiSt4pairIKiP6WorkerEN6kotlin11std_support9allocatorIS4_EENSt8__detail10_Select1stESt8equal_toIiESt4hashIiENS9_18_Mod_range_hashingENS9_20_Default_ranged_hashENS9_20_Prime_rehash_policyENS9_17_Hashtable_traitsILb0ELb0ELb1EEEE21_M_insert_unique_nodeEmmPNS9_10_Hash_nodeIS4_Lb0EEEm.exit.i.i ]
-  %396 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %395, i64 0, i32 0, i32 1, i32 0, i32 0, i64 8
-  %397 = bitcast i8* %396 to i8**
-  store i8* %184, i8** %397, align 8, !tbaa !3
-  %398 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
-  %399 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %398, i64 328
-  %400 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %399 to i32*
-  %401 = atomicrmw xchg i32* %400, i32 1 seq_cst, align 4
-  %402 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %166) #37
-  %403 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %398, null
-  br i1 %403, label %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i, label %404
+401:                                              ; preds = %_ZNSt10_HashtableIiSt4pairIKiP6WorkerEN6kotlin11std_support9allocatorIS4_EENSt8__detail10_Select1stESt8equal_toIiESt4hashIiENS9_18_Mod_range_hashingENS9_20_Default_ranged_hashENS9_20_Prime_rehash_policyENS9_17_Hashtable_traitsILb0ELb0ELb1EEEE21_M_insert_unique_nodeEmmPNS9_10_Hash_nodeIS4_Lb0EEEm.exit.i.i, %291, %289
+  %402 = phi %"struct.std::__detail::_Hash_node.203"* [ %270, %291 ], [ %281, %289 ], [ %294, %_ZNSt10_HashtableIiSt4pairIKiP6WorkerEN6kotlin11std_support9allocatorIS4_EENSt8__detail10_Select1stESt8equal_toIiESt4hashIiENS9_18_Mod_range_hashingENS9_20_Default_ranged_hashENS9_20_Prime_rehash_policyENS9_17_Hashtable_traitsILb0ELb0ELb1EEEE21_M_insert_unique_nodeEmmPNS9_10_Hash_nodeIS4_Lb0EEEm.exit.i.i ]
+  %403 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %402, i64 0, i32 0, i32 1, i32 0, i32 0, i64 8
+  %404 = bitcast i8* %403 to i8**
+  store i8* %186, i8** %404, align 8, !tbaa !3
+  %405 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
+  %406 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %405, i64 328
+  %407 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %406 to i32*
+  %408 = atomicrmw xchg i32* %407, i32 1 seq_cst, align 4
+  %409 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %168) #37
+  %410 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %405, null
+  br i1 %410, label %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i, label %411
 
-404:                                              ; preds = %394
-  %405 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %399 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %406 = atomicrmw xchg i32* %400, i32 %401 seq_cst, align 4
-  %407 = icmp eq i32 %406, 1
-  %408 = icmp eq i32 %401, 0
-  %409 = and i1 %408, %407
-  br i1 %409, label %410, label %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i
+411:                                              ; preds = %401
+  %412 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %406 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %413 = atomicrmw xchg i32* %407, i32 %408 seq_cst, align 4
+  %414 = icmp eq i32 %413, 1
+  %415 = icmp eq i32 %408, 0
+  %416 = and i1 %415, %414
+  br i1 %416, label %417, label %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i
 
-410:                                              ; preds = %404
-  %411 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %412 = and i8 %411, 1
-  %413 = icmp eq i8 %412, 0
-  br i1 %413, label %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i, label %414
+417:                                              ; preds = %411
+  %418 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %419 = and i8 %418, 1
+  %420 = icmp eq i8 %419, 0
+  br i1 %420, label %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i, label %421
 
-414:                                              ; preds = %410
-  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %405) #37
+421:                                              ; preds = %417
+  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %412) #37
   br label %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i
 
-415:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i
-  %416 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
-  %417 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %416, i64 328
-  %418 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %417 to i32*
-  %419 = atomicrmw xchg i32* %418, i32 1 seq_cst, align 4
-  %420 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %166) #37
-  %421 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %416, null
-  br i1 %421, label %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i, label %422
+422:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit2.i.i
+  %423 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
+  %424 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %423, i64 328
+  %425 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %424 to i32*
+  %426 = atomicrmw xchg i32* %425, i32 1 seq_cst, align 4
+  %427 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %168) #37
+  %428 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %423, null
+  br i1 %428, label %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i, label %429
 
-422:                                              ; preds = %415
-  %423 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %417 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %424 = atomicrmw xchg i32* %418, i32 %419 seq_cst, align 4
-  %425 = icmp eq i32 %424, 1
-  %426 = icmp eq i32 %419, 0
-  %427 = and i1 %426, %425
-  br i1 %427, label %428, label %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i
+429:                                              ; preds = %422
+  %430 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %424 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %431 = atomicrmw xchg i32* %425, i32 %426 seq_cst, align 4
+  %432 = icmp eq i32 %431, 1
+  %433 = icmp eq i32 %426, 0
+  %434 = and i1 %433, %432
+  br i1 %434, label %435, label %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i
 
-428:                                              ; preds = %422
-  %429 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %430 = and i8 %429, 1
-  %431 = icmp eq i8 %430, 0
-  br i1 %431, label %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i, label %432
+435:                                              ; preds = %429
+  %436 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %437 = and i8 %436, 1
+  %438 = icmp eq i8 %437, 0
+  br i1 %438, label %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i, label %439
 
-432:                                              ; preds = %428
-  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %423) #37
+439:                                              ; preds = %435
+  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %430) #37
   br label %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i
 
-433:                                              ; preds = %.loopexit20
-  %434 = landingpad { i8*, i32 }
+440:                                              ; preds = %.loopexit21
+  %441 = landingpad { i8*, i32 }
           catch i8* null
-  %435 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
-  %436 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %435, i64 328
-  %437 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %436 to i32*
-  %438 = atomicrmw xchg i32* %437, i32 1 seq_cst, align 4
-  %439 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %166) #37
-  %440 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %435, null
-  br i1 %440, label %.body, label %441
+  %442 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
+  %443 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %442, i64 328
+  %444 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %443 to i32*
+  %445 = atomicrmw xchg i32* %444, i32 1 seq_cst, align 4
+  %446 = call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %168) #37
+  %447 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %442, null
+  br i1 %447, label %.body, label %448
 
-441:                                              ; preds = %433
-  %442 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %436 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %443 = atomicrmw xchg i32* %437, i32 %438 seq_cst, align 4
-  %444 = icmp eq i32 %443, 1
-  %445 = icmp eq i32 %438, 0
-  %446 = and i1 %445, %444
-  br i1 %446, label %447, label %.body
+448:                                              ; preds = %440
+  %449 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %443 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %450 = atomicrmw xchg i32* %444, i32 %445 seq_cst, align 4
+  %451 = icmp eq i32 %450, 1
+  %452 = icmp eq i32 %445, 0
+  %453 = and i1 %452, %451
+  br i1 %453, label %454, label %.body
 
-447:                                              ; preds = %441
-  %448 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %449 = and i8 %448, 1
-  %450 = icmp eq i8 %449, 0
-  br i1 %450, label %.body, label %451
+454:                                              ; preds = %448
+  %455 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %456 = and i8 %455, 1
+  %457 = icmp eq i8 %456, 0
+  br i1 %457, label %.body, label %458
 
-451:                                              ; preds = %447
-  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %442) #37
+458:                                              ; preds = %454
+  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %449) #37
   br label %.body
 
-_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i: ; preds = %432, %428, %422, %415, %414, %410, %404, %394
-  %452 = phi %class.Worker* [ null, %415 ], [ %187, %404 ], [ %187, %410 ], [ %187, %414 ], [ %187, %394 ], [ null, %432 ], [ null, %428 ], [ null, %422 ]
-  store %class.Worker* %452, %class.Worker** @_ZN12_GLOBAL__N_18g_workerE, align 8, !tbaa !3
-  %.pre25 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %149, align 8, !tbaa !699
-  br label %453
+_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i: ; preds = %439, %435, %429, %422, %421, %417, %411, %401
+  %459 = phi %class.Worker* [ null, %422 ], [ %189, %411 ], [ %189, %417 ], [ %189, %421 ], [ %189, %401 ], [ null, %439 ], [ null, %435 ], [ null, %429 ]
+  store %class.Worker* %459, %class.Worker** @_ZN12_GLOBAL__N_18g_workerE, align 8, !tbaa !3
+  %.pre = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %151 unordered, align 8, !tbaa !711
+  br label %460
 
-453:                                              ; preds = %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
-  %454 = phi %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* [ %.pre25, %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i ], [ %163, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit ]
-  %455 = phi %class.Worker* [ %452, %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i ], [ %161, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit ]
-  %456 = tail call i64 @pthread_self() #1
-  %457 = getelementptr inbounds %class.Worker, %class.Worker* %455, i64 0, i32 9
-  store i64 %456, i64* %457, align 8, !tbaa !717
-  %458 = getelementptr inbounds %class.Worker, %class.Worker* %455, i64 0, i32 10
-  %459 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %458 to i64*
-  store i64 %160, i64* %459, align 8, !tbaa !718
-  %460 = getelementptr inbounds i8, i8* %26, i64 8
-  %461 = bitcast i8* %460 to %class.Worker**
-  store %class.Worker* %455, %class.Worker** %461, align 8, !tbaa !719
-  %462 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %463 = icmp eq %struct.InitNode.173* %462, null
-  br i1 %463, label %473, label %.preheader17
+460:                                              ; preds = %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
+  %461 = phi %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* [ %.pre, %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i ], [ %165, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit ]
+  %462 = phi %class.Worker* [ %459, %_ZN12_GLOBAL__N_15State17addWorkerUnlockedENS_23WorkerExceptionHandlingEP9ObjHeaderNS_10WorkerKindE.exit.i ], [ %163, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit ]
+  %463 = tail call i64 @pthread_self() #1
+  %464 = getelementptr inbounds %class.Worker, %class.Worker* %462, i64 0, i32 9
+  store i64 %463, i64* %464, align 8, !tbaa !729
+  %465 = getelementptr inbounds %class.Worker, %class.Worker* %462, i64 0, i32 10
+  %466 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %465 to i64*
+  store i64 %162, i64* %466, align 8, !tbaa !730
+  %467 = getelementptr inbounds i8, i8* %26, i64 8
+  %468 = bitcast i8* %467 to %class.Worker**
+  store %class.Worker* %462, %class.Worker** %468, align 8, !tbaa !731
+  %469 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %470 = icmp eq %struct.InitNode.173* %469, null
+  br i1 %470, label %480, label %.preheader18
 
-.preheader17:                                     ; preds = %467, %453
-  %464 = phi %struct.InitNode.173* [ %469, %467 ], [ %462, %453 ]
-  %465 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %464, i64 0, i32 0
-  %466 = load void (i32, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*)*, void (i32, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*)** %465, align 8, !tbaa !720
-  invoke void %466(i32 0, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %454)
-          to label %467 unwind label %38
+.preheader18:                                     ; preds = %474, %460
+  %471 = phi %struct.InitNode.173* [ %476, %474 ], [ %469, %460 ]
+  %472 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %471, i64 0, i32 0
+  %473 = load atomic void (i32, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*)*, void (i32, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*)** %472 unordered, align 8, !tbaa !732
+  invoke void %473(i32 0, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %461)
+          to label %474 unwind label %38
 
-467:                                              ; preds = %.preheader17
-  %468 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %464, i64 0, i32 1
-  %469 = load %struct.InitNode.173*, %struct.InitNode.173** %468, align 8, !tbaa !3
-  %470 = icmp eq %struct.InitNode.173* %469, null
-  br i1 %470, label %471, label %.preheader17
+474:                                              ; preds = %.preheader18
+  %475 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %471, i64 0, i32 1
+  %476 = load atomic %struct.InitNode.173*, %struct.InitNode.173** %475 unordered, align 8, !tbaa !3
+  %477 = icmp eq %struct.InitNode.173* %476, null
+  br i1 %477, label %478, label %.preheader18
 
-471:                                              ; preds = %467
-  %472 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %149, align 8, !tbaa !699
-  br label %473
+478:                                              ; preds = %474
+  %479 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %151 unordered, align 8, !tbaa !711
+  br label %480
 
-473:                                              ; preds = %471, %453
-  %474 = phi %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* [ %472, %471 ], [ %454, %453 ]
-  %475 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %474, i64 72
-  %476 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %474, i64 156
-  %477 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %476 to i32*
-  %478 = load i32, i32* %477, align 4, !tbaa !274
-  %479 = sext i32 %478 to i64
-  %480 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %474, i64 80
-  %481 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %480 to %struct.ObjHeader***
-  %482 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %480 to i64*
-  %483 = load i64, i64* %482, align 8, !tbaa !722
-  %484 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %475 to i64*
-  %485 = load i64, i64* %484, align 8, !tbaa !219
-  %486 = sub i64 %483, %485
-  %487 = ashr exact i64 %486, 3
-  %488 = icmp ult i64 %487, %479
-  %489 = inttoptr i64 %485 to %struct.ObjHeader**
-  %490 = inttoptr i64 %483 to %struct.ObjHeader**
-  br i1 %488, label %491, label %649
+480:                                              ; preds = %478, %460
+  %481 = phi %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* [ %479, %478 ], [ %461, %460 ]
+  %482 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %481, i64 72
+  %483 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %481, i64 156
+  %484 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %483 to i32*
+  %485 = load atomic i32, i32* %484 unordered, align 4, !tbaa !272
+  %486 = sext i32 %485 to i64
+  %487 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %481, i64 80
+  %488 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %487 to %struct.ObjHeader***
+  %489 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %487 to i64*
+  %490 = load atomic i64, i64* %489 unordered, align 8, !tbaa !734
+  %491 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %482 to i64*
+  %492 = load atomic i64, i64* %491 unordered, align 8, !tbaa !218
+  %493 = sub i64 %490, %492
+  %494 = ashr exact i64 %493, 3
+  %495 = icmp ult i64 %494, %486
+  %496 = inttoptr i64 %492 to %struct.ObjHeader**
+  %497 = inttoptr i64 %490 to %struct.ObjHeader**
+  br i1 %495, label %498, label %656
 
-491:                                              ; preds = %473
-  %492 = sub nsw i64 %479, %487
-  %493 = icmp eq i64 %492, 0
-  br i1 %493, label %CommitTLSStorage.exit, label %494
+498:                                              ; preds = %480
+  %499 = sub nsw i64 %486, %494
+  %500 = icmp eq i64 %499, 0
+  br i1 %500, label %CommitTLSStorage.exit, label %501
 
-494:                                              ; preds = %491
-  %495 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %474, i64 88
-  %496 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %495 to %struct.ObjHeader***
-  %497 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %495 to i64*
-  %498 = load i64, i64* %497, align 8, !tbaa !723
-  %499 = sub i64 %498, %483
-  %500 = ashr exact i64 %499, 3
-  %501 = icmp ult i64 %487, 2305843009213693952
-  call void @llvm.assume(i1 %501) #37
-  %502 = xor i64 %487, 2305843009213693951
-  %503 = icmp ule i64 %500, %502
-  call void @llvm.assume(i1 %503) #37
-  %504 = icmp ult i64 %500, %492
-  br i1 %504, label %509, label %505
+501:                                              ; preds = %498
+  %502 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %481, i64 88
+  %503 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %502 to %struct.ObjHeader***
+  %504 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %502 to i64*
+  %505 = load atomic i64, i64* %504 unordered, align 8, !tbaa !735
+  %506 = sub i64 %505, %490
+  %507 = ashr exact i64 %506, 3
+  %508 = icmp ult i64 %494, 2305843009213693952
+  call void @llvm.assume(i1 %508) #37
+  %509 = xor i64 %494, 2305843009213693951
+  %510 = icmp ule i64 %507, %509
+  call void @llvm.assume(i1 %510) #37
+  %511 = icmp ult i64 %507, %499
+  br i1 %511, label %516, label %512
 
-505:                                              ; preds = %494
-  %506 = inttoptr i64 %483 to i8*
-  %507 = shl nuw i64 %492, 3
-  call void @llvm.memset.p0i8.i64(i8* align 8 %506, i8 0, i64 %507, i1 false) #37
-  %508 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %490, i64 %492
-  br label %646
+512:                                              ; preds = %501
+  %513 = inttoptr i64 %490 to i8*
+  %514 = shl nuw i64 %499, 3
+  call void @llvm.memset.p0i8.i64(i8* align 8 %513, i8 0, i64 %514, i1 false) #37
+  %515 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %497, i64 %499
+  br label %653
 
-509:                                              ; preds = %494
-  %510 = icmp ult i64 %502, %492
-  br i1 %510, label %511, label %512
+516:                                              ; preds = %501
+  %517 = icmp ult i64 %509, %499
+  br i1 %517, label %518, label %519
 
-511:                                              ; preds = %509
+518:                                              ; preds = %516
   call fastcc void @_ZSt20__throw_length_errorPKc(i8* getelementptr inbounds ([26 x i8], [26 x i8]* @.str.17.572, i64 0, i64 0)) #51
   unreachable
 
-512:                                              ; preds = %509
-  %513 = icmp ult i64 %487, %492
-  %514 = select i1 %513, i64 %492, i64 %487
-  %515 = add nsw i64 %514, %487
-  %516 = icmp ult i64 %515, %487
-  %517 = icmp ugt i64 %515, 2305843009213693951
-  %518 = or i1 %516, %517
-  %519 = select i1 %518, i64 2305843009213693951, i64 %515
-  %520 = icmp eq i64 %519, 0
-  br i1 %520, label %524, label %521
+519:                                              ; preds = %516
+  %520 = icmp ult i64 %494, %499
+  %521 = select i1 %520, i64 %499, i64 %494
+  %522 = add nsw i64 %521, %494
+  %523 = icmp ult i64 %522, %494
+  %524 = icmp ugt i64 %522, 2305843009213693951
+  %525 = or i1 %523, %524
+  %526 = select i1 %525, i64 2305843009213693951, i64 %522
+  %527 = icmp eq i64 %526, 0
+  br i1 %527, label %531, label %528
 
-521:                                              ; preds = %512
-  %522 = call noalias i8* @calloc(i64 %519, i64 8) #37
-  %523 = bitcast i8* %522 to %struct.ObjHeader**
-  br label %524
+528:                                              ; preds = %519
+  %529 = call noalias i8* @calloc(i64 %526, i64 8) #37
+  %530 = bitcast i8* %529 to %struct.ObjHeader**
+  br label %531
 
-524:                                              ; preds = %521, %512
-  %525 = phi %struct.ObjHeader** [ %523, %521 ], [ null, %512 ]
-  %526 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %525, i64 %487
-  %527 = bitcast %struct.ObjHeader** %526 to i8*
-  %528 = shl nuw i64 %492, 3
-  call void @llvm.memset.p0i8.i64(i8* align 8 %527, i8 0, i64 %528, i1 false) #37
-  %529 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %475 to %struct.ObjHeader***
-  %530 = load %struct.ObjHeader**, %struct.ObjHeader*** %529, align 8, !tbaa !219
-  %531 = load %struct.ObjHeader**, %struct.ObjHeader*** %481, align 8, !tbaa !722
-  %532 = icmp eq %struct.ObjHeader** %530, %531
-  br i1 %532, label %638, label %533
+531:                                              ; preds = %528, %519
+  %532 = phi %struct.ObjHeader** [ %530, %528 ], [ null, %519 ]
+  %533 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %532, i64 %494
+  %534 = bitcast %struct.ObjHeader** %533 to i8*
+  %535 = shl nuw i64 %499, 3
+  call void @llvm.memset.p0i8.i64(i8* align 8 %534, i8 0, i64 %535, i1 false) #37
+  %536 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %482 to %struct.ObjHeader***
+  %537 = load atomic %struct.ObjHeader**, %struct.ObjHeader*** %536 unordered, align 8, !tbaa !218
+  %538 = load atomic %struct.ObjHeader**, %struct.ObjHeader*** %488 unordered, align 8, !tbaa !734
+  %539 = icmp eq %struct.ObjHeader** %537, %538
+  br i1 %539, label %645, label %540
 
-533:                                              ; preds = %524
-  %534 = ptrtoint %struct.ObjHeader** %530 to i64
-  %535 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %531, i64 -1
-  %536 = ptrtoint %struct.ObjHeader** %535 to i64
-  %537 = sub i64 %536, %534
-  %538 = lshr i64 %537, 3
-  %539 = add nuw nsw i64 %538, 1
-  %540 = icmp ult i64 %537, 24
-  br i1 %540, label %625, label %541
+540:                                              ; preds = %531
+  %541 = ptrtoint %struct.ObjHeader** %537 to i64
+  %542 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %538, i64 -1
+  %543 = ptrtoint %struct.ObjHeader** %542 to i64
+  %544 = sub i64 %543, %541
+  %545 = lshr i64 %544, 3
+  %546 = add nuw nsw i64 %545, 1
+  %547 = icmp ult i64 %544, 24
+  br i1 %547, label %632, label %548
 
-541:                                              ; preds = %533
-  %542 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %525, i64 %539
-  %543 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %530, i64 %539
-  %544 = icmp ult %struct.ObjHeader** %525, %543
-  %545 = icmp ult %struct.ObjHeader** %530, %542
-  %546 = and i1 %544, %545
-  br i1 %546, label %625, label %547
+548:                                              ; preds = %540
+  %549 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %532, i64 %546
+  %550 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %537, i64 %546
+  %551 = icmp ult %struct.ObjHeader** %532, %550
+  %552 = icmp ult %struct.ObjHeader** %537, %549
+  %553 = and i1 %551, %552
+  br i1 %553, label %632, label %554
 
-547:                                              ; preds = %541
-  %548 = and i64 %539, 4611686018427387900
-  %549 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %525, i64 %548
-  %550 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %530, i64 %548
-  %551 = add nsw i64 %548, -4
-  %552 = lshr exact i64 %551, 2
-  %553 = add nuw nsw i64 %552, 1
-  %554 = and i64 %553, 3
-  %555 = icmp ult i64 %551, 12
-  br i1 %555, label %.loopexit16, label %556
+554:                                              ; preds = %548
+  %555 = and i64 %546, 4611686018427387900
+  %556 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %532, i64 %555
+  %557 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %537, i64 %555
+  %558 = add nsw i64 %555, -4
+  %559 = lshr exact i64 %558, 2
+  %560 = add nuw nsw i64 %559, 1
+  %561 = and i64 %560, 3
+  %562 = icmp ult i64 %558, 12
+  br i1 %562, label %.loopexit17, label %563
 
-556:                                              ; preds = %547
-  %557 = and i64 %553, 9223372036854775804
-  br label %558
+563:                                              ; preds = %554
+  %564 = and i64 %560, 9223372036854775804
+  br label %565
 
-558:                                              ; preds = %558, %556
-  %559 = phi i64 [ 0, %556 ], [ %604, %558 ]
-  %560 = phi i64 [ %557, %556 ], [ %605, %558 ]
-  %561 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %525, i64 %559
-  %562 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %530, i64 %559
-  %563 = bitcast %struct.ObjHeader** %562 to <2 x i64>*
-  %564 = load <2 x i64>, <2 x i64>* %563, align 8, !tbaa !3, !alias.scope !724
-  %565 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %562, i64 2
-  %566 = bitcast %struct.ObjHeader** %565 to <2 x i64>*
-  %567 = load <2 x i64>, <2 x i64>* %566, align 8, !tbaa !3, !alias.scope !724
-  %568 = bitcast %struct.ObjHeader** %561 to <2 x i64>*
-  store <2 x i64> %564, <2 x i64>* %568, align 8, !tbaa !3, !alias.scope !727, !noalias !724
-  %569 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %561, i64 2
+565:                                              ; preds = %565, %563
+  %566 = phi i64 [ 0, %563 ], [ %611, %565 ]
+  %567 = phi i64 [ %564, %563 ], [ %612, %565 ]
+  %568 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %532, i64 %566
+  %569 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %537, i64 %566
   %570 = bitcast %struct.ObjHeader** %569 to <2 x i64>*
-  store <2 x i64> %567, <2 x i64>* %570, align 8, !tbaa !3, !alias.scope !727, !noalias !724
-  %571 = or i64 %559, 4
-  %572 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %525, i64 %571
-  %573 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %530, i64 %571
-  %574 = bitcast %struct.ObjHeader** %573 to <2 x i64>*
-  %575 = load <2 x i64>, <2 x i64>* %574, align 8, !tbaa !3, !alias.scope !724
-  %576 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %573, i64 2
+  %571 = load <2 x i64>, <2 x i64>* %570, align 8, !tbaa !3, !alias.scope !736
+  %572 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %569, i64 2
+  %573 = bitcast %struct.ObjHeader** %572 to <2 x i64>*
+  %574 = load <2 x i64>, <2 x i64>* %573, align 8, !tbaa !3, !alias.scope !736
+  %575 = bitcast %struct.ObjHeader** %568 to <2 x i64>*
+  store <2 x i64> %571, <2 x i64>* %575, align 8, !tbaa !3, !alias.scope !739, !noalias !736
+  %576 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %568, i64 2
   %577 = bitcast %struct.ObjHeader** %576 to <2 x i64>*
-  %578 = load <2 x i64>, <2 x i64>* %577, align 8, !tbaa !3, !alias.scope !724
-  %579 = bitcast %struct.ObjHeader** %572 to <2 x i64>*
-  store <2 x i64> %575, <2 x i64>* %579, align 8, !tbaa !3, !alias.scope !727, !noalias !724
-  %580 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %572, i64 2
+  store <2 x i64> %574, <2 x i64>* %577, align 8, !tbaa !3, !alias.scope !739, !noalias !736
+  %578 = or i64 %566, 4
+  %579 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %532, i64 %578
+  %580 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %537, i64 %578
   %581 = bitcast %struct.ObjHeader** %580 to <2 x i64>*
-  store <2 x i64> %578, <2 x i64>* %581, align 8, !tbaa !3, !alias.scope !727, !noalias !724
-  %582 = or i64 %559, 8
-  %583 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %525, i64 %582
-  %584 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %530, i64 %582
-  %585 = bitcast %struct.ObjHeader** %584 to <2 x i64>*
-  %586 = load <2 x i64>, <2 x i64>* %585, align 8, !tbaa !3, !alias.scope !724
-  %587 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %584, i64 2
+  %582 = load <2 x i64>, <2 x i64>* %581, align 8, !tbaa !3, !alias.scope !736
+  %583 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %580, i64 2
+  %584 = bitcast %struct.ObjHeader** %583 to <2 x i64>*
+  %585 = load <2 x i64>, <2 x i64>* %584, align 8, !tbaa !3, !alias.scope !736
+  %586 = bitcast %struct.ObjHeader** %579 to <2 x i64>*
+  store <2 x i64> %582, <2 x i64>* %586, align 8, !tbaa !3, !alias.scope !739, !noalias !736
+  %587 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %579, i64 2
   %588 = bitcast %struct.ObjHeader** %587 to <2 x i64>*
-  %589 = load <2 x i64>, <2 x i64>* %588, align 8, !tbaa !3, !alias.scope !724
-  %590 = bitcast %struct.ObjHeader** %583 to <2 x i64>*
-  store <2 x i64> %586, <2 x i64>* %590, align 8, !tbaa !3, !alias.scope !727, !noalias !724
-  %591 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %583, i64 2
+  store <2 x i64> %585, <2 x i64>* %588, align 8, !tbaa !3, !alias.scope !739, !noalias !736
+  %589 = or i64 %566, 8
+  %590 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %532, i64 %589
+  %591 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %537, i64 %589
   %592 = bitcast %struct.ObjHeader** %591 to <2 x i64>*
-  store <2 x i64> %589, <2 x i64>* %592, align 8, !tbaa !3, !alias.scope !727, !noalias !724
-  %593 = or i64 %559, 12
-  %594 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %525, i64 %593
-  %595 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %530, i64 %593
-  %596 = bitcast %struct.ObjHeader** %595 to <2 x i64>*
-  %597 = load <2 x i64>, <2 x i64>* %596, align 8, !tbaa !3, !alias.scope !724
-  %598 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %595, i64 2
+  %593 = load <2 x i64>, <2 x i64>* %592, align 8, !tbaa !3, !alias.scope !736
+  %594 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %591, i64 2
+  %595 = bitcast %struct.ObjHeader** %594 to <2 x i64>*
+  %596 = load <2 x i64>, <2 x i64>* %595, align 8, !tbaa !3, !alias.scope !736
+  %597 = bitcast %struct.ObjHeader** %590 to <2 x i64>*
+  store <2 x i64> %593, <2 x i64>* %597, align 8, !tbaa !3, !alias.scope !739, !noalias !736
+  %598 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %590, i64 2
   %599 = bitcast %struct.ObjHeader** %598 to <2 x i64>*
-  %600 = load <2 x i64>, <2 x i64>* %599, align 8, !tbaa !3, !alias.scope !724
-  %601 = bitcast %struct.ObjHeader** %594 to <2 x i64>*
-  store <2 x i64> %597, <2 x i64>* %601, align 8, !tbaa !3, !alias.scope !727, !noalias !724
-  %602 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %594, i64 2
+  store <2 x i64> %596, <2 x i64>* %599, align 8, !tbaa !3, !alias.scope !739, !noalias !736
+  %600 = or i64 %566, 12
+  %601 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %532, i64 %600
+  %602 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %537, i64 %600
   %603 = bitcast %struct.ObjHeader** %602 to <2 x i64>*
-  store <2 x i64> %600, <2 x i64>* %603, align 8, !tbaa !3, !alias.scope !727, !noalias !724
-  %604 = add i64 %559, 16
-  %605 = add i64 %560, -4
-  %606 = icmp eq i64 %605, 0
-  br i1 %606, label %.loopexit16, label %558, !llvm.loop !729
+  %604 = load <2 x i64>, <2 x i64>* %603, align 8, !tbaa !3, !alias.scope !736
+  %605 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %602, i64 2
+  %606 = bitcast %struct.ObjHeader** %605 to <2 x i64>*
+  %607 = load <2 x i64>, <2 x i64>* %606, align 8, !tbaa !3, !alias.scope !736
+  %608 = bitcast %struct.ObjHeader** %601 to <2 x i64>*
+  store <2 x i64> %604, <2 x i64>* %608, align 8, !tbaa !3, !alias.scope !739, !noalias !736
+  %609 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %601, i64 2
+  %610 = bitcast %struct.ObjHeader** %609 to <2 x i64>*
+  store <2 x i64> %607, <2 x i64>* %610, align 8, !tbaa !3, !alias.scope !739, !noalias !736
+  %611 = add i64 %566, 16
+  %612 = add i64 %567, -4
+  %613 = icmp eq i64 %612, 0
+  br i1 %613, label %.loopexit17, label %565, !llvm.loop !741
 
-.loopexit16:                                      ; preds = %558, %547
-  %607 = phi i64 [ 0, %547 ], [ %604, %558 ]
-  %608 = icmp eq i64 %554, 0
-  br i1 %608, label %.loopexit15, label %.preheader14
+.loopexit17:                                      ; preds = %565, %554
+  %614 = phi i64 [ 0, %554 ], [ %611, %565 ]
+  %615 = icmp eq i64 %561, 0
+  br i1 %615, label %.loopexit16, label %.preheader15
 
-.preheader14:                                     ; preds = %.preheader14, %.loopexit16
-  %609 = phi i64 [ %621, %.preheader14 ], [ %607, %.loopexit16 ]
-  %610 = phi i64 [ %622, %.preheader14 ], [ %554, %.loopexit16 ]
-  %611 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %525, i64 %609
-  %612 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %530, i64 %609
-  %613 = bitcast %struct.ObjHeader** %612 to <2 x i64>*
-  %614 = load <2 x i64>, <2 x i64>* %613, align 8, !tbaa !3, !alias.scope !724
-  %615 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %612, i64 2
-  %616 = bitcast %struct.ObjHeader** %615 to <2 x i64>*
-  %617 = load <2 x i64>, <2 x i64>* %616, align 8, !tbaa !3, !alias.scope !724
-  %618 = bitcast %struct.ObjHeader** %611 to <2 x i64>*
-  store <2 x i64> %614, <2 x i64>* %618, align 8, !tbaa !3, !alias.scope !727, !noalias !724
-  %619 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %611, i64 2
+.preheader15:                                     ; preds = %.preheader15, %.loopexit17
+  %616 = phi i64 [ %628, %.preheader15 ], [ %614, %.loopexit17 ]
+  %617 = phi i64 [ %629, %.preheader15 ], [ %561, %.loopexit17 ]
+  %618 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %532, i64 %616
+  %619 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %537, i64 %616
   %620 = bitcast %struct.ObjHeader** %619 to <2 x i64>*
-  store <2 x i64> %617, <2 x i64>* %620, align 8, !tbaa !3, !alias.scope !727, !noalias !724
-  %621 = add i64 %609, 4
-  %622 = add nsw i64 %610, -1
-  %623 = icmp eq i64 %622, 0
-  br i1 %623, label %.loopexit15, label %.preheader14, !llvm.loop !730
+  %621 = load <2 x i64>, <2 x i64>* %620, align 8, !tbaa !3, !alias.scope !736
+  %622 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %619, i64 2
+  %623 = bitcast %struct.ObjHeader** %622 to <2 x i64>*
+  %624 = load <2 x i64>, <2 x i64>* %623, align 8, !tbaa !3, !alias.scope !736
+  %625 = bitcast %struct.ObjHeader** %618 to <2 x i64>*
+  store <2 x i64> %621, <2 x i64>* %625, align 8, !tbaa !3, !alias.scope !739, !noalias !736
+  %626 = getelementptr %struct.ObjHeader*, %struct.ObjHeader** %618, i64 2
+  %627 = bitcast %struct.ObjHeader** %626 to <2 x i64>*
+  store <2 x i64> %624, <2 x i64>* %627, align 8, !tbaa !3, !alias.scope !739, !noalias !736
+  %628 = add i64 %616, 4
+  %629 = add nsw i64 %617, -1
+  %630 = icmp eq i64 %629, 0
+  br i1 %630, label %.loopexit16, label %.preheader15, !llvm.loop !742
 
-.loopexit15:                                      ; preds = %.preheader14, %.loopexit16
-  %624 = icmp eq i64 %539, %548
-  br i1 %624, label %.loopexit13, label %625
+.loopexit16:                                      ; preds = %.preheader15, %.loopexit17
+  %631 = icmp eq i64 %546, %555
+  br i1 %631, label %.loopexit14, label %632
 
-625:                                              ; preds = %.loopexit15, %541, %533
-  %626 = phi %struct.ObjHeader** [ %525, %541 ], [ %525, %533 ], [ %549, %.loopexit15 ]
-  %627 = phi %struct.ObjHeader** [ %530, %541 ], [ %530, %533 ], [ %550, %.loopexit15 ]
-  br label %628
+632:                                              ; preds = %.loopexit16, %548, %540
+  %633 = phi %struct.ObjHeader** [ %532, %548 ], [ %532, %540 ], [ %556, %.loopexit16 ]
+  %634 = phi %struct.ObjHeader** [ %537, %548 ], [ %537, %540 ], [ %557, %.loopexit16 ]
+  br label %635
 
-628:                                              ; preds = %628, %625
-  %629 = phi %struct.ObjHeader** [ %635, %628 ], [ %626, %625 ]
-  %630 = phi %struct.ObjHeader** [ %634, %628 ], [ %627, %625 ]
-  %631 = bitcast %struct.ObjHeader** %630 to i64*
-  %632 = load i64, i64* %631, align 8, !tbaa !3
-  %633 = bitcast %struct.ObjHeader** %629 to i64*
-  store i64 %632, i64* %633, align 8, !tbaa !3
-  %634 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %630, i64 1
-  %635 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %629, i64 1
-  %636 = icmp eq %struct.ObjHeader** %634, %531
-  br i1 %636, label %.loopexit13, label %628, !llvm.loop !731
+635:                                              ; preds = %635, %632
+  %636 = phi %struct.ObjHeader** [ %642, %635 ], [ %633, %632 ]
+  %637 = phi %struct.ObjHeader** [ %641, %635 ], [ %634, %632 ]
+  %638 = bitcast %struct.ObjHeader** %637 to i64*
+  %639 = load atomic i64, i64* %638 unordered, align 8, !tbaa !3
+  %640 = bitcast %struct.ObjHeader** %636 to i64*
+  store i64 %639, i64* %640, align 8, !tbaa !3
+  %641 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %637, i64 1
+  %642 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %636, i64 1
+  %643 = icmp eq %struct.ObjHeader** %641, %538
+  br i1 %643, label %.loopexit14, label %635, !llvm.loop !743
 
-.loopexit13:                                      ; preds = %628, %.loopexit15
-  %637 = load %struct.ObjHeader**, %struct.ObjHeader*** %529, align 8, !tbaa !219
-  br label %638
+.loopexit14:                                      ; preds = %635, %.loopexit16
+  %644 = load atomic %struct.ObjHeader**, %struct.ObjHeader*** %536 unordered, align 8, !tbaa !218
+  br label %645
 
-638:                                              ; preds = %.loopexit13, %524
-  %639 = phi %struct.ObjHeader** [ %637, %.loopexit13 ], [ %530, %524 ]
-  %640 = icmp eq %struct.ObjHeader** %639, null
-  br i1 %640, label %643, label %641
+645:                                              ; preds = %.loopexit14, %531
+  %646 = phi %struct.ObjHeader** [ %644, %.loopexit14 ], [ %537, %531 ]
+  %647 = icmp eq %struct.ObjHeader** %646, null
+  br i1 %647, label %650, label %648
 
-641:                                              ; preds = %638
-  %642 = bitcast %struct.ObjHeader** %639 to i8*
-  call void @free(i8* %642) #37
-  br label %643
+648:                                              ; preds = %645
+  %649 = bitcast %struct.ObjHeader** %646 to i8*
+  call void @free(i8* %649) #37
+  br label %650
 
-643:                                              ; preds = %641, %638
-  store %struct.ObjHeader** %525, %struct.ObjHeader*** %529, align 8, !tbaa !219
-  %644 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %525, i64 %479
-  store %struct.ObjHeader** %644, %struct.ObjHeader*** %481, align 8, !tbaa !722
-  %645 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %525, i64 %519
-  br label %646
+650:                                              ; preds = %648, %645
+  store %struct.ObjHeader** %532, %struct.ObjHeader*** %536, align 8, !tbaa !218
+  %651 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %532, i64 %486
+  store %struct.ObjHeader** %651, %struct.ObjHeader*** %488, align 8, !tbaa !734
+  %652 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %532, i64 %526
+  br label %653
 
-646:                                              ; preds = %643, %505
-  %647 = phi %struct.ObjHeader*** [ %481, %505 ], [ %496, %643 ]
-  %648 = phi %struct.ObjHeader** [ %508, %505 ], [ %645, %643 ]
-  store %struct.ObjHeader** %648, %struct.ObjHeader*** %647, align 8, !tbaa !3
+653:                                              ; preds = %650, %512
+  %654 = phi %struct.ObjHeader*** [ %488, %512 ], [ %503, %650 ]
+  %655 = phi %struct.ObjHeader** [ %515, %512 ], [ %652, %650 ]
+  store %struct.ObjHeader** %655, %struct.ObjHeader*** %654, align 8, !tbaa !3
   br label %CommitTLSStorage.exit
 
-649:                                              ; preds = %473
-  %650 = icmp ugt i64 %487, %479
-  br i1 %650, label %651, label %CommitTLSStorage.exit
+656:                                              ; preds = %480
+  %657 = icmp ugt i64 %494, %486
+  br i1 %657, label %658, label %CommitTLSStorage.exit
 
-651:                                              ; preds = %649
-  %652 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %489, i64 %479
-  %653 = icmp eq %struct.ObjHeader** %652, %490
-  br i1 %653, label %CommitTLSStorage.exit, label %654
+658:                                              ; preds = %656
+  %659 = getelementptr inbounds %struct.ObjHeader*, %struct.ObjHeader** %496, i64 %486
+  %660 = icmp eq %struct.ObjHeader** %659, %497
+  br i1 %660, label %CommitTLSStorage.exit, label %661
 
-654:                                              ; preds = %651
-  store %struct.ObjHeader** %652, %struct.ObjHeader*** %481, align 8, !tbaa !722
+661:                                              ; preds = %658
+  store %struct.ObjHeader** %659, %struct.ObjHeader*** %488, align 8, !tbaa !734
   br label %CommitTLSStorage.exit
 
-CommitTLSStorage.exit:                            ; preds = %654, %651, %649, %646, %491
-  %655 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %474, i64 152
-  %656 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %655 to i32*
-  store i32 1, i32* %656, align 8, !tbaa !732
-  br i1 %43, label %657, label %.loopexit12
-
-657:                                              ; preds = %CommitTLSStorage.exit
-  %658 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %149, align 8, !tbaa !699
-  %659 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %660 = icmp eq %struct.InitNode.173* %659, null
-  br i1 %660, label %.loopexit, label %.preheader11
-
-.preheader11:                                     ; preds = %664, %657
-  %661 = phi %struct.InitNode.173* [ %666, %664 ], [ %659, %657 ]
-  %662 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %661, i64 0, i32 0
-  %663 = load void (i32, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*)*, void (i32, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*)** %662, align 8, !tbaa !720
-  invoke void %663(i32 1, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %658)
-          to label %664 unwind label %36
+CommitTLSStorage.exit:                            ; preds = %661, %658, %656, %653, %498
+  %662 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %481, i64 152
+  %663 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %662 to i32*
+  store i32 1, i32* %663, align 8, !tbaa !744
+  br i1 %43, label %664, label %.loopexit13
 
-664:                                              ; preds = %.preheader11
-  %665 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %661, i64 0, i32 1
-  %666 = load %struct.InitNode.173*, %struct.InitNode.173** %665, align 8, !tbaa !3
+664:                                              ; preds = %CommitTLSStorage.exit
+  %665 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %151 unordered, align 8, !tbaa !711
+  %666 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
   %667 = icmp eq %struct.InitNode.173* %666, null
-  br i1 %667, label %.loopexit12, label %.preheader11
+  br i1 %667, label %.loopexit, label %.preheader12
 
-.loopexit12:                                      ; preds = %664, %CommitTLSStorage.exit
-  %668 = load %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE, align 8, !tbaa !3
-  %669 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %149, align 8, !tbaa !699
-  %670 = icmp eq %struct.InitNode.173* %668, null
-  br i1 %670, label %.loopexit, label %.preheader
+.preheader12:                                     ; preds = %671, %664
+  %668 = phi %struct.InitNode.173* [ %673, %671 ], [ %666, %664 ]
+  %669 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %668, i64 0, i32 0
+  %670 = load atomic void (i32, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*)*, void (i32, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*)** %669 unordered, align 8, !tbaa !732
+  invoke void %670(i32 1, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %665)
+          to label %671 unwind label %36
 
-.preheader:                                       ; preds = %674, %.loopexit12
-  %671 = phi %struct.InitNode.173* [ %676, %674 ], [ %668, %.loopexit12 ]
-  %672 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %671, i64 0, i32 0
-  %673 = load void (i32, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*)*, void (i32, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*)** %672, align 8, !tbaa !720
-  invoke void %673(i32 2, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %669)
-          to label %674 unwind label %34
+671:                                              ; preds = %.preheader12
+  %672 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %668, i64 0, i32 1
+  %673 = load atomic %struct.InitNode.173*, %struct.InitNode.173** %672 unordered, align 8, !tbaa !3
+  %674 = icmp eq %struct.InitNode.173* %673, null
+  br i1 %674, label %.loopexit13, label %.preheader12
 
-674:                                              ; preds = %.preheader
-  %675 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %671, i64 0, i32 1
-  %676 = load %struct.InitNode.173*, %struct.InitNode.173** %675, align 8, !tbaa !3
-  %677 = icmp eq %struct.InitNode.173* %676, null
+.loopexit13:                                      ; preds = %671, %CommitTLSStorage.exit
+  %675 = load atomic %struct.InitNode.173*, %struct.InitNode.173** @_ZN12_GLOBAL__N_112initHeadNodeE unordered, align 8, !tbaa !3
+  %676 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %151 unordered, align 8, !tbaa !711
+  %677 = icmp eq %struct.InitNode.173* %675, null
   br i1 %677, label %.loopexit, label %.preheader
 
-.loopexit:                                        ; preds = %674, %.loopexit12, %657
-  store i32 1, i32* %30, align 8, !tbaa !733
-  %678 = icmp eq i8* %45, null
-  br i1 %678, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit9, label %679
+.preheader:                                       ; preds = %681, %.loopexit13
+  %678 = phi %struct.InitNode.173* [ %683, %681 ], [ %675, %.loopexit13 ]
+  %679 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %678, i64 0, i32 0
+  %680 = load atomic void (i32, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*)*, void (i32, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*)** %679 unordered, align 8, !tbaa !732
+  invoke void %680(i32 2, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %676)
+          to label %681 unwind label %34
 
-679:                                              ; preds = %.loopexit
-  %680 = atomicrmw xchg i32* %94, i32 %152 seq_cst, align 4
-  %681 = icmp eq i32 %680, 1
-  %682 = icmp eq i32 %152, 0
-  %683 = and i1 %682, %681
-  br i1 %683, label %684, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit9
+681:                                              ; preds = %.preheader
+  %682 = getelementptr inbounds %struct.InitNode.173, %struct.InitNode.173* %678, i64 0, i32 1
+  %683 = load atomic %struct.InitNode.173*, %struct.InitNode.173** %682 unordered, align 8, !tbaa !3
+  %684 = icmp eq %struct.InitNode.173* %683, null
+  br i1 %684, label %.loopexit, label %.preheader
 
-684:                                              ; preds = %679
-  %685 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %686 = and i8 %685, 1
-  %687 = icmp eq i8 %686, 0
-  br i1 %687, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit9, label %688
+.loopexit:                                        ; preds = %681, %.loopexit13, %664
+  store i32 1, i32* %30, align 8, !tbaa !745
+  %685 = icmp eq i8* %45, null
+  br i1 %685, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit9, label %686
 
-688:                                              ; preds = %684
-  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %151) #37
+686:                                              ; preds = %.loopexit
+  %687 = atomicrmw xchg i32* %94, i32 %154 seq_cst, align 4
+  %688 = icmp eq i32 %687, 1
+  %689 = icmp eq i32 %154, 0
+  %690 = and i1 %689, %688
+  br i1 %690, label %691, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit9
+
+691:                                              ; preds = %686
+  %692 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %693 = and i8 %692, 1
+  %694 = icmp eq i8 %693, 0
+  br i1 %694, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit9, label %695
+
+695:                                              ; preds = %691
+  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %153) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit9
 
-.body:                                            ; preds = %451, %447, %441, %433, %38, %36, %34
-  %689 = phi { i8*, i32 } [ %35, %34 ], [ %37, %36 ], [ %39, %38 ], [ %434, %433 ], [ %434, %451 ], [ %434, %447 ], [ %434, %441 ]
-  %690 = icmp eq i8* %45, null
-  br i1 %690, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit10, label %691
+.body:                                            ; preds = %458, %454, %448, %440, %38, %36, %34
+  %696 = phi { i8*, i32 } [ %35, %34 ], [ %37, %36 ], [ %39, %38 ], [ %441, %440 ], [ %441, %458 ], [ %441, %454 ], [ %441, %448 ]
+  %697 = icmp eq i8* %45, null
+  br i1 %697, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit10, label %698
 
-691:                                              ; preds = %.body
-  %692 = atomicrmw xchg i32* %94, i32 %152 seq_cst, align 4
-  %693 = icmp eq i32 %692, 1
-  %694 = icmp eq i32 %152, 0
-  %695 = and i1 %694, %693
-  br i1 %695, label %696, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit10
+698:                                              ; preds = %.body
+  %699 = atomicrmw xchg i32* %94, i32 %154 seq_cst, align 4
+  %700 = icmp eq i32 %699, 1
+  %701 = icmp eq i32 %154, 0
+  %702 = and i1 %701, %700
+  br i1 %702, label %703, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit10
 
-696:                                              ; preds = %691
-  %697 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %698 = and i8 %697, 1
-  %699 = icmp eq i8 %698, 0
-  br i1 %699, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit10, label %700
+703:                                              ; preds = %698
+  %704 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %705 = and i8 %704, 1
+  %706 = icmp eq i8 %705, 0
+  br i1 %706, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit10, label %707
 
-700:                                              ; preds = %696
-  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %151) #37
+707:                                              ; preds = %703
+  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %153) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit10
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit9: ; preds = %688, %684, %679, %.loopexit, %_ZN6kotlin14initObjectPoolEv.exit
-  %701 = load i64, i64* bitcast (%"struct.(anonymous namespace)::RuntimeState"** @_ZN12_GLOBAL__N_112runtimeStateE to i64*), align 8, !tbaa !3
-  %702 = invoke i32 @pthread_once(i32* nonnull @_ZN5konan25terminationKeyOnceControlE, void ()* nonnull @_ZN5konanL16onThreadExitInitEv)
-          to label %_ZN5konan12onThreadExitEPFvPvES0_.exit unwind label %714
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit9: ; preds = %695, %691, %686, %.loopexit, %_ZN6kotlin14initObjectPoolEv.exit
+  %708 = load atomic i64, i64* bitcast (%"struct.(anonymous namespace)::RuntimeState"** @_ZN12_GLOBAL__N_112runtimeStateE to i64*) unordered, align 8, !tbaa !3
+  %709 = invoke i32 @pthread_once(i32* nonnull @_ZN5konan25terminationKeyOnceControlE, void ()* nonnull @_ZN5konanL16onThreadExitInitEv)
+          to label %_ZN5konan12onThreadExitEPFvPvES0_.exit unwind label %721
 
 _ZN5konan12onThreadExitEPFvPvES0_.exit:           ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit9
-  %703 = call noalias dereferenceable_or_null(24) i8* @calloc(i64 1, i64 24) #37
-  %704 = getelementptr inbounds i8, i8* %703, i64 8
-  %705 = bitcast i8* %704 to void (i8*)**
-  store void (i8*)* @_ZN12_GLOBAL__N_128Kotlin_deinitRuntimeCallbackEPv, void (i8*)** %705, align 8, !tbaa !734
-  %706 = getelementptr inbounds i8, i8* %703, i64 16
-  %707 = bitcast i8* %706 to i64*
-  store i64 %701, i64* %707, align 8, !tbaa !736
-  %708 = load i32, i32* @_ZN5konan14terminationKeyE, align 4, !tbaa !73
-  %709 = call i8* @pthread_getspecific(i32 %708) #37
-  %710 = bitcast i8* %703 to i8**
-  store i8* %709, i8** %710, align 8, !tbaa !737
-  %711 = load i32, i32* @_ZN5konan14terminationKeyE, align 4, !tbaa !73
-  %712 = call i32 @pthread_setspecific(i32 %711, i8* %703) #37
-  br label %713
+  %710 = call noalias dereferenceable_or_null(24) i8* @calloc(i64 1, i64 24) #37
+  %711 = getelementptr inbounds i8, i8* %710, i64 8
+  %712 = bitcast i8* %711 to void (i8*)**
+  store void (i8*)* @_ZN12_GLOBAL__N_128Kotlin_deinitRuntimeCallbackEPv, void (i8*)** %712, align 8, !tbaa !746
+  %713 = getelementptr inbounds i8, i8* %710, i64 16
+  %714 = bitcast i8* %713 to i64*
+  store i64 %708, i64* %714, align 8, !tbaa !748
+  %715 = load atomic i32, i32* @_ZN5konan14terminationKeyE unordered, align 4, !tbaa !71
+  %716 = call i8* @pthread_getspecific(i32 %715) #37
+  %717 = bitcast i8* %710 to i8**
+  store i8* %716, i8** %717, align 8, !tbaa !749
+  %718 = load atomic i32, i32* @_ZN5konan14terminationKeyE unordered, align 4, !tbaa !71
+  %719 = call i32 @pthread_setspecific(i32 %718, i8* %710) #37
+  br label %720
 
-713:                                              ; preds = %_ZN5konan12onThreadExitEPFvPvES0_.exit, %0
+720:                                              ; preds = %_ZN5konan12onThreadExitEPFvPvES0_.exit, %0
   ret void
 
-714:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit9
-  %715 = landingpad { i8*, i32 }
+721:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit9
+  %722 = landingpad { i8*, i32 }
           catch i8* null
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit10
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit10: ; preds = %714, %700, %696, %691, %.body
-  %716 = phi { i8*, i32 } [ %715, %714 ], [ %689, %.body ], [ %689, %691 ], [ %689, %696 ], [ %689, %700 ]
-  %717 = extractvalue { i8*, i32 } %716, 0
-  tail call fastcc void @__clang_call_terminate(i8* %717) #51
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit10: ; preds = %721, %707, %703, %698, %.body
+  %723 = phi { i8*, i32 } [ %722, %721 ], [ %696, %.body ], [ %696, %698 ], [ %696, %703 ], [ %696, %707 ]
+  %724 = extractvalue { i8*, i32 } %723, 0
+  tail call fastcc void @__clang_call_terminate(i8* %724) #51
   unreachable
 }
 
 ; Function Attrs: nounwind uwtable
 define internal void @_ZN12_GLOBAL__N_128Kotlin_deinitRuntimeCallbackEPv(i8* %0) #17 personality i32 (...)* @__gxx_personality_v0 {
   %2 = bitcast i8* %0 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**
-  %3 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %2, align 8, !tbaa !699
+  %3 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %2 unordered, align 8, !tbaa !711
   %4 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %3, i64 328
   %5 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %4 to %"class.kotlin::mm::ThreadSuspensionData.37"*
   %6 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %4 to i32*
@@ -52758,37 +53583,37 @@
 _ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %13, %9, %1
   %14 = getelementptr inbounds i8, i8* %0, i64 16
   %15 = bitcast i8* %14 to i32*
-  store i32 2, i32* %15, align 8, !tbaa !733
+  store i32 2, i32* %15, align 8, !tbaa !745
   store i8* %0, i8** bitcast (%"struct.(anonymous namespace)::RuntimeState"** @_ZN12_GLOBAL__N_112runtimeStateE to i8**), align 8, !tbaa !3
   %16 = atomicrmw add i32* @_ZN12_GLOBAL__N_118aliveRuntimesCountE, i32 -1 seq_cst, align 4
-  %17 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %2, align 8, !tbaa !699
+  %17 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %2 unordered, align 8, !tbaa !711
   %18 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %17, i64 72
   %19 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %18 to %struct.ObjHeader***
-  %20 = load %struct.ObjHeader**, %struct.ObjHeader*** %19, align 8, !tbaa !219
+  %20 = load atomic %struct.ObjHeader**, %struct.ObjHeader*** %19 unordered, align 8, !tbaa !218
   %21 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %17, i64 80
   %22 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %21 to %struct.ObjHeader***
-  %23 = load %struct.ObjHeader**, %struct.ObjHeader*** %22, align 8, !tbaa !722
+  %23 = load atomic %struct.ObjHeader**, %struct.ObjHeader*** %22 unordered, align 8, !tbaa !734
   %24 = icmp eq %struct.ObjHeader** %23, %20
   br i1 %24, label %ClearTLS.exit.i, label %25
 
 25:                                               ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
-  store %struct.ObjHeader** %20, %struct.ObjHeader*** %22, align 8, !tbaa !722
+  store %struct.ObjHeader** %20, %struct.ObjHeader*** %22, align 8, !tbaa !734
   br label %ClearTLS.exit.i
 
 ClearTLS.exit.i:                                  ; preds = %25, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
   %26 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %17, i64 152
   %27 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %26 to i32*
-  store i32 2, i32* %27, align 8, !tbaa !732
+  store i32 2, i32* %27, align 8, !tbaa !744
   %28 = getelementptr inbounds i8, i8* %0, i64 8
   %29 = bitcast i8* %28 to %class.Worker**
-  %30 = load %class.Worker*, %class.Worker** %29, align 8, !tbaa !719
+  %30 = load atomic %class.Worker*, %class.Worker** %29 unordered, align 8, !tbaa !731
   %31 = getelementptr inbounds %class.Worker, %class.Worker* %30, i64 0, i32 0
-  %32 = load i32, i32* %31, align 8, !tbaa !701
+  %32 = load atomic i32, i32* %31 unordered, align 8, !tbaa !713
   store %class.Worker* null, %class.Worker** @_ZN12_GLOBAL__N_18g_workerE, align 8, !tbaa !3
   %33 = tail call fastcc %"class.(anonymous namespace)::State"* @_ZN12_GLOBAL__N_18theStateEv() #37
   %34 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %33, i64 0, i32 0
   %35 = getelementptr inbounds %class.Worker, %class.Worker* %30, i64 0, i32 10
-  %36 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35, align 8, !tbaa !718
+  %36 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35 unordered, align 8, !tbaa !730
   %37 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %36, i64 328
   %38 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %37 to i32*
   %39 = atomicrmw xchg i32* %38, i32 1 seq_cst, align 4
@@ -52815,24 +53640,24 @@
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i
 
 _ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i: ; preds = %52, %48, %42, %ClearTLS.exit.i
-  %53 = load i32, i32* %31, align 8, !tbaa !701
+  %53 = load atomic i32, i32* %31 unordered, align 8, !tbaa !713
   %54 = sext i32 %53 to i64
   %55 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %33, i64 0, i32 3, i32 0, i32 1
-  %56 = load i64, i64* %55, align 8, !tbaa !635
+  %56 = load atomic i64, i64* %55 unordered, align 8, !tbaa !647
   %57 = urem i64 %54, %56
   %58 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %33, i64 0, i32 3, i32 0, i32 0
-  %59 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %58, align 8, !tbaa !637
+  %59 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %58 unordered, align 8, !tbaa !649
   %60 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %59, i64 %57
-  %61 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %60, align 8, !tbaa !3
+  %61 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %60 unordered, align 8, !tbaa !3
   %62 = icmp eq %"struct.std::__detail::_Hash_node_base"* %61, null
   br i1 %62, label %.loopexit4, label %63
 
 63:                                               ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i
   %64 = bitcast %"struct.std::__detail::_Hash_node_base"* %61 to %"struct.std::__detail::_Hash_node.203"**
-  %65 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %64, align 8, !tbaa !216
+  %65 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %64 unordered, align 8, !tbaa !215
   %66 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %65, i64 0, i32 0, i32 1
   %67 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %66 to i32*
-  %68 = load i32, i32* %67, align 4, !tbaa !73
+  %68 = load atomic i32, i32* %67 unordered, align 4, !tbaa !71
   %69 = icmp eq i32 %53, %68
   br i1 %69, label %86, label %.preheader3
 
@@ -52843,7 +53668,7 @@
 .preheader3:                                      ; preds = %70, %63
   %72 = phi %"struct.std::__detail::_Hash_node.203"* [ %76, %70 ], [ %65, %63 ]
   %73 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %72, i64 0, i32 0, i32 0, i32 0
-  %74 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %73, align 8, !tbaa !216
+  %74 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %73 unordered, align 8, !tbaa !215
   %75 = icmp eq %"struct.std::__detail::_Hash_node_base"* %74, null
   %76 = bitcast %"struct.std::__detail::_Hash_node_base"* %74 to %"struct.std::__detail::_Hash_node.203"*
   br i1 %75, label %.loopexit4, label %77
@@ -52851,7 +53676,7 @@
 77:                                               ; preds = %.preheader3
   %78 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %74, i64 1
   %79 = bitcast %"struct.std::__detail::_Hash_node_base"* %78 to i32*
-  %80 = load i32, i32* %79, align 4, !tbaa !73
+  %80 = load atomic i32, i32* %79 unordered, align 4, !tbaa !71
   %81 = sext i32 %80 to i64
   %82 = urem i64 %81, %56
   %83 = icmp eq i64 %82, %57
@@ -52873,7 +53698,7 @@
 91:                                               ; preds = %91, %88
   %92 = phi %"struct.std::__detail::_Hash_node_base"* [ %61, %88 ], [ %94, %91 ]
   %93 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %92, i64 0, i32 0
-  %94 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %93, align 8, !tbaa !216
+  %94 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %93 unordered, align 8, !tbaa !215
   %95 = icmp eq %"struct.std::__detail::_Hash_node_base"* %94, %90
   br i1 %95, label %96, label %91
 
@@ -52884,14 +53709,14 @@
 
 99:                                               ; preds = %96
   %100 = bitcast %"struct.std::__detail::_Hash_node.203"* %89 to %"struct.std::__detail::_Hash_node.203"**
-  %101 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %100, align 8, !tbaa !216
+  %101 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %100 unordered, align 8, !tbaa !215
   %102 = icmp eq %"struct.std::__detail::_Hash_node.203"* %101, null
   br i1 %102, label %116, label %103
 
 103:                                              ; preds = %99
   %104 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %101, i64 0, i32 0, i32 1
   %105 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %104 to i32*
-  %106 = load i32, i32* %105, align 4, !tbaa !73
+  %106 = load atomic i32, i32* %105 unordered, align 4, !tbaa !71
   %107 = sext i32 %106 to i64
   %108 = urem i64 %107, %56
   %109 = icmp eq i64 %108, %57
@@ -52901,9 +53726,9 @@
   %111 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %59, i64 %108
   %112 = bitcast %"struct.std::__detail::_Hash_node_base"** %111 to i64*
   store i64 %98, i64* %112, align 8, !tbaa !3
-  %113 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %58, align 8, !tbaa !637
+  %113 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %58 unordered, align 8, !tbaa !649
   %114 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %113, i64 %57
-  %115 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %114, align 8, !tbaa !3
+  %115 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %114 unordered, align 8, !tbaa !3
   br label %116
 
 116:                                              ; preds = %110, %99
@@ -52917,7 +53742,7 @@
 122:                                              ; preds = %116
   %123 = getelementptr %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %101, i64 0, i32 0, i32 0
   %124 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %117, i64 0, i32 0
-  store %"struct.std::__detail::_Hash_node_base"* %123, %"struct.std::__detail::_Hash_node_base"** %124, align 8, !tbaa !672
+  store %"struct.std::__detail::_Hash_node_base"* %123, %"struct.std::__detail::_Hash_node_base"** %124, align 8, !tbaa !684
   br label %125
 
 125:                                              ; preds = %122, %116
@@ -52926,14 +53751,14 @@
 
 126:                                              ; preds = %96
   %127 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %89, i64 0, i32 0, i32 0, i32 0
-  %128 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %127, align 8, !tbaa !216
+  %128 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %127 unordered, align 8, !tbaa !215
   %129 = icmp eq %"struct.std::__detail::_Hash_node_base"* %128, null
   br i1 %129, label %139, label %130
 
 130:                                              ; preds = %126
   %131 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %128, i64 1
   %132 = bitcast %"struct.std::__detail::_Hash_node_base"* %131 to i32*
-  %133 = load i32, i32* %132, align 4, !tbaa !73
+  %133 = load atomic i32, i32* %132 unordered, align 4, !tbaa !71
   %134 = sext i32 %133 to i64
   %135 = urem i64 %134, %56
   %136 = icmp eq i64 %135, %57
@@ -52946,15 +53771,15 @@
 
 139:                                              ; preds = %137, %130, %126, %125, %103
   %140 = bitcast %"struct.std::__detail::_Hash_node.203"* %89 to i64*
-  %141 = load i64, i64* %140, align 8, !tbaa !216
+  %141 = load atomic i64, i64* %140 unordered, align 8, !tbaa !215
   %142 = bitcast %"struct.std::__detail::_Hash_node_base"* %92 to i64*
-  store i64 %141, i64* %142, align 8, !tbaa !216
+  store i64 %141, i64* %142, align 8, !tbaa !215
   %143 = bitcast %"struct.std::__detail::_Hash_node.203"* %89 to i8*
   tail call void @free(i8* %143) #37
   %144 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %33, i64 0, i32 3, i32 0, i32 3
-  %145 = load i64, i64* %144, align 8, !tbaa !715
+  %145 = load atomic i64, i64* %144 unordered, align 8, !tbaa !727
   %146 = add i64 %145, -1
-  store i64 %146, i64* %144, align 8, !tbaa !715
+  store i64 %146, i64* %144, align 8, !tbaa !727
   br label %.loopexit4
 
 .loopexit4:                                       ; preds = %139, %86, %84, %77, %.preheader3, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i
@@ -52966,7 +53791,7 @@
   br label %157
 
 150:                                              ; preds = %.loopexit4
-  %151 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
+  %151 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
   %152 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %151, i64 328
   %153 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %152 to i32*
   %154 = atomicrmw xchg i32* %153, i32 1 seq_cst, align 4
@@ -53000,27 +53825,27 @@
   %171 = bitcast %class.Worker* %30 to i8*
   %172 = getelementptr inbounds %class.Worker, %class.Worker* %30, i64 0, i32 2
   %173 = getelementptr inbounds %class.Worker, %class.Worker* %30, i64 0, i32 2, i32 0, i32 0, i32 2, i32 0
-  %174 = load %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %173, align 8, !tbaa !738, !noalias !739
+  %174 = load atomic %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %173 unordered, align 8, !tbaa !750, !noalias !751
   %175 = getelementptr inbounds %class.Worker, %class.Worker* %30, i64 0, i32 2, i32 0, i32 0, i32 2, i32 3
   %176 = getelementptr inbounds %class.Worker, %class.Worker* %30, i64 0, i32 2, i32 0, i32 0, i32 3, i32 0
-  %177 = load %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %176, align 8, !tbaa !738, !noalias !742
+  %177 = load atomic %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %176 unordered, align 8, !tbaa !750, !noalias !754
   %178 = getelementptr inbounds %class.Worker, %class.Worker* %30, i64 0, i32 2, i32 0, i32 0, i32 3, i32 3
   %179 = icmp eq %"struct.(anonymous namespace)::Job"* %177, %174
   br i1 %179, label %.loopexit2, label %180
 
 180:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit12.i.i
   %181 = bitcast %"struct.(anonymous namespace)::Job"*** %175 to i64*
-  %182 = load i64, i64* %181, align 8, !tbaa !650, !noalias !739
+  %182 = load atomic i64, i64* %181 unordered, align 8, !tbaa !662, !noalias !751
   %183 = getelementptr inbounds %class.Worker, %class.Worker* %30, i64 0, i32 2, i32 0, i32 0, i32 2, i32 2
   %184 = bitcast %"struct.(anonymous namespace)::Job"** %183 to i64*
-  %185 = load i64, i64* %184, align 8, !tbaa !652, !noalias !739
+  %185 = load atomic i64, i64* %184 unordered, align 8, !tbaa !664, !noalias !751
   br label %193
 
 .loopexit2:                                       ; preds = %234, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit12.i.i
   %186 = getelementptr inbounds %class.Worker, %class.Worker* %30, i64 0, i32 3, i32 0, i32 0, i32 0, i32 0, i32 0
   %187 = getelementptr inbounds i8, i8* %186, i64 24
   %188 = bitcast i8* %187 to %"struct.std::_Rb_tree_node_base"**
-  %189 = load %"struct.std::_Rb_tree_node_base"*, %"struct.std::_Rb_tree_node_base"** %188, align 8, !tbaa !709
+  %189 = load atomic %"struct.std::_Rb_tree_node_base"*, %"struct.std::_Rb_tree_node_base"** %188 unordered, align 8, !tbaa !721
   %190 = getelementptr inbounds i8, i8* %186, i64 8
   %191 = bitcast i8* %190 to %"struct.std::_Rb_tree_node_base"*
   %192 = icmp eq %"struct.std::_Rb_tree_node_base"* %189, %191
@@ -53031,9 +53856,9 @@
   %195 = phi i64 [ %185, %180 ], [ %236, %234 ]
   %196 = phi %"struct.(anonymous namespace)::Job"* [ %174, %180 ], [ %235, %234 ]
   %197 = getelementptr inbounds %"struct.(anonymous namespace)::Job", %"struct.(anonymous namespace)::Job"* %196, i64 0, i32 0
-  %198 = load i32, i32* %197, align 8, !tbaa.struct !645
+  %198 = load atomic i32, i32* %197 unordered, align 8, !tbaa.struct !657
   %199 = getelementptr inbounds %"struct.(anonymous namespace)::Job", %"struct.(anonymous namespace)::Job"* %196, i64 0, i32 1, i32 0, i32 0
-  %200 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %199, align 8, !tbaa.struct !645
+  %200 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)** %199 unordered, align 8, !tbaa.struct !657
   switch i32 %198, label %DisposeStablePointerFor.exit11.i.i.i [
     i32 2, label %201
     i32 3, label %213
@@ -53043,14 +53868,14 @@
 
 201:                                              ; preds = %193
   %202 = getelementptr inbounds %"struct.(anonymous namespace)::Job", %"struct.(anonymous namespace)::Job"* %196, i64 0, i32 1, i32 0, i32 2
-  %203 = load %"class.(anonymous namespace)::Future"*, %"class.(anonymous namespace)::Future"** %202, align 8, !tbaa.struct !645
+  %203 = load atomic %"class.(anonymous namespace)::Future"*, %"class.(anonymous namespace)::Future"** %202 unordered, align 8, !tbaa.struct !657
   %204 = getelementptr inbounds %"struct.(anonymous namespace)::Job", %"struct.(anonymous namespace)::Job"* %196, i64 0, i32 1, i32 0, i32 1
-  %205 = load i8*, i8** %204, align 8, !tbaa.struct !645
+  %205 = load atomic i8*, i8** %204 unordered, align 8, !tbaa.struct !657
   %206 = icmp eq i8* %205, null
   br i1 %206, label %DisposeStablePointerFor.exit.i.i.i, label %207
 
 207:                                              ; preds = %201
-  %208 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35, align 8, !tbaa !718
+  %208 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35 unordered, align 8, !tbaa !730
   %209 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %208, i64 8
   %210 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %209 to %"class.kotlin::mm::ThreadData.38"*
   %211 = bitcast i8* %205 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*
@@ -53058,7 +53883,7 @@
   br label %DisposeStablePointerFor.exit.i.i.i
 
 DisposeStablePointerFor.exit.i.i.i:               ; preds = %207, %201
-  %212 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35, align 8, !tbaa !718
+  %212 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35 unordered, align 8, !tbaa !730
   tail call fastcc void @_ZN12_GLOBAL__N_16Future14cancelUnlockedEP11MemoryState(%"class.(anonymous namespace)::Future"* %203, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %212) #37
   br label %DisposeStablePointerFor.exit11.i.i.i
 
@@ -53067,7 +53892,7 @@
   br i1 %214, label %DisposeStablePointerFor.exit11.i.i.i, label %215
 
 215:                                              ; preds = %213
-  %216 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35, align 8, !tbaa !718
+  %216 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35 unordered, align 8, !tbaa !730
   %217 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %216, i64 8
   %218 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %217 to %"class.kotlin::mm::ThreadData.38"*
   %219 = bitcast %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)* %200 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*
@@ -53076,7 +53901,7 @@
 
 220:                                              ; preds = %193
   %221 = bitcast %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader**)* %200 to %"class.(anonymous namespace)::Future"*
-  %222 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35, align 8, !tbaa !718
+  %222 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35 unordered, align 8, !tbaa !730
   tail call fastcc void @_ZN12_GLOBAL__N_16Future14cancelUnlockedEP11MemoryState(%"class.(anonymous namespace)::Future"* %221, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %222) #37
   br label %DisposeStablePointerFor.exit11.i.i.i
 
@@ -53094,7 +53919,7 @@
   %228 = inttoptr i64 %194 to %"struct.(anonymous namespace)::Job"**
   %229 = getelementptr inbounds %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %228, i64 1
   %230 = ptrtoint %"struct.(anonymous namespace)::Job"** %229 to i64
-  %231 = load %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %229, align 8, !tbaa !3
+  %231 = load atomic %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %229 unordered, align 8, !tbaa !3
   %232 = getelementptr inbounds %"struct.(anonymous namespace)::Job", %"struct.(anonymous namespace)::Job"* %231, i64 12
   %233 = ptrtoint %"struct.(anonymous namespace)::Job"* %232 to i64
   br label %234
@@ -53108,7 +53933,7 @@
 
 .loopexit:                                        ; preds = %DisposeStablePointerFor.exit12.i.i.i, %.loopexit2
   %239 = getelementptr inbounds %class.Worker, %class.Worker* %30, i64 0, i32 4
-  %240 = load i8*, i8** %239, align 8, !tbaa !745
+  %240 = load atomic i8*, i8** %239 unordered, align 8, !tbaa !757
   %241 = icmp eq i8* %240, null
   br i1 %241, label %259, label %DisposeStablePointerFor.exit13.i.i.i
 
@@ -53116,12 +53941,12 @@
   %243 = phi %"struct.std::_Rb_tree_node_base"* [ %253, %DisposeStablePointerFor.exit12.i.i.i ], [ %189, %.loopexit2 ]
   %244 = getelementptr inbounds %"struct.std::_Rb_tree_node_base", %"struct.std::_Rb_tree_node_base"* %243, i64 1, i32 1
   %245 = bitcast %"struct.std::_Rb_tree_node_base"** %244 to i8**
-  %246 = load i8*, i8** %245, align 8, !tbaa.struct !645
+  %246 = load atomic i8*, i8** %245 unordered, align 8, !tbaa.struct !657
   %247 = icmp eq i8* %246, null
   br i1 %247, label %DisposeStablePointerFor.exit12.i.i.i, label %248
 
 248:                                              ; preds = %242
-  %249 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35, align 8, !tbaa !718
+  %249 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35 unordered, align 8, !tbaa !730
   %250 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %249, i64 8
   %251 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %250 to %"class.kotlin::mm::ThreadData.38"*
   %252 = bitcast i8* %246 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*
@@ -53134,7 +53959,7 @@
   br i1 %254, label %.loopexit, label %242
 
 DisposeStablePointerFor.exit13.i.i.i:             ; preds = %.loopexit
-  %255 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35, align 8, !tbaa !718
+  %255 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35 unordered, align 8, !tbaa !730
   %256 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %255, i64 8
   %257 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %256 to %"class.kotlin::mm::ThreadData.38"*
   %258 = bitcast i8* %240 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*
@@ -53142,7 +53967,7 @@
   br label %259
 
 259:                                              ; preds = %DisposeStablePointerFor.exit13.i.i.i, %.loopexit
-  %260 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35, align 8, !tbaa !718
+  %260 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %35 unordered, align 8, !tbaa !730
   %261 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %260, i64 328
   %262 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %261 to i32*
   %263 = atomicrmw xchg i32* %262, i32 1 seq_cst, align 4
@@ -53174,17 +53999,17 @@
 _ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i.i: ; preds = %279, %275, %269, %259
   %280 = getelementptr inbounds i8, i8* %186, i64 16
   %281 = bitcast i8* %280 to %"struct.std::_Rb_tree_node"**
-  %282 = load %"struct.std::_Rb_tree_node"*, %"struct.std::_Rb_tree_node"** %281, align 8, !tbaa !746
+  %282 = load atomic %"struct.std::_Rb_tree_node"*, %"struct.std::_Rb_tree_node"** %281 unordered, align 8, !tbaa !758
   tail call fastcc void @_ZNSt8_Rb_treeIN12_GLOBAL__N_13JobES1_St9_IdentityIS1_ENS0_10JobCompareEN6kotlin11std_support9allocatorIS1_EEE8_M_eraseEPSt13_Rb_tree_nodeIS1_E(%"struct.std::_Rb_tree_node"* %282) #37
   %283 = getelementptr inbounds %"class.std::deque", %"class.std::deque"* %172, i64 0, i32 0, i32 0, i32 0
-  %284 = load %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %283, align 8, !tbaa !648
+  %284 = load atomic %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %283 unordered, align 8, !tbaa !660
   %285 = icmp eq %"struct.(anonymous namespace)::Job"** %284, null
   br i1 %285, label %_Z12WorkerDeinitP6Worker.exit.i, label %286
 
 286:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i.i
   %287 = bitcast %"struct.(anonymous namespace)::Job"** %284 to i8*
-  %288 = load %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %175, align 8, !tbaa !649
-  %289 = load %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %178, align 8, !tbaa !647
+  %288 = load atomic %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %175 unordered, align 8, !tbaa !661
+  %289 = load atomic %"struct.(anonymous namespace)::Job"**, %"struct.(anonymous namespace)::Job"*** %178 unordered, align 8, !tbaa !659
   %290 = getelementptr inbounds %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %289, i64 1
   %291 = icmp ult %"struct.(anonymous namespace)::Job"** %288, %290
   br i1 %291, label %.preheader1, label %300
@@ -53192,7 +54017,7 @@
 .preheader1:                                      ; preds = %.preheader1, %286
   %292 = phi %"struct.(anonymous namespace)::Job"** [ %295, %.preheader1 ], [ %288, %286 ]
   %293 = bitcast %"struct.(anonymous namespace)::Job"** %292 to i8**
-  %294 = load i8*, i8** %293, align 8, !tbaa !3
+  %294 = load atomic i8*, i8** %293 unordered, align 8, !tbaa !3
   tail call void @free(i8* %294) #37
   %295 = getelementptr inbounds %"struct.(anonymous namespace)::Job"*, %"struct.(anonymous namespace)::Job"** %292, i64 1
   %296 = icmp ult %"struct.(anonymous namespace)::Job"** %292, %289
@@ -53200,7 +54025,7 @@
 
 297:                                              ; preds = %.preheader1
   %298 = bitcast %"class.std::deque"* %172 to i8**
-  %299 = load i8*, i8** %298, align 8, !tbaa !648
+  %299 = load atomic i8*, i8** %298 unordered, align 8, !tbaa !660
   br label %300
 
 300:                                              ; preds = %297, %286
@@ -53210,13 +54035,13 @@
 
 _Z12WorkerDeinitP6Worker.exit.i:                  ; preds = %300, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit.i.i.i
   tail call void @free(i8* %171) #37
-  %302 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %2, align 8, !tbaa !699
+  %302 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %2 unordered, align 8, !tbaa !711
   %303 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %302, i64 328
   %304 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %303 to i32*
   %305 = atomicrmw xchg i32* %304, i32 1 seq_cst, align 4
   %306 = bitcast i8* %0 to %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"**
-  %307 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %306, align 8, !tbaa !699
-  %308 = load i32, i32* @_ZN5konan14terminationKeyE, align 4, !tbaa !73
+  %307 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %306 unordered, align 8, !tbaa !711
+  %308 = load atomic i32, i32* @_ZN5konan14terminationKeyE unordered, align 4, !tbaa !71
   %309 = icmp eq i32 %308, 0
   br i1 %309, label %_ZN5konan36isOnThreadExitNotSetOrAlreadyStartedEv.exit.i.i.thread, label %_ZN5konan36isOnThreadExitNotSetOrAlreadyStartedEv.exit.i.i
 
@@ -53245,17 +54070,17 @@
   unreachable
 
 318:                                              ; preds = %313, %312
-  %319 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !3
+  %319 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) unordered, align 8, !tbaa !3
   %320 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %319, null
-  %321 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 2), align 8, !tbaa !696
+  %321 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 2) unordered, align 8, !tbaa !708
   %322 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %321, %307
   br i1 %322, label %323, label %330
 
 323:                                              ; preds = %318
   %324 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %307, i64 0, i32 3
   %325 = bitcast %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %324 to i64*
-  %326 = load i64, i64* %325, align 8, !tbaa !691
-  store i64 %326, i64* bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 2) to i64*), align 8, !tbaa !696
+  %326 = load atomic i64, i64* %325 unordered, align 8, !tbaa !703
+  store i64 %326, i64* bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 2) to i64*), align 8, !tbaa !708
   br label %330
 
 327:                                              ; preds = %316
@@ -53267,266 +54092,277 @@
 
 330:                                              ; preds = %323, %318
   %331 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %319, %307
-  br i1 %331, label %332, label %348
+  br i1 %331, label %332, label %353
 
 332:                                              ; preds = %330
   %333 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %307, i64 0, i32 2
   %334 = getelementptr inbounds %"class.std::unique_ptr.59", %"class.std::unique_ptr.59"* %333, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
   %335 = bitcast %"class.std::unique_ptr.59"* %333 to i64*
-  %336 = load i64, i64* %335, align 8, !tbaa !3
+  %336 = load atomic i64, i64* %335 unordered, align 8, !tbaa !3
   store %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* null, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %334, align 8, !tbaa !3
   store i64 %336, i64* bitcast (%"class.std::unique_ptr.59"* getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1) to i64*), align 8, !tbaa !3
   %337 = inttoptr i64 %336 to %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*
-  br i1 %320, label %343, label %338
+  br i1 %320, label %348, label %338
 
 338:                                              ; preds = %332
   %339 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %307, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
+  %340 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %339 unordered, align 8, !tbaa !3
+  %341 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %340, null
+  br i1 %341, label %344, label %342
+
+342:                                              ; preds = %338
+  tail call fastcc void @_ZNSt16allocator_traitsIN6kotlin11std_support9allocatorINS0_14SingleLockListINS0_2mm10ThreadDataESt15recursive_mutexNS2_IS5_EEE4NodeEEEE10_S_destroyISA_S9_EEvRT_PT0_z(%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* nonnull %340) #37
+  %343 = getelementptr %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %340, i64 0, i32 0, i64 0
+  tail call void @free(i8* %343) #37
+  br label %344
+
+344:                                              ; preds = %342, %338
   store %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* null, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %339, align 8, !tbaa !3
-  %340 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %307, i64 0, i32 1
-  tail call fastcc void @_ZN6kotlin2mm10ThreadDataD2Ev(%"class.kotlin::mm::ThreadData.38"* nonnull %340) #37
-  %341 = getelementptr %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %307, i64 0, i32 0, i64 0
-  tail call void @free(i8* %341) #37
-  %342 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0), align 8, !tbaa !3
-  br label %343
+  %345 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %307, i64 0, i32 1
+  tail call fastcc void @_ZN6kotlin2mm10ThreadDataD2Ev(%"class.kotlin::mm::ThreadData.38"* nonnull %345) #37
+  %346 = getelementptr %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %307, i64 0, i32 0, i64 0
+  tail call void @free(i8* %346) #37
+  %347 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 1, i32 0, i32 0, i32 0, i32 0, i32 0) unordered, align 8, !tbaa !3
+  br label %348
 
-343:                                              ; preds = %338, %332
-  %344 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %337, %332 ], [ %342, %338 ]
-  %345 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %344, null
-  br i1 %345, label %.thread, label %346
+348:                                              ; preds = %344, %332
+  %349 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %337, %332 ], [ %347, %344 ]
+  %350 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %349, null
+  br i1 %350, label %.thread, label %351
 
-346:                                              ; preds = %343
-  %347 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %344, i64 0, i32 3
-  store %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* null, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %347, align 8, !tbaa !691
+351:                                              ; preds = %348
+  %352 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %349, i64 0, i32 3
+  store %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* null, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %352, align 8, !tbaa !703
   br label %.thread
 
-348:                                              ; preds = %330
-  %349 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %307, i64 0, i32 3
-  %350 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %349, align 8, !tbaa !691
-  %351 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %350, i64 0, i32 2
-  %352 = getelementptr %"class.std::unique_ptr.59", %"class.std::unique_ptr.59"* %351, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %353 = bitcast %"class.std::unique_ptr.59"* %351 to i64*
-  %354 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %352, align 8, !tbaa !3
-  store %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* null, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %352, align 8, !tbaa !3
-  %355 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %307, i64 0, i32 2
-  %356 = getelementptr inbounds %"class.std::unique_ptr.59", %"class.std::unique_ptr.59"* %355, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
-  %357 = bitcast %"class.std::unique_ptr.59"* %355 to i64*
-  %358 = load i64, i64* %357, align 8, !tbaa !3
-  store %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* null, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %356, align 8, !tbaa !3
-  %359 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %352, align 8, !tbaa !3
-  store i64 %358, i64* %353, align 8, !tbaa !3
-  %360 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %359, null
-  %361 = inttoptr i64 %358 to %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*
-  br i1 %360, label %372, label %362
-
-362:                                              ; preds = %348
-  %363 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %359, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
-  %364 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %363, align 8, !tbaa !3
+353:                                              ; preds = %330
+  %354 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %307, i64 0, i32 3
+  %355 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %354 unordered, align 8, !tbaa !703
+  %356 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %355, i64 0, i32 2
+  %357 = getelementptr %"class.std::unique_ptr.59", %"class.std::unique_ptr.59"* %356, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %358 = bitcast %"class.std::unique_ptr.59"* %356 to i64*
+  %359 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %357 unordered, align 8, !tbaa !3
+  store %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* null, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %357, align 8, !tbaa !3
+  %360 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %307, i64 0, i32 2
+  %361 = getelementptr inbounds %"class.std::unique_ptr.59", %"class.std::unique_ptr.59"* %360, i64 0, i32 0, i32 0, i32 0, i32 0, i32 0
+  %362 = bitcast %"class.std::unique_ptr.59"* %360 to i64*
+  %363 = load atomic i64, i64* %362 unordered, align 8, !tbaa !3
+  store %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* null, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %361, align 8, !tbaa !3
+  %364 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %357 unordered, align 8, !tbaa !3
+  store i64 %363, i64* %358, align 8, !tbaa !3
   %365 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %364, null
-  br i1 %365, label %368, label %366
-
-366:                                              ; preds = %362
-  tail call fastcc void @_ZNSt16allocator_traitsIN6kotlin11std_support9allocatorINS0_14SingleLockListINS0_2mm10ThreadDataESt15recursive_mutexNS2_IS5_EEE4NodeEEEE10_S_destroyISA_S9_EEvRT_PT0_z(%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* nonnull %364) #37
-  %367 = getelementptr %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %364, i64 0, i32 0, i64 0
-  tail call void @free(i8* %367) #37
-  br label %368
+  %366 = inttoptr i64 %363 to %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*
+  br i1 %365, label %377, label %367
 
-368:                                              ; preds = %366, %362
-  store %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* null, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %363, align 8, !tbaa !3
-  %369 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %359, i64 0, i32 1
-  tail call fastcc void @_ZN6kotlin2mm10ThreadDataD2Ev(%"class.kotlin::mm::ThreadData.38"* nonnull %369) #37
-  %370 = getelementptr %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %359, i64 0, i32 0, i64 0
-  tail call void @free(i8* %370) #37
-  %371 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %352, align 8, !tbaa !3
-  br label %372
+367:                                              ; preds = %353
+  %368 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %364, i64 0, i32 2, i32 0, i32 0, i32 0, i32 0, i32 0
+  %369 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %368 unordered, align 8, !tbaa !3
+  %370 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %369, null
+  br i1 %370, label %373, label %371
 
-372:                                              ; preds = %368, %348
-  %373 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %361, %348 ], [ %371, %368 ]
-  %374 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %373, null
-  br i1 %374, label %377, label %375
+371:                                              ; preds = %367
+  tail call fastcc void @_ZNSt16allocator_traitsIN6kotlin11std_support9allocatorINS0_14SingleLockListINS0_2mm10ThreadDataESt15recursive_mutexNS2_IS5_EEE4NodeEEEE10_S_destroyISA_S9_EEvRT_PT0_z(%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* nonnull %369) #37
+  %372 = getelementptr %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %369, i64 0, i32 0, i64 0
+  tail call void @free(i8* %372) #37
+  br label %373
 
-375:                                              ; preds = %372
-  %376 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %373, i64 0, i32 3
-  store %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %350, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %376, align 8, !tbaa !691
+373:                                              ; preds = %371, %367
+  store %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* null, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %368, align 8, !tbaa !3
+  %374 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %364, i64 0, i32 1
+  tail call fastcc void @_ZN6kotlin2mm10ThreadDataD2Ev(%"class.kotlin::mm::ThreadData.38"* nonnull %374) #37
+  %375 = getelementptr %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %364, i64 0, i32 0, i64 0
+  tail call void @free(i8* %375) #37
+  %376 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %357 unordered, align 8, !tbaa !3
   br label %377
 
-377:                                              ; preds = %375, %372
-  %378 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %354, null
-  br i1 %378, label %.thread, label %379
+377:                                              ; preds = %373, %353
+  %378 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %366, %353 ], [ %376, %373 ]
+  %379 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %378, null
+  br i1 %379, label %382, label %380
 
-379:                                              ; preds = %377
-  tail call fastcc void @_ZNSt16allocator_traitsIN6kotlin11std_support9allocatorINS0_14SingleLockListINS0_2mm10ThreadDataESt15recursive_mutexNS2_IS5_EEE4NodeEEEE10_S_destroyISA_S9_EEvRT_PT0_z(%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* nonnull %354) #37
-  %380 = getelementptr %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %354, i64 0, i32 0, i64 0
-  tail call void @free(i8* %380) #37
+380:                                              ; preds = %377
+  %381 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %378, i64 0, i32 3
+  store %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %355, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** %381, align 8, !tbaa !703
+  br label %382
+
+382:                                              ; preds = %380, %377
+  %383 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %359, null
+  br i1 %383, label %.thread, label %384
+
+384:                                              ; preds = %382
+  tail call fastcc void @_ZNSt16allocator_traitsIN6kotlin11std_support9allocatorINS0_14SingleLockListINS0_2mm10ThreadDataESt15recursive_mutexNS2_IS5_EEE4NodeEEEE10_S_destroyISA_S9_EEvRT_PT0_z(%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* nonnull %359) #37
+  %385 = getelementptr %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %359, i64 0, i32 0, i64 0
+  tail call void @free(i8* %385) #37
   br label %.thread
 
-.thread:                                          ; preds = %379, %377, %346, %343
-  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %381, label %DeinitMemory.exit.i
+.thread:                                          ; preds = %384, %382, %351, %348
+  br i1 icmp ne (i8* bitcast (i32 (i32*, void (i8*)*)* @__pthread_key_create to i8*), i8* null), label %386, label %DeinitMemory.exit.i
 
-381:                                              ; preds = %.thread
-  %382 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0)) #37
+386:                                              ; preds = %.thread
+  %387 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull getelementptr inbounds (%"class.kotlin::mm::GlobalData", %"class.kotlin::mm::GlobalData"* @_ZN6kotlin2mm10GlobalData9instance_E, i64 0, i32 1, i32 1, i32 3, i32 0, i32 0)) #37
   br label %DeinitMemory.exit.i
 
-DeinitMemory.exit.i:                              ; preds = %381, %.thread
+DeinitMemory.exit.i:                              ; preds = %386, %.thread
   tail call void @free(i8* %0) #37
-  %383 = tail call fastcc %"class.(anonymous namespace)::State"* @_ZN12_GLOBAL__N_18theStateEv() #37
-  %384 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %383, i64 0, i32 0
-  %385 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %384) #37
-  %386 = sext i32 %32 to i64
-  %387 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %383, i64 0, i32 4, i32 0, i32 1
-  %388 = load i64, i64* %387, align 8, !tbaa !663
-  %389 = urem i64 %386, %388
-  %390 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %383, i64 0, i32 4, i32 0, i32 0
-  %391 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %390, align 8, !tbaa !661
-  %392 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %391, i64 %389
-  %393 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %392, align 8, !tbaa !3
-  %394 = icmp eq %"struct.std::__detail::_Hash_node_base"* %393, null
-  br i1 %394, label %_ZN12_GLOBAL__N_113deinitRuntimeEPNS_12RuntimeStateEb.exit, label %395
+  %388 = tail call fastcc %"class.(anonymous namespace)::State"* @_ZN12_GLOBAL__N_18theStateEv() #37
+  %389 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %388, i64 0, i32 0
+  %390 = tail call i32 @pthread_mutex_lock(%union.pthread_mutex_t* %389) #37
+  %391 = sext i32 %32 to i64
+  %392 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %388, i64 0, i32 4, i32 0, i32 1
+  %393 = load atomic i64, i64* %392 unordered, align 8, !tbaa !675
+  %394 = urem i64 %391, %393
+  %395 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %388, i64 0, i32 4, i32 0, i32 0
+  %396 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %395 unordered, align 8, !tbaa !673
+  %397 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %396, i64 %394
+  %398 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %397 unordered, align 8, !tbaa !3
+  %399 = icmp eq %"struct.std::__detail::_Hash_node_base"* %398, null
+  br i1 %399, label %_ZN12_GLOBAL__N_113deinitRuntimeEPNS_12RuntimeStateEb.exit, label %400
 
-395:                                              ; preds = %DeinitMemory.exit.i
-  %396 = bitcast %"struct.std::__detail::_Hash_node_base"* %393 to %"struct.std::__detail::_Hash_node.203"**
-  %397 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %396, align 8, !tbaa !216
-  %398 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %397, i64 0, i32 0, i32 1
-  %399 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %398 to i32*
-  %400 = load i32, i32* %399, align 4, !tbaa !73
-  %401 = icmp eq i32 %400, %32
-  br i1 %401, label %418, label %.preheader
+400:                                              ; preds = %DeinitMemory.exit.i
+  %401 = bitcast %"struct.std::__detail::_Hash_node_base"* %398 to %"struct.std::__detail::_Hash_node.203"**
+  %402 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %401 unordered, align 8, !tbaa !215
+  %403 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %402, i64 0, i32 0, i32 1
+  %404 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %403 to i32*
+  %405 = load atomic i32, i32* %404 unordered, align 4, !tbaa !71
+  %406 = icmp eq i32 %405, %32
+  br i1 %406, label %423, label %.preheader
 
-402:                                              ; preds = %409
-  %403 = icmp eq i32 %412, %32
-  br i1 %403, label %416, label %.preheader
+407:                                              ; preds = %414
+  %408 = icmp eq i32 %417, %32
+  br i1 %408, label %421, label %.preheader
 
-.preheader:                                       ; preds = %402, %395
-  %404 = phi %"struct.std::__detail::_Hash_node.203"* [ %408, %402 ], [ %397, %395 ]
-  %405 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %404, i64 0, i32 0, i32 0, i32 0
-  %406 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %405, align 8, !tbaa !216
-  %407 = icmp eq %"struct.std::__detail::_Hash_node_base"* %406, null
-  %408 = bitcast %"struct.std::__detail::_Hash_node_base"* %406 to %"struct.std::__detail::_Hash_node.203"*
-  br i1 %407, label %_ZN12_GLOBAL__N_113deinitRuntimeEPNS_12RuntimeStateEb.exit, label %409
+.preheader:                                       ; preds = %407, %400
+  %409 = phi %"struct.std::__detail::_Hash_node.203"* [ %413, %407 ], [ %402, %400 ]
+  %410 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %409, i64 0, i32 0, i32 0, i32 0
+  %411 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %410 unordered, align 8, !tbaa !215
+  %412 = icmp eq %"struct.std::__detail::_Hash_node_base"* %411, null
+  %413 = bitcast %"struct.std::__detail::_Hash_node_base"* %411 to %"struct.std::__detail::_Hash_node.203"*
+  br i1 %412, label %_ZN12_GLOBAL__N_113deinitRuntimeEPNS_12RuntimeStateEb.exit, label %414
 
-409:                                              ; preds = %.preheader
-  %410 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %406, i64 1
-  %411 = bitcast %"struct.std::__detail::_Hash_node_base"* %410 to i32*
-  %412 = load i32, i32* %411, align 4, !tbaa !73
-  %413 = sext i32 %412 to i64
-  %414 = urem i64 %413, %388
-  %415 = icmp eq i64 %414, %389
-  br i1 %415, label %402, label %_ZN12_GLOBAL__N_113deinitRuntimeEPNS_12RuntimeStateEb.exit
+414:                                              ; preds = %.preheader
+  %415 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %411, i64 1
+  %416 = bitcast %"struct.std::__detail::_Hash_node_base"* %415 to i32*
+  %417 = load atomic i32, i32* %416 unordered, align 4, !tbaa !71
+  %418 = sext i32 %417 to i64
+  %419 = urem i64 %418, %393
+  %420 = icmp eq i64 %419, %394
+  br i1 %420, label %407, label %_ZN12_GLOBAL__N_113deinitRuntimeEPNS_12RuntimeStateEb.exit
 
-416:                                              ; preds = %402
-  %417 = icmp eq %"struct.std::__detail::_Hash_node.203"* %404, null
-  br i1 %417, label %_ZN12_GLOBAL__N_113deinitRuntimeEPNS_12RuntimeStateEb.exit, label %._crit_edge
+421:                                              ; preds = %407
+  %422 = icmp eq %"struct.std::__detail::_Hash_node.203"* %409, null
+  br i1 %422, label %_ZN12_GLOBAL__N_113deinitRuntimeEPNS_12RuntimeStateEb.exit, label %._crit_edge
 
-418:                                              ; preds = %395
-  %419 = icmp eq %"struct.std::__detail::_Hash_node.203"* %397, null
-  br i1 %419, label %_ZN12_GLOBAL__N_113deinitRuntimeEPNS_12RuntimeStateEb.exit, label %._crit_edge
+423:                                              ; preds = %400
+  %424 = icmp eq %"struct.std::__detail::_Hash_node.203"* %402, null
+  br i1 %424, label %_ZN12_GLOBAL__N_113deinitRuntimeEPNS_12RuntimeStateEb.exit, label %._crit_edge
 
-._crit_edge:                                      ; preds = %418, %416
-  %420 = phi %"struct.std::__detail::_Hash_node.203"* [ %397, %418 ], [ %408, %416 ]
-  %421 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %420, i64 0, i32 0, i32 1, i32 0, i32 0, i64 8
-  %422 = bitcast i8* %421 to i64*
-  %423 = load i64, i64* %422, align 8, !tbaa !747
-  %424 = tail call i32 @pthread_detach(i64 %423) #37
-  %425 = load i64, i64* %387, align 8, !tbaa !663
-  %426 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %420, i64 0, i32 0, i32 1
-  %427 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %426 to i32*
-  %428 = load i32, i32* %427, align 4, !tbaa !73
-  %429 = sext i32 %428 to i64
-  %430 = urem i64 %429, %425
-  %431 = getelementptr %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %420, i64 0, i32 0, i32 0
-  %432 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %390, align 8, !tbaa !661
-  %433 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %432, i64 %430
-  %434 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %433, align 8, !tbaa !3
-  br label %435
+._crit_edge:                                      ; preds = %423, %421
+  %425 = phi %"struct.std::__detail::_Hash_node.203"* [ %402, %423 ], [ %413, %421 ]
+  %426 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %425, i64 0, i32 0, i32 1, i32 0, i32 0, i64 8
+  %427 = bitcast i8* %426 to i64*
+  %428 = load atomic i64, i64* %427 unordered, align 8, !tbaa !759
+  %429 = tail call i32 @pthread_detach(i64 %428) #37
+  %430 = load atomic i64, i64* %392 unordered, align 8, !tbaa !675
+  %431 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %425, i64 0, i32 0, i32 1
+  %432 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %431 to i32*
+  %433 = load atomic i32, i32* %432 unordered, align 4, !tbaa !71
+  %434 = sext i32 %433 to i64
+  %435 = urem i64 %434, %430
+  %436 = getelementptr %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %425, i64 0, i32 0, i32 0
+  %437 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %395 unordered, align 8, !tbaa !673
+  %438 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %437, i64 %435
+  %439 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %438 unordered, align 8, !tbaa !3
+  br label %440
 
-435:                                              ; preds = %435, %._crit_edge
-  %436 = phi %"struct.std::__detail::_Hash_node_base"* [ %434, %._crit_edge ], [ %438, %435 ]
-  %437 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %436, i64 0, i32 0
-  %438 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %437, align 8, !tbaa !216
-  %439 = icmp eq %"struct.std::__detail::_Hash_node_base"* %438, %431
-  br i1 %439, label %440, label %435
+440:                                              ; preds = %440, %._crit_edge
+  %441 = phi %"struct.std::__detail::_Hash_node_base"* [ %439, %._crit_edge ], [ %443, %440 ]
+  %442 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %441, i64 0, i32 0
+  %443 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %442 unordered, align 8, !tbaa !215
+  %444 = icmp eq %"struct.std::__detail::_Hash_node_base"* %443, %436
+  br i1 %444, label %445, label %440
 
-440:                                              ; preds = %435
-  %441 = icmp eq %"struct.std::__detail::_Hash_node_base"* %434, %436
-  %442 = ptrtoint %"struct.std::__detail::_Hash_node_base"* %434 to i64
-  br i1 %441, label %443, label %470
+445:                                              ; preds = %440
+  %446 = icmp eq %"struct.std::__detail::_Hash_node_base"* %439, %441
+  %447 = ptrtoint %"struct.std::__detail::_Hash_node_base"* %439 to i64
+  br i1 %446, label %448, label %475
 
-443:                                              ; preds = %440
-  %444 = bitcast %"struct.std::__detail::_Hash_node.203"* %420 to %"struct.std::__detail::_Hash_node.203"**
-  %445 = load %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %444, align 8, !tbaa !216
-  %446 = icmp eq %"struct.std::__detail::_Hash_node.203"* %445, null
-  br i1 %446, label %460, label %447
+448:                                              ; preds = %445
+  %449 = bitcast %"struct.std::__detail::_Hash_node.203"* %425 to %"struct.std::__detail::_Hash_node.203"**
+  %450 = load atomic %"struct.std::__detail::_Hash_node.203"*, %"struct.std::__detail::_Hash_node.203"** %449 unordered, align 8, !tbaa !215
+  %451 = icmp eq %"struct.std::__detail::_Hash_node.203"* %450, null
+  br i1 %451, label %465, label %452
 
-447:                                              ; preds = %443
-  %448 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %445, i64 0, i32 0, i32 1
-  %449 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %448 to i32*
-  %450 = load i32, i32* %449, align 4, !tbaa !73
-  %451 = sext i32 %450 to i64
-  %452 = urem i64 %451, %425
-  %453 = icmp eq i64 %452, %430
-  br i1 %453, label %483, label %454
+452:                                              ; preds = %448
+  %453 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %450, i64 0, i32 0, i32 1
+  %454 = bitcast %"struct.__gnu_cxx::__aligned_buffer.201"* %453 to i32*
+  %455 = load atomic i32, i32* %454 unordered, align 4, !tbaa !71
+  %456 = sext i32 %455 to i64
+  %457 = urem i64 %456, %430
+  %458 = icmp eq i64 %457, %435
+  br i1 %458, label %488, label %459
 
-454:                                              ; preds = %447
-  %455 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %432, i64 %452
-  %456 = bitcast %"struct.std::__detail::_Hash_node_base"** %455 to i64*
-  store i64 %442, i64* %456, align 8, !tbaa !3
-  %457 = load %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %390, align 8, !tbaa !661
-  %458 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %457, i64 %430
-  %459 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %458, align 8, !tbaa !3
-  br label %460
+459:                                              ; preds = %452
+  %460 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %437, i64 %457
+  %461 = bitcast %"struct.std::__detail::_Hash_node_base"** %460 to i64*
+  store i64 %447, i64* %461, align 8, !tbaa !3
+  %462 = load atomic %"struct.std::__detail::_Hash_node_base"**, %"struct.std::__detail::_Hash_node_base"*** %395 unordered, align 8, !tbaa !673
+  %463 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %462, i64 %435
+  %464 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %463 unordered, align 8, !tbaa !3
+  br label %465
 
-460:                                              ; preds = %454, %443
-  %461 = phi %"struct.std::__detail::_Hash_node_base"* [ %459, %454 ], [ %434, %443 ]
-  %462 = phi %"struct.std::__detail::_Hash_node_base"** [ %457, %454 ], [ %432, %443 ]
-  %463 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %383, i64 0, i32 4, i32 0, i32 2
-  %464 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %462, i64 %430
-  %465 = icmp eq %"struct.std::__detail::_Hash_node_base"* %463, %461
-  br i1 %465, label %466, label %469
+465:                                              ; preds = %459, %448
+  %466 = phi %"struct.std::__detail::_Hash_node_base"* [ %464, %459 ], [ %439, %448 ]
+  %467 = phi %"struct.std::__detail::_Hash_node_base"** [ %462, %459 ], [ %437, %448 ]
+  %468 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %388, i64 0, i32 4, i32 0, i32 2
+  %469 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %467, i64 %435
+  %470 = icmp eq %"struct.std::__detail::_Hash_node_base"* %468, %466
+  br i1 %470, label %471, label %474
 
-466:                                              ; preds = %460
-  %467 = getelementptr %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %445, i64 0, i32 0, i32 0
-  %468 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %461, i64 0, i32 0
-  store %"struct.std::__detail::_Hash_node_base"* %467, %"struct.std::__detail::_Hash_node_base"** %468, align 8, !tbaa !671
-  br label %469
+471:                                              ; preds = %465
+  %472 = getelementptr %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %450, i64 0, i32 0, i32 0
+  %473 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %466, i64 0, i32 0
+  store %"struct.std::__detail::_Hash_node_base"* %472, %"struct.std::__detail::_Hash_node_base"** %473, align 8, !tbaa !683
+  br label %474
 
-469:                                              ; preds = %466, %460
-  store %"struct.std::__detail::_Hash_node_base"* null, %"struct.std::__detail::_Hash_node_base"** %464, align 8, !tbaa !3
-  br label %483
+474:                                              ; preds = %471, %465
+  store %"struct.std::__detail::_Hash_node_base"* null, %"struct.std::__detail::_Hash_node_base"** %469, align 8, !tbaa !3
+  br label %488
 
-470:                                              ; preds = %440
-  %471 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %420, i64 0, i32 0, i32 0, i32 0
-  %472 = load %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %471, align 8, !tbaa !216
-  %473 = icmp eq %"struct.std::__detail::_Hash_node_base"* %472, null
-  br i1 %473, label %483, label %474
+475:                                              ; preds = %445
+  %476 = getelementptr inbounds %"struct.std::__detail::_Hash_node.203", %"struct.std::__detail::_Hash_node.203"* %425, i64 0, i32 0, i32 0, i32 0
+  %477 = load atomic %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %476 unordered, align 8, !tbaa !215
+  %478 = icmp eq %"struct.std::__detail::_Hash_node_base"* %477, null
+  br i1 %478, label %488, label %479
 
-474:                                              ; preds = %470
-  %475 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %472, i64 1
-  %476 = bitcast %"struct.std::__detail::_Hash_node_base"* %475 to i32*
-  %477 = load i32, i32* %476, align 4, !tbaa !73
-  %478 = sext i32 %477 to i64
-  %479 = urem i64 %478, %425
-  %480 = icmp eq i64 %479, %430
-  br i1 %480, label %483, label %481
+479:                                              ; preds = %475
+  %480 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base", %"struct.std::__detail::_Hash_node_base"* %477, i64 1
+  %481 = bitcast %"struct.std::__detail::_Hash_node_base"* %480 to i32*
+  %482 = load atomic i32, i32* %481 unordered, align 4, !tbaa !71
+  %483 = sext i32 %482 to i64
+  %484 = urem i64 %483, %430
+  %485 = icmp eq i64 %484, %435
+  br i1 %485, label %488, label %486
 
-481:                                              ; preds = %474
-  %482 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %432, i64 %479
-  store %"struct.std::__detail::_Hash_node_base"* %436, %"struct.std::__detail::_Hash_node_base"** %482, align 8, !tbaa !3
-  br label %483
+486:                                              ; preds = %479
+  %487 = getelementptr inbounds %"struct.std::__detail::_Hash_node_base"*, %"struct.std::__detail::_Hash_node_base"** %437, i64 %484
+  store %"struct.std::__detail::_Hash_node_base"* %441, %"struct.std::__detail::_Hash_node_base"** %487, align 8, !tbaa !3
+  br label %488
 
-483:                                              ; preds = %481, %474, %470, %469, %447
-  %484 = bitcast %"struct.std::__detail::_Hash_node.203"* %420 to i64*
-  %485 = load i64, i64* %484, align 8, !tbaa !216
-  %486 = bitcast %"struct.std::__detail::_Hash_node_base"* %436 to i64*
-  store i64 %485, i64* %486, align 8, !tbaa !216
-  %487 = bitcast %"struct.std::__detail::_Hash_node.203"* %420 to i8*
-  tail call void @free(i8* %487) #37
-  %488 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %383, i64 0, i32 4, i32 0, i32 3
-  %489 = load i64, i64* %488, align 8, !tbaa !749
-  %490 = add i64 %489, -1
-  store i64 %490, i64* %488, align 8, !tbaa !749
+488:                                              ; preds = %486, %479, %475, %474, %452
+  %489 = bitcast %"struct.std::__detail::_Hash_node.203"* %425 to i64*
+  %490 = load atomic i64, i64* %489 unordered, align 8, !tbaa !215
+  %491 = bitcast %"struct.std::__detail::_Hash_node_base"* %441 to i64*
+  store i64 %490, i64* %491, align 8, !tbaa !215
+  %492 = bitcast %"struct.std::__detail::_Hash_node.203"* %425 to i8*
+  tail call void @free(i8* %492) #37
+  %493 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %388, i64 0, i32 4, i32 0, i32 3
+  %494 = load atomic i64, i64* %493 unordered, align 8, !tbaa !761
+  %495 = add i64 %494, -1
+  store i64 %495, i64* %493, align 8, !tbaa !761
   br label %_ZN12_GLOBAL__N_113deinitRuntimeEPNS_12RuntimeStateEb.exit
 
-_ZN12_GLOBAL__N_113deinitRuntimeEPNS_12RuntimeStateEb.exit: ; preds = %483, %418, %416, %409, %.preheader, %DeinitMemory.exit.i
-  %491 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %384) #37
+_ZN12_GLOBAL__N_113deinitRuntimeEPNS_12RuntimeStateEb.exit: ; preds = %488, %423, %421, %414, %.preheader, %DeinitMemory.exit.i
+  %496 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* %389) #37
   store %"struct.(anonymous namespace)::RuntimeState"* null, %"struct.(anonymous namespace)::RuntimeState"** @_ZN12_GLOBAL__N_112runtimeStateE, align 8, !tbaa !3
   ret void
 }
@@ -53540,7 +54376,7 @@
 
 ; Function Attrs: uwtable
 define internal void @_ZN5konanL20onThreadExitCallbackEPv(i8* %0) #20 {
-  %2 = load i32, i32* @_ZN5konan14terminationKeyE, align 4, !tbaa !73
+  %2 = load atomic i32, i32* @_ZN5konan14terminationKeyE unordered, align 4, !tbaa !71
   %3 = tail call i32 @pthread_setspecific(i32 %2, i8* null) #37
   %4 = icmp eq i8* %0, null
   br i1 %4, label %.loopexit, label %5
@@ -53552,12 +54388,12 @@
 7:                                                ; preds = %7, %5
   %8 = phi %"struct.konan::DestructorRecord"* [ %14, %7 ], [ %6, %5 ]
   %9 = getelementptr inbounds %"struct.konan::DestructorRecord", %"struct.konan::DestructorRecord"* %8, i64 0, i32 1
-  %10 = load void (i8*)*, void (i8*)** %9, align 8, !tbaa !734
+  %10 = load atomic void (i8*)*, void (i8*)** %9 unordered, align 8, !tbaa !746
   %11 = getelementptr inbounds %"struct.konan::DestructorRecord", %"struct.konan::DestructorRecord"* %8, i64 0, i32 2
-  %12 = load i8*, i8** %11, align 8, !tbaa !736
+  %12 = load atomic i8*, i8** %11 unordered, align 8, !tbaa !748
   tail call void %10(i8* %12)
   %13 = getelementptr inbounds %"struct.konan::DestructorRecord", %"struct.konan::DestructorRecord"* %8, i64 0, i32 0
-  %14 = load %"struct.konan::DestructorRecord"*, %"struct.konan::DestructorRecord"** %13, align 8, !tbaa !737
+  %14 = load atomic %"struct.konan::DestructorRecord"*, %"struct.konan::DestructorRecord"** %13 unordered, align 8, !tbaa !749
   %15 = bitcast %"struct.konan::DestructorRecord"* %8 to i8*
   tail call void @free(i8* %15) #37
   %16 = icmp eq %"struct.konan::DestructorRecord"* %14, null
@@ -53601,9 +54437,9 @@
 
 _ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit6: ; preds = %20, %16, %10
   %21 = getelementptr inbounds %"class.(anonymous namespace)::Future", %"class.(anonymous namespace)::Future"* %0, i64 0, i32 0
-  store i32 3, i32* %21, align 8, !tbaa !750
+  store i32 3, i32* %21, align 8, !tbaa !762
   %22 = getelementptr inbounds %"class.(anonymous namespace)::Future", %"class.(anonymous namespace)::Future"* %0, i64 0, i32 2
-  store i8* null, i8** %22, align 8, !tbaa !752
+  store i8* null, i8** %22, align 8, !tbaa !764
   %23 = getelementptr inbounds %"class.(anonymous namespace)::Future", %"class.(anonymous namespace)::Future"* %0, i64 0, i32 4
   %24 = tail call i32 @pthread_cond_broadcast(%union.pthread_cond_t* nonnull %23) #37
   %25 = atomicrmw xchg i32* %4, i32 1 seq_cst, align 4
@@ -53612,12 +54448,12 @@
 
 27:                                               ; preds = %2
   %28 = getelementptr inbounds %"class.(anonymous namespace)::Future", %"class.(anonymous namespace)::Future"* %0, i64 0, i32 0
-  store i32 3, i32* %28, align 8, !tbaa !750
+  store i32 3, i32* %28, align 8, !tbaa !762
   %29 = getelementptr inbounds %"class.(anonymous namespace)::Future", %"class.(anonymous namespace)::Future"* %0, i64 0, i32 2
-  store i8* null, i8** %29, align 8, !tbaa !752
+  store i8* null, i8** %29, align 8, !tbaa !764
   %30 = getelementptr inbounds %"class.(anonymous namespace)::Future", %"class.(anonymous namespace)::Future"* %0, i64 0, i32 4
   %31 = tail call i32 @pthread_cond_broadcast(%union.pthread_cond_t* nonnull %30) #37
-  %32 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
+  %32 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
   %33 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %32, i64 328
   %34 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %33 to i32*
   %35 = atomicrmw xchg i32* %34, i32 1 seq_cst, align 4
@@ -53683,9 +54519,9 @@
 
 _ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit7: ; preds = %68, %64, %58
   %69 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %54, i64 0, i32 7
-  %70 = load i32, i32* %69, align 8, !tbaa !670
+  %70 = load atomic i32, i32* %69 unordered, align 8, !tbaa !682
   %71 = add nsw i32 %70, 1
-  store i32 %71, i32* %69, align 8, !tbaa !670
+  store i32 %71, i32* %69, align 8, !tbaa !682
   %72 = atomicrmw xchg i32* %4, i32 1 seq_cst, align 4
   %73 = tail call i32 @pthread_mutex_unlock(%union.pthread_mutex_t* nonnull %56) #37
   br label %89
@@ -53694,10 +54530,10 @@
   %75 = phi %union.pthread_mutex_t* [ %40, %.thread ], [ %56, %53 ]
   %76 = phi %"class.(anonymous namespace)::State"* [ %38, %.thread ], [ %54, %53 ]
   %77 = getelementptr inbounds %"class.(anonymous namespace)::State", %"class.(anonymous namespace)::State"* %76, i64 0, i32 7
-  %78 = load i32, i32* %77, align 8, !tbaa !670
+  %78 = load atomic i32, i32* %77 unordered, align 8, !tbaa !682
   %79 = add nsw i32 %78, 1
-  store i32 %79, i32* %77, align 8, !tbaa !670
-  %80 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
+  store i32 %79, i32* %77, align 8, !tbaa !682
+  %80 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
   %81 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %80, i64 328
   %82 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %81 to i32*
   %83 = atomicrmw xchg i32* %82, i32 1 seq_cst, align 4
@@ -53774,11 +54610,11 @@
   %3 = phi %"struct.std::_Rb_tree_node"* [ %9, %.preheader ], [ %0, %1 ]
   %4 = getelementptr inbounds %"struct.std::_Rb_tree_node", %"struct.std::_Rb_tree_node"* %3, i64 0, i32 0, i32 3
   %5 = bitcast %"struct.std::_Rb_tree_node_base"** %4 to %"struct.std::_Rb_tree_node"**
-  %6 = load %"struct.std::_Rb_tree_node"*, %"struct.std::_Rb_tree_node"** %5, align 8, !tbaa !753
+  %6 = load atomic %"struct.std::_Rb_tree_node"*, %"struct.std::_Rb_tree_node"** %5 unordered, align 8, !tbaa !765
   tail call fastcc void @_ZNSt8_Rb_treeIN12_GLOBAL__N_13JobES1_St9_IdentityIS1_ENS0_10JobCompareEN6kotlin11std_support9allocatorIS1_EEE8_M_eraseEPSt13_Rb_tree_nodeIS1_E(%"struct.std::_Rb_tree_node"* %6)
   %7 = getelementptr inbounds %"struct.std::_Rb_tree_node", %"struct.std::_Rb_tree_node"* %3, i64 0, i32 0, i32 2
   %8 = bitcast %"struct.std::_Rb_tree_node_base"** %7 to %"struct.std::_Rb_tree_node"**
-  %9 = load %"struct.std::_Rb_tree_node"*, %"struct.std::_Rb_tree_node"** %8, align 8, !tbaa !754
+  %9 = load atomic %"struct.std::_Rb_tree_node"*, %"struct.std::_Rb_tree_node"** %8 unordered, align 8, !tbaa !766
   %10 = bitcast %"struct.std::_Rb_tree_node"* %3 to i8*
   tail call void @free(i8* %10) #37
   %11 = icmp eq %"struct.std::_Rb_tree_node"* %9, null
@@ -53799,7 +54635,7 @@
   call void @llvm.lifetime.start.p0i8(i64 8, i8* nonnull %3) #37
   call void @_ZSt17current_exceptionv(%"struct.std::__cxx11::basic_string<char, std::char_traits<char>, kotlin::std_support::allocator<char>>::_Alloc_hider"* nonnull sret(%"struct.std::__cxx11::basic_string<char, std::char_traits<char>, kotlin::std_support::allocator<char>>::_Alloc_hider") align 8 %1) #37
   %4 = getelementptr inbounds %"struct.std::__cxx11::basic_string<char, std::char_traits<char>, kotlin::std_support::allocator<char>>::_Alloc_hider", %"struct.std::__cxx11::basic_string<char, std::char_traits<char>, kotlin::std_support::allocator<char>>::_Alloc_hider"* %1, i64 0, i32 0
-  %5 = load i8*, i8** %4, align 8, !tbaa !755
+  %5 = load atomic i8*, i8** %4 unordered, align 8, !tbaa !767
   %6 = icmp eq i8* %5, null
   br i1 %6, label %79, label %7
 
@@ -53825,7 +54661,7 @@
 
 16:                                               ; preds = %9
   call fastcc void @Kotlin_initRuntimeIfNeeded() #37
-  %17 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
+  %17 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
   %18 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %17, i64 328
   %19 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %18 to %"class.kotlin::mm::ThreadSuspensionData.37"*
   %20 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %18 to i32*
@@ -53846,13 +54682,13 @@
 _ZN6kotlin21CalledFromNativeGuardC2Eb.exit:       ; preds = %27, %23, %16
   %28 = getelementptr inbounds i8, i8* %15, i64 8
   %29 = bitcast i8* %28 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"**
-  %30 = load %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %29, align 8, !tbaa !65
+  %30 = load atomic %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %29 unordered, align 8, !tbaa !64
   %31 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %30, i64 0, i32 0
-  %32 = load %struct.ObjHeader*, %struct.ObjHeader** %31, align 8, !tbaa !3
+  %32 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %31 unordered, align 8, !tbaa !3
   call fastcc void @_ZN12_GLOBAL__N_125processUnhandledExceptionEP9ObjHeader(%struct.ObjHeader* %32) #37
-  %33 = load %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %29, align 8, !tbaa !65
+  %33 = load atomic %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %29 unordered, align 8, !tbaa !64
   %34 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %33, i64 0, i32 0
-  %35 = load %struct.ObjHeader*, %struct.ObjHeader** %34, align 8, !tbaa !3
+  %35 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %34 unordered, align 8, !tbaa !3
   invoke fastcc void @_ZN12_GLOBAL__N_131terminateWithUnhandledExceptionEP9ObjHeader(%struct.ObjHeader* %35) #50
           to label %36 unwind label %65
 
@@ -53860,7 +54696,7 @@
   unreachable
 
 37:                                               ; preds = %9
-  %38 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %38 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %.not = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %38, null
   br i1 %.not, label %43, label %39
 
@@ -53939,7 +54775,7 @@
 79:                                               ; preds = %0
   call void @_ZNSt15__exception_ptr13exception_ptrD1Ev(%"struct.std::__cxx11::basic_string<char, std::char_traits<char>, kotlin::std_support::allocator<char>>::_Alloc_hider"* nonnull %1) #37
   call void @llvm.lifetime.end.p0i8(i64 8, i8* nonnull %3) #37
-  %80 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %80 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %.not4 = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %80, null
   br i1 %.not4, label %85, label %81
 
@@ -54026,11 +54862,11 @@
   %4 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 3
   %5 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 4
   %6 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 5
-  %7 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %7 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %8 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 5
   %9 = bitcast [6 x %struct.ObjHeader*]* %2 to %struct.FrameOverlay.6*
   %10 = bitcast %"class.kotlin::mm::ShadowStack"* %8 to i64*
-  %11 = load i64, i64* %10, align 8, !tbaa !7
+  %11 = load atomic i64, i64* %10 unordered, align 8, !tbaa !7
   %12 = getelementptr inbounds [6 x %struct.ObjHeader*], [6 x %struct.ObjHeader*]* %2, i64 0, i64 1
   %13 = bitcast %struct.ObjHeader** %12 to i64*
   store i64 %11, i64* %13, align 8, !tbaa !9
@@ -54060,11 +54896,11 @@
           to label %"kfun:kotlin.native.internal.UnhandledExceptionHookHolder#<get-$instance>#static(){}kotlin.native.internal.UnhandledExceptionHookHolder.exit.i" unwind label %.body
 
 "kfun:kotlin.native.internal.UnhandledExceptionHookHolder#<get-$instance>#static(){}kotlin.native.internal.UnhandledExceptionHookHolder.exit.i": ; preds = %label_init.i.i, %Kotlin_mm_safePointFunctionPrologue.exit
-  %24 = load %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.internal.UnhandledExceptionHookHolder.$instance#internal", align 8
+  %24 = load atomic %struct.ObjHeader*, %struct.ObjHeader** @"kvar:kotlin.native.internal.UnhandledExceptionHookHolder.$instance#internal" unordered, align 8
   store %struct.ObjHeader* %24, %struct.ObjHeader** %4, align 8, !tbaa !3
   %25 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %24, i64 1
   %26 = bitcast %struct.ObjHeader* %25 to %struct.ObjHeader**
-  %27 = load %struct.ObjHeader*, %struct.ObjHeader** %26, align 8
+  %27 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %26 unordered, align 8
   %28 = getelementptr inbounds %struct.ObjHeader, %struct.ObjHeader* %27, i64 1
   %29 = bitcast %struct.ObjHeader* %28 to i64*
   %30 = load atomic i64, i64* %29 acquire, align 8
@@ -54089,15 +54925,15 @@
   %38 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %37, i64 0, i32 0
   %39 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %38 monotonic, align 8
   %40 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %39, i64 0, i32 9
-  %41 = load i32, i32* %40, align 4
+  %41 = load atomic i32, i32* %40 unordered, align 4
   %42 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %39, i64 0, i32 10
-  %43 = load %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %42, align 8
+  %43 = load atomic %struct.InterfaceTableRecord*, %struct.InterfaceTableRecord** %42 unordered, align 8
   %44 = and i32 %41, 44
   %45 = zext i32 %44 to i64
   %46 = getelementptr %struct.InterfaceTableRecord, %struct.InterfaceTableRecord* %43, i64 %45, i32 2
   %47 = bitcast i8*** %46 to %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader**)***
-  %48 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader**)*** %47, align 8
-  %49 = load %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader**)** %48, align 8
+  %48 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader**)**, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader**)*** %47 unordered, align 8
+  %49 = load atomic %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader**)*, %struct.ObjHeader* (%struct.ObjHeader*, %struct.ObjHeader*, %struct.ObjHeader**)** %48 unordered, align 8
   %50 = invoke %struct.ObjHeader* %49(%struct.ObjHeader* nonnull %31, %struct.ObjHeader* %0, %struct.ObjHeader** nonnull %6)
           to label %71 unwind label %.body
 
@@ -54105,9 +54941,9 @@
   %51 = landingpad { i8*, i32 }
           catch i8* bitcast ({ i8*, i8* }* @_ZTI18ExceptionObjHolder to i8*)
           catch i8* null
-  %52 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %52 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %53 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %52, i64 0, i32 1, i32 5
-  %54 = load i64, i64* %13, align 8, !tbaa !9
+  %54 = load atomic i64, i64* %13 unordered, align 8, !tbaa !9
   %55 = bitcast %"class.kotlin::mm::ShadowStack"* %53 to i64*
   store i64 %54, i64* %55, align 8, !tbaa !7
   %56 = extractvalue { i8*, i32 } %51, 0
@@ -54120,9 +54956,9 @@
   %61 = tail call i8* @__cxa_begin_catch(i8* %56) #37
   %62 = getelementptr inbounds i8, i8* %61, i64 8
   %63 = bitcast i8* %62 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"**
-  %64 = load %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %63, align 8, !tbaa !65
+  %64 = load atomic %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %63 unordered, align 8, !tbaa !64
   %65 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %64, i64 0, i32 0
-  %66 = load %struct.ObjHeader*, %struct.ObjHeader** %65, align 8, !tbaa !3
+  %66 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %65 unordered, align 8, !tbaa !3
   invoke fastcc void @_ZN12_GLOBAL__N_131terminateWithUnhandledExceptionEP9ObjHeader(%struct.ObjHeader* %66) #50
           to label %67 unwind label %68
 
@@ -54137,9 +54973,9 @@
   br label %76
 
 71:                                               ; preds = %when_next.i
-  %72 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %72 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %73 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %72, i64 0, i32 1, i32 5
-  %74 = load i64, i64* %13, align 8, !tbaa !9
+  %74 = load atomic i64, i64* %13 unordered, align 8, !tbaa !9
   %75 = bitcast %"class.kotlin::mm::ShadowStack"* %73 to i64*
   store i64 %74, i64* %75, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 48, i8* nonnull %3)
@@ -54165,73 +55001,88 @@
 
 ; Function Attrs: noreturn uwtable
 define internal fastcc void @"_ZN12_GLOBAL__N_13$_0clIZNS_16TerminateHandler13queuedHandlerEvEUlvE_EEvT_"() unnamed_addr #25 align 2 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
-  %1 = cmpxchg volatile i32* getelementptr inbounds (%"struct.kotlin::mm::ThreadLocalStorage::Entry", %"struct.kotlin::mm::ThreadLocalStorage::Entry"* @_ZN12_GLOBAL__N_126concurrentTerminateWrapperE, i64 0, i32 1), i32 0, i32 1 seq_cst seq_cst, align 4
-  %2 = extractvalue { i32, i1 } %1, 1
-  br i1 %2, label %3, label %4
+  %1 = alloca %"class.kotlin::NativeOrUnregisteredThreadGuard", align 8
+  %2 = cmpxchg volatile i32* getelementptr inbounds (%"struct.kotlin::mm::ThreadLocalStorage::Entry", %"struct.kotlin::mm::ThreadLocalStorage::Entry"* @_ZN12_GLOBAL__N_126concurrentTerminateWrapperE, i64 0, i32 1), i32 0, i32 1 seq_cst seq_cst, align 4
+  %3 = extractvalue { i32, i1 } %2, 1
+  br i1 %3, label %4, label %5
 
-3:                                                ; preds = %0
+4:                                                ; preds = %0
   tail call fastcc void @_ZZN12_GLOBAL__N_116TerminateHandler13queuedHandlerEvENKUlvE_clEv()
   unreachable
 
-4:                                                ; preds = %0
-  %5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %.not = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, null
-  br i1 %.not, label %10, label %6
+5:                                                ; preds = %0
+  %6 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %1, i64 0, i32 0, i64 0
+  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %6) #37
+  %7 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %1, i64 0, i32 1
+  %8 = getelementptr inbounds %"class.kotlin::CalledFromNativeGuard", %"class.kotlin::CalledFromNativeGuard"* %7, i64 0, i32 0
+  store %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* null, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %8, align 8, !tbaa !34
+  %9 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %1, i64 0, i32 1, i32 1
+  store i32 1, i32* %9, align 8, !tbaa !38
+  %10 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %1, i64 0, i32 1, i32 2
+  store i8 0, i8* %10, align 4, !tbaa !39
+  %11 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %.not = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, null
+  br i1 %.not, label %18, label %12
 
-6:                                                ; preds = %4
-  %7 = bitcast %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*
-  %8 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5, i64 0, i32 1, i32 8, i32 0, i32 0
-  %9 = atomicrmw xchg i32* %8, i32 1 seq_cst, align 4
-  %phi.cast = bitcast %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %5 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*
-  br label %10
+12:                                               ; preds = %5
+  %13 = bitcast %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*
+  %14 = ptrtoint %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11 to i64
+  %15 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %11, i64 0, i32 1, i32 8, i32 0, i32 0
+  %16 = atomicrmw xchg i32* %15, i32 1 seq_cst, align 4
+  %17 = bitcast %"class.kotlin::CalledFromNativeGuard"* %7 to i64*
+  store i64 %14, i64* %17, align 8, !tbaa !34
+  store i32 %16, i32* %9, align 8, !tbaa !38
+  store i8 1, i8* %10, align 4, !tbaa !39
+  br label %18
 
-10:                                               ; preds = %6, %4
-  %.sroa.6.0 = phi i32 [ 1, %4 ], [ %9, %6 ]
-  %.sroa.3.0 = phi %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* [ null, %4 ], [ %phi.cast, %6 ]
-  %11 = phi %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* [ null, %4 ], [ %7, %6 ]
-  %12 = load i32, i32* getelementptr inbounds (%"struct.kotlin::mm::ThreadLocalStorage::Entry", %"struct.kotlin::mm::ThreadLocalStorage::Entry"* @_ZN12_GLOBAL__N_126concurrentTerminateWrapperE, i64 0, i32 0), align 4, !tbaa !757
-  %13 = invoke i32 @sleep(i32 %12)
-          to label %14 unwind label %15
+18:                                               ; preds = %12, %5
+  %19 = phi i32 [ 1, %5 ], [ %16, %12 ]
+  %20 = phi %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* [ null, %5 ], [ %13, %12 ]
+  %21 = load atomic i32, i32* getelementptr inbounds (%"struct.kotlin::mm::ThreadLocalStorage::Entry", %"struct.kotlin::mm::ThreadLocalStorage::Entry"* @_ZN12_GLOBAL__N_126concurrentTerminateWrapperE, i64 0, i32 0) unordered, align 4, !tbaa !769
+  %22 = invoke i32 @sleep(i32 %21)
+          to label %23 unwind label %24
 
-14:                                               ; preds = %10
-  tail call fastcc void @_ZN6kotlin31NativeOrUnregisteredThreadGuardD2Ev(%"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %.sroa.3.0, i32 %.sroa.6.0) #37
+23:                                               ; preds = %18
+  call fastcc void @_ZN6kotlin31NativeOrUnregisteredThreadGuardD2Ev(%"class.kotlin::NativeOrUnregisteredThreadGuard"* nonnull %1) #37
+  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %6) #37
   tail call void @_Exit(i32 1) #51
   unreachable
 
-15:                                               ; preds = %10
-  %16 = landingpad { i8*, i32 }
+24:                                               ; preds = %18
+  %25 = landingpad { i8*, i32 }
           cleanup
-  %17 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %11, null
-  br i1 %17, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %18
+  %26 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %20, null
+  br i1 %26, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %27
 
-18:                                               ; preds = %15
-  %19 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %11, i64 328
-  %20 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %19 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %21 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %19 to i32*
-  %22 = atomicrmw xchg i32* %21, i32 %.sroa.6.0 seq_cst, align 4
-  %23 = icmp eq i32 %22, 1
-  %24 = icmp eq i32 %.sroa.6.0, 0
-  %25 = and i1 %24, %23
-  br i1 %25, label %26, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
+27:                                               ; preds = %24
+  %28 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %20, i64 328
+  %29 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %28 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %30 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %28 to i32*
+  %31 = atomicrmw xchg i32* %30, i32 %19 seq_cst, align 4
+  %32 = icmp eq i32 %31, 1
+  %33 = icmp eq i32 %19, 0
+  %34 = and i1 %33, %32
+  br i1 %34, label %35, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-26:                                               ; preds = %18
-  %27 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %28 = and i8 %27, 1
-  %29 = icmp eq i8 %28, 0
-  br i1 %29, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %30
+35:                                               ; preds = %27
+  %36 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %37 = and i8 %36, 1
+  %38 = icmp eq i8 %37, 0
+  br i1 %38, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %39
 
-30:                                               ; preds = %26
-  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %20) #37
+39:                                               ; preds = %35
+  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %29) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %30, %26, %18, %15
-  resume { i8*, i32 } %16
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %39, %35, %27, %24
+  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %6) #37
+  resume { i8*, i32 } %25
 }
 
 ; Function Attrs: inlinehint noreturn uwtable
 define internal fastcc void @_ZZN12_GLOBAL__N_116TerminateHandler13queuedHandlerEvENKUlvE_clEv() unnamed_addr #47 align 2 {
   tail call fastcc void @_ZN12_GLOBAL__N_116TerminateHandler8instanceEv()
-  %1 = load void ()*, void ()** @_ZZN12_GLOBAL__N_116TerminateHandler8instanceEvE9singleton.0, align 8, !tbaa !675
+  %1 = load atomic void ()*, void ()** @_ZZN12_GLOBAL__N_116TerminateHandler8instanceEvE9singleton.0 unordered, align 8, !tbaa !687
   tail call void %1() #50
   unreachable
 }
@@ -54245,7 +55096,7 @@
 define internal fastcc void @_ZN12_GLOBAL__N_116TerminateHandler8instanceEv() unnamed_addr #17 align 2 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
   %1 = load atomic i8, i8* bitcast (i64* @_ZGVZN12_GLOBAL__N_116TerminateHandler8instanceEvE9singleton to i8*) acquire, align 8
   %2 = icmp eq i8 %1, 0
-  br i1 %2, label %3, label %8, !prof !674
+  br i1 %2, label %3, label %8, !prof !686
 
 3:                                                ; preds = %0
   %4 = tail call i32 @__cxa_guard_acquire(i64* nonnull @_ZGVZN12_GLOBAL__N_116TerminateHandler8instanceEvE9singleton) #37
@@ -54254,7 +55105,7 @@
 
 6:                                                ; preds = %3
   %7 = tail call void ()* @_ZSt13set_terminatePFvvE(void ()* nonnull @_ZN12_GLOBAL__N_116TerminateHandler13kotlinHandlerEv) #37
-  store void ()* %7, void ()** @_ZZN12_GLOBAL__N_116TerminateHandler8instanceEvE9singleton.0, align 8, !tbaa !675
+  store void ()* %7, void ()** @_ZZN12_GLOBAL__N_116TerminateHandler8instanceEvE9singleton.0, align 8, !tbaa !687
   tail call void @__cxa_guard_release(i64* nonnull @_ZGVZN12_GLOBAL__N_116TerminateHandler8instanceEvE9singleton) #37
   br label %8
 
@@ -54264,72 +55115,92 @@
 
 ; Function Attrs: noreturn uwtable
 define internal fastcc void @"_ZN12_GLOBAL__N_13$_0clIZNS_31terminateWithUnhandledExceptionEP9ObjHeaderE3$_1EEvT_"(%struct.ObjHeader* %0) unnamed_addr #25 align 2 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
-  %2 = cmpxchg volatile i32* getelementptr inbounds (%"struct.kotlin::mm::ThreadLocalStorage::Entry", %"struct.kotlin::mm::ThreadLocalStorage::Entry"* @_ZN12_GLOBAL__N_126concurrentTerminateWrapperE, i64 0, i32 1), i32 0, i32 1 seq_cst seq_cst, align 4
-  %3 = extractvalue { i32, i1 } %2, 1
-  br i1 %3, label %4, label %5
+  %2 = alloca %"struct.std::__atomic_base.1", align 8
+  %3 = alloca %"class.kotlin::NativeOrUnregisteredThreadGuard", align 8
+  %4 = getelementptr inbounds %"struct.std::__atomic_base.1", %"struct.std::__atomic_base.1"* %2, i64 0, i32 0
+  store %struct.ObjHeader* %0, %struct.ObjHeader** %4, align 8
+  %5 = cmpxchg volatile i32* getelementptr inbounds (%"struct.kotlin::mm::ThreadLocalStorage::Entry", %"struct.kotlin::mm::ThreadLocalStorage::Entry"* @_ZN12_GLOBAL__N_126concurrentTerminateWrapperE, i64 0, i32 1), i32 0, i32 1 seq_cst seq_cst, align 4
+  %6 = extractvalue { i32, i1 } %5, 1
+  br i1 %6, label %7, label %8
 
-4:                                                ; preds = %1
-  tail call fastcc void @"_ZZN12_GLOBAL__N_131terminateWithUnhandledExceptionEP9ObjHeaderENK3$_1clEv"(%struct.ObjHeader* %0)
+7:                                                ; preds = %1
+  call fastcc void @"_ZZN12_GLOBAL__N_131terminateWithUnhandledExceptionEP9ObjHeaderENK3$_1clEv"(%"struct.std::__atomic_base.1"* nonnull %2)
   unreachable
 
-5:                                                ; preds = %1
-  %6 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %.not = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, null
-  br i1 %.not, label %11, label %7
+8:                                                ; preds = %1
+  %9 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %3, i64 0, i32 0, i64 0
+  call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %9) #37
+  %10 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %3, i64 0, i32 1
+  %11 = getelementptr inbounds %"class.kotlin::CalledFromNativeGuard", %"class.kotlin::CalledFromNativeGuard"* %10, i64 0, i32 0
+  store %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* null, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %11, align 8, !tbaa !34
+  %12 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %3, i64 0, i32 1, i32 1
+  store i32 1, i32* %12, align 8, !tbaa !38
+  %13 = getelementptr inbounds %"class.kotlin::NativeOrUnregisteredThreadGuard", %"class.kotlin::NativeOrUnregisteredThreadGuard"* %3, i64 0, i32 1, i32 2
+  store i8 0, i8* %13, align 4, !tbaa !39
+  %14 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %.not = icmp eq %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %14, null
+  br i1 %.not, label %21, label %15
 
-7:                                                ; preds = %5
-  %8 = bitcast %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*
-  %9 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6, i64 0, i32 1, i32 8, i32 0, i32 0
-  %10 = atomicrmw xchg i32* %9, i32 1 seq_cst, align 4
-  %phi.cast = bitcast %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %6 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*
-  br label %11
+15:                                               ; preds = %8
+  %16 = bitcast %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %14 to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*
+  %17 = ptrtoint %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %14 to i64
+  %18 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %14, i64 0, i32 1, i32 8, i32 0, i32 0
+  %19 = atomicrmw xchg i32* %18, i32 1 seq_cst, align 4
+  %20 = bitcast %"class.kotlin::CalledFromNativeGuard"* %10 to i64*
+  store i64 %17, i64* %20, align 8, !tbaa !34
+  store i32 %19, i32* %12, align 8, !tbaa !38
+  store i8 1, i8* %13, align 4, !tbaa !39
+  br label %21
 
-11:                                               ; preds = %7, %5
-  %.sroa.6.0 = phi i32 [ 1, %5 ], [ %10, %7 ]
-  %.sroa.3.0 = phi %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* [ null, %5 ], [ %phi.cast, %7 ]
-  %12 = phi %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* [ null, %5 ], [ %8, %7 ]
-  %13 = load i32, i32* getelementptr inbounds (%"struct.kotlin::mm::ThreadLocalStorage::Entry", %"struct.kotlin::mm::ThreadLocalStorage::Entry"* @_ZN12_GLOBAL__N_126concurrentTerminateWrapperE, i64 0, i32 0), align 4, !tbaa !757
-  %14 = invoke i32 @sleep(i32 %13)
-          to label %15 unwind label %16
+21:                                               ; preds = %15, %8
+  %22 = phi i32 [ 1, %8 ], [ %19, %15 ]
+  %23 = phi %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* [ null, %8 ], [ %16, %15 ]
+  %24 = load atomic i32, i32* getelementptr inbounds (%"struct.kotlin::mm::ThreadLocalStorage::Entry", %"struct.kotlin::mm::ThreadLocalStorage::Entry"* @_ZN12_GLOBAL__N_126concurrentTerminateWrapperE, i64 0, i32 0) unordered, align 4, !tbaa !769
+  %25 = invoke i32 @sleep(i32 %24)
+          to label %26 unwind label %27
 
-15:                                               ; preds = %11
-  tail call fastcc void @_ZN6kotlin31NativeOrUnregisteredThreadGuardD2Ev(%"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %.sroa.3.0, i32 %.sroa.6.0) #37
+26:                                               ; preds = %21
+  call fastcc void @_ZN6kotlin31NativeOrUnregisteredThreadGuardD2Ev(%"class.kotlin::NativeOrUnregisteredThreadGuard"* nonnull %3) #37
+  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %9) #37
   tail call void @_Exit(i32 1) #51
   unreachable
 
-16:                                               ; preds = %11
-  %17 = landingpad { i8*, i32 }
+27:                                               ; preds = %21
+  %28 = landingpad { i8*, i32 }
           cleanup
-  %18 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %12, null
-  br i1 %18, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %19
+  %29 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %23, null
+  br i1 %29, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %30
 
-19:                                               ; preds = %16
-  %20 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %12, i64 328
-  %21 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %20 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %22 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %20 to i32*
-  %23 = atomicrmw xchg i32* %22, i32 %.sroa.6.0 seq_cst, align 4
-  %24 = icmp eq i32 %23, 1
-  %25 = icmp eq i32 %.sroa.6.0, 0
-  %26 = and i1 %25, %24
-  br i1 %26, label %27, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
+30:                                               ; preds = %27
+  %31 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %23, i64 328
+  %32 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %31 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %33 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %31 to i32*
+  %34 = atomicrmw xchg i32* %33, i32 %22 seq_cst, align 4
+  %35 = icmp eq i32 %34, 1
+  %36 = icmp eq i32 %22, 0
+  %37 = and i1 %36, %35
+  br i1 %37, label %38, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-27:                                               ; preds = %19
-  %28 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %29 = and i8 %28, 1
-  %30 = icmp eq i8 %29, 0
-  br i1 %30, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %31
+38:                                               ; preds = %30
+  %39 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %40 = and i8 %39, 1
+  %41 = icmp eq i8 %40, 0
+  br i1 %41, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %42
 
-31:                                               ; preds = %27
-  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %21) #37
+42:                                               ; preds = %38
+  tail call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %32) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %31, %27, %19, %16
-  resume { i8*, i32 } %17
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %42, %38, %30, %27
+  call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %9) #37
+  resume { i8*, i32 } %28
 }
 
 ; Function Attrs: inlinehint noreturn uwtable
-define internal fastcc void @"_ZZN12_GLOBAL__N_131terminateWithUnhandledExceptionEP9ObjHeaderENK3$_1clEv"(%struct.ObjHeader* %.0.0.val) unnamed_addr #47 align 2 {
-  tail call fastcc void @ReportUnhandledException(%struct.ObjHeader* %.0.0.val)
+define internal fastcc void @"_ZZN12_GLOBAL__N_131terminateWithUnhandledExceptionEP9ObjHeaderENK3$_1clEv"(%"struct.std::__atomic_base.1"* nocapture readonly %0) unnamed_addr #47 align 2 {
+  %2 = getelementptr inbounds %"struct.std::__atomic_base.1", %"struct.std::__atomic_base.1"* %0, i64 0, i32 0
+  %3 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %2 unordered, align 8, !tbaa !771
+  tail call fastcc void @ReportUnhandledException(%struct.ObjHeader* %3)
   tail call fastcc void @_ZN5konan5abortEv() #50
   unreachable
 }
@@ -54364,7 +55235,7 @@
   br i1 %12, label %74, label %13
 
 13:                                               ; preds = %9
-  %14 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
+  %14 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
   %15 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %14, i64 328
   %16 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %15 to i32*
   %17 = atomicrmw xchg i32* %16, i32 1 seq_cst, align 4
@@ -54437,7 +55308,7 @@
   br label %74
 
 50:                                               ; preds = %37
-  %51 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
+  %51 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
   %52 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %51, i64 328
   %53 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %52 to i32*
   %54 = atomicrmw xchg i32* %53, i32 1 seq_cst, align 4
@@ -54488,7 +55359,7 @@
 
 ; Function Attrs: uwtable
 define internal fastcc void @CallInitThreadLocal(i32* nocapture %0, void ()* nocapture %1) unnamed_addr #20 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
-  %3 = load i32, i32* %0, align 4, !tbaa !73
+  %3 = load atomic i32, i32* %0 unordered, align 4, !tbaa !71
   %4 = icmp eq i32 %3, 3
   br i1 %4, label %5, label %6
 
@@ -54497,16 +55368,16 @@
   unreachable
 
 6:                                                ; preds = %2
-  store i32 2, i32* %0, align 4, !tbaa !73
+  store i32 2, i32* %0, align 4, !tbaa !71
   invoke void %1()
-          to label %11 unwind label %7, !callees !759
+          to label %11 unwind label %7, !callees !773
 
 7:                                                ; preds = %6
   %8 = landingpad { i8*, i32 }
           catch i8* null
   %9 = extractvalue { i8*, i32 } %8, 0
   %10 = tail call i8* @__cxa_begin_catch(i8* %9) #37
-  store i32 3, i32* %0, align 4, !tbaa !73
+  store i32 3, i32* %0, align 4, !tbaa !71
   invoke void @__cxa_rethrow() #50
           to label %14 unwind label %12
 
@@ -54551,7 +55422,7 @@
   %19 = add i8 %18, %17
   %20 = add nuw i64 %11, 1
   %21 = getelementptr inbounds [66 x i8], [66 x i8]* %3, i64 0, i64 %11
-  store i8 %19, i8* %21, align 1, !tbaa !51
+  store i8 %19, i8* %21, align 1, !tbaa !50
   %22 = sdiv i64 %12, 16
   %23 = icmp slt i64 %12, -15
   br i1 %23, label %10, label %24
@@ -54574,7 +55445,7 @@
 .loopexit:                                        ; preds = %35, %27
   %32 = phi i64 [ %28, %27 ], [ %30, %35 ]
   %33 = getelementptr inbounds [66 x i8], [66 x i8]* %3, i64 0, i64 %32
-  store i8 0, i8* %33, align 1, !tbaa !51
+  store i8 0, i8* %33, align 1, !tbaa !50
   %34 = call fastcc %struct.ObjHeader* @CreateStringFromCString(i8* nonnull %8, %struct.ObjHeader** %1)
   call void @llvm.lifetime.end.p0i8(i64 66, i8* nonnull %8) #37
   br label %45
@@ -54583,11 +55454,11 @@
   %36 = phi i64 [ 0, %29 ], [ %42, %35 ]
   %37 = phi i64 [ %31, %29 ], [ %43, %35 ]
   %38 = getelementptr inbounds [66 x i8], [66 x i8]* %3, i64 0, i64 %36
-  %39 = load i8, i8* %38, align 1, !tbaa !51
+  %39 = load atomic i8, i8* %38 unordered, align 1, !tbaa !50
   %40 = getelementptr inbounds [66 x i8], [66 x i8]* %3, i64 0, i64 %37
-  %41 = load i8, i8* %40, align 1, !tbaa !51
-  store i8 %41, i8* %38, align 1, !tbaa !51
-  store i8 %39, i8* %40, align 1, !tbaa !51
+  %41 = load atomic i8, i8* %40 unordered, align 1, !tbaa !50
+  store i8 %41, i8* %38, align 1, !tbaa !50
+  store i8 %39, i8* %40, align 1, !tbaa !50
   %42 = add nuw nsw i64 %36, 1
   %43 = add nsw i64 %37, -1
   %44 = icmp slt i64 %42, %43
@@ -54620,7 +55491,7 @@
 define internal fastcc nonnull %struct.ObjHeader* @Kotlin_getCurrentStackTrace(%struct.ObjHeader** nocapture %0) unnamed_addr #29 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
   %2 = alloca %"class.kotlin::StackTrace.198", align 8
   %3 = alloca %class.ObjHolder, align 8
-  %4 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
+  %4 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
   %5 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %4, i64 328
   %6 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %5 to i32*
   %7 = atomicrmw xchg i32* %6, i32 1 seq_cst, align 4
@@ -54628,11 +55499,11 @@
   call void @llvm.lifetime.start.p0i8(i64 24, i8* nonnull %8) #37
   call fastcc void @_ZN6kotlin10StackTraceILm18446744073709551615EE7currentEm(%"class.kotlin::StackTrace.198"* noalias nonnull align 8 %2)
   %9 = bitcast %"class.kotlin::StackTrace.198"* %2 to i64*
-  %10 = load i64, i64* %9, align 8, !tbaa !3
+  %10 = load atomic i64, i64* %9 unordered, align 8, !tbaa !3
   store i64 0, i64* %9, align 8, !tbaa !3
   %11 = getelementptr inbounds %"class.kotlin::StackTrace.198", %"class.kotlin::StackTrace.198"* %2, i64 0, i32 0, i32 0, i32 0, i32 1
   %12 = bitcast i8*** %11 to i64*
-  %13 = load i64, i64* %12, align 8, !tbaa !3
+  %13 = load atomic i64, i64* %12 unordered, align 8, !tbaa !3
   call void @llvm.lifetime.end.p0i8(i64 24, i8* nonnull %8) #37
   %14 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %4, null
   br i1 %14, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %15
@@ -54659,11 +55530,11 @@
   %26 = bitcast %class.ObjHolder* %3 to i8*
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %26) #37
   %27 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %3, i64 0, i32 1
-  store %struct.ObjHeader* null, %struct.ObjHeader** %27, align 8, !tbaa !61
-  %28 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  store %struct.ObjHeader* null, %struct.ObjHeader** %27, align 8, !tbaa !60
+  %28 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %29 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %28, i64 0, i32 1, i32 5
   %30 = bitcast %"class.kotlin::mm::ShadowStack"* %29 to i64*
-  %31 = load i64, i64* %30, align 8, !tbaa !7
+  %31 = load atomic i64, i64* %30 unordered, align 8, !tbaa !7
   %32 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %3, i64 0, i32 0, i32 1
   %33 = bitcast %struct.FrameOverlay.6** %32 to i64*
   store i64 %31, i64* %33, align 8, !tbaa !9
@@ -54681,7 +55552,7 @@
 
 41:                                               ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
   invoke fastcc void @ThrowIllegalArgumentException() #50
-          to label %.noexc unwind label %75
+          to label %.noexc unwind label %76
 
 .noexc:                                           ; preds = %41
   unreachable
@@ -54689,7 +55560,7 @@
 42:                                               ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
   %43 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %28, i64 0, i32 1, i32 6
   %44 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %43 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %45 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %44, align 8, !tbaa !3
+  %45 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %44 unordered, align 8, !tbaa !3
   %46 = and i64 %37, 34359738360
   %47 = add nuw nsw i64 %46, 31
   %48 = and i64 %47, 68719476728
@@ -54713,97 +55584,98 @@
   %60 = inttoptr i64 %10 to i8**
   %61 = icmp ugt i64 %38, 1
   %62 = select i1 %61, i64 %38, i64 1
-  %63 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %52 to i64*
-  %64 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %50, i64 4
-  %wide.trip.count = and i64 %38, 4294967295
-  br label %77
+  %63 = load atomic i32, i32* %56 unordered, align 8, !tbaa !18
+  %64 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %52 to i64*
+  %65 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %50, i64 4
+  %wide.trip.count = zext i32 %63 to i64
+  br label %78
 
-.loopexit:                                        ; preds = %80, %42
-  %65 = bitcast %struct.ObjHeader** %0 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
-  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %52, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %65, align 8, !tbaa !3
-  %66 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %67 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %66, i64 0, i32 1, i32 5
-  %68 = load i64, i64* %33, align 8, !tbaa !9
-  %69 = bitcast %"class.kotlin::mm::ShadowStack"* %67 to i64*
-  store i64 %68, i64* %69, align 8, !tbaa !7
+.loopexit:                                        ; preds = %81, %42
+  %66 = bitcast %struct.ObjHeader** %0 to %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"**
+  store %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %52, %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"** %66, align 8, !tbaa !3
+  %67 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %68 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %67, i64 0, i32 1, i32 5
+  %69 = load atomic i64, i64* %33 unordered, align 8, !tbaa !9
+  %70 = bitcast %"class.kotlin::mm::ShadowStack"* %68 to i64*
+  store i64 %69, i64* %70, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %26) #37
-  %70 = icmp eq i64 %10, 0
-  br i1 %70, label %73, label %71
+  %71 = icmp eq i64 %10, 0
+  br i1 %71, label %74, label %72
 
-71:                                               ; preds = %.loopexit
-  %72 = inttoptr i64 %10 to i8*
-  call void @free(i8* %72) #37
-  br label %73
+72:                                               ; preds = %.loopexit
+  %73 = inttoptr i64 %10 to i8*
+  call void @free(i8* %73) #37
+  br label %74
 
-73:                                               ; preds = %71, %.loopexit
-  %74 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %52 to %struct.ObjHeader*
-  ret %struct.ObjHeader* %74
+74:                                               ; preds = %72, %.loopexit
+  %75 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %52 to %struct.ObjHeader*
+  ret %struct.ObjHeader* %75
 
-75:                                               ; preds = %41
-  %76 = landingpad { i8*, i32 }
+76:                                               ; preds = %41
+  %77 = landingpad { i8*, i32 }
           cleanup
-  br label %92
+  br label %93
 
-77:                                               ; preds = %80, %59
-  %78 = phi i64 [ 0, %59 ], [ %88, %80 ]
-  %exitcond.not = icmp eq i64 %78, %wide.trip.count
-  br i1 %exitcond.not, label %79, label %80
+78:                                               ; preds = %81, %59
+  %79 = phi i64 [ 0, %59 ], [ %89, %81 ]
+  %exitcond.not = icmp eq i64 %79, %wide.trip.count
+  br i1 %exitcond.not, label %80, label %81
 
-79:                                               ; preds = %77
+80:                                               ; preds = %78
   invoke fastcc void @ThrowArrayIndexOutOfBoundsException() #50
-          to label %.noexc3 unwind label %90
+          to label %.noexc3 unwind label %91
 
-.noexc3:                                          ; preds = %79
+.noexc3:                                          ; preds = %80
   unreachable
 
-80:                                               ; preds = %77
-  %81 = getelementptr inbounds i8*, i8** %60, i64 %78
-  %82 = bitcast i8** %81 to i64*
-  %83 = load i64, i64* %82, align 8, !tbaa !3
-  %84 = load atomic volatile i64, i64* %63 monotonic, align 8
-  %sext = shl i64 %78, 32
-  %85 = ashr exact i64 %sext, 32
-  %86 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %64, i64 %85
-  %87 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %86 to i64*
-  store i64 %83, i64* %87, align 8, !tbaa !3
-  %88 = add nuw nsw i64 %78, 1
-  %89 = icmp eq i64 %88, %62
-  br i1 %89, label %.loopexit, label %77
+81:                                               ; preds = %78
+  %82 = getelementptr inbounds i8*, i8** %60, i64 %79
+  %83 = bitcast i8** %82 to i64*
+  %84 = load atomic i64, i64* %83 unordered, align 8, !tbaa !3
+  %85 = load atomic volatile i64, i64* %64 monotonic, align 8
+  %sext = shl i64 %79, 32
+  %86 = ashr exact i64 %sext, 32
+  %87 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %65, i64 %86
+  %88 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %87 to i64*
+  store i64 %84, i64* %88, align 8, !tbaa !3
+  %89 = add nuw nsw i64 %79, 1
+  %90 = icmp eq i64 %89, %62
+  br i1 %90, label %.loopexit, label %78
 
-90:                                               ; preds = %79
-  %91 = landingpad { i8*, i32 }
+91:                                               ; preds = %80
+  %92 = landingpad { i8*, i32 }
           cleanup
-  br label %92
+  br label %93
 
-92:                                               ; preds = %90, %75
-  %93 = phi { i8*, i32 } [ %91, %90 ], [ %76, %75 ]
-  %94 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %95 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %94, i64 0, i32 1, i32 5
-  %96 = load i64, i64* %33, align 8, !tbaa !9
-  %97 = bitcast %"class.kotlin::mm::ShadowStack"* %95 to i64*
-  store i64 %96, i64* %97, align 8, !tbaa !7
+93:                                               ; preds = %91, %76
+  %94 = phi { i8*, i32 } [ %92, %91 ], [ %77, %76 ]
+  %95 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %96 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %95, i64 0, i32 1, i32 5
+  %97 = load atomic i64, i64* %33 unordered, align 8, !tbaa !9
+  %98 = bitcast %"class.kotlin::mm::ShadowStack"* %96 to i64*
+  store i64 %97, i64* %98, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %26) #37
-  %98 = icmp eq i64 %10, 0
-  br i1 %98, label %101, label %99
+  %99 = icmp eq i64 %10, 0
+  br i1 %99, label %102, label %100
 
-99:                                               ; preds = %92
-  %100 = inttoptr i64 %10 to i8*
-  call void @free(i8* %100) #37
-  br label %101
+100:                                              ; preds = %93
+  %101 = inttoptr i64 %10 to i8*
+  call void @free(i8* %101) #37
+  br label %102
 
-101:                                              ; preds = %99, %92
-  resume { i8*, i32 } %93
+102:                                              ; preds = %100, %93
+  resume { i8*, i32 } %94
 }
 
 ; Function Attrs: uwtable
 define internal fastcc void @Kotlin_io_Console_print(%struct.ArrayHeader* %0) unnamed_addr #20 personality i8* bitcast (i32 (...)* @__gxx_personality_v0 to i8*) {
   %2 = alloca %"class.std::__cxx11::basic_string", align 8
   %3 = bitcast %struct.ArrayHeader* %0 to i64*
-  %4 = load i64, i64* %3, align 8, !tbaa !16
+  %4 = load atomic i64, i64* %3 unordered, align 8, !tbaa !16
   %5 = and i64 %4, -4
   %6 = inttoptr i64 %5 to %struct.TypeInfo*
   %7 = getelementptr inbounds %struct.TypeInfo, %struct.TypeInfo* %6, i64 0, i32 0
-  %8 = load %struct.TypeInfo*, %struct.TypeInfo** %7, align 8, !tbaa !335
+  %8 = load atomic %struct.TypeInfo*, %struct.TypeInfo** %7 unordered, align 8, !tbaa !339
   %9 = icmp eq %struct.TypeInfo* %8, getelementptr inbounds ({ %struct.TypeInfo, [3 x i8*] }, { %struct.TypeInfo, [3 x i8*] }* @"ktypeglobal:kotlin.String#internal", i64 0, i32 0)
   br i1 %9, label %12, label %10
 
@@ -54819,164 +55691,246 @@
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %15) #37
   %16 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %2, i64 0, i32 2
   %17 = bitcast %"class.std::__cxx11::basic_string"* %2 to %union.anon.108**
-  store %union.anon.108* %16, %union.anon.108** %17, align 8, !tbaa !56
+  store %union.anon.108* %16, %union.anon.108** %17, align 8, !tbaa !45
   %18 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %2, i64 0, i32 1
-  store i64 0, i64* %18, align 8, !tbaa !60
+  store i64 0, i64* %18, align 8, !tbaa !51
   %19 = bitcast %union.anon.108* %16 to i8*
-  store i8 0, i8* %19, align 8, !tbaa !51
+  store i8 0, i8* %19, align 8, !tbaa !50
   %20 = getelementptr inbounds %struct.ArrayHeader, %struct.ArrayHeader* %0, i64 0, i32 1
-  %21 = load i32, i32* %20, align 8, !tbaa !18
+  %21 = load atomic i32, i32* %20 unordered, align 8, !tbaa !18
   %22 = zext i32 %21 to i64
-  %23 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %2, i64 0, i32 0, i32 0
-  %24 = icmp ugt i32 %21, 15
-  br i1 %24, label %25, label %_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE7reserveEm.exit
+  %23 = load atomic i64, i64* %18 unordered, align 8, !tbaa !51
+  %24 = icmp ugt i64 %23, %22
+  %25 = select i1 %24, i64 %23, i64 %22
+  %26 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %2, i64 0, i32 0, i32 0
+  %27 = load atomic i8*, i8** %26 unordered, align 8, !tbaa !47
+  %28 = icmp eq i8* %27, %19
+  %29 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %2, i64 0, i32 2, i32 0
+  %30 = load atomic i64, i64* %29 unordered, align 8
+  %31 = select i1 %28, i64 15, i64 %30
+  %32 = icmp eq i64 %25, %31
+  br i1 %32, label %_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE7reserveEm.exit, label %33
 
-25:                                               ; preds = %12
-  %26 = icmp ugt i32 %21, 30
-  %spec.select9 = select i1 %26, i32 %21, i32 30
-  %27 = zext i32 %spec.select9 to i64
-  %28 = add nuw nsw i64 %27, 1
-  %29 = call noalias i8* @calloc(i64 %28, i64 1) #37
-  store i8* %29, i8** %23, align 8, !tbaa !58
-  %30 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %2, i64 0, i32 2, i32 0
-  store i64 %27, i64* %30, align 8, !tbaa !51
+33:                                               ; preds = %12
+  %34 = icmp ugt i64 %25, %31
+  %35 = icmp ugt i64 %25, 15
+  %36 = or i1 %35, %34
+  br i1 %36, label %37, label %59
+
+37:                                               ; preds = %33
+  %38 = icmp slt i64 %25, 0
+  br i1 %38, label %39, label %40
+
+39:                                               ; preds = %37
+  call fastcc void @_ZSt20__throw_length_errorPKc(i8* getelementptr inbounds ([24 x i8], [24 x i8]* @.str.14.134.831, i64 0, i64 0)) #51
+  unreachable
+
+40:                                               ; preds = %37
+  br i1 %34, label %41, label %47
+
+41:                                               ; preds = %40
+  %42 = shl i64 %31, 1
+  %43 = icmp ult i64 %25, %42
+  br i1 %43, label %44, label %47
+
+44:                                               ; preds = %41
+  %45 = icmp ult i64 %42, 9223372036854775807
+  %46 = select i1 %45, i64 %42, i64 9223372036854775807
+  br label %47
+
+47:                                               ; preds = %44, %41, %40
+  %48 = phi i64 [ %46, %44 ], [ %25, %41 ], [ %25, %40 ]
+  %49 = add nuw i64 %48, 1
+  %50 = call noalias i8* @calloc(i64 %49, i64 1) #37
+  switch i64 %23, label %53 [
+    i64 0, label %51
+    i64 -1, label %55
+  ]
+
+51:                                               ; preds = %47
+  %52 = load atomic i8, i8* %27 unordered, align 1, !tbaa !50
+  store i8 %52, i8* %50, align 1, !tbaa !50
+  br label %55
+
+53:                                               ; preds = %47
+  %54 = add nuw i64 %23, 1
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* align 1 %50, i8* align 1 %27, i64 %54, i1 false) #37
+  br label %55
+
+55:                                               ; preds = %53, %51, %47
+  br i1 %28, label %57, label %56
+
+56:                                               ; preds = %55
+  call void @free(i8* %27) #37
+  br label %57
+
+57:                                               ; preds = %56, %55
+  store i8* %50, i8** %26, align 8, !tbaa !47
+  %58 = getelementptr inbounds %"class.std::__cxx11::basic_string", %"class.std::__cxx11::basic_string"* %2, i64 0, i32 2, i32 0
+  store i64 %48, i64* %58, align 8, !tbaa !50
   br label %_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE7reserveEm.exit
 
-_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE7reserveEm.exit: ; preds = %25, %12
-  %31 = getelementptr inbounds i16, i16* %14, i64 %22
-  %32 = icmp eq i16* %31, %14
-  br i1 %32, label %.loopexit, label %.preheader
+59:                                               ; preds = %33
+  br i1 %28, label %_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE7reserveEm.exit, label %60
 
-.preheader:                                       ; preds = %57, %_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE7reserveEm.exit
-  %33 = phi i16* [ %59, %57 ], [ %14, %_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE7reserveEm.exit ]
-  %34 = getelementptr inbounds i16, i16* %33, i64 1
-  %35 = load i16, i16* %33, align 2, !tbaa !34
-  %36 = zext i16 %35 to i32
-  %37 = and i32 %36, 64512
-  %38 = icmp eq i32 %37, 55296
-  br i1 %38, label %39, label %54
+60:                                               ; preds = %59
+  switch i64 %23, label %63 [
+    i64 0, label %61
+    i64 -1, label %65
+  ]
 
-39:                                               ; preds = %.preheader
-  %40 = icmp eq i16* %34, %31
-  br i1 %40, label %41, label %43
+61:                                               ; preds = %60
+  %62 = load atomic i8, i8* %27 unordered, align 1, !tbaa !50
+  store i8 %62, i8* %19, align 8, !tbaa !50
+  br label %65
 
-41:                                               ; preds = %39
-  %42 = call fastcc %"class.std::__cxx11::basic_string"* @_ZN4utf89unchecked6appendISt20back_insert_iteratorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEEEEET_jSD_(i32 65533, %"class.std::__cxx11::basic_string"* nonnull %2)
+63:                                               ; preds = %60
+  %64 = add nuw i64 %23, 1
+  call void @llvm.memcpy.p0i8.p0i8.i64(i8* nonnull align 8 %19, i8* align 1 %27, i64 %64, i1 false) #37
+  br label %65
+
+65:                                               ; preds = %63, %61, %60
+  call void @free(i8* %27) #37
+  store %union.anon.108* %16, %union.anon.108** %17, align 8, !tbaa !47
+  br label %_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE7reserveEm.exit
+
+_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE7reserveEm.exit: ; preds = %65, %59, %57, %12
+  %66 = load atomic i32, i32* %20 unordered, align 8, !tbaa !18
+  %67 = zext i32 %66 to i64
+  %68 = getelementptr inbounds i16, i16* %14, i64 %67
+  %69 = icmp eq i16* %68, %14
+  br i1 %69, label %.loopexit, label %.preheader
+
+.preheader:                                       ; preds = %94, %_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE7reserveEm.exit
+  %70 = phi i16* [ %96, %94 ], [ %14, %_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE7reserveEm.exit ]
+  %71 = getelementptr inbounds i16, i16* %70, i64 1
+  %72 = load atomic i16, i16* %70 unordered, align 2, !tbaa !27
+  %73 = zext i16 %72 to i32
+  %74 = and i32 %73, 64512
+  %75 = icmp eq i32 %74, 55296
+  br i1 %75, label %76, label %91
+
+76:                                               ; preds = %.preheader
+  %77 = icmp eq i16* %71, %68
+  br i1 %77, label %78, label %80
+
+78:                                               ; preds = %76
+  %79 = call fastcc %"class.std::__cxx11::basic_string"* @_ZN4utf89unchecked6appendISt20back_insert_iteratorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEEEEET_jSD_(i32 65533, %"class.std::__cxx11::basic_string"* nonnull %2)
   br label %.loopexit
 
-43:                                               ; preds = %39
-  %44 = load i16, i16* %34, align 2, !tbaa !34
-  %45 = zext i16 %44 to i32
-  %46 = and i32 %45, 64512
-  %47 = icmp eq i32 %46, 56320
-  %48 = shl nuw nsw i32 %36, 10
-  %49 = add nsw i32 %48, -56613888
-  %50 = add nsw i32 %49, %45
-  %51 = getelementptr inbounds i16, i16* %33, i64 2
-  %52 = select i1 %47, i32 %50, i32 65533
-  %53 = select i1 %47, i16* %51, i16* %34
-  br label %57
+80:                                               ; preds = %76
+  %81 = load atomic i16, i16* %71 unordered, align 2, !tbaa !27
+  %82 = zext i16 %81 to i32
+  %83 = and i32 %82, 64512
+  %84 = icmp eq i32 %83, 56320
+  %85 = shl nuw nsw i32 %73, 10
+  %86 = add nsw i32 %85, -56613888
+  %87 = add nsw i32 %86, %82
+  %88 = getelementptr inbounds i16, i16* %70, i64 2
+  %89 = select i1 %84, i32 %87, i32 65533
+  %90 = select i1 %84, i16* %88, i16* %71
+  br label %94
 
-54:                                               ; preds = %.preheader
-  %55 = icmp eq i32 %37, 56320
-  %56 = select i1 %55, i32 65533, i32 %36
-  br label %57
+91:                                               ; preds = %.preheader
+  %92 = icmp eq i32 %74, 56320
+  %93 = select i1 %92, i32 65533, i32 %73
+  br label %94
 
-57:                                               ; preds = %54, %43
-  %58 = phi i32 [ %52, %43 ], [ %56, %54 ]
-  %59 = phi i16* [ %53, %43 ], [ %34, %54 ]
-  %60 = call fastcc %"class.std::__cxx11::basic_string"* @_ZN4utf89unchecked6appendISt20back_insert_iteratorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEEEEET_jSD_(i32 %58, %"class.std::__cxx11::basic_string"* nonnull %2)
-  %61 = icmp eq i16* %59, %31
-  br i1 %61, label %.loopexit, label %.preheader
+94:                                               ; preds = %91, %80
+  %95 = phi i32 [ %89, %80 ], [ %93, %91 ]
+  %96 = phi i16* [ %90, %80 ], [ %71, %91 ]
+  %97 = call fastcc %"class.std::__cxx11::basic_string"* @_ZN4utf89unchecked6appendISt20back_insert_iteratorINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEEEEET_jSD_(i32 %95, %"class.std::__cxx11::basic_string"* nonnull %2)
+  %98 = icmp eq i16* %96, %68
+  br i1 %98, label %.loopexit, label %.preheader
 
-.loopexit:                                        ; preds = %57, %41, %_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE7reserveEm.exit
-  %62 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
-  %63 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %62, i64 328
-  %64 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %63 to i32*
-  %65 = atomicrmw xchg i32* %64, i32 1 seq_cst, align 4
-  %66 = load i8*, i8** %23, align 8, !tbaa !58
-  %67 = load i64, i64* %18, align 8, !tbaa !60
-  %68 = and i64 %67, 4294967295
-  %69 = invoke i64 @write(i32 1, i8* %66, i64 %68)
-          to label %_ZN5konan16consoleWriteUtf8EPKcj.exit unwind label %86
+.loopexit:                                        ; preds = %94, %78, %_ZNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE7reserveEm.exit
+  %99 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
+  %100 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %99, i64 328
+  %101 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %100 to i32*
+  %102 = atomicrmw xchg i32* %101, i32 1 seq_cst, align 4
+  %103 = load atomic i8*, i8** %26 unordered, align 8, !tbaa !47
+  %104 = load atomic i64, i64* %18 unordered, align 8, !tbaa !51
+  %105 = and i64 %104, 4294967295
+  %106 = invoke i64 @write(i32 1, i8* %103, i64 %105)
+          to label %_ZN5konan16consoleWriteUtf8EPKcj.exit unwind label %123
 
 _ZN5konan16consoleWriteUtf8EPKcj.exit:            ; preds = %.loopexit
-  %70 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %62, null
-  br i1 %70, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %71
+  %107 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %99, null
+  br i1 %107, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %108
 
-71:                                               ; preds = %_ZN5konan16consoleWriteUtf8EPKcj.exit
-  %72 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %63 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %73 = atomicrmw xchg i32* %64, i32 %65 seq_cst, align 4
-  %74 = icmp eq i32 %73, 1
-  %75 = icmp eq i32 %65, 0
-  %76 = and i1 %75, %74
-  br i1 %76, label %77, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
+108:                                              ; preds = %_ZN5konan16consoleWriteUtf8EPKcj.exit
+  %109 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %100 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %110 = atomicrmw xchg i32* %101, i32 %102 seq_cst, align 4
+  %111 = icmp eq i32 %110, 1
+  %112 = icmp eq i32 %102, 0
+  %113 = and i1 %112, %111
+  br i1 %113, label %114, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-77:                                               ; preds = %71
-  %78 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %79 = and i8 %78, 1
-  %80 = icmp eq i8 %79, 0
-  br i1 %80, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %81
+114:                                              ; preds = %108
+  %115 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %116 = and i8 %115, 1
+  %117 = icmp eq i8 %116, 0
+  br i1 %117, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit, label %118
 
-81:                                               ; preds = %77
-  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %72) #37
+118:                                              ; preds = %114
+  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %109) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %81, %77, %71, %_ZN5konan16consoleWriteUtf8EPKcj.exit
-  %82 = load i8*, i8** %23, align 8, !tbaa !58
-  %83 = icmp eq i8* %82, %19
-  br i1 %83, label %85, label %84
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit: ; preds = %118, %114, %108, %_ZN5konan16consoleWriteUtf8EPKcj.exit
+  %119 = load atomic i8*, i8** %26 unordered, align 8, !tbaa !47
+  %120 = icmp eq i8* %119, %19
+  br i1 %120, label %122, label %121
 
-84:                                               ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
-  call void @free(i8* %82) #37
-  br label %85
+121:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
+  call void @free(i8* %119) #37
+  br label %122
 
-85:                                               ; preds = %84, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
+122:                                              ; preds = %121, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %15) #37
   ret void
 
-86:                                               ; preds = %.loopexit
-  %87 = landingpad { i8*, i32 }
+123:                                              ; preds = %.loopexit
+  %124 = landingpad { i8*, i32 }
           cleanup
-  %88 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %62, null
-  br i1 %88, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit8, label %89
+  %125 = icmp eq %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %99, null
+  br i1 %125, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit8, label %126
 
-89:                                               ; preds = %86
-  %90 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %63 to %"class.kotlin::mm::ThreadSuspensionData.37"*
-  %91 = atomicrmw xchg i32* %64, i32 %65 seq_cst, align 4
-  %92 = icmp eq i32 %91, 1
-  %93 = icmp eq i32 %65, 0
-  %94 = and i1 %93, %92
-  br i1 %94, label %95, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit8
+126:                                              ; preds = %123
+  %127 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %100 to %"class.kotlin::mm::ThreadSuspensionData.37"*
+  %128 = atomicrmw xchg i32* %101, i32 %102 seq_cst, align 4
+  %129 = icmp eq i32 %128, 1
+  %130 = icmp eq i32 %102, 0
+  %131 = and i1 %130, %129
+  br i1 %131, label %132, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit8
 
-95:                                               ; preds = %89
-  %96 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %97 = and i8 %96, 1
-  %98 = icmp eq i8 %97, 0
-  br i1 %98, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit8, label %99
+132:                                              ; preds = %126
+  %133 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %134 = and i8 %133, 1
+  %135 = icmp eq i8 %134, 0
+  br i1 %135, label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit8, label %136
 
-99:                                               ; preds = %95
-  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %90) #37
+136:                                              ; preds = %132
+  call void @_ZN6kotlin2mm20ThreadSuspensionData26suspendIfRequestedSlowPathEv(%"class.kotlin::mm::ThreadSuspensionData.37"* nonnull %127) #37
   br label %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit8
 
-_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit8: ; preds = %99, %95, %89, %86
-  %100 = load i8*, i8** %23, align 8, !tbaa !58
-  %101 = icmp eq i8* %100, %19
-  br i1 %101, label %103, label %102
+_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit8: ; preds = %136, %132, %126, %123
+  %137 = load atomic i8*, i8** %26 unordered, align 8, !tbaa !47
+  %138 = icmp eq i8* %137, %19
+  br i1 %138, label %140, label %139
 
-102:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit8
-  call void @free(i8* %100) #37
-  br label %103
+139:                                              ; preds = %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit8
+  call void @free(i8* %137) #37
+  br label %140
 
-103:                                              ; preds = %102, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit8
+140:                                              ; preds = %139, %_ZN6kotlin17SwitchThreadStateEP11MemoryStateNS_11ThreadStateEb.exit8
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %15) #37
-  resume { i8*, i32 } %87
+  resume { i8*, i32 } %124
 }
 
 ; Function Attrs: uwtable
 define internal fastcc void @Kotlin_io_Console_println(%struct.ArrayHeader* %0) unnamed_addr #20 personality i32 (...)* @__gxx_personality_v0 {
   tail call fastcc void @Kotlin_io_Console_print(%struct.ArrayHeader* %0)
-  %2 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**), align 8, !tbaa !3
+  %2 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** bitcast (%"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E to %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"**) unordered, align 8, !tbaa !3
   %3 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %2, i64 328
   %4 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %3 to i32*
   %5 = atomicrmw xchg i32* %4, i32 1 seq_cst, align 4
@@ -55042,7 +55996,7 @@
   %5 = alloca [4 x %struct.ObjHeader*], align 8
   %6 = alloca %class.ObjHolder, align 8
   tail call fastcc void @Kotlin_initRuntimeIfNeeded() #37
-  %7 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %7 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %8 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %7, i64 0, i32 1, i32 8
   %9 = getelementptr inbounds %"class.kotlin::mm::ThreadSuspensionData.37", %"class.kotlin::mm::ThreadSuspensionData.37"* %8, i64 0, i32 0, i32 0
   %10 = atomicrmw xchg i32* %9, i32 0 seq_cst, align 4
@@ -55063,11 +56017,11 @@
   %17 = bitcast %class.ObjHolder* %6 to i8*
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %17) #37
   %18 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %6, i64 0, i32 1
-  store %struct.ObjHeader* null, %struct.ObjHeader** %18, align 8, !tbaa !61
-  %19 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  store %struct.ObjHeader* null, %struct.ObjHeader** %18, align 8, !tbaa !60
+  %19 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   %20 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %19, i64 0, i32 1, i32 5
   %21 = bitcast %"class.kotlin::mm::ShadowStack"* %20 to i64*
-  %22 = load i64, i64* %21, align 8, !tbaa !7
+  %22 = load atomic i64, i64* %21 unordered, align 8, !tbaa !7
   %23 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %6, i64 0, i32 0, i32 1
   %24 = bitcast %struct.FrameOverlay.6** %23 to i64*
   store i64 %22, i64* %24, align 8, !tbaa !9
@@ -55083,7 +56037,7 @@
 
 30:                                               ; preds = %Kotlin_mm_switchThreadStateRunnable.exit
   invoke fastcc void @ThrowIllegalArgumentException() #50
-          to label %.noexc unwind label %113
+          to label %.noexc unwind label %115
 
 .noexc:                                           ; preds = %30
   unreachable
@@ -55091,7 +56045,7 @@
 AllocArrayInstance.exit.i:                        ; preds = %Kotlin_mm_switchThreadStateRunnable.exit
   %31 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %19, i64 0, i32 1, i32 6
   %32 = bitcast %"class.kotlin::gc::GC::ThreadData.34"* %31 to %"class.kotlin::gc::GC::ThreadData::Impl.115"**
-  %33 = load %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %32, align 8, !tbaa !3
+  %33 = load atomic %"class.kotlin::gc::GC::ThreadData::Impl.115"*, %"class.kotlin::gc::GC::ThreadData::Impl.115"** %32 unordered, align 8, !tbaa !3
   %34 = zext i32 %28 to i64
   %35 = shl nuw nsw i64 %34, 3
   %36 = add nuw nsw i64 %35, 31
@@ -55113,10 +56067,7 @@
   br i1 %.not, label %AllocArrayInstance.exit.i._Z9setupArgsiPPKcPP9ObjHeader.exit_crit_edge, label %47
 
 AllocArrayInstance.exit.i._Z9setupArgsiPPKcPP9ObjHeader.exit_crit_edge: ; preds = %AllocArrayInstance.exit.i
-  %.pre5 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %.phi.trans.insert6 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %.pre5, i64 0, i32 1, i32 5
-  %.phi.trans.insert7 = bitcast %"class.kotlin::mm::ShadowStack"* %.phi.trans.insert6 to i64*
-  %.pre8 = load i64, i64* %.phi.trans.insert7, align 8, !tbaa !7
+  %.pre3 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   br label %_Z9setupArgsiPPKcPP9ObjHeader.exit
 
 47:                                               ; preds = %AllocArrayInstance.exit.i
@@ -55129,160 +56080,159 @@
   %54 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %4, i64 0, i32 0, i32 2
   %55 = getelementptr inbounds %class.ObjHolder, %class.ObjHolder* %4, i64 0, i32 0, i32 3
   %56 = bitcast %struct.ObjHeader** %49 to i64*
-  %.pre = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %.phi.trans.insert = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %.pre, i64 0, i32 1, i32 5
-  %.phi.trans.insert3 = bitcast %"class.kotlin::mm::ShadowStack"* %.phi.trans.insert to i64*
-  %.pre4 = load i64, i64* %.phi.trans.insert3, align 8, !tbaa !7
+  %.pre = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   br label %57
 
-57:                                               ; preds = %66, %47
-  %58 = phi i64 [ %.pre4, %47 ], [ %73, %66 ]
-  %59 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %.pre, %47 ], [ %71, %66 ]
-  %60 = phi i64 [ 1, %47 ], [ %75, %66 ]
+57:                                               ; preds = %67, %47
+  %58 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %.pre, %47 ], [ %72, %67 ]
+  %59 = phi i64 [ 1, %47 ], [ %76, %67 ]
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %48) #37
-  store %struct.ObjHeader* null, %struct.ObjHeader** %49, align 8, !tbaa !61
-  %61 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %59, i64 0, i32 1, i32 5
-  store i64 %58, i64* %53, align 8, !tbaa !9
-  %62 = bitcast %"class.kotlin::mm::ShadowStack"* %61 to %class.ObjHolder**
-  store %class.ObjHolder* %4, %class.ObjHolder** %62, align 8, !tbaa !7
+  store %struct.ObjHeader* null, %struct.ObjHeader** %49, align 8, !tbaa !60
+  %60 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %58, i64 0, i32 1, i32 5
+  %61 = bitcast %"class.kotlin::mm::ShadowStack"* %60 to i64*
+  %62 = load atomic i64, i64* %61 unordered, align 8, !tbaa !7
+  store i64 %62, i64* %53, align 8, !tbaa !9
+  %63 = bitcast %"class.kotlin::mm::ShadowStack"* %60 to %class.ObjHolder**
+  store %class.ObjHolder* %4, %class.ObjHolder** %63, align 8, !tbaa !7
   store i32 0, i32* %54, align 8, !tbaa !12
   store i32 4, i32* %55, align 4, !tbaa !13
-  %63 = getelementptr inbounds i8*, i8** %1, i64 %60
-  %64 = load i8*, i8** %63, align 8, !tbaa !3
-  %65 = invoke fastcc %struct.ObjHeader* @CreateStringFromCString(i8* %64, %struct.ObjHeader** nonnull %49)
-          to label %66 unwind label %77
+  %64 = getelementptr inbounds i8*, i8** %1, i64 %59
+  %65 = load atomic i8*, i8** %64 unordered, align 8, !tbaa !3
+  %66 = invoke fastcc %struct.ObjHeader* @CreateStringFromCString(i8* %65, %struct.ObjHeader** nonnull %49)
+          to label %67 unwind label %78
 
-66:                                               ; preds = %57
-  %67 = add nsw i64 %60, -1
-  %68 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %50, i64 %67
-  %69 = load i64, i64* %56, align 8, !tbaa !61
-  %70 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %68 to i64*
-  store i64 %69, i64* %70, align 8, !tbaa !3
-  %71 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %72 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %71, i64 0, i32 1, i32 5
-  %73 = load i64, i64* %53, align 8, !tbaa !9
-  %74 = bitcast %"class.kotlin::mm::ShadowStack"* %72 to i64*
-  store i64 %73, i64* %74, align 8, !tbaa !7
+67:                                               ; preds = %57
+  %68 = add nsw i64 %59, -1
+  %69 = getelementptr inbounds %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node", %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %50, i64 %68
+  %70 = load atomic i64, i64* %56 unordered, align 8, !tbaa !60
+  %71 = bitcast %"class.kotlin::mm::internal::ObjectFactoryStorage<8, kotlin::gc::AllocatorWithGC<kotlin::gc::Allocator, kotlin::gc::ConcurrentMarkAndSweep::ThreadData>>::Node"* %69 to i64*
+  store i64 %70, i64* %71, align 8, !tbaa !3
+  %72 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %73 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %72, i64 0, i32 1, i32 5
+  %74 = load atomic i64, i64* %53 unordered, align 8, !tbaa !9
+  %75 = bitcast %"class.kotlin::mm::ShadowStack"* %73 to i64*
+  store i64 %74, i64* %75, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %48) #37
-  %75 = add nuw nsw i64 %60, 1
-  %76 = icmp eq i64 %75, %51
-  br i1 %76, label %_Z9setupArgsiPPKcPP9ObjHeader.exit, label %57
+  %76 = add nuw nsw i64 %59, 1
+  %77 = icmp eq i64 %76, %51
+  br i1 %77, label %_Z9setupArgsiPPKcPP9ObjHeader.exit, label %57
 
-77:                                               ; preds = %57
-  %78 = landingpad { i8*, i32 }
+78:                                               ; preds = %57
+  %79 = landingpad { i8*, i32 }
           cleanup
-  %79 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %80 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %79, i64 0, i32 1, i32 5
-  %81 = load i64, i64* %53, align 8, !tbaa !9
-  %82 = bitcast %"class.kotlin::mm::ShadowStack"* %80 to i64*
-  store i64 %81, i64* %82, align 8, !tbaa !7
+  %80 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %81 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %80, i64 0, i32 1, i32 5
+  %82 = load atomic i64, i64* %53 unordered, align 8, !tbaa !9
+  %83 = bitcast %"class.kotlin::mm::ShadowStack"* %81 to i64*
+  store i64 %82, i64* %83, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %48) #37
   br label %.body
 
-_Z9setupArgsiPPKcPP9ObjHeader.exit:               ; preds = %66, %AllocArrayInstance.exit.i._Z9setupArgsiPPKcPP9ObjHeader.exit_crit_edge
-  %83 = phi i64 [ %.pre8, %AllocArrayInstance.exit.i._Z9setupArgsiPPKcPP9ObjHeader.exit_crit_edge ], [ %73, %66 ]
-  %84 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %.pre5, %AllocArrayInstance.exit.i._Z9setupArgsiPPKcPP9ObjHeader.exit_crit_edge ], [ %71, %66 ]
+_Z9setupArgsiPPKcPP9ObjHeader.exit:               ; preds = %67, %AllocArrayInstance.exit.i._Z9setupArgsiPPKcPP9ObjHeader.exit_crit_edge
+  %84 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %.pre3, %AllocArrayInstance.exit.i._Z9setupArgsiPPKcPP9ObjHeader.exit_crit_edge ], [ %72, %67 ]
   %85 = bitcast [4 x %struct.ObjHeader*]* %5 to i8*
   call void @llvm.lifetime.start.p0i8(i64 32, i8* nonnull %85)
   %.sub.i = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %5, i64 0, i64 0
   call void @llvm.memset.p0i8.i32(i8* nocapture nonnull writeonly align 8 dereferenceable(32) %85, i8 0, i32 32, i1 immarg false) #49
   %86 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %84, i64 0, i32 1, i32 5
   %87 = bitcast [4 x %struct.ObjHeader*]* %5 to %struct.FrameOverlay.6*
-  %88 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %5, i64 0, i64 1
-  %89 = bitcast %struct.ObjHeader** %88 to i64*
-  store i64 %83, i64* %89, align 8, !tbaa !9
-  %90 = bitcast %"class.kotlin::mm::ShadowStack"* %86 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %90, align 8, !tbaa !7
-  %91 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %5, i64 0, i64 2
-  %92 = bitcast %struct.ObjHeader** %91 to i32*
-  store i32 0, i32* %92, align 8, !tbaa !12
-  %93 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %87, i64 0, i32 3
-  store i32 4, i32* %93, align 4, !tbaa !13
-  %94 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
-  %95 = and i8 %94, 1
-  %96 = icmp eq i8 %95, 0
-  br i1 %96, label %Kotlin_mm_safePointFunctionPrologue.exit, label %97
+  %88 = bitcast %"class.kotlin::mm::ShadowStack"* %86 to i64*
+  %89 = load atomic i64, i64* %88 unordered, align 8, !tbaa !7
+  %90 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %5, i64 0, i64 1
+  %91 = bitcast %struct.ObjHeader** %90 to i64*
+  store i64 %89, i64* %91, align 8, !tbaa !9
+  %92 = bitcast %"class.kotlin::mm::ShadowStack"* %86 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %92, align 8, !tbaa !7
+  %93 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %5, i64 0, i64 2
+  %94 = bitcast %struct.ObjHeader** %93 to i32*
+  store i32 0, i32* %94, align 8, !tbaa !12
+  %95 = getelementptr inbounds %struct.FrameOverlay.6, %struct.FrameOverlay.6* %87, i64 0, i32 3
+  store i32 4, i32* %95, align 4, !tbaa !13
+  %96 = load atomic i8, i8* getelementptr inbounds (%"struct.std::atomic_flag", %"struct.std::atomic_flag"* @_ZN6kotlin2mm8internal20gSuspensionRequestedE, i64 0, i32 0, i32 0) seq_cst, align 1
+  %97 = and i8 %96, 1
+  %98 = icmp eq i8 %97, 0
+  br i1 %98, label %Kotlin_mm_safePointFunctionPrologue.exit, label %99
 
-97:                                               ; preds = %_Z9setupArgsiPPKcPP9ObjHeader.exit
+99:                                               ; preds = %_Z9setupArgsiPPKcPP9ObjHeader.exit
   call fastcc void @_ZN6kotlin2mm26SuspendIfRequestedSlowPathEv() #37
   br label %Kotlin_mm_safePointFunctionPrologue.exit
 
-Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %97, %_Z9setupArgsiPPKcPP9ObjHeader.exit
+Kotlin_mm_safePointFunctionPrologue.exit:         ; preds = %99, %_Z9setupArgsiPPKcPP9ObjHeader.exit
   invoke fastcc void @"kfun:#main(){}"() #56
-          to label %119 unwind label %landingpad.i
+          to label %121 unwind label %landingpad.i
 
 landingpad.i:                                     ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
   %lp.i = landingpad { i8*, i32 }
           catch i8* null
-  %98 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %5, i64 0, i64 3
-  %99 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %100 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %99, i64 0, i32 1, i32 5
-  %101 = bitcast %"class.kotlin::mm::ShadowStack"* %100 to %struct.ObjHeader***
-  store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %101, align 8, !tbaa !7
+  %100 = getelementptr inbounds [4 x %struct.ObjHeader*], [4 x %struct.ObjHeader*]* %5, i64 0, i64 3
+  %101 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %102 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %101, i64 0, i32 1, i32 5
+  %103 = bitcast %"class.kotlin::mm::ShadowStack"* %102 to %struct.ObjHeader***
+  store %struct.ObjHeader** %.sub.i, %struct.ObjHeader*** %103, align 8, !tbaa !7
   %er.i = extractvalue { i8*, i32 } %lp.i, 0
-  %102 = call i8* @__cxa_begin_catch(i8* %er.i) #37
-  %103 = getelementptr inbounds i8, i8* %102, i64 8
-  %104 = bitcast i8* %103 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"**
-  %105 = load %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %104, align 8, !tbaa !65
-  %106 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %105, i64 0, i32 0
-  %107 = load %struct.ObjHeader*, %struct.ObjHeader** %106, align 8, !tbaa !3
-  store %struct.ObjHeader* %107, %struct.ObjHeader** %98, align 8, !tbaa !3
+  %104 = call i8* @__cxa_begin_catch(i8* %er.i) #37
+  %105 = getelementptr inbounds i8, i8* %104, i64 8
+  %106 = bitcast i8* %105 to %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"**
+  %107 = load atomic %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"*, %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"** %106 unordered, align 8, !tbaa !64
+  %108 = getelementptr inbounds %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node", %"class.kotlin::MultiSourceQueue<ObjHeader *, kotlin::SpinLock<MutexThreadStateHandling::kIgnore>, kotlin::std_support::allocator<ObjHeader *>>::Node"* %107, i64 0, i32 0
+  %109 = load atomic %struct.ObjHeader*, %struct.ObjHeader** %108 unordered, align 8, !tbaa !3
+  store %struct.ObjHeader* %109, %struct.ObjHeader** %100, align 8, !tbaa !3
   call void @__cxa_end_catch() #37
-  call fastcc void @_ZN12_GLOBAL__N_125processUnhandledExceptionEP9ObjHeader(%struct.ObjHeader* %107) #37
-  invoke fastcc void @Kotlin_terminateWithUnhandledException(%struct.ObjHeader* %107) #50
+  call fastcc void @_ZN12_GLOBAL__N_125processUnhandledExceptionEP9ObjHeader(%struct.ObjHeader* %109) #37
+  invoke fastcc void @Kotlin_terminateWithUnhandledException(%struct.ObjHeader* %109) #50
           to label %call_success2.i unwind label %cleanup_landingpad.i
 
 call_success2.i:                                  ; preds = %landingpad.i
   unreachable
 
 cleanup_landingpad.i:                             ; preds = %landingpad.i
-  %108 = landingpad { i8*, i32 }
+  %110 = landingpad { i8*, i32 }
           cleanup
-  %109 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %110 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %109, i64 0, i32 1, i32 5
-  %111 = load i64, i64* %89, align 8, !tbaa !9
-  %112 = bitcast %"class.kotlin::mm::ShadowStack"* %110 to i64*
-  store i64 %111, i64* %112, align 8, !tbaa !7
+  %111 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %112 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %111, i64 0, i32 1, i32 5
+  %113 = load atomic i64, i64* %91 unordered, align 8, !tbaa !9
+  %114 = bitcast %"class.kotlin::mm::ShadowStack"* %112 to i64*
+  store i64 %113, i64* %114, align 8, !tbaa !7
   br label %.body
 
-113:                                              ; preds = %30
-  %114 = landingpad { i8*, i32 }
+115:                                              ; preds = %30
+  %116 = landingpad { i8*, i32 }
           cleanup
-  %.pre9 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
+  %.pre4 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
   br label %.body
 
-.body:                                            ; preds = %113, %cleanup_landingpad.i, %77
-  %115 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %109, %cleanup_landingpad.i ], [ %.pre9, %113 ], [ %79, %77 ]
-  %eh.lpad-body = phi { i8*, i32 } [ %108, %cleanup_landingpad.i ], [ %114, %113 ], [ %78, %77 ]
-  %116 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %115, i64 0, i32 1, i32 5
-  %117 = load i64, i64* %24, align 8, !tbaa !9
-  %118 = bitcast %"class.kotlin::mm::ShadowStack"* %116 to i64*
-  store i64 %117, i64* %118, align 8, !tbaa !7
+.body:                                            ; preds = %115, %cleanup_landingpad.i, %78
+  %117 = phi %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* [ %111, %cleanup_landingpad.i ], [ %.pre4, %115 ], [ %80, %78 ]
+  %eh.lpad-body = phi { i8*, i32 } [ %110, %cleanup_landingpad.i ], [ %116, %115 ], [ %79, %78 ]
+  %118 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %117, i64 0, i32 1, i32 5
+  %119 = load atomic i64, i64* %24 unordered, align 8, !tbaa !9
+  %120 = bitcast %"class.kotlin::mm::ShadowStack"* %118 to i64*
+  store i64 %119, i64* %120, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %17) #37
   resume { i8*, i32 } %eh.lpad-body
 
-119:                                              ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
-  %120 = load %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E, align 8, !tbaa !3
-  %121 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %120, i64 0, i32 1, i32 5
-  %122 = bitcast %"class.kotlin::mm::ShadowStack"* %121 to i64*
+121:                                              ; preds = %Kotlin_mm_safePointFunctionPrologue.exit
+  %122 = load atomic %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"*, %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"** @_ZN6kotlin2mm14ThreadRegistry22currentThreadDataNode_E unordered, align 8, !tbaa !3
+  %123 = getelementptr inbounds %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node", %"class.kotlin::SingleLockList<kotlin::mm::ThreadData, std::recursive_mutex, kotlin::std_support::allocator<kotlin::mm::ThreadData>>::Node"* %122, i64 0, i32 1, i32 5
+  %124 = bitcast %"class.kotlin::mm::ShadowStack"* %123 to i64*
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %85)
-  %123 = load i64, i64* %24, align 8, !tbaa !9
-  store i64 %123, i64* %122, align 8, !tbaa !7
+  %125 = load atomic i64, i64* %24 unordered, align 8, !tbaa !9
+  store i64 %125, i64* %124, align 8, !tbaa !7
   call void @llvm.lifetime.end.p0i8(i64 32, i8* nonnull %17) #37
-  %124 = icmp eq i32 %2, 0
-  br i1 %124, label %133, label %125
+  %126 = icmp eq i32 %2, 0
+  br i1 %126, label %135, label %127
 
-125:                                              ; preds = %119
-  %126 = load %"struct.(anonymous namespace)::RuntimeState"*, %"struct.(anonymous namespace)::RuntimeState"** @_ZN12_GLOBAL__N_112runtimeStateE, align 8, !tbaa !3
-  %127 = cmpxchg volatile i32* @_ZN12_GLOBAL__N_119globalRuntimeStatusE, i32 1, i32 2 seq_cst seq_cst, align 4
-  %128 = getelementptr inbounds %"struct.(anonymous namespace)::RuntimeState", %"struct.(anonymous namespace)::RuntimeState"* %126, i64 0, i32 0
-  %129 = load %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %128, align 8, !tbaa !699
-  %130 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %129, i64 328
-  %131 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %130 to i32*
-  %132 = atomicrmw xchg i32* %131, i32 1 seq_cst, align 4
-  br label %133
+127:                                              ; preds = %121
+  %128 = load atomic %"struct.(anonymous namespace)::RuntimeState"*, %"struct.(anonymous namespace)::RuntimeState"** @_ZN12_GLOBAL__N_112runtimeStateE unordered, align 8, !tbaa !3
+  %129 = cmpxchg volatile i32* @_ZN12_GLOBAL__N_119globalRuntimeStatusE, i32 1, i32 2 seq_cst seq_cst, align 4
+  %130 = getelementptr inbounds %"struct.(anonymous namespace)::RuntimeState", %"struct.(anonymous namespace)::RuntimeState"* %128, i64 0, i32 0
+  %131 = load atomic %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"*, %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"** %130 unordered, align 8, !tbaa !711
+  %132 = getelementptr inbounds %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte", %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %131, i64 328
+  %133 = bitcast %"struct.std::_Optional_payload<unsigned long, true, true, true>::_Empty_byte"* %132 to i32*
+  %134 = atomicrmw xchg i32* %133, i32 1 seq_cst, align 4
+  br label %135
 
-133:                                              ; preds = %125, %119
+135:                                              ; preds = %127, %121
   ret i32 0
 }
 
@@ -55374,742 +56324,756 @@
 !18 = !{!17, !11, i64 8}
 !19 = !{!20, !11, i64 92}
 !20 = !{!"_ZTS8TypeInfo", !4, i64 0, !4, i64 8, !11, i64 16, !11, i64 20, !4, i64 24, !4, i64 32, !11, i64 40, !4, i64 48, !11, i64 56, !11, i64 60, !4, i64 64, !4, i64 72, !4, i64 80, !11, i64 88, !11, i64 92, !4, i64 96, !4, i64 104}
-!21 = !{!22}
-!22 = distinct !{!22, !23}
-!23 = distinct !{!23, !"LVerDomain"}
-!24 = !{!25}
-!25 = distinct !{!25, !23}
-!26 = distinct !{!26, !27}
-!27 = !{!"llvm.loop.isvectorized", i32 1}
-!28 = distinct !{!28, !29}
-!29 = !{!"llvm.loop.unroll.disable"}
-!30 = distinct !{!30, !27}
-!31 = !{i32 0, i32 33}
-!32 = distinct !{!32, !27}
-!33 = distinct !{!33, !29}
-!34 = !{!35, !35, i64 0}
-!35 = !{!"short", !5, i64 0}
-!36 = distinct !{!36, !37, !27}
-!37 = !{!"llvm.loop.unroll.runtime.disable"}
-!38 = !{!39}
-!39 = distinct !{!39, !40, !"_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE: argument 0"}
-!40 = distinct !{!40, !"_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE"}
-!41 = !{!42, !4, i64 0}
-!42 = !{!"_ZTSSt12_Vector_baseINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE", !43, i64 0}
-!43 = !{!"_ZTSNSt12_Vector_baseINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE12_Vector_implE", !4, i64 0, !4, i64 8, !4, i64 16}
-!44 = !{!42, !4, i64 8}
-!45 = !{!42, !4, i64 16}
-!46 = !{!47, !4, i64 0}
-!47 = !{!"_ZTSNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12_Alloc_hiderE", !4, i64 0}
-!48 = !{!49, !50, i64 8}
-!49 = !{!"_ZTSNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE", !47, i64 0, !50, i64 8, !5, i64 16}
-!50 = !{!"long", !5, i64 0}
-!51 = !{!5, !5, i64 0}
-!52 = !{!53, !11, i64 32}
-!53 = !{!"_ZTS10SourceInfo", !49, i64 0, !11, i64 32, !11, i64 36}
-!54 = !{!53, !11, i64 36}
-!55 = !{!49, !4, i64 0}
-!56 = !{!57, !4, i64 0}
-!57 = !{!"_ZTSNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE12_Alloc_hiderE", !4, i64 0}
-!58 = !{!59, !4, i64 0}
-!59 = !{!"_ZTSNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEE", !57, i64 0, !50, i64 8, !5, i64 16}
-!60 = !{!59, !50, i64 8}
-!61 = !{!62, !4, i64 24}
-!62 = !{!"_ZTS9ObjHolder", !10, i64 0, !4, i64 24}
-!63 = distinct !{!63, !27}
-!64 = distinct !{!64, !37, !27}
-!65 = !{!66, !4, i64 8}
-!66 = !{!"_ZTSN12_GLOBAL__N_122ExceptionObjHolderImplE", !4, i64 8}
-!67 = !{!20, !11, i64 88}
-!68 = !{!20, !4, i64 80}
-!69 = !{!20, !4, i64 72}
-!70 = !{!71, !71, i64 0}
-!71 = !{!"bool", !5, i64 0}
-!72 = !{i8 0, i8 2}
-!73 = !{!11, !11, i64 0}
-!74 = distinct !{!74, !27}
-!75 = distinct !{!75, !29}
-!76 = distinct !{!76, !37, !27}
-!77 = !{!78, !71, i64 88}
-!78 = !{!"_ZTSN6kotlin13RepeatedTimerINS_12steady_clockEEE", !79, i64 0, !80, i64 40, !71, i64 88, !81, i64 96, !83, i64 104, !71, i64 112, !84, i64 120}
-!79 = !{!"_ZTSSt5mutex"}
-!80 = !{!"_ZTSSt18condition_variable", !5, i64 0}
-!81 = !{!"_ZTSNSt6chrono8durationIN6kotlin10saturatingIlEESt5ratioILl1ELl1000000000EEEE", !82, i64 0}
-!82 = !{!"_ZTSN6kotlin10saturatingIlEE", !50, i64 0}
-!83 = !{!"_ZTSNSt6chrono10time_pointIN6kotlin12steady_clockENS_8durationINS1_10saturatingIlEESt5ratioILl1ELl1000000000EEEEEE", !81, i64 0}
-!84 = !{!"_ZTSN6kotlin12ScopedThreadE", !85, i64 0}
-!85 = !{!"_ZTSSt6thread", !86, i64 0}
-!86 = !{!"_ZTSNSt6thread2idE", !50, i64 0}
-!87 = !{!78, !71, i64 112}
-!88 = !{i64 0, i64 8, !89}
-!89 = !{!50, !50, i64 0}
-!90 = !{!91, !50, i64 0}
-!91 = !{!"_ZTS8timespec", !50, i64 0, !50, i64 8}
-!92 = !{!91, !50, i64 8}
-!93 = !{!94, !4, i64 0}
-!94 = !{!"_ZTSZN6kotlin2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEC1ERNS0_17GCSchedulerConfigESt8functionIFvvEEEUlvE_", !4, i64 0}
-!95 = !{!96, !4, i64 16}
-!96 = !{!"_ZTSN6kotlin2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEE", !4, i64 8, !4, i64 16, !97, i64 24, !99, i64 48, !101, i64 64, !78, i64 96}
-!97 = !{!"_ZTSN6kotlin2gc8internal20HeapGrowthControllerE", !4, i64 0, !98, i64 8, !98, i64 16}
-!98 = !{!"_ZTSSt6atomicImE"}
-!99 = !{!"_ZTSN6kotlin2gc8internal20RegularIntervalPacerINS_12steady_clockEEE", !4, i64 0, !100, i64 8}
-!100 = !{!"_ZTSSt6atomicINSt6chrono10time_pointIN6kotlin12steady_clockENS0_8durationINS2_10saturatingIlEESt5ratioILl1ELl1000000000EEEEEEE", !83, i64 0}
-!101 = !{!"_ZTSSt8functionIFvvEE", !4, i64 24}
-!102 = !{!99, !4, i64 0}
-!103 = !{!104, !4, i64 16}
-!104 = !{!"_ZTSSt14_Function_base", !5, i64 0, !4, i64 16}
-!105 = !{!101, !4, i64 24}
-!106 = !{!107, !71, i64 32}
-!107 = !{!"_ZTSSt14_Optional_baseINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEELb0ELb0EE", !108, i64 0}
-!108 = !{!"_ZTSSt17_Optional_payloadINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEELb0ELb0ELb0EE", !5, i64 0, !71, i64 32}
-!109 = !{!110, !110, i64 0}
-!110 = !{!"vtable pointer", !6, i64 0}
-!111 = !{}
-!112 = !{!108, !71, i64 32}
-!113 = !{!114, !50, i64 40}
-!114 = !{!"_ZTSN6kotlin2gc21GCSchedulerThreadDataE", !4, i64 0, !115, i64 8, !50, i64 40, !50, i64 48, !50, i64 56, !50, i64 64}
-!115 = !{!"_ZTSSt8functionIFvRN6kotlin2gc21GCSchedulerThreadDataEEE", !4, i64 24}
-!116 = !{!97, !4, i64 0}
-!117 = !{!96, !4, i64 8}
-!118 = !{!119, !11, i64 16}
-!119 = !{!"_ZTSN15pthread_mutex_t17__pthread_mutex_sE", !11, i64 0, !11, i64 4, !11, i64 8, !11, i64 12, !11, i64 16, !35, i64 20, !35, i64 22, !120, i64 24}
-!120 = !{!"_ZTS23__pthread_internal_list", !4, i64 0, !4, i64 8}
-!121 = !{!122, !4, i64 0}
-!122 = !{!"_ZTSSt10_Head_baseILm0EPN6kotlin2mm16AppStateTracking4ImplELb0EE", !4, i64 0}
-!123 = !{!124, !4, i64 8}
-!124 = !{!"_ZTSNSt8__detail15_List_node_baseE", !4, i64 0, !4, i64 8}
-!125 = !{!124, !4, i64 0}
-!126 = !{!127, !50, i64 16}
-!127 = !{!"_ZTSNSt8__detail17_List_node_headerE", !50, i64 16}
-!128 = !{!129, !71, i64 0}
-!129 = !{!"_ZTSSt18__atomic_flag_base", !71, i64 0}
-!130 = !{!131, !133}
-!131 = distinct !{!131, !132, !"_ZN6kotlin11std_support15allocate_uniqueINS_2gc2GC4ImplENS0_9allocatorIS4_EEJEEEDaRKT0_DpOT1_: argument 0"}
-!132 = distinct !{!132, !"_ZN6kotlin11std_support15allocate_uniqueINS_2gc2GC4ImplENS0_9allocatorIS4_EEJEEEDaRKT0_DpOT1_"}
-!133 = distinct !{!133, !134, !"_ZN6kotlin11std_support11make_uniqueINS_2gc2GC4ImplEJEEEDaDpOT0_: argument 0"}
-!134 = distinct !{!134, !"_ZN6kotlin11std_support11make_uniqueINS_2gc2GC4ImplEJEEEDaDpOT0_"}
-!135 = !{!136, !11, i64 0}
-!136 = !{!"_ZTSSt13__atomic_baseIiE", !11, i64 0}
-!137 = !{!138, !50, i64 0}
-!138 = !{!"_ZTSSt13__atomic_baseIlE", !50, i64 0}
-!139 = !{!140, !71, i64 0}
-!140 = !{!"_ZTSSt13__atomic_baseIbE", !71, i64 0}
-!141 = !{!142, !143, i64 0}
-!142 = !{!"_ZTSSt6atomicIdE", !143, i64 0}
-!143 = !{!"double", !5, i64 0}
-!144 = !{!145, !50, i64 0}
-!145 = !{!"_ZTSN13GCStateHolder16ValueWithCondVarIlEE", !50, i64 0, !4, i64 8, !80, i64 16}
-!146 = !{!147, !71, i64 296}
-!147 = !{!"_ZTS13GCStateHolder", !79, i64 0, !145, i64 40, !145, i64 104, !145, i64 168, !145, i64 232, !71, i64 296}
-!148 = !{!86, !50, i64 0}
-!149 = !{!150, !152, !131, !133}
-!150 = distinct !{!150, !151, !"_ZN6kotlin11std_support15allocate_uniqueINS_2gc18FinalizerProcessorENS0_9allocatorIS3_EEJZNS2_22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS6_EERNS2_11GCSchedulerEE3$_1EEEDaRKT0_DpOT1_: argument 0"}
-!151 = distinct !{!151, !"_ZN6kotlin11std_support15allocate_uniqueINS_2gc18FinalizerProcessorENS0_9allocatorIS3_EEJZNS2_22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS6_EERNS2_11GCSchedulerEE3$_1EEEDaRKT0_DpOT1_"}
-!152 = distinct !{!152, !153, !"_ZN6kotlin11std_support11make_uniqueINS_2gc18FinalizerProcessorEJZNS2_22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS4_EERNS2_11GCSchedulerEE3$_1EEEDaDpOT0_: argument 0"}
-!153 = distinct !{!153, !"_ZN6kotlin11std_support11make_uniqueINS_2gc18FinalizerProcessorEJZNS2_22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS4_EERNS2_11GCSchedulerEE3$_1EEEDaDpOT0_"}
-!154 = !{i64 0, i64 8, !51, i64 0, i64 8, !51, i64 0, i64 8, !51, i64 0, i64 16, !51, i64 0, i64 16, !51}
-!155 = !{!156, !50, i64 160}
-!156 = !{!"_ZTSN6kotlin2gc18FinalizerProcessorE", !84, i64 0, !157, i64 8, !80, i64 40, !79, i64 88, !162, i64 128, !50, i64 160, !71, i64 168, !71, i64 169, !79, i64 176, !80, i64 216, !71, i64 264, !79, i64 272}
-!157 = !{!"_ZTSN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE14FinalizerQueueE", !158, i64 8}
-!158 = !{!"_ZTSN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8ConsumerE", !159, i64 0, !4, i64 8, !50, i64 16}
-!159 = !{!"_ZTSSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEE", !160, i64 0}
-!160 = !{!"_ZTSSt15__uniq_ptr_implIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEE", !161, i64 0}
-!161 = !{!"_ZTSSt5tupleIJPN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEEE"}
-!162 = !{!"_ZTSSt8functionIFvlEE", !4, i64 24}
-!163 = !{!156, !71, i64 168}
-!164 = !{!156, !71, i64 169}
-!165 = !{!156, !71, i64 264}
-!166 = !{!167, !4, i64 0}
-!167 = !{!"_ZTSSt10_Head_baseILm0EPN6kotlin2gc18FinalizerProcessorELb0EE", !4, i64 0}
-!168 = !{!150, !152}
-!169 = !{!170, !4, i64 8}
-!170 = !{!"_ZTSN6kotlin2gc22ConcurrentMarkAndSweepE", !4, i64 0, !4, i64 8, !147, i64 16, !84, i64 320, !171, i64 328, !174, i64 336, !175, i64 344}
-!171 = !{!"_ZTSSt10unique_ptrIN6kotlin2gc18FinalizerProcessorENS0_11std_support17allocator_deleterIS2_NS3_9allocatorIS2_EEEEE", !172, i64 0}
-!172 = !{!"_ZTSSt15__uniq_ptr_implIN6kotlin2gc18FinalizerProcessorENS0_11std_support17allocator_deleterIS2_NS3_9allocatorIS2_EEEEE", !173, i64 0}
-!173 = !{!"_ZTSSt5tupleIJPN6kotlin2gc18FinalizerProcessorENS0_11std_support17allocator_deleterIS2_NS4_9allocatorIS2_EEEEEE"}
-!174 = !{!"_ZTSN6kotlin22intrusive_forward_listINS_2gc22ConcurrentMarkAndSweep10ObjectDataENS_33DefaultIntrusiveForwardListTraitsIS3_EEEE", !5, i64 0}
-!175 = !{!"_ZTSN6kotlin2gc22ConcurrentMarkAndSweep15MarkingBehaviorE", !5, i64 0}
-!176 = !{!177, !4, i64 0}
-!177 = !{!"_ZTSSt10_Head_baseILm3EPN6kotlin13RepeatedTimerINS0_12steady_clockEEELb0EE", !4, i64 0}
-!178 = !{!179, !5, i64 0}
-!179 = !{!"_ZTSSt10_Head_baseILm2EMN6kotlin13RepeatedTimerINS0_12steady_clockEEEDoFvOZNS0_2gc8internal24GCSchedulerDataWithTimerIS2_EC1ERNS4_17GCSchedulerConfigESt8functionIFvvEEEUlvE_ELb0EE", !5, i64 0}
-!180 = !{!181, !4, i64 0}
-!181 = !{!"_ZTSSt10_Head_baseILm0EPFvN6kotlin12ScopedThread10attributesEOMNS0_13RepeatedTimerINS0_12steady_clockEEEDoFvOZNS0_2gc8internal24GCSchedulerDataWithTimerIS4_EC1ERNS6_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS5_SG_ELb0EE", !4, i64 0}
-!182 = !{!183}
-!183 = distinct !{!183, !184, !"_ZNSt6thread14__make_invokerIPFvN6kotlin12ScopedThread10attributesEOMNS1_13RepeatedTimerINS1_12steady_clockEEEDoFvOZNS1_2gc8internal24GCSchedulerDataWithTimerIS5_EC1ERNS7_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS6_SH_EJRKS3_SJ_SL_SG_EEENS_8_InvokerISt5tupleIJNSt5decayIT_E4typeEDpNST_IT0_E4typeEEEEEOSU_DpOSX_: argument 0"}
-!184 = distinct !{!184, !"_ZNSt6thread14__make_invokerIPFvN6kotlin12ScopedThread10attributesEOMNS1_13RepeatedTimerINS1_12steady_clockEEEDoFvOZNS1_2gc8internal24GCSchedulerDataWithTimerIS5_EC1ERNS7_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS6_SH_EJRKS3_SJ_SL_SG_EEENS_8_InvokerISt5tupleIJNSt5decayIT_E4typeEDpNST_IT0_E4typeEEEEEOSU_DpOSX_"}
-!185 = !{!186, !131, !133}
-!186 = distinct !{!186, !187, !"_ZNSt6thread13_S_make_stateINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOMNS3_13RepeatedTimerINS3_12steady_clockEEEDoFvOZNS3_2gc8internal24GCSchedulerDataWithTimerIS7_EC1ERNS9_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS8_SJ_ES5_SL_SN_SI_EEEEEESt10unique_ptrINS_6_StateESt14default_deleteISU_EEOT_: argument 0"}
-!187 = distinct !{!187, !"_ZNSt6thread13_S_make_stateINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOMNS3_13RepeatedTimerINS3_12steady_clockEEEDoFvOZNS3_2gc8internal24GCSchedulerDataWithTimerIS7_EC1ERNS9_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS8_SJ_ES5_SL_SN_SI_EEEEEESt10unique_ptrINS_6_StateESt14default_deleteISU_EEOT_"}
-!188 = !{!186}
-!189 = !{!190}
-!190 = distinct !{!190, !191, !"_ZNSt6thread14__make_invokerIPFvN6kotlin12ScopedThread10attributesEOZNS1_2gc22ConcurrentMarkAndSweepC1ERNS1_2mm13ObjectFactoryIS5_EERNS4_11GCSchedulerEE3$_3EJRKS3_SC_EEENS_8_InvokerISt5tupleIJNSt5decayIT_E4typeEDpNSK_IT0_E4typeEEEEEOSL_DpOSO_: argument 0"}
-!191 = distinct !{!191, !"_ZNSt6thread14__make_invokerIPFvN6kotlin12ScopedThread10attributesEOZNS1_2gc22ConcurrentMarkAndSweepC1ERNS1_2mm13ObjectFactoryIS5_EERNS4_11GCSchedulerEE3$_3EJRKS3_SC_EEENS_8_InvokerISt5tupleIJNSt5decayIT_E4typeEDpNSK_IT0_E4typeEEEEEOSL_DpOSO_"}
-!192 = !{!193, !4, i64 0}
-!193 = !{!"_ZTSSt10_Head_baseILm0EPFvN6kotlin12ScopedThread10attributesEOZNS0_2gc22ConcurrentMarkAndSweepC1ERNS0_2mm13ObjectFactoryIS4_EERNS3_11GCSchedulerEE3$_3ELb0EE", !4, i64 0}
-!194 = !{!195, !131, !133}
-!195 = distinct !{!195, !196, !"_ZNSt6thread13_S_make_stateINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc22ConcurrentMarkAndSweepC1ERNS3_2mm13ObjectFactoryIS7_EERNS6_11GCSchedulerEE3$_3ES5_SE_EEEEEESt10unique_ptrINS_6_StateESt14default_deleteISL_EEOT_: argument 0"}
-!196 = distinct !{!196, !"_ZNSt6thread13_S_make_stateINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc22ConcurrentMarkAndSweepC1ERNS3_2mm13ObjectFactoryIS7_EERNS6_11GCSchedulerEE3$_3ES5_SE_EEEEEESt10unique_ptrINS_6_StateESt14default_deleteISL_EEOT_"}
-!197 = !{!195}
-!198 = !{!199, !4, i64 0}
-!199 = !{!"_ZTSSt10_Head_baseILm0EPN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeELb0EE", !4, i64 0}
-!200 = !{!170, !175, i64 344}
-!201 = !{!202, !4, i64 0}
-!202 = !{!"_ZTSSt10_Head_baseILm0EPN6kotlin2gc2GC4ImplELb0EE", !4, i64 0}
-!203 = !{!204, !4, i64 0}
-!204 = !{!"_ZTSSt10_HashtableIPKvS1_N6kotlin11std_support9allocatorIS1_EENSt8__detail9_IdentityESt8equal_toIS1_ESt4hashIS1_ENS6_18_Mod_range_hashingENS6_20_Default_ranged_hashENS6_20_Prime_rehash_policyENS6_17_Hashtable_traitsILb0ELb1ELb1EEEE", !4, i64 0, !50, i64 8, !205, i64 16, !50, i64 24, !206, i64 32, !4, i64 48}
-!205 = !{!"_ZTSNSt8__detail15_Hash_node_baseE", !4, i64 0}
-!206 = !{!"_ZTSNSt8__detail20_Prime_rehash_policyE", !207, i64 0, !50, i64 8}
-!207 = !{!"float", !5, i64 0}
-!208 = !{!204, !50, i64 8}
-!209 = !{!206, !207, i64 0}
-!210 = !{i64 0, i64 8, !89, i64 8, i64 8, !3}
-!211 = !{!212, !4, i64 0}
-!212 = !{!"_ZTSSt12_Vector_baseISt4pairIPP9ObjHeaderS2_EN6kotlin11std_support9allocatorIS4_EEE", !213, i64 0}
-!213 = !{!"_ZTSNSt12_Vector_baseISt4pairIPP9ObjHeaderS2_EN6kotlin11std_support9allocatorIS4_EEE12_Vector_implE", !4, i64 0, !4, i64 8, !4, i64 16}
-!214 = !{!215, !4, i64 16}
-!215 = !{!"_ZTSSt10_HashtableIPvSt4pairIKS0_N6kotlin2mm18ThreadLocalStorage5EntryEENS3_11std_support9allocatorIS7_EENSt8__detail10_Select1stESt8equal_toIS0_ESt4hashIS0_ENSB_18_Mod_range_hashingENSB_20_Default_ranged_hashENSB_20_Prime_rehash_policyENSB_17_Hashtable_traitsILb0ELb0ELb1EEEE", !4, i64 0, !50, i64 8, !205, i64 16, !50, i64 24, !206, i64 32, !4, i64 48}
-!216 = !{!205, !4, i64 0}
-!217 = !{!215, !4, i64 0}
-!218 = !{!215, !50, i64 8}
-!219 = !{!220, !4, i64 0}
-!220 = !{!"_ZTSSt12_Vector_baseIP9ObjHeaderN6kotlin11std_support9allocatorIS1_EEE", !221, i64 0}
-!221 = !{!"_ZTSNSt12_Vector_baseIP9ObjHeaderN6kotlin11std_support9allocatorIS1_EEE12_Vector_implE", !4, i64 0, !4, i64 8, !4, i64 16}
-!222 = !{!223, !4, i64 0}
-!223 = !{!"_ZTSN6kotlin16MultiSourceQueueINS_2mm15ExtraObjectDataENS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_19ObjectPoolAllocatorIS2_EEE8ProducerE", !4, i64 0, !224, i64 8, !225, i64 32}
-!224 = !{!"_ZTSNSt7__cxx114listIN6kotlin16MultiSourceQueueINS1_2mm15ExtraObjectDataENS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_19ObjectPoolAllocatorIS4_EEE4NodeENS8_ISB_EEEE"}
-!225 = !{!"_ZTSNSt7__cxx114listIPN6kotlin16MultiSourceQueueINS1_2mm15ExtraObjectDataENS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_19ObjectPoolAllocatorIS4_EEE4NodeENS8_ISC_EEEE"}
-!226 = !{!227, !50, i64 16}
-!227 = !{!"_ZTSNSt7__cxx1110_List_baseIN6kotlin16MultiSourceQueueINS1_2mm15ExtraObjectDataENS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_19ObjectPoolAllocatorIS4_EEE4NodeENS8_ISB_EEEE", !228, i64 0}
-!228 = !{!"_ZTSNSt7__cxx1110_List_baseIN6kotlin16MultiSourceQueueINS1_2mm15ExtraObjectDataENS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_19ObjectPoolAllocatorIS4_EEE4NodeENS8_ISB_EEE10_List_implE", !127, i64 0}
-!229 = !{!230, !50, i64 16}
-!230 = !{!"_ZTSNSt7__cxx1110_List_baseIPN6kotlin16MultiSourceQueueINS1_2mm15ExtraObjectDataENS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_19ObjectPoolAllocatorIS4_EEE4NodeENS8_ISC_EEEE", !231, i64 0}
-!231 = !{!"_ZTSNSt7__cxx1110_List_baseIPN6kotlin16MultiSourceQueueINS1_2mm15ExtraObjectDataENS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_19ObjectPoolAllocatorIS4_EEE4NodeENS8_ISC_EEE10_List_implE", !127, i64 0}
-!232 = !{!233, !4, i64 0}
-!233 = !{!"_ZTSN6kotlin16MultiSourceQueueIP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS2_EEE8ProducerE", !4, i64 0, !234, i64 8, !235, i64 32}
-!234 = !{!"_ZTSNSt7__cxx114listIN6kotlin16MultiSourceQueueIP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS4_EEE4NodeENS9_ISC_EEEE"}
-!235 = !{!"_ZTSNSt7__cxx114listIPN6kotlin16MultiSourceQueueIP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS4_EEE4NodeENS9_ISD_EEEE"}
-!236 = !{!237, !50, i64 16}
-!237 = !{!"_ZTSNSt7__cxx1110_List_baseIN6kotlin16MultiSourceQueueIP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS4_EEE4NodeENS9_ISC_EEEE", !238, i64 0}
-!238 = !{!"_ZTSNSt7__cxx1110_List_baseIN6kotlin16MultiSourceQueueIP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS4_EEE4NodeENS9_ISC_EEE10_List_implE", !127, i64 0}
-!239 = !{!240, !50, i64 16}
-!240 = !{!"_ZTSNSt7__cxx1110_List_baseIPN6kotlin16MultiSourceQueueIP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS4_EEE4NodeENS9_ISD_EEEE", !241, i64 0}
-!241 = !{!"_ZTSNSt7__cxx1110_List_baseIPN6kotlin16MultiSourceQueueIP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS4_EEE4NodeENS9_ISD_EEE10_List_implE", !127, i64 0}
-!242 = !{!243, !4, i64 0}
-!243 = !{!"_ZTSN6kotlin16MultiSourceQueueIPP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS3_EEE8ProducerE", !4, i64 0, !244, i64 8, !245, i64 32}
-!244 = !{!"_ZTSNSt7__cxx114listIN6kotlin16MultiSourceQueueIPP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS5_EEE4NodeENSA_ISD_EEEE"}
-!245 = !{!"_ZTSNSt7__cxx114listIPN6kotlin16MultiSourceQueueIPP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS5_EEE4NodeENSA_ISE_EEEE"}
-!246 = !{!247, !50, i64 16}
-!247 = !{!"_ZTSNSt7__cxx1110_List_baseIN6kotlin16MultiSourceQueueIPP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS5_EEE4NodeENSA_ISD_EEEE", !248, i64 0}
-!248 = !{!"_ZTSNSt7__cxx1110_List_baseIN6kotlin16MultiSourceQueueIPP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS5_EEE4NodeENSA_ISD_EEE10_List_implE", !127, i64 0}
-!249 = !{!250, !50, i64 16}
-!250 = !{!"_ZTSNSt7__cxx1110_List_baseIPN6kotlin16MultiSourceQueueIPP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS5_EEE4NodeENSA_ISE_EEEE", !251, i64 0}
-!251 = !{!"_ZTSNSt7__cxx1110_List_baseIPN6kotlin16MultiSourceQueueIPP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS5_EEE4NodeENSA_ISE_EEE10_List_implE", !127, i64 0}
-!252 = !{!253, !4, i64 8}
-!253 = !{!"_ZTSN6kotlin2mm20ThreadSuspensionDataE", !254, i64 0, !4, i64 8, !256, i64 16}
-!254 = !{!"_ZTSSt6atomicIN6kotlin11ThreadStateEE", !255, i64 0}
-!255 = !{!"_ZTSN6kotlin11ThreadStateE", !5, i64 0}
-!256 = !{!"_ZTSSt6atomicIbE", !140, i64 0}
-!257 = !{!258, !4, i64 0}
-!258 = !{!"_ZTSSt11unique_lockISt5mutexE", !4, i64 0, !71, i64 8}
-!259 = !{!258, !71, i64 8}
+!21 = distinct !{!21, !22}
+!22 = !{!"llvm.loop.unroll.disable"}
+!23 = !{i32 0, i32 33}
+!24 = distinct !{!24, !25}
+!25 = !{!"llvm.loop.isvectorized", i32 1}
+!26 = distinct !{!26, !22}
+!27 = !{!28, !28, i64 0}
+!28 = !{!"short", !5, i64 0}
+!29 = distinct !{!29, !30, !25}
+!30 = !{!"llvm.loop.unroll.runtime.disable"}
+!31 = !{!32}
+!32 = distinct !{!32, !33, !"_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE: argument 0"}
+!33 = distinct !{!33, !"_ZN6kotlin20GetStackTraceStringsB5cxx11ENS_11std_support4spanIKPvLm18446744073709551615EEE"}
+!34 = !{!35, !4, i64 0}
+!35 = !{!"_ZTSN6kotlin16ThreadStateGuardE", !4, i64 0, !36, i64 8, !37, i64 12}
+!36 = !{!"_ZTSN6kotlin11ThreadStateE", !5, i64 0}
+!37 = !{!"bool", !5, i64 0}
+!38 = !{!35, !36, i64 8}
+!39 = !{!35, !37, i64 12}
+!40 = !{!41, !4, i64 16}
+!41 = !{!"_ZTSSt12_Vector_baseINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE", !42, i64 0}
+!42 = !{!"_ZTSNSt12_Vector_baseINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEENS6_IS8_EEE12_Vector_implE", !4, i64 0, !4, i64 8, !4, i64 16}
+!43 = !{!41, !4, i64 0}
+!44 = !{!41, !4, i64 8}
+!45 = !{!46, !4, i64 0}
+!46 = !{!"_ZTSNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEE12_Alloc_hiderE", !4, i64 0}
+!47 = !{!48, !4, i64 0}
+!48 = !{!"_ZTSNSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEE", !46, i64 0, !49, i64 8, !5, i64 16}
+!49 = !{!"long", !5, i64 0}
+!50 = !{!5, !5, i64 0}
+!51 = !{!48, !49, i64 8}
+!52 = !{!53, !4, i64 0}
+!53 = !{!"_ZTSNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE12_Alloc_hiderE", !4, i64 0}
+!54 = !{!55, !49, i64 8}
+!55 = !{!"_ZTSNSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEEE", !53, i64 0, !49, i64 8, !5, i64 16}
+!56 = !{!57, !11, i64 32}
+!57 = !{!"_ZTS10SourceInfo", !55, i64 0, !11, i64 32, !11, i64 36}
+!58 = !{!57, !11, i64 36}
+!59 = !{!55, !4, i64 0}
+!60 = !{!61, !4, i64 24}
+!61 = !{!"_ZTS9ObjHolder", !10, i64 0, !4, i64 24}
+!62 = distinct !{!62, !25}
+!63 = distinct !{!63, !30, !25}
+!64 = !{!65, !4, i64 8}
+!65 = !{!"_ZTSN12_GLOBAL__N_122ExceptionObjHolderImplE", !4, i64 8}
+!66 = !{!20, !11, i64 88}
+!67 = !{!20, !4, i64 80}
+!68 = !{!20, !4, i64 72}
+!69 = !{!37, !37, i64 0}
+!70 = !{i8 0, i8 2}
+!71 = !{!11, !11, i64 0}
+!72 = distinct !{!72, !25}
+!73 = distinct !{!73, !22}
+!74 = distinct !{!74, !30, !25}
+!75 = !{!76, !37, i64 88}
+!76 = !{!"_ZTSN6kotlin13RepeatedTimerINS_12steady_clockEEE", !77, i64 0, !78, i64 40, !37, i64 88, !79, i64 96, !81, i64 104, !37, i64 112, !82, i64 120}
+!77 = !{!"_ZTSSt5mutex"}
+!78 = !{!"_ZTSSt18condition_variable", !5, i64 0}
+!79 = !{!"_ZTSNSt6chrono8durationIN6kotlin10saturatingIlEESt5ratioILl1ELl1000000000EEEE", !80, i64 0}
+!80 = !{!"_ZTSN6kotlin10saturatingIlEE", !49, i64 0}
+!81 = !{!"_ZTSNSt6chrono10time_pointIN6kotlin12steady_clockENS_8durationINS1_10saturatingIlEESt5ratioILl1ELl1000000000EEEEEE", !79, i64 0}
+!82 = !{!"_ZTSN6kotlin12ScopedThreadE", !83, i64 0}
+!83 = !{!"_ZTSSt6thread", !84, i64 0}
+!84 = !{!"_ZTSNSt6thread2idE", !49, i64 0}
+!85 = !{!76, !37, i64 112}
+!86 = !{i64 0, i64 8, !87}
+!87 = !{!49, !49, i64 0}
+!88 = !{!89, !49, i64 0}
+!89 = !{!"_ZTS8timespec", !49, i64 0, !49, i64 8}
+!90 = !{!89, !49, i64 8}
+!91 = !{!92, !4, i64 0}
+!92 = !{!"_ZTSZN6kotlin2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEC1ERNS0_17GCSchedulerConfigESt8functionIFvvEEEUlvE_", !4, i64 0}
+!93 = !{!94, !4, i64 16}
+!94 = !{!"_ZTSN6kotlin2gc8internal24GCSchedulerDataWithTimerINS_12steady_clockEEE", !4, i64 8, !4, i64 16, !95, i64 24, !97, i64 48, !99, i64 64, !76, i64 96}
+!95 = !{!"_ZTSN6kotlin2gc8internal20HeapGrowthControllerE", !4, i64 0, !96, i64 8, !96, i64 16}
+!96 = !{!"_ZTSSt6atomicImE"}
+!97 = !{!"_ZTSN6kotlin2gc8internal20RegularIntervalPacerINS_12steady_clockEEE", !4, i64 0, !98, i64 8}
+!98 = !{!"_ZTSSt6atomicINSt6chrono10time_pointIN6kotlin12steady_clockENS0_8durationINS2_10saturatingIlEESt5ratioILl1ELl1000000000EEEEEEE", !81, i64 0}
+!99 = !{!"_ZTSSt8functionIFvvEE", !4, i64 24}
+!100 = !{!97, !4, i64 0}
+!101 = !{!102, !4, i64 16}
+!102 = !{!"_ZTSSt14_Function_base", !5, i64 0, !4, i64 16}
+!103 = !{!99, !4, i64 24}
+!104 = !{!105, !37, i64 32}
+!105 = !{!"_ZTSSt14_Optional_baseINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEELb0ELb0EE", !106, i64 0}
+!106 = !{!"_ZTSSt17_Optional_payloadINSt7__cxx1112basic_stringIcSt11char_traitsIcEN6kotlin11std_support9allocatorIcEEEELb0ELb0ELb0EE", !5, i64 0, !37, i64 32}
+!107 = !{!108, !108, i64 0}
+!108 = !{!"vtable pointer", !6, i64 0}
+!109 = !{}
+!110 = !{!106, !37, i64 32}
+!111 = !{!112, !49, i64 40}
+!112 = !{!"_ZTSN6kotlin2gc21GCSchedulerThreadDataE", !4, i64 0, !113, i64 8, !49, i64 40, !49, i64 48, !49, i64 56, !49, i64 64}
+!113 = !{!"_ZTSSt8functionIFvRN6kotlin2gc21GCSchedulerThreadDataEEE", !4, i64 24}
+!114 = !{!95, !4, i64 0}
+!115 = !{!94, !4, i64 8}
+!116 = !{!117, !11, i64 16}
+!117 = !{!"_ZTSN15pthread_mutex_t17__pthread_mutex_sE", !11, i64 0, !11, i64 4, !11, i64 8, !11, i64 12, !11, i64 16, !28, i64 20, !28, i64 22, !118, i64 24}
+!118 = !{!"_ZTS23__pthread_internal_list", !4, i64 0, !4, i64 8}
+!119 = !{!120, !4, i64 0}
+!120 = !{!"_ZTSSt10_Head_baseILm0EPN6kotlin2mm16AppStateTracking4ImplELb0EE", !4, i64 0}
+!121 = !{!122, !4, i64 8}
+!122 = !{!"_ZTSNSt8__detail15_List_node_baseE", !4, i64 0, !4, i64 8}
+!123 = !{!122, !4, i64 0}
+!124 = !{!125, !49, i64 16}
+!125 = !{!"_ZTSNSt8__detail17_List_node_headerE", !49, i64 16}
+!126 = !{!127, !37, i64 0}
+!127 = !{!"_ZTSSt18__atomic_flag_base", !37, i64 0}
+!128 = !{!129, !131}
+!129 = distinct !{!129, !130, !"_ZN6kotlin11std_support15allocate_uniqueINS_2gc2GC4ImplENS0_9allocatorIS4_EEJEEEDaRKT0_DpOT1_: argument 0"}
+!130 = distinct !{!130, !"_ZN6kotlin11std_support15allocate_uniqueINS_2gc2GC4ImplENS0_9allocatorIS4_EEJEEEDaRKT0_DpOT1_"}
+!131 = distinct !{!131, !132, !"_ZN6kotlin11std_support11make_uniqueINS_2gc2GC4ImplEJEEEDaDpOT0_: argument 0"}
+!132 = distinct !{!132, !"_ZN6kotlin11std_support11make_uniqueINS_2gc2GC4ImplEJEEEDaDpOT0_"}
+!133 = !{!134, !11, i64 0}
+!134 = !{!"_ZTSSt13__atomic_baseIiE", !11, i64 0}
+!135 = !{!136, !49, i64 0}
+!136 = !{!"_ZTSSt13__atomic_baseIlE", !49, i64 0}
+!137 = !{!138, !37, i64 0}
+!138 = !{!"_ZTSSt13__atomic_baseIbE", !37, i64 0}
+!139 = !{!140, !141, i64 0}
+!140 = !{!"_ZTSSt6atomicIdE", !141, i64 0}
+!141 = !{!"double", !5, i64 0}
+!142 = !{!143, !49, i64 0}
+!143 = !{!"_ZTSN13GCStateHolder16ValueWithCondVarIlEE", !49, i64 0, !4, i64 8, !78, i64 16}
+!144 = !{!145, !37, i64 296}
+!145 = !{!"_ZTS13GCStateHolder", !77, i64 0, !143, i64 40, !143, i64 104, !143, i64 168, !143, i64 232, !37, i64 296}
+!146 = !{!84, !49, i64 0}
+!147 = !{!148, !150, !129, !131}
+!148 = distinct !{!148, !149, !"_ZN6kotlin11std_support15allocate_uniqueINS_2gc18FinalizerProcessorENS0_9allocatorIS3_EEJZNS2_22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS6_EERNS2_11GCSchedulerEE3$_1EEEDaRKT0_DpOT1_: argument 0"}
+!149 = distinct !{!149, !"_ZN6kotlin11std_support15allocate_uniqueINS_2gc18FinalizerProcessorENS0_9allocatorIS3_EEJZNS2_22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS6_EERNS2_11GCSchedulerEE3$_1EEEDaRKT0_DpOT1_"}
+!150 = distinct !{!150, !151, !"_ZN6kotlin11std_support11make_uniqueINS_2gc18FinalizerProcessorEJZNS2_22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS4_EERNS2_11GCSchedulerEE3$_1EEEDaDpOT0_: argument 0"}
+!151 = distinct !{!151, !"_ZN6kotlin11std_support11make_uniqueINS_2gc18FinalizerProcessorEJZNS2_22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS4_EERNS2_11GCSchedulerEE3$_1EEEDaDpOT0_"}
+!152 = !{i64 0, i64 8, !50, i64 0, i64 8, !50, i64 0, i64 8, !50, i64 0, i64 16, !50, i64 0, i64 16, !50}
+!153 = !{!154, !49, i64 160}
+!154 = !{!"_ZTSN6kotlin2gc18FinalizerProcessorE", !82, i64 0, !155, i64 8, !78, i64 40, !77, i64 88, !160, i64 128, !49, i64 160, !37, i64 168, !37, i64 169, !77, i64 176, !78, i64 216, !37, i64 264, !77, i64 272}
+!155 = !{!"_ZTSN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE14FinalizerQueueE", !156, i64 8}
+!156 = !{!"_ZTSN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8ConsumerE", !157, i64 0, !4, i64 8, !49, i64 16}
+!157 = !{!"_ZTSSt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEE", !158, i64 0}
+!158 = !{!"_ZTSSt15__uniq_ptr_implIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEE", !159, i64 0}
+!159 = !{!"_ZTSSt5tupleIJPN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSA_7DeleterISB_EEEE"}
+!160 = !{!"_ZTSSt8functionIFvlEE", !4, i64 24}
+!161 = !{!154, !37, i64 168}
+!162 = !{!154, !37, i64 169}
+!163 = !{!154, !37, i64 264}
+!164 = !{!165, !4, i64 0}
+!165 = !{!"_ZTSSt10_Head_baseILm0EPN6kotlin2gc18FinalizerProcessorELb0EE", !4, i64 0}
+!166 = !{!148, !150}
+!167 = !{!168, !4, i64 8}
+!168 = !{!"_ZTSN6kotlin2gc22ConcurrentMarkAndSweepE", !4, i64 0, !4, i64 8, !145, i64 16, !82, i64 320, !169, i64 328, !172, i64 336, !173, i64 344}
+!169 = !{!"_ZTSSt10unique_ptrIN6kotlin2gc18FinalizerProcessorENS0_11std_support17allocator_deleterIS2_NS3_9allocatorIS2_EEEEE", !170, i64 0}
+!170 = !{!"_ZTSSt15__uniq_ptr_implIN6kotlin2gc18FinalizerProcessorENS0_11std_support17allocator_deleterIS2_NS3_9allocatorIS2_EEEEE", !171, i64 0}
+!171 = !{!"_ZTSSt5tupleIJPN6kotlin2gc18FinalizerProcessorENS0_11std_support17allocator_deleterIS2_NS4_9allocatorIS2_EEEEEE"}
+!172 = !{!"_ZTSN6kotlin22intrusive_forward_listINS_2gc22ConcurrentMarkAndSweep10ObjectDataENS_33DefaultIntrusiveForwardListTraitsIS3_EEEE", !5, i64 0}
+!173 = !{!"_ZTSN6kotlin2gc22ConcurrentMarkAndSweep15MarkingBehaviorE", !5, i64 0}
+!174 = !{!175, !4, i64 0}
+!175 = !{!"_ZTSSt10_Head_baseILm3EPN6kotlin13RepeatedTimerINS0_12steady_clockEEELb0EE", !4, i64 0}
+!176 = !{!177, !5, i64 0}
+!177 = !{!"_ZTSSt10_Head_baseILm2EMN6kotlin13RepeatedTimerINS0_12steady_clockEEEDoFvOZNS0_2gc8internal24GCSchedulerDataWithTimerIS2_EC1ERNS4_17GCSchedulerConfigESt8functionIFvvEEEUlvE_ELb0EE", !5, i64 0}
+!178 = !{!179, !4, i64 0}
+!179 = !{!"_ZTSSt10_Head_baseILm0EPFvN6kotlin12ScopedThread10attributesEOMNS0_13RepeatedTimerINS0_12steady_clockEEEDoFvOZNS0_2gc8internal24GCSchedulerDataWithTimerIS4_EC1ERNS6_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS5_SG_ELb0EE", !4, i64 0}
+!180 = !{!181}
+!181 = distinct !{!181, !182, !"_ZNSt6thread14__make_invokerIPFvN6kotlin12ScopedThread10attributesEOMNS1_13RepeatedTimerINS1_12steady_clockEEEDoFvOZNS1_2gc8internal24GCSchedulerDataWithTimerIS5_EC1ERNS7_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS6_SH_EJRKS3_SJ_SL_SG_EEENS_8_InvokerISt5tupleIJNSt5decayIT_E4typeEDpNST_IT0_E4typeEEEEEOSU_DpOSX_: argument 0"}
+!182 = distinct !{!182, !"_ZNSt6thread14__make_invokerIPFvN6kotlin12ScopedThread10attributesEOMNS1_13RepeatedTimerINS1_12steady_clockEEEDoFvOZNS1_2gc8internal24GCSchedulerDataWithTimerIS5_EC1ERNS7_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS6_SH_EJRKS3_SJ_SL_SG_EEENS_8_InvokerISt5tupleIJNSt5decayIT_E4typeEDpNST_IT0_E4typeEEEEEOSU_DpOSX_"}
+!183 = !{!184, !129, !131}
+!184 = distinct !{!184, !185, !"_ZNSt6thread13_S_make_stateINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOMNS3_13RepeatedTimerINS3_12steady_clockEEEDoFvOZNS3_2gc8internal24GCSchedulerDataWithTimerIS7_EC1ERNS9_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS8_SJ_ES5_SL_SN_SI_EEEEEESt10unique_ptrINS_6_StateESt14default_deleteISU_EEOT_: argument 0"}
+!185 = distinct !{!185, !"_ZNSt6thread13_S_make_stateINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOMNS3_13RepeatedTimerINS3_12steady_clockEEEDoFvOZNS3_2gc8internal24GCSchedulerDataWithTimerIS7_EC1ERNS9_17GCSchedulerConfigESt8functionIFvvEEEUlvE_EOPS8_SJ_ES5_SL_SN_SI_EEEEEESt10unique_ptrINS_6_StateESt14default_deleteISU_EEOT_"}
+!186 = !{!184}
+!187 = !{!188}
+!188 = distinct !{!188, !189, !"_ZNSt6thread14__make_invokerIPFvN6kotlin12ScopedThread10attributesEOZNS1_2gc22ConcurrentMarkAndSweepC1ERNS1_2mm13ObjectFactoryIS5_EERNS4_11GCSchedulerEE3$_3EJRKS3_SC_EEENS_8_InvokerISt5tupleIJNSt5decayIT_E4typeEDpNSK_IT0_E4typeEEEEEOSL_DpOSO_: argument 0"}
+!189 = distinct !{!189, !"_ZNSt6thread14__make_invokerIPFvN6kotlin12ScopedThread10attributesEOZNS1_2gc22ConcurrentMarkAndSweepC1ERNS1_2mm13ObjectFactoryIS5_EERNS4_11GCSchedulerEE3$_3EJRKS3_SC_EEENS_8_InvokerISt5tupleIJNSt5decayIT_E4typeEDpNSK_IT0_E4typeEEEEEOSL_DpOSO_"}
+!190 = !{!188, !129, !131}
+!191 = !{!192, !4, i64 0}
+!192 = !{!"_ZTSSt10_Head_baseILm0EPFvN6kotlin12ScopedThread10attributesEOZNS0_2gc22ConcurrentMarkAndSweepC1ERNS0_2mm13ObjectFactoryIS4_EERNS3_11GCSchedulerEE3$_3ELb0EE", !4, i64 0}
+!193 = !{!194, !129, !131}
+!194 = distinct !{!194, !195, !"_ZNSt6thread13_S_make_stateINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc22ConcurrentMarkAndSweepC1ERNS3_2mm13ObjectFactoryIS7_EERNS6_11GCSchedulerEE3$_3ES5_SE_EEEEEESt10unique_ptrINS_6_StateESt14default_deleteISL_EEOT_: argument 0"}
+!195 = distinct !{!195, !"_ZNSt6thread13_S_make_stateINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc22ConcurrentMarkAndSweepC1ERNS3_2mm13ObjectFactoryIS7_EERNS6_11GCSchedulerEE3$_3ES5_SE_EEEEEESt10unique_ptrINS_6_StateESt14default_deleteISL_EEOT_"}
+!196 = !{!194}
+!197 = !{!198, !4, i64 0}
+!198 = !{!"_ZTSSt10_Head_baseILm0EPN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS0_2gc15AllocatorWithGCINS4_9AllocatorENS4_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeELb0EE", !4, i64 0}
+!199 = !{!168, !173, i64 344}
+!200 = !{!201, !4, i64 0}
+!201 = !{!"_ZTSSt10_Head_baseILm0EPN6kotlin2gc2GC4ImplELb0EE", !4, i64 0}
+!202 = !{!203, !4, i64 0}
+!203 = !{!"_ZTSSt10_HashtableIPKvS1_N6kotlin11std_support9allocatorIS1_EENSt8__detail9_IdentityESt8equal_toIS1_ESt4hashIS1_ENS6_18_Mod_range_hashingENS6_20_Default_ranged_hashENS6_20_Prime_rehash_policyENS6_17_Hashtable_traitsILb0ELb1ELb1EEEE", !4, i64 0, !49, i64 8, !204, i64 16, !49, i64 24, !205, i64 32, !4, i64 48}
+!204 = !{!"_ZTSNSt8__detail15_Hash_node_baseE", !4, i64 0}
+!205 = !{!"_ZTSNSt8__detail20_Prime_rehash_policyE", !206, i64 0, !49, i64 8}
+!206 = !{!"float", !5, i64 0}
+!207 = !{!203, !49, i64 8}
+!208 = !{!205, !206, i64 0}
+!209 = !{i64 0, i64 8, !87, i64 8, i64 8, !3}
+!210 = !{!211, !4, i64 0}
+!211 = !{!"_ZTSSt12_Vector_baseISt4pairIPP9ObjHeaderS2_EN6kotlin11std_support9allocatorIS4_EEE", !212, i64 0}
+!212 = !{!"_ZTSNSt12_Vector_baseISt4pairIPP9ObjHeaderS2_EN6kotlin11std_support9allocatorIS4_EEE12_Vector_implE", !4, i64 0, !4, i64 8, !4, i64 16}
+!213 = !{!214, !4, i64 16}
+!214 = !{!"_ZTSSt10_HashtableIPvSt4pairIKS0_N6kotlin2mm18ThreadLocalStorage5EntryEENS3_11std_support9allocatorIS7_EENSt8__detail10_Select1stESt8equal_toIS0_ESt4hashIS0_ENSB_18_Mod_range_hashingENSB_20_Default_ranged_hashENSB_20_Prime_rehash_policyENSB_17_Hashtable_traitsILb0ELb0ELb1EEEE", !4, i64 0, !49, i64 8, !204, i64 16, !49, i64 24, !205, i64 32, !4, i64 48}
+!215 = !{!204, !4, i64 0}
+!216 = !{!214, !4, i64 0}
+!217 = !{!214, !49, i64 8}
+!218 = !{!219, !4, i64 0}
+!219 = !{!"_ZTSSt12_Vector_baseIP9ObjHeaderN6kotlin11std_support9allocatorIS1_EEE", !220, i64 0}
+!220 = !{!"_ZTSNSt12_Vector_baseIP9ObjHeaderN6kotlin11std_support9allocatorIS1_EEE12_Vector_implE", !4, i64 0, !4, i64 8, !4, i64 16}
+!221 = !{!222, !4, i64 0}
+!222 = !{!"_ZTSN6kotlin16MultiSourceQueueINS_2mm15ExtraObjectDataENS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_19ObjectPoolAllocatorIS2_EEE8ProducerE", !4, i64 0, !223, i64 8, !224, i64 32}
+!223 = !{!"_ZTSNSt7__cxx114listIN6kotlin16MultiSourceQueueINS1_2mm15ExtraObjectDataENS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_19ObjectPoolAllocatorIS4_EEE4NodeENS8_ISB_EEEE"}
+!224 = !{!"_ZTSNSt7__cxx114listIPN6kotlin16MultiSourceQueueINS1_2mm15ExtraObjectDataENS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_19ObjectPoolAllocatorIS4_EEE4NodeENS8_ISC_EEEE"}
+!225 = !{!226, !49, i64 16}
+!226 = !{!"_ZTSNSt7__cxx1110_List_baseIN6kotlin16MultiSourceQueueINS1_2mm15ExtraObjectDataENS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_19ObjectPoolAllocatorIS4_EEE4NodeENS8_ISB_EEEE", !227, i64 0}
+!227 = !{!"_ZTSNSt7__cxx1110_List_baseIN6kotlin16MultiSourceQueueINS1_2mm15ExtraObjectDataENS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_19ObjectPoolAllocatorIS4_EEE4NodeENS8_ISB_EEE10_List_implE", !125, i64 0}
+!228 = !{!229, !49, i64 16}
+!229 = !{!"_ZTSNSt7__cxx1110_List_baseIPN6kotlin16MultiSourceQueueINS1_2mm15ExtraObjectDataENS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_19ObjectPoolAllocatorIS4_EEE4NodeENS8_ISC_EEEE", !230, i64 0}
+!230 = !{!"_ZTSNSt7__cxx1110_List_baseIPN6kotlin16MultiSourceQueueINS1_2mm15ExtraObjectDataENS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_19ObjectPoolAllocatorIS4_EEE4NodeENS8_ISC_EEE10_List_implE", !125, i64 0}
+!231 = !{!232, !4, i64 0}
+!232 = !{!"_ZTSN6kotlin16MultiSourceQueueIP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS2_EEE8ProducerE", !4, i64 0, !233, i64 8, !234, i64 32}
+!233 = !{!"_ZTSNSt7__cxx114listIN6kotlin16MultiSourceQueueIP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS4_EEE4NodeENS9_ISC_EEEE"}
+!234 = !{!"_ZTSNSt7__cxx114listIPN6kotlin16MultiSourceQueueIP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS4_EEE4NodeENS9_ISD_EEEE"}
+!235 = !{!236, !49, i64 16}
+!236 = !{!"_ZTSNSt7__cxx1110_List_baseIN6kotlin16MultiSourceQueueIP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS4_EEE4NodeENS9_ISC_EEEE", !237, i64 0}
+!237 = !{!"_ZTSNSt7__cxx1110_List_baseIN6kotlin16MultiSourceQueueIP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS4_EEE4NodeENS9_ISC_EEE10_List_implE", !125, i64 0}
+!238 = !{!239, !49, i64 16}
+!239 = !{!"_ZTSNSt7__cxx1110_List_baseIPN6kotlin16MultiSourceQueueIP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS4_EEE4NodeENS9_ISD_EEEE", !240, i64 0}
+!240 = !{!"_ZTSNSt7__cxx1110_List_baseIPN6kotlin16MultiSourceQueueIP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS4_EEE4NodeENS9_ISD_EEE10_List_implE", !125, i64 0}
+!241 = !{!242, !4, i64 0}
+!242 = !{!"_ZTSN6kotlin16MultiSourceQueueIPP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS3_EEE8ProducerE", !4, i64 0, !243, i64 8, !244, i64 32}
+!243 = !{!"_ZTSNSt7__cxx114listIN6kotlin16MultiSourceQueueIPP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS5_EEE4NodeENSA_ISD_EEEE"}
+!244 = !{!"_ZTSNSt7__cxx114listIPN6kotlin16MultiSourceQueueIPP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS5_EEE4NodeENSA_ISE_EEEE"}
+!245 = !{!246, !49, i64 16}
+!246 = !{!"_ZTSNSt7__cxx1110_List_baseIN6kotlin16MultiSourceQueueIPP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS5_EEE4NodeENSA_ISD_EEEE", !247, i64 0}
+!247 = !{!"_ZTSNSt7__cxx1110_List_baseIN6kotlin16MultiSourceQueueIPP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS5_EEE4NodeENSA_ISD_EEE10_List_implE", !125, i64 0}
+!248 = !{!249, !49, i64 16}
+!249 = !{!"_ZTSNSt7__cxx1110_List_baseIPN6kotlin16MultiSourceQueueIPP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS5_EEE4NodeENSA_ISE_EEEE", !250, i64 0}
+!250 = !{!"_ZTSNSt7__cxx1110_List_baseIPN6kotlin16MultiSourceQueueIPP9ObjHeaderNS1_8SpinLockILNS1_24MutexThreadStateHandlingE0EEENS1_11std_support9allocatorIS5_EEE4NodeENSA_ISE_EEE10_List_implE", !125, i64 0}
+!251 = !{!252, !4, i64 8}
+!252 = !{!"_ZTSN6kotlin2mm20ThreadSuspensionDataE", !253, i64 0, !4, i64 8, !254, i64 16}
+!253 = !{!"_ZTSSt6atomicIN6kotlin11ThreadStateEE", !36, i64 0}
+!254 = !{!"_ZTSSt6atomicIbE", !138, i64 0}
+!255 = !{!256, !4, i64 0}
+!256 = !{!"_ZTSSt11unique_lockISt5mutexE", !4, i64 0, !37, i64 8}
+!257 = !{!256, !37, i64 8}
+!258 = !{!259, !4, i64 0}
+!259 = !{!"_ZTSSt14_List_iteratorIN6kotlin16MultiSourceQueueIP9ObjHeaderNS0_8SpinLockILNS0_24MutexThreadStateHandlingE0EEENS0_11std_support9allocatorIS3_EEE4NodeEE", !4, i64 0}
 !260 = !{!261, !4, i64 0}
-!261 = !{!"_ZTSSt14_List_iteratorIN6kotlin16MultiSourceQueueIP9ObjHeaderNS0_8SpinLockILNS0_24MutexThreadStateHandlingE0EEENS0_11std_support9allocatorIS3_EEE4NodeEE", !4, i64 0}
-!262 = !{!263, !4, i64 0}
-!263 = !{!"_ZTSN6kotlin16MultiSourceQueueIP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS2_EEE4NodeE", !4, i64 0, !264, i64 8, !261, i64 16}
-!264 = !{!"_ZTSSt6atomicIPN6kotlin16MultiSourceQueueIP9ObjHeaderNS0_8SpinLockILNS0_24MutexThreadStateHandlingE0EEENS0_11std_support9allocatorIS3_EEE8ProducerEE", !265, i64 0}
-!265 = !{!"_ZTSSt13__atomic_baseIPN6kotlin16MultiSourceQueueIP9ObjHeaderNS0_8SpinLockILNS0_24MutexThreadStateHandlingE0EEENS0_11std_support9allocatorIS3_EEE8ProducerEE", !4, i64 0}
-!266 = !{!265, !4, i64 0}
-!267 = !{i64 0, i64 8, !3}
-!268 = !{!269, !4, i64 0}
-!269 = !{!"_ZTSN6kotlin16MultiSourceQueueIPP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS3_EEE4NodeE", !4, i64 0, !270, i64 8, !272, i64 16}
-!270 = !{!"_ZTSSt6atomicIPN6kotlin16MultiSourceQueueIPP9ObjHeaderNS0_8SpinLockILNS0_24MutexThreadStateHandlingE0EEENS0_11std_support9allocatorIS4_EEE8ProducerEE", !271, i64 0}
-!271 = !{!"_ZTSSt13__atomic_baseIPN6kotlin16MultiSourceQueueIPP9ObjHeaderNS0_8SpinLockILNS0_24MutexThreadStateHandlingE0EEENS0_11std_support9allocatorIS4_EEE8ProducerEE", !4, i64 0}
-!272 = !{!"_ZTSSt14_List_iteratorIN6kotlin16MultiSourceQueueIPP9ObjHeaderNS0_8SpinLockILNS0_24MutexThreadStateHandlingE0EEENS0_11std_support9allocatorIS4_EEE4NodeEE", !4, i64 0}
-!273 = !{!271, !4, i64 0}
-!274 = !{!275, !11, i64 84}
-!275 = !{!"_ZTSN6kotlin2mm18ThreadLocalStorageE", !276, i64 0, !277, i64 24, !278, i64 80, !11, i64 84, !279, i64 88}
-!276 = !{!"_ZTSSt6vectorIP9ObjHeaderN6kotlin11std_support9allocatorIS1_EEE"}
-!277 = !{!"_ZTSSt13unordered_mapIPvN6kotlin2mm18ThreadLocalStorage5EntryESt4hashIS0_ESt8equal_toIS0_ENS1_11std_support9allocatorISt4pairIKS0_S4_EEEE", !215, i64 0}
-!278 = !{!"_ZTSN6kotlin2mm18ThreadLocalStorage5StateE", !5, i64 0}
-!279 = !{!"_ZTSSt4pairIPvN6kotlin2mm18ThreadLocalStorage5EntryEE", !4, i64 0, !280, i64 8}
-!280 = !{!"_ZTSN6kotlin2mm18ThreadLocalStorage5EntryE", !11, i64 0, !11, i64 4}
-!281 = !{!282, !4, i64 0}
-!282 = !{!"_ZTSSt4pairIKPvN6kotlin2mm18ThreadLocalStorage5EntryEE", !4, i64 0, !280, i64 8}
-!283 = !{!215, !50, i64 24}
-!284 = !{!"branch_weights", i32 1, i32 2000}
-!285 = !{!"misexpect", i64 1, i64 2000, i64 1}
-!286 = !{!215, !4, i64 48}
-!287 = !{!275, !4, i64 88}
-!288 = !{i64 0, i64 4, !73, i64 4, i64 4, !73}
-!289 = !{!279, !4, i64 0}
-!290 = !{!20, !11, i64 40}
-!291 = !{!20, !4, i64 32}
-!292 = !{!293, !4, i64 8}
-!293 = !{!"_ZTSN6kotlin2gc22ConcurrentMarkAndSweep10ThreadDataE", !4, i64 0, !4, i64 8, !4, i64 16, !256, i64 24}
-!294 = !{!295, !297, !299}
-!295 = distinct !{!295, !296, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE4LockEv: argument 0"}
-!296 = distinct !{!296, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE4LockEv"}
-!297 = distinct !{!297, !298, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE11LockForIterEv: argument 0"}
-!298 = distinct !{!298, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE11LockForIterEv"}
-!299 = distinct !{!299, !300, !"_ZN6kotlin2mm14ThreadRegistry11LockForIterEv: argument 0"}
-!300 = distinct !{!300, !"_ZN6kotlin2mm14ThreadRegistry11LockForIterEv"}
-!301 = !{!302, !304}
-!302 = distinct !{!302, !303, !"_ZN6kotlin16MultiSourceQueueIPP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS3_EEE11LockForIterEv: argument 0"}
-!303 = distinct !{!303, !"_ZN6kotlin16MultiSourceQueueIPP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS3_EEE11LockForIterEv"}
-!304 = distinct !{!304, !305, !"_ZN6kotlin2mm15GlobalsRegistry11LockForIterEv: argument 0"}
-!305 = distinct !{!305, !"_ZN6kotlin2mm15GlobalsRegistry11LockForIterEv"}
-!306 = !{!307, !309}
-!307 = distinct !{!307, !308, !"_ZN6kotlin16MultiSourceQueueIP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS2_EEE11LockForIterEv: argument 0"}
-!308 = distinct !{!308, !"_ZN6kotlin16MultiSourceQueueIP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS2_EEE11LockForIterEv"}
-!309 = distinct !{!309, !310, !"_ZN6kotlin2mm17StableRefRegistry11LockForIterEv: argument 0"}
-!310 = distinct !{!310, !"_ZN6kotlin2mm17StableRefRegistry11LockForIterEv"}
-!311 = !{!312, !71, i64 8}
-!312 = !{!"_ZTSSt14_Optional_baseImLb1ELb1EE", !313, i64 0}
-!313 = !{!"_ZTSSt17_Optional_payloadImLb1ELb1ELb1EE", !5, i64 0, !71, i64 8}
-!314 = !{!315, !71, i64 32}
-!315 = !{!"_ZTSSt14_Optional_baseIN12_GLOBAL__N_117RootSetStatisticsELb1ELb1EE", !316, i64 0}
-!316 = !{!"_ZTSSt17_Optional_payloadIN12_GLOBAL__N_117RootSetStatisticsELb1ELb1ELb1EE", !5, i64 0, !71, i64 32}
-!317 = !{!114, !50, i64 56}
-!318 = !{!114, !4, i64 0}
-!319 = !{!114, !50, i64 48}
-!320 = !{!114, !50, i64 64}
-!321 = !{!322}
-!322 = distinct !{!322, !323, !"_ZN6kotlin2mm11ShadowStack5beginEv: argument 0"}
-!323 = distinct !{!323, !"_ZN6kotlin2mm11ShadowStack5beginEv"}
-!324 = !{!20, !4, i64 104}
-!325 = !{!326, !4, i64 0}
-!326 = !{!"_ZTSN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8ProducerE", !4, i64 0, !327, i64 8, !159, i64 24, !4, i64 32, !50, i64 40, !50, i64 48}
-!327 = !{!"_ZTSN6kotlin2gc15AllocatorWithGCINS0_9AllocatorENS0_22ConcurrentMarkAndSweep10ThreadDataEEE", !328, i64 0, !4, i64 8}
-!328 = !{!"_ZTSN6kotlin2gc9AllocatorE"}
-!329 = !{!330, !4, i64 8}
-!330 = !{!"_ZTSN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEEE", !159, i64 0, !4, i64 8, !50, i64 16, !50, i64 24, !331, i64 32}
-!331 = !{!"_ZTSN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EEE", !332, i64 0}
-!332 = !{!"_ZTSSt11atomic_flag"}
-!333 = !{!326, !4, i64 32}
-!334 = !{!20, !11, i64 20}
-!335 = !{!20, !4, i64 0}
-!336 = !{!337, !71, i64 16}
-!337 = !{!"_ZTSSt14_Optional_baseIN6kotlin2gc11MemoryUsageELb1ELb1EE", !338, i64 0}
-!338 = !{!"_ZTSSt17_Optional_payloadIN6kotlin2gc11MemoryUsageELb1ELb1ELb1EE", !5, i64 0, !71, i64 16}
-!339 = !{!340, !4, i64 0}
-!340 = !{!"_ZTSZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS1_EERNS0_11GCSchedulerEE3$_1", !4, i64 0}
-!341 = !{!342, !4, i64 0}
-!342 = !{!"_ZTSZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS1_EERNS0_11GCSchedulerEE3$_2", !4, i64 0}
+!261 = !{!"_ZTSN6kotlin16MultiSourceQueueIP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS2_EEE4NodeE", !4, i64 0, !262, i64 8, !259, i64 16}
+!262 = !{!"_ZTSSt6atomicIPN6kotlin16MultiSourceQueueIP9ObjHeaderNS0_8SpinLockILNS0_24MutexThreadStateHandlingE0EEENS0_11std_support9allocatorIS3_EEE8ProducerEE", !263, i64 0}
+!263 = !{!"_ZTSSt13__atomic_baseIPN6kotlin16MultiSourceQueueIP9ObjHeaderNS0_8SpinLockILNS0_24MutexThreadStateHandlingE0EEENS0_11std_support9allocatorIS3_EEE8ProducerEE", !4, i64 0}
+!264 = !{!263, !4, i64 0}
+!265 = !{i64 0, i64 8, !3}
+!266 = !{!267, !4, i64 0}
+!267 = !{!"_ZTSN6kotlin16MultiSourceQueueIPP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS3_EEE4NodeE", !4, i64 0, !268, i64 8, !270, i64 16}
+!268 = !{!"_ZTSSt6atomicIPN6kotlin16MultiSourceQueueIPP9ObjHeaderNS0_8SpinLockILNS0_24MutexThreadStateHandlingE0EEENS0_11std_support9allocatorIS4_EEE8ProducerEE", !269, i64 0}
+!269 = !{!"_ZTSSt13__atomic_baseIPN6kotlin16MultiSourceQueueIPP9ObjHeaderNS0_8SpinLockILNS0_24MutexThreadStateHandlingE0EEENS0_11std_support9allocatorIS4_EEE8ProducerEE", !4, i64 0}
+!270 = !{!"_ZTSSt14_List_iteratorIN6kotlin16MultiSourceQueueIPP9ObjHeaderNS0_8SpinLockILNS0_24MutexThreadStateHandlingE0EEENS0_11std_support9allocatorIS4_EEE4NodeEE", !4, i64 0}
+!271 = !{!269, !4, i64 0}
+!272 = !{!273, !11, i64 84}
+!273 = !{!"_ZTSN6kotlin2mm18ThreadLocalStorageE", !274, i64 0, !275, i64 24, !276, i64 80, !11, i64 84, !277, i64 88}
+!274 = !{!"_ZTSSt6vectorIP9ObjHeaderN6kotlin11std_support9allocatorIS1_EEE"}
+!275 = !{!"_ZTSSt13unordered_mapIPvN6kotlin2mm18ThreadLocalStorage5EntryESt4hashIS0_ESt8equal_toIS0_ENS1_11std_support9allocatorISt4pairIKS0_S4_EEEE", !214, i64 0}
+!276 = !{!"_ZTSN6kotlin2mm18ThreadLocalStorage5StateE", !5, i64 0}
+!277 = !{!"_ZTSSt4pairIPvN6kotlin2mm18ThreadLocalStorage5EntryEE", !4, i64 0, !278, i64 8}
+!278 = !{!"_ZTSN6kotlin2mm18ThreadLocalStorage5EntryE", !11, i64 0, !11, i64 4}
+!279 = !{!280, !4, i64 0}
+!280 = !{!"_ZTSSt4pairIKPvN6kotlin2mm18ThreadLocalStorage5EntryEE", !4, i64 0, !278, i64 8}
+!281 = !{!214, !49, i64 24}
+!282 = !{!"branch_weights", i32 1, i32 2000}
+!283 = !{!"misexpect", i64 1, i64 2000, i64 1}
+!284 = !{!214, !4, i64 48}
+!285 = !{!273, !4, i64 88}
+!286 = !{i64 0, i64 4, !71, i64 4, i64 4, !71}
+!287 = !{!277, !4, i64 0}
+!288 = !{!20, !11, i64 40}
+!289 = !{!20, !4, i64 32}
+!290 = !{!291, !4, i64 8}
+!291 = !{!"_ZTSN6kotlin2gc22ConcurrentMarkAndSweep10ThreadDataE", !4, i64 0, !4, i64 8, !4, i64 16, !254, i64 24}
+!292 = !{!293, !295, !297}
+!293 = distinct !{!293, !294, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE4LockEv: argument 0"}
+!294 = distinct !{!294, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE4LockEv"}
+!295 = distinct !{!295, !296, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE11LockForIterEv: argument 0"}
+!296 = distinct !{!296, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE11LockForIterEv"}
+!297 = distinct !{!297, !298, !"_ZN6kotlin2mm14ThreadRegistry11LockForIterEv: argument 0"}
+!298 = distinct !{!298, !"_ZN6kotlin2mm14ThreadRegistry11LockForIterEv"}
+!299 = !{!300, !302}
+!300 = distinct !{!300, !301, !"_ZN6kotlin16MultiSourceQueueIPP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS3_EEE11LockForIterEv: argument 0"}
+!301 = distinct !{!301, !"_ZN6kotlin16MultiSourceQueueIPP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS3_EEE11LockForIterEv"}
+!302 = distinct !{!302, !303, !"_ZN6kotlin2mm15GlobalsRegistry11LockForIterEv: argument 0"}
+!303 = distinct !{!303, !"_ZN6kotlin2mm15GlobalsRegistry11LockForIterEv"}
+!304 = !{!305, !307}
+!305 = distinct !{!305, !306, !"_ZN6kotlin16MultiSourceQueueIP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS2_EEE11LockForIterEv: argument 0"}
+!306 = distinct !{!306, !"_ZN6kotlin16MultiSourceQueueIP9ObjHeaderNS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_11std_support9allocatorIS2_EEE11LockForIterEv"}
+!307 = distinct !{!307, !308, !"_ZN6kotlin2mm17StableRefRegistry11LockForIterEv: argument 0"}
+!308 = distinct !{!308, !"_ZN6kotlin2mm17StableRefRegistry11LockForIterEv"}
+!309 = !{!310, !37, i64 8}
+!310 = !{!"_ZTSSt14_Optional_baseImLb1ELb1EE", !311, i64 0}
+!311 = !{!"_ZTSSt17_Optional_payloadImLb1ELb1ELb1EE", !5, i64 0, !37, i64 8}
+!312 = !{!313, !37, i64 32}
+!313 = !{!"_ZTSSt14_Optional_baseIN12_GLOBAL__N_117RootSetStatisticsELb1ELb1EE", !314, i64 0}
+!314 = !{!"_ZTSSt17_Optional_payloadIN12_GLOBAL__N_117RootSetStatisticsELb1ELb1ELb1EE", !5, i64 0, !37, i64 32}
+!315 = !{!112, !49, i64 56}
+!316 = !{!112, !4, i64 0}
+!317 = !{!112, !49, i64 48}
+!318 = !{!112, !49, i64 64}
+!319 = !{!320}
+!320 = distinct !{!320, !321, !"_ZN6kotlin2mm11ShadowStack5beginEv: argument 0"}
+!321 = distinct !{!321, !"_ZN6kotlin2mm11ShadowStack5beginEv"}
+!322 = !{!323, !4, i64 0}
+!323 = !{!"_ZTSN6kotlin2mm11ShadowStack8IteratorE", !4, i64 0, !4, i64 8, !4, i64 16}
+!324 = !{!323, !4, i64 16}
+!325 = !{!323, !4, i64 8}
+!326 = !{!327, !4, i64 0}
+!327 = !{!"_ZTSN9__gnu_cxx17__normal_iteratorIPP9ObjHeaderSt6vectorIS2_N6kotlin11std_support9allocatorIS2_EEEEE", !4, i64 0}
+!328 = !{!20, !4, i64 104}
+!329 = !{!330, !4, i64 0}
+!330 = !{!"_ZTSN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE8ProducerE", !4, i64 0, !331, i64 8, !157, i64 24, !4, i64 32, !49, i64 40, !49, i64 48}
+!331 = !{!"_ZTSN6kotlin2gc15AllocatorWithGCINS0_9AllocatorENS0_22ConcurrentMarkAndSweep10ThreadDataEEE", !332, i64 0, !4, i64 8}
+!332 = !{!"_ZTSN6kotlin2gc9AllocatorE"}
+!333 = !{!334, !4, i64 8}
+!334 = !{!"_ZTSN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEEE", !157, i64 0, !4, i64 8, !49, i64 16, !49, i64 24, !335, i64 32}
+!335 = !{!"_ZTSN6kotlin8SpinLockILNS_24MutexThreadStateHandlingE0EEE", !336, i64 0}
+!336 = !{!"_ZTSSt11atomic_flag"}
+!337 = !{!330, !4, i64 32}
+!338 = !{!20, !11, i64 20}
+!339 = !{!20, !4, i64 0}
+!340 = !{!341, !37, i64 16}
+!341 = !{!"_ZTSSt14_Optional_baseIN6kotlin2gc11MemoryUsageELb1ELb1EE", !342, i64 0}
+!342 = !{!"_ZTSSt17_Optional_payloadIN6kotlin2gc11MemoryUsageELb1ELb1ELb1EE", !5, i64 0, !37, i64 16}
 !343 = !{!344, !4, i64 0}
-!344 = !{!"_ZTSZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS1_EERNS0_11GCSchedulerEE3$_3", !4, i64 0}
-!345 = !{!346, !348, !350}
-!346 = distinct !{!346, !347, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE4LockEv: argument 0"}
-!347 = distinct !{!347, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE4LockEv"}
-!348 = distinct !{!348, !349, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE11LockForIterEv: argument 0"}
-!349 = distinct !{!349, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE11LockForIterEv"}
-!350 = distinct !{!350, !351, !"_ZN6kotlin2mm14ThreadRegistry11LockForIterEv: argument 0"}
-!351 = distinct !{!351, !"_ZN6kotlin2mm14ThreadRegistry11LockForIterEv"}
-!352 = !{!353, !71, i64 8}
-!353 = !{!"_ZTSSt14_Optional_baseIlLb1ELb1EE", !354, i64 0}
-!354 = !{!"_ZTSSt17_Optional_payloadIlLb1ELb1ELb1EE", !5, i64 0, !71, i64 8}
-!355 = !{!356, !358, !360}
-!356 = distinct !{!356, !357, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE4LockEv: argument 0"}
-!357 = distinct !{!357, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE4LockEv"}
-!358 = distinct !{!358, !359, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE11LockForIterEv: argument 0"}
-!359 = distinct !{!359, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE11LockForIterEv"}
-!360 = distinct !{!360, !361, !"_ZN6kotlin2mm14ThreadRegistry11LockForIterEv: argument 0"}
-!361 = distinct !{!361, !"_ZN6kotlin2mm14ThreadRegistry11LockForIterEv"}
-!362 = !{i64 0, i64 8, !89, i64 8, i64 8, !89}
-!363 = !{!364, !4, i64 0}
-!364 = !{!"_ZTSSt14_List_iteratorIN6kotlin16MultiSourceQueueINS0_2mm15ExtraObjectDataENS0_8SpinLockILNS0_24MutexThreadStateHandlingE0EEENS0_19ObjectPoolAllocatorIS3_EEE4NodeEE", !4, i64 0}
-!365 = !{!366, !368}
-!366 = distinct !{!366, !367, !"_ZN6kotlin16MultiSourceQueueINS_2mm15ExtraObjectDataENS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_19ObjectPoolAllocatorIS2_EEE11LockForIterEv: argument 0"}
-!367 = distinct !{!367, !"_ZN6kotlin16MultiSourceQueueINS_2mm15ExtraObjectDataENS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_19ObjectPoolAllocatorIS2_EEE11LockForIterEv"}
-!368 = distinct !{!368, !369, !"_ZN6kotlin2mm22ExtraObjectDataFactory11LockForIterEv: argument 0"}
-!369 = distinct !{!369, !"_ZN6kotlin2mm22ExtraObjectDataFactory11LockForIterEv"}
-!370 = !{!371, !4, i64 8}
-!371 = !{!"_ZTSN12_GLOBAL__N_120WeakReferenceCounterE", !15, i64 0, !4, i64 8, !11, i64 16, !11, i64 20}
-!372 = !{!373, !4, i64 0}
-!373 = !{!"_ZTSN6kotlin2mm15ExtraObjectDataE", !4, i64 0, !374, i64 8, !375, i64 16}
-!374 = !{!"_ZTSSt6atomicIjE"}
-!375 = !{!"_ZTSSt6atomicIP9ObjHeaderE", !376, i64 0}
-!376 = !{!"_ZTSSt13__atomic_baseIP9ObjHeaderE", !4, i64 0}
-!377 = !{!170, !4, i64 0}
-!378 = !{!379, !381}
-!379 = distinct !{!379, !380, !"_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE11LockForIterEv: argument 0"}
-!380 = distinct !{!380, !"_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE11LockForIterEv"}
-!381 = distinct !{!381, !382, !"_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE11LockForIterEv: argument 0"}
-!382 = distinct !{!382, !"_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE11LockForIterEv"}
-!383 = !{!384}
-!384 = distinct !{!384, !385, !"_ZN6kotlin2gc5SweepIN12_GLOBAL__N_111SweepTraitsEEENT_13ObjectFactory14FinalizerQueueENS0_8GCHandleERNS4_13ObjectFactory8IterableE: argument 0"}
-!385 = distinct !{!385, !"_ZN6kotlin2gc5SweepIN12_GLOBAL__N_111SweepTraitsEEENT_13ObjectFactory14FinalizerQueueENS0_8GCHandleERNS4_13ObjectFactory8IterableE"}
-!386 = !{!330, !50, i64 16}
-!387 = !{!330, !50, i64 24}
-!388 = !{!389, !4, i64 8}
-!389 = !{!"_ZTSSt4pairISt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS1_2gc15AllocatorWithGCINS5_9AllocatorENS5_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSB_7DeleterISC_EEEPSC_E", !159, i64 0, !4, i64 8}
-!390 = !{!158, !4, i64 8}
-!391 = !{!158, !50, i64 16}
-!392 = !{!162, !4, i64 24}
-!393 = !{!394}
-!394 = distinct !{!394, !395, !"_ZNSt6thread14__make_invokerIPFvN6kotlin12ScopedThread10attributesEOZNS1_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0EJRKS3_S6_EEENS_8_InvokerISt5tupleIJNSt5decayIT_E4typeEDpNSE_IT0_E4typeEEEEEOSF_DpOSI_: argument 0"}
-!395 = distinct !{!395, !"_ZNSt6thread14__make_invokerIPFvN6kotlin12ScopedThread10attributesEOZNS1_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0EJRKS3_S6_EEENS_8_InvokerISt5tupleIJNSt5decayIT_E4typeEDpNSE_IT0_E4typeEEEEEOSF_DpOSI_"}
-!396 = !{!397, !4, i64 0}
-!397 = !{!"_ZTSSt10_Head_baseILm0EPFvN6kotlin12ScopedThread10attributesEOZNS0_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0ELb0EE", !4, i64 0}
-!398 = !{!399}
-!399 = distinct !{!399, !400, !"_ZNSt6thread13_S_make_stateINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0ES5_S8_EEEEEESt10unique_ptrINS_6_StateESt14default_deleteISF_EEOT_: argument 0"}
-!400 = distinct !{!400, !"_ZNSt6thread13_S_make_stateINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0ES5_S8_EEEEEESt10unique_ptrINS_6_StateESt14default_deleteISF_EEOT_"}
-!401 = !{!145, !4, i64 8}
-!402 = !{!403, !4, i64 0}
-!403 = !{!"_ZTSZN6kotlin2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0", !4, i64 0}
-!404 = !{!405, !407}
-!405 = distinct !{!405, !406, !"_ZN6kotlin11std_support15allocate_uniqueINS_2gc2GC10ThreadData4ImplENS0_9allocatorIS5_EEJRS3_RNS_2mm10ThreadDataEEEEDaRKT0_DpOT1_: argument 0"}
-!406 = distinct !{!406, !"_ZN6kotlin11std_support15allocate_uniqueINS_2gc2GC10ThreadData4ImplENS0_9allocatorIS5_EEJRS3_RNS_2mm10ThreadDataEEEEDaRKT0_DpOT1_"}
-!407 = distinct !{!407, !408, !"_ZN6kotlin11std_support11make_uniqueINS_2gc2GC10ThreadData4ImplEJRS3_RNS_2mm10ThreadDataEEEEDaDpOT0_: argument 0"}
-!408 = distinct !{!408, !"_ZN6kotlin11std_support11make_uniqueINS_2gc2GC10ThreadData4ImplEJRS3_RNS_2mm10ThreadDataEEEEDaDpOT0_"}
-!409 = !{!410, !405, !407}
-!410 = distinct !{!410, !411, !"_ZN6kotlin2gc11GCScheduler13NewThreadDataEv: argument 0"}
-!411 = distinct !{!411, !"_ZN6kotlin2gc11GCScheduler13NewThreadDataEv"}
-!412 = !{!410}
-!413 = !{i64 8, i64 8, !3}
-!414 = !{!415, !4, i64 0}
-!415 = !{!"_ZTSSt10_Head_baseILm0EPN6kotlin2gc2GC10ThreadData4ImplELb0EE", !4, i64 0}
-!416 = !{!417, !4, i64 0}
-!417 = !{!"_ZTSZN6kotlin2gc11GCScheduler13NewThreadDataEvEUlRT_E_", !4, i64 0}
-!418 = !{!327, !4, i64 8}
-!419 = !{!420}
-!420 = distinct !{!420, !421, !"_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE4Node6CreateERS8_m: argument 0"}
-!421 = distinct !{!421, !"_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE4Node6CreateERS8_m"}
-!422 = !{!293, !4, i64 16}
-!423 = !{!115, !4, i64 24}
-!424 = !{!293, !4, i64 0}
-!425 = !{!326, !50, i64 40}
-!426 = !{!326, !50, i64 48}
-!427 = !{!428, !429, i64 0}
-!428 = !{!"mi_option_desc_s", !429, i64 0, !430, i64 8, !430, i64 12, !432, i64 16}
-!429 = !{!"long", !430, i64 0}
-!430 = !{!"omnipotent char", !431, i64 0}
-!431 = !{!"Simple C/C++ TBAA"}
-!432 = !{!"any pointer", !430, i64 0}
-!433 = !{!428, !430, i64 8}
-!434 = !{!432, !432, i64 0}
-!435 = !{!"branch_weights", i32 -294967296, i32 6003000}
-!436 = !{!"branch_weights", i32 2000, i32 1}
-!437 = !{!"misexpect", i64 0, i64 2000, i64 1}
-!438 = !{!439, !432, i64 8}
-!439 = !{!"mi_page_s", !430, i64 0, !430, i64 1, !430, i64 1, !430, i64 1, !430, i64 1, !440, i64 2, !440, i64 4, !430, i64 6, !430, i64 7, !430, i64 7, !432, i64 8, !441, i64 16, !441, i64 20, !432, i64 24, !430, i64 32, !430, i64 40, !432, i64 48, !432, i64 56}
-!440 = !{!"short", !430, i64 0}
-!441 = !{!"int", !430, i64 0}
-!442 = !{!439, !441, i64 16}
-!443 = !{!444, !429, i64 0}
-!444 = !{!"mi_block_s", !429, i64 0}
-!445 = !{!446, !429, i64 96}
-!446 = !{!"mi_segment_s", !429, i64 0, !447, i64 8, !447, i64 9, !430, i64 16, !432, i64 24, !432, i64 32, !429, i64 40, !429, i64 48, !429, i64 56, !429, i64 64, !429, i64 72, !429, i64 80, !429, i64 88, !429, i64 96, !430, i64 104, !430, i64 112, !430, i64 120}
-!447 = !{!"_Bool", !430, i64 0}
-!448 = !{!449, !429, i64 2856}
-!449 = !{!"mi_heap_s", !432, i64 0, !430, i64 8, !430, i64 1040, !430, i64 2840, !429, i64 2848, !429, i64 2856, !430, i64 2864, !450, i64 2880, !429, i64 3016, !429, i64 3024, !429, i64 3032, !432, i64 3040, !447, i64 3048}
-!450 = !{!"mi_random_cxt_s", !430, i64 0, !430, i64 64, !441, i64 128}
-!451 = !{i32 106872}
-!452 = !{!449, !429, i64 2848}
-!453 = !{!429, !429, i64 0}
-!454 = !{!430, !430, i64 0}
-!455 = !{!428, !432, i64 16}
-!456 = !{!457, !429, i64 0}
-!457 = !{!"timespec", !429, i64 0, !429, i64 8}
-!458 = !{!457, !429, i64 8}
-!459 = !{!441, !441, i64 0}
-!460 = !{!450, !441, i64 128}
-!461 = !{!449, !432, i64 0}
-!462 = !{!463, !432, i64 16}
-!463 = !{!"buffered_s", !432, i64 0, !432, i64 8, !432, i64 16, !429, i64 24, !429, i64 32}
-!464 = !{!465, !429, i64 8}
-!465 = !{!"mi_stat_counter_s", !429, i64 0, !429, i64 8}
-!466 = !{!465, !429, i64 0}
-!467 = !{!468, !429, i64 0}
-!468 = !{!"timeval", !429, i64 0, !429, i64 8}
-!469 = !{!468, !429, i64 8}
-!470 = !{!471, !429, i64 8}
-!471 = !{!"mi_arena_s", !430, i64 0, !429, i64 8, !429, i64 16, !441, i64 24, !447, i64 28, !447, i64 29, !447, i64 30, !430, i64 32, !432, i64 40, !432, i64 48, !430, i64 56}
-!472 = !{!471, !429, i64 16}
-!473 = !{!471, !430, i64 0}
-!474 = !{!471, !441, i64 24}
-!475 = !{!471, !447, i64 30}
-!476 = !{!471, !447, i64 28}
-!477 = !{!471, !447, i64 29}
-!478 = !{!471, !430, i64 32}
-!479 = !{!471, !432, i64 40}
-!480 = !{!471, !432, i64 48}
-!481 = !{i64 0, i64 65}
-!482 = !{!447, !447, i64 0}
-!483 = !{!484, !432, i64 16}
-!484 = !{!"mi_tld_s", !485, i64 0, !447, i64 8, !432, i64 16, !432, i64 24, !486, i64 32, !489, i64 160, !490, i64 176}
-!485 = !{!"long long", !430, i64 0}
-!486 = !{!"mi_segments_tld_s", !487, i64 0, !487, i64 16, !488, i64 32, !429, i64 56, !429, i64 64, !429, i64 72, !429, i64 80, !429, i64 88, !429, i64 96, !432, i64 104, !432, i64 112, !432, i64 120}
-!487 = !{!"mi_segment_queue_s", !432, i64 0, !432, i64 8}
-!488 = !{!"mi_page_queue_s", !432, i64 0, !432, i64 8, !429, i64 16}
-!489 = !{!"mi_os_tld_s", !429, i64 0, !432, i64 8}
-!490 = !{!"mi_stats_s", !491, i64 0, !491, i64 32, !491, i64 64, !491, i64 96, !491, i64 128, !491, i64 160, !491, i64 192, !491, i64 224, !491, i64 256, !491, i64 288, !491, i64 320, !491, i64 352, !491, i64 384, !491, i64 416, !465, i64 448, !465, i64 464, !465, i64 480, !465, i64 496, !465, i64 512, !465, i64 528, !465, i64 544, !465, i64 560}
-!491 = !{!"mi_stat_count_s", !429, i64 0, !429, i64 8, !429, i64 16, !429, i64 24}
-!492 = !{!484, !432, i64 24}
-!493 = !{!449, !432, i64 3040}
-!494 = !{!449, !429, i64 3016}
-!495 = !{!449, !430, i64 2840}
-!496 = !{!488, !432, i64 0}
-!497 = !{!488, !432, i64 8}
-!498 = !{!"branch_weights", i32 2000, i32 3, i32 2000, i32 2000}
-!499 = !{!439, !432, i64 48}
-!500 = !{!488, !429, i64 16}
-!501 = distinct !{!501, !27}
-!502 = distinct !{!502, !29}
-!503 = distinct !{!503, !37, !27}
-!504 = !{!439, !432, i64 56}
-!505 = !{!484, !432, i64 144}
-!506 = !{!484, !432, i64 152}
-!507 = !{!484, !432, i64 168}
-!508 = distinct !{!508, !29}
-!509 = !{!428, !430, i64 12}
-!510 = !{!491, !429, i64 24}
-!511 = !{!491, !429, i64 16}
-!512 = !{!491, !429, i64 0}
-!513 = !{!491, !429, i64 8}
-!514 = !{!484, !485, i64 0}
-!515 = !{!484, !447, i64 8}
-!516 = !{!449, !447, i64 3048}
-!517 = !{!"branch_weights", i32 1073205, i32 2146410443}
-!518 = !{!"branch_weights", i32 2000, i32 2, i32 2000}
-!519 = !{!449, !429, i64 3024}
-!520 = !{!449, !429, i64 3032}
-!521 = distinct !{!521, !27}
-!522 = distinct !{!522, !29}
-!523 = distinct !{!523, !37, !27}
-!524 = !{!446, !429, i64 40}
-!525 = !{!486, !432, i64 112}
-!526 = !{!446, !429, i64 56}
-!527 = !{!486, !432, i64 104}
-!528 = !{!486, !429, i64 88}
-!529 = !{!446, !432, i64 24}
-!530 = !{!446, !429, i64 72}
-!531 = !{!446, !430, i64 104}
-!532 = !{!486, !429, i64 56}
-!533 = !{!486, !429, i64 64}
-!534 = !{!486, !429, i64 72}
-!535 = !{!486, !429, i64 80}
-!536 = !{!446, !429, i64 64}
-!537 = !{!446, !429, i64 0}
-!538 = !{!439, !440, i64 2}
-!539 = !{!439, !432, i64 24}
-!540 = distinct !{!540, !27}
-!541 = distinct !{!541, !29}
-!542 = distinct !{!542, !37, !27}
-!543 = distinct !{!543, !29}
-!544 = !{!446, !447, i64 8}
-!545 = !{!446, !430, i64 112}
-!546 = !{!439, !430, i64 0}
-!547 = !{!446, !429, i64 80}
-!548 = !{!487, !432, i64 8}
-!549 = !{!446, !432, i64 32}
-!550 = !{!439, !441, i64 20}
-!551 = !{!439, !440, i64 4}
-!552 = !{!486, !432, i64 32}
-!553 = !{!486, !432, i64 40}
-!554 = !{!487, !432, i64 0}
-!555 = !{!446, !429, i64 48}
-!556 = !{!"branch_weights", i32 4001, i32 4000000}
-!557 = distinct !{!557, !27}
-!558 = distinct !{!558, !29}
-!559 = distinct !{!559, !37, !27}
-!560 = distinct !{!560, !27}
-!561 = distinct !{!561, !29}
-!562 = distinct !{!562, !37, !27}
-!563 = !{i32 141452}
-!564 = distinct !{!564, !27}
-!565 = distinct !{!565, !29}
-!566 = distinct !{!566, !37, !27}
-!567 = !{i32 117678}
-!568 = !{!463, !429, i64 24}
-!569 = !{!463, !429, i64 32}
-!570 = !{!463, !432, i64 0}
-!571 = !{!463, !432, i64 8}
-!572 = distinct !{!572, !27}
-!573 = distinct !{!573, !29}
-!574 = distinct !{!574, !37, !27}
-!575 = distinct !{!575, !27}
-!576 = distinct !{!576, !29}
-!577 = distinct !{!577, !37, !27}
-!578 = distinct !{!578, !27}
-!579 = distinct !{!579, !29}
-!580 = distinct !{!580, !37, !27}
-!581 = !{!489, !429, i64 0}
-!582 = !{!583, !430, i64 48}
-!583 = !{!"mem_region_s", !430, i64 0, !430, i64 8, !430, i64 16, !430, i64 24, !430, i64 32, !430, i64 40, !430, i64 48, !429, i64 56}
-!584 = !{!446, !447, i64 9}
-!585 = !{!446, !429, i64 88}
-!586 = distinct !{!586, !29}
-!587 = !{!588, !4, i64 8}
-!588 = !{!"_ZTSSt12_Vector_baseIPvN6kotlin11std_support9allocatorIS0_EEE", !589, i64 0}
-!589 = !{!"_ZTSNSt12_Vector_baseIPvN6kotlin11std_support9allocatorIS0_EEE12_Vector_implE", !4, i64 0, !4, i64 8, !4, i64 16}
-!590 = !{!588, !4, i64 0}
-!591 = !{!588, !4, i64 16}
-!592 = !{!593}
-!593 = distinct !{!593, !594}
-!594 = distinct !{!594, !"LVerDomain"}
-!595 = !{!596}
-!596 = distinct !{!596, !594}
-!597 = distinct !{!597, !27}
-!598 = distinct !{!598, !29}
-!599 = distinct !{!599, !27}
-!600 = !{!601, !4, i64 0}
-!601 = !{!"_ZTS7Dl_info", !4, i64 0, !4, i64 8, !4, i64 16, !4, i64 24}
-!602 = !{!601, !4, i64 16}
-!603 = !{!601, !4, i64 24}
-!604 = !{!605, !50, i64 48}
-!605 = !{!"_ZTS4stat", !50, i64 0, !50, i64 8, !50, i64 16, !11, i64 24, !11, i64 28, !11, i64 32, !11, i64 36, !50, i64 40, !50, i64 48, !50, i64 56, !50, i64 64, !91, i64 72, !91, i64 88, !91, i64 104, !5, i64 120}
-!606 = !{!607, !50, i64 40}
-!607 = !{!"_ZTS10Elf64_Ehdr", !5, i64 0, !35, i64 16, !35, i64 18, !11, i64 20, !50, i64 24, !50, i64 32, !50, i64 40, !11, i64 48, !35, i64 52, !35, i64 54, !35, i64 56, !35, i64 58, !35, i64 60, !35, i64 62}
-!608 = !{!607, !35, i64 60}
-!609 = !{!610, !11, i64 4}
-!610 = !{!"_ZTS10Elf64_Shdr", !11, i64 0, !11, i64 4, !50, i64 8, !50, i64 16, !50, i64 24, !50, i64 32, !11, i64 40, !11, i64 44, !50, i64 48, !50, i64 56}
-!611 = !{!610, !50, i64 24}
-!612 = !{!610, !50, i64 32}
-!613 = !{!610, !11, i64 40}
-!614 = !{!615, !4, i64 8}
-!615 = !{!"_ZTSSt12_Vector_baseIN12_GLOBAL__N_19SymRecordEN6kotlin11std_support9allocatorIS1_EEE", !616, i64 0}
-!616 = !{!"_ZTSNSt12_Vector_baseIN12_GLOBAL__N_19SymRecordEN6kotlin11std_support9allocatorIS1_EEE12_Vector_implE", !4, i64 0, !4, i64 8, !4, i64 16}
-!617 = !{!615, !4, i64 16}
-!618 = !{i64 0, i64 8, !3, i64 8, i64 8, !3, i64 16, i64 8, !3}
-!619 = !{!615, !4, i64 0}
-!620 = !{!621, !50, i64 8}
-!621 = !{!"_ZTS9Elf64_Sym", !11, i64 0, !5, i64 4, !5, i64 5, !35, i64 6, !50, i64 8, !50, i64 16}
-!622 = !{!621, !50, i64 16}
-!623 = !{!621, !11, i64 0}
-!624 = !{!625, !50, i64 0}
-!625 = !{!"_ZTSN12_GLOBAL__N_19BacktraceE", !50, i64 0, !50, i64 8, !626, i64 16}
-!626 = !{!"_ZTSN6kotlin11std_support4spanIPvLm18446744073709551615EEE", !4, i64 0, !50, i64 8}
-!627 = !{!625, !50, i64 8}
-!628 = !{i64 0, i64 8, !3, i64 8, i64 8, !89}
-!629 = !{!626, !50, i64 8}
-!630 = !{!626, !4, i64 0}
-!631 = distinct !{!631, !29}
-!632 = distinct !{!632, !29}
-!633 = !{!634, !4, i64 8}
-!634 = !{!"_ZTSN12_GLOBAL__N_111CleanerImplE", !15, i64 0, !4, i64 8}
-!635 = !{!636, !50, i64 8}
-!636 = !{!"_ZTSSt10_HashtableIiSt4pairIKiP6WorkerEN6kotlin11std_support9allocatorIS4_EENSt8__detail10_Select1stESt8equal_toIiESt4hashIiENS9_18_Mod_range_hashingENS9_20_Default_ranged_hashENS9_20_Prime_rehash_policyENS9_17_Hashtable_traitsILb0ELb0ELb1EEEE", !4, i64 0, !50, i64 8, !205, i64 16, !50, i64 24, !206, i64 32, !4, i64 48}
-!637 = !{!636, !4, i64 0}
-!638 = !{!639, !4, i64 8}
-!639 = !{!"_ZTSSt4pairIKiP6WorkerE", !11, i64 0, !4, i64 8}
-!640 = !{!641, !4, i64 48}
-!641 = !{!"_ZTSSt11_Deque_baseIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE", !642, i64 0}
-!642 = !{!"_ZTSNSt11_Deque_baseIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE11_Deque_implE", !4, i64 0, !50, i64 8, !643, i64 16, !643, i64 48}
-!643 = !{!"_ZTSSt15_Deque_iteratorIN12_GLOBAL__N_13JobERS1_PS1_E", !4, i64 0, !4, i64 8, !4, i64 16, !4, i64 24}
-!644 = !{!641, !4, i64 64}
-!645 = !{i64 0, i64 4, !51, i64 8, i64 8, !3, i64 16, i64 8, !3, i64 24, i64 8, !3, i64 32, i64 4, !73, i64 8, i64 8, !3, i64 16, i64 1, !70, i64 8, i64 8, !3, i64 16, i64 8, !89}
-!646 = !{!641, !50, i64 8}
-!647 = !{!641, !4, i64 72}
-!648 = !{!641, !4, i64 0}
-!649 = !{!641, !4, i64 40}
-!650 = !{!643, !4, i64 24}
-!651 = !{!643, !4, i64 8}
-!652 = !{!643, !4, i64 16}
-!653 = !{!654, !4, i64 8}
-!654 = !{!"_ZTSN12_GLOBAL__N_120WorkerBoundReferenceE", !15, i64 0, !4, i64 8}
-!655 = !{!656, !4, i64 0}
-!656 = !{!"_ZTS16KRefSharedHolder", !4, i64 0, !4, i64 8}
-!657 = !{!656, !4, i64 8}
-!658 = !{!659, !4, i64 0}
-!659 = !{!"_ZTSSt10_HashtableIiSt4pairIKiPN12_GLOBAL__N_16FutureEEN6kotlin11std_support9allocatorIS5_EENSt8__detail10_Select1stESt8equal_toIiESt4hashIiENSA_18_Mod_range_hashingENSA_20_Default_ranged_hashENSA_20_Prime_rehash_policyENSA_17_Hashtable_traitsILb0ELb0ELb1EEEE", !4, i64 0, !50, i64 8, !205, i64 16, !50, i64 24, !206, i64 32, !4, i64 48}
-!660 = !{!659, !50, i64 8}
-!661 = !{!662, !4, i64 0}
-!662 = !{!"_ZTSSt10_HashtableIiSt4pairIKimEN6kotlin11std_support9allocatorIS2_EENSt8__detail10_Select1stESt8equal_toIiESt4hashIiENS7_18_Mod_range_hashingENS7_20_Default_ranged_hashENS7_20_Prime_rehash_policyENS7_17_Hashtable_traitsILb0ELb0ELb1EEEE", !4, i64 0, !50, i64 8, !205, i64 16, !50, i64 24, !206, i64 32, !4, i64 48}
-!663 = !{!662, !50, i64 8}
-!664 = !{!665, !11, i64 256}
-!665 = !{!"_ZTSN12_GLOBAL__N_15StateE", !5, i64 0, !5, i64 40, !666, i64 88, !667, i64 144, !668, i64 200, !11, i64 256, !11, i64 260, !11, i64 264}
-!666 = !{!"_ZTSSt13unordered_mapIiPN12_GLOBAL__N_16FutureESt4hashIiESt8equal_toIiEN6kotlin11std_support9allocatorISt4pairIKiS2_EEEE", !659, i64 0}
-!667 = !{!"_ZTSSt13unordered_mapIiP6WorkerSt4hashIiESt8equal_toIiEN6kotlin11std_support9allocatorISt4pairIKiS1_EEEE", !636, i64 0}
-!668 = !{!"_ZTSSt13unordered_mapIimSt4hashIiESt8equal_toIiEN6kotlin11std_support9allocatorISt4pairIKimEEEE", !662, i64 0}
-!669 = !{!665, !11, i64 260}
-!670 = !{!665, !11, i64 264}
-!671 = !{!662, !4, i64 16}
-!672 = !{!636, !4, i64 16}
-!673 = !{!659, !4, i64 16}
-!674 = !{!"branch_weights", i32 1, i32 1048575}
-!675 = !{!676, !4, i64 0}
-!676 = !{!"_ZTSN12_GLOBAL__N_116TerminateHandlerE", !4, i64 0}
-!677 = !{!678, !11, i64 0}
-!678 = !{!"_ZTSN6kotlin2mm10ThreadDataE", !11, i64 0, !679, i64 8, !275, i64 64, !680, i64 168, !681, i64 224, !8, i64 280, !682, i64 288, !686, i64 296, !253, i64 320}
-!679 = !{!"_ZTSN6kotlin2mm15GlobalsRegistry11ThreadQueueE"}
-!680 = !{!"_ZTSN6kotlin2mm17StableRefRegistry11ThreadQueueE"}
-!681 = !{!"_ZTSN6kotlin2mm22ExtraObjectDataFactory11ThreadQueueE"}
-!682 = !{!"_ZTSN6kotlin2gc2GC10ThreadDataE", !683, i64 0}
-!683 = !{!"_ZTSSt10unique_ptrIN6kotlin2gc2GC10ThreadData4ImplENS0_11std_support17allocator_deleterIS4_NS5_9allocatorIS4_EEEEE", !684, i64 0}
-!684 = !{!"_ZTSSt15__uniq_ptr_implIN6kotlin2gc2GC10ThreadData4ImplENS0_11std_support17allocator_deleterIS4_NS5_9allocatorIS4_EEEEE", !685, i64 0}
-!685 = !{!"_ZTSSt5tupleIJPN6kotlin2gc2GC10ThreadData4ImplENS0_11std_support17allocator_deleterIS4_NS6_9allocatorIS4_EEEEEE"}
-!686 = !{!"_ZTSSt6vectorISt4pairIPP9ObjHeaderS2_EN6kotlin11std_support9allocatorIS4_EEE"}
-!687 = !{!688}
-!688 = distinct !{!688, !689, !"_ZN6kotlin11std_support15allocate_uniqueINS_14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS0_9allocatorIS4_EEE4NodeENS6_IS9_EEJRSA_iEEEDaRKT0_DpOT1_: argument 0"}
-!689 = distinct !{!689, !"_ZN6kotlin11std_support15allocate_uniqueINS_14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS0_9allocatorIS4_EEE4NodeENS6_IS9_EEJRSA_iEEEDaRKT0_DpOT1_"}
-!690 = !{!254, !255, i64 0}
-!691 = !{!692, !4, i64 360}
-!692 = !{!"_ZTSN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE4NodeE", !678, i64 8, !693, i64 352, !4, i64 360}
-!693 = !{!"_ZTSSt10unique_ptrIN6kotlin14SingleLockListINS0_2mm10ThreadDataESt15recursive_mutexNS0_11std_support9allocatorIS3_EEE4NodeENS5_17allocator_deleterIS9_NS6_IS9_EEEEE", !694, i64 0}
-!694 = !{!"_ZTSSt15__uniq_ptr_implIN6kotlin14SingleLockListINS0_2mm10ThreadDataESt15recursive_mutexNS0_11std_support9allocatorIS3_EEE4NodeENS5_17allocator_deleterIS9_NS6_IS9_EEEEE", !695, i64 0}
-!695 = !{!"_ZTSSt5tupleIJPN6kotlin14SingleLockListINS0_2mm10ThreadDataESt15recursive_mutexNS0_11std_support9allocatorIS3_EEE4NodeENS5_17allocator_deleterIS9_NS6_IS9_EEEEEE"}
-!696 = !{!697, !4, i64 16}
-!697 = !{!"_ZTSN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEEE", !693, i64 8, !4, i64 16, !698, i64 24}
-!698 = !{!"_ZTSSt15recursive_mutex"}
-!699 = !{!700, !4, i64 0}
-!700 = !{!"_ZTSN12_GLOBAL__N_112RuntimeStateE", !4, i64 0, !4, i64 8, !5, i64 16}
-!701 = !{!702, !11, i64 0}
-!702 = !{!"_ZTS6Worker", !11, i64 0, !5, i64 4, !703, i64 8, !704, i64 88, !4, i64 136, !5, i64 144, !5, i64 184, !5, i64 232, !71, i64 236, !50, i64 240, !4, i64 248}
-!703 = !{!"_ZTSSt5dequeIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE"}
-!704 = !{!"_ZTSSt8multisetIN12_GLOBAL__N_13JobENS0_10JobCompareEN6kotlin11std_support9allocatorIS1_EEE", !705, i64 0}
-!705 = !{!"_ZTSSt8_Rb_treeIN12_GLOBAL__N_13JobES1_St9_IdentityIS1_ENS0_10JobCompareEN6kotlin11std_support9allocatorIS1_EEE", !706, i64 0}
-!706 = !{!"_ZTSNSt8_Rb_treeIN12_GLOBAL__N_13JobES1_St9_IdentityIS1_ENS0_10JobCompareEN6kotlin11std_support9allocatorIS1_EEE13_Rb_tree_implIS4_Lb1EEE"}
-!707 = !{!702, !5, i64 4}
-!708 = !{!641, !4, i64 16}
-!709 = !{!710, !4, i64 16}
-!710 = !{!"_ZTSSt15_Rb_tree_header", !711, i64 0, !50, i64 32}
-!711 = !{!"_ZTSSt18_Rb_tree_node_base", !712, i64 0, !4, i64 8, !4, i64 16, !4, i64 24}
-!712 = !{!"_ZTSSt14_Rb_tree_color", !5, i64 0}
-!713 = !{!710, !4, i64 24}
-!714 = !{!639, !11, i64 0}
-!715 = !{!636, !50, i64 24}
-!716 = !{!636, !4, i64 48}
-!717 = !{!702, !50, i64 240}
-!718 = !{!702, !4, i64 248}
-!719 = !{!700, !4, i64 8}
-!720 = !{!721, !4, i64 0}
-!721 = !{!"_ZTS8InitNode", !4, i64 0, !4, i64 8}
-!722 = !{!220, !4, i64 8}
-!723 = !{!220, !4, i64 16}
-!724 = !{!725}
-!725 = distinct !{!725, !726}
-!726 = distinct !{!726, !"LVerDomain"}
-!727 = !{!728}
-!728 = distinct !{!728, !726}
-!729 = distinct !{!729, !27}
-!730 = distinct !{!730, !29}
-!731 = distinct !{!731, !27}
-!732 = !{!275, !278, i64 80}
-!733 = !{!700, !5, i64 16}
-!734 = !{!735, !4, i64 8}
-!735 = !{!"_ZTSN5konan16DestructorRecordE", !4, i64 0, !4, i64 8, !4, i64 16}
-!736 = !{!735, !4, i64 16}
-!737 = !{!735, !4, i64 0}
-!738 = !{!643, !4, i64 0}
+!344 = !{!"_ZTSZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS1_EERNS0_11GCSchedulerEE3$_1", !4, i64 0}
+!345 = !{!346, !4, i64 0}
+!346 = !{!"_ZTSZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS1_EERNS0_11GCSchedulerEE3$_3", !4, i64 0}
+!347 = !{!348, !350, !352}
+!348 = distinct !{!348, !349, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE4LockEv: argument 0"}
+!349 = distinct !{!349, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE4LockEv"}
+!350 = distinct !{!350, !351, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE11LockForIterEv: argument 0"}
+!351 = distinct !{!351, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE11LockForIterEv"}
+!352 = distinct !{!352, !353, !"_ZN6kotlin2mm14ThreadRegistry11LockForIterEv: argument 0"}
+!353 = distinct !{!353, !"_ZN6kotlin2mm14ThreadRegistry11LockForIterEv"}
+!354 = !{!355, !37, i64 8}
+!355 = !{!"_ZTSSt14_Optional_baseIlLb1ELb1EE", !356, i64 0}
+!356 = !{!"_ZTSSt17_Optional_payloadIlLb1ELb1ELb1EE", !5, i64 0, !37, i64 8}
+!357 = !{!358, !360, !362}
+!358 = distinct !{!358, !359, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE4LockEv: argument 0"}
+!359 = distinct !{!359, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE4LockEv"}
+!360 = distinct !{!360, !361, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE11LockForIterEv: argument 0"}
+!361 = distinct !{!361, !"_ZN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE11LockForIterEv"}
+!362 = distinct !{!362, !363, !"_ZN6kotlin2mm14ThreadRegistry11LockForIterEv: argument 0"}
+!363 = distinct !{!363, !"_ZN6kotlin2mm14ThreadRegistry11LockForIterEv"}
+!364 = !{i64 0, i64 8, !87, i64 8, i64 8, !87}
+!365 = !{!366, !4, i64 0}
+!366 = !{!"_ZTSSt14_List_iteratorIN6kotlin16MultiSourceQueueINS0_2mm15ExtraObjectDataENS0_8SpinLockILNS0_24MutexThreadStateHandlingE0EEENS0_19ObjectPoolAllocatorIS3_EEE4NodeEE", !4, i64 0}
+!367 = !{!368, !370}
+!368 = distinct !{!368, !369, !"_ZN6kotlin16MultiSourceQueueINS_2mm15ExtraObjectDataENS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_19ObjectPoolAllocatorIS2_EEE11LockForIterEv: argument 0"}
+!369 = distinct !{!369, !"_ZN6kotlin16MultiSourceQueueINS_2mm15ExtraObjectDataENS_8SpinLockILNS_24MutexThreadStateHandlingE0EEENS_19ObjectPoolAllocatorIS2_EEE11LockForIterEv"}
+!370 = distinct !{!370, !371, !"_ZN6kotlin2mm22ExtraObjectDataFactory11LockForIterEv: argument 0"}
+!371 = distinct !{!371, !"_ZN6kotlin2mm22ExtraObjectDataFactory11LockForIterEv"}
+!372 = !{!373, !4, i64 8}
+!373 = !{!"_ZTSN12_GLOBAL__N_120WeakReferenceCounterE", !15, i64 0, !4, i64 8, !11, i64 16, !11, i64 20}
+!374 = !{!375, !4, i64 0}
+!375 = !{!"_ZTSN6kotlin2mm15ExtraObjectDataE", !4, i64 0, !376, i64 8, !377, i64 16}
+!376 = !{!"_ZTSSt6atomicIjE"}
+!377 = !{!"_ZTSSt6atomicIP9ObjHeaderE", !378, i64 0}
+!378 = !{!"_ZTSSt13__atomic_baseIP9ObjHeaderE", !4, i64 0}
+!379 = !{!168, !4, i64 0}
+!380 = !{!381, !383}
+!381 = distinct !{!381, !382, !"_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE11LockForIterEv: argument 0"}
+!382 = distinct !{!382, !"_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE11LockForIterEv"}
+!383 = distinct !{!383, !384, !"_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE11LockForIterEv: argument 0"}
+!384 = distinct !{!384, !"_ZN6kotlin2mm13ObjectFactoryINS_2gc22ConcurrentMarkAndSweepEE11LockForIterEv"}
+!385 = !{!386}
+!386 = distinct !{!386, !387, !"_ZN6kotlin2gc5SweepIN12_GLOBAL__N_111SweepTraitsEEENT_13ObjectFactory14FinalizerQueueENS0_8GCHandleERNS4_13ObjectFactory8IterableE: argument 0"}
+!387 = distinct !{!387, !"_ZN6kotlin2gc5SweepIN12_GLOBAL__N_111SweepTraitsEEENT_13ObjectFactory14FinalizerQueueENS0_8GCHandleERNS4_13ObjectFactory8IterableE"}
+!388 = !{!334, !49, i64 16}
+!389 = !{!334, !49, i64 24}
+!390 = !{!391, !4, i64 8}
+!391 = !{!"_ZTSSt4pairISt10unique_ptrIN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS1_2gc15AllocatorWithGCINS5_9AllocatorENS5_22ConcurrentMarkAndSweep10ThreadDataEEEE4NodeENSB_7DeleterISC_EEEPSC_E", !157, i64 0, !4, i64 8}
+!392 = !{!156, !4, i64 8}
+!393 = !{!156, !49, i64 16}
+!394 = !{!160, !4, i64 24}
+!395 = !{!396}
+!396 = distinct !{!396, !397, !"_ZNSt6thread14__make_invokerIPFvN6kotlin12ScopedThread10attributesEOZNS1_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0EJRKS3_S6_EEENS_8_InvokerISt5tupleIJNSt5decayIT_E4typeEDpNSE_IT0_E4typeEEEEEOSF_DpOSI_: argument 0"}
+!397 = distinct !{!397, !"_ZNSt6thread14__make_invokerIPFvN6kotlin12ScopedThread10attributesEOZNS1_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0EJRKS3_S6_EEENS_8_InvokerISt5tupleIJNSt5decayIT_E4typeEDpNSE_IT0_E4typeEEEEEOSF_DpOSI_"}
+!398 = !{!399, !4, i64 0}
+!399 = !{!"_ZTSSt10_Head_baseILm0EPFvN6kotlin12ScopedThread10attributesEOZNS0_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0ELb0EE", !4, i64 0}
+!400 = !{!401}
+!401 = distinct !{!401, !402, !"_ZNSt6thread13_S_make_stateINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0ES5_S8_EEEEEESt10unique_ptrINS_6_StateESt14default_deleteISF_EEOT_: argument 0"}
+!402 = distinct !{!402, !"_ZNSt6thread13_S_make_stateINS_8_InvokerISt5tupleIJPFvN6kotlin12ScopedThread10attributesEOZNS3_2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0ES5_S8_EEEEEESt10unique_ptrINS_6_StateESt14default_deleteISF_EEOT_"}
+!403 = !{!143, !4, i64 8}
+!404 = !{!405, !4, i64 0}
+!405 = !{!"_ZTSZN6kotlin2gc18FinalizerProcessor26StartFinalizerThreadIfNoneEvE3$_0", !4, i64 0}
+!406 = !{!407, !4, i64 0}
+!407 = !{!"_ZTSZN6kotlin2gc22ConcurrentMarkAndSweepC1ERNS_2mm13ObjectFactoryIS1_EERNS0_11GCSchedulerEE3$_2", !4, i64 0}
+!408 = !{!409, !411}
+!409 = distinct !{!409, !410, !"_ZN6kotlin11std_support15allocate_uniqueINS_2gc2GC10ThreadData4ImplENS0_9allocatorIS5_EEJRS3_RNS_2mm10ThreadDataEEEEDaRKT0_DpOT1_: argument 0"}
+!410 = distinct !{!410, !"_ZN6kotlin11std_support15allocate_uniqueINS_2gc2GC10ThreadData4ImplENS0_9allocatorIS5_EEJRS3_RNS_2mm10ThreadDataEEEEDaRKT0_DpOT1_"}
+!411 = distinct !{!411, !412, !"_ZN6kotlin11std_support11make_uniqueINS_2gc2GC10ThreadData4ImplEJRS3_RNS_2mm10ThreadDataEEEEDaDpOT0_: argument 0"}
+!412 = distinct !{!412, !"_ZN6kotlin11std_support11make_uniqueINS_2gc2GC10ThreadData4ImplEJRS3_RNS_2mm10ThreadDataEEEEDaDpOT0_"}
+!413 = !{!414, !409, !411}
+!414 = distinct !{!414, !415, !"_ZN6kotlin2gc11GCScheduler13NewThreadDataEv: argument 0"}
+!415 = distinct !{!415, !"_ZN6kotlin2gc11GCScheduler13NewThreadDataEv"}
+!416 = !{!414}
+!417 = !{i64 8, i64 8, !3}
+!418 = !{!419, !4, i64 0}
+!419 = !{!"_ZTSSt10_Head_baseILm0EPN6kotlin2gc2GC10ThreadData4ImplELb0EE", !4, i64 0}
+!420 = !{!421, !4, i64 0}
+!421 = !{!"_ZTSZN6kotlin2gc11GCScheduler13NewThreadDataEvEUlRT_E_", !4, i64 0}
+!422 = !{!331, !4, i64 8}
+!423 = !{!424}
+!424 = distinct !{!424, !425, !"_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE4Node6CreateERS8_m: argument 0"}
+!425 = distinct !{!425, !"_ZN6kotlin2mm8internal20ObjectFactoryStorageILm8ENS_2gc15AllocatorWithGCINS3_9AllocatorENS3_22ConcurrentMarkAndSweep10ThreadDataEEEE4Node6CreateERS8_m"}
+!426 = !{!291, !4, i64 16}
+!427 = !{!113, !4, i64 24}
+!428 = !{!291, !4, i64 0}
+!429 = !{!330, !49, i64 40}
+!430 = !{!330, !49, i64 48}
+!431 = !{!432, !433, i64 0}
+!432 = !{!"mi_option_desc_s", !433, i64 0, !434, i64 8, !434, i64 12, !436, i64 16}
+!433 = !{!"long", !434, i64 0}
+!434 = !{!"omnipotent char", !435, i64 0}
+!435 = !{!"Simple C/C++ TBAA"}
+!436 = !{!"any pointer", !434, i64 0}
+!437 = !{!432, !434, i64 8}
+!438 = !{!436, !436, i64 0}
+!439 = !{!"branch_weights", i32 -294967296, i32 6003000}
+!440 = !{!"branch_weights", i32 2000, i32 1}
+!441 = !{!"misexpect", i64 0, i64 2000, i64 1}
+!442 = !{!443, !436, i64 8}
+!443 = !{!"mi_page_s", !434, i64 0, !434, i64 1, !434, i64 1, !434, i64 1, !434, i64 1, !444, i64 2, !444, i64 4, !434, i64 6, !434, i64 7, !434, i64 7, !436, i64 8, !445, i64 16, !445, i64 20, !436, i64 24, !434, i64 32, !434, i64 40, !436, i64 48, !436, i64 56}
+!444 = !{!"short", !434, i64 0}
+!445 = !{!"int", !434, i64 0}
+!446 = !{!443, !445, i64 16}
+!447 = !{!448, !433, i64 0}
+!448 = !{!"mi_block_s", !433, i64 0}
+!449 = !{!450, !433, i64 96}
+!450 = !{!"mi_segment_s", !433, i64 0, !451, i64 8, !451, i64 9, !434, i64 16, !436, i64 24, !436, i64 32, !433, i64 40, !433, i64 48, !433, i64 56, !433, i64 64, !433, i64 72, !433, i64 80, !433, i64 88, !433, i64 96, !434, i64 104, !434, i64 112, !434, i64 120}
+!451 = !{!"_Bool", !434, i64 0}
+!452 = !{!453, !433, i64 2856}
+!453 = !{!"mi_heap_s", !436, i64 0, !434, i64 8, !434, i64 1040, !434, i64 2840, !433, i64 2848, !433, i64 2856, !434, i64 2864, !454, i64 2880, !433, i64 3016, !433, i64 3024, !433, i64 3032, !436, i64 3040, !451, i64 3048}
+!454 = !{!"mi_random_cxt_s", !434, i64 0, !434, i64 64, !445, i64 128}
+!455 = !{i32 106872}
+!456 = !{!453, !433, i64 2848}
+!457 = !{!433, !433, i64 0}
+!458 = !{!434, !434, i64 0}
+!459 = !{!432, !436, i64 16}
+!460 = !{!461, !433, i64 0}
+!461 = !{!"timespec", !433, i64 0, !433, i64 8}
+!462 = !{!461, !433, i64 8}
+!463 = !{!445, !445, i64 0}
+!464 = !{!454, !445, i64 128}
+!465 = !{!451, !451, i64 0}
+!466 = !{!453, !436, i64 0}
+!467 = !{!468, !436, i64 16}
+!468 = !{!"buffered_s", !436, i64 0, !436, i64 8, !436, i64 16, !433, i64 24, !433, i64 32}
+!469 = !{!470, !433, i64 8}
+!470 = !{!"mi_stat_counter_s", !433, i64 0, !433, i64 8}
+!471 = !{!470, !433, i64 0}
+!472 = !{!473, !433, i64 0}
+!473 = !{!"timeval", !433, i64 0, !433, i64 8}
+!474 = !{!473, !433, i64 8}
+!475 = !{!476, !433, i64 8}
+!476 = !{!"mi_arena_s", !434, i64 0, !433, i64 8, !433, i64 16, !445, i64 24, !451, i64 28, !451, i64 29, !451, i64 30, !434, i64 32, !436, i64 40, !436, i64 48, !434, i64 56}
+!477 = !{!476, !433, i64 16}
+!478 = !{!476, !434, i64 0}
+!479 = !{!476, !445, i64 24}
+!480 = !{!476, !451, i64 30}
+!481 = !{!476, !451, i64 28}
+!482 = !{!476, !451, i64 29}
+!483 = !{!476, !434, i64 32}
+!484 = !{!476, !436, i64 40}
+!485 = !{!476, !436, i64 48}
+!486 = !{i64 0, i64 65}
+!487 = !{!488, !436, i64 16}
+!488 = !{!"mi_tld_s", !489, i64 0, !451, i64 8, !436, i64 16, !436, i64 24, !490, i64 32, !493, i64 160, !494, i64 176}
+!489 = !{!"long long", !434, i64 0}
+!490 = !{!"mi_segments_tld_s", !491, i64 0, !491, i64 16, !492, i64 32, !433, i64 56, !433, i64 64, !433, i64 72, !433, i64 80, !433, i64 88, !433, i64 96, !436, i64 104, !436, i64 112, !436, i64 120}
+!491 = !{!"mi_segment_queue_s", !436, i64 0, !436, i64 8}
+!492 = !{!"mi_page_queue_s", !436, i64 0, !436, i64 8, !433, i64 16}
+!493 = !{!"mi_os_tld_s", !433, i64 0, !436, i64 8}
+!494 = !{!"mi_stats_s", !495, i64 0, !495, i64 32, !495, i64 64, !495, i64 96, !495, i64 128, !495, i64 160, !495, i64 192, !495, i64 224, !495, i64 256, !495, i64 288, !495, i64 320, !495, i64 352, !495, i64 384, !495, i64 416, !470, i64 448, !470, i64 464, !470, i64 480, !470, i64 496, !470, i64 512, !470, i64 528, !470, i64 544, !470, i64 560}
+!495 = !{!"mi_stat_count_s", !433, i64 0, !433, i64 8, !433, i64 16, !433, i64 24}
+!496 = !{!488, !436, i64 24}
+!497 = !{!453, !436, i64 3040}
+!498 = !{!453, !433, i64 3016}
+!499 = !{!453, !434, i64 2840}
+!500 = !{!492, !436, i64 0}
+!501 = !{!492, !436, i64 8}
+!502 = !{!"branch_weights", i32 2000, i32 3, i32 2000, i32 2000}
+!503 = !{!443, !436, i64 48}
+!504 = !{!492, !433, i64 16}
+!505 = distinct !{!505, !25}
+!506 = distinct !{!506, !22}
+!507 = distinct !{!507, !30, !25}
+!508 = !{!443, !436, i64 56}
+!509 = !{!488, !436, i64 144}
+!510 = !{!488, !436, i64 152}
+!511 = !{!488, !436, i64 168}
+!512 = distinct !{!512, !22}
+!513 = !{!432, !434, i64 12}
+!514 = !{!495, !433, i64 24}
+!515 = !{!495, !433, i64 16}
+!516 = !{!495, !433, i64 0}
+!517 = !{!495, !433, i64 8}
+!518 = !{!488, !489, i64 0}
+!519 = !{!488, !451, i64 8}
+!520 = !{!453, !451, i64 3048}
+!521 = !{!"branch_weights", i32 1073205, i32 2146410443}
+!522 = !{!"branch_weights", i32 2000, i32 2, i32 2000}
+!523 = !{!453, !433, i64 3024}
+!524 = !{!453, !433, i64 3032}
+!525 = distinct !{!525, !25}
+!526 = distinct !{!526, !22}
+!527 = distinct !{!527, !30, !25}
+!528 = !{!450, !433, i64 40}
+!529 = !{!490, !436, i64 112}
+!530 = !{!450, !433, i64 56}
+!531 = !{!490, !436, i64 104}
+!532 = !{!490, !433, i64 88}
+!533 = !{!450, !436, i64 24}
+!534 = !{!450, !433, i64 72}
+!535 = !{!450, !434, i64 104}
+!536 = !{!490, !433, i64 56}
+!537 = !{!490, !433, i64 64}
+!538 = !{!490, !433, i64 72}
+!539 = !{!490, !433, i64 80}
+!540 = !{!450, !433, i64 64}
+!541 = !{!450, !433, i64 0}
+!542 = !{!443, !444, i64 2}
+!543 = !{!443, !436, i64 24}
+!544 = distinct !{!544, !25}
+!545 = distinct !{!545, !22}
+!546 = distinct !{!546, !30, !25}
+!547 = distinct !{!547, !22}
+!548 = !{!450, !451, i64 8}
+!549 = !{!450, !434, i64 112}
+!550 = !{!443, !434, i64 0}
+!551 = !{!450, !433, i64 80}
+!552 = !{!491, !436, i64 8}
+!553 = !{!450, !436, i64 32}
+!554 = !{!443, !445, i64 20}
+!555 = !{!443, !444, i64 4}
+!556 = !{!490, !436, i64 32}
+!557 = !{!490, !436, i64 40}
+!558 = !{!491, !436, i64 0}
+!559 = !{!450, !433, i64 48}
+!560 = !{!"branch_weights", i32 4001, i32 4000000}
+!561 = distinct !{!561, !25}
+!562 = distinct !{!562, !22}
+!563 = distinct !{!563, !30, !25}
+!564 = distinct !{!564, !25}
+!565 = distinct !{!565, !22}
+!566 = distinct !{!566, !30, !25}
+!567 = !{i32 141452}
+!568 = distinct !{!568, !25}
+!569 = distinct !{!569, !22}
+!570 = distinct !{!570, !30, !25}
+!571 = !{i32 117678}
+!572 = !{!468, !433, i64 24}
+!573 = !{!468, !433, i64 32}
+!574 = !{!468, !436, i64 0}
+!575 = !{!468, !436, i64 8}
+!576 = distinct !{!576, !25}
+!577 = distinct !{!577, !22}
+!578 = distinct !{!578, !30, !25}
+!579 = distinct !{!579, !25}
+!580 = distinct !{!580, !22}
+!581 = distinct !{!581, !30, !25}
+!582 = distinct !{!582, !25}
+!583 = distinct !{!583, !22}
+!584 = distinct !{!584, !30, !25}
+!585 = !{!493, !433, i64 0}
+!586 = !{!587, !434, i64 48}
+!587 = !{!"mem_region_s", !434, i64 0, !434, i64 8, !434, i64 16, !434, i64 24, !434, i64 32, !434, i64 40, !434, i64 48, !433, i64 56}
+!588 = !{!450, !451, i64 9}
+!589 = !{!450, !433, i64 88}
+!590 = distinct !{!590, !22}
+!591 = !{!592, !4, i64 8}
+!592 = !{!"_ZTSSt12_Vector_baseIPvN6kotlin11std_support9allocatorIS0_EEE", !593, i64 0}
+!593 = !{!"_ZTSNSt12_Vector_baseIPvN6kotlin11std_support9allocatorIS0_EEE12_Vector_implE", !4, i64 0, !4, i64 8, !4, i64 16}
+!594 = !{!592, !4, i64 0}
+!595 = !{!592, !4, i64 16}
+!596 = !{!597}
+!597 = distinct !{!597, !598}
+!598 = distinct !{!598, !"LVerDomain"}
+!599 = !{!600}
+!600 = distinct !{!600, !598}
+!601 = distinct !{!601, !25}
+!602 = distinct !{!602, !22}
+!603 = distinct !{!603, !25}
+!604 = !{!605, !4, i64 0}
+!605 = !{!"_ZTS7Dl_info", !4, i64 0, !4, i64 8, !4, i64 16, !4, i64 24}
+!606 = !{!605, !4, i64 16}
+!607 = !{!605, !4, i64 24}
+!608 = !{!609, !49, i64 48}
+!609 = !{!"_ZTS4stat", !49, i64 0, !49, i64 8, !49, i64 16, !11, i64 24, !11, i64 28, !11, i64 32, !11, i64 36, !49, i64 40, !49, i64 48, !49, i64 56, !49, i64 64, !89, i64 72, !89, i64 88, !89, i64 104, !5, i64 120}
+!610 = !{!611, !49, i64 40}
+!611 = !{!"_ZTS10Elf64_Ehdr", !5, i64 0, !28, i64 16, !28, i64 18, !11, i64 20, !49, i64 24, !49, i64 32, !49, i64 40, !11, i64 48, !28, i64 52, !28, i64 54, !28, i64 56, !28, i64 58, !28, i64 60, !28, i64 62}
+!612 = !{!611, !28, i64 60}
+!613 = !{!614, !11, i64 4}
+!614 = !{!"_ZTS10Elf64_Shdr", !11, i64 0, !11, i64 4, !49, i64 8, !49, i64 16, !49, i64 24, !49, i64 32, !11, i64 40, !11, i64 44, !49, i64 48, !49, i64 56}
+!615 = !{!614, !49, i64 24}
+!616 = !{!614, !49, i64 32}
+!617 = !{!614, !11, i64 40}
+!618 = !{!619, !4, i64 8}
+!619 = !{!"_ZTSSt12_Vector_baseIN12_GLOBAL__N_19SymRecordEN6kotlin11std_support9allocatorIS1_EEE", !620, i64 0}
+!620 = !{!"_ZTSNSt12_Vector_baseIN12_GLOBAL__N_19SymRecordEN6kotlin11std_support9allocatorIS1_EEE12_Vector_implE", !4, i64 0, !4, i64 8, !4, i64 16}
+!621 = !{!619, !4, i64 16}
+!622 = !{i64 0, i64 8, !3, i64 8, i64 8, !3, i64 16, i64 8, !3}
+!623 = !{!619, !4, i64 0}
+!624 = !{!625, !49, i64 8}
+!625 = !{!"_ZTS9Elf64_Sym", !11, i64 0, !5, i64 4, !5, i64 5, !28, i64 6, !49, i64 8, !49, i64 16}
+!626 = !{!625, !49, i64 16}
+!627 = !{!625, !11, i64 0}
+!628 = !{!629}
+!629 = distinct !{!629, !630}
+!630 = distinct !{!630, !"LVerDomain"}
+!631 = !{!632}
+!632 = distinct !{!632, !630}
+!633 = distinct !{!633, !25}
+!634 = distinct !{!634, !22}
+!635 = distinct !{!635, !25}
+!636 = !{!637, !49, i64 0}
+!637 = !{!"_ZTSN12_GLOBAL__N_19BacktraceE", !49, i64 0, !49, i64 8, !638, i64 16}
+!638 = !{!"_ZTSN6kotlin11std_support4spanIPvLm18446744073709551615EEE", !4, i64 0, !49, i64 8}
+!639 = !{!637, !49, i64 8}
+!640 = !{i64 0, i64 8, !3, i64 8, i64 8, !87}
+!641 = !{!638, !49, i64 8}
+!642 = !{!638, !4, i64 0}
+!643 = distinct !{!643, !22}
+!644 = distinct !{!644, !22}
+!645 = !{!646, !4, i64 8}
+!646 = !{!"_ZTSN12_GLOBAL__N_111CleanerImplE", !15, i64 0, !4, i64 8}
+!647 = !{!648, !49, i64 8}
+!648 = !{!"_ZTSSt10_HashtableIiSt4pairIKiP6WorkerEN6kotlin11std_support9allocatorIS4_EENSt8__detail10_Select1stESt8equal_toIiESt4hashIiENS9_18_Mod_range_hashingENS9_20_Default_ranged_hashENS9_20_Prime_rehash_policyENS9_17_Hashtable_traitsILb0ELb0ELb1EEEE", !4, i64 0, !49, i64 8, !204, i64 16, !49, i64 24, !205, i64 32, !4, i64 48}
+!649 = !{!648, !4, i64 0}
+!650 = !{!651, !4, i64 8}
+!651 = !{!"_ZTSSt4pairIKiP6WorkerE", !11, i64 0, !4, i64 8}
+!652 = !{!653, !4, i64 48}
+!653 = !{!"_ZTSSt11_Deque_baseIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE", !654, i64 0}
+!654 = !{!"_ZTSNSt11_Deque_baseIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE11_Deque_implE", !4, i64 0, !49, i64 8, !655, i64 16, !655, i64 48}
+!655 = !{!"_ZTSSt15_Deque_iteratorIN12_GLOBAL__N_13JobERS1_PS1_E", !4, i64 0, !4, i64 8, !4, i64 16, !4, i64 24}
+!656 = !{!653, !4, i64 64}
+!657 = !{i64 0, i64 4, !50, i64 8, i64 8, !3, i64 16, i64 8, !3, i64 24, i64 8, !3, i64 32, i64 4, !71, i64 8, i64 8, !3, i64 16, i64 1, !69, i64 8, i64 8, !3, i64 16, i64 8, !87}
+!658 = !{!653, !49, i64 8}
+!659 = !{!653, !4, i64 72}
+!660 = !{!653, !4, i64 0}
+!661 = !{!653, !4, i64 40}
+!662 = !{!655, !4, i64 24}
+!663 = !{!655, !4, i64 8}
+!664 = !{!655, !4, i64 16}
+!665 = !{!666, !4, i64 8}
+!666 = !{!"_ZTSN12_GLOBAL__N_120WorkerBoundReferenceE", !15, i64 0, !4, i64 8}
+!667 = !{!668, !4, i64 0}
+!668 = !{!"_ZTS16KRefSharedHolder", !4, i64 0, !4, i64 8}
+!669 = !{!668, !4, i64 8}
+!670 = !{!671, !4, i64 0}
+!671 = !{!"_ZTSSt10_HashtableIiSt4pairIKiPN12_GLOBAL__N_16FutureEEN6kotlin11std_support9allocatorIS5_EENSt8__detail10_Select1stESt8equal_toIiESt4hashIiENSA_18_Mod_range_hashingENSA_20_Default_ranged_hashENSA_20_Prime_rehash_policyENSA_17_Hashtable_traitsILb0ELb0ELb1EEEE", !4, i64 0, !49, i64 8, !204, i64 16, !49, i64 24, !205, i64 32, !4, i64 48}
+!672 = !{!671, !49, i64 8}
+!673 = !{!674, !4, i64 0}
+!674 = !{!"_ZTSSt10_HashtableIiSt4pairIKimEN6kotlin11std_support9allocatorIS2_EENSt8__detail10_Select1stESt8equal_toIiESt4hashIiENS7_18_Mod_range_hashingENS7_20_Default_ranged_hashENS7_20_Prime_rehash_policyENS7_17_Hashtable_traitsILb0ELb0ELb1EEEE", !4, i64 0, !49, i64 8, !204, i64 16, !49, i64 24, !205, i64 32, !4, i64 48}
+!675 = !{!674, !49, i64 8}
+!676 = !{!677, !11, i64 256}
+!677 = !{!"_ZTSN12_GLOBAL__N_15StateE", !5, i64 0, !5, i64 40, !678, i64 88, !679, i64 144, !680, i64 200, !11, i64 256, !11, i64 260, !11, i64 264}
+!678 = !{!"_ZTSSt13unordered_mapIiPN12_GLOBAL__N_16FutureESt4hashIiESt8equal_toIiEN6kotlin11std_support9allocatorISt4pairIKiS2_EEEE", !671, i64 0}
+!679 = !{!"_ZTSSt13unordered_mapIiP6WorkerSt4hashIiESt8equal_toIiEN6kotlin11std_support9allocatorISt4pairIKiS1_EEEE", !648, i64 0}
+!680 = !{!"_ZTSSt13unordered_mapIimSt4hashIiESt8equal_toIiEN6kotlin11std_support9allocatorISt4pairIKimEEEE", !674, i64 0}
+!681 = !{!677, !11, i64 260}
+!682 = !{!677, !11, i64 264}
+!683 = !{!674, !4, i64 16}
+!684 = !{!648, !4, i64 16}
+!685 = !{!671, !4, i64 16}
+!686 = !{!"branch_weights", i32 1, i32 1048575}
+!687 = !{!688, !4, i64 0}
+!688 = !{!"_ZTSN12_GLOBAL__N_116TerminateHandlerE", !4, i64 0}
+!689 = !{!690, !11, i64 0}
+!690 = !{!"_ZTSN6kotlin2mm10ThreadDataE", !11, i64 0, !691, i64 8, !273, i64 64, !692, i64 168, !693, i64 224, !8, i64 280, !694, i64 288, !698, i64 296, !252, i64 320}
+!691 = !{!"_ZTSN6kotlin2mm15GlobalsRegistry11ThreadQueueE"}
+!692 = !{!"_ZTSN6kotlin2mm17StableRefRegistry11ThreadQueueE"}
+!693 = !{!"_ZTSN6kotlin2mm22ExtraObjectDataFactory11ThreadQueueE"}
+!694 = !{!"_ZTSN6kotlin2gc2GC10ThreadDataE", !695, i64 0}
+!695 = !{!"_ZTSSt10unique_ptrIN6kotlin2gc2GC10ThreadData4ImplENS0_11std_support17allocator_deleterIS4_NS5_9allocatorIS4_EEEEE", !696, i64 0}
+!696 = !{!"_ZTSSt15__uniq_ptr_implIN6kotlin2gc2GC10ThreadData4ImplENS0_11std_support17allocator_deleterIS4_NS5_9allocatorIS4_EEEEE", !697, i64 0}
+!697 = !{!"_ZTSSt5tupleIJPN6kotlin2gc2GC10ThreadData4ImplENS0_11std_support17allocator_deleterIS4_NS6_9allocatorIS4_EEEEEE"}
+!698 = !{!"_ZTSSt6vectorISt4pairIPP9ObjHeaderS2_EN6kotlin11std_support9allocatorIS4_EEE"}
+!699 = !{!700}
+!700 = distinct !{!700, !701, !"_ZN6kotlin11std_support15allocate_uniqueINS_14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS0_9allocatorIS4_EEE4NodeENS6_IS9_EEJRSA_iEEEDaRKT0_DpOT1_: argument 0"}
+!701 = distinct !{!701, !"_ZN6kotlin11std_support15allocate_uniqueINS_14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS0_9allocatorIS4_EEE4NodeENS6_IS9_EEJRSA_iEEEDaRKT0_DpOT1_"}
+!702 = !{!253, !36, i64 0}
+!703 = !{!704, !4, i64 360}
+!704 = !{!"_ZTSN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEE4NodeE", !690, i64 8, !705, i64 352, !4, i64 360}
+!705 = !{!"_ZTSSt10unique_ptrIN6kotlin14SingleLockListINS0_2mm10ThreadDataESt15recursive_mutexNS0_11std_support9allocatorIS3_EEE4NodeENS5_17allocator_deleterIS9_NS6_IS9_EEEEE", !706, i64 0}
+!706 = !{!"_ZTSSt15__uniq_ptr_implIN6kotlin14SingleLockListINS0_2mm10ThreadDataESt15recursive_mutexNS0_11std_support9allocatorIS3_EEE4NodeENS5_17allocator_deleterIS9_NS6_IS9_EEEEE", !707, i64 0}
+!707 = !{!"_ZTSSt5tupleIJPN6kotlin14SingleLockListINS0_2mm10ThreadDataESt15recursive_mutexNS0_11std_support9allocatorIS3_EEE4NodeENS5_17allocator_deleterIS9_NS6_IS9_EEEEEE"}
+!708 = !{!709, !4, i64 16}
+!709 = !{!"_ZTSN6kotlin14SingleLockListINS_2mm10ThreadDataESt15recursive_mutexNS_11std_support9allocatorIS2_EEEE", !705, i64 8, !4, i64 16, !710, i64 24}
+!710 = !{!"_ZTSSt15recursive_mutex"}
+!711 = !{!712, !4, i64 0}
+!712 = !{!"_ZTSN12_GLOBAL__N_112RuntimeStateE", !4, i64 0, !4, i64 8, !5, i64 16}
+!713 = !{!714, !11, i64 0}
+!714 = !{!"_ZTS6Worker", !11, i64 0, !5, i64 4, !715, i64 8, !716, i64 88, !4, i64 136, !5, i64 144, !5, i64 184, !5, i64 232, !37, i64 236, !49, i64 240, !4, i64 248}
+!715 = !{!"_ZTSSt5dequeIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE"}
+!716 = !{!"_ZTSSt8multisetIN12_GLOBAL__N_13JobENS0_10JobCompareEN6kotlin11std_support9allocatorIS1_EEE", !717, i64 0}
+!717 = !{!"_ZTSSt8_Rb_treeIN12_GLOBAL__N_13JobES1_St9_IdentityIS1_ENS0_10JobCompareEN6kotlin11std_support9allocatorIS1_EEE", !718, i64 0}
+!718 = !{!"_ZTSNSt8_Rb_treeIN12_GLOBAL__N_13JobES1_St9_IdentityIS1_ENS0_10JobCompareEN6kotlin11std_support9allocatorIS1_EEE13_Rb_tree_implIS4_Lb1EEE"}
+!719 = !{!714, !5, i64 4}
+!720 = !{!653, !4, i64 16}
+!721 = !{!722, !4, i64 16}
+!722 = !{!"_ZTSSt15_Rb_tree_header", !723, i64 0, !49, i64 32}
+!723 = !{!"_ZTSSt18_Rb_tree_node_base", !724, i64 0, !4, i64 8, !4, i64 16, !4, i64 24}
+!724 = !{!"_ZTSSt14_Rb_tree_color", !5, i64 0}
+!725 = !{!722, !4, i64 24}
+!726 = !{!651, !11, i64 0}
+!727 = !{!648, !49, i64 24}
+!728 = !{!648, !4, i64 48}
+!729 = !{!714, !49, i64 240}
+!730 = !{!714, !4, i64 248}
+!731 = !{!712, !4, i64 8}
+!732 = !{!733, !4, i64 0}
+!733 = !{!"_ZTS8InitNode", !4, i64 0, !4, i64 8}
+!734 = !{!219, !4, i64 8}
+!735 = !{!219, !4, i64 16}
+!736 = !{!737}
+!737 = distinct !{!737, !738}
+!738 = distinct !{!738, !"LVerDomain"}
 !739 = !{!740}
-!740 = distinct !{!740, !741, !"_ZNSt5dequeIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE5beginEv: argument 0"}
-!741 = distinct !{!741, !"_ZNSt5dequeIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE5beginEv"}
-!742 = !{!743}
-!743 = distinct !{!743, !744, !"_ZNSt5dequeIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE3endEv: argument 0"}
-!744 = distinct !{!744, !"_ZNSt5dequeIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE3endEv"}
-!745 = !{!702, !4, i64 136}
-!746 = !{!710, !4, i64 8}
-!747 = !{!748, !50, i64 8}
-!748 = !{!"_ZTSSt4pairIKimE", !11, i64 0, !50, i64 8}
-!749 = !{!662, !50, i64 24}
-!750 = !{!751, !11, i64 0}
-!751 = !{!"_ZTSN12_GLOBAL__N_16FutureE", !11, i64 0, !11, i64 4, !4, i64 8, !5, i64 16, !5, i64 56}
-!752 = !{!751, !4, i64 8}
-!753 = !{!711, !4, i64 24}
-!754 = !{!711, !4, i64 16}
-!755 = !{!756, !4, i64 0}
-!756 = !{!"_ZTSNSt15__exception_ptr13exception_ptrE", !4, i64 0}
-!757 = !{!758, !11, i64 0}
-!758 = !{!"_ZTSN12_GLOBAL__N_13$_0E", !11, i64 0, !11, i64 4}
-!759 = !{void ()* @"kfun:Blackhole.$init_thread_local#internal", void ()* @"kfun:kotlin.native.concurrent.CurrentThread.$init_thread_local#internal"}
+!740 = distinct !{!740, !738}
+!741 = distinct !{!741, !25}
+!742 = distinct !{!742, !22}
+!743 = distinct !{!743, !25}
+!744 = !{!273, !276, i64 80}
+!745 = !{!712, !5, i64 16}
+!746 = !{!747, !4, i64 8}
+!747 = !{!"_ZTSN5konan16DestructorRecordE", !4, i64 0, !4, i64 8, !4, i64 16}
+!748 = !{!747, !4, i64 16}
+!749 = !{!747, !4, i64 0}
+!750 = !{!655, !4, i64 0}
+!751 = !{!752}
+!752 = distinct !{!752, !753, !"_ZNSt5dequeIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE5beginEv: argument 0"}
+!753 = distinct !{!753, !"_ZNSt5dequeIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE5beginEv"}
+!754 = !{!755}
+!755 = distinct !{!755, !756, !"_ZNSt5dequeIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE3endEv: argument 0"}
+!756 = distinct !{!756, !"_ZNSt5dequeIN12_GLOBAL__N_13JobEN6kotlin11std_support9allocatorIS1_EEE3endEv"}
+!757 = !{!714, !4, i64 136}
+!758 = !{!722, !4, i64 8}
+!759 = !{!760, !49, i64 8}
+!760 = !{!"_ZTSSt4pairIKimE", !11, i64 0, !49, i64 8}
+!761 = !{!674, !49, i64 24}
+!762 = !{!763, !11, i64 0}
+!763 = !{!"_ZTSN12_GLOBAL__N_16FutureE", !11, i64 0, !11, i64 4, !4, i64 8, !5, i64 16, !5, i64 56}
+!764 = !{!763, !4, i64 8}
+!765 = !{!723, !4, i64 24}
+!766 = !{!723, !4, i64 16}
+!767 = !{!768, !4, i64 0}
+!768 = !{!"_ZTSNSt15__exception_ptr13exception_ptrE", !4, i64 0}
+!769 = !{!770, !11, i64 0}
+!770 = !{!"_ZTSN12_GLOBAL__N_13$_0E", !11, i64 0, !11, i64 4}
+!771 = !{!772, !4, i64 0}
+!772 = !{!"_ZTSZN12_GLOBAL__N_131terminateWithUnhandledExceptionEP9ObjHeaderE3$_1", !4, i64 0}
+!773 = !{void ()* @"kfun:Blackhole.$init_thread_local#internal", void ()* @"kfun:kotlin.native.concurrent.CurrentThread.$init_thread_local#internal"}
